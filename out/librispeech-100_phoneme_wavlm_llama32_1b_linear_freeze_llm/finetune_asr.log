[2024-12-16 01:06:12,177][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': False, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_freeze_llm', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': True}
[2024-12-16 01:06:12,177][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-16 01:06:12,177][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-16 01:06:12,177][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'librispeech-100_phoneme_wavlm_llama32_1b_linear_freeze_llm', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-16_01-06-11.txt', 'log_interval': 5}
[2024-12-16 01:06:35,385][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-16 01:06:40,822][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:06:40,825][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-16 01:06:40,827][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:06:40,828][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-16 01:06:49,109][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 01:06:49,111][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-16 01:06:49,112][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 01:06:49,113][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 0.0 Million params

[2024-12-16 01:06:49,217][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-12-16 01:06:49,218][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-12-16 01:06:49,218][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-16 01:06:49,221][slam_llm.utils.train_utils][INFO] - --> asr has 14.68416 Million params

[2024-12-16 01:06:51,181][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-16 01:06:53,140][root][INFO] - --> Training Set Length = 28539
[2024-12-16 01:06:53,157][root][INFO] - --> Validation Set Length = 2703
[2024-12-16 01:06:53,157][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-16 01:06:53,158][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-16 01:12:55,613][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': False, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_freeze_llm', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': True}
[2024-12-16 01:12:55,613][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-16 01:12:55,613][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-16 01:12:55,613][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'librispeech-100_phoneme_wavlm_llama32_1b_linear_freeze_llm', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-16_01-12-55.txt', 'log_interval': 5}
[2024-12-16 01:13:15,415][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-16 01:13:20,827][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:13:20,830][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-16 01:13:20,832][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:13:20,833][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-16 01:13:26,526][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 01:13:26,527][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-16 01:13:26,529][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 01:13:26,529][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 0.0 Million params

[2024-12-16 01:13:26,633][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-12-16 01:13:26,633][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-12-16 01:13:26,634][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-16 01:13:26,636][slam_llm.utils.train_utils][INFO] - --> asr has 14.68416 Million params

[2024-12-16 01:13:28,638][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-16 01:13:29,584][root][INFO] - --> Training Set Length = 28539
[2024-12-16 01:13:29,600][root][INFO] - --> Validation Set Length = 2703
[2024-12-16 01:13:29,600][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-16 01:13:29,601][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-17 01:32:52,384][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': False, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_freeze_llm', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': False}
[2024-12-17 01:32:52,384][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-17 01:32:52,384][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-17 01:32:52,384][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'librispeech-100_phoneme_wavlm_llama32_1b_linear_freeze_llm', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-17_01-32-51.txt', 'log_interval': 5}
[2024-12-17 01:33:22,011][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-17 01:33:27,278][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-17 01:33:27,282][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-17 01:33:27,284][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-17 01:33:27,285][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-17 01:33:38,174][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-17 01:33:38,176][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-17 01:33:38,177][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-17 01:33:38,178][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 0.0 Million params

[2024-12-17 01:33:38,293][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-12-17 01:33:38,293][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-12-17 01:33:38,293][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-17 01:33:38,295][slam_llm.utils.train_utils][INFO] - --> asr has 14.68416 Million params

[2024-12-17 01:33:40,211][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-17 01:33:44,651][root][INFO] - --> Training Set Length = 28539
[2024-12-17 01:33:44,681][root][INFO] - --> Validation Set Length = 2703
[2024-12-17 01:33:44,682][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-17 01:33:44,682][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-17 01:33:47,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:50,206][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-12-17 01:33:52,647][root][INFO] - Training Epoch: 1/2, step 0/7134 completed (loss: 4.078270435333252, acc: 0.22585438191890717)
[2024-12-17 01:33:52,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:53,059][root][INFO] - Training Epoch: 1/2, step 1/7134 completed (loss: 4.166868686676025, acc: 0.20083682239055634)
[2024-12-17 01:33:53,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:53,415][root][INFO] - Training Epoch: 1/2, step 2/7134 completed (loss: 3.935776710510254, acc: 0.2650602459907532)
[2024-12-17 01:33:53,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:53,771][root][INFO] - Training Epoch: 1/2, step 3/7134 completed (loss: 4.070797443389893, acc: 0.23687580227851868)
[2024-12-17 01:33:53,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:54,153][root][INFO] - Training Epoch: 1/2, step 4/7134 completed (loss: 4.022093772888184, acc: 0.22510232031345367)
[2024-12-17 01:33:54,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:54,535][root][INFO] - Training Epoch: 1/2, step 5/7134 completed (loss: 3.9014978408813477, acc: 0.2411167472600937)
[2024-12-17 01:33:54,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:54,893][root][INFO] - Training Epoch: 1/2, step 6/7134 completed (loss: 3.926755905151367, acc: 0.2648475170135498)
[2024-12-17 01:33:55,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:55,247][root][INFO] - Training Epoch: 1/2, step 7/7134 completed (loss: 3.988420248031616, acc: 0.2254047393798828)
[2024-12-17 01:33:55,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:55,628][root][INFO] - Training Epoch: 1/2, step 8/7134 completed (loss: 4.006176471710205, acc: 0.2228335589170456)
[2024-12-17 01:33:55,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:55,993][root][INFO] - Training Epoch: 1/2, step 9/7134 completed (loss: 3.95269775390625, acc: 0.26356589794158936)
[2024-12-17 01:33:56,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:56,427][root][INFO] - Training Epoch: 1/2, step 10/7134 completed (loss: 4.086457252502441, acc: 0.22048364579677582)
[2024-12-17 01:33:56,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:56,813][root][INFO] - Training Epoch: 1/2, step 11/7134 completed (loss: 4.164839267730713, acc: 0.227016881108284)
[2024-12-17 01:33:56,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:57,238][root][INFO] - Training Epoch: 1/2, step 12/7134 completed (loss: 3.806752920150757, acc: 0.2557200491428375)
[2024-12-17 01:33:57,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:57,586][root][INFO] - Training Epoch: 1/2, step 13/7134 completed (loss: 3.956954002380371, acc: 0.236588716506958)
[2024-12-17 01:33:57,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:57,961][root][INFO] - Training Epoch: 1/2, step 14/7134 completed (loss: 3.9556756019592285, acc: 0.23025210201740265)
[2024-12-17 01:33:58,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:58,311][root][INFO] - Training Epoch: 1/2, step 15/7134 completed (loss: 3.966261863708496, acc: 0.25473320484161377)
[2024-12-17 01:33:58,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:58,668][root][INFO] - Training Epoch: 1/2, step 16/7134 completed (loss: 3.928222179412842, acc: 0.25)
[2024-12-17 01:33:58,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:58,972][root][INFO] - Training Epoch: 1/2, step 17/7134 completed (loss: 4.263674259185791, acc: 0.22162161767482758)
[2024-12-17 01:33:59,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:59,331][root][INFO] - Training Epoch: 1/2, step 18/7134 completed (loss: 3.7572274208068848, acc: 0.2713068127632141)
[2024-12-17 01:33:59,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:59,715][root][INFO] - Training Epoch: 1/2, step 19/7134 completed (loss: 3.8068504333496094, acc: 0.25517240166664124)
[2024-12-17 01:33:59,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:00,071][root][INFO] - Training Epoch: 1/2, step 20/7134 completed (loss: 3.825864791870117, acc: 0.24210526049137115)
[2024-12-17 01:34:00,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:00,472][root][INFO] - Training Epoch: 1/2, step 21/7134 completed (loss: 3.6004135608673096, acc: 0.26932990550994873)
[2024-12-17 01:34:00,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:00,841][root][INFO] - Training Epoch: 1/2, step 22/7134 completed (loss: 3.6200942993164062, acc: 0.28674352169036865)
[2024-12-17 01:34:01,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:01,216][root][INFO] - Training Epoch: 1/2, step 23/7134 completed (loss: 3.4992761611938477, acc: 0.28940218687057495)
[2024-12-17 01:34:01,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:01,572][root][INFO] - Training Epoch: 1/2, step 24/7134 completed (loss: 3.6331522464752197, acc: 0.3064066767692566)
[2024-12-17 01:34:01,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:01,980][root][INFO] - Training Epoch: 1/2, step 25/7134 completed (loss: 3.6047792434692383, acc: 0.27272728085517883)
[2024-12-17 01:34:02,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:02,361][root][INFO] - Training Epoch: 1/2, step 26/7134 completed (loss: 3.7030248641967773, acc: 0.2743362784385681)
[2024-12-17 01:34:02,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:02,727][root][INFO] - Training Epoch: 1/2, step 27/7134 completed (loss: 3.677323341369629, acc: 0.28064993023872375)
[2024-12-17 01:34:02,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:03,108][root][INFO] - Training Epoch: 1/2, step 28/7134 completed (loss: 3.674077272415161, acc: 0.26867470145225525)
[2024-12-17 01:34:03,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:03,492][root][INFO] - Training Epoch: 1/2, step 29/7134 completed (loss: 3.689910650253296, acc: 0.28328612446784973)
[2024-12-17 01:34:03,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:03,876][root][INFO] - Training Epoch: 1/2, step 30/7134 completed (loss: 3.6757092475891113, acc: 0.2305084764957428)
[2024-12-17 01:34:03,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:04,225][root][INFO] - Training Epoch: 1/2, step 31/7134 completed (loss: 3.6777503490448, acc: 0.25529661774635315)
[2024-12-17 01:34:04,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:04,595][root][INFO] - Training Epoch: 1/2, step 32/7134 completed (loss: 3.618021249771118, acc: 0.2769830822944641)
[2024-12-17 01:34:04,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:04,918][root][INFO] - Training Epoch: 1/2, step 33/7134 completed (loss: 3.832490921020508, acc: 0.2529880404472351)
[2024-12-17 01:34:05,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:05,295][root][INFO] - Training Epoch: 1/2, step 34/7134 completed (loss: 3.6222798824310303, acc: 0.2590855658054352)
[2024-12-17 01:34:05,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:05,742][root][INFO] - Training Epoch: 1/2, step 35/7134 completed (loss: 3.489983081817627, acc: 0.28180962800979614)
[2024-12-17 01:34:05,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:06,123][root][INFO] - Training Epoch: 1/2, step 36/7134 completed (loss: 3.5329301357269287, acc: 0.279044508934021)
[2024-12-17 01:34:06,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:06,493][root][INFO] - Training Epoch: 1/2, step 37/7134 completed (loss: 3.6028711795806885, acc: 0.2590738534927368)
[2024-12-17 01:34:06,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:06,837][root][INFO] - Training Epoch: 1/2, step 38/7134 completed (loss: 3.710881233215332, acc: 0.2514880895614624)
[2024-12-17 01:34:06,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:07,199][root][INFO] - Training Epoch: 1/2, step 39/7134 completed (loss: 3.600086212158203, acc: 0.2841677963733673)
[2024-12-17 01:34:07,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:07,544][root][INFO] - Training Epoch: 1/2, step 40/7134 completed (loss: 3.9947800636291504, acc: 0.24887892603874207)
[2024-12-17 01:34:07,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:07,888][root][INFO] - Training Epoch: 1/2, step 41/7134 completed (loss: 3.6243858337402344, acc: 0.28155338764190674)
[2024-12-17 01:34:08,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:08,268][root][INFO] - Training Epoch: 1/2, step 42/7134 completed (loss: 3.6344945430755615, acc: 0.2510519027709961)
[2024-12-17 01:34:08,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:08,602][root][INFO] - Training Epoch: 1/2, step 43/7134 completed (loss: 3.572054862976074, acc: 0.26709678769111633)
[2024-12-17 01:34:08,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:08,959][root][INFO] - Training Epoch: 1/2, step 44/7134 completed (loss: 3.592822551727295, acc: 0.2738853394985199)
[2024-12-17 01:34:09,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:09,357][root][INFO] - Training Epoch: 1/2, step 45/7134 completed (loss: 3.4724199771881104, acc: 0.2806067168712616)
[2024-12-17 01:34:09,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:09,713][root][INFO] - Training Epoch: 1/2, step 46/7134 completed (loss: 3.5547473430633545, acc: 0.2773333191871643)
[2024-12-17 01:34:09,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:10,096][root][INFO] - Training Epoch: 1/2, step 47/7134 completed (loss: 3.4398868083953857, acc: 0.30591630935668945)
[2024-12-17 01:34:10,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:10,522][root][INFO] - Training Epoch: 1/2, step 48/7134 completed (loss: 3.4249980449676514, acc: 0.28426966071128845)
[2024-12-17 01:34:10,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:10,902][root][INFO] - Training Epoch: 1/2, step 49/7134 completed (loss: 3.591679334640503, acc: 0.26474621891975403)
[2024-12-17 01:34:11,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:11,319][root][INFO] - Training Epoch: 1/2, step 50/7134 completed (loss: 3.483705997467041, acc: 0.27566319704055786)
[2024-12-17 01:34:11,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:11,644][root][INFO] - Training Epoch: 1/2, step 51/7134 completed (loss: 3.4503297805786133, acc: 0.2931472063064575)
[2024-12-17 01:34:11,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:11,991][root][INFO] - Training Epoch: 1/2, step 52/7134 completed (loss: 3.607295274734497, acc: 0.2699187099933624)
[2024-12-17 01:34:12,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:12,344][root][INFO] - Training Epoch: 1/2, step 53/7134 completed (loss: 3.5252490043640137, acc: 0.2690288722515106)
[2024-12-17 01:34:12,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:12,726][root][INFO] - Training Epoch: 1/2, step 54/7134 completed (loss: 3.4440290927886963, acc: 0.29229000210762024)
[2024-12-17 01:34:12,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:13,085][root][INFO] - Training Epoch: 1/2, step 55/7134 completed (loss: 3.4340500831604004, acc: 0.27157360315322876)
[2024-12-17 01:34:13,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:13,449][root][INFO] - Training Epoch: 1/2, step 56/7134 completed (loss: 3.58402681350708, acc: 0.2874999940395355)
[2024-12-17 01:34:13,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:13,834][root][INFO] - Training Epoch: 1/2, step 57/7134 completed (loss: 3.4396848678588867, acc: 0.2745341658592224)
[2024-12-17 01:34:13,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:14,213][root][INFO] - Training Epoch: 1/2, step 58/7134 completed (loss: 3.439483642578125, acc: 0.28937259316444397)
[2024-12-17 01:34:14,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:14,567][root][INFO] - Training Epoch: 1/2, step 59/7134 completed (loss: 3.279184103012085, acc: 0.3120567500591278)
[2024-12-17 01:34:14,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:14,968][root][INFO] - Training Epoch: 1/2, step 60/7134 completed (loss: 3.495229482650757, acc: 0.2599431872367859)
[2024-12-17 01:34:15,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:15,347][root][INFO] - Training Epoch: 1/2, step 61/7134 completed (loss: 3.371429920196533, acc: 0.2888616919517517)
[2024-12-17 01:34:15,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:15,712][root][INFO] - Training Epoch: 1/2, step 62/7134 completed (loss: 3.42446231842041, acc: 0.28081321716308594)
[2024-12-17 01:34:15,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:16,078][root][INFO] - Training Epoch: 1/2, step 63/7134 completed (loss: 3.2940404415130615, acc: 0.2988792061805725)
[2024-12-17 01:34:16,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:16,479][root][INFO] - Training Epoch: 1/2, step 64/7134 completed (loss: 3.4029524326324463, acc: 0.2634408473968506)
[2024-12-17 01:34:16,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:16,863][root][INFO] - Training Epoch: 1/2, step 65/7134 completed (loss: 3.528839111328125, acc: 0.2309582382440567)
[2024-12-17 01:34:16,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:17,212][root][INFO] - Training Epoch: 1/2, step 66/7134 completed (loss: 3.6905486583709717, acc: 0.2526881694793701)
[2024-12-17 01:34:17,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:17,592][root][INFO] - Training Epoch: 1/2, step 67/7134 completed (loss: 3.4089651107788086, acc: 0.2732026278972626)
[2024-12-17 01:34:17,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:17,932][root][INFO] - Training Epoch: 1/2, step 68/7134 completed (loss: 3.481607437133789, acc: 0.23096774518489838)
[2024-12-17 01:34:18,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:18,289][root][INFO] - Training Epoch: 1/2, step 69/7134 completed (loss: 3.300971269607544, acc: 0.2817955017089844)
[2024-12-17 01:34:18,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:18,668][root][INFO] - Training Epoch: 1/2, step 70/7134 completed (loss: 3.539515733718872, acc: 0.26140350103378296)
[2024-12-17 01:34:18,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:19,053][root][INFO] - Training Epoch: 1/2, step 71/7134 completed (loss: 3.4674954414367676, acc: 0.2759103775024414)
[2024-12-17 01:34:19,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:19,415][root][INFO] - Training Epoch: 1/2, step 72/7134 completed (loss: 3.3799421787261963, acc: 0.26854220032691956)
[2024-12-17 01:34:19,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:19,737][root][INFO] - Training Epoch: 1/2, step 73/7134 completed (loss: 3.4433560371398926, acc: 0.25951087474823)
[2024-12-17 01:34:19,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:20,104][root][INFO] - Training Epoch: 1/2, step 74/7134 completed (loss: 3.4037697315216064, acc: 0.28969359397888184)
[2024-12-17 01:34:20,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:20,502][root][INFO] - Training Epoch: 1/2, step 75/7134 completed (loss: 3.422238826751709, acc: 0.2959641218185425)
[2024-12-17 01:34:20,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:20,868][root][INFO] - Training Epoch: 1/2, step 76/7134 completed (loss: 3.300726890563965, acc: 0.2821158766746521)
[2024-12-17 01:34:21,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:21,243][root][INFO] - Training Epoch: 1/2, step 77/7134 completed (loss: 3.2557246685028076, acc: 0.2957393527030945)
[2024-12-17 01:34:21,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:21,630][root][INFO] - Training Epoch: 1/2, step 78/7134 completed (loss: 3.378203868865967, acc: 0.276729553937912)
[2024-12-17 01:34:21,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:21,979][root][INFO] - Training Epoch: 1/2, step 79/7134 completed (loss: 3.427781105041504, acc: 0.2839506268501282)
[2024-12-17 01:34:22,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:22,331][root][INFO] - Training Epoch: 1/2, step 80/7134 completed (loss: 3.286261796951294, acc: 0.2864583432674408)
[2024-12-17 01:34:22,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:22,704][root][INFO] - Training Epoch: 1/2, step 81/7134 completed (loss: 3.2564117908477783, acc: 0.3049738109111786)
[2024-12-17 01:34:22,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:23,079][root][INFO] - Training Epoch: 1/2, step 82/7134 completed (loss: 3.202548027038574, acc: 0.3140028417110443)
[2024-12-17 01:34:23,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:23,489][root][INFO] - Training Epoch: 1/2, step 83/7134 completed (loss: 3.262857437133789, acc: 0.3071979582309723)
[2024-12-17 01:34:23,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:23,848][root][INFO] - Training Epoch: 1/2, step 84/7134 completed (loss: 3.3592498302459717, acc: 0.2832469642162323)
[2024-12-17 01:34:24,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:24,169][root][INFO] - Training Epoch: 1/2, step 85/7134 completed (loss: 3.6149604320526123, acc: 0.2434367537498474)
[2024-12-17 01:34:24,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:24,540][root][INFO] - Training Epoch: 1/2, step 86/7134 completed (loss: 3.442162275314331, acc: 0.2683486342430115)
[2024-12-17 01:34:24,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:24,920][root][INFO] - Training Epoch: 1/2, step 87/7134 completed (loss: 3.1976301670074463, acc: 0.2980910539627075)
[2024-12-17 01:34:25,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:25,280][root][INFO] - Training Epoch: 1/2, step 88/7134 completed (loss: 3.3499624729156494, acc: 0.2669433057308197)
[2024-12-17 01:34:25,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:25,649][root][INFO] - Training Epoch: 1/2, step 89/7134 completed (loss: 3.2659528255462646, acc: 0.30423620343208313)
[2024-12-17 01:34:25,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:26,029][root][INFO] - Training Epoch: 1/2, step 90/7134 completed (loss: 3.4476873874664307, acc: 0.25)
[2024-12-17 01:34:26,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:26,390][root][INFO] - Training Epoch: 1/2, step 91/7134 completed (loss: 3.527130365371704, acc: 0.23673468828201294)
[2024-12-17 01:34:26,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:26,762][root][INFO] - Training Epoch: 1/2, step 92/7134 completed (loss: 3.28322434425354, acc: 0.2791023850440979)
[2024-12-17 01:34:26,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:27,153][root][INFO] - Training Epoch: 1/2, step 93/7134 completed (loss: 3.2431397438049316, acc: 0.27410468459129333)
[2024-12-17 01:34:27,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:27,424][root][INFO] - Training Epoch: 1/2, step 94/7134 completed (loss: 3.557810068130493, acc: 0.24129930138587952)
[2024-12-17 01:34:27,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:27,799][root][INFO] - Training Epoch: 1/2, step 95/7134 completed (loss: 3.2571356296539307, acc: 0.2650753855705261)
[2024-12-17 01:34:27,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:28,071][root][INFO] - Training Epoch: 1/2, step 96/7134 completed (loss: 3.480090379714966, acc: 0.2532588541507721)
[2024-12-17 01:34:28,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:28,319][root][INFO] - Training Epoch: 1/2, step 97/7134 completed (loss: 3.9083142280578613, acc: 0.22289156913757324)
[2024-12-17 01:34:28,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:28,724][root][INFO] - Training Epoch: 1/2, step 98/7134 completed (loss: 3.382486581802368, acc: 0.2443365752696991)
[2024-12-17 01:34:28,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:29,091][root][INFO] - Training Epoch: 1/2, step 99/7134 completed (loss: 3.308786153793335, acc: 0.2899082601070404)
[2024-12-17 01:34:29,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:29,499][root][INFO] - Training Epoch: 1/2, step 100/7134 completed (loss: 3.168095111846924, acc: 0.3064102530479431)
[2024-12-17 01:34:29,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:29,834][root][INFO] - Training Epoch: 1/2, step 101/7134 completed (loss: 3.3625128269195557, acc: 0.24506579339504242)
[2024-12-17 01:34:29,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:30,176][root][INFO] - Training Epoch: 1/2, step 102/7134 completed (loss: 3.2106685638427734, acc: 0.311355322599411)
[2024-12-17 01:34:30,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:30,495][root][INFO] - Training Epoch: 1/2, step 103/7134 completed (loss: 3.387619733810425, acc: 0.25999999046325684)
[2024-12-17 01:34:30,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:30,888][root][INFO] - Training Epoch: 1/2, step 104/7134 completed (loss: 3.300619602203369, acc: 0.25830814242362976)
[2024-12-17 01:34:31,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:31,273][root][INFO] - Training Epoch: 1/2, step 105/7134 completed (loss: 3.1108756065368652, acc: 0.3181076645851135)
[2024-12-17 01:34:31,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:31,642][root][INFO] - Training Epoch: 1/2, step 106/7134 completed (loss: 3.136613607406616, acc: 0.317440390586853)
[2024-12-17 01:34:31,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:31,987][root][INFO] - Training Epoch: 1/2, step 107/7134 completed (loss: 3.2926337718963623, acc: 0.27936962246894836)
[2024-12-17 01:34:32,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:32,368][root][INFO] - Training Epoch: 1/2, step 108/7134 completed (loss: 2.9959726333618164, acc: 0.3225419521331787)
[2024-12-17 01:34:32,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:32,688][root][INFO] - Training Epoch: 1/2, step 109/7134 completed (loss: 3.3141283988952637, acc: 0.28308823704719543)
[2024-12-17 01:34:32,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:33,055][root][INFO] - Training Epoch: 1/2, step 110/7134 completed (loss: 3.0019712448120117, acc: 0.3337250351905823)
[2024-12-17 01:34:33,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:33,395][root][INFO] - Training Epoch: 1/2, step 111/7134 completed (loss: 3.225149393081665, acc: 0.2944251000881195)
[2024-12-17 01:34:33,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:33,722][root][INFO] - Training Epoch: 1/2, step 112/7134 completed (loss: 3.1788952350616455, acc: 0.3112480640411377)
[2024-12-17 01:34:33,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:34,064][root][INFO] - Training Epoch: 1/2, step 113/7134 completed (loss: 3.0425848960876465, acc: 0.32658228278160095)
[2024-12-17 01:34:34,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:34,423][root][INFO] - Training Epoch: 1/2, step 114/7134 completed (loss: 3.1973226070404053, acc: 0.2944297194480896)
[2024-12-17 01:34:34,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:34,745][root][INFO] - Training Epoch: 1/2, step 115/7134 completed (loss: 3.2539987564086914, acc: 0.2860892415046692)
[2024-12-17 01:34:34,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:35,197][root][INFO] - Training Epoch: 1/2, step 116/7134 completed (loss: 3.1947121620178223, acc: 0.27797409892082214)
[2024-12-17 01:34:35,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:35,577][root][INFO] - Training Epoch: 1/2, step 117/7134 completed (loss: 3.1973938941955566, acc: 0.3033241033554077)
[2024-12-17 01:34:35,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:35,995][root][INFO] - Training Epoch: 1/2, step 118/7134 completed (loss: 3.1254405975341797, acc: 0.2946428656578064)
[2024-12-17 01:34:36,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:36,363][root][INFO] - Training Epoch: 1/2, step 119/7134 completed (loss: 3.1756837368011475, acc: 0.31355932354927063)
[2024-12-17 01:34:36,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:36,732][root][INFO] - Training Epoch: 1/2, step 120/7134 completed (loss: 3.1926326751708984, acc: 0.27129751443862915)
[2024-12-17 01:34:36,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:37,099][root][INFO] - Training Epoch: 1/2, step 121/7134 completed (loss: 3.10653018951416, acc: 0.3117569386959076)
[2024-12-17 01:34:37,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:37,456][root][INFO] - Training Epoch: 1/2, step 122/7134 completed (loss: 3.0080201625823975, acc: 0.32847681641578674)
[2024-12-17 01:34:37,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:37,775][root][INFO] - Training Epoch: 1/2, step 123/7134 completed (loss: 3.16117525100708, acc: 0.29279279708862305)
[2024-12-17 01:34:37,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:38,101][root][INFO] - Training Epoch: 1/2, step 124/7134 completed (loss: 3.3249287605285645, acc: 0.27931034564971924)
[2024-12-17 01:34:38,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:38,510][root][INFO] - Training Epoch: 1/2, step 125/7134 completed (loss: 3.040386199951172, acc: 0.3340708017349243)
[2024-12-17 01:34:38,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:38,859][root][INFO] - Training Epoch: 1/2, step 126/7134 completed (loss: 3.1486854553222656, acc: 0.31466665863990784)
[2024-12-17 01:34:38,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:39,213][root][INFO] - Training Epoch: 1/2, step 127/7134 completed (loss: 3.032313346862793, acc: 0.3185185194015503)
[2024-12-17 01:34:39,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:39,584][root][INFO] - Training Epoch: 1/2, step 128/7134 completed (loss: 3.018667221069336, acc: 0.32987311482429504)
[2024-12-17 01:34:39,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:39,984][root][INFO] - Training Epoch: 1/2, step 129/7134 completed (loss: 3.1588449478149414, acc: 0.30024510622024536)
[2024-12-17 01:34:40,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:40,324][root][INFO] - Training Epoch: 1/2, step 130/7134 completed (loss: 3.0710811614990234, acc: 0.3078947365283966)
[2024-12-17 01:34:40,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:40,720][root][INFO] - Training Epoch: 1/2, step 131/7134 completed (loss: 2.9500069618225098, acc: 0.3328947424888611)
[2024-12-17 01:34:40,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:41,081][root][INFO] - Training Epoch: 1/2, step 132/7134 completed (loss: 3.163728713989258, acc: 0.3033381700515747)
[2024-12-17 01:34:41,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:41,421][root][INFO] - Training Epoch: 1/2, step 133/7134 completed (loss: 3.2472336292266846, acc: 0.2628951668739319)
[2024-12-17 01:34:41,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:41,790][root][INFO] - Training Epoch: 1/2, step 134/7134 completed (loss: 3.239502191543579, acc: 0.31150442361831665)
[2024-12-17 01:34:41,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:42,166][root][INFO] - Training Epoch: 1/2, step 135/7134 completed (loss: 3.0038957595825195, acc: 0.3100000023841858)
[2024-12-17 01:34:42,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:42,517][root][INFO] - Training Epoch: 1/2, step 136/7134 completed (loss: 3.0582962036132812, acc: 0.301075279712677)
[2024-12-17 01:34:42,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:42,890][root][INFO] - Training Epoch: 1/2, step 137/7134 completed (loss: 3.135765552520752, acc: 0.2915129065513611)
[2024-12-17 01:34:43,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:43,322][root][INFO] - Training Epoch: 1/2, step 138/7134 completed (loss: 3.0386288166046143, acc: 0.3324905037879944)
[2024-12-17 01:34:43,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:43,732][root][INFO] - Training Epoch: 1/2, step 139/7134 completed (loss: 3.0042266845703125, acc: 0.322250634431839)
[2024-12-17 01:34:43,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:44,117][root][INFO] - Training Epoch: 1/2, step 140/7134 completed (loss: 3.190291166305542, acc: 0.2805970013141632)
[2024-12-17 01:34:44,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:44,474][root][INFO] - Training Epoch: 1/2, step 141/7134 completed (loss: 2.991183042526245, acc: 0.32900944352149963)
[2024-12-17 01:34:44,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:44,893][root][INFO] - Training Epoch: 1/2, step 142/7134 completed (loss: 3.119547128677368, acc: 0.30180805921554565)
[2024-12-17 01:34:45,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:45,269][root][INFO] - Training Epoch: 1/2, step 143/7134 completed (loss: 2.960785150527954, acc: 0.3194263279438019)
[2024-12-17 01:34:45,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:45,658][root][INFO] - Training Epoch: 1/2, step 144/7134 completed (loss: 3.1803224086761475, acc: 0.3038397431373596)
[2024-12-17 01:34:45,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:46,023][root][INFO] - Training Epoch: 1/2, step 145/7134 completed (loss: 3.160501718521118, acc: 0.3140845000743866)
[2024-12-17 01:34:46,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:46,400][root][INFO] - Training Epoch: 1/2, step 146/7134 completed (loss: 3.0769832134246826, acc: 0.31908831000328064)
[2024-12-17 01:34:46,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:46,801][root][INFO] - Training Epoch: 1/2, step 147/7134 completed (loss: 3.069549322128296, acc: 0.327556312084198)
[2024-12-17 01:34:46,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:47,173][root][INFO] - Training Epoch: 1/2, step 148/7134 completed (loss: 3.2457029819488525, acc: 0.2830626368522644)
[2024-12-17 01:34:47,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:47,556][root][INFO] - Training Epoch: 1/2, step 149/7134 completed (loss: 2.9376626014709473, acc: 0.35483869910240173)
[2024-12-17 01:34:47,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:47,926][root][INFO] - Training Epoch: 1/2, step 150/7134 completed (loss: 3.1523215770721436, acc: 0.3114973306655884)
[2024-12-17 01:34:48,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:48,280][root][INFO] - Training Epoch: 1/2, step 151/7134 completed (loss: 3.062800168991089, acc: 0.31861576437950134)
[2024-12-17 01:34:48,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:48,653][root][INFO] - Training Epoch: 1/2, step 152/7134 completed (loss: 3.0391359329223633, acc: 0.31662869453430176)
[2024-12-17 01:34:48,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:48,993][root][INFO] - Training Epoch: 1/2, step 153/7134 completed (loss: 3.161238431930542, acc: 0.30865922570228577)
[2024-12-17 01:34:49,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:49,340][root][INFO] - Training Epoch: 1/2, step 154/7134 completed (loss: 3.1806793212890625, acc: 0.3039513826370239)
[2024-12-17 01:34:49,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:49,704][root][INFO] - Training Epoch: 1/2, step 155/7134 completed (loss: 3.013901472091675, acc: 0.31298699975013733)
[2024-12-17 01:34:49,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:50,094][root][INFO] - Training Epoch: 1/2, step 156/7134 completed (loss: 2.97123122215271, acc: 0.33488914370536804)
[2024-12-17 01:34:50,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:50,466][root][INFO] - Training Epoch: 1/2, step 157/7134 completed (loss: 2.942049741744995, acc: 0.32891565561294556)
[2024-12-17 01:34:50,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:50,881][root][INFO] - Training Epoch: 1/2, step 158/7134 completed (loss: 3.0330379009246826, acc: 0.31439894437789917)
[2024-12-17 01:34:51,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:51,286][root][INFO] - Training Epoch: 1/2, step 159/7134 completed (loss: 3.0847482681274414, acc: 0.31168830394744873)
[2024-12-17 01:34:51,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:51,643][root][INFO] - Training Epoch: 1/2, step 160/7134 completed (loss: 3.1806066036224365, acc: 0.2955465614795685)
[2024-12-17 01:34:51,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:51,939][root][INFO] - Training Epoch: 1/2, step 161/7134 completed (loss: 3.1835856437683105, acc: 0.3604651093482971)
[2024-12-17 01:34:52,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:52,238][root][INFO] - Training Epoch: 1/2, step 162/7134 completed (loss: 3.3719449043273926, acc: 0.2557544708251953)
[2024-12-17 01:34:52,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:52,635][root][INFO] - Training Epoch: 1/2, step 163/7134 completed (loss: 3.036292314529419, acc: 0.33087149262428284)
[2024-12-17 01:34:52,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:52,948][root][INFO] - Training Epoch: 1/2, step 164/7134 completed (loss: 3.104616403579712, acc: 0.3617021143436432)
[2024-12-17 01:34:53,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:53,302][root][INFO] - Training Epoch: 1/2, step 165/7134 completed (loss: 3.331937551498413, acc: 0.2918660342693329)
[2024-12-17 01:34:53,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:53,628][root][INFO] - Training Epoch: 1/2, step 166/7134 completed (loss: 3.2821719646453857, acc: 0.3552238941192627)
[2024-12-17 01:34:53,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:54,050][root][INFO] - Training Epoch: 1/2, step 167/7134 completed (loss: 3.1581883430480957, acc: 0.30481284856796265)
[2024-12-17 01:34:54,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:54,347][root][INFO] - Training Epoch: 1/2, step 168/7134 completed (loss: 3.595179796218872, acc: 0.27843138575553894)
[2024-12-17 01:34:54,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:54,674][root][INFO] - Training Epoch: 1/2, step 169/7134 completed (loss: 3.227700710296631, acc: 0.32492998242378235)
[2024-12-17 01:34:54,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:55,008][root][INFO] - Training Epoch: 1/2, step 170/7134 completed (loss: 3.1501786708831787, acc: 0.3282732367515564)
[2024-12-17 01:34:55,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:55,307][root][INFO] - Training Epoch: 1/2, step 171/7134 completed (loss: 3.2349114418029785, acc: 0.3474026024341583)
[2024-12-17 01:34:55,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:55,649][root][INFO] - Training Epoch: 1/2, step 172/7134 completed (loss: 3.334038496017456, acc: 0.2958435118198395)
[2024-12-17 01:34:55,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:55,943][root][INFO] - Training Epoch: 1/2, step 173/7134 completed (loss: 3.2153563499450684, acc: 0.2853982448577881)
[2024-12-17 01:34:56,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:56,310][root][INFO] - Training Epoch: 1/2, step 174/7134 completed (loss: 3.5924384593963623, acc: 0.22535210847854614)
[2024-12-17 01:34:56,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:56,657][root][INFO] - Training Epoch: 1/2, step 175/7134 completed (loss: 3.2275052070617676, acc: 0.2690909206867218)
[2024-12-17 01:34:56,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:57,025][root][INFO] - Training Epoch: 1/2, step 176/7134 completed (loss: 3.1849825382232666, acc: 0.2956521809101105)
[2024-12-17 01:34:57,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:57,357][root][INFO] - Training Epoch: 1/2, step 177/7134 completed (loss: 3.2423906326293945, acc: 0.2777777910232544)
[2024-12-17 01:34:57,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:57,646][root][INFO] - Training Epoch: 1/2, step 178/7134 completed (loss: 3.5400238037109375, acc: 0.26744186878204346)
[2024-12-17 01:34:57,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:57,979][root][INFO] - Training Epoch: 1/2, step 179/7134 completed (loss: 3.1875860691070557, acc: 0.3133462369441986)
[2024-12-17 01:34:58,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:58,382][root][INFO] - Training Epoch: 1/2, step 180/7134 completed (loss: 3.181992769241333, acc: 0.27506425976753235)
[2024-12-17 01:34:58,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:58,730][root][INFO] - Training Epoch: 1/2, step 181/7134 completed (loss: 3.0835883617401123, acc: 0.28458496928215027)
[2024-12-17 01:34:58,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:59,116][root][INFO] - Training Epoch: 1/2, step 182/7134 completed (loss: 3.0737504959106445, acc: 0.31379732489585876)
[2024-12-17 01:34:59,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:59,505][root][INFO] - Training Epoch: 1/2, step 183/7134 completed (loss: 3.0836894512176514, acc: 0.29564031958580017)
[2024-12-17 01:34:59,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:59,832][root][INFO] - Training Epoch: 1/2, step 184/7134 completed (loss: 2.9607701301574707, acc: 0.3164362609386444)
[2024-12-17 01:34:59,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:00,166][root][INFO] - Training Epoch: 1/2, step 185/7134 completed (loss: 2.923308849334717, acc: 0.3290414810180664)
[2024-12-17 01:35:00,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:00,553][root][INFO] - Training Epoch: 1/2, step 186/7134 completed (loss: 3.16702938079834, acc: 0.28044870495796204)
[2024-12-17 01:35:00,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:00,952][root][INFO] - Training Epoch: 1/2, step 187/7134 completed (loss: 3.089076280593872, acc: 0.30027931928634644)
[2024-12-17 01:35:01,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:01,291][root][INFO] - Training Epoch: 1/2, step 188/7134 completed (loss: 2.9526546001434326, acc: 0.30694442987442017)
[2024-12-17 01:35:01,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:01,575][root][INFO] - Training Epoch: 1/2, step 189/7134 completed (loss: 3.1633224487304688, acc: 0.2730769217014313)
[2024-12-17 01:35:01,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:01,928][root][INFO] - Training Epoch: 1/2, step 190/7134 completed (loss: 3.19887638092041, acc: 0.2761310338973999)
[2024-12-17 01:35:02,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:02,272][root][INFO] - Training Epoch: 1/2, step 191/7134 completed (loss: 3.189213752746582, acc: 0.28632479906082153)
[2024-12-17 01:35:02,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:02,670][root][INFO] - Training Epoch: 1/2, step 192/7134 completed (loss: 2.9811949729919434, acc: 0.31156930327415466)
[2024-12-17 01:35:02,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:03,006][root][INFO] - Training Epoch: 1/2, step 193/7134 completed (loss: 3.0162699222564697, acc: 0.3073825538158417)
[2024-12-17 01:35:03,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:03,421][root][INFO] - Training Epoch: 1/2, step 194/7134 completed (loss: 3.17628812789917, acc: 0.26829269528388977)
[2024-12-17 01:35:03,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:03,796][root][INFO] - Training Epoch: 1/2, step 195/7134 completed (loss: 3.163050651550293, acc: 0.26386556029319763)
[2024-12-17 01:35:03,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:04,184][root][INFO] - Training Epoch: 1/2, step 196/7134 completed (loss: 2.995448589324951, acc: 0.312834233045578)
[2024-12-17 01:35:04,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:04,565][root][INFO] - Training Epoch: 1/2, step 197/7134 completed (loss: 3.0395302772521973, acc: 0.3176638185977936)
[2024-12-17 01:35:04,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:04,964][root][INFO] - Training Epoch: 1/2, step 198/7134 completed (loss: 3.01694917678833, acc: 0.3137003779411316)
[2024-12-17 01:35:05,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:05,352][root][INFO] - Training Epoch: 1/2, step 199/7134 completed (loss: 3.114889144897461, acc: 0.29228243231773376)
[2024-12-17 01:35:05,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:05,817][root][INFO] - Training Epoch: 1/2, step 200/7134 completed (loss: 2.9807450771331787, acc: 0.33288589119911194)
[2024-12-17 01:35:05,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:06,160][root][INFO] - Training Epoch: 1/2, step 201/7134 completed (loss: 3.127793788909912, acc: 0.2808988690376282)
[2024-12-17 01:35:06,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:06,520][root][INFO] - Training Epoch: 1/2, step 202/7134 completed (loss: 2.962449073791504, acc: 0.3255172371864319)
[2024-12-17 01:35:06,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:06,888][root][INFO] - Training Epoch: 1/2, step 203/7134 completed (loss: 3.0315561294555664, acc: 0.2975206673145294)
[2024-12-17 01:35:07,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:07,266][root][INFO] - Training Epoch: 1/2, step 204/7134 completed (loss: 2.933773994445801, acc: 0.3085106313228607)
[2024-12-17 01:35:07,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:07,618][root][INFO] - Training Epoch: 1/2, step 205/7134 completed (loss: 3.014014959335327, acc: 0.30142301321029663)
[2024-12-17 01:35:07,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:07,982][root][INFO] - Training Epoch: 1/2, step 206/7134 completed (loss: 3.0062217712402344, acc: 0.3001605272293091)
[2024-12-17 01:35:08,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:08,310][root][INFO] - Training Epoch: 1/2, step 207/7134 completed (loss: 2.9840407371520996, acc: 0.33276450634002686)
[2024-12-17 01:35:08,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:08,643][root][INFO] - Training Epoch: 1/2, step 208/7134 completed (loss: 3.0500383377075195, acc: 0.3137255012989044)
[2024-12-17 01:35:08,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:09,031][root][INFO] - Training Epoch: 1/2, step 209/7134 completed (loss: 3.0428905487060547, acc: 0.3056994676589966)
[2024-12-17 01:35:09,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:09,411][root][INFO] - Training Epoch: 1/2, step 210/7134 completed (loss: 2.8300836086273193, acc: 0.35534214973449707)
[2024-12-17 01:35:09,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:09,707][root][INFO] - Training Epoch: 1/2, step 211/7134 completed (loss: 3.0731844902038574, acc: 0.3104575276374817)
[2024-12-17 01:35:09,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:10,062][root][INFO] - Training Epoch: 1/2, step 212/7134 completed (loss: 3.0744071006774902, acc: 0.30785122513771057)
[2024-12-17 01:35:10,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:10,441][root][INFO] - Training Epoch: 1/2, step 213/7134 completed (loss: 2.8878285884857178, acc: 0.34142395853996277)
[2024-12-17 01:35:10,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:10,778][root][INFO] - Training Epoch: 1/2, step 214/7134 completed (loss: 3.080655336380005, acc: 0.2756410241127014)
[2024-12-17 01:35:10,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:11,130][root][INFO] - Training Epoch: 1/2, step 215/7134 completed (loss: 2.9608278274536133, acc: 0.3402777910232544)
[2024-12-17 01:35:11,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:11,460][root][INFO] - Training Epoch: 1/2, step 216/7134 completed (loss: 2.9635074138641357, acc: 0.3444444537162781)
[2024-12-17 01:35:11,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:11,901][root][INFO] - Training Epoch: 1/2, step 217/7134 completed (loss: 2.7886955738067627, acc: 0.3806060552597046)
[2024-12-17 01:35:12,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:12,262][root][INFO] - Training Epoch: 1/2, step 218/7134 completed (loss: 2.8060028553009033, acc: 0.347328245639801)
[2024-12-17 01:35:12,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:12,608][root][INFO] - Training Epoch: 1/2, step 219/7134 completed (loss: 3.0060207843780518, acc: 0.3255360722541809)
[2024-12-17 01:35:12,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:12,970][root][INFO] - Training Epoch: 1/2, step 220/7134 completed (loss: 2.922104835510254, acc: 0.34518828988075256)
[2024-12-17 01:35:13,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:13,363][root][INFO] - Training Epoch: 1/2, step 221/7134 completed (loss: 2.938446283340454, acc: 0.3253731429576874)
[2024-12-17 01:35:13,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:13,772][root][INFO] - Training Epoch: 1/2, step 222/7134 completed (loss: 2.953996419906616, acc: 0.28926700353622437)
[2024-12-17 01:35:13,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:14,117][root][INFO] - Training Epoch: 1/2, step 223/7134 completed (loss: 2.858041524887085, acc: 0.3388960063457489)
[2024-12-17 01:35:14,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:14,455][root][INFO] - Training Epoch: 1/2, step 224/7134 completed (loss: 3.0301499366760254, acc: 0.32166019082069397)
[2024-12-17 01:35:14,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:14,817][root][INFO] - Training Epoch: 1/2, step 225/7134 completed (loss: 2.9213759899139404, acc: 0.3350449204444885)
[2024-12-17 01:35:14,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:15,211][root][INFO] - Training Epoch: 1/2, step 226/7134 completed (loss: 2.998439311981201, acc: 0.31173592805862427)
[2024-12-17 01:35:15,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:15,571][root][INFO] - Training Epoch: 1/2, step 227/7134 completed (loss: 3.0660016536712646, acc: 0.29900744557380676)
[2024-12-17 01:35:15,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:15,977][root][INFO] - Training Epoch: 1/2, step 228/7134 completed (loss: 2.9888041019439697, acc: 0.31259045004844666)
[2024-12-17 01:35:16,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:16,365][root][INFO] - Training Epoch: 1/2, step 229/7134 completed (loss: 3.002713680267334, acc: 0.3164556920528412)
[2024-12-17 01:35:16,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:16,765][root][INFO] - Training Epoch: 1/2, step 230/7134 completed (loss: 2.903207540512085, acc: 0.34152334928512573)
[2024-12-17 01:35:16,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:17,094][root][INFO] - Training Epoch: 1/2, step 231/7134 completed (loss: 2.980555772781372, acc: 0.2956685423851013)
[2024-12-17 01:35:17,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:17,436][root][INFO] - Training Epoch: 1/2, step 232/7134 completed (loss: 2.9684832096099854, acc: 0.3261944055557251)
[2024-12-17 01:35:17,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:17,770][root][INFO] - Training Epoch: 1/2, step 233/7134 completed (loss: 2.9830057621002197, acc: 0.30903327465057373)
[2024-12-17 01:35:17,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:18,129][root][INFO] - Training Epoch: 1/2, step 234/7134 completed (loss: 3.060621738433838, acc: 0.2989864945411682)
[2024-12-17 01:35:18,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:18,484][root][INFO] - Training Epoch: 1/2, step 235/7134 completed (loss: 2.973196029663086, acc: 0.2977207899093628)
[2024-12-17 01:35:18,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:18,822][root][INFO] - Training Epoch: 1/2, step 236/7134 completed (loss: 2.957566499710083, acc: 0.3031249940395355)
[2024-12-17 01:35:18,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:19,162][root][INFO] - Training Epoch: 1/2, step 237/7134 completed (loss: 3.070930004119873, acc: 0.29955291748046875)
[2024-12-17 01:35:19,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:19,492][root][INFO] - Training Epoch: 1/2, step 238/7134 completed (loss: 2.9065864086151123, acc: 0.319029837846756)
[2024-12-17 01:35:19,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:19,826][root][INFO] - Training Epoch: 1/2, step 239/7134 completed (loss: 3.148159980773926, acc: 0.2647058963775635)
[2024-12-17 01:35:19,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:20,174][root][INFO] - Training Epoch: 1/2, step 240/7134 completed (loss: 3.113079309463501, acc: 0.30084747076034546)
[2024-12-17 01:35:20,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:20,518][root][INFO] - Training Epoch: 1/2, step 241/7134 completed (loss: 3.026933431625366, acc: 0.28985506296157837)
[2024-12-17 01:35:20,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:20,877][root][INFO] - Training Epoch: 1/2, step 242/7134 completed (loss: 3.0311195850372314, acc: 0.2876949608325958)
[2024-12-17 01:35:21,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:21,211][root][INFO] - Training Epoch: 1/2, step 243/7134 completed (loss: 2.9626216888427734, acc: 0.28911563754081726)
[2024-12-17 01:35:21,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:21,549][root][INFO] - Training Epoch: 1/2, step 244/7134 completed (loss: 2.8508894443511963, acc: 0.3152337968349457)
[2024-12-17 01:35:21,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:21,894][root][INFO] - Training Epoch: 1/2, step 245/7134 completed (loss: 2.943068742752075, acc: 0.32574430108070374)
[2024-12-17 01:35:22,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:22,242][root][INFO] - Training Epoch: 1/2, step 246/7134 completed (loss: 2.928306818008423, acc: 0.30283913016319275)
[2024-12-17 01:35:22,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:22,563][root][INFO] - Training Epoch: 1/2, step 247/7134 completed (loss: 2.989779233932495, acc: 0.29945552349090576)
[2024-12-17 01:35:22,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:22,932][root][INFO] - Training Epoch: 1/2, step 248/7134 completed (loss: 2.9482626914978027, acc: 0.34302327036857605)
[2024-12-17 01:35:23,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:23,270][root][INFO] - Training Epoch: 1/2, step 249/7134 completed (loss: 2.9078500270843506, acc: 0.34316354990005493)
[2024-12-17 01:35:23,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:23,657][root][INFO] - Training Epoch: 1/2, step 250/7134 completed (loss: 2.9924399852752686, acc: 0.30063292384147644)
[2024-12-17 01:35:23,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:23,991][root][INFO] - Training Epoch: 1/2, step 251/7134 completed (loss: 2.939567804336548, acc: 0.32307693362236023)
[2024-12-17 01:35:24,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:24,299][root][INFO] - Training Epoch: 1/2, step 252/7134 completed (loss: 2.960761308670044, acc: 0.30000001192092896)
[2024-12-17 01:35:24,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:24,651][root][INFO] - Training Epoch: 1/2, step 253/7134 completed (loss: 3.0182197093963623, acc: 0.29946523904800415)
[2024-12-17 01:35:24,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:24,979][root][INFO] - Training Epoch: 1/2, step 254/7134 completed (loss: 2.9742748737335205, acc: 0.28928571939468384)
[2024-12-17 01:35:25,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:25,328][root][INFO] - Training Epoch: 1/2, step 255/7134 completed (loss: 2.800830364227295, acc: 0.32894736528396606)
[2024-12-17 01:35:25,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:25,630][root][INFO] - Training Epoch: 1/2, step 256/7134 completed (loss: 3.105539321899414, acc: 0.30514705181121826)
[2024-12-17 01:35:25,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:26,045][root][INFO] - Training Epoch: 1/2, step 257/7134 completed (loss: 2.9816291332244873, acc: 0.30061349272727966)
[2024-12-17 01:35:26,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:26,398][root][INFO] - Training Epoch: 1/2, step 258/7134 completed (loss: 2.903534412384033, acc: 0.3140496015548706)
[2024-12-17 01:35:26,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:26,842][root][INFO] - Training Epoch: 1/2, step 259/7134 completed (loss: 2.9357404708862305, acc: 0.28849270939826965)
[2024-12-17 01:35:26,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:27,200][root][INFO] - Training Epoch: 1/2, step 260/7134 completed (loss: 2.893893241882324, acc: 0.29949238896369934)
[2024-12-17 01:35:27,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:27,559][root][INFO] - Training Epoch: 1/2, step 261/7134 completed (loss: 3.033825159072876, acc: 0.2985685169696808)
[2024-12-17 01:35:27,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:27,908][root][INFO] - Training Epoch: 1/2, step 262/7134 completed (loss: 2.943798065185547, acc: 0.3144758641719818)
[2024-12-17 01:35:28,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:28,256][root][INFO] - Training Epoch: 1/2, step 263/7134 completed (loss: 2.7607171535491943, acc: 0.3384418785572052)
[2024-12-17 01:35:28,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:28,608][root][INFO] - Training Epoch: 1/2, step 264/7134 completed (loss: 2.812211036682129, acc: 0.33060747385025024)
[2024-12-17 01:35:28,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:28,960][root][INFO] - Training Epoch: 1/2, step 265/7134 completed (loss: 2.8532092571258545, acc: 0.3414948582649231)
[2024-12-17 01:35:29,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:29,307][root][INFO] - Training Epoch: 1/2, step 266/7134 completed (loss: 2.7646079063415527, acc: 0.3474770784378052)
[2024-12-17 01:35:29,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:29,716][root][INFO] - Training Epoch: 1/2, step 267/7134 completed (loss: 2.8449342250823975, acc: 0.318390816450119)
[2024-12-17 01:35:29,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:30,142][root][INFO] - Training Epoch: 1/2, step 268/7134 completed (loss: 2.8166921138763428, acc: 0.32166019082069397)
[2024-12-17 01:35:30,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:30,530][root][INFO] - Training Epoch: 1/2, step 269/7134 completed (loss: 2.808070421218872, acc: 0.32823365926742554)
[2024-12-17 01:35:30,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:30,862][root][INFO] - Training Epoch: 1/2, step 270/7134 completed (loss: 2.7362258434295654, acc: 0.35671642422676086)
[2024-12-17 01:35:31,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:31,276][root][INFO] - Training Epoch: 1/2, step 271/7134 completed (loss: 2.8534903526306152, acc: 0.3215636909008026)
[2024-12-17 01:35:31,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:31,627][root][INFO] - Training Epoch: 1/2, step 272/7134 completed (loss: 2.837592840194702, acc: 0.32824426889419556)
[2024-12-17 01:35:31,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:31,970][root][INFO] - Training Epoch: 1/2, step 273/7134 completed (loss: 2.653240442276001, acc: 0.3688622713088989)
[2024-12-17 01:35:32,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:32,336][root][INFO] - Training Epoch: 1/2, step 274/7134 completed (loss: 2.8050825595855713, acc: 0.32187071442604065)
[2024-12-17 01:35:32,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:32,741][root][INFO] - Training Epoch: 1/2, step 275/7134 completed (loss: 2.7555501461029053, acc: 0.35034802556037903)
[2024-12-17 01:35:32,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:33,174][root][INFO] - Training Epoch: 1/2, step 276/7134 completed (loss: 2.8035542964935303, acc: 0.3361753821372986)
[2024-12-17 01:35:33,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:33,546][root][INFO] - Training Epoch: 1/2, step 277/7134 completed (loss: 2.9180219173431396, acc: 0.30630630254745483)
[2024-12-17 01:35:33,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:33,882][root][INFO] - Training Epoch: 1/2, step 278/7134 completed (loss: 2.8223252296447754, acc: 0.320561945438385)
[2024-12-17 01:35:34,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:34,244][root][INFO] - Training Epoch: 1/2, step 279/7134 completed (loss: 2.812906503677368, acc: 0.31102362275123596)
[2024-12-17 01:35:34,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:34,620][root][INFO] - Training Epoch: 1/2, step 280/7134 completed (loss: 2.9240691661834717, acc: 0.29928314685821533)
[2024-12-17 01:35:34,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:34,962][root][INFO] - Training Epoch: 1/2, step 281/7134 completed (loss: 2.897770881652832, acc: 0.2919999957084656)
[2024-12-17 01:35:35,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:35,322][root][INFO] - Training Epoch: 1/2, step 282/7134 completed (loss: 2.949838161468506, acc: 0.3175572454929352)
[2024-12-17 01:35:35,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:35,670][root][INFO] - Training Epoch: 1/2, step 283/7134 completed (loss: 2.83137583732605, acc: 0.3344652056694031)
[2024-12-17 01:35:35,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:36,039][root][INFO] - Training Epoch: 1/2, step 284/7134 completed (loss: 2.8968186378479004, acc: 0.32046979665756226)
[2024-12-17 01:35:36,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:36,385][root][INFO] - Training Epoch: 1/2, step 285/7134 completed (loss: 2.8780128955841064, acc: 0.3086419701576233)
[2024-12-17 01:35:36,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:36,719][root][INFO] - Training Epoch: 1/2, step 286/7134 completed (loss: 2.6696064472198486, acc: 0.35575219988822937)
[2024-12-17 01:35:36,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:37,088][root][INFO] - Training Epoch: 1/2, step 287/7134 completed (loss: 2.8123996257781982, acc: 0.3338683843612671)
[2024-12-17 01:35:37,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:37,495][root][INFO] - Training Epoch: 1/2, step 288/7134 completed (loss: 2.8270161151885986, acc: 0.3388581871986389)
[2024-12-17 01:35:37,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:37,887][root][INFO] - Training Epoch: 1/2, step 289/7134 completed (loss: 2.8740217685699463, acc: 0.2965641915798187)
[2024-12-17 01:35:38,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:38,226][root][INFO] - Training Epoch: 1/2, step 290/7134 completed (loss: 2.801135301589966, acc: 0.3404255211353302)
[2024-12-17 01:35:38,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:38,591][root][INFO] - Training Epoch: 1/2, step 291/7134 completed (loss: 2.771054744720459, acc: 0.35361841320991516)
[2024-12-17 01:35:38,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:38,943][root][INFO] - Training Epoch: 1/2, step 292/7134 completed (loss: 3.039098024368286, acc: 0.30368098616600037)
[2024-12-17 01:35:39,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:39,327][root][INFO] - Training Epoch: 1/2, step 293/7134 completed (loss: 2.8633835315704346, acc: 0.3052208721637726)
[2024-12-17 01:35:39,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:39,708][root][INFO] - Training Epoch: 1/2, step 294/7134 completed (loss: 2.8335719108581543, acc: 0.35087719559669495)
[2024-12-17 01:35:39,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:40,116][root][INFO] - Training Epoch: 1/2, step 295/7134 completed (loss: 2.80024790763855, acc: 0.3310580253601074)
[2024-12-17 01:35:40,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:40,505][root][INFO] - Training Epoch: 1/2, step 296/7134 completed (loss: 2.648970603942871, acc: 0.3503876030445099)
[2024-12-17 01:35:40,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:40,860][root][INFO] - Training Epoch: 1/2, step 297/7134 completed (loss: 2.8259072303771973, acc: 0.3214920163154602)
[2024-12-17 01:35:41,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:41,263][root][INFO] - Training Epoch: 1/2, step 298/7134 completed (loss: 2.9498355388641357, acc: 0.2879999876022339)
[2024-12-17 01:35:41,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:41,637][root][INFO] - Training Epoch: 1/2, step 299/7134 completed (loss: 2.707764148712158, acc: 0.3323308229446411)
[2024-12-17 01:35:41,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:42,008][root][INFO] - Training Epoch: 1/2, step 300/7134 completed (loss: 2.642418384552002, acc: 0.34789642691612244)
[2024-12-17 01:35:42,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:42,390][root][INFO] - Training Epoch: 1/2, step 301/7134 completed (loss: 2.740058660507202, acc: 0.33380481600761414)
[2024-12-17 01:35:42,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:42,711][root][INFO] - Training Epoch: 1/2, step 302/7134 completed (loss: 2.860153913497925, acc: 0.317738801240921)
[2024-12-17 01:35:42,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:43,019][root][INFO] - Training Epoch: 1/2, step 303/7134 completed (loss: 2.859022855758667, acc: 0.2932038903236389)
[2024-12-17 01:35:43,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:43,424][root][INFO] - Training Epoch: 1/2, step 304/7134 completed (loss: 2.8089113235473633, acc: 0.3055555522441864)
[2024-12-17 01:35:43,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:43,768][root][INFO] - Training Epoch: 1/2, step 305/7134 completed (loss: 2.737032175064087, acc: 0.30206677317619324)
[2024-12-17 01:35:43,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:44,109][root][INFO] - Training Epoch: 1/2, step 306/7134 completed (loss: 2.6800646781921387, acc: 0.33152174949645996)
[2024-12-17 01:35:44,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:44,484][root][INFO] - Training Epoch: 1/2, step 307/7134 completed (loss: 2.8107776641845703, acc: 0.3078291714191437)
[2024-12-17 01:35:44,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:44,819][root][INFO] - Training Epoch: 1/2, step 308/7134 completed (loss: 2.740142345428467, acc: 0.32894736528396606)
[2024-12-17 01:35:44,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:45,199][root][INFO] - Training Epoch: 1/2, step 309/7134 completed (loss: 2.7660298347473145, acc: 0.317241370677948)
[2024-12-17 01:35:45,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:45,625][root][INFO] - Training Epoch: 1/2, step 310/7134 completed (loss: 2.6349666118621826, acc: 0.3523391783237457)
[2024-12-17 01:35:45,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:45,961][root][INFO] - Training Epoch: 1/2, step 311/7134 completed (loss: 2.600863218307495, acc: 0.353032648563385)
[2024-12-17 01:35:46,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:46,315][root][INFO] - Training Epoch: 1/2, step 312/7134 completed (loss: 2.6579220294952393, acc: 0.35008665919303894)
[2024-12-17 01:35:46,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:46,653][root][INFO] - Training Epoch: 1/2, step 313/7134 completed (loss: 2.6062042713165283, acc: 0.36000001430511475)
[2024-12-17 01:35:46,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:46,989][root][INFO] - Training Epoch: 1/2, step 314/7134 completed (loss: 2.585263729095459, acc: 0.359375)
[2024-12-17 01:35:47,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:47,350][root][INFO] - Training Epoch: 1/2, step 315/7134 completed (loss: 2.6518590450286865, acc: 0.34918034076690674)
[2024-12-17 01:35:47,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:47,662][root][INFO] - Training Epoch: 1/2, step 316/7134 completed (loss: 2.7335362434387207, acc: 0.29241877794265747)
[2024-12-17 01:35:47,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:48,083][root][INFO] - Training Epoch: 1/2, step 317/7134 completed (loss: 2.8045780658721924, acc: 0.311231404542923)
[2024-12-17 01:35:48,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:48,457][root][INFO] - Training Epoch: 1/2, step 318/7134 completed (loss: 2.7440032958984375, acc: 0.3369963467121124)
[2024-12-17 01:35:48,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:48,778][root][INFO] - Training Epoch: 1/2, step 319/7134 completed (loss: 2.7946269512176514, acc: 0.29593268036842346)
[2024-12-17 01:35:48,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:49,149][root][INFO] - Training Epoch: 1/2, step 320/7134 completed (loss: 2.6564383506774902, acc: 0.37232524156570435)
[2024-12-17 01:35:49,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:49,514][root][INFO] - Training Epoch: 1/2, step 321/7134 completed (loss: 2.77323579788208, acc: 0.3295019268989563)
[2024-12-17 01:35:49,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:49,899][root][INFO] - Training Epoch: 1/2, step 322/7134 completed (loss: 2.8017191886901855, acc: 0.3333333432674408)
[2024-12-17 01:35:50,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:50,257][root][INFO] - Training Epoch: 1/2, step 323/7134 completed (loss: 2.8068695068359375, acc: 0.319640576839447)
[2024-12-17 01:35:50,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:50,621][root][INFO] - Training Epoch: 1/2, step 324/7134 completed (loss: 2.7549476623535156, acc: 0.3429228961467743)
[2024-12-17 01:35:50,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:51,021][root][INFO] - Training Epoch: 1/2, step 325/7134 completed (loss: 2.6916165351867676, acc: 0.3431876599788666)
[2024-12-17 01:35:51,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:51,396][root][INFO] - Training Epoch: 1/2, step 326/7134 completed (loss: 2.6506128311157227, acc: 0.32643118500709534)
[2024-12-17 01:35:51,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:51,763][root][INFO] - Training Epoch: 1/2, step 327/7134 completed (loss: 2.7255263328552246, acc: 0.33445945382118225)
[2024-12-17 01:35:51,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:52,168][root][INFO] - Training Epoch: 1/2, step 328/7134 completed (loss: 2.7984979152679443, acc: 0.33037036657333374)
[2024-12-17 01:35:52,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:52,534][root][INFO] - Training Epoch: 1/2, step 329/7134 completed (loss: 2.6260883808135986, acc: 0.3725029230117798)
[2024-12-17 01:35:52,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:52,926][root][INFO] - Training Epoch: 1/2, step 330/7134 completed (loss: 2.6688344478607178, acc: 0.3645518720149994)
[2024-12-17 01:35:53,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:53,352][root][INFO] - Training Epoch: 1/2, step 331/7134 completed (loss: 2.6404337882995605, acc: 0.34777650237083435)
[2024-12-17 01:35:53,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:53,734][root][INFO] - Training Epoch: 1/2, step 332/7134 completed (loss: 2.545682907104492, acc: 0.3648169934749603)
[2024-12-17 01:35:53,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:54,086][root][INFO] - Training Epoch: 1/2, step 333/7134 completed (loss: 2.752333879470825, acc: 0.32116788625717163)
[2024-12-17 01:35:54,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:54,465][root][INFO] - Training Epoch: 1/2, step 334/7134 completed (loss: 2.6983675956726074, acc: 0.30925223231315613)
[2024-12-17 01:35:54,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:54,857][root][INFO] - Training Epoch: 1/2, step 335/7134 completed (loss: 2.7216227054595947, acc: 0.3231441080570221)
[2024-12-17 01:35:54,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:55,213][root][INFO] - Training Epoch: 1/2, step 336/7134 completed (loss: 2.627340793609619, acc: 0.34011974930763245)
[2024-12-17 01:35:55,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:55,558][root][INFO] - Training Epoch: 1/2, step 337/7134 completed (loss: 2.6975653171539307, acc: 0.34355828166007996)
[2024-12-17 01:35:55,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:55,900][root][INFO] - Training Epoch: 1/2, step 338/7134 completed (loss: 2.6183431148529053, acc: 0.33375313878059387)
[2024-12-17 01:35:55,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:56,245][root][INFO] - Training Epoch: 1/2, step 339/7134 completed (loss: 2.6685540676116943, acc: 0.3499999940395355)
[2024-12-17 01:35:56,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:56,588][root][INFO] - Training Epoch: 1/2, step 340/7134 completed (loss: 2.9281139373779297, acc: 0.3002544641494751)
[2024-12-17 01:35:56,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:56,961][root][INFO] - Training Epoch: 1/2, step 341/7134 completed (loss: 2.579594850540161, acc: 0.3581336736679077)
[2024-12-17 01:35:57,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:57,323][root][INFO] - Training Epoch: 1/2, step 342/7134 completed (loss: 2.6636064052581787, acc: 0.3166666626930237)
[2024-12-17 01:35:57,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:57,679][root][INFO] - Training Epoch: 1/2, step 343/7134 completed (loss: 2.9023396968841553, acc: 0.3024574816226959)
[2024-12-17 01:35:57,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:58,005][root][INFO] - Training Epoch: 1/2, step 344/7134 completed (loss: 2.6137707233428955, acc: 0.3521897792816162)
[2024-12-17 01:35:58,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:58,313][root][INFO] - Training Epoch: 1/2, step 345/7134 completed (loss: 2.6866581439971924, acc: 0.33392858505249023)
[2024-12-17 01:35:58,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:58,720][root][INFO] - Training Epoch: 1/2, step 346/7134 completed (loss: 2.6148228645324707, acc: 0.36883941292762756)
[2024-12-17 01:35:58,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:59,062][root][INFO] - Training Epoch: 1/2, step 347/7134 completed (loss: 2.698418617248535, acc: 0.3253856897354126)
[2024-12-17 01:35:59,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:59,420][root][INFO] - Training Epoch: 1/2, step 348/7134 completed (loss: 2.718417167663574, acc: 0.31478968262672424)
[2024-12-17 01:35:59,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:59,815][root][INFO] - Training Epoch: 1/2, step 349/7134 completed (loss: 2.616431474685669, acc: 0.33422818779945374)
[2024-12-17 01:35:59,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:00,240][root][INFO] - Training Epoch: 1/2, step 350/7134 completed (loss: 2.6974613666534424, acc: 0.33694344758987427)
[2024-12-17 01:36:00,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:00,673][root][INFO] - Training Epoch: 1/2, step 351/7134 completed (loss: 2.6970741748809814, acc: 0.32824426889419556)
[2024-12-17 01:36:00,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:01,021][root][INFO] - Training Epoch: 1/2, step 352/7134 completed (loss: 2.553910732269287, acc: 0.3709239065647125)
[2024-12-17 01:36:01,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:01,415][root][INFO] - Training Epoch: 1/2, step 353/7134 completed (loss: 2.623019218444824, acc: 0.35638296604156494)
[2024-12-17 01:36:01,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:01,773][root][INFO] - Training Epoch: 1/2, step 354/7134 completed (loss: 2.6376166343688965, acc: 0.35157158970832825)
[2024-12-17 01:36:01,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:02,161][root][INFO] - Training Epoch: 1/2, step 355/7134 completed (loss: 2.6443827152252197, acc: 0.3421787619590759)
[2024-12-17 01:36:02,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:02,552][root][INFO] - Training Epoch: 1/2, step 356/7134 completed (loss: 2.577615261077881, acc: 0.35052910447120667)
[2024-12-17 01:36:02,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:02,953][root][INFO] - Training Epoch: 1/2, step 357/7134 completed (loss: 2.6679675579071045, acc: 0.32824426889419556)
[2024-12-17 01:36:03,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:03,342][root][INFO] - Training Epoch: 1/2, step 358/7134 completed (loss: 2.646639585494995, acc: 0.347885400056839)
[2024-12-17 01:36:03,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:03,740][root][INFO] - Training Epoch: 1/2, step 359/7134 completed (loss: 2.6009955406188965, acc: 0.3351351320743561)
[2024-12-17 01:36:03,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:04,068][root][INFO] - Training Epoch: 1/2, step 360/7134 completed (loss: 2.5280776023864746, acc: 0.3674698770046234)
[2024-12-17 01:36:04,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:04,395][root][INFO] - Training Epoch: 1/2, step 361/7134 completed (loss: 2.5943427085876465, acc: 0.3480176329612732)
[2024-12-17 01:36:04,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:04,753][root][INFO] - Training Epoch: 1/2, step 362/7134 completed (loss: 2.5493648052215576, acc: 0.33982035517692566)
[2024-12-17 01:36:04,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:05,114][root][INFO] - Training Epoch: 1/2, step 363/7134 completed (loss: 2.685837984085083, acc: 0.3203125)
[2024-12-17 01:36:05,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:05,469][root][INFO] - Training Epoch: 1/2, step 364/7134 completed (loss: 2.6571972370147705, acc: 0.3317756950855255)
[2024-12-17 01:36:05,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:05,867][root][INFO] - Training Epoch: 1/2, step 365/7134 completed (loss: 2.6565418243408203, acc: 0.3292011022567749)
[2024-12-17 01:36:05,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:06,232][root][INFO] - Training Epoch: 1/2, step 366/7134 completed (loss: 2.6443161964416504, acc: 0.3557993769645691)
[2024-12-17 01:36:06,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:06,631][root][INFO] - Training Epoch: 1/2, step 367/7134 completed (loss: 2.6665942668914795, acc: 0.3462499976158142)
[2024-12-17 01:36:06,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:06,967][root][INFO] - Training Epoch: 1/2, step 368/7134 completed (loss: 2.665724754333496, acc: 0.3580980598926544)
[2024-12-17 01:36:07,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:07,294][root][INFO] - Training Epoch: 1/2, step 369/7134 completed (loss: 2.6726503372192383, acc: 0.34762632846832275)
[2024-12-17 01:36:07,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:07,672][root][INFO] - Training Epoch: 1/2, step 370/7134 completed (loss: 2.6857070922851562, acc: 0.3129548728466034)
[2024-12-17 01:36:07,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:08,040][root][INFO] - Training Epoch: 1/2, step 371/7134 completed (loss: 2.522840976715088, acc: 0.36240601539611816)
[2024-12-17 01:36:08,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:08,377][root][INFO] - Training Epoch: 1/2, step 372/7134 completed (loss: 2.615687370300293, acc: 0.3358097970485687)
[2024-12-17 01:36:08,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:08,746][root][INFO] - Training Epoch: 1/2, step 373/7134 completed (loss: 2.6162126064300537, acc: 0.3363228738307953)
[2024-12-17 01:36:08,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:09,114][root][INFO] - Training Epoch: 1/2, step 374/7134 completed (loss: 2.521249771118164, acc: 0.3954983949661255)
[2024-12-17 01:36:09,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:09,516][root][INFO] - Training Epoch: 1/2, step 375/7134 completed (loss: 2.479353666305542, acc: 0.3654618561267853)
[2024-12-17 01:36:09,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:09,876][root][INFO] - Training Epoch: 1/2, step 376/7134 completed (loss: 2.64876389503479, acc: 0.3475862145423889)
[2024-12-17 01:36:09,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:10,235][root][INFO] - Training Epoch: 1/2, step 377/7134 completed (loss: 2.695596694946289, acc: 0.35213205218315125)
[2024-12-17 01:36:10,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:10,604][root][INFO] - Training Epoch: 1/2, step 378/7134 completed (loss: 2.608870267868042, acc: 0.3310626745223999)
[2024-12-17 01:36:10,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:10,986][root][INFO] - Training Epoch: 1/2, step 379/7134 completed (loss: 2.4662387371063232, acc: 0.37437185645103455)
[2024-12-17 01:36:11,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:11,348][root][INFO] - Training Epoch: 1/2, step 380/7134 completed (loss: 2.6995601654052734, acc: 0.34559789299964905)
[2024-12-17 01:36:11,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:11,721][root][INFO] - Training Epoch: 1/2, step 381/7134 completed (loss: 2.5880584716796875, acc: 0.33850130438804626)
[2024-12-17 01:36:11,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:12,115][root][INFO] - Training Epoch: 1/2, step 382/7134 completed (loss: 2.5132017135620117, acc: 0.3684210479259491)
[2024-12-17 01:36:12,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:12,451][root][INFO] - Training Epoch: 1/2, step 383/7134 completed (loss: 2.623295783996582, acc: 0.33270320296287537)
[2024-12-17 01:36:12,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:12,815][root][INFO] - Training Epoch: 1/2, step 384/7134 completed (loss: 2.521045207977295, acc: 0.356475293636322)
[2024-12-17 01:36:12,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:13,166][root][INFO] - Training Epoch: 1/2, step 385/7134 completed (loss: 2.4764292240142822, acc: 0.35164836049079895)
[2024-12-17 01:36:13,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:13,478][root][INFO] - Training Epoch: 1/2, step 386/7134 completed (loss: 2.5150399208068848, acc: 0.35787320137023926)
[2024-12-17 01:36:13,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:13,966][root][INFO] - Training Epoch: 1/2, step 387/7134 completed (loss: 2.658566951751709, acc: 0.3309037983417511)
[2024-12-17 01:36:14,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:14,337][root][INFO] - Training Epoch: 1/2, step 388/7134 completed (loss: 2.5545060634613037, acc: 0.3673709034919739)
[2024-12-17 01:36:14,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:14,703][root][INFO] - Training Epoch: 1/2, step 389/7134 completed (loss: 2.471447706222534, acc: 0.3650137782096863)
[2024-12-17 01:36:14,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:15,050][root][INFO] - Training Epoch: 1/2, step 390/7134 completed (loss: 2.55637788772583, acc: 0.34951457381248474)
[2024-12-17 01:36:15,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:15,372][root][INFO] - Training Epoch: 1/2, step 391/7134 completed (loss: 2.509977340698242, acc: 0.3758503496646881)
[2024-12-17 01:36:15,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:15,749][root][INFO] - Training Epoch: 1/2, step 392/7134 completed (loss: 2.5175514221191406, acc: 0.3614814877510071)
[2024-12-17 01:36:15,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:16,095][root][INFO] - Training Epoch: 1/2, step 393/7134 completed (loss: 2.57443904876709, acc: 0.3541666567325592)
[2024-12-17 01:36:16,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:16,427][root][INFO] - Training Epoch: 1/2, step 394/7134 completed (loss: 2.446948766708374, acc: 0.37354084849357605)
[2024-12-17 01:36:16,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:16,790][root][INFO] - Training Epoch: 1/2, step 395/7134 completed (loss: 2.4231812953948975, acc: 0.39094650745391846)
[2024-12-17 01:36:16,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:17,153][root][INFO] - Training Epoch: 1/2, step 396/7134 completed (loss: 2.492011547088623, acc: 0.34193548560142517)
[2024-12-17 01:36:17,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:17,562][root][INFO] - Training Epoch: 1/2, step 397/7134 completed (loss: 2.6602816581726074, acc: 0.35185185074806213)
[2024-12-17 01:36:17,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:17,912][root][INFO] - Training Epoch: 1/2, step 398/7134 completed (loss: 2.3751063346862793, acc: 0.4136597812175751)
[2024-12-17 01:36:18,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:18,315][root][INFO] - Training Epoch: 1/2, step 399/7134 completed (loss: 2.384807586669922, acc: 0.41045957803726196)
[2024-12-17 01:36:18,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:18,672][root][INFO] - Training Epoch: 1/2, step 400/7134 completed (loss: 2.85565447807312, acc: 0.2850746214389801)
[2024-12-17 01:36:18,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:19,085][root][INFO] - Training Epoch: 1/2, step 401/7134 completed (loss: 2.521498441696167, acc: 0.3700980246067047)
[2024-12-17 01:36:19,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:19,443][root][INFO] - Training Epoch: 1/2, step 402/7134 completed (loss: 2.5897774696350098, acc: 0.3523447513580322)
[2024-12-17 01:36:19,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:19,845][root][INFO] - Training Epoch: 1/2, step 403/7134 completed (loss: 2.5472445487976074, acc: 0.36717063188552856)
[2024-12-17 01:36:19,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:20,171][root][INFO] - Training Epoch: 1/2, step 404/7134 completed (loss: 2.561721086502075, acc: 0.35256409645080566)
[2024-12-17 01:36:20,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:20,549][root][INFO] - Training Epoch: 1/2, step 405/7134 completed (loss: 2.5642786026000977, acc: 0.3629283607006073)
[2024-12-17 01:36:20,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:20,929][root][INFO] - Training Epoch: 1/2, step 406/7134 completed (loss: 2.5089120864868164, acc: 0.39249640703201294)
[2024-12-17 01:36:21,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:21,261][root][INFO] - Training Epoch: 1/2, step 407/7134 completed (loss: 2.641683340072632, acc: 0.34067797660827637)
[2024-12-17 01:36:21,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:21,610][root][INFO] - Training Epoch: 1/2, step 408/7134 completed (loss: 2.4937400817871094, acc: 0.37722909450531006)
[2024-12-17 01:36:21,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:21,978][root][INFO] - Training Epoch: 1/2, step 409/7134 completed (loss: 2.4646494388580322, acc: 0.3597484230995178)
[2024-12-17 01:36:22,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:22,402][root][INFO] - Training Epoch: 1/2, step 410/7134 completed (loss: 2.6308279037475586, acc: 0.3338278830051422)
[2024-12-17 01:36:22,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:22,771][root][INFO] - Training Epoch: 1/2, step 411/7134 completed (loss: 2.602013111114502, acc: 0.34637513756752014)
[2024-12-17 01:36:22,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:23,141][root][INFO] - Training Epoch: 1/2, step 412/7134 completed (loss: 2.5659241676330566, acc: 0.3524027466773987)
[2024-12-17 01:36:23,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:23,492][root][INFO] - Training Epoch: 1/2, step 413/7134 completed (loss: 2.487745761871338, acc: 0.34045395255088806)
[2024-12-17 01:36:23,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:23,868][root][INFO] - Training Epoch: 1/2, step 414/7134 completed (loss: 2.5732131004333496, acc: 0.33531156182289124)
[2024-12-17 01:36:23,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:24,220][root][INFO] - Training Epoch: 1/2, step 415/7134 completed (loss: 2.5393381118774414, acc: 0.3680555522441864)
[2024-12-17 01:36:24,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:24,597][root][INFO] - Training Epoch: 1/2, step 416/7134 completed (loss: 2.56272292137146, acc: 0.3636363744735718)
[2024-12-17 01:36:24,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:24,979][root][INFO] - Training Epoch: 1/2, step 417/7134 completed (loss: 2.5263445377349854, acc: 0.34375)
[2024-12-17 01:36:25,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:25,370][root][INFO] - Training Epoch: 1/2, step 418/7134 completed (loss: 2.6141815185546875, acc: 0.3340987265110016)
[2024-12-17 01:36:25,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:25,733][root][INFO] - Training Epoch: 1/2, step 419/7134 completed (loss: 2.6034371852874756, acc: 0.33870968222618103)
[2024-12-17 01:36:25,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:26,103][root][INFO] - Training Epoch: 1/2, step 420/7134 completed (loss: 2.5603597164154053, acc: 0.3384094834327698)
[2024-12-17 01:36:26,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:26,458][root][INFO] - Training Epoch: 1/2, step 421/7134 completed (loss: 2.4856114387512207, acc: 0.3646496832370758)
[2024-12-17 01:36:26,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:26,832][root][INFO] - Training Epoch: 1/2, step 422/7134 completed (loss: 2.416206121444702, acc: 0.36617645621299744)
[2024-12-17 01:36:26,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:27,198][root][INFO] - Training Epoch: 1/2, step 423/7134 completed (loss: 2.52475905418396, acc: 0.37142857909202576)
[2024-12-17 01:36:27,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:27,557][root][INFO] - Training Epoch: 1/2, step 424/7134 completed (loss: 2.3874268531799316, acc: 0.38132911920547485)
[2024-12-17 01:36:27,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:27,907][root][INFO] - Training Epoch: 1/2, step 425/7134 completed (loss: 2.388906955718994, acc: 0.375)
[2024-12-17 01:36:28,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:28,242][root][INFO] - Training Epoch: 1/2, step 426/7134 completed (loss: 2.3848562240600586, acc: 0.37465181946754456)
[2024-12-17 01:36:28,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:28,566][root][INFO] - Training Epoch: 1/2, step 427/7134 completed (loss: 2.5078163146972656, acc: 0.34901365637779236)
[2024-12-17 01:36:28,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:28,951][root][INFO] - Training Epoch: 1/2, step 428/7134 completed (loss: 2.6836154460906982, acc: 0.33734938502311707)
[2024-12-17 01:36:29,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:29,283][root][INFO] - Training Epoch: 1/2, step 429/7134 completed (loss: 2.46826171875, acc: 0.36565977334976196)
[2024-12-17 01:36:29,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:29,626][root][INFO] - Training Epoch: 1/2, step 430/7134 completed (loss: 2.5085196495056152, acc: 0.36298421025276184)
[2024-12-17 01:36:29,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:29,965][root][INFO] - Training Epoch: 1/2, step 431/7134 completed (loss: 2.4091598987579346, acc: 0.3631123900413513)
[2024-12-17 01:36:30,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:30,300][root][INFO] - Training Epoch: 1/2, step 432/7134 completed (loss: 2.588815450668335, acc: 0.3290676474571228)
[2024-12-17 01:36:30,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:30,733][root][INFO] - Training Epoch: 1/2, step 433/7134 completed (loss: 2.4908859729766846, acc: 0.36820653080940247)
[2024-12-17 01:36:30,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:31,080][root][INFO] - Training Epoch: 1/2, step 434/7134 completed (loss: 2.507509708404541, acc: 0.3352855145931244)
[2024-12-17 01:36:31,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:31,432][root][INFO] - Training Epoch: 1/2, step 435/7134 completed (loss: 2.5424060821533203, acc: 0.3361702263355255)
[2024-12-17 01:36:31,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:31,750][root][INFO] - Training Epoch: 1/2, step 436/7134 completed (loss: 2.377021551132202, acc: 0.36614173650741577)
[2024-12-17 01:36:31,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:32,071][root][INFO] - Training Epoch: 1/2, step 437/7134 completed (loss: 2.4870805740356445, acc: 0.3551236689090729)
[2024-12-17 01:36:32,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:32,383][root][INFO] - Training Epoch: 1/2, step 438/7134 completed (loss: 2.5192947387695312, acc: 0.36153846979141235)
[2024-12-17 01:36:32,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:32,780][root][INFO] - Training Epoch: 1/2, step 439/7134 completed (loss: 2.6151509284973145, acc: 0.33376961946487427)
[2024-12-17 01:36:32,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:33,116][root][INFO] - Training Epoch: 1/2, step 440/7134 completed (loss: 2.6047987937927246, acc: 0.33448874950408936)
[2024-12-17 01:36:33,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:33,465][root][INFO] - Training Epoch: 1/2, step 441/7134 completed (loss: 2.5091490745544434, acc: 0.3628185987472534)
[2024-12-17 01:36:33,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:33,848][root][INFO] - Training Epoch: 1/2, step 442/7134 completed (loss: 2.2973766326904297, acc: 0.38246268033981323)
[2024-12-17 01:36:33,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:34,194][root][INFO] - Training Epoch: 1/2, step 443/7134 completed (loss: 2.4349639415740967, acc: 0.34728682041168213)
[2024-12-17 01:36:34,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:34,528][root][INFO] - Training Epoch: 1/2, step 444/7134 completed (loss: 2.4636597633361816, acc: 0.38333332538604736)
[2024-12-17 01:36:34,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:34,863][root][INFO] - Training Epoch: 1/2, step 445/7134 completed (loss: 2.515597105026245, acc: 0.3469387888908386)
[2024-12-17 01:36:34,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:35,218][root][INFO] - Training Epoch: 1/2, step 446/7134 completed (loss: 2.4735093116760254, acc: 0.38300836086273193)
[2024-12-17 01:36:35,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:35,579][root][INFO] - Training Epoch: 1/2, step 447/7134 completed (loss: 2.4431533813476562, acc: 0.3633841872215271)
[2024-12-17 01:36:35,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:35,940][root][INFO] - Training Epoch: 1/2, step 448/7134 completed (loss: 2.5831189155578613, acc: 0.36189258098602295)
[2024-12-17 01:36:36,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:36,302][root][INFO] - Training Epoch: 1/2, step 449/7134 completed (loss: 2.4324121475219727, acc: 0.37041884660720825)
[2024-12-17 01:36:36,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:36,669][root][INFO] - Training Epoch: 1/2, step 450/7134 completed (loss: 2.5173535346984863, acc: 0.36199575662612915)
[2024-12-17 01:36:36,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:37,032][root][INFO] - Training Epoch: 1/2, step 451/7134 completed (loss: 2.526496410369873, acc: 0.36979785561561584)
[2024-12-17 01:36:37,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:37,396][root][INFO] - Training Epoch: 1/2, step 452/7134 completed (loss: 2.637681722640991, acc: 0.3315068483352661)
[2024-12-17 01:36:37,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:37,715][root][INFO] - Training Epoch: 1/2, step 453/7134 completed (loss: 2.4699325561523438, acc: 0.38348624110221863)
[2024-12-17 01:36:37,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:38,084][root][INFO] - Training Epoch: 1/2, step 454/7134 completed (loss: 2.365107774734497, acc: 0.3832077383995056)
[2024-12-17 01:36:38,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:38,455][root][INFO] - Training Epoch: 1/2, step 455/7134 completed (loss: 2.59794020652771, acc: 0.3516339957714081)
[2024-12-17 01:36:38,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:38,870][root][INFO] - Training Epoch: 1/2, step 456/7134 completed (loss: 2.4167685508728027, acc: 0.3597733676433563)
[2024-12-17 01:36:38,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:39,222][root][INFO] - Training Epoch: 1/2, step 457/7134 completed (loss: 2.626696825027466, acc: 0.3255033493041992)
[2024-12-17 01:36:39,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:39,586][root][INFO] - Training Epoch: 1/2, step 458/7134 completed (loss: 2.5079433917999268, acc: 0.3479125201702118)
[2024-12-17 01:36:39,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:39,931][root][INFO] - Training Epoch: 1/2, step 459/7134 completed (loss: 2.5938045978546143, acc: 0.3318518400192261)
[2024-12-17 01:36:40,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:40,266][root][INFO] - Training Epoch: 1/2, step 460/7134 completed (loss: 2.475985288619995, acc: 0.3606299161911011)
[2024-12-17 01:36:40,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:40,624][root][INFO] - Training Epoch: 1/2, step 461/7134 completed (loss: 2.5273571014404297, acc: 0.35203367471694946)
[2024-12-17 01:36:40,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:41,015][root][INFO] - Training Epoch: 1/2, step 462/7134 completed (loss: 2.5258843898773193, acc: 0.3539719581604004)
[2024-12-17 01:36:41,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:41,412][root][INFO] - Training Epoch: 1/2, step 463/7134 completed (loss: 2.600740432739258, acc: 0.32245922088623047)
[2024-12-17 01:36:41,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:41,781][root][INFO] - Training Epoch: 1/2, step 464/7134 completed (loss: 2.498793601989746, acc: 0.3611898124217987)
[2024-12-17 01:36:41,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:42,151][root][INFO] - Training Epoch: 1/2, step 465/7134 completed (loss: 2.5390267372131348, acc: 0.33420366048812866)
[2024-12-17 01:36:42,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:42,517][root][INFO] - Training Epoch: 1/2, step 466/7134 completed (loss: 2.444718360900879, acc: 0.35392534732818604)
[2024-12-17 01:36:42,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:42,886][root][INFO] - Training Epoch: 1/2, step 467/7134 completed (loss: 2.505693197250366, acc: 0.3431483507156372)
[2024-12-17 01:36:43,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:43,249][root][INFO] - Training Epoch: 1/2, step 468/7134 completed (loss: 2.6162972450256348, acc: 0.331499308347702)
[2024-12-17 01:36:43,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:43,595][root][INFO] - Training Epoch: 1/2, step 469/7134 completed (loss: 2.588212013244629, acc: 0.33573487401008606)
[2024-12-17 01:36:43,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:43,922][root][INFO] - Training Epoch: 1/2, step 470/7134 completed (loss: 2.581784725189209, acc: 0.3292517066001892)
[2024-12-17 01:36:44,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:44,260][root][INFO] - Training Epoch: 1/2, step 471/7134 completed (loss: 2.491039514541626, acc: 0.3467455506324768)
[2024-12-17 01:36:44,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:44,612][root][INFO] - Training Epoch: 1/2, step 472/7134 completed (loss: 2.581477642059326, acc: 0.3123167157173157)
[2024-12-17 01:36:44,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:44,975][root][INFO] - Training Epoch: 1/2, step 473/7134 completed (loss: 2.5482780933380127, acc: 0.3503086566925049)
[2024-12-17 01:36:45,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:45,326][root][INFO] - Training Epoch: 1/2, step 474/7134 completed (loss: 2.597891092300415, acc: 0.3267457187175751)
[2024-12-17 01:36:45,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:45,684][root][INFO] - Training Epoch: 1/2, step 475/7134 completed (loss: 2.5122056007385254, acc: 0.3397058844566345)
[2024-12-17 01:36:45,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:46,040][root][INFO] - Training Epoch: 1/2, step 476/7134 completed (loss: 2.6439011096954346, acc: 0.3452722132205963)
[2024-12-17 01:36:46,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:46,415][root][INFO] - Training Epoch: 1/2, step 477/7134 completed (loss: 2.6143229007720947, acc: 0.3288508653640747)
[2024-12-17 01:36:46,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:46,740][root][INFO] - Training Epoch: 1/2, step 478/7134 completed (loss: 2.5447285175323486, acc: 0.353065550327301)
[2024-12-17 01:36:46,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:47,060][root][INFO] - Training Epoch: 1/2, step 479/7134 completed (loss: 2.4990925788879395, acc: 0.3529411852359772)
[2024-12-17 01:36:47,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:47,380][root][INFO] - Training Epoch: 1/2, step 480/7134 completed (loss: 2.413252115249634, acc: 0.37226277589797974)
[2024-12-17 01:36:47,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:47,728][root][INFO] - Training Epoch: 1/2, step 481/7134 completed (loss: 2.5682857036590576, acc: 0.3372395932674408)
[2024-12-17 01:36:47,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:48,066][root][INFO] - Training Epoch: 1/2, step 482/7134 completed (loss: 2.4104723930358887, acc: 0.3757142722606659)
[2024-12-17 01:36:48,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:48,420][root][INFO] - Training Epoch: 1/2, step 483/7134 completed (loss: 2.505948305130005, acc: 0.36486485600471497)
[2024-12-17 01:36:48,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:48,757][root][INFO] - Training Epoch: 1/2, step 484/7134 completed (loss: 2.463991165161133, acc: 0.36229947209358215)
[2024-12-17 01:36:48,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:49,089][root][INFO] - Training Epoch: 1/2, step 485/7134 completed (loss: 2.418031930923462, acc: 0.3812405467033386)
[2024-12-17 01:36:49,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:49,427][root][INFO] - Training Epoch: 1/2, step 486/7134 completed (loss: 2.636843204498291, acc: 0.3322368562221527)
[2024-12-17 01:36:49,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:49,775][root][INFO] - Training Epoch: 1/2, step 487/7134 completed (loss: 2.543883800506592, acc: 0.3480176329612732)
[2024-12-17 01:36:49,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:50,086][root][INFO] - Training Epoch: 1/2, step 488/7134 completed (loss: 2.524754285812378, acc: 0.35144928097724915)
[2024-12-17 01:36:50,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:50,447][root][INFO] - Training Epoch: 1/2, step 489/7134 completed (loss: 2.4735865592956543, acc: 0.3462184965610504)
[2024-12-17 01:36:50,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:50,777][root][INFO] - Training Epoch: 1/2, step 490/7134 completed (loss: 2.3701820373535156, acc: 0.3782312870025635)
[2024-12-17 01:36:50,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:51,101][root][INFO] - Training Epoch: 1/2, step 491/7134 completed (loss: 2.5569398403167725, acc: 0.3503289520740509)
[2024-12-17 01:36:51,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:51,431][root][INFO] - Training Epoch: 1/2, step 492/7134 completed (loss: 2.3804194927215576, acc: 0.3721633851528168)
[2024-12-17 01:36:51,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:51,834][root][INFO] - Training Epoch: 1/2, step 493/7134 completed (loss: 2.6491446495056152, acc: 0.32091689109802246)
[2024-12-17 01:36:51,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:52,180][root][INFO] - Training Epoch: 1/2, step 494/7134 completed (loss: 2.4293298721313477, acc: 0.37968748807907104)
[2024-12-17 01:36:52,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:52,524][root][INFO] - Training Epoch: 1/2, step 495/7134 completed (loss: 2.5209128856658936, acc: 0.36666667461395264)
[2024-12-17 01:36:52,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:52,799][root][INFO] - Training Epoch: 1/2, step 496/7134 completed (loss: 2.5220770835876465, acc: 0.3333333432674408)
[2024-12-17 01:36:52,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:53,144][root][INFO] - Training Epoch: 1/2, step 497/7134 completed (loss: 2.524240255355835, acc: 0.33914729952812195)
[2024-12-17 01:36:53,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:53,502][root][INFO] - Training Epoch: 1/2, step 498/7134 completed (loss: 2.4395198822021484, acc: 0.37660256028175354)
[2024-12-17 01:36:53,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:53,895][root][INFO] - Training Epoch: 1/2, step 499/7134 completed (loss: 2.3488516807556152, acc: 0.38664811849594116)
[2024-12-17 01:36:53,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:54,226][root][INFO] - Training Epoch: 1/2, step 500/7134 completed (loss: 2.458922863006592, acc: 0.36800000071525574)
[2024-12-17 01:36:54,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:54,605][root][INFO] - Training Epoch: 1/2, step 501/7134 completed (loss: 2.454380989074707, acc: 0.37534627318382263)
[2024-12-17 01:36:54,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:54,935][root][INFO] - Training Epoch: 1/2, step 502/7134 completed (loss: 2.398519515991211, acc: 0.37461772561073303)
[2024-12-17 01:36:55,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:55,257][root][INFO] - Training Epoch: 1/2, step 503/7134 completed (loss: 2.391727924346924, acc: 0.38657718896865845)
[2024-12-17 01:36:55,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:55,608][root][INFO] - Training Epoch: 1/2, step 504/7134 completed (loss: 2.4855499267578125, acc: 0.3533519506454468)
[2024-12-17 01:36:55,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:55,935][root][INFO] - Training Epoch: 1/2, step 505/7134 completed (loss: 2.4490301609039307, acc: 0.33507853746414185)
[2024-12-17 01:36:56,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:56,319][root][INFO] - Training Epoch: 1/2, step 506/7134 completed (loss: 2.446927785873413, acc: 0.3731343150138855)
[2024-12-17 01:36:56,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:56,742][root][INFO] - Training Epoch: 1/2, step 507/7134 completed (loss: 2.3868160247802734, acc: 0.3565789461135864)
[2024-12-17 01:36:56,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:57,103][root][INFO] - Training Epoch: 1/2, step 508/7134 completed (loss: 2.539367914199829, acc: 0.3296089470386505)
[2024-12-17 01:36:57,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:57,502][root][INFO] - Training Epoch: 1/2, step 509/7134 completed (loss: 2.5327422618865967, acc: 0.35085007548332214)
[2024-12-17 01:36:57,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:57,802][root][INFO] - Training Epoch: 1/2, step 510/7134 completed (loss: 2.570578098297119, acc: 0.3451143503189087)
[2024-12-17 01:36:57,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:58,117][root][INFO] - Training Epoch: 1/2, step 511/7134 completed (loss: 2.5719645023345947, acc: 0.37163814902305603)
[2024-12-17 01:36:58,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:58,440][root][INFO] - Training Epoch: 1/2, step 512/7134 completed (loss: 2.4028513431549072, acc: 0.3807615339756012)
[2024-12-17 01:36:58,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:58,796][root][INFO] - Training Epoch: 1/2, step 513/7134 completed (loss: 2.3570358753204346, acc: 0.4061962068080902)
[2024-12-17 01:36:58,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:59,097][root][INFO] - Training Epoch: 1/2, step 514/7134 completed (loss: 2.5294289588928223, acc: 0.3542713522911072)
[2024-12-17 01:36:59,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:59,468][root][INFO] - Training Epoch: 1/2, step 515/7134 completed (loss: 2.4510819911956787, acc: 0.3677510619163513)
[2024-12-17 01:36:59,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:59,744][root][INFO] - Training Epoch: 1/2, step 516/7134 completed (loss: 2.405912399291992, acc: 0.40732264518737793)
[2024-12-17 01:36:59,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:00,076][root][INFO] - Training Epoch: 1/2, step 517/7134 completed (loss: 2.542334794998169, acc: 0.35304659605026245)
[2024-12-17 01:37:00,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:00,429][root][INFO] - Training Epoch: 1/2, step 518/7134 completed (loss: 2.4437406063079834, acc: 0.371814101934433)
[2024-12-17 01:37:00,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:00,797][root][INFO] - Training Epoch: 1/2, step 519/7134 completed (loss: 2.4159152507781982, acc: 0.3814432919025421)
[2024-12-17 01:37:00,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:01,126][root][INFO] - Training Epoch: 1/2, step 520/7134 completed (loss: 2.420511245727539, acc: 0.3718354403972626)
[2024-12-17 01:37:01,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:01,466][root][INFO] - Training Epoch: 1/2, step 521/7134 completed (loss: 2.482969045639038, acc: 0.33778372406959534)
[2024-12-17 01:37:01,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:01,831][root][INFO] - Training Epoch: 1/2, step 522/7134 completed (loss: 2.351069688796997, acc: 0.36058980226516724)
[2024-12-17 01:37:01,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:02,189][root][INFO] - Training Epoch: 1/2, step 523/7134 completed (loss: 2.421921491622925, acc: 0.37280702590942383)
[2024-12-17 01:37:02,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:02,537][root][INFO] - Training Epoch: 1/2, step 524/7134 completed (loss: 2.3445894718170166, acc: 0.3870967626571655)
[2024-12-17 01:37:02,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:02,895][root][INFO] - Training Epoch: 1/2, step 525/7134 completed (loss: 2.3470871448516846, acc: 0.38948994874954224)
[2024-12-17 01:37:03,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:03,252][root][INFO] - Training Epoch: 1/2, step 526/7134 completed (loss: 2.499199628829956, acc: 0.3643835484981537)
[2024-12-17 01:37:03,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:03,577][root][INFO] - Training Epoch: 1/2, step 527/7134 completed (loss: 2.3400070667266846, acc: 0.3768656849861145)
[2024-12-17 01:37:03,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:03,927][root][INFO] - Training Epoch: 1/2, step 528/7134 completed (loss: 2.4548568725585938, acc: 0.3702213168144226)
[2024-12-17 01:37:04,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:04,325][root][INFO] - Training Epoch: 1/2, step 529/7134 completed (loss: 2.400718927383423, acc: 0.3730158805847168)
[2024-12-17 01:37:04,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:04,648][root][INFO] - Training Epoch: 1/2, step 530/7134 completed (loss: 2.508122205734253, acc: 0.35506004095077515)
[2024-12-17 01:37:04,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:04,959][root][INFO] - Training Epoch: 1/2, step 531/7134 completed (loss: 2.389863967895508, acc: 0.36068376898765564)
[2024-12-17 01:37:05,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:05,284][root][INFO] - Training Epoch: 1/2, step 532/7134 completed (loss: 2.4162867069244385, acc: 0.3887733817100525)
[2024-12-17 01:37:05,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:05,644][root][INFO] - Training Epoch: 1/2, step 533/7134 completed (loss: 2.3571741580963135, acc: 0.3865979313850403)
[2024-12-17 01:37:05,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:05,993][root][INFO] - Training Epoch: 1/2, step 534/7134 completed (loss: 2.257469892501831, acc: 0.40109890699386597)
[2024-12-17 01:37:06,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:06,393][root][INFO] - Training Epoch: 1/2, step 535/7134 completed (loss: 2.440614700317383, acc: 0.35852372646331787)
[2024-12-17 01:37:06,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:06,739][root][INFO] - Training Epoch: 1/2, step 536/7134 completed (loss: 2.414726495742798, acc: 0.37810218334198)
[2024-12-17 01:37:06,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:07,062][root][INFO] - Training Epoch: 1/2, step 537/7134 completed (loss: 2.41062068939209, acc: 0.3549337387084961)
[2024-12-17 01:37:07,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:07,422][root][INFO] - Training Epoch: 1/2, step 538/7134 completed (loss: 2.3996522426605225, acc: 0.3649851679801941)
[2024-12-17 01:37:07,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:07,762][root][INFO] - Training Epoch: 1/2, step 539/7134 completed (loss: 2.5402843952178955, acc: 0.366782009601593)
[2024-12-17 01:37:07,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:08,077][root][INFO] - Training Epoch: 1/2, step 540/7134 completed (loss: 2.5369184017181396, acc: 0.3252525329589844)
[2024-12-17 01:37:08,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:08,449][root][INFO] - Training Epoch: 1/2, step 541/7134 completed (loss: 2.5776970386505127, acc: 0.3257978856563568)
[2024-12-17 01:37:08,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:08,722][root][INFO] - Training Epoch: 1/2, step 542/7134 completed (loss: 2.4887826442718506, acc: 0.33568075299263)
[2024-12-17 01:37:08,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:09,055][root][INFO] - Training Epoch: 1/2, step 543/7134 completed (loss: 2.57442045211792, acc: 0.32007232308387756)
[2024-12-17 01:37:09,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:09,399][root][INFO] - Training Epoch: 1/2, step 544/7134 completed (loss: 2.547318696975708, acc: 0.33438485860824585)
[2024-12-17 01:37:09,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:09,801][root][INFO] - Training Epoch: 1/2, step 545/7134 completed (loss: 2.5900022983551025, acc: 0.32689210772514343)
[2024-12-17 01:37:09,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:10,134][root][INFO] - Training Epoch: 1/2, step 546/7134 completed (loss: 2.6602020263671875, acc: 0.30732861161231995)
[2024-12-17 01:37:10,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:10,491][root][INFO] - Training Epoch: 1/2, step 547/7134 completed (loss: 2.441654920578003, acc: 0.3599419593811035)
[2024-12-17 01:37:10,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:10,825][root][INFO] - Training Epoch: 1/2, step 548/7134 completed (loss: 2.487353801727295, acc: 0.32203391194343567)
[2024-12-17 01:37:10,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:11,155][root][INFO] - Training Epoch: 1/2, step 549/7134 completed (loss: 2.570636749267578, acc: 0.3229813575744629)
[2024-12-17 01:37:11,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:11,491][root][INFO] - Training Epoch: 1/2, step 550/7134 completed (loss: 2.593552827835083, acc: 0.30546075105667114)
[2024-12-17 01:37:11,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:11,804][root][INFO] - Training Epoch: 1/2, step 551/7134 completed (loss: 2.45100474357605, acc: 0.3278084695339203)
[2024-12-17 01:37:11,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:12,128][root][INFO] - Training Epoch: 1/2, step 552/7134 completed (loss: 2.434922456741333, acc: 0.37321937084198)
[2024-12-17 01:37:12,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:12,455][root][INFO] - Training Epoch: 1/2, step 553/7134 completed (loss: 2.5069081783294678, acc: 0.3333333432674408)
[2024-12-17 01:37:12,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:12,839][root][INFO] - Training Epoch: 1/2, step 554/7134 completed (loss: 2.4036126136779785, acc: 0.343794584274292)
[2024-12-17 01:37:12,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:13,169][root][INFO] - Training Epoch: 1/2, step 555/7134 completed (loss: 2.4398016929626465, acc: 0.35545024275779724)
[2024-12-17 01:37:13,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:13,497][root][INFO] - Training Epoch: 1/2, step 556/7134 completed (loss: 2.2924938201904297, acc: 0.3847241997718811)
[2024-12-17 01:37:13,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:13,824][root][INFO] - Training Epoch: 1/2, step 557/7134 completed (loss: 2.4847142696380615, acc: 0.3299492299556732)
[2024-12-17 01:37:13,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:14,191][root][INFO] - Training Epoch: 1/2, step 558/7134 completed (loss: 2.431966781616211, acc: 0.34609928727149963)
[2024-12-17 01:37:14,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:14,546][root][INFO] - Training Epoch: 1/2, step 559/7134 completed (loss: 2.511850595474243, acc: 0.3603988587856293)
[2024-12-17 01:37:14,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:14,867][root][INFO] - Training Epoch: 1/2, step 560/7134 completed (loss: 2.4335856437683105, acc: 0.3462214469909668)
[2024-12-17 01:37:14,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:15,254][root][INFO] - Training Epoch: 1/2, step 561/7134 completed (loss: 2.4866394996643066, acc: 0.343550443649292)
[2024-12-17 01:37:15,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:15,589][root][INFO] - Training Epoch: 1/2, step 562/7134 completed (loss: 2.380908727645874, acc: 0.3523178696632385)
[2024-12-17 01:37:15,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:15,909][root][INFO] - Training Epoch: 1/2, step 563/7134 completed (loss: 2.474963903427124, acc: 0.3512658178806305)
[2024-12-17 01:37:16,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:16,290][root][INFO] - Training Epoch: 1/2, step 564/7134 completed (loss: 2.4501917362213135, acc: 0.3423980176448822)
[2024-12-17 01:37:16,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:16,623][root][INFO] - Training Epoch: 1/2, step 565/7134 completed (loss: 2.406439781188965, acc: 0.35343384742736816)
[2024-12-17 01:37:16,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:16,945][root][INFO] - Training Epoch: 1/2, step 566/7134 completed (loss: 2.459472417831421, acc: 0.34106728434562683)
[2024-12-17 01:37:17,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:17,292][root][INFO] - Training Epoch: 1/2, step 567/7134 completed (loss: 2.468716859817505, acc: 0.3492286205291748)
[2024-12-17 01:37:17,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:17,626][root][INFO] - Training Epoch: 1/2, step 568/7134 completed (loss: 2.3086297512054443, acc: 0.3986928164958954)
[2024-12-17 01:37:17,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:17,990][root][INFO] - Training Epoch: 1/2, step 569/7134 completed (loss: 2.344080686569214, acc: 0.37654322385787964)
[2024-12-17 01:37:18,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:18,363][root][INFO] - Training Epoch: 1/2, step 570/7134 completed (loss: 2.4761295318603516, acc: 0.3560517132282257)
[2024-12-17 01:37:18,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:18,717][root][INFO] - Training Epoch: 1/2, step 571/7134 completed (loss: 2.4734957218170166, acc: 0.3488664925098419)
[2024-12-17 01:37:18,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:19,057][root][INFO] - Training Epoch: 1/2, step 572/7134 completed (loss: 2.2823898792266846, acc: 0.3912484049797058)
[2024-12-17 01:37:19,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:19,410][root][INFO] - Training Epoch: 1/2, step 573/7134 completed (loss: 2.343909740447998, acc: 0.3734015226364136)
[2024-12-17 01:37:19,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:19,761][root][INFO] - Training Epoch: 1/2, step 574/7134 completed (loss: 2.333606004714966, acc: 0.39262187480926514)
[2024-12-17 01:37:19,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:20,156][root][INFO] - Training Epoch: 1/2, step 575/7134 completed (loss: 2.4368820190429688, acc: 0.3598971664905548)
[2024-12-17 01:37:20,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:20,493][root][INFO] - Training Epoch: 1/2, step 576/7134 completed (loss: 2.206477642059326, acc: 0.4108910858631134)
[2024-12-17 01:37:20,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:20,838][root][INFO] - Training Epoch: 1/2, step 577/7134 completed (loss: 2.3950188159942627, acc: 0.37285903096199036)
[2024-12-17 01:37:20,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:21,232][root][INFO] - Training Epoch: 1/2, step 578/7134 completed (loss: 2.4004909992218018, acc: 0.37935033440589905)
[2024-12-17 01:37:21,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:21,568][root][INFO] - Training Epoch: 1/2, step 579/7134 completed (loss: 2.3735153675079346, acc: 0.37483954429626465)
[2024-12-17 01:37:21,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:21,954][root][INFO] - Training Epoch: 1/2, step 580/7134 completed (loss: 2.4664835929870605, acc: 0.32509753108024597)
[2024-12-17 01:37:22,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:22,268][root][INFO] - Training Epoch: 1/2, step 581/7134 completed (loss: 2.4251949787139893, acc: 0.3793584406375885)
[2024-12-17 01:37:22,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:22,625][root][INFO] - Training Epoch: 1/2, step 582/7134 completed (loss: 2.440509557723999, acc: 0.35688623785972595)
[2024-12-17 01:37:22,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:22,978][root][INFO] - Training Epoch: 1/2, step 583/7134 completed (loss: 2.429060935974121, acc: 0.3545454442501068)
[2024-12-17 01:37:23,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:23,347][root][INFO] - Training Epoch: 1/2, step 584/7134 completed (loss: 2.3815908432006836, acc: 0.37081339955329895)
[2024-12-17 01:37:23,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:23,687][root][INFO] - Training Epoch: 1/2, step 585/7134 completed (loss: 2.404226541519165, acc: 0.35144928097724915)
[2024-12-17 01:37:23,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:24,013][root][INFO] - Training Epoch: 1/2, step 586/7134 completed (loss: 2.346501350402832, acc: 0.35723599791526794)
[2024-12-17 01:37:24,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:24,373][root][INFO] - Training Epoch: 1/2, step 587/7134 completed (loss: 2.2415361404418945, acc: 0.36975857615470886)
[2024-12-17 01:37:24,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:24,726][root][INFO] - Training Epoch: 1/2, step 588/7134 completed (loss: 2.4089300632476807, acc: 0.3579277992248535)
[2024-12-17 01:37:24,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:25,069][root][INFO] - Training Epoch: 1/2, step 589/7134 completed (loss: 2.4542460441589355, acc: 0.35976505279541016)
[2024-12-17 01:37:25,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:25,405][root][INFO] - Training Epoch: 1/2, step 590/7134 completed (loss: 2.361032247543335, acc: 0.3864661753177643)
[2024-12-17 01:37:25,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:25,745][root][INFO] - Training Epoch: 1/2, step 591/7134 completed (loss: 2.349827289581299, acc: 0.35835352540016174)
[2024-12-17 01:37:25,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:26,071][root][INFO] - Training Epoch: 1/2, step 592/7134 completed (loss: 2.3208401203155518, acc: 0.35406091809272766)
[2024-12-17 01:37:26,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:26,399][root][INFO] - Training Epoch: 1/2, step 593/7134 completed (loss: 2.254741907119751, acc: 0.404199481010437)
[2024-12-17 01:37:26,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:26,749][root][INFO] - Training Epoch: 1/2, step 594/7134 completed (loss: 2.3067376613616943, acc: 0.36729559302330017)
[2024-12-17 01:37:26,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:27,127][root][INFO] - Training Epoch: 1/2, step 595/7134 completed (loss: 2.320763349533081, acc: 0.37041720747947693)
[2024-12-17 01:37:27,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:27,512][root][INFO] - Training Epoch: 1/2, step 596/7134 completed (loss: 2.3264505863189697, acc: 0.3685567080974579)
[2024-12-17 01:37:27,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:27,879][root][INFO] - Training Epoch: 1/2, step 597/7134 completed (loss: 2.27878999710083, acc: 0.37812912464141846)
[2024-12-17 01:37:27,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:28,225][root][INFO] - Training Epoch: 1/2, step 598/7134 completed (loss: 2.3765220642089844, acc: 0.3653585910797119)
[2024-12-17 01:37:28,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:28,571][root][INFO] - Training Epoch: 1/2, step 599/7134 completed (loss: 2.3547375202178955, acc: 0.3709273040294647)
[2024-12-17 01:37:28,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:28,925][root][INFO] - Training Epoch: 1/2, step 600/7134 completed (loss: 2.394761323928833, acc: 0.39590853452682495)
[2024-12-17 01:37:29,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:29,307][root][INFO] - Training Epoch: 1/2, step 601/7134 completed (loss: 2.352412700653076, acc: 0.3720608651638031)
[2024-12-17 01:37:29,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:29,655][root][INFO] - Training Epoch: 1/2, step 602/7134 completed (loss: 2.311157703399658, acc: 0.38863107562065125)
[2024-12-17 01:37:29,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:30,006][root][INFO] - Training Epoch: 1/2, step 603/7134 completed (loss: 2.277132034301758, acc: 0.39203083515167236)
[2024-12-17 01:37:30,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:30,313][root][INFO] - Training Epoch: 1/2, step 604/7134 completed (loss: 2.344393730163574, acc: 0.35139092803001404)
[2024-12-17 01:37:30,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:30,670][root][INFO] - Training Epoch: 1/2, step 605/7134 completed (loss: 2.2846646308898926, acc: 0.38989636301994324)
[2024-12-17 01:37:30,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:31,018][root][INFO] - Training Epoch: 1/2, step 606/7134 completed (loss: 2.376762628555298, acc: 0.3720642626285553)
[2024-12-17 01:37:31,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:31,370][root][INFO] - Training Epoch: 1/2, step 607/7134 completed (loss: 2.3681983947753906, acc: 0.37650200724601746)
[2024-12-17 01:37:31,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:31,767][root][INFO] - Training Epoch: 1/2, step 608/7134 completed (loss: 2.3036417961120605, acc: 0.3847150206565857)
[2024-12-17 01:37:31,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:32,132][root][INFO] - Training Epoch: 1/2, step 609/7134 completed (loss: 2.3619353771209717, acc: 0.36768150329589844)
[2024-12-17 01:37:32,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:32,486][root][INFO] - Training Epoch: 1/2, step 610/7134 completed (loss: 2.3402974605560303, acc: 0.3603034019470215)
[2024-12-17 01:37:32,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:32,864][root][INFO] - Training Epoch: 1/2, step 611/7134 completed (loss: 2.311624765396118, acc: 0.3792682886123657)
[2024-12-17 01:37:33,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:33,228][root][INFO] - Training Epoch: 1/2, step 612/7134 completed (loss: 2.318937301635742, acc: 0.36939314007759094)
[2024-12-17 01:37:33,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:33,602][root][INFO] - Training Epoch: 1/2, step 613/7134 completed (loss: 2.334482431411743, acc: 0.36928486824035645)
[2024-12-17 01:37:33,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:33,955][root][INFO] - Training Epoch: 1/2, step 614/7134 completed (loss: 2.333737373352051, acc: 0.3646659255027771)
[2024-12-17 01:37:34,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:34,374][root][INFO] - Training Epoch: 1/2, step 615/7134 completed (loss: 2.301543951034546, acc: 0.366871178150177)
[2024-12-17 01:37:34,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:34,744][root][INFO] - Training Epoch: 1/2, step 616/7134 completed (loss: 2.331200122833252, acc: 0.3590908944606781)
[2024-12-17 01:37:34,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:35,102][root][INFO] - Training Epoch: 1/2, step 617/7134 completed (loss: 2.2631523609161377, acc: 0.37015944719314575)
[2024-12-17 01:37:35,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:35,444][root][INFO] - Training Epoch: 1/2, step 618/7134 completed (loss: 2.2265145778656006, acc: 0.38770052790641785)
[2024-12-17 01:37:35,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:35,772][root][INFO] - Training Epoch: 1/2, step 619/7134 completed (loss: 2.371216297149658, acc: 0.35020244121551514)
[2024-12-17 01:37:35,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:36,144][root][INFO] - Training Epoch: 1/2, step 620/7134 completed (loss: 2.4337501525878906, acc: 0.3407643437385559)
[2024-12-17 01:37:36,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:36,483][root][INFO] - Training Epoch: 1/2, step 621/7134 completed (loss: 2.352264881134033, acc: 0.3622526526451111)
[2024-12-17 01:37:36,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:36,818][root][INFO] - Training Epoch: 1/2, step 622/7134 completed (loss: 2.294578790664673, acc: 0.3572453260421753)
[2024-12-17 01:37:36,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:37,177][root][INFO] - Training Epoch: 1/2, step 623/7134 completed (loss: 2.3120229244232178, acc: 0.4023323655128479)
[2024-12-17 01:37:37,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:37,531][root][INFO] - Training Epoch: 1/2, step 624/7134 completed (loss: 2.469564437866211, acc: 0.34594595432281494)
[2024-12-17 01:37:37,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:37,884][root][INFO] - Training Epoch: 1/2, step 625/7134 completed (loss: 2.3191099166870117, acc: 0.3839050233364105)
[2024-12-17 01:37:38,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:38,214][root][INFO] - Training Epoch: 1/2, step 626/7134 completed (loss: 2.396739959716797, acc: 0.34192439913749695)
[2024-12-17 01:37:38,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:38,567][root][INFO] - Training Epoch: 1/2, step 627/7134 completed (loss: 2.321110486984253, acc: 0.37020647525787354)
[2024-12-17 01:37:38,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:38,901][root][INFO] - Training Epoch: 1/2, step 628/7134 completed (loss: 2.311023473739624, acc: 0.366158127784729)
[2024-12-17 01:37:39,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:39,250][root][INFO] - Training Epoch: 1/2, step 629/7134 completed (loss: 2.4146528244018555, acc: 0.3605150282382965)
[2024-12-17 01:37:39,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:39,633][root][INFO] - Training Epoch: 1/2, step 630/7134 completed (loss: 2.407431125640869, acc: 0.3549222946166992)
[2024-12-17 01:37:39,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:40,018][root][INFO] - Training Epoch: 1/2, step 631/7134 completed (loss: 2.2989559173583984, acc: 0.3907894790172577)
[2024-12-17 01:37:40,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:40,365][root][INFO] - Training Epoch: 1/2, step 632/7134 completed (loss: 2.353640079498291, acc: 0.37055015563964844)
[2024-12-17 01:37:40,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:40,692][root][INFO] - Training Epoch: 1/2, step 633/7134 completed (loss: 2.3082079887390137, acc: 0.3889695107936859)
[2024-12-17 01:37:40,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:41,019][root][INFO] - Training Epoch: 1/2, step 634/7134 completed (loss: 2.2818028926849365, acc: 0.3939873278141022)
[2024-12-17 01:37:41,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:41,362][root][INFO] - Training Epoch: 1/2, step 635/7134 completed (loss: 2.350092887878418, acc: 0.37099236249923706)
[2024-12-17 01:37:41,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:41,699][root][INFO] - Training Epoch: 1/2, step 636/7134 completed (loss: 2.35636305809021, acc: 0.39862069487571716)
[2024-12-17 01:37:41,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:42,017][root][INFO] - Training Epoch: 1/2, step 637/7134 completed (loss: 2.1778903007507324, acc: 0.4040968418121338)
[2024-12-17 01:37:42,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:42,339][root][INFO] - Training Epoch: 1/2, step 638/7134 completed (loss: 2.4045472145080566, acc: 0.3759750425815582)
[2024-12-17 01:37:42,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:42,659][root][INFO] - Training Epoch: 1/2, step 639/7134 completed (loss: 2.267317295074463, acc: 0.398333340883255)
[2024-12-17 01:37:42,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:42,974][root][INFO] - Training Epoch: 1/2, step 640/7134 completed (loss: 2.1563167572021484, acc: 0.42434781789779663)
[2024-12-17 01:37:43,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:43,294][root][INFO] - Training Epoch: 1/2, step 641/7134 completed (loss: 2.2322089672088623, acc: 0.39279869198799133)
[2024-12-17 01:37:43,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:43,651][root][INFO] - Training Epoch: 1/2, step 642/7134 completed (loss: 2.217667818069458, acc: 0.39115646481513977)
[2024-12-17 01:37:43,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:43,988][root][INFO] - Training Epoch: 1/2, step 643/7134 completed (loss: 2.383937358856201, acc: 0.378690630197525)
[2024-12-17 01:37:44,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:44,362][root][INFO] - Training Epoch: 1/2, step 644/7134 completed (loss: 2.2653369903564453, acc: 0.3918918967247009)
[2024-12-17 01:37:44,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:44,680][root][INFO] - Training Epoch: 1/2, step 645/7134 completed (loss: 2.21854305267334, acc: 0.40740740299224854)
[2024-12-17 01:37:44,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:45,012][root][INFO] - Training Epoch: 1/2, step 646/7134 completed (loss: 2.227144241333008, acc: 0.40214067697525024)
[2024-12-17 01:37:45,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:45,382][root][INFO] - Training Epoch: 1/2, step 647/7134 completed (loss: 2.2661471366882324, acc: 0.42808797955513)
[2024-12-17 01:37:45,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:45,758][root][INFO] - Training Epoch: 1/2, step 648/7134 completed (loss: 2.4070684909820557, acc: 0.38045376539230347)
[2024-12-17 01:37:45,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:46,117][root][INFO] - Training Epoch: 1/2, step 649/7134 completed (loss: 2.3399391174316406, acc: 0.38461539149284363)
[2024-12-17 01:37:46,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:46,450][root][INFO] - Training Epoch: 1/2, step 650/7134 completed (loss: 2.439047336578369, acc: 0.3579277992248535)
[2024-12-17 01:37:46,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:46,782][root][INFO] - Training Epoch: 1/2, step 651/7134 completed (loss: 2.547245979309082, acc: 0.3302752375602722)
[2024-12-17 01:37:46,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:47,115][root][INFO] - Training Epoch: 1/2, step 652/7134 completed (loss: 2.26825213432312, acc: 0.38831615447998047)
[2024-12-17 01:37:47,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:47,442][root][INFO] - Training Epoch: 1/2, step 653/7134 completed (loss: 2.3987650871276855, acc: 0.34893617033958435)
[2024-12-17 01:37:47,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:47,757][root][INFO] - Training Epoch: 1/2, step 654/7134 completed (loss: 2.440882921218872, acc: 0.3261339068412781)
[2024-12-17 01:37:47,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:48,133][root][INFO] - Training Epoch: 1/2, step 655/7134 completed (loss: 2.3962690830230713, acc: 0.3407258093357086)
[2024-12-17 01:37:48,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:48,485][root][INFO] - Training Epoch: 1/2, step 656/7134 completed (loss: 2.363327741622925, acc: 0.35356199741363525)
[2024-12-17 01:37:48,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:48,840][root][INFO] - Training Epoch: 1/2, step 657/7134 completed (loss: 2.3652451038360596, acc: 0.36918139457702637)
[2024-12-17 01:37:48,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:49,176][root][INFO] - Training Epoch: 1/2, step 658/7134 completed (loss: 2.275627613067627, acc: 0.3860342502593994)
[2024-12-17 01:37:49,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:49,527][root][INFO] - Training Epoch: 1/2, step 659/7134 completed (loss: 2.255981922149658, acc: 0.4032258093357086)
[2024-12-17 01:37:49,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:49,886][root][INFO] - Training Epoch: 1/2, step 660/7134 completed (loss: 2.3781580924987793, acc: 0.38596490025520325)
[2024-12-17 01:37:50,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:50,257][root][INFO] - Training Epoch: 1/2, step 661/7134 completed (loss: 2.3422470092773438, acc: 0.3880753219127655)
[2024-12-17 01:37:50,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:50,651][root][INFO] - Training Epoch: 1/2, step 662/7134 completed (loss: 2.243612289428711, acc: 0.39678284525871277)
[2024-12-17 01:37:50,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:51,045][root][INFO] - Training Epoch: 1/2, step 663/7134 completed (loss: 2.30438232421875, acc: 0.36475870013237)
[2024-12-17 01:37:51,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:51,418][root][INFO] - Training Epoch: 1/2, step 664/7134 completed (loss: 2.2365715503692627, acc: 0.40833333134651184)
[2024-12-17 01:37:51,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:51,755][root][INFO] - Training Epoch: 1/2, step 665/7134 completed (loss: 2.3415746688842773, acc: 0.36742934584617615)
[2024-12-17 01:37:51,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:52,124][root][INFO] - Training Epoch: 1/2, step 666/7134 completed (loss: 2.3602874279022217, acc: 0.36950549483299255)
[2024-12-17 01:37:52,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:52,492][root][INFO] - Training Epoch: 1/2, step 667/7134 completed (loss: 2.351963520050049, acc: 0.36229750514030457)
[2024-12-17 01:37:52,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:52,838][root][INFO] - Training Epoch: 1/2, step 668/7134 completed (loss: 2.1627018451690674, acc: 0.4030418395996094)
[2024-12-17 01:37:52,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:53,202][root][INFO] - Training Epoch: 1/2, step 669/7134 completed (loss: 2.333584785461426, acc: 0.36425647139549255)
[2024-12-17 01:37:53,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:53,585][root][INFO] - Training Epoch: 1/2, step 670/7134 completed (loss: 2.3283371925354004, acc: 0.3911704421043396)
[2024-12-17 01:37:53,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:53,961][root][INFO] - Training Epoch: 1/2, step 671/7134 completed (loss: 2.442154884338379, acc: 0.37299033999443054)
[2024-12-17 01:37:54,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:54,324][root][INFO] - Training Epoch: 1/2, step 672/7134 completed (loss: 2.1707730293273926, acc: 0.3994038701057434)
[2024-12-17 01:37:54,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:54,671][root][INFO] - Training Epoch: 1/2, step 673/7134 completed (loss: 2.2101519107818604, acc: 0.3943488895893097)
[2024-12-17 01:37:54,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:55,019][root][INFO] - Training Epoch: 1/2, step 674/7134 completed (loss: 2.193155288696289, acc: 0.4238310754299164)
[2024-12-17 01:37:55,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:55,385][root][INFO] - Training Epoch: 1/2, step 675/7134 completed (loss: 2.2405447959899902, acc: 0.39634940028190613)
[2024-12-17 01:37:55,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:55,729][root][INFO] - Training Epoch: 1/2, step 676/7134 completed (loss: 2.224687337875366, acc: 0.389349102973938)
[2024-12-17 01:37:55,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:56,093][root][INFO] - Training Epoch: 1/2, step 677/7134 completed (loss: 2.126594305038452, acc: 0.419235497713089)
[2024-12-17 01:37:56,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:56,450][root][INFO] - Training Epoch: 1/2, step 678/7134 completed (loss: 2.3266043663024902, acc: 0.36473754048347473)
[2024-12-17 01:37:56,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:56,755][root][INFO] - Training Epoch: 1/2, step 679/7134 completed (loss: 2.251495599746704, acc: 0.4026465117931366)
[2024-12-17 01:37:56,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:57,110][root][INFO] - Training Epoch: 1/2, step 680/7134 completed (loss: 2.1744048595428467, acc: 0.42587602138519287)
[2024-12-17 01:37:57,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:57,504][root][INFO] - Training Epoch: 1/2, step 681/7134 completed (loss: 2.1555001735687256, acc: 0.4147239327430725)
[2024-12-17 01:37:57,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:57,846][root][INFO] - Training Epoch: 1/2, step 682/7134 completed (loss: 2.0761642456054688, acc: 0.4149855971336365)
[2024-12-17 01:37:57,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:58,238][root][INFO] - Training Epoch: 1/2, step 683/7134 completed (loss: 2.3174898624420166, acc: 0.3758573532104492)
[2024-12-17 01:37:58,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:58,617][root][INFO] - Training Epoch: 1/2, step 684/7134 completed (loss: 2.252486228942871, acc: 0.3947368562221527)
[2024-12-17 01:37:58,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:58,967][root][INFO] - Training Epoch: 1/2, step 685/7134 completed (loss: 2.331865072250366, acc: 0.39775562286376953)
[2024-12-17 01:37:59,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:59,320][root][INFO] - Training Epoch: 1/2, step 686/7134 completed (loss: 2.107679843902588, acc: 0.41743725538253784)
[2024-12-17 01:37:59,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:59,674][root][INFO] - Training Epoch: 1/2, step 687/7134 completed (loss: 2.2086427211761475, acc: 0.3791102468967438)
[2024-12-17 01:37:59,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:00,045][root][INFO] - Training Epoch: 1/2, step 688/7134 completed (loss: 2.163609504699707, acc: 0.3994082808494568)
[2024-12-17 01:38:00,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:00,390][root][INFO] - Training Epoch: 1/2, step 689/7134 completed (loss: 2.285921096801758, acc: 0.3709401786327362)
[2024-12-17 01:38:00,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:00,748][root][INFO] - Training Epoch: 1/2, step 690/7134 completed (loss: 2.1621735095977783, acc: 0.3958664536476135)
[2024-12-17 01:38:00,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:01,079][root][INFO] - Training Epoch: 1/2, step 691/7134 completed (loss: 2.329894781112671, acc: 0.3448275923728943)
[2024-12-17 01:38:01,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:01,437][root][INFO] - Training Epoch: 1/2, step 692/7134 completed (loss: 2.2351937294006348, acc: 0.40933331847190857)
[2024-12-17 01:38:01,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:01,812][root][INFO] - Training Epoch: 1/2, step 693/7134 completed (loss: 2.2145626544952393, acc: 0.35379645228385925)
[2024-12-17 01:38:01,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:02,144][root][INFO] - Training Epoch: 1/2, step 694/7134 completed (loss: 2.257883310317993, acc: 0.3664233684539795)
[2024-12-17 01:38:02,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:02,495][root][INFO] - Training Epoch: 1/2, step 695/7134 completed (loss: 2.355860948562622, acc: 0.3562822639942169)
[2024-12-17 01:38:02,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:02,815][root][INFO] - Training Epoch: 1/2, step 696/7134 completed (loss: 2.2063262462615967, acc: 0.37378641963005066)
[2024-12-17 01:38:02,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:03,170][root][INFO] - Training Epoch: 1/2, step 697/7134 completed (loss: 2.148848295211792, acc: 0.41439205408096313)
[2024-12-17 01:38:03,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:03,510][root][INFO] - Training Epoch: 1/2, step 698/7134 completed (loss: 2.1922390460968018, acc: 0.3973941504955292)
[2024-12-17 01:38:03,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:03,903][root][INFO] - Training Epoch: 1/2, step 699/7134 completed (loss: 2.3356516361236572, acc: 0.35514017939567566)
[2024-12-17 01:38:04,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:04,251][root][INFO] - Training Epoch: 1/2, step 700/7134 completed (loss: 2.2385079860687256, acc: 0.36194029450416565)
[2024-12-17 01:38:04,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:04,571][root][INFO] - Training Epoch: 1/2, step 701/7134 completed (loss: 2.225346326828003, acc: 0.3794326186180115)
[2024-12-17 01:38:04,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:04,927][root][INFO] - Training Epoch: 1/2, step 702/7134 completed (loss: 2.210862874984741, acc: 0.37987011671066284)
[2024-12-17 01:38:05,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:05,268][root][INFO] - Training Epoch: 1/2, step 703/7134 completed (loss: 2.206315279006958, acc: 0.38449111580848694)
[2024-12-17 01:38:05,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:05,632][root][INFO] - Training Epoch: 1/2, step 704/7134 completed (loss: 2.333827257156372, acc: 0.3784194588661194)
[2024-12-17 01:38:05,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:06,023][root][INFO] - Training Epoch: 1/2, step 705/7134 completed (loss: 2.2265636920928955, acc: 0.3966480493545532)
[2024-12-17 01:38:06,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:06,381][root][INFO] - Training Epoch: 1/2, step 706/7134 completed (loss: 2.181443214416504, acc: 0.4004376232624054)
[2024-12-17 01:38:06,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:06,726][root][INFO] - Training Epoch: 1/2, step 707/7134 completed (loss: 2.2808918952941895, acc: 0.3884892165660858)
[2024-12-17 01:38:06,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:07,091][root][INFO] - Training Epoch: 1/2, step 708/7134 completed (loss: 2.236381769180298, acc: 0.38661709427833557)
[2024-12-17 01:38:07,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:07,435][root][INFO] - Training Epoch: 1/2, step 709/7134 completed (loss: 2.2243878841400146, acc: 0.4116944968700409)
[2024-12-17 01:38:07,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:07,794][root][INFO] - Training Epoch: 1/2, step 710/7134 completed (loss: 2.226278781890869, acc: 0.40799030661582947)
[2024-12-17 01:38:07,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:08,124][root][INFO] - Training Epoch: 1/2, step 711/7134 completed (loss: 2.1508662700653076, acc: 0.40731996297836304)
[2024-12-17 01:38:08,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:08,461][root][INFO] - Training Epoch: 1/2, step 712/7134 completed (loss: 2.116421937942505, acc: 0.4114774167537689)
[2024-12-17 01:38:08,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:08,823][root][INFO] - Training Epoch: 1/2, step 713/7134 completed (loss: 2.1043615341186523, acc: 0.4198385179042816)
[2024-12-17 01:38:08,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:09,088][root][INFO] - Training Epoch: 1/2, step 714/7134 completed (loss: 2.2179861068725586, acc: 0.39613527059555054)
[2024-12-17 01:38:09,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:09,458][root][INFO] - Training Epoch: 1/2, step 715/7134 completed (loss: 2.0966646671295166, acc: 0.41335228085517883)
[2024-12-17 01:38:09,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:09,807][root][INFO] - Training Epoch: 1/2, step 716/7134 completed (loss: 2.171841859817505, acc: 0.42207053303718567)
[2024-12-17 01:38:09,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:10,147][root][INFO] - Training Epoch: 1/2, step 717/7134 completed (loss: 2.104707717895508, acc: 0.4007585346698761)
[2024-12-17 01:38:10,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:10,511][root][INFO] - Training Epoch: 1/2, step 718/7134 completed (loss: 2.1235320568084717, acc: 0.4160400927066803)
[2024-12-17 01:38:10,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:10,824][root][INFO] - Training Epoch: 1/2, step 719/7134 completed (loss: 1.9979522228240967, acc: 0.4396551847457886)
[2024-12-17 01:38:10,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:11,175][root][INFO] - Training Epoch: 1/2, step 720/7134 completed (loss: 2.095592737197876, acc: 0.4260651767253876)
[2024-12-17 01:38:11,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:11,534][root][INFO] - Training Epoch: 1/2, step 721/7134 completed (loss: 2.088832139968872, acc: 0.41613316535949707)
[2024-12-17 01:38:11,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:11,925][root][INFO] - Training Epoch: 1/2, step 722/7134 completed (loss: 2.084341526031494, acc: 0.4142357110977173)
[2024-12-17 01:38:12,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:12,278][root][INFO] - Training Epoch: 1/2, step 723/7134 completed (loss: 2.0034379959106445, acc: 0.4406779706478119)
[2024-12-17 01:38:12,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:12,683][root][INFO] - Training Epoch: 1/2, step 724/7134 completed (loss: 2.040201425552368, acc: 0.4234620928764343)
[2024-12-17 01:38:12,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:13,032][root][INFO] - Training Epoch: 1/2, step 725/7134 completed (loss: 1.9183884859085083, acc: 0.4471780061721802)
[2024-12-17 01:38:13,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:13,383][root][INFO] - Training Epoch: 1/2, step 726/7134 completed (loss: 1.7323853969573975, acc: 0.5355648398399353)
[2024-12-17 01:38:13,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:13,723][root][INFO] - Training Epoch: 1/2, step 727/7134 completed (loss: 1.9751110076904297, acc: 0.48773449659347534)
[2024-12-17 01:38:13,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:14,062][root][INFO] - Training Epoch: 1/2, step 728/7134 completed (loss: 1.9262101650238037, acc: 0.4586776793003082)
[2024-12-17 01:38:14,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:14,453][root][INFO] - Training Epoch: 1/2, step 729/7134 completed (loss: 1.925777554512024, acc: 0.4673157036304474)
[2024-12-17 01:38:14,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:14,816][root][INFO] - Training Epoch: 1/2, step 730/7134 completed (loss: 1.8112989664077759, acc: 0.496757447719574)
[2024-12-17 01:38:14,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:15,168][root][INFO] - Training Epoch: 1/2, step 731/7134 completed (loss: 1.6899662017822266, acc: 0.5133333206176758)
[2024-12-17 01:38:15,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:15,501][root][INFO] - Training Epoch: 1/2, step 732/7134 completed (loss: 1.9676021337509155, acc: 0.46037736535072327)
[2024-12-17 01:38:15,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:15,808][root][INFO] - Training Epoch: 1/2, step 733/7134 completed (loss: 1.8369508981704712, acc: 0.4884546995162964)
[2024-12-17 01:38:15,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:16,128][root][INFO] - Training Epoch: 1/2, step 734/7134 completed (loss: 1.6331650018692017, acc: 0.5529953837394714)
[2024-12-17 01:38:16,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:16,470][root][INFO] - Training Epoch: 1/2, step 735/7134 completed (loss: 1.6164199113845825, acc: 0.5466237664222717)
[2024-12-17 01:38:16,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:16,787][root][INFO] - Training Epoch: 1/2, step 736/7134 completed (loss: 1.6328587532043457, acc: 0.5252747535705566)
[2024-12-17 01:38:16,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:17,118][root][INFO] - Training Epoch: 1/2, step 737/7134 completed (loss: 1.5923192501068115, acc: 0.5618661046028137)
[2024-12-17 01:38:17,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:17,443][root][INFO] - Training Epoch: 1/2, step 738/7134 completed (loss: 1.6746379137039185, acc: 0.5096153616905212)
[2024-12-17 01:38:17,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:17,777][root][INFO] - Training Epoch: 1/2, step 739/7134 completed (loss: 1.6195212602615356, acc: 0.5431192517280579)
[2024-12-17 01:38:17,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:18,102][root][INFO] - Training Epoch: 1/2, step 740/7134 completed (loss: 1.3204485177993774, acc: 0.6539682745933533)
[2024-12-17 01:38:18,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:18,429][root][INFO] - Training Epoch: 1/2, step 741/7134 completed (loss: 1.4478808641433716, acc: 0.5977917909622192)
[2024-12-17 01:38:18,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:18,713][root][INFO] - Training Epoch: 1/2, step 742/7134 completed (loss: 1.1335848569869995, acc: 0.6750524044036865)
[2024-12-17 01:38:18,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:19,078][root][INFO] - Training Epoch: 1/2, step 743/7134 completed (loss: 1.403680682182312, acc: 0.6069276928901672)
[2024-12-17 01:38:19,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:19,438][root][INFO] - Training Epoch: 1/2, step 744/7134 completed (loss: 1.2284525632858276, acc: 0.6666666865348816)
[2024-12-17 01:38:19,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:19,809][root][INFO] - Training Epoch: 1/2, step 745/7134 completed (loss: 1.1876689195632935, acc: 0.6450151205062866)
[2024-12-17 01:38:19,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:20,192][root][INFO] - Training Epoch: 1/2, step 746/7134 completed (loss: 1.3610984086990356, acc: 0.6239737272262573)
[2024-12-17 01:38:20,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:20,494][root][INFO] - Training Epoch: 1/2, step 747/7134 completed (loss: 1.0694564580917358, acc: 0.6926910281181335)
[2024-12-17 01:38:20,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:20,863][root][INFO] - Training Epoch: 1/2, step 748/7134 completed (loss: 1.0783888101577759, acc: 0.6796992421150208)
[2024-12-17 01:38:20,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:21,201][root][INFO] - Training Epoch: 1/2, step 749/7134 completed (loss: 0.9302673935890198, acc: 0.7420749068260193)
[2024-12-17 01:38:21,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:21,594][root][INFO] - Training Epoch: 1/2, step 750/7134 completed (loss: 0.9721667766571045, acc: 0.7207207083702087)
[2024-12-17 01:38:21,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:21,921][root][INFO] - Training Epoch: 1/2, step 751/7134 completed (loss: 1.1229238510131836, acc: 0.6712095141410828)
[2024-12-17 01:38:22,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:22,207][root][INFO] - Training Epoch: 1/2, step 752/7134 completed (loss: 0.8488432168960571, acc: 0.7417417168617249)
[2024-12-17 01:38:22,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:22,533][root][INFO] - Training Epoch: 1/2, step 753/7134 completed (loss: 0.9163360595703125, acc: 0.7297297120094299)
[2024-12-17 01:38:22,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:22,863][root][INFO] - Training Epoch: 1/2, step 754/7134 completed (loss: 0.7613186836242676, acc: 0.7828054428100586)
[2024-12-17 01:38:23,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:23,252][root][INFO] - Training Epoch: 1/2, step 755/7134 completed (loss: 0.9454110860824585, acc: 0.7541254162788391)
[2024-12-17 01:38:23,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:23,566][root][INFO] - Training Epoch: 1/2, step 756/7134 completed (loss: 0.6926968097686768, acc: 0.8168224096298218)
[2024-12-17 01:38:23,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:23,890][root][INFO] - Training Epoch: 1/2, step 757/7134 completed (loss: 0.6826241612434387, acc: 0.7988505959510803)
[2024-12-17 01:38:24,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:24,212][root][INFO] - Training Epoch: 1/2, step 758/7134 completed (loss: 0.7316152453422546, acc: 0.7882960438728333)
[2024-12-17 01:38:24,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:24,501][root][INFO] - Training Epoch: 1/2, step 759/7134 completed (loss: 0.8286962509155273, acc: 0.7906976938247681)
[2024-12-17 01:38:24,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:24,823][root][INFO] - Training Epoch: 1/2, step 760/7134 completed (loss: 0.9026673436164856, acc: 0.7348353266716003)
[2024-12-17 01:38:24,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:25,155][root][INFO] - Training Epoch: 1/2, step 761/7134 completed (loss: 0.9136187434196472, acc: 0.7323943376541138)
[2024-12-17 01:38:25,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:25,481][root][INFO] - Training Epoch: 1/2, step 762/7134 completed (loss: 0.8800880908966064, acc: 0.740143358707428)
[2024-12-17 01:38:25,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:25,810][root][INFO] - Training Epoch: 1/2, step 763/7134 completed (loss: 0.798420786857605, acc: 0.7882736325263977)
[2024-12-17 01:38:25,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:26,141][root][INFO] - Training Epoch: 1/2, step 764/7134 completed (loss: 0.7157483100891113, acc: 0.7804877758026123)
[2024-12-17 01:38:26,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:26,526][root][INFO] - Training Epoch: 1/2, step 765/7134 completed (loss: 0.8687652945518494, acc: 0.7496339678764343)
[2024-12-17 01:38:26,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:26,865][root][INFO] - Training Epoch: 1/2, step 766/7134 completed (loss: 0.7775329947471619, acc: 0.7729970216751099)
[2024-12-17 01:38:26,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:27,198][root][INFO] - Training Epoch: 1/2, step 767/7134 completed (loss: 0.6950470805168152, acc: 0.7964860796928406)
[2024-12-17 01:38:27,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:27,534][root][INFO] - Training Epoch: 1/2, step 768/7134 completed (loss: 0.8211174607276917, acc: 0.7776203751564026)
[2024-12-17 01:38:27,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:27,870][root][INFO] - Training Epoch: 1/2, step 769/7134 completed (loss: 0.8680059909820557, acc: 0.7621776461601257)
[2024-12-17 01:38:27,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:28,188][root][INFO] - Training Epoch: 1/2, step 770/7134 completed (loss: 0.7237221002578735, acc: 0.7825421094894409)
[2024-12-17 01:38:28,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:28,470][root][INFO] - Training Epoch: 1/2, step 771/7134 completed (loss: 0.713765025138855, acc: 0.801980197429657)
[2024-12-17 01:38:28,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:28,786][root][INFO] - Training Epoch: 1/2, step 772/7134 completed (loss: 0.541294276714325, acc: 0.8475711941719055)
[2024-12-17 01:38:28,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:29,141][root][INFO] - Training Epoch: 1/2, step 773/7134 completed (loss: 0.7321950197219849, acc: 0.8149100542068481)
[2024-12-17 01:38:29,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:29,472][root][INFO] - Training Epoch: 1/2, step 774/7134 completed (loss: 0.6032301783561707, acc: 0.8471760749816895)
[2024-12-17 01:38:29,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:29,830][root][INFO] - Training Epoch: 1/2, step 775/7134 completed (loss: 0.7032647132873535, acc: 0.7989347577095032)
[2024-12-17 01:38:29,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:30,176][root][INFO] - Training Epoch: 1/2, step 776/7134 completed (loss: 0.6095033288002014, acc: 0.8210059404373169)
[2024-12-17 01:38:30,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:30,520][root][INFO] - Training Epoch: 1/2, step 777/7134 completed (loss: 0.5514166355133057, acc: 0.8539325594902039)
[2024-12-17 01:38:30,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:30,857][root][INFO] - Training Epoch: 1/2, step 778/7134 completed (loss: 0.6792518496513367, acc: 0.8285256624221802)
[2024-12-17 01:38:30,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:31,184][root][INFO] - Training Epoch: 1/2, step 779/7134 completed (loss: 0.7969943881034851, acc: 0.8014598488807678)
[2024-12-17 01:38:31,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:31,547][root][INFO] - Training Epoch: 1/2, step 780/7134 completed (loss: 1.0337796211242676, acc: 0.7427123188972473)
[2024-12-17 01:38:31,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:31,918][root][INFO] - Training Epoch: 1/2, step 781/7134 completed (loss: 1.0334852933883667, acc: 0.7228327393531799)
[2024-12-17 01:38:32,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:32,232][root][INFO] - Training Epoch: 1/2, step 782/7134 completed (loss: 0.9738081097602844, acc: 0.767405092716217)
[2024-12-17 01:38:32,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:32,594][root][INFO] - Training Epoch: 1/2, step 783/7134 completed (loss: 1.084822654724121, acc: 0.7681528925895691)
[2024-12-17 01:38:32,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:32,927][root][INFO] - Training Epoch: 1/2, step 784/7134 completed (loss: 0.8429518342018127, acc: 0.7844092845916748)
[2024-12-17 01:38:33,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:33,270][root][INFO] - Training Epoch: 1/2, step 785/7134 completed (loss: 0.8603968024253845, acc: 0.7625418305397034)
[2024-12-17 01:38:33,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:33,612][root][INFO] - Training Epoch: 1/2, step 786/7134 completed (loss: 0.7702640891075134, acc: 0.8234200477600098)
[2024-12-17 01:38:33,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:33,906][root][INFO] - Training Epoch: 1/2, step 787/7134 completed (loss: 0.5755722522735596, acc: 0.8594890236854553)
[2024-12-17 01:38:34,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:34,289][root][INFO] - Training Epoch: 1/2, step 788/7134 completed (loss: 0.8489547371864319, acc: 0.7914831042289734)
[2024-12-17 01:38:34,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:34,610][root][INFO] - Training Epoch: 1/2, step 789/7134 completed (loss: 0.6366413831710815, acc: 0.8396946787834167)
[2024-12-17 01:38:34,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:34,938][root][INFO] - Training Epoch: 1/2, step 790/7134 completed (loss: 0.5939116477966309, acc: 0.8491124510765076)
[2024-12-17 01:38:35,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:35,293][root][INFO] - Training Epoch: 1/2, step 791/7134 completed (loss: 0.587921142578125, acc: 0.8517786264419556)
[2024-12-17 01:38:35,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:35,617][root][INFO] - Training Epoch: 1/2, step 792/7134 completed (loss: 0.5608379244804382, acc: 0.859350860118866)
[2024-12-17 01:38:35,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:35,944][root][INFO] - Training Epoch: 1/2, step 793/7134 completed (loss: 0.4275420010089874, acc: 0.8934911489486694)
[2024-12-17 01:38:36,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:36,268][root][INFO] - Training Epoch: 1/2, step 794/7134 completed (loss: 0.4132113754749298, acc: 0.9067599177360535)
[2024-12-17 01:38:36,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:36,579][root][INFO] - Training Epoch: 1/2, step 795/7134 completed (loss: 0.5759719014167786, acc: 0.8629283308982849)
[2024-12-17 01:38:36,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:36,916][root][INFO] - Training Epoch: 1/2, step 796/7134 completed (loss: 0.5346145629882812, acc: 0.8636363744735718)
[2024-12-17 01:38:37,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:37,214][root][INFO] - Training Epoch: 1/2, step 797/7134 completed (loss: 0.6406022310256958, acc: 0.8574297428131104)
[2024-12-17 01:38:37,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:37,490][root][INFO] - Training Epoch: 1/2, step 798/7134 completed (loss: 0.4490339457988739, acc: 0.8941798806190491)
[2024-12-17 01:38:37,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:37,786][root][INFO] - Training Epoch: 1/2, step 799/7134 completed (loss: 0.5071349143981934, acc: 0.8602150678634644)
[2024-12-17 01:38:37,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:38,100][root][INFO] - Training Epoch: 1/2, step 800/7134 completed (loss: 0.5147812962532043, acc: 0.8491619825363159)
[2024-12-17 01:38:38,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:38,434][root][INFO] - Training Epoch: 1/2, step 801/7134 completed (loss: 0.4918769896030426, acc: 0.8799999952316284)
[2024-12-17 01:38:38,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:38,767][root][INFO] - Training Epoch: 1/2, step 802/7134 completed (loss: 0.46778419613838196, acc: 0.8711755275726318)
[2024-12-17 01:38:38,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:39,058][root][INFO] - Training Epoch: 1/2, step 803/7134 completed (loss: 0.3770352005958557, acc: 0.8946428298950195)
[2024-12-17 01:38:39,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:39,389][root][INFO] - Training Epoch: 1/2, step 804/7134 completed (loss: 0.7513275742530823, acc: 0.8146639466285706)
[2024-12-17 01:38:39,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:39,717][root][INFO] - Training Epoch: 1/2, step 805/7134 completed (loss: 0.6965968012809753, acc: 0.8408239483833313)
[2024-12-17 01:38:39,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:40,100][root][INFO] - Training Epoch: 1/2, step 806/7134 completed (loss: 0.4349276125431061, acc: 0.8868715167045593)
[2024-12-17 01:38:40,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:40,486][root][INFO] - Training Epoch: 1/2, step 807/7134 completed (loss: 0.5341405272483826, acc: 0.8625304102897644)
[2024-12-17 01:38:40,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:40,828][root][INFO] - Training Epoch: 1/2, step 808/7134 completed (loss: 0.4276767075061798, acc: 0.8922155499458313)
[2024-12-17 01:38:40,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:41,165][root][INFO] - Training Epoch: 1/2, step 809/7134 completed (loss: 0.45718592405319214, acc: 0.8855869174003601)
[2024-12-17 01:38:41,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:41,489][root][INFO] - Training Epoch: 1/2, step 810/7134 completed (loss: 0.45191314816474915, acc: 0.8690958023071289)
[2024-12-17 01:38:41,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:41,845][root][INFO] - Training Epoch: 1/2, step 811/7134 completed (loss: 0.6733667850494385, acc: 0.8330404162406921)
[2024-12-17 01:38:41,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:42,187][root][INFO] - Training Epoch: 1/2, step 812/7134 completed (loss: 0.5839084982872009, acc: 0.8663303852081299)
[2024-12-17 01:38:42,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:42,529][root][INFO] - Training Epoch: 1/2, step 813/7134 completed (loss: 0.3934479057788849, acc: 0.9042090177536011)
[2024-12-17 01:38:42,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:42,897][root][INFO] - Training Epoch: 1/2, step 814/7134 completed (loss: 0.4619942605495453, acc: 0.8774193525314331)
[2024-12-17 01:38:42,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:43,247][root][INFO] - Training Epoch: 1/2, step 815/7134 completed (loss: 0.36060813069343567, acc: 0.9134466648101807)
[2024-12-17 01:38:43,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:43,593][root][INFO] - Training Epoch: 1/2, step 816/7134 completed (loss: 0.46317675709724426, acc: 0.8898305296897888)
[2024-12-17 01:38:43,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:43,929][root][INFO] - Training Epoch: 1/2, step 817/7134 completed (loss: 0.39821892976760864, acc: 0.9085923433303833)
[2024-12-17 01:38:44,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:44,287][root][INFO] - Training Epoch: 1/2, step 818/7134 completed (loss: 0.6564172506332397, acc: 0.8350515365600586)
[2024-12-17 01:38:44,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:44,609][root][INFO] - Training Epoch: 1/2, step 819/7134 completed (loss: 0.4016990065574646, acc: 0.902400016784668)
[2024-12-17 01:38:44,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:44,980][root][INFO] - Training Epoch: 1/2, step 820/7134 completed (loss: 0.46855905652046204, acc: 0.8732612133026123)
[2024-12-17 01:38:45,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:45,361][root][INFO] - Training Epoch: 1/2, step 821/7134 completed (loss: 0.48562106490135193, acc: 0.8833780288696289)
[2024-12-17 01:38:45,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:45,677][root][INFO] - Training Epoch: 1/2, step 822/7134 completed (loss: 0.3932993710041046, acc: 0.8963893055915833)
[2024-12-17 01:38:45,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:46,014][root][INFO] - Training Epoch: 1/2, step 823/7134 completed (loss: 0.31486377120018005, acc: 0.9118198752403259)
[2024-12-17 01:38:46,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:46,346][root][INFO] - Training Epoch: 1/2, step 824/7134 completed (loss: 0.469269335269928, acc: 0.8745583295822144)
[2024-12-17 01:38:46,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:46,745][root][INFO] - Training Epoch: 1/2, step 825/7134 completed (loss: 0.449019193649292, acc: 0.8827404379844666)
[2024-12-17 01:38:46,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:47,123][root][INFO] - Training Epoch: 1/2, step 826/7134 completed (loss: 0.4410936236381531, acc: 0.888283371925354)
[2024-12-17 01:38:47,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:47,459][root][INFO] - Training Epoch: 1/2, step 827/7134 completed (loss: 0.40089112520217896, acc: 0.9028871655464172)
[2024-12-17 01:38:47,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:47,772][root][INFO] - Training Epoch: 1/2, step 828/7134 completed (loss: 0.40681952238082886, acc: 0.9020217657089233)
[2024-12-17 01:38:47,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:48,097][root][INFO] - Training Epoch: 1/2, step 829/7134 completed (loss: 0.47577279806137085, acc: 0.8713592290878296)
[2024-12-17 01:38:48,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:48,461][root][INFO] - Training Epoch: 1/2, step 830/7134 completed (loss: 0.48966073989868164, acc: 0.8787375688552856)
[2024-12-17 01:38:48,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:48,813][root][INFO] - Training Epoch: 1/2, step 831/7134 completed (loss: 0.2993207275867462, acc: 0.9205479621887207)
[2024-12-17 01:38:48,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:49,144][root][INFO] - Training Epoch: 1/2, step 832/7134 completed (loss: 0.46657106280326843, acc: 0.8890784978866577)
[2024-12-17 01:38:49,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:49,502][root][INFO] - Training Epoch: 1/2, step 833/7134 completed (loss: 0.4106143116950989, acc: 0.9033613204956055)
[2024-12-17 01:38:49,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:49,845][root][INFO] - Training Epoch: 1/2, step 834/7134 completed (loss: 0.2841683626174927, acc: 0.9188811182975769)
[2024-12-17 01:38:49,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:50,190][root][INFO] - Training Epoch: 1/2, step 835/7134 completed (loss: 0.3997989594936371, acc: 0.892307698726654)
[2024-12-17 01:38:50,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:50,574][root][INFO] - Training Epoch: 1/2, step 836/7134 completed (loss: 0.47213947772979736, acc: 0.8886311054229736)
[2024-12-17 01:38:50,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:50,925][root][INFO] - Training Epoch: 1/2, step 837/7134 completed (loss: 0.2946363091468811, acc: 0.9250681400299072)
[2024-12-17 01:38:51,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:51,264][root][INFO] - Training Epoch: 1/2, step 838/7134 completed (loss: 0.28155040740966797, acc: 0.9125596284866333)
[2024-12-17 01:38:51,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:51,620][root][INFO] - Training Epoch: 1/2, step 839/7134 completed (loss: 0.3693696856498718, acc: 0.9114832282066345)
[2024-12-17 01:38:51,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:51,945][root][INFO] - Training Epoch: 1/2, step 840/7134 completed (loss: 0.3249383270740509, acc: 0.909344494342804)
[2024-12-17 01:38:52,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:52,286][root][INFO] - Training Epoch: 1/2, step 841/7134 completed (loss: 0.4717687964439392, acc: 0.885200560092926)
[2024-12-17 01:38:52,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:52,657][root][INFO] - Training Epoch: 1/2, step 842/7134 completed (loss: 0.3647785782814026, acc: 0.9123989343643188)
[2024-12-17 01:38:52,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:53,006][root][INFO] - Training Epoch: 1/2, step 843/7134 completed (loss: 0.37050092220306396, acc: 0.8956884741783142)
[2024-12-17 01:38:53,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:53,329][root][INFO] - Training Epoch: 1/2, step 844/7134 completed (loss: 0.28474923968315125, acc: 0.9210110306739807)
[2024-12-17 01:38:53,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:53,653][root][INFO] - Training Epoch: 1/2, step 845/7134 completed (loss: 0.39499467611312866, acc: 0.9026548862457275)
[2024-12-17 01:38:53,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:53,999][root][INFO] - Training Epoch: 1/2, step 846/7134 completed (loss: 0.5300433039665222, acc: 0.8560830950737)
[2024-12-17 01:38:54,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:54,335][root][INFO] - Training Epoch: 1/2, step 847/7134 completed (loss: 0.4433281421661377, acc: 0.8860435485839844)
[2024-12-17 01:38:54,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:54,665][root][INFO] - Training Epoch: 1/2, step 848/7134 completed (loss: 0.4658050835132599, acc: 0.8838071823120117)
[2024-12-17 01:38:54,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:55,031][root][INFO] - Training Epoch: 1/2, step 849/7134 completed (loss: 0.384509414434433, acc: 0.8984280824661255)
[2024-12-17 01:38:55,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:55,388][root][INFO] - Training Epoch: 1/2, step 850/7134 completed (loss: 0.4609734117984772, acc: 0.8711409568786621)
[2024-12-17 01:38:55,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:55,762][root][INFO] - Training Epoch: 1/2, step 851/7134 completed (loss: 0.47318142652511597, acc: 0.8817345499992371)
[2024-12-17 01:38:55,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:56,114][root][INFO] - Training Epoch: 1/2, step 852/7134 completed (loss: 0.4174688756465912, acc: 0.891330897808075)
[2024-12-17 01:38:56,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:56,479][root][INFO] - Training Epoch: 1/2, step 853/7134 completed (loss: 0.4526340067386627, acc: 0.8799559473991394)
[2024-12-17 01:38:56,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:56,811][root][INFO] - Training Epoch: 1/2, step 854/7134 completed (loss: 0.4491170346736908, acc: 0.8905472755432129)
[2024-12-17 01:38:56,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:57,178][root][INFO] - Training Epoch: 1/2, step 855/7134 completed (loss: 0.39411208033561707, acc: 0.9004684090614319)
[2024-12-17 01:38:57,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:57,521][root][INFO] - Training Epoch: 1/2, step 856/7134 completed (loss: 0.40287429094314575, acc: 0.8849878907203674)
[2024-12-17 01:38:57,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:57,854][root][INFO] - Training Epoch: 1/2, step 857/7134 completed (loss: 0.4092352092266083, acc: 0.91629958152771)
[2024-12-17 01:38:57,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:58,196][root][INFO] - Training Epoch: 1/2, step 858/7134 completed (loss: 0.47451239824295044, acc: 0.8868159055709839)
[2024-12-17 01:38:58,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:58,548][root][INFO] - Training Epoch: 1/2, step 859/7134 completed (loss: 0.5238586068153381, acc: 0.849526047706604)
[2024-12-17 01:38:58,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:58,894][root][INFO] - Training Epoch: 1/2, step 860/7134 completed (loss: 0.41259193420410156, acc: 0.8723134994506836)
[2024-12-17 01:38:59,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:59,300][root][INFO] - Training Epoch: 1/2, step 861/7134 completed (loss: 0.4988342523574829, acc: 0.8775731325149536)
[2024-12-17 01:38:59,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:59,634][root][INFO] - Training Epoch: 1/2, step 862/7134 completed (loss: 0.4413275420665741, acc: 0.8868832588195801)
[2024-12-17 01:38:59,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:59,987][root][INFO] - Training Epoch: 1/2, step 863/7134 completed (loss: 0.4349149465560913, acc: 0.8894062638282776)
[2024-12-17 01:39:00,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:00,329][root][INFO] - Training Epoch: 1/2, step 864/7134 completed (loss: 0.5127751231193542, acc: 0.8778761029243469)
[2024-12-17 01:39:00,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:00,681][root][INFO] - Training Epoch: 1/2, step 865/7134 completed (loss: 0.4457361698150635, acc: 0.8990267515182495)
[2024-12-17 01:39:00,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:01,032][root][INFO] - Training Epoch: 1/2, step 866/7134 completed (loss: 0.48255959153175354, acc: 0.8785185217857361)
[2024-12-17 01:39:01,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:01,373][root][INFO] - Training Epoch: 1/2, step 867/7134 completed (loss: 0.44310450553894043, acc: 0.9036295413970947)
[2024-12-17 01:39:01,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:01,728][root][INFO] - Training Epoch: 1/2, step 868/7134 completed (loss: 0.5153704881668091, acc: 0.8795811533927917)
[2024-12-17 01:39:01,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:01,999][root][INFO] - Training Epoch: 1/2, step 869/7134 completed (loss: 0.4890277683734894, acc: 0.8566879034042358)
[2024-12-17 01:39:02,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:02,337][root][INFO] - Training Epoch: 1/2, step 870/7134 completed (loss: 0.388468861579895, acc: 0.9070081114768982)
[2024-12-17 01:39:02,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:02,661][root][INFO] - Training Epoch: 1/2, step 871/7134 completed (loss: 0.4529258906841278, acc: 0.8827361464500427)
[2024-12-17 01:39:02,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:02,988][root][INFO] - Training Epoch: 1/2, step 872/7134 completed (loss: 0.3686894476413727, acc: 0.9120879173278809)
[2024-12-17 01:39:03,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:03,331][root][INFO] - Training Epoch: 1/2, step 873/7134 completed (loss: 0.41706743836402893, acc: 0.8957746624946594)
[2024-12-17 01:39:03,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:03,683][root][INFO] - Training Epoch: 1/2, step 874/7134 completed (loss: 0.4117310345172882, acc: 0.9106317162513733)
[2024-12-17 01:39:03,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:04,018][root][INFO] - Training Epoch: 1/2, step 875/7134 completed (loss: 0.4349633753299713, acc: 0.8975110054016113)
[2024-12-17 01:39:04,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:04,386][root][INFO] - Training Epoch: 1/2, step 876/7134 completed (loss: 0.3902144432067871, acc: 0.9049707651138306)
[2024-12-17 01:39:04,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:04,738][root][INFO] - Training Epoch: 1/2, step 877/7134 completed (loss: 0.5210312008857727, acc: 0.870198667049408)
[2024-12-17 01:39:04,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:05,072][root][INFO] - Training Epoch: 1/2, step 878/7134 completed (loss: 0.3695061504840851, acc: 0.9164456129074097)
[2024-12-17 01:39:05,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:05,405][root][INFO] - Training Epoch: 1/2, step 879/7134 completed (loss: 0.3545205295085907, acc: 0.9184861779212952)
[2024-12-17 01:39:05,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:05,765][root][INFO] - Training Epoch: 1/2, step 880/7134 completed (loss: 0.2647635340690613, acc: 0.9301310181617737)
[2024-12-17 01:39:05,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:06,080][root][INFO] - Training Epoch: 1/2, step 881/7134 completed (loss: 0.38827773928642273, acc: 0.8957915902137756)
[2024-12-17 01:39:06,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:06,410][root][INFO] - Training Epoch: 1/2, step 882/7134 completed (loss: 0.37276411056518555, acc: 0.9100719690322876)
[2024-12-17 01:39:06,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:06,758][root][INFO] - Training Epoch: 1/2, step 883/7134 completed (loss: 0.47277623414993286, acc: 0.8868501782417297)
[2024-12-17 01:39:06,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:07,084][root][INFO] - Training Epoch: 1/2, step 884/7134 completed (loss: 0.4387419819831848, acc: 0.8914209008216858)
[2024-12-17 01:39:07,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:07,429][root][INFO] - Training Epoch: 1/2, step 885/7134 completed (loss: 0.3916226029396057, acc: 0.9044944047927856)
[2024-12-17 01:39:07,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:07,775][root][INFO] - Training Epoch: 1/2, step 886/7134 completed (loss: 0.48133575916290283, acc: 0.8791422843933105)
[2024-12-17 01:39:07,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:08,104][root][INFO] - Training Epoch: 1/2, step 887/7134 completed (loss: 0.3602573573589325, acc: 0.9079645872116089)
[2024-12-17 01:39:08,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:08,441][root][INFO] - Training Epoch: 1/2, step 888/7134 completed (loss: 0.42734017968177795, acc: 0.9013656973838806)
[2024-12-17 01:39:08,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:08,775][root][INFO] - Training Epoch: 1/2, step 889/7134 completed (loss: 0.34785839915275574, acc: 0.9133333563804626)
[2024-12-17 01:39:08,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:09,098][root][INFO] - Training Epoch: 1/2, step 890/7134 completed (loss: 0.2829173803329468, acc: 0.9439728260040283)
[2024-12-17 01:39:09,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:09,445][root][INFO] - Training Epoch: 1/2, step 891/7134 completed (loss: 0.3792387545108795, acc: 0.9095966815948486)
[2024-12-17 01:39:09,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:09,827][root][INFO] - Training Epoch: 1/2, step 892/7134 completed (loss: 0.31175097823143005, acc: 0.930232584476471)
[2024-12-17 01:39:09,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:10,137][root][INFO] - Training Epoch: 1/2, step 893/7134 completed (loss: 0.26640817523002625, acc: 0.9380804896354675)
[2024-12-17 01:39:10,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:10,482][root][INFO] - Training Epoch: 1/2, step 894/7134 completed (loss: 0.3659351170063019, acc: 0.910614550113678)
[2024-12-17 01:39:10,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:10,813][root][INFO] - Training Epoch: 1/2, step 895/7134 completed (loss: 0.22554439306259155, acc: 0.9418803453445435)
[2024-12-17 01:39:10,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:11,123][root][INFO] - Training Epoch: 1/2, step 896/7134 completed (loss: 0.4215337634086609, acc: 0.9039999842643738)
[2024-12-17 01:39:11,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:11,499][root][INFO] - Training Epoch: 1/2, step 897/7134 completed (loss: 0.3492433428764343, acc: 0.9011142253875732)
[2024-12-17 01:39:11,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:11,860][root][INFO] - Training Epoch: 1/2, step 898/7134 completed (loss: 0.2956661283969879, acc: 0.9041095972061157)
[2024-12-17 01:39:11,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:12,201][root][INFO] - Training Epoch: 1/2, step 899/7134 completed (loss: 0.32854872941970825, acc: 0.9017412662506104)
[2024-12-17 01:39:12,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:12,524][root][INFO] - Training Epoch: 1/2, step 900/7134 completed (loss: 0.2637038826942444, acc: 0.9282700419425964)
[2024-12-17 01:39:12,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:12,902][root][INFO] - Training Epoch: 1/2, step 901/7134 completed (loss: 0.2692422568798065, acc: 0.9333333373069763)
[2024-12-17 01:39:13,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:13,235][root][INFO] - Training Epoch: 1/2, step 902/7134 completed (loss: 0.2717292904853821, acc: 0.9239598512649536)
[2024-12-17 01:39:13,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:13,584][root][INFO] - Training Epoch: 1/2, step 903/7134 completed (loss: 0.20732203125953674, acc: 0.9498018622398376)
[2024-12-17 01:39:13,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:13,941][root][INFO] - Training Epoch: 1/2, step 904/7134 completed (loss: 0.25942903757095337, acc: 0.9296875)
[2024-12-17 01:39:14,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:14,293][root][INFO] - Training Epoch: 1/2, step 905/7134 completed (loss: 0.18138453364372253, acc: 0.9487870335578918)
[2024-12-17 01:39:14,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:14,632][root][INFO] - Training Epoch: 1/2, step 906/7134 completed (loss: 0.294531911611557, acc: 0.9249329566955566)
[2024-12-17 01:39:14,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:14,977][root][INFO] - Training Epoch: 1/2, step 907/7134 completed (loss: 0.2560785114765167, acc: 0.9355263113975525)
[2024-12-17 01:39:15,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:15,318][root][INFO] - Training Epoch: 1/2, step 908/7134 completed (loss: 0.22095927596092224, acc: 0.9349805116653442)
[2024-12-17 01:39:15,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:15,634][root][INFO] - Training Epoch: 1/2, step 909/7134 completed (loss: 0.28413864970207214, acc: 0.9189189076423645)
[2024-12-17 01:39:15,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:15,994][root][INFO] - Training Epoch: 1/2, step 910/7134 completed (loss: 0.25432485342025757, acc: 0.9319092035293579)
[2024-12-17 01:39:16,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:16,337][root][INFO] - Training Epoch: 1/2, step 911/7134 completed (loss: 0.249385803937912, acc: 0.9300699234008789)
[2024-12-17 01:39:16,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:16,691][root][INFO] - Training Epoch: 1/2, step 912/7134 completed (loss: 0.23636218905448914, acc: 0.9482976198196411)
[2024-12-17 01:39:16,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:17,050][root][INFO] - Training Epoch: 1/2, step 913/7134 completed (loss: 0.2241557389497757, acc: 0.94597989320755)
[2024-12-17 01:39:17,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:17,387][root][INFO] - Training Epoch: 1/2, step 914/7134 completed (loss: 0.22790400683879852, acc: 0.9323979616165161)
[2024-12-17 01:39:17,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:17,737][root][INFO] - Training Epoch: 1/2, step 915/7134 completed (loss: 0.274962842464447, acc: 0.9288026094436646)
[2024-12-17 01:39:17,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:18,067][root][INFO] - Training Epoch: 1/2, step 916/7134 completed (loss: 0.2542130649089813, acc: 0.9319371581077576)
[2024-12-17 01:39:18,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:18,393][root][INFO] - Training Epoch: 1/2, step 917/7134 completed (loss: 0.21707220375537872, acc: 0.9457013607025146)
[2024-12-17 01:39:18,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:18,731][root][INFO] - Training Epoch: 1/2, step 918/7134 completed (loss: 0.15366794168949127, acc: 0.9663093686103821)
[2024-12-17 01:39:18,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:19,040][root][INFO] - Training Epoch: 1/2, step 919/7134 completed (loss: 0.19632290303707123, acc: 0.9466089606285095)
[2024-12-17 01:39:19,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:19,356][root][INFO] - Training Epoch: 1/2, step 920/7134 completed (loss: 0.21196357905864716, acc: 0.9425770044326782)
[2024-12-17 01:39:19,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:19,692][root][INFO] - Training Epoch: 1/2, step 921/7134 completed (loss: 0.19994062185287476, acc: 0.9376693964004517)
[2024-12-17 01:39:19,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:20,008][root][INFO] - Training Epoch: 1/2, step 922/7134 completed (loss: 0.28993475437164307, acc: 0.9213114976882935)
[2024-12-17 01:39:20,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:20,335][root][INFO] - Training Epoch: 1/2, step 923/7134 completed (loss: 0.28125500679016113, acc: 0.9259259104728699)
[2024-12-17 01:39:20,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:20,744][root][INFO] - Training Epoch: 1/2, step 924/7134 completed (loss: 0.22696590423583984, acc: 0.9311594367027283)
[2024-12-17 01:39:20,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:21,108][root][INFO] - Training Epoch: 1/2, step 925/7134 completed (loss: 0.3743232190608978, acc: 0.907489001750946)
[2024-12-17 01:39:21,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:21,466][root][INFO] - Training Epoch: 1/2, step 926/7134 completed (loss: 0.2672257125377655, acc: 0.9313358068466187)
[2024-12-17 01:39:21,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:21,812][root][INFO] - Training Epoch: 1/2, step 927/7134 completed (loss: 0.226094588637352, acc: 0.9477124214172363)
[2024-12-17 01:39:21,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:22,161][root][INFO] - Training Epoch: 1/2, step 928/7134 completed (loss: 0.32479262351989746, acc: 0.9230769276618958)
[2024-12-17 01:39:22,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:22,505][root][INFO] - Training Epoch: 1/2, step 929/7134 completed (loss: 0.20808176696300507, acc: 0.9462875127792358)
[2024-12-17 01:39:22,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:22,771][root][INFO] - Training Epoch: 1/2, step 930/7134 completed (loss: 0.19312602281570435, acc: 0.9455645084381104)
[2024-12-17 01:39:22,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:23,108][root][INFO] - Training Epoch: 1/2, step 931/7134 completed (loss: 0.25145140290260315, acc: 0.9453262686729431)
[2024-12-17 01:39:23,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:23,435][root][INFO] - Training Epoch: 1/2, step 932/7134 completed (loss: 0.23558558523654938, acc: 0.9297994375228882)
[2024-12-17 01:39:23,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:23,759][root][INFO] - Training Epoch: 1/2, step 933/7134 completed (loss: 0.28383132815361023, acc: 0.9407616257667542)
[2024-12-17 01:39:23,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:24,098][root][INFO] - Training Epoch: 1/2, step 934/7134 completed (loss: 0.212953120470047, acc: 0.9437173008918762)
[2024-12-17 01:39:24,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:24,421][root][INFO] - Training Epoch: 1/2, step 935/7134 completed (loss: 0.1852221041917801, acc: 0.9465776085853577)
[2024-12-17 01:39:24,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:24,751][root][INFO] - Training Epoch: 1/2, step 936/7134 completed (loss: 0.2843133807182312, acc: 0.9314587116241455)
[2024-12-17 01:39:24,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:25,089][root][INFO] - Training Epoch: 1/2, step 937/7134 completed (loss: 0.24412405490875244, acc: 0.9348591566085815)
[2024-12-17 01:39:25,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:25,466][root][INFO] - Training Epoch: 1/2, step 938/7134 completed (loss: 0.20772685110569, acc: 0.9498567581176758)
[2024-12-17 01:39:25,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:25,777][root][INFO] - Training Epoch: 1/2, step 939/7134 completed (loss: 0.2923884391784668, acc: 0.9299065470695496)
[2024-12-17 01:39:25,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:26,133][root][INFO] - Training Epoch: 1/2, step 940/7134 completed (loss: 0.2679765224456787, acc: 0.9284692406654358)
[2024-12-17 01:39:26,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:26,493][root][INFO] - Training Epoch: 1/2, step 941/7134 completed (loss: 0.23045973479747772, acc: 0.935172438621521)
[2024-12-17 01:39:26,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:26,830][root][INFO] - Training Epoch: 1/2, step 942/7134 completed (loss: 0.23286469280719757, acc: 0.9433962106704712)
[2024-12-17 01:39:26,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:27,161][root][INFO] - Training Epoch: 1/2, step 943/7134 completed (loss: 0.2194191962480545, acc: 0.9452054500579834)
[2024-12-17 01:39:27,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:27,476][root][INFO] - Training Epoch: 1/2, step 944/7134 completed (loss: 0.20592422783374786, acc: 0.9445277452468872)
[2024-12-17 01:39:27,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:27,800][root][INFO] - Training Epoch: 1/2, step 945/7134 completed (loss: 0.2695237100124359, acc: 0.9370629191398621)
[2024-12-17 01:39:27,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:28,138][root][INFO] - Training Epoch: 1/2, step 946/7134 completed (loss: 0.1440722942352295, acc: 0.9614561200141907)
[2024-12-17 01:39:28,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:28,483][root][INFO] - Training Epoch: 1/2, step 947/7134 completed (loss: 0.24819952249526978, acc: 0.9397590160369873)
[2024-12-17 01:39:28,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:28,888][root][INFO] - Training Epoch: 1/2, step 948/7134 completed (loss: 0.1991891711950302, acc: 0.9471487998962402)
[2024-12-17 01:39:29,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:29,283][root][INFO] - Training Epoch: 1/2, step 949/7134 completed (loss: 0.23507700860500336, acc: 0.946704089641571)
[2024-12-17 01:39:29,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:29,623][root][INFO] - Training Epoch: 1/2, step 950/7134 completed (loss: 0.28356480598449707, acc: 0.9259259104728699)
[2024-12-17 01:39:29,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:29,973][root][INFO] - Training Epoch: 1/2, step 951/7134 completed (loss: 0.31697121262550354, acc: 0.922535240650177)
[2024-12-17 01:39:30,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:30,314][root][INFO] - Training Epoch: 1/2, step 952/7134 completed (loss: 0.32024112343788147, acc: 0.921796977519989)
[2024-12-17 01:39:30,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:30,673][root][INFO] - Training Epoch: 1/2, step 953/7134 completed (loss: 0.3906492292881012, acc: 0.9104294180870056)
[2024-12-17 01:39:30,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:31,023][root][INFO] - Training Epoch: 1/2, step 954/7134 completed (loss: 0.31558889150619507, acc: 0.91629958152771)
[2024-12-17 01:39:31,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:31,381][root][INFO] - Training Epoch: 1/2, step 955/7134 completed (loss: 0.2665978670120239, acc: 0.9317269325256348)
[2024-12-17 01:39:31,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:31,714][root][INFO] - Training Epoch: 1/2, step 956/7134 completed (loss: 0.2529989778995514, acc: 0.9268292784690857)
[2024-12-17 01:39:31,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:32,062][root][INFO] - Training Epoch: 1/2, step 957/7134 completed (loss: 0.2981489598751068, acc: 0.916951060295105)
[2024-12-17 01:39:32,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:32,381][root][INFO] - Training Epoch: 1/2, step 958/7134 completed (loss: 0.3621690273284912, acc: 0.9099264740943909)
[2024-12-17 01:39:32,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:32,709][root][INFO] - Training Epoch: 1/2, step 959/7134 completed (loss: 0.41026291251182556, acc: 0.8957219123840332)
[2024-12-17 01:39:32,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:33,033][root][INFO] - Training Epoch: 1/2, step 960/7134 completed (loss: 0.48210638761520386, acc: 0.8809073567390442)
[2024-12-17 01:39:33,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:33,363][root][INFO] - Training Epoch: 1/2, step 961/7134 completed (loss: 0.4146747291088104, acc: 0.8975741267204285)
[2024-12-17 01:39:33,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:33,706][root][INFO] - Training Epoch: 1/2, step 962/7134 completed (loss: 0.47406309843063354, acc: 0.8896551728248596)
[2024-12-17 01:39:33,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:34,055][root][INFO] - Training Epoch: 1/2, step 963/7134 completed (loss: 0.3747923672199249, acc: 0.9100610017776489)
[2024-12-17 01:39:34,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:34,389][root][INFO] - Training Epoch: 1/2, step 964/7134 completed (loss: 0.4597858786582947, acc: 0.8770614862442017)
[2024-12-17 01:39:34,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:34,727][root][INFO] - Training Epoch: 1/2, step 965/7134 completed (loss: 0.40125203132629395, acc: 0.8981348872184753)
[2024-12-17 01:39:34,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:35,041][root][INFO] - Training Epoch: 1/2, step 966/7134 completed (loss: 0.2946983873844147, acc: 0.9180327653884888)
[2024-12-17 01:39:35,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:35,389][root][INFO] - Training Epoch: 1/2, step 967/7134 completed (loss: 0.3494563400745392, acc: 0.9140518307685852)
[2024-12-17 01:39:35,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:35,717][root][INFO] - Training Epoch: 1/2, step 968/7134 completed (loss: 0.42072051763534546, acc: 0.890656054019928)
[2024-12-17 01:39:35,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:36,025][root][INFO] - Training Epoch: 1/2, step 969/7134 completed (loss: 0.347332239151001, acc: 0.9079939723014832)
[2024-12-17 01:39:36,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:36,349][root][INFO] - Training Epoch: 1/2, step 970/7134 completed (loss: 0.4597562253475189, acc: 0.8797709941864014)
[2024-12-17 01:39:36,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:36,693][root][INFO] - Training Epoch: 1/2, step 971/7134 completed (loss: 0.46281298995018005, acc: 0.8895705342292786)
[2024-12-17 01:39:36,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:37,054][root][INFO] - Training Epoch: 1/2, step 972/7134 completed (loss: 0.35537993907928467, acc: 0.9128268957138062)
[2024-12-17 01:39:37,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:37,397][root][INFO] - Training Epoch: 1/2, step 973/7134 completed (loss: 0.38012710213661194, acc: 0.9051281809806824)
[2024-12-17 01:39:37,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:37,767][root][INFO] - Training Epoch: 1/2, step 974/7134 completed (loss: 0.38578134775161743, acc: 0.9156214594841003)
[2024-12-17 01:39:37,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:38,101][root][INFO] - Training Epoch: 1/2, step 975/7134 completed (loss: 0.38647785782814026, acc: 0.9066985845565796)
[2024-12-17 01:39:38,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:38,443][root][INFO] - Training Epoch: 1/2, step 976/7134 completed (loss: 0.3508492708206177, acc: 0.9174454808235168)
[2024-12-17 01:39:38,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:38,798][root][INFO] - Training Epoch: 1/2, step 977/7134 completed (loss: 0.39067405462265015, acc: 0.9058441519737244)
[2024-12-17 01:39:38,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:39,195][root][INFO] - Training Epoch: 1/2, step 978/7134 completed (loss: 0.24315987527370453, acc: 0.9410349130630493)
[2024-12-17 01:39:39,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:39,539][root][INFO] - Training Epoch: 1/2, step 979/7134 completed (loss: 0.33969998359680176, acc: 0.9171122908592224)
[2024-12-17 01:39:39,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:39,873][root][INFO] - Training Epoch: 1/2, step 980/7134 completed (loss: 0.32077476382255554, acc: 0.9150000214576721)
[2024-12-17 01:39:39,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:40,184][root][INFO] - Training Epoch: 1/2, step 981/7134 completed (loss: 0.40629369020462036, acc: 0.8778135180473328)
[2024-12-17 01:39:40,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:40,530][root][INFO] - Training Epoch: 1/2, step 982/7134 completed (loss: 0.24307535588741302, acc: 0.9438202381134033)
[2024-12-17 01:39:40,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:40,859][root][INFO] - Training Epoch: 1/2, step 983/7134 completed (loss: 0.2736113369464874, acc: 0.9246575236320496)
[2024-12-17 01:39:41,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:41,205][root][INFO] - Training Epoch: 1/2, step 984/7134 completed (loss: 0.31109169125556946, acc: 0.9227941036224365)
[2024-12-17 01:39:41,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:41,555][root][INFO] - Training Epoch: 1/2, step 985/7134 completed (loss: 0.22328981757164001, acc: 0.9438775777816772)
[2024-12-17 01:39:41,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:41,887][root][INFO] - Training Epoch: 1/2, step 986/7134 completed (loss: 0.25212177634239197, acc: 0.9334277510643005)
[2024-12-17 01:39:41,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:42,202][root][INFO] - Training Epoch: 1/2, step 987/7134 completed (loss: 0.23910734057426453, acc: 0.9292604327201843)
[2024-12-17 01:39:42,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:42,528][root][INFO] - Training Epoch: 1/2, step 988/7134 completed (loss: 0.3963198959827423, acc: 0.8973647952079773)
[2024-12-17 01:39:42,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:42,859][root][INFO] - Training Epoch: 1/2, step 989/7134 completed (loss: 0.31131893396377563, acc: 0.9193323850631714)
[2024-12-17 01:39:42,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:43,200][root][INFO] - Training Epoch: 1/2, step 990/7134 completed (loss: 0.3207502067089081, acc: 0.9102401733398438)
[2024-12-17 01:39:43,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:43,533][root][INFO] - Training Epoch: 1/2, step 991/7134 completed (loss: 0.32487428188323975, acc: 0.920187771320343)
[2024-12-17 01:39:43,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:43,884][root][INFO] - Training Epoch: 1/2, step 992/7134 completed (loss: 0.33926934003829956, acc: 0.9105263352394104)
[2024-12-17 01:39:43,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:44,210][root][INFO] - Training Epoch: 1/2, step 993/7134 completed (loss: 0.25170284509658813, acc: 0.9328969120979309)
[2024-12-17 01:39:44,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:44,599][root][INFO] - Training Epoch: 1/2, step 994/7134 completed (loss: 0.26632773876190186, acc: 0.9313063025474548)
[2024-12-17 01:39:44,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:44,966][root][INFO] - Training Epoch: 1/2, step 995/7134 completed (loss: 0.34632495045661926, acc: 0.9104938507080078)
[2024-12-17 01:39:45,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:45,291][root][INFO] - Training Epoch: 1/2, step 996/7134 completed (loss: 0.27184271812438965, acc: 0.924580991268158)
[2024-12-17 01:39:45,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:45,622][root][INFO] - Training Epoch: 1/2, step 997/7134 completed (loss: 0.3093087375164032, acc: 0.9312320947647095)
[2024-12-17 01:39:45,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:45,954][root][INFO] - Training Epoch: 1/2, step 998/7134 completed (loss: 0.30757734179496765, acc: 0.9239436388015747)
[2024-12-17 01:39:46,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:46,282][root][INFO] - Training Epoch: 1/2, step 999/7134 completed (loss: 0.29290127754211426, acc: 0.9157705903053284)
[2024-12-17 01:39:46,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:46,608][root][INFO] - Training Epoch: 1/2, step 1000/7134 completed (loss: 0.23773759603500366, acc: 0.9452054500579834)
[2024-12-17 01:39:46,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:46,943][root][INFO] - Training Epoch: 1/2, step 1001/7134 completed (loss: 0.2519102990627289, acc: 0.9333333373069763)
[2024-12-17 01:39:47,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:47,291][root][INFO] - Training Epoch: 1/2, step 1002/7134 completed (loss: 0.2962554693222046, acc: 0.9172610640525818)
[2024-12-17 01:39:47,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:47,630][root][INFO] - Training Epoch: 1/2, step 1003/7134 completed (loss: 0.32186368107795715, acc: 0.9242199063301086)
[2024-12-17 01:39:47,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:47,942][root][INFO] - Training Epoch: 1/2, step 1004/7134 completed (loss: 0.3333097994327545, acc: 0.9195876121520996)
[2024-12-17 01:39:48,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:48,279][root][INFO] - Training Epoch: 1/2, step 1005/7134 completed (loss: 0.3544851541519165, acc: 0.9122516512870789)
[2024-12-17 01:39:48,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:48,601][root][INFO] - Training Epoch: 1/2, step 1006/7134 completed (loss: 0.2720375657081604, acc: 0.9331476092338562)
[2024-12-17 01:39:48,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:48,935][root][INFO] - Training Epoch: 1/2, step 1007/7134 completed (loss: 0.36673665046691895, acc: 0.8995290398597717)
[2024-12-17 01:39:49,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:49,273][root][INFO] - Training Epoch: 1/2, step 1008/7134 completed (loss: 0.29087033867836, acc: 0.9234042763710022)
[2024-12-17 01:39:49,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:49,597][root][INFO] - Training Epoch: 1/2, step 1009/7134 completed (loss: 0.2688668668270111, acc: 0.9342806339263916)
[2024-12-17 01:39:49,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:49,913][root][INFO] - Training Epoch: 1/2, step 1010/7134 completed (loss: 0.22399213910102844, acc: 0.9288537502288818)
[2024-12-17 01:39:50,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:50,245][root][INFO] - Training Epoch: 1/2, step 1011/7134 completed (loss: 0.304477721452713, acc: 0.9183955788612366)
[2024-12-17 01:39:50,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:50,576][root][INFO] - Training Epoch: 1/2, step 1012/7134 completed (loss: 0.26301199197769165, acc: 0.9348441958427429)
[2024-12-17 01:39:50,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:50,909][root][INFO] - Training Epoch: 1/2, step 1013/7134 completed (loss: 0.24258960783481598, acc: 0.9355300664901733)
[2024-12-17 01:39:51,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:51,247][root][INFO] - Training Epoch: 1/2, step 1014/7134 completed (loss: 0.2916284203529358, acc: 0.9277504086494446)
[2024-12-17 01:39:51,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:51,576][root][INFO] - Training Epoch: 1/2, step 1015/7134 completed (loss: 0.24975623190402985, acc: 0.9367470145225525)
[2024-12-17 01:39:51,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:51,903][root][INFO] - Training Epoch: 1/2, step 1016/7134 completed (loss: 0.305668443441391, acc: 0.9369024634361267)
[2024-12-17 01:39:51,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:52,259][root][INFO] - Training Epoch: 1/2, step 1017/7134 completed (loss: 0.23229506611824036, acc: 0.9422819018363953)
[2024-12-17 01:39:52,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:52,592][root][INFO] - Training Epoch: 1/2, step 1018/7134 completed (loss: 0.22510308027267456, acc: 0.9443631172180176)
[2024-12-17 01:39:52,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:52,917][root][INFO] - Training Epoch: 1/2, step 1019/7134 completed (loss: 0.25282880663871765, acc: 0.9342948794364929)
[2024-12-17 01:39:53,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:53,280][root][INFO] - Training Epoch: 1/2, step 1020/7134 completed (loss: 0.38701435923576355, acc: 0.9089552164077759)
[2024-12-17 01:39:53,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:53,616][root][INFO] - Training Epoch: 1/2, step 1021/7134 completed (loss: 0.24516060948371887, acc: 0.9283439517021179)
[2024-12-17 01:39:53,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:53,962][root][INFO] - Training Epoch: 1/2, step 1022/7134 completed (loss: 0.17521414160728455, acc: 0.9512516260147095)
[2024-12-17 01:39:54,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:54,307][root][INFO] - Training Epoch: 1/2, step 1023/7134 completed (loss: 0.23966830968856812, acc: 0.9369369149208069)
[2024-12-17 01:39:54,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:54,649][root][INFO] - Training Epoch: 1/2, step 1024/7134 completed (loss: 0.26212233304977417, acc: 0.9353680610656738)
[2024-12-17 01:39:54,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:54,966][root][INFO] - Training Epoch: 1/2, step 1025/7134 completed (loss: 0.303914874792099, acc: 0.9412811398506165)
[2024-12-17 01:39:55,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:55,293][root][INFO] - Training Epoch: 1/2, step 1026/7134 completed (loss: 0.3010498285293579, acc: 0.9284210801124573)
[2024-12-17 01:39:55,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:55,618][root][INFO] - Training Epoch: 1/2, step 1027/7134 completed (loss: 0.18385936319828033, acc: 0.9648173451423645)
[2024-12-17 01:39:55,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:55,946][root][INFO] - Training Epoch: 1/2, step 1028/7134 completed (loss: 0.1724659949541092, acc: 0.9626308083534241)
[2024-12-17 01:39:56,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:56,296][root][INFO] - Training Epoch: 1/2, step 1029/7134 completed (loss: 0.14205069839954376, acc: 0.9673105478286743)
[2024-12-17 01:39:56,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:56,631][root][INFO] - Training Epoch: 1/2, step 1030/7134 completed (loss: 0.11931732296943665, acc: 0.9649595618247986)
[2024-12-17 01:39:56,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:56,940][root][INFO] - Training Epoch: 1/2, step 1031/7134 completed (loss: 0.21776461601257324, acc: 0.9496951103210449)
[2024-12-17 01:39:57,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:57,290][root][INFO] - Training Epoch: 1/2, step 1032/7134 completed (loss: 0.24743126332759857, acc: 0.9285714030265808)
[2024-12-17 01:39:57,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:57,645][root][INFO] - Training Epoch: 1/2, step 1033/7134 completed (loss: 0.24540095031261444, acc: 0.9282639622688293)
[2024-12-17 01:39:57,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:57,989][root][INFO] - Training Epoch: 1/2, step 1034/7134 completed (loss: 0.23366735875606537, acc: 0.9465153813362122)
[2024-12-17 01:39:58,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:58,263][root][INFO] - Training Epoch: 1/2, step 1035/7134 completed (loss: 0.4551008939743042, acc: 0.8999999761581421)
[2024-12-17 01:39:58,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:58,583][root][INFO] - Training Epoch: 1/2, step 1036/7134 completed (loss: 0.4412771463394165, acc: 0.8955555558204651)
[2024-12-17 01:39:58,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:58,931][root][INFO] - Training Epoch: 1/2, step 1037/7134 completed (loss: 0.17145346105098724, acc: 0.9547619223594666)
[2024-12-17 01:39:59,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:59,280][root][INFO] - Training Epoch: 1/2, step 1038/7134 completed (loss: 0.1973336786031723, acc: 0.9530201554298401)
[2024-12-17 01:39:59,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:59,616][root][INFO] - Training Epoch: 1/2, step 1039/7134 completed (loss: 0.24195633828639984, acc: 0.9358177781105042)
[2024-12-17 01:39:59,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:59,962][root][INFO] - Training Epoch: 1/2, step 1040/7134 completed (loss: 0.18176661431789398, acc: 0.9571917653083801)
[2024-12-17 01:40:00,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:00,290][root][INFO] - Training Epoch: 1/2, step 1041/7134 completed (loss: 0.20066693425178528, acc: 0.9361370801925659)
[2024-12-17 01:40:00,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:00,669][root][INFO] - Training Epoch: 1/2, step 1042/7134 completed (loss: 0.26098284125328064, acc: 0.9269230961799622)
[2024-12-17 01:40:00,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:01,019][root][INFO] - Training Epoch: 1/2, step 1043/7134 completed (loss: 0.23422223329544067, acc: 0.9362214207649231)
[2024-12-17 01:40:01,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:01,366][root][INFO] - Training Epoch: 1/2, step 1044/7134 completed (loss: 0.26958417892456055, acc: 0.9383561611175537)
[2024-12-17 01:40:01,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:01,704][root][INFO] - Training Epoch: 1/2, step 1045/7134 completed (loss: 0.289822518825531, acc: 0.9273021221160889)
[2024-12-17 01:40:01,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:02,026][root][INFO] - Training Epoch: 1/2, step 1046/7134 completed (loss: 0.17773373425006866, acc: 0.9633204340934753)
[2024-12-17 01:40:02,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:02,364][root][INFO] - Training Epoch: 1/2, step 1047/7134 completed (loss: 0.2746727466583252, acc: 0.9407407641410828)
[2024-12-17 01:40:02,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:02,782][root][INFO] - Training Epoch: 1/2, step 1048/7134 completed (loss: 0.1885315328836441, acc: 0.9604105353355408)
[2024-12-17 01:40:02,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:03,115][root][INFO] - Training Epoch: 1/2, step 1049/7134 completed (loss: 0.2391740083694458, acc: 0.9502196311950684)
[2024-12-17 01:40:03,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:03,456][root][INFO] - Training Epoch: 1/2, step 1050/7134 completed (loss: 0.20474639534950256, acc: 0.9521858096122742)
[2024-12-17 01:40:03,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:03,815][root][INFO] - Training Epoch: 1/2, step 1051/7134 completed (loss: 0.2335350513458252, acc: 0.9479451775550842)
[2024-12-17 01:40:03,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:04,137][root][INFO] - Training Epoch: 1/2, step 1052/7134 completed (loss: 0.24297979474067688, acc: 0.9369951486587524)
[2024-12-17 01:40:04,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:04,461][root][INFO] - Training Epoch: 1/2, step 1053/7134 completed (loss: 0.14852558076381683, acc: 0.9690141081809998)
[2024-12-17 01:40:04,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:04,798][root][INFO] - Training Epoch: 1/2, step 1054/7134 completed (loss: 0.21002252399921417, acc: 0.9470198750495911)
[2024-12-17 01:40:04,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:05,119][root][INFO] - Training Epoch: 1/2, step 1055/7134 completed (loss: 0.32879990339279175, acc: 0.9246119856834412)
[2024-12-17 01:40:05,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:05,448][root][INFO] - Training Epoch: 1/2, step 1056/7134 completed (loss: 0.3464083671569824, acc: 0.9179229736328125)
[2024-12-17 01:40:05,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:05,781][root][INFO] - Training Epoch: 1/2, step 1057/7134 completed (loss: 0.4913172721862793, acc: 0.8930636048316956)
[2024-12-17 01:40:05,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:06,149][root][INFO] - Training Epoch: 1/2, step 1058/7134 completed (loss: 0.38057348132133484, acc: 0.904347836971283)
[2024-12-17 01:40:06,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:06,541][root][INFO] - Training Epoch: 1/2, step 1059/7134 completed (loss: 0.29357603192329407, acc: 0.9238709807395935)
[2024-12-17 01:40:06,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:06,871][root][INFO] - Training Epoch: 1/2, step 1060/7134 completed (loss: 0.2866339087486267, acc: 0.9369085431098938)
[2024-12-17 01:40:07,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:07,269][root][INFO] - Training Epoch: 1/2, step 1061/7134 completed (loss: 0.3521355390548706, acc: 0.9156976938247681)
[2024-12-17 01:40:07,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:07,595][root][INFO] - Training Epoch: 1/2, step 1062/7134 completed (loss: 0.3351016938686371, acc: 0.9271186590194702)
[2024-12-17 01:40:07,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:07,928][root][INFO] - Training Epoch: 1/2, step 1063/7134 completed (loss: 0.21246221661567688, acc: 0.9513776302337646)
[2024-12-17 01:40:08,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:08,286][root][INFO] - Training Epoch: 1/2, step 1064/7134 completed (loss: 0.20173640549182892, acc: 0.9537037014961243)
[2024-12-17 01:40:08,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:08,630][root][INFO] - Training Epoch: 1/2, step 1065/7134 completed (loss: 0.15833811461925507, acc: 0.9539295434951782)
[2024-12-17 01:40:08,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:08,961][root][INFO] - Training Epoch: 1/2, step 1066/7134 completed (loss: 0.20528188347816467, acc: 0.9395973086357117)
[2024-12-17 01:40:09,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:09,291][root][INFO] - Training Epoch: 1/2, step 1067/7134 completed (loss: 0.2061116248369217, acc: 0.9445300698280334)
[2024-12-17 01:40:09,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:09,636][root][INFO] - Training Epoch: 1/2, step 1068/7134 completed (loss: 0.2140689343214035, acc: 0.9455909729003906)
[2024-12-17 01:40:09,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:09,973][root][INFO] - Training Epoch: 1/2, step 1069/7134 completed (loss: 0.20745763182640076, acc: 0.9465776085853577)
[2024-12-17 01:40:10,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:10,281][root][INFO] - Training Epoch: 1/2, step 1070/7134 completed (loss: 0.21951566636562347, acc: 0.9573070406913757)
[2024-12-17 01:40:10,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:10,654][root][INFO] - Training Epoch: 1/2, step 1071/7134 completed (loss: 0.16509558260440826, acc: 0.9558233022689819)
[2024-12-17 01:40:10,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:10,993][root][INFO] - Training Epoch: 1/2, step 1072/7134 completed (loss: 0.10607703775167465, acc: 0.975642740726471)
[2024-12-17 01:40:11,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:11,322][root][INFO] - Training Epoch: 1/2, step 1073/7134 completed (loss: 0.13402584195137024, acc: 0.9682996869087219)
[2024-12-17 01:40:11,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:11,633][root][INFO] - Training Epoch: 1/2, step 1074/7134 completed (loss: 0.28919824957847595, acc: 0.9412780404090881)
[2024-12-17 01:40:11,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:11,973][root][INFO] - Training Epoch: 1/2, step 1075/7134 completed (loss: 0.48485615849494934, acc: 0.8913443684577942)
[2024-12-17 01:40:12,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:12,313][root][INFO] - Training Epoch: 1/2, step 1076/7134 completed (loss: 0.4331930875778198, acc: 0.8909574747085571)
[2024-12-17 01:40:12,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:12,616][root][INFO] - Training Epoch: 1/2, step 1077/7134 completed (loss: 0.377667099237442, acc: 0.9189189076423645)
[2024-12-17 01:40:12,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:12,962][root][INFO] - Training Epoch: 1/2, step 1078/7134 completed (loss: 0.5004615187644958, acc: 0.8804523348808289)
[2024-12-17 01:40:13,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:13,307][root][INFO] - Training Epoch: 1/2, step 1079/7134 completed (loss: 0.28523939847946167, acc: 0.9204152226448059)
[2024-12-17 01:40:13,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:13,657][root][INFO] - Training Epoch: 1/2, step 1080/7134 completed (loss: 0.40317779779434204, acc: 0.8947368264198303)
[2024-12-17 01:40:13,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:13,997][root][INFO] - Training Epoch: 1/2, step 1081/7134 completed (loss: 0.27956509590148926, acc: 0.9340813755989075)
[2024-12-17 01:40:14,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:14,405][root][INFO] - Training Epoch: 1/2, step 1082/7134 completed (loss: 0.27273309230804443, acc: 0.9249743223190308)
[2024-12-17 01:40:14,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:14,761][root][INFO] - Training Epoch: 1/2, step 1083/7134 completed (loss: 0.2107083797454834, acc: 0.9457626938819885)
[2024-12-17 01:40:14,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:15,125][root][INFO] - Training Epoch: 1/2, step 1084/7134 completed (loss: 0.19946077466011047, acc: 0.9491945505142212)
[2024-12-17 01:40:15,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:15,467][root][INFO] - Training Epoch: 1/2, step 1085/7134 completed (loss: 0.1831926852464676, acc: 0.9504685401916504)
[2024-12-17 01:40:15,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:15,784][root][INFO] - Training Epoch: 1/2, step 1086/7134 completed (loss: 0.2790053188800812, acc: 0.9357277750968933)
[2024-12-17 01:40:15,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:16,137][root][INFO] - Training Epoch: 1/2, step 1087/7134 completed (loss: 0.22750799357891083, acc: 0.9329268336296082)
[2024-12-17 01:40:16,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:16,462][root][INFO] - Training Epoch: 1/2, step 1088/7134 completed (loss: 0.17166827619075775, acc: 0.9539105892181396)
[2024-12-17 01:40:16,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:16,787][root][INFO] - Training Epoch: 1/2, step 1089/7134 completed (loss: 0.1998215913772583, acc: 0.9523099660873413)
[2024-12-17 01:40:16,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:17,133][root][INFO] - Training Epoch: 1/2, step 1090/7134 completed (loss: 0.26239943504333496, acc: 0.923556923866272)
[2024-12-17 01:40:17,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:17,457][root][INFO] - Training Epoch: 1/2, step 1091/7134 completed (loss: 0.16719073057174683, acc: 0.9482496380805969)
[2024-12-17 01:40:17,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:17,805][root][INFO] - Training Epoch: 1/2, step 1092/7134 completed (loss: 0.13558541238307953, acc: 0.9624277353286743)
[2024-12-17 01:40:17,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:18,136][root][INFO] - Training Epoch: 1/2, step 1093/7134 completed (loss: 0.23010633885860443, acc: 0.9498432874679565)
[2024-12-17 01:40:18,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:18,467][root][INFO] - Training Epoch: 1/2, step 1094/7134 completed (loss: 0.24165956676006317, acc: 0.9293680191040039)
[2024-12-17 01:40:18,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:18,856][root][INFO] - Training Epoch: 1/2, step 1095/7134 completed (loss: 0.2584574818611145, acc: 0.9342265725135803)
[2024-12-17 01:40:18,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:19,223][root][INFO] - Training Epoch: 1/2, step 1096/7134 completed (loss: 0.2770557403564453, acc: 0.9341772198677063)
[2024-12-17 01:40:19,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:19,574][root][INFO] - Training Epoch: 1/2, step 1097/7134 completed (loss: 0.30383622646331787, acc: 0.9171348214149475)
[2024-12-17 01:40:19,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:19,921][root][INFO] - Training Epoch: 1/2, step 1098/7134 completed (loss: 0.20134665071964264, acc: 0.9493201375007629)
[2024-12-17 01:40:20,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:20,270][root][INFO] - Training Epoch: 1/2, step 1099/7134 completed (loss: 0.2204313576221466, acc: 0.9410256147384644)
[2024-12-17 01:40:20,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:20,640][root][INFO] - Training Epoch: 1/2, step 1100/7134 completed (loss: 0.22137297689914703, acc: 0.9442934989929199)
[2024-12-17 01:40:20,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:20,991][root][INFO] - Training Epoch: 1/2, step 1101/7134 completed (loss: 0.2237754911184311, acc: 0.9402597546577454)
[2024-12-17 01:40:21,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:21,317][root][INFO] - Training Epoch: 1/2, step 1102/7134 completed (loss: 0.2133013904094696, acc: 0.9393346309661865)
[2024-12-17 01:40:21,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:21,672][root][INFO] - Training Epoch: 1/2, step 1103/7134 completed (loss: 0.29511725902557373, acc: 0.9213333129882812)
[2024-12-17 01:40:21,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:21,992][root][INFO] - Training Epoch: 1/2, step 1104/7134 completed (loss: 0.21893860399723053, acc: 0.9351584911346436)
[2024-12-17 01:40:22,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:22,322][root][INFO] - Training Epoch: 1/2, step 1105/7134 completed (loss: 0.2203863263130188, acc: 0.9487870335578918)
[2024-12-17 01:40:22,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:22,661][root][INFO] - Training Epoch: 1/2, step 1106/7134 completed (loss: 0.24264870584011078, acc: 0.936639130115509)
[2024-12-17 01:40:22,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:23,027][root][INFO] - Training Epoch: 1/2, step 1107/7134 completed (loss: 0.2786566913127899, acc: 0.9226260185241699)
[2024-12-17 01:40:23,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:23,372][root][INFO] - Training Epoch: 1/2, step 1108/7134 completed (loss: 0.19591085612773895, acc: 0.9407216310501099)
[2024-12-17 01:40:23,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:23,738][root][INFO] - Training Epoch: 1/2, step 1109/7134 completed (loss: 0.32868891954421997, acc: 0.9148044586181641)
[2024-12-17 01:40:23,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:24,069][root][INFO] - Training Epoch: 1/2, step 1110/7134 completed (loss: 0.31227073073387146, acc: 0.9200524091720581)
[2024-12-17 01:40:24,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:24,403][root][INFO] - Training Epoch: 1/2, step 1111/7134 completed (loss: 0.21985232830047607, acc: 0.9447513818740845)
[2024-12-17 01:40:24,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:24,745][root][INFO] - Training Epoch: 1/2, step 1112/7134 completed (loss: 0.2599548101425171, acc: 0.9323529601097107)
[2024-12-17 01:40:24,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:25,082][root][INFO] - Training Epoch: 1/2, step 1113/7134 completed (loss: 0.1824054718017578, acc: 0.9446589350700378)
[2024-12-17 01:40:25,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:25,479][root][INFO] - Training Epoch: 1/2, step 1114/7134 completed (loss: 0.23546628654003143, acc: 0.9368165135383606)
[2024-12-17 01:40:25,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:25,815][root][INFO] - Training Epoch: 1/2, step 1115/7134 completed (loss: 0.2790430784225464, acc: 0.9371069073677063)
[2024-12-17 01:40:25,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:26,129][root][INFO] - Training Epoch: 1/2, step 1116/7134 completed (loss: 0.16967131197452545, acc: 0.9533582329750061)
[2024-12-17 01:40:26,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:26,462][root][INFO] - Training Epoch: 1/2, step 1117/7134 completed (loss: 0.20207780599594116, acc: 0.949386477470398)
[2024-12-17 01:40:26,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:26,775][root][INFO] - Training Epoch: 1/2, step 1118/7134 completed (loss: 0.27488863468170166, acc: 0.9396551847457886)
[2024-12-17 01:40:26,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:27,113][root][INFO] - Training Epoch: 1/2, step 1119/7134 completed (loss: 0.268403559923172, acc: 0.9399684071540833)
[2024-12-17 01:40:27,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:27,443][root][INFO] - Training Epoch: 1/2, step 1120/7134 completed (loss: 0.35423070192337036, acc: 0.9072327017784119)
[2024-12-17 01:40:27,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:27,771][root][INFO] - Training Epoch: 1/2, step 1121/7134 completed (loss: 0.26130977272987366, acc: 0.9438700079917908)
[2024-12-17 01:40:27,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:28,077][root][INFO] - Training Epoch: 1/2, step 1122/7134 completed (loss: 0.19145046174526215, acc: 0.9495145678520203)
[2024-12-17 01:40:28,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:28,407][root][INFO] - Training Epoch: 1/2, step 1123/7134 completed (loss: 0.2017151564359665, acc: 0.9406099319458008)
[2024-12-17 01:40:28,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:28,743][root][INFO] - Training Epoch: 1/2, step 1124/7134 completed (loss: 0.19919173419475555, acc: 0.9411764740943909)
[2024-12-17 01:40:28,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:29,077][root][INFO] - Training Epoch: 1/2, step 1125/7134 completed (loss: 0.12562663853168488, acc: 0.9661704897880554)
[2024-12-17 01:40:29,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:29,403][root][INFO] - Training Epoch: 1/2, step 1126/7134 completed (loss: 0.27139371633529663, acc: 0.9323204159736633)
[2024-12-17 01:40:29,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:29,730][root][INFO] - Training Epoch: 1/2, step 1127/7134 completed (loss: 0.15545588731765747, acc: 0.9567999839782715)
[2024-12-17 01:40:29,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:30,055][root][INFO] - Training Epoch: 1/2, step 1128/7134 completed (loss: 0.1457129269838333, acc: 0.9635416865348816)
[2024-12-17 01:40:30,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:30,351][root][INFO] - Training Epoch: 1/2, step 1129/7134 completed (loss: 0.24260638654232025, acc: 0.939461886882782)
[2024-12-17 01:40:30,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:30,692][root][INFO] - Training Epoch: 1/2, step 1130/7134 completed (loss: 0.21522635221481323, acc: 0.9434571862220764)
[2024-12-17 01:40:30,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:31,059][root][INFO] - Training Epoch: 1/2, step 1131/7134 completed (loss: 0.29604876041412354, acc: 0.9257075190544128)
[2024-12-17 01:40:31,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:31,383][root][INFO] - Training Epoch: 1/2, step 1132/7134 completed (loss: 0.2787069082260132, acc: 0.93108731508255)
[2024-12-17 01:40:31,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:31,741][root][INFO] - Training Epoch: 1/2, step 1133/7134 completed (loss: 0.3073969781398773, acc: 0.9258202314376831)
[2024-12-17 01:40:31,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:32,077][root][INFO] - Training Epoch: 1/2, step 1134/7134 completed (loss: 0.22562578320503235, acc: 0.9438902735710144)
[2024-12-17 01:40:32,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:32,424][root][INFO] - Training Epoch: 1/2, step 1135/7134 completed (loss: 0.23825669288635254, acc: 0.9408000111579895)
[2024-12-17 01:40:32,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:32,780][root][INFO] - Training Epoch: 1/2, step 1136/7134 completed (loss: 0.32645487785339355, acc: 0.9251700639724731)
[2024-12-17 01:40:32,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:33,115][root][INFO] - Training Epoch: 1/2, step 1137/7134 completed (loss: 0.2808516323566437, acc: 0.9159091114997864)
[2024-12-17 01:40:33,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:33,478][root][INFO] - Training Epoch: 1/2, step 1138/7134 completed (loss: 0.3192123770713806, acc: 0.9207650423049927)
[2024-12-17 01:40:33,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:33,807][root][INFO] - Training Epoch: 1/2, step 1139/7134 completed (loss: 0.33765217661857605, acc: 0.9139966368675232)
[2024-12-17 01:40:33,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:34,168][root][INFO] - Training Epoch: 1/2, step 1140/7134 completed (loss: 0.2816002368927002, acc: 0.9348371028900146)
[2024-12-17 01:40:34,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:34,496][root][INFO] - Training Epoch: 1/2, step 1141/7134 completed (loss: 0.21777595579624176, acc: 0.9367681741714478)
[2024-12-17 01:40:34,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:34,837][root][INFO] - Training Epoch: 1/2, step 1142/7134 completed (loss: 0.19146256148815155, acc: 0.94921875)
[2024-12-17 01:40:34,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:35,167][root][INFO] - Training Epoch: 1/2, step 1143/7134 completed (loss: 0.27995428442955017, acc: 0.924895703792572)
[2024-12-17 01:40:35,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:35,510][root][INFO] - Training Epoch: 1/2, step 1144/7134 completed (loss: 0.2212335765361786, acc: 0.9437500238418579)
[2024-12-17 01:40:35,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:35,856][root][INFO] - Training Epoch: 1/2, step 1145/7134 completed (loss: 0.14340612292289734, acc: 0.9628297090530396)
[2024-12-17 01:40:35,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:36,169][root][INFO] - Training Epoch: 1/2, step 1146/7134 completed (loss: 0.16590623557567596, acc: 0.9601449370384216)
[2024-12-17 01:40:36,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:36,490][root][INFO] - Training Epoch: 1/2, step 1147/7134 completed (loss: 0.20883893966674805, acc: 0.9438902735710144)
[2024-12-17 01:40:36,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:36,816][root][INFO] - Training Epoch: 1/2, step 1148/7134 completed (loss: 0.20275212824344635, acc: 0.9556313753128052)
[2024-12-17 01:40:36,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:37,130][root][INFO] - Training Epoch: 1/2, step 1149/7134 completed (loss: 0.362326443195343, acc: 0.89670330286026)
[2024-12-17 01:40:37,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:37,479][root][INFO] - Training Epoch: 1/2, step 1150/7134 completed (loss: 0.19201792776584625, acc: 0.9519379734992981)
[2024-12-17 01:40:37,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:37,820][root][INFO] - Training Epoch: 1/2, step 1151/7134 completed (loss: 0.09673157334327698, acc: 0.9756592512130737)
[2024-12-17 01:40:37,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:38,150][root][INFO] - Training Epoch: 1/2, step 1152/7134 completed (loss: 0.12448194622993469, acc: 0.952136754989624)
[2024-12-17 01:40:38,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:38,489][root][INFO] - Training Epoch: 1/2, step 1153/7134 completed (loss: 0.2390461266040802, acc: 0.946866512298584)
[2024-12-17 01:40:38,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:38,826][root][INFO] - Training Epoch: 1/2, step 1154/7134 completed (loss: 0.16841305792331696, acc: 0.9557521939277649)
[2024-12-17 01:40:38,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:39,160][root][INFO] - Training Epoch: 1/2, step 1155/7134 completed (loss: 0.23313573002815247, acc: 0.9342105388641357)
[2024-12-17 01:40:39,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:39,510][root][INFO] - Training Epoch: 1/2, step 1156/7134 completed (loss: 0.14831861853599548, acc: 0.9585253596305847)
[2024-12-17 01:40:39,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:39,832][root][INFO] - Training Epoch: 1/2, step 1157/7134 completed (loss: 0.2566620111465454, acc: 0.930390477180481)
[2024-12-17 01:40:39,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:40,151][root][INFO] - Training Epoch: 1/2, step 1158/7134 completed (loss: 0.265332967042923, acc: 0.9349112510681152)
[2024-12-17 01:40:40,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:40,498][root][INFO] - Training Epoch: 1/2, step 1159/7134 completed (loss: 0.2526519000530243, acc: 0.9319148659706116)
[2024-12-17 01:40:40,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:40,849][root][INFO] - Training Epoch: 1/2, step 1160/7134 completed (loss: 0.20977844297885895, acc: 0.944940447807312)
[2024-12-17 01:40:40,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:41,180][root][INFO] - Training Epoch: 1/2, step 1161/7134 completed (loss: 0.23341424763202667, acc: 0.9477977156639099)
[2024-12-17 01:40:41,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:41,498][root][INFO] - Training Epoch: 1/2, step 1162/7134 completed (loss: 0.16004811227321625, acc: 0.9586777091026306)
[2024-12-17 01:40:41,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:41,812][root][INFO] - Training Epoch: 1/2, step 1163/7134 completed (loss: 0.14668045938014984, acc: 0.9692832827568054)
[2024-12-17 01:40:41,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:42,145][root][INFO] - Training Epoch: 1/2, step 1164/7134 completed (loss: 0.2039862871170044, acc: 0.9485396146774292)
[2024-12-17 01:40:42,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:42,510][root][INFO] - Training Epoch: 1/2, step 1165/7134 completed (loss: 0.11084377020597458, acc: 0.9687923789024353)
[2024-12-17 01:40:42,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:42,839][root][INFO] - Training Epoch: 1/2, step 1166/7134 completed (loss: 0.11524644494056702, acc: 0.9698216915130615)
[2024-12-17 01:40:42,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:43,165][root][INFO] - Training Epoch: 1/2, step 1167/7134 completed (loss: 0.09164559096097946, acc: 0.9626718759536743)
[2024-12-17 01:40:43,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:43,540][root][INFO] - Training Epoch: 1/2, step 1168/7134 completed (loss: 0.15108181536197662, acc: 0.9605262875556946)
[2024-12-17 01:40:43,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:43,883][root][INFO] - Training Epoch: 1/2, step 1169/7134 completed (loss: 0.250448077917099, acc: 0.9351351261138916)
[2024-12-17 01:40:44,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:44,243][root][INFO] - Training Epoch: 1/2, step 1170/7134 completed (loss: 0.1548767387866974, acc: 0.9719101190567017)
[2024-12-17 01:40:44,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:44,557][root][INFO] - Training Epoch: 1/2, step 1171/7134 completed (loss: 0.1923280954360962, acc: 0.9599332213401794)
[2024-12-17 01:40:44,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:44,889][root][INFO] - Training Epoch: 1/2, step 1172/7134 completed (loss: 0.21511554718017578, acc: 0.9470499157905579)
[2024-12-17 01:40:45,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:45,220][root][INFO] - Training Epoch: 1/2, step 1173/7134 completed (loss: 0.2188498079776764, acc: 0.9507246613502502)
[2024-12-17 01:40:45,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:45,575][root][INFO] - Training Epoch: 1/2, step 1174/7134 completed (loss: 0.11574006825685501, acc: 0.9759759902954102)
[2024-12-17 01:40:45,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:46,001][root][INFO] - Training Epoch: 1/2, step 1175/7134 completed (loss: 0.16365142166614532, acc: 0.9521738886833191)
[2024-12-17 01:40:46,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:46,330][root][INFO] - Training Epoch: 1/2, step 1176/7134 completed (loss: 0.09582941979169846, acc: 0.9691780805587769)
[2024-12-17 01:40:46,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:46,639][root][INFO] - Training Epoch: 1/2, step 1177/7134 completed (loss: 0.08727659285068512, acc: 0.9803921580314636)
[2024-12-17 01:40:46,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:46,946][root][INFO] - Training Epoch: 1/2, step 1178/7134 completed (loss: 0.12142716348171234, acc: 0.9649532437324524)
[2024-12-17 01:40:47,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:47,278][root][INFO] - Training Epoch: 1/2, step 1179/7134 completed (loss: 0.1774931252002716, acc: 0.9598470330238342)
[2024-12-17 01:40:47,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:47,639][root][INFO] - Training Epoch: 1/2, step 1180/7134 completed (loss: 0.12424474209547043, acc: 0.9671533107757568)
[2024-12-17 01:40:47,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:47,969][root][INFO] - Training Epoch: 1/2, step 1181/7134 completed (loss: 0.18014396727085114, acc: 0.9568345546722412)
[2024-12-17 01:40:48,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:48,281][root][INFO] - Training Epoch: 1/2, step 1182/7134 completed (loss: 0.10753489285707474, acc: 0.9692307710647583)
[2024-12-17 01:40:48,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:48,631][root][INFO] - Training Epoch: 1/2, step 1183/7134 completed (loss: 0.10990067571401596, acc: 0.9750367403030396)
[2024-12-17 01:40:48,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:48,961][root][INFO] - Training Epoch: 1/2, step 1184/7134 completed (loss: 0.2172936499118805, acc: 0.9542202949523926)
[2024-12-17 01:40:49,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:49,310][root][INFO] - Training Epoch: 1/2, step 1185/7134 completed (loss: 0.08670327067375183, acc: 0.9744361042976379)
[2024-12-17 01:40:49,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:49,639][root][INFO] - Training Epoch: 1/2, step 1186/7134 completed (loss: 0.08468274772167206, acc: 0.9792477488517761)
[2024-12-17 01:40:49,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:49,974][root][INFO] - Training Epoch: 1/2, step 1187/7134 completed (loss: 0.14899516105651855, acc: 0.9695290923118591)
[2024-12-17 01:40:50,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:50,318][root][INFO] - Training Epoch: 1/2, step 1188/7134 completed (loss: 0.10357829183340073, acc: 0.9749340415000916)
[2024-12-17 01:40:50,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:50,645][root][INFO] - Training Epoch: 1/2, step 1189/7134 completed (loss: 0.12935686111450195, acc: 0.9667630195617676)
[2024-12-17 01:40:50,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:50,963][root][INFO] - Training Epoch: 1/2, step 1190/7134 completed (loss: 0.1375323235988617, acc: 0.9592875242233276)
[2024-12-17 01:40:51,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:51,296][root][INFO] - Training Epoch: 1/2, step 1191/7134 completed (loss: 0.13663709163665771, acc: 0.9556868672370911)
[2024-12-17 01:40:51,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:51,636][root][INFO] - Training Epoch: 1/2, step 1192/7134 completed (loss: 0.1659419685602188, acc: 0.955439031124115)
[2024-12-17 01:40:51,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:51,973][root][INFO] - Training Epoch: 1/2, step 1193/7134 completed (loss: 0.16932295262813568, acc: 0.9537479877471924)
[2024-12-17 01:40:52,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:52,304][root][INFO] - Training Epoch: 1/2, step 1194/7134 completed (loss: 0.15932893753051758, acc: 0.9629120826721191)
[2024-12-17 01:40:52,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:52,635][root][INFO] - Training Epoch: 1/2, step 1195/7134 completed (loss: 0.17232723534107208, acc: 0.9591503143310547)
[2024-12-17 01:40:52,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:52,983][root][INFO] - Training Epoch: 1/2, step 1196/7134 completed (loss: 0.22029998898506165, acc: 0.94590163230896)
[2024-12-17 01:40:53,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:53,310][root][INFO] - Training Epoch: 1/2, step 1197/7134 completed (loss: 0.1686612218618393, acc: 0.9574779868125916)
[2024-12-17 01:40:53,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:53,644][root][INFO] - Training Epoch: 1/2, step 1198/7134 completed (loss: 0.13698555529117584, acc: 0.9625899195671082)
[2024-12-17 01:40:53,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:54,045][root][INFO] - Training Epoch: 1/2, step 1199/7134 completed (loss: 0.15318737924098969, acc: 0.9661266803741455)
[2024-12-17 01:40:54,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:54,403][root][INFO] - Training Epoch: 1/2, step 1200/7134 completed (loss: 0.2141861617565155, acc: 0.9507187008857727)
[2024-12-17 01:40:54,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:54,754][root][INFO] - Training Epoch: 1/2, step 1201/7134 completed (loss: 0.15758928656578064, acc: 0.9572901129722595)
[2024-12-17 01:40:54,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:55,115][root][INFO] - Training Epoch: 1/2, step 1202/7134 completed (loss: 0.2349647581577301, acc: 0.9380888342857361)
[2024-12-17 01:40:55,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:55,438][root][INFO] - Training Epoch: 1/2, step 1203/7134 completed (loss: 0.09654494374990463, acc: 0.9772382378578186)
[2024-12-17 01:40:55,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:55,764][root][INFO] - Training Epoch: 1/2, step 1204/7134 completed (loss: 0.16730181872844696, acc: 0.9608209133148193)
[2024-12-17 01:40:55,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:56,107][root][INFO] - Training Epoch: 1/2, step 1205/7134 completed (loss: 0.17481419444084167, acc: 0.9535211324691772)
[2024-12-17 01:40:56,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:56,460][root][INFO] - Training Epoch: 1/2, step 1206/7134 completed (loss: 0.13460716605186462, acc: 0.9702233076095581)
[2024-12-17 01:40:56,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:56,813][root][INFO] - Training Epoch: 1/2, step 1207/7134 completed (loss: 0.16061881184577942, acc: 0.963567852973938)
[2024-12-17 01:40:56,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:57,146][root][INFO] - Training Epoch: 1/2, step 1208/7134 completed (loss: 0.17781557142734528, acc: 0.9589552283287048)
[2024-12-17 01:40:57,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:57,476][root][INFO] - Training Epoch: 1/2, step 1209/7134 completed (loss: 0.24121813476085663, acc: 0.9396709203720093)
[2024-12-17 01:40:57,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:57,809][root][INFO] - Training Epoch: 1/2, step 1210/7134 completed (loss: 0.25176823139190674, acc: 0.9377990365028381)
[2024-12-17 01:40:57,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:58,136][root][INFO] - Training Epoch: 1/2, step 1211/7134 completed (loss: 0.32984718680381775, acc: 0.9287090301513672)
[2024-12-17 01:40:58,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:58,453][root][INFO] - Training Epoch: 1/2, step 1212/7134 completed (loss: 0.19299209117889404, acc: 0.9557926654815674)
[2024-12-17 01:40:58,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:58,801][root][INFO] - Training Epoch: 1/2, step 1213/7134 completed (loss: 0.17066071927547455, acc: 0.9519094824790955)
[2024-12-17 01:40:58,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:59,126][root][INFO] - Training Epoch: 1/2, step 1214/7134 completed (loss: 0.18474934995174408, acc: 0.9507692456245422)
[2024-12-17 01:40:59,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:59,472][root][INFO] - Training Epoch: 1/2, step 1215/7134 completed (loss: 0.22896377742290497, acc: 0.9489654898643494)
[2024-12-17 01:40:59,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:59,815][root][INFO] - Training Epoch: 1/2, step 1216/7134 completed (loss: 0.19991542398929596, acc: 0.9489051103591919)
[2024-12-17 01:40:59,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:00,174][root][INFO] - Training Epoch: 1/2, step 1217/7134 completed (loss: 0.17579646408557892, acc: 0.9594155550003052)
[2024-12-17 01:41:00,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:00,534][root][INFO] - Training Epoch: 1/2, step 1218/7134 completed (loss: 0.29392778873443604, acc: 0.9283581972122192)
[2024-12-17 01:41:00,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:00,895][root][INFO] - Training Epoch: 1/2, step 1219/7134 completed (loss: 0.347666472196579, acc: 0.9103690981864929)
[2024-12-17 01:41:01,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:01,253][root][INFO] - Training Epoch: 1/2, step 1220/7134 completed (loss: 0.36164531111717224, acc: 0.913705587387085)
[2024-12-17 01:41:01,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:01,634][root][INFO] - Training Epoch: 1/2, step 1221/7134 completed (loss: 0.36148205399513245, acc: 0.9035087823867798)
[2024-12-17 01:41:01,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:01,984][root][INFO] - Training Epoch: 1/2, step 1222/7134 completed (loss: 0.2927354872226715, acc: 0.9308700561523438)
[2024-12-17 01:41:02,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:02,334][root][INFO] - Training Epoch: 1/2, step 1223/7134 completed (loss: 0.45543545484542847, acc: 0.8847736716270447)
[2024-12-17 01:41:02,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:02,692][root][INFO] - Training Epoch: 1/2, step 1224/7134 completed (loss: 0.2810943126678467, acc: 0.9249448180198669)
[2024-12-17 01:41:02,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:03,052][root][INFO] - Training Epoch: 1/2, step 1225/7134 completed (loss: 0.32355010509490967, acc: 0.911464273929596)
[2024-12-17 01:41:03,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:03,397][root][INFO] - Training Epoch: 1/2, step 1226/7134 completed (loss: 0.37085703015327454, acc: 0.895372211933136)
[2024-12-17 01:41:03,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:03,742][root][INFO] - Training Epoch: 1/2, step 1227/7134 completed (loss: 0.3742479681968689, acc: 0.9061661958694458)
[2024-12-17 01:41:03,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:04,084][root][INFO] - Training Epoch: 1/2, step 1228/7134 completed (loss: 0.34901130199432373, acc: 0.9198855757713318)
[2024-12-17 01:41:04,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:04,433][root][INFO] - Training Epoch: 1/2, step 1229/7134 completed (loss: 0.2688709497451782, acc: 0.9267706871032715)
[2024-12-17 01:41:04,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:04,799][root][INFO] - Training Epoch: 1/2, step 1230/7134 completed (loss: 0.3979159891605377, acc: 0.8926553726196289)
[2024-12-17 01:41:04,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:05,204][root][INFO] - Training Epoch: 1/2, step 1231/7134 completed (loss: 0.27758002281188965, acc: 0.9307135343551636)
[2024-12-17 01:41:05,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:05,582][root][INFO] - Training Epoch: 1/2, step 1232/7134 completed (loss: 0.2752366065979004, acc: 0.9339722990989685)
[2024-12-17 01:41:05,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:05,936][root][INFO] - Training Epoch: 1/2, step 1233/7134 completed (loss: 0.3723130524158478, acc: 0.9098265767097473)
[2024-12-17 01:41:06,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:06,316][root][INFO] - Training Epoch: 1/2, step 1234/7134 completed (loss: 0.23194681107997894, acc: 0.9301242232322693)
[2024-12-17 01:41:06,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:06,676][root][INFO] - Training Epoch: 1/2, step 1235/7134 completed (loss: 0.2517508268356323, acc: 0.9340527653694153)
[2024-12-17 01:41:06,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:07,027][root][INFO] - Training Epoch: 1/2, step 1236/7134 completed (loss: 0.35869306325912476, acc: 0.9194729328155518)
[2024-12-17 01:41:07,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:07,377][root][INFO] - Training Epoch: 1/2, step 1237/7134 completed (loss: 0.25827643275260925, acc: 0.9347826242446899)
[2024-12-17 01:41:07,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:07,724][root][INFO] - Training Epoch: 1/2, step 1238/7134 completed (loss: 0.4645562469959259, acc: 0.8762736320495605)
[2024-12-17 01:41:07,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:08,090][root][INFO] - Training Epoch: 1/2, step 1239/7134 completed (loss: 0.3483021557331085, acc: 0.8941344618797302)
[2024-12-17 01:41:08,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:08,446][root][INFO] - Training Epoch: 1/2, step 1240/7134 completed (loss: 0.3105759620666504, acc: 0.9312169551849365)
[2024-12-17 01:41:08,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:08,703][root][INFO] - Training Epoch: 1/2, step 1241/7134 completed (loss: 0.39185234904289246, acc: 0.9076305031776428)
[2024-12-17 01:41:08,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:09,068][root][INFO] - Training Epoch: 1/2, step 1242/7134 completed (loss: 0.2741137444972992, acc: 0.926682710647583)
[2024-12-17 01:41:09,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:09,436][root][INFO] - Training Epoch: 1/2, step 1243/7134 completed (loss: 0.23918341100215912, acc: 0.9403765797615051)
[2024-12-17 01:41:09,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:09,784][root][INFO] - Training Epoch: 1/2, step 1244/7134 completed (loss: 0.3136637508869171, acc: 0.9205297827720642)
[2024-12-17 01:41:09,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:10,150][root][INFO] - Training Epoch: 1/2, step 1245/7134 completed (loss: 0.28185945749282837, acc: 0.9370276927947998)
[2024-12-17 01:41:10,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:10,477][root][INFO] - Training Epoch: 1/2, step 1246/7134 completed (loss: 0.29946210980415344, acc: 0.9293966889381409)
[2024-12-17 01:41:10,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:10,847][root][INFO] - Training Epoch: 1/2, step 1247/7134 completed (loss: 0.214549258351326, acc: 0.9493487477302551)
[2024-12-17 01:41:10,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:11,182][root][INFO] - Training Epoch: 1/2, step 1248/7134 completed (loss: 0.22176098823547363, acc: 0.9450801014900208)
[2024-12-17 01:41:11,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:11,540][root][INFO] - Training Epoch: 1/2, step 1249/7134 completed (loss: 0.15412725508213043, acc: 0.9608541131019592)
[2024-12-17 01:41:11,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:11,861][root][INFO] - Training Epoch: 1/2, step 1250/7134 completed (loss: 0.14186078310012817, acc: 0.9603399634361267)
[2024-12-17 01:41:11,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:12,195][root][INFO] - Training Epoch: 1/2, step 1251/7134 completed (loss: 0.14637261629104614, acc: 0.965706467628479)
[2024-12-17 01:41:12,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:12,523][root][INFO] - Training Epoch: 1/2, step 1252/7134 completed (loss: 0.14718718826770782, acc: 0.959876537322998)
[2024-12-17 01:41:12,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:12,857][root][INFO] - Training Epoch: 1/2, step 1253/7134 completed (loss: 0.18420825898647308, acc: 0.953667938709259)
[2024-12-17 01:41:12,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:13,195][root][INFO] - Training Epoch: 1/2, step 1254/7134 completed (loss: 0.30949586629867554, acc: 0.9303030371665955)
[2024-12-17 01:41:13,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:13,523][root][INFO] - Training Epoch: 1/2, step 1255/7134 completed (loss: 0.16911056637763977, acc: 0.9591836929321289)
[2024-12-17 01:41:13,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:13,835][root][INFO] - Training Epoch: 1/2, step 1256/7134 completed (loss: 0.15341052412986755, acc: 0.9581993818283081)
[2024-12-17 01:41:13,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:14,169][root][INFO] - Training Epoch: 1/2, step 1257/7134 completed (loss: 0.09826316684484482, acc: 0.9741518497467041)
[2024-12-17 01:41:14,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:14,510][root][INFO] - Training Epoch: 1/2, step 1258/7134 completed (loss: 0.21895663440227509, acc: 0.9458272457122803)
[2024-12-17 01:41:14,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:14,866][root][INFO] - Training Epoch: 1/2, step 1259/7134 completed (loss: 0.1683526337146759, acc: 0.9613733887672424)
[2024-12-17 01:41:15,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:15,218][root][INFO] - Training Epoch: 1/2, step 1260/7134 completed (loss: 0.1444789171218872, acc: 0.9638728499412537)
[2024-12-17 01:41:15,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:15,607][root][INFO] - Training Epoch: 1/2, step 1261/7134 completed (loss: 0.13826824724674225, acc: 0.9673590660095215)
[2024-12-17 01:41:15,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:15,899][root][INFO] - Training Epoch: 1/2, step 1262/7134 completed (loss: 0.06043485179543495, acc: 0.9853479862213135)
[2024-12-17 01:41:15,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:16,214][root][INFO] - Training Epoch: 1/2, step 1263/7134 completed (loss: 0.11658715456724167, acc: 0.9800000190734863)
[2024-12-17 01:41:16,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:16,565][root][INFO] - Training Epoch: 1/2, step 1264/7134 completed (loss: 0.124745212495327, acc: 0.9719626307487488)
[2024-12-17 01:41:16,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:16,926][root][INFO] - Training Epoch: 1/2, step 1265/7134 completed (loss: 0.12382781505584717, acc: 0.9661654233932495)
[2024-12-17 01:41:17,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:17,262][root][INFO] - Training Epoch: 1/2, step 1266/7134 completed (loss: 0.11142542958259583, acc: 0.9690189361572266)
[2024-12-17 01:41:17,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:17,585][root][INFO] - Training Epoch: 1/2, step 1267/7134 completed (loss: 0.11128745973110199, acc: 0.9765517115592957)
[2024-12-17 01:41:17,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:17,925][root][INFO] - Training Epoch: 1/2, step 1268/7134 completed (loss: 0.14833423495292664, acc: 0.9615952968597412)
[2024-12-17 01:41:18,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:18,260][root][INFO] - Training Epoch: 1/2, step 1269/7134 completed (loss: 0.1798555999994278, acc: 0.9534482955932617)
[2024-12-17 01:41:18,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:18,589][root][INFO] - Training Epoch: 1/2, step 1270/7134 completed (loss: 0.16049888730049133, acc: 0.956764280796051)
[2024-12-17 01:41:18,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:18,901][root][INFO] - Training Epoch: 1/2, step 1271/7134 completed (loss: 0.19413916766643524, acc: 0.9611111283302307)
[2024-12-17 01:41:19,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:19,297][root][INFO] - Training Epoch: 1/2, step 1272/7134 completed (loss: 0.08452185988426208, acc: 0.9788639545440674)
[2024-12-17 01:41:19,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:19,621][root][INFO] - Training Epoch: 1/2, step 1273/7134 completed (loss: 0.0741974413394928, acc: 0.9806451797485352)
[2024-12-17 01:41:19,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:19,951][root][INFO] - Training Epoch: 1/2, step 1274/7134 completed (loss: 0.10468997061252594, acc: 0.9729729890823364)
[2024-12-17 01:41:20,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:20,278][root][INFO] - Training Epoch: 1/2, step 1275/7134 completed (loss: 0.15468984842300415, acc: 0.9605026841163635)
[2024-12-17 01:41:20,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:20,593][root][INFO] - Training Epoch: 1/2, step 1276/7134 completed (loss: 0.09383232146501541, acc: 0.9741935729980469)
[2024-12-17 01:41:20,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:20,905][root][INFO] - Training Epoch: 1/2, step 1277/7134 completed (loss: 0.09927446395158768, acc: 0.9709208607673645)
[2024-12-17 01:41:21,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:21,289][root][INFO] - Training Epoch: 1/2, step 1278/7134 completed (loss: 0.201669380068779, acc: 0.9409019947052002)
[2024-12-17 01:41:21,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:21,622][root][INFO] - Training Epoch: 1/2, step 1279/7134 completed (loss: 0.17972026765346527, acc: 0.9454094171524048)
[2024-12-17 01:41:21,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:21,950][root][INFO] - Training Epoch: 1/2, step 1280/7134 completed (loss: 0.21027830243110657, acc: 0.9500657320022583)
[2024-12-17 01:41:22,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:22,282][root][INFO] - Training Epoch: 1/2, step 1281/7134 completed (loss: 0.23631028831005096, acc: 0.9449225664138794)
[2024-12-17 01:41:22,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:22,634][root][INFO] - Training Epoch: 1/2, step 1282/7134 completed (loss: 0.27567988634109497, acc: 0.9358288645744324)
[2024-12-17 01:41:22,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:22,994][root][INFO] - Training Epoch: 1/2, step 1283/7134 completed (loss: 0.37282440066337585, acc: 0.9102112650871277)
[2024-12-17 01:41:23,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:23,337][root][INFO] - Training Epoch: 1/2, step 1284/7134 completed (loss: 0.1631542146205902, acc: 0.9645776748657227)
[2024-12-17 01:41:23,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:23,688][root][INFO] - Training Epoch: 1/2, step 1285/7134 completed (loss: 0.1974082887172699, acc: 0.9581529498100281)
[2024-12-17 01:41:23,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:24,039][root][INFO] - Training Epoch: 1/2, step 1286/7134 completed (loss: 0.22197040915489197, acc: 0.9542202949523926)
[2024-12-17 01:41:24,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:24,361][root][INFO] - Training Epoch: 1/2, step 1287/7134 completed (loss: 0.31859731674194336, acc: 0.9235880374908447)
[2024-12-17 01:41:24,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:24,681][root][INFO] - Training Epoch: 1/2, step 1288/7134 completed (loss: 0.1678137183189392, acc: 0.9631979465484619)
[2024-12-17 01:41:24,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:25,001][root][INFO] - Training Epoch: 1/2, step 1289/7134 completed (loss: 0.15871700644493103, acc: 0.9631490707397461)
[2024-12-17 01:41:25,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:25,346][root][INFO] - Training Epoch: 1/2, step 1290/7134 completed (loss: 0.22554613649845123, acc: 0.9507042169570923)
[2024-12-17 01:41:25,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:25,727][root][INFO] - Training Epoch: 1/2, step 1291/7134 completed (loss: 0.19687554240226746, acc: 0.9525802135467529)
[2024-12-17 01:41:25,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:26,064][root][INFO] - Training Epoch: 1/2, step 1292/7134 completed (loss: 0.23284196853637695, acc: 0.9363636374473572)
[2024-12-17 01:41:26,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:26,416][root][INFO] - Training Epoch: 1/2, step 1293/7134 completed (loss: 0.2034439593553543, acc: 0.9452852010726929)
[2024-12-17 01:41:26,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:26,752][root][INFO] - Training Epoch: 1/2, step 1294/7134 completed (loss: 0.16826950013637543, acc: 0.9596878886222839)
[2024-12-17 01:41:26,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:27,105][root][INFO] - Training Epoch: 1/2, step 1295/7134 completed (loss: 0.20204685628414154, acc: 0.9422750473022461)
[2024-12-17 01:41:27,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:27,447][root][INFO] - Training Epoch: 1/2, step 1296/7134 completed (loss: 0.1533203125, acc: 0.9646017551422119)
[2024-12-17 01:41:27,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:27,762][root][INFO] - Training Epoch: 1/2, step 1297/7134 completed (loss: 0.17401714622974396, acc: 0.9480249285697937)
[2024-12-17 01:41:27,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:28,096][root][INFO] - Training Epoch: 1/2, step 1298/7134 completed (loss: 0.20624037086963654, acc: 0.9388489127159119)
[2024-12-17 01:41:28,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:28,422][root][INFO] - Training Epoch: 1/2, step 1299/7134 completed (loss: 0.13126638531684875, acc: 0.96875)
[2024-12-17 01:41:28,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:28,811][root][INFO] - Training Epoch: 1/2, step 1300/7134 completed (loss: 0.18153999745845795, acc: 0.9439707398414612)
[2024-12-17 01:41:28,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:29,140][root][INFO] - Training Epoch: 1/2, step 1301/7134 completed (loss: 0.13879238069057465, acc: 0.9569733142852783)
[2024-12-17 01:41:29,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:29,497][root][INFO] - Training Epoch: 1/2, step 1302/7134 completed (loss: 0.1667012721300125, acc: 0.9564732313156128)
[2024-12-17 01:41:29,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:29,865][root][INFO] - Training Epoch: 1/2, step 1303/7134 completed (loss: 0.2070314884185791, acc: 0.9350961446762085)
[2024-12-17 01:41:29,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:30,196][root][INFO] - Training Epoch: 1/2, step 1304/7134 completed (loss: 0.2801607549190521, acc: 0.9288537502288818)
[2024-12-17 01:41:30,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:30,552][root][INFO] - Training Epoch: 1/2, step 1305/7134 completed (loss: 0.17999470233917236, acc: 0.9555837512016296)
[2024-12-17 01:41:30,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:30,948][root][INFO] - Training Epoch: 1/2, step 1306/7134 completed (loss: 0.27800998091697693, acc: 0.9301972389221191)
[2024-12-17 01:41:31,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:31,264][root][INFO] - Training Epoch: 1/2, step 1307/7134 completed (loss: 0.14642056822776794, acc: 0.9573459625244141)
[2024-12-17 01:41:31,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:31,609][root][INFO] - Training Epoch: 1/2, step 1308/7134 completed (loss: 0.14977900683879852, acc: 0.9609022736549377)
[2024-12-17 01:41:31,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:31,971][root][INFO] - Training Epoch: 1/2, step 1309/7134 completed (loss: 0.18072398006916046, acc: 0.9521530866622925)
[2024-12-17 01:41:32,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:32,332][root][INFO] - Training Epoch: 1/2, step 1310/7134 completed (loss: 0.2472057342529297, acc: 0.9428571462631226)
[2024-12-17 01:41:32,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:32,674][root][INFO] - Training Epoch: 1/2, step 1311/7134 completed (loss: 0.24701033532619476, acc: 0.9479637742042542)
[2024-12-17 01:41:32,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:33,032][root][INFO] - Training Epoch: 1/2, step 1312/7134 completed (loss: 0.2880518138408661, acc: 0.9245283007621765)
[2024-12-17 01:41:33,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:33,385][root][INFO] - Training Epoch: 1/2, step 1313/7134 completed (loss: 0.24164743721485138, acc: 0.9390934705734253)
[2024-12-17 01:41:33,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:33,707][root][INFO] - Training Epoch: 1/2, step 1314/7134 completed (loss: 0.195313960313797, acc: 0.9526315927505493)
[2024-12-17 01:41:33,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:34,037][root][INFO] - Training Epoch: 1/2, step 1315/7134 completed (loss: 0.315493643283844, acc: 0.9213333129882812)
[2024-12-17 01:41:34,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:34,385][root][INFO] - Training Epoch: 1/2, step 1316/7134 completed (loss: 0.19467931985855103, acc: 0.9491525292396545)
[2024-12-17 01:41:34,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:34,653][root][INFO] - Training Epoch: 1/2, step 1317/7134 completed (loss: 0.3321852684020996, acc: 0.9105691313743591)
[2024-12-17 01:41:34,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:35,039][root][INFO] - Training Epoch: 1/2, step 1318/7134 completed (loss: 0.2664121091365814, acc: 0.9346048831939697)
[2024-12-17 01:41:35,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:35,295][root][INFO] - Training Epoch: 1/2, step 1319/7134 completed (loss: 0.32546550035476685, acc: 0.9199084639549255)
[2024-12-17 01:41:35,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:35,621][root][INFO] - Training Epoch: 1/2, step 1320/7134 completed (loss: 0.28651899099349976, acc: 0.9250814318656921)
[2024-12-17 01:41:35,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:35,999][root][INFO] - Training Epoch: 1/2, step 1321/7134 completed (loss: 0.2313312292098999, acc: 0.9375)
[2024-12-17 01:41:36,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:36,340][root][INFO] - Training Epoch: 1/2, step 1322/7134 completed (loss: 0.19526110589504242, acc: 0.9443535208702087)
[2024-12-17 01:41:36,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:36,688][root][INFO] - Training Epoch: 1/2, step 1323/7134 completed (loss: 0.30417099595069885, acc: 0.9267857074737549)
[2024-12-17 01:41:36,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:37,031][root][INFO] - Training Epoch: 1/2, step 1324/7134 completed (loss: 0.22676628828048706, acc: 0.9226973652839661)
[2024-12-17 01:41:37,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:37,303][root][INFO] - Training Epoch: 1/2, step 1325/7134 completed (loss: 0.24498577415943146, acc: 0.9342403411865234)
[2024-12-17 01:41:37,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:37,672][root][INFO] - Training Epoch: 1/2, step 1326/7134 completed (loss: 0.28066113591194153, acc: 0.9165751934051514)
[2024-12-17 01:41:37,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:38,018][root][INFO] - Training Epoch: 1/2, step 1327/7134 completed (loss: 0.20953916013240814, acc: 0.9595202207565308)
[2024-12-17 01:41:38,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:38,362][root][INFO] - Training Epoch: 1/2, step 1328/7134 completed (loss: 0.23598627746105194, acc: 0.9488372206687927)
[2024-12-17 01:41:38,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:38,705][root][INFO] - Training Epoch: 1/2, step 1329/7134 completed (loss: 0.2158050388097763, acc: 0.9558011293411255)
[2024-12-17 01:41:38,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:39,019][root][INFO] - Training Epoch: 1/2, step 1330/7134 completed (loss: 0.18586574494838715, acc: 0.9519725441932678)
[2024-12-17 01:41:39,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:39,376][root][INFO] - Training Epoch: 1/2, step 1331/7134 completed (loss: 0.13409027457237244, acc: 0.9592834115028381)
[2024-12-17 01:41:39,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:39,675][root][INFO] - Training Epoch: 1/2, step 1332/7134 completed (loss: 0.16079692542552948, acc: 0.9672489166259766)
[2024-12-17 01:41:39,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:40,036][root][INFO] - Training Epoch: 1/2, step 1333/7134 completed (loss: 0.2347690314054489, acc: 0.9353741407394409)
[2024-12-17 01:41:40,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:40,389][root][INFO] - Training Epoch: 1/2, step 1334/7134 completed (loss: 0.2791769802570343, acc: 0.9363353848457336)
[2024-12-17 01:41:40,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:40,712][root][INFO] - Training Epoch: 1/2, step 1335/7134 completed (loss: 0.24761055409908295, acc: 0.9480692148208618)
[2024-12-17 01:41:40,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:41,054][root][INFO] - Training Epoch: 1/2, step 1336/7134 completed (loss: 0.14358165860176086, acc: 0.968876838684082)
[2024-12-17 01:41:41,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:41,415][root][INFO] - Training Epoch: 1/2, step 1337/7134 completed (loss: 0.23964698612689972, acc: 0.9355828166007996)
[2024-12-17 01:41:41,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:41,686][root][INFO] - Training Epoch: 1/2, step 1338/7134 completed (loss: 0.2591080665588379, acc: 0.9196786880493164)
[2024-12-17 01:41:41,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:41,991][root][INFO] - Training Epoch: 1/2, step 1339/7134 completed (loss: 0.17940570414066315, acc: 0.9522472023963928)
[2024-12-17 01:41:42,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:42,311][root][INFO] - Training Epoch: 1/2, step 1340/7134 completed (loss: 0.23396505415439606, acc: 0.9388971924781799)
[2024-12-17 01:41:42,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:42,637][root][INFO] - Training Epoch: 1/2, step 1341/7134 completed (loss: 0.24926462769508362, acc: 0.9576271176338196)
[2024-12-17 01:41:42,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:43,000][root][INFO] - Training Epoch: 1/2, step 1342/7134 completed (loss: 0.1577119380235672, acc: 0.9549114108085632)
[2024-12-17 01:41:43,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:43,353][root][INFO] - Training Epoch: 1/2, step 1343/7134 completed (loss: 0.23528288304805756, acc: 0.9481216669082642)
[2024-12-17 01:41:43,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:43,660][root][INFO] - Training Epoch: 1/2, step 1344/7134 completed (loss: 0.14095629751682281, acc: 0.9615384340286255)
[2024-12-17 01:41:43,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:43,932][root][INFO] - Training Epoch: 1/2, step 1345/7134 completed (loss: 0.19172395765781403, acc: 0.9496021270751953)
[2024-12-17 01:41:44,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:44,362][root][INFO] - Training Epoch: 1/2, step 1346/7134 completed (loss: 0.19234240055084229, acc: 0.9612817168235779)
[2024-12-17 01:41:44,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:44,684][root][INFO] - Training Epoch: 1/2, step 1347/7134 completed (loss: 0.18479330837726593, acc: 0.9581881761550903)
[2024-12-17 01:41:44,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:45,023][root][INFO] - Training Epoch: 1/2, step 1348/7134 completed (loss: 0.16387292742729187, acc: 0.956749677658081)
[2024-12-17 01:41:45,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:45,364][root][INFO] - Training Epoch: 1/2, step 1349/7134 completed (loss: 0.1511298567056656, acc: 0.9589743614196777)
[2024-12-17 01:41:45,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:45,685][root][INFO] - Training Epoch: 1/2, step 1350/7134 completed (loss: 0.13050149381160736, acc: 0.9652677178382874)
[2024-12-17 01:41:45,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:46,004][root][INFO] - Training Epoch: 1/2, step 1351/7134 completed (loss: 0.1303255558013916, acc: 0.9646365642547607)
[2024-12-17 01:41:46,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:46,322][root][INFO] - Training Epoch: 1/2, step 1352/7134 completed (loss: 0.27069926261901855, acc: 0.9404761791229248)
[2024-12-17 01:41:46,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:46,655][root][INFO] - Training Epoch: 1/2, step 1353/7134 completed (loss: 0.1664605587720871, acc: 0.9655172228813171)
[2024-12-17 01:41:46,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:46,990][root][INFO] - Training Epoch: 1/2, step 1354/7134 completed (loss: 0.1166471615433693, acc: 0.9675850868225098)
[2024-12-17 01:41:47,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:47,306][root][INFO] - Training Epoch: 1/2, step 1355/7134 completed (loss: 0.08771979808807373, acc: 0.9766355156898499)
[2024-12-17 01:41:47,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:47,661][root][INFO] - Training Epoch: 1/2, step 1356/7134 completed (loss: 0.06909976154565811, acc: 0.9815789461135864)
[2024-12-17 01:41:47,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:48,000][root][INFO] - Training Epoch: 1/2, step 1357/7134 completed (loss: 0.08050832152366638, acc: 0.9798234701156616)
[2024-12-17 01:41:48,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:48,374][root][INFO] - Training Epoch: 1/2, step 1358/7134 completed (loss: 0.10261659324169159, acc: 0.9753246903419495)
[2024-12-17 01:41:48,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:48,699][root][INFO] - Training Epoch: 1/2, step 1359/7134 completed (loss: 0.11373026669025421, acc: 0.9757084846496582)
[2024-12-17 01:41:48,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:49,031][root][INFO] - Training Epoch: 1/2, step 1360/7134 completed (loss: 0.09411217272281647, acc: 0.9784946441650391)
[2024-12-17 01:41:49,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:49,442][root][INFO] - Training Epoch: 1/2, step 1361/7134 completed (loss: 0.11102130264043808, acc: 0.9722627997398376)
[2024-12-17 01:41:49,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:49,779][root][INFO] - Training Epoch: 1/2, step 1362/7134 completed (loss: 0.10282552242279053, acc: 0.9713114500045776)
[2024-12-17 01:41:49,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:50,142][root][INFO] - Training Epoch: 1/2, step 1363/7134 completed (loss: 0.07939218729734421, acc: 0.9825737476348877)
[2024-12-17 01:41:50,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:50,477][root][INFO] - Training Epoch: 1/2, step 1364/7134 completed (loss: 0.08428023755550385, acc: 0.9742857217788696)
[2024-12-17 01:41:50,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:50,793][root][INFO] - Training Epoch: 1/2, step 1365/7134 completed (loss: 0.1922231763601303, acc: 0.9505494236946106)
[2024-12-17 01:41:50,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:51,142][root][INFO] - Training Epoch: 1/2, step 1366/7134 completed (loss: 0.07444069534540176, acc: 0.9750000238418579)
[2024-12-17 01:41:51,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:51,468][root][INFO] - Training Epoch: 1/2, step 1367/7134 completed (loss: 0.06573036313056946, acc: 0.9879310131072998)
[2024-12-17 01:41:51,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:51,823][root][INFO] - Training Epoch: 1/2, step 1368/7134 completed (loss: 0.15740074217319489, acc: 0.9618902206420898)
[2024-12-17 01:41:51,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:52,150][root][INFO] - Training Epoch: 1/2, step 1369/7134 completed (loss: 0.13164713978767395, acc: 0.9772329330444336)
[2024-12-17 01:41:52,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:52,484][root][INFO] - Training Epoch: 1/2, step 1370/7134 completed (loss: 0.1381950080394745, acc: 0.9696586728096008)
[2024-12-17 01:41:52,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:52,833][root][INFO] - Training Epoch: 1/2, step 1371/7134 completed (loss: 0.12364964187145233, acc: 0.9650654792785645)
[2024-12-17 01:41:52,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:53,163][root][INFO] - Training Epoch: 1/2, step 1372/7134 completed (loss: 0.23809823393821716, acc: 0.9382022619247437)
[2024-12-17 01:41:53,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:53,527][root][INFO] - Training Epoch: 1/2, step 1373/7134 completed (loss: 0.12431394308805466, acc: 0.9665354490280151)
[2024-12-17 01:41:53,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:53,907][root][INFO] - Training Epoch: 1/2, step 1374/7134 completed (loss: 0.1763118952512741, acc: 0.9544554352760315)
[2024-12-17 01:41:53,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:54,199][root][INFO] - Training Epoch: 1/2, step 1375/7134 completed (loss: 0.1654319018125534, acc: 0.9447115659713745)
[2024-12-17 01:41:54,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:54,523][root][INFO] - Training Epoch: 1/2, step 1376/7134 completed (loss: 0.27903062105178833, acc: 0.924843430519104)
[2024-12-17 01:41:54,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:54,859][root][INFO] - Training Epoch: 1/2, step 1377/7134 completed (loss: 0.11010108143091202, acc: 0.9788235425949097)
[2024-12-17 01:41:54,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:55,161][root][INFO] - Training Epoch: 1/2, step 1378/7134 completed (loss: 0.19296598434448242, acc: 0.9454191327095032)
[2024-12-17 01:41:55,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:55,475][root][INFO] - Training Epoch: 1/2, step 1379/7134 completed (loss: 0.2109130620956421, acc: 0.9569892287254333)
[2024-12-17 01:41:55,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:55,812][root][INFO] - Training Epoch: 1/2, step 1380/7134 completed (loss: 0.17358078062534332, acc: 0.9626168012619019)
[2024-12-17 01:41:55,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:56,193][root][INFO] - Training Epoch: 1/2, step 1381/7134 completed (loss: 0.19484767317771912, acc: 0.9519071578979492)
[2024-12-17 01:41:56,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:56,516][root][INFO] - Training Epoch: 1/2, step 1382/7134 completed (loss: 0.17552641034126282, acc: 0.9523809552192688)
[2024-12-17 01:41:56,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:56,860][root][INFO] - Training Epoch: 1/2, step 1383/7134 completed (loss: 0.12100553512573242, acc: 0.9672977328300476)
[2024-12-17 01:41:57,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:57,228][root][INFO] - Training Epoch: 1/2, step 1384/7134 completed (loss: 0.27836844325065613, acc: 0.9284525513648987)
[2024-12-17 01:41:57,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:57,551][root][INFO] - Training Epoch: 1/2, step 1385/7134 completed (loss: 0.2564786374568939, acc: 0.9412844181060791)
[2024-12-17 01:41:57,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:57,886][root][INFO] - Training Epoch: 1/2, step 1386/7134 completed (loss: 0.144220769405365, acc: 0.9631268382072449)
[2024-12-17 01:41:57,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:58,215][root][INFO] - Training Epoch: 1/2, step 1387/7134 completed (loss: 0.17897075414657593, acc: 0.9598853588104248)
[2024-12-17 01:41:58,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:58,536][root][INFO] - Training Epoch: 1/2, step 1388/7134 completed (loss: 0.1619005799293518, acc: 0.9574105739593506)
[2024-12-17 01:41:58,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:58,884][root][INFO] - Training Epoch: 1/2, step 1389/7134 completed (loss: 0.18216533958911896, acc: 0.9513776302337646)
[2024-12-17 01:41:59,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:59,220][root][INFO] - Training Epoch: 1/2, step 1390/7134 completed (loss: 0.13939420878887177, acc: 0.9594383835792542)
[2024-12-17 01:41:59,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:59,558][root][INFO] - Training Epoch: 1/2, step 1391/7134 completed (loss: 0.2051229029893875, acc: 0.945518434047699)
[2024-12-17 01:41:59,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:59,895][root][INFO] - Training Epoch: 1/2, step 1392/7134 completed (loss: 0.13592705130577087, acc: 0.9688581228256226)
[2024-12-17 01:42:00,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:00,215][root][INFO] - Training Epoch: 1/2, step 1393/7134 completed (loss: 0.1271297037601471, acc: 0.9723502397537231)
[2024-12-17 01:42:00,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:00,551][root][INFO] - Training Epoch: 1/2, step 1394/7134 completed (loss: 0.11355502158403397, acc: 0.97817462682724)
[2024-12-17 01:42:00,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:00,847][root][INFO] - Training Epoch: 1/2, step 1395/7134 completed (loss: 0.14296618103981018, acc: 0.9684418439865112)
[2024-12-17 01:42:00,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:01,163][root][INFO] - Training Epoch: 1/2, step 1396/7134 completed (loss: 0.17045973241329193, acc: 0.9493243098258972)
[2024-12-17 01:42:01,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:01,485][root][INFO] - Training Epoch: 1/2, step 1397/7134 completed (loss: 0.23063503205776215, acc: 0.9477234482765198)
[2024-12-17 01:42:01,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:01,796][root][INFO] - Training Epoch: 1/2, step 1398/7134 completed (loss: 0.13946354389190674, acc: 0.9614604711532593)
[2024-12-17 01:42:01,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:02,129][root][INFO] - Training Epoch: 1/2, step 1399/7134 completed (loss: 0.23587210476398468, acc: 0.945652186870575)
[2024-12-17 01:42:02,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:02,468][root][INFO] - Training Epoch: 1/2, step 1400/7134 completed (loss: 0.09863540530204773, acc: 0.9738219976425171)
[2024-12-17 01:42:02,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:02,808][root][INFO] - Training Epoch: 1/2, step 1401/7134 completed (loss: 0.1313752830028534, acc: 0.9637562036514282)
[2024-12-17 01:42:02,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:03,120][root][INFO] - Training Epoch: 1/2, step 1402/7134 completed (loss: 0.09351303428411484, acc: 0.9671847820281982)
[2024-12-17 01:42:03,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:03,465][root][INFO] - Training Epoch: 1/2, step 1403/7134 completed (loss: 0.10410166531801224, acc: 0.9732262492179871)
[2024-12-17 01:42:03,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:03,819][root][INFO] - Training Epoch: 1/2, step 1404/7134 completed (loss: 0.07493092119693756, acc: 0.9854111671447754)
[2024-12-17 01:42:03,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:04,171][root][INFO] - Training Epoch: 1/2, step 1405/7134 completed (loss: 0.1281454712152481, acc: 0.9700854420661926)
[2024-12-17 01:42:04,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:04,521][root][INFO] - Training Epoch: 1/2, step 1406/7134 completed (loss: 0.11026233434677124, acc: 0.9798850417137146)
[2024-12-17 01:42:04,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:04,852][root][INFO] - Training Epoch: 1/2, step 1407/7134 completed (loss: 0.08751355856657028, acc: 0.9830508232116699)
[2024-12-17 01:42:04,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:05,191][root][INFO] - Training Epoch: 1/2, step 1408/7134 completed (loss: 0.1392419934272766, acc: 0.9647436141967773)
[2024-12-17 01:42:05,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:05,529][root][INFO] - Training Epoch: 1/2, step 1409/7134 completed (loss: 0.09720873087644577, acc: 0.9776452779769897)
[2024-12-17 01:42:05,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:05,888][root][INFO] - Training Epoch: 1/2, step 1410/7134 completed (loss: 0.17434225976467133, acc: 0.9557291865348816)
[2024-12-17 01:42:05,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:06,231][root][INFO] - Training Epoch: 1/2, step 1411/7134 completed (loss: 0.08015550673007965, acc: 0.980053186416626)
[2024-12-17 01:42:06,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:06,590][root][INFO] - Training Epoch: 1/2, step 1412/7134 completed (loss: 0.09397066384553909, acc: 0.978622317314148)
[2024-12-17 01:42:06,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:06,936][root][INFO] - Training Epoch: 1/2, step 1413/7134 completed (loss: 0.0882478803396225, acc: 0.9784172773361206)
[2024-12-17 01:42:07,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:07,265][root][INFO] - Training Epoch: 1/2, step 1414/7134 completed (loss: 0.07865369319915771, acc: 0.9813084006309509)
[2024-12-17 01:42:07,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:07,618][root][INFO] - Training Epoch: 1/2, step 1415/7134 completed (loss: 0.13317997753620148, acc: 0.9718543291091919)
[2024-12-17 01:42:07,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:07,988][root][INFO] - Training Epoch: 1/2, step 1416/7134 completed (loss: 0.12158533185720444, acc: 0.9691011309623718)
[2024-12-17 01:42:08,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:08,313][root][INFO] - Training Epoch: 1/2, step 1417/7134 completed (loss: 0.09294351935386658, acc: 0.9778911471366882)
[2024-12-17 01:42:08,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:08,619][root][INFO] - Training Epoch: 1/2, step 1418/7134 completed (loss: 0.051917314529418945, acc: 0.9904580116271973)
[2024-12-17 01:42:08,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:09,010][root][INFO] - Training Epoch: 1/2, step 1419/7134 completed (loss: 0.08887042105197906, acc: 0.9811066389083862)
[2024-12-17 01:42:09,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:09,354][root][INFO] - Training Epoch: 1/2, step 1420/7134 completed (loss: 0.09060759097337723, acc: 0.979784369468689)
[2024-12-17 01:42:09,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:09,690][root][INFO] - Training Epoch: 1/2, step 1421/7134 completed (loss: 0.09631620347499847, acc: 0.9727563858032227)
[2024-12-17 01:42:09,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:10,073][root][INFO] - Training Epoch: 1/2, step 1422/7134 completed (loss: 0.18360990285873413, acc: 0.9586894512176514)
[2024-12-17 01:42:10,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:10,430][root][INFO] - Training Epoch: 1/2, step 1423/7134 completed (loss: 0.17221230268478394, acc: 0.9551020264625549)
[2024-12-17 01:42:10,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:10,766][root][INFO] - Training Epoch: 1/2, step 1424/7134 completed (loss: 0.2702183425426483, acc: 0.9429658055305481)
[2024-12-17 01:42:10,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:11,106][root][INFO] - Training Epoch: 1/2, step 1425/7134 completed (loss: 0.10379600524902344, acc: 0.9701937437057495)
[2024-12-17 01:42:11,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:11,512][root][INFO] - Training Epoch: 1/2, step 1426/7134 completed (loss: 0.14477001130580902, acc: 0.9601542353630066)
[2024-12-17 01:42:11,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:11,870][root][INFO] - Training Epoch: 1/2, step 1427/7134 completed (loss: 0.16609127819538116, acc: 0.9591315388679504)
[2024-12-17 01:42:12,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:12,216][root][INFO] - Training Epoch: 1/2, step 1428/7134 completed (loss: 0.5714043378829956, acc: 0.8821752071380615)
[2024-12-17 01:42:12,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:12,587][root][INFO] - Training Epoch: 1/2, step 1429/7134 completed (loss: 0.1095290258526802, acc: 0.9812889695167542)
[2024-12-17 01:42:12,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:12,955][root][INFO] - Training Epoch: 1/2, step 1430/7134 completed (loss: 0.186640664935112, acc: 0.9630996584892273)
[2024-12-17 01:42:13,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:13,297][root][INFO] - Training Epoch: 1/2, step 1431/7134 completed (loss: 0.15770865976810455, acc: 0.9579375982284546)
[2024-12-17 01:42:13,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:13,664][root][INFO] - Training Epoch: 1/2, step 1432/7134 completed (loss: 0.11113210022449493, acc: 0.9755469560623169)
[2024-12-17 01:42:13,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:14,012][root][INFO] - Training Epoch: 1/2, step 1433/7134 completed (loss: 0.17866118252277374, acc: 0.9476439952850342)
[2024-12-17 01:42:14,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:14,347][root][INFO] - Training Epoch: 1/2, step 1434/7134 completed (loss: 0.17143242061138153, acc: 0.9518072009086609)
[2024-12-17 01:42:14,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:14,706][root][INFO] - Training Epoch: 1/2, step 1435/7134 completed (loss: 0.19208891689777374, acc: 0.9501466155052185)
[2024-12-17 01:42:14,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:15,053][root][INFO] - Training Epoch: 1/2, step 1436/7134 completed (loss: 0.23042400181293488, acc: 0.9441624283790588)
[2024-12-17 01:42:15,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:15,379][root][INFO] - Training Epoch: 1/2, step 1437/7134 completed (loss: 0.17419175803661346, acc: 0.956824541091919)
[2024-12-17 01:42:15,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:15,734][root][INFO] - Training Epoch: 1/2, step 1438/7134 completed (loss: 0.22595445811748505, acc: 0.947445273399353)
[2024-12-17 01:42:15,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:16,087][root][INFO] - Training Epoch: 1/2, step 1439/7134 completed (loss: 0.22133024036884308, acc: 0.9573283791542053)
[2024-12-17 01:42:16,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:16,406][root][INFO] - Training Epoch: 1/2, step 1440/7134 completed (loss: 0.24127838015556335, acc: 0.9328743815422058)
[2024-12-17 01:42:16,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:16,754][root][INFO] - Training Epoch: 1/2, step 1441/7134 completed (loss: 0.12319408357143402, acc: 0.9648093581199646)
[2024-12-17 01:42:16,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:17,046][root][INFO] - Training Epoch: 1/2, step 1442/7134 completed (loss: 0.16287963092327118, acc: 0.9665071964263916)
[2024-12-17 01:42:17,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:17,386][root][INFO] - Training Epoch: 1/2, step 1443/7134 completed (loss: 0.21868759393692017, acc: 0.9507908821105957)
[2024-12-17 01:42:17,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:17,733][root][INFO] - Training Epoch: 1/2, step 1444/7134 completed (loss: 0.15045665204524994, acc: 0.9649805426597595)
[2024-12-17 01:42:17,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:18,086][root][INFO] - Training Epoch: 1/2, step 1445/7134 completed (loss: 0.20778809487819672, acc: 0.9517470598220825)
[2024-12-17 01:42:18,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:18,419][root][INFO] - Training Epoch: 1/2, step 1446/7134 completed (loss: 0.16136252880096436, acc: 0.9516358375549316)
[2024-12-17 01:42:18,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:18,753][root][INFO] - Training Epoch: 1/2, step 1447/7134 completed (loss: 0.1911933571100235, acc: 0.9460992813110352)
[2024-12-17 01:42:18,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:19,056][root][INFO] - Training Epoch: 1/2, step 1448/7134 completed (loss: 0.18745176494121552, acc: 0.9364407062530518)
[2024-12-17 01:42:19,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:19,402][root][INFO] - Training Epoch: 1/2, step 1449/7134 completed (loss: 0.2270422726869583, acc: 0.9367977380752563)
[2024-12-17 01:42:19,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:19,717][root][INFO] - Training Epoch: 1/2, step 1450/7134 completed (loss: 0.15950371325016022, acc: 0.9637155532836914)
[2024-12-17 01:42:19,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:20,035][root][INFO] - Training Epoch: 1/2, step 1451/7134 completed (loss: 0.12482278048992157, acc: 0.9604685306549072)
[2024-12-17 01:42:20,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:20,367][root][INFO] - Training Epoch: 1/2, step 1452/7134 completed (loss: 0.16966921091079712, acc: 0.9635416865348816)
[2024-12-17 01:42:20,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:20,700][root][INFO] - Training Epoch: 1/2, step 1453/7134 completed (loss: 0.16818246245384216, acc: 0.9651346802711487)
[2024-12-17 01:42:20,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:21,061][root][INFO] - Training Epoch: 1/2, step 1454/7134 completed (loss: 0.20010994374752045, acc: 0.9609690308570862)
[2024-12-17 01:42:21,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:21,393][root][INFO] - Training Epoch: 1/2, step 1455/7134 completed (loss: 0.1655225306749344, acc: 0.9688073396682739)
[2024-12-17 01:42:21,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:21,739][root][INFO] - Training Epoch: 1/2, step 1456/7134 completed (loss: 0.08896395564079285, acc: 0.9759825468063354)
[2024-12-17 01:42:21,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:22,083][root][INFO] - Training Epoch: 1/2, step 1457/7134 completed (loss: 0.08723888546228409, acc: 0.9767441749572754)
[2024-12-17 01:42:22,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:22,439][root][INFO] - Training Epoch: 1/2, step 1458/7134 completed (loss: 0.079862080514431, acc: 0.9808542132377625)
[2024-12-17 01:42:22,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:22,773][root][INFO] - Training Epoch: 1/2, step 1459/7134 completed (loss: 0.15545953810214996, acc: 0.9591474533081055)
[2024-12-17 01:42:22,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:23,130][root][INFO] - Training Epoch: 1/2, step 1460/7134 completed (loss: 0.25744765996932983, acc: 0.932894766330719)
[2024-12-17 01:42:23,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:23,460][root][INFO] - Training Epoch: 1/2, step 1461/7134 completed (loss: 0.16764017939567566, acc: 0.9569377899169922)
[2024-12-17 01:42:23,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:23,818][root][INFO] - Training Epoch: 1/2, step 1462/7134 completed (loss: 0.3090026080608368, acc: 0.942460298538208)
[2024-12-17 01:42:23,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:24,155][root][INFO] - Training Epoch: 1/2, step 1463/7134 completed (loss: 0.28059306740760803, acc: 0.9344490766525269)
[2024-12-17 01:42:24,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:24,525][root][INFO] - Training Epoch: 1/2, step 1464/7134 completed (loss: 0.36144503951072693, acc: 0.9189189076423645)
[2024-12-17 01:42:24,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:24,865][root][INFO] - Training Epoch: 1/2, step 1465/7134 completed (loss: 0.2356344759464264, acc: 0.9435736536979675)
[2024-12-17 01:42:25,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:25,255][root][INFO] - Training Epoch: 1/2, step 1466/7134 completed (loss: 0.21443481743335724, acc: 0.9532577991485596)
[2024-12-17 01:42:25,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:25,600][root][INFO] - Training Epoch: 1/2, step 1467/7134 completed (loss: 0.14125372469425201, acc: 0.9610950946807861)
[2024-12-17 01:42:25,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:25,961][root][INFO] - Training Epoch: 1/2, step 1468/7134 completed (loss: 0.18098770081996918, acc: 0.95772784948349)
[2024-12-17 01:42:26,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:26,304][root][INFO] - Training Epoch: 1/2, step 1469/7134 completed (loss: 0.10366485267877579, acc: 0.9798115491867065)
[2024-12-17 01:42:26,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:26,627][root][INFO] - Training Epoch: 1/2, step 1470/7134 completed (loss: 0.15834353864192963, acc: 0.9609826803207397)
[2024-12-17 01:42:26,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:26,962][root][INFO] - Training Epoch: 1/2, step 1471/7134 completed (loss: 0.13540267944335938, acc: 0.9715808033943176)
[2024-12-17 01:42:27,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:27,328][root][INFO] - Training Epoch: 1/2, step 1472/7134 completed (loss: 0.13082800805568695, acc: 0.9723270535469055)
[2024-12-17 01:42:27,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:27,669][root][INFO] - Training Epoch: 1/2, step 1473/7134 completed (loss: 0.1838107407093048, acc: 0.9584569931030273)
[2024-12-17 01:42:27,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:27,986][root][INFO] - Training Epoch: 1/2, step 1474/7134 completed (loss: 0.28441739082336426, acc: 0.936241626739502)
[2024-12-17 01:42:28,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:28,329][root][INFO] - Training Epoch: 1/2, step 1475/7134 completed (loss: 0.1674605756998062, acc: 0.9643799662590027)
[2024-12-17 01:42:28,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:28,660][root][INFO] - Training Epoch: 1/2, step 1476/7134 completed (loss: 0.1412680745124817, acc: 0.967391312122345)
[2024-12-17 01:42:28,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:29,003][root][INFO] - Training Epoch: 1/2, step 1477/7134 completed (loss: 0.1603025496006012, acc: 0.9616056084632874)
[2024-12-17 01:42:29,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:29,356][root][INFO] - Training Epoch: 1/2, step 1478/7134 completed (loss: 0.12605716288089752, acc: 0.9649634957313538)
[2024-12-17 01:42:29,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:29,700][root][INFO] - Training Epoch: 1/2, step 1479/7134 completed (loss: 0.20086224377155304, acc: 0.9525862336158752)
[2024-12-17 01:42:29,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:30,048][root][INFO] - Training Epoch: 1/2, step 1480/7134 completed (loss: 0.09608727693557739, acc: 0.9766233563423157)
[2024-12-17 01:42:30,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:30,407][root][INFO] - Training Epoch: 1/2, step 1481/7134 completed (loss: 0.15933763980865479, acc: 0.9618421196937561)
[2024-12-17 01:42:30,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:30,760][root][INFO] - Training Epoch: 1/2, step 1482/7134 completed (loss: 0.13521920144557953, acc: 0.96875)
[2024-12-17 01:42:30,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:31,088][root][INFO] - Training Epoch: 1/2, step 1483/7134 completed (loss: 0.10621768236160278, acc: 0.9731437563896179)
[2024-12-17 01:42:31,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:31,430][root][INFO] - Training Epoch: 1/2, step 1484/7134 completed (loss: 0.1801144778728485, acc: 0.9552023410797119)
[2024-12-17 01:42:31,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:31,764][root][INFO] - Training Epoch: 1/2, step 1485/7134 completed (loss: 0.12808838486671448, acc: 0.9734513163566589)
[2024-12-17 01:42:31,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:32,095][root][INFO] - Training Epoch: 1/2, step 1486/7134 completed (loss: 0.10306262224912643, acc: 0.9783491492271423)
[2024-12-17 01:42:32,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:32,439][root][INFO] - Training Epoch: 1/2, step 1487/7134 completed (loss: 0.1106872633099556, acc: 0.9660130739212036)
[2024-12-17 01:42:32,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:32,812][root][INFO] - Training Epoch: 1/2, step 1488/7134 completed (loss: 0.15264122188091278, acc: 0.9625668525695801)
[2024-12-17 01:42:32,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:33,153][root][INFO] - Training Epoch: 1/2, step 1489/7134 completed (loss: 0.1544685661792755, acc: 0.9579439163208008)
[2024-12-17 01:42:33,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:33,526][root][INFO] - Training Epoch: 1/2, step 1490/7134 completed (loss: 0.13176961243152618, acc: 0.961904764175415)
[2024-12-17 01:42:33,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:33,870][root][INFO] - Training Epoch: 1/2, step 1491/7134 completed (loss: 0.09796824306249619, acc: 0.9724137783050537)
[2024-12-17 01:42:33,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:34,214][root][INFO] - Training Epoch: 1/2, step 1492/7134 completed (loss: 0.12782299518585205, acc: 0.9698376059532166)
[2024-12-17 01:42:34,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:34,555][root][INFO] - Training Epoch: 1/2, step 1493/7134 completed (loss: 0.15568731725215912, acc: 0.9596773982048035)
[2024-12-17 01:42:34,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:34,912][root][INFO] - Training Epoch: 1/2, step 1494/7134 completed (loss: 0.12737928330898285, acc: 0.9683698415756226)
[2024-12-17 01:42:35,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:35,255][root][INFO] - Training Epoch: 1/2, step 1495/7134 completed (loss: 0.16670960187911987, acc: 0.9497005939483643)
[2024-12-17 01:42:35,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:35,605][root][INFO] - Training Epoch: 1/2, step 1496/7134 completed (loss: 0.1368088722229004, acc: 0.9743589758872986)
[2024-12-17 01:42:35,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:35,975][root][INFO] - Training Epoch: 1/2, step 1497/7134 completed (loss: 0.1152954250574112, acc: 0.9660633206367493)
[2024-12-17 01:42:36,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:36,287][root][INFO] - Training Epoch: 1/2, step 1498/7134 completed (loss: 0.11201108247041702, acc: 0.9710144996643066)
[2024-12-17 01:42:36,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:36,652][root][INFO] - Training Epoch: 1/2, step 1499/7134 completed (loss: 0.08718365430831909, acc: 0.9762752056121826)
[2024-12-17 01:42:36,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:36,960][root][INFO] - Training Epoch: 1/2, step 1500/7134 completed (loss: 0.11241374909877777, acc: 0.9718543291091919)
[2024-12-17 01:42:37,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:37,314][root][INFO] - Training Epoch: 1/2, step 1501/7134 completed (loss: 0.16378729045391083, acc: 0.9601770043373108)
[2024-12-17 01:42:37,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:37,665][root][INFO] - Training Epoch: 1/2, step 1502/7134 completed (loss: 0.13832752406597137, acc: 0.9673055410385132)
[2024-12-17 01:42:37,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:37,983][root][INFO] - Training Epoch: 1/2, step 1503/7134 completed (loss: 0.1797965168952942, acc: 0.9644886255264282)
[2024-12-17 01:42:38,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:38,337][root][INFO] - Training Epoch: 1/2, step 1504/7134 completed (loss: 0.10809218883514404, acc: 0.9723270535469055)
[2024-12-17 01:42:38,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:38,672][root][INFO] - Training Epoch: 1/2, step 1505/7134 completed (loss: 0.11232881247997284, acc: 0.9735202789306641)
[2024-12-17 01:42:38,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:39,019][root][INFO] - Training Epoch: 1/2, step 1506/7134 completed (loss: 0.1807928830385208, acc: 0.9528875350952148)
[2024-12-17 01:42:39,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:39,362][root][INFO] - Training Epoch: 1/2, step 1507/7134 completed (loss: 0.09264218807220459, acc: 0.9751309156417847)
[2024-12-17 01:42:39,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:39,721][root][INFO] - Training Epoch: 1/2, step 1508/7134 completed (loss: 0.09472477436065674, acc: 0.9759299755096436)
[2024-12-17 01:42:39,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:40,064][root][INFO] - Training Epoch: 1/2, step 1509/7134 completed (loss: 0.12090630829334259, acc: 0.9677870869636536)
[2024-12-17 01:42:40,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:40,417][root][INFO] - Training Epoch: 1/2, step 1510/7134 completed (loss: 0.362568736076355, acc: 0.9399999976158142)
[2024-12-17 01:42:40,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:40,757][root][INFO] - Training Epoch: 1/2, step 1511/7134 completed (loss: 0.23231348395347595, acc: 0.9347517490386963)
[2024-12-17 01:42:40,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:41,106][root][INFO] - Training Epoch: 1/2, step 1512/7134 completed (loss: 0.11889828741550446, acc: 0.9741247892379761)
[2024-12-17 01:42:41,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:41,436][root][INFO] - Training Epoch: 1/2, step 1513/7134 completed (loss: 0.07905381172895432, acc: 0.976190447807312)
[2024-12-17 01:42:41,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:41,791][root][INFO] - Training Epoch: 1/2, step 1514/7134 completed (loss: 0.16827663779258728, acc: 0.95652174949646)
[2024-12-17 01:42:41,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:42,141][root][INFO] - Training Epoch: 1/2, step 1515/7134 completed (loss: 0.1921902894973755, acc: 0.9509345889091492)
[2024-12-17 01:42:42,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:42,364][root][INFO] - Training Epoch: 1/2, step 1516/7134 completed (loss: 0.19714927673339844, acc: 0.945868968963623)
[2024-12-17 01:42:42,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:42,685][root][INFO] - Training Epoch: 1/2, step 1517/7134 completed (loss: 0.25426384806632996, acc: 0.9369747638702393)
[2024-12-17 01:42:42,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:42,995][root][INFO] - Training Epoch: 1/2, step 1518/7134 completed (loss: 0.1847989559173584, acc: 0.9638554453849792)
[2024-12-17 01:42:43,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:43,357][root][INFO] - Training Epoch: 1/2, step 1519/7134 completed (loss: 0.14219312369823456, acc: 0.9723502397537231)
[2024-12-17 01:42:43,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:43,712][root][INFO] - Training Epoch: 1/2, step 1520/7134 completed (loss: 0.20080435276031494, acc: 0.948517918586731)
[2024-12-17 01:42:43,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:44,176][root][INFO] - Training Epoch: 1/2, step 1521/7134 completed (loss: 0.25885558128356934, acc: 0.916201114654541)
[2024-12-17 01:42:44,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:44,514][root][INFO] - Training Epoch: 1/2, step 1522/7134 completed (loss: 0.3319719433784485, acc: 0.9152215719223022)
[2024-12-17 01:42:44,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:44,843][root][INFO] - Training Epoch: 1/2, step 1523/7134 completed (loss: 0.2901592552661896, acc: 0.9190405011177063)
[2024-12-17 01:42:44,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:45,129][root][INFO] - Training Epoch: 1/2, step 1524/7134 completed (loss: 0.1488862931728363, acc: 0.9731543660163879)
[2024-12-17 01:42:45,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:45,471][root][INFO] - Training Epoch: 1/2, step 1525/7134 completed (loss: 0.21716813743114471, acc: 0.929864227771759)
[2024-12-17 01:42:45,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:45,841][root][INFO] - Training Epoch: 1/2, step 1526/7134 completed (loss: 0.2297743260860443, acc: 0.9317851662635803)
[2024-12-17 01:42:45,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:46,218][root][INFO] - Training Epoch: 1/2, step 1527/7134 completed (loss: 0.40395233035087585, acc: 0.8964941501617432)
[2024-12-17 01:42:46,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:46,604][root][INFO] - Training Epoch: 1/2, step 1528/7134 completed (loss: 0.2507523000240326, acc: 0.9259259104728699)
[2024-12-17 01:42:46,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:46,959][root][INFO] - Training Epoch: 1/2, step 1529/7134 completed (loss: 0.21533092856407166, acc: 0.940546989440918)
[2024-12-17 01:42:47,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:47,278][root][INFO] - Training Epoch: 1/2, step 1530/7134 completed (loss: 0.22524958848953247, acc: 0.9349904656410217)
[2024-12-17 01:42:47,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:47,594][root][INFO] - Training Epoch: 1/2, step 1531/7134 completed (loss: 0.37715962529182434, acc: 0.9042553305625916)
[2024-12-17 01:42:47,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:47,976][root][INFO] - Training Epoch: 1/2, step 1532/7134 completed (loss: 0.1870318055152893, acc: 0.954913318157196)
[2024-12-17 01:42:48,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:48,311][root][INFO] - Training Epoch: 1/2, step 1533/7134 completed (loss: 0.14561720192432404, acc: 0.9598893523216248)
[2024-12-17 01:42:48,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:48,662][root][INFO] - Training Epoch: 1/2, step 1534/7134 completed (loss: 0.1398647427558899, acc: 0.9653739333152771)
[2024-12-17 01:42:48,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:49,071][root][INFO] - Training Epoch: 1/2, step 1535/7134 completed (loss: 0.12593507766723633, acc: 0.9676646590232849)
[2024-12-17 01:42:49,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:49,420][root][INFO] - Training Epoch: 1/2, step 1536/7134 completed (loss: 0.11647918075323105, acc: 0.9646017551422119)
[2024-12-17 01:42:49,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:49,756][root][INFO] - Training Epoch: 1/2, step 1537/7134 completed (loss: 0.1995140016078949, acc: 0.9541884660720825)
[2024-12-17 01:42:49,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:50,098][root][INFO] - Training Epoch: 1/2, step 1538/7134 completed (loss: 0.1645192801952362, acc: 0.9615877270698547)
[2024-12-17 01:42:50,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:50,448][root][INFO] - Training Epoch: 1/2, step 1539/7134 completed (loss: 0.16763152182102203, acc: 0.9512516260147095)
[2024-12-17 01:42:50,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:50,800][root][INFO] - Training Epoch: 1/2, step 1540/7134 completed (loss: 0.1367097645998001, acc: 0.9638069868087769)
[2024-12-17 01:42:50,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:51,149][root][INFO] - Training Epoch: 1/2, step 1541/7134 completed (loss: 0.22898410260677338, acc: 0.9509434103965759)
[2024-12-17 01:42:51,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:51,523][root][INFO] - Training Epoch: 1/2, step 1542/7134 completed (loss: 0.18329302966594696, acc: 0.9595687389373779)
[2024-12-17 01:42:51,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:51,872][root][INFO] - Training Epoch: 1/2, step 1543/7134 completed (loss: 0.09123890101909637, acc: 0.9825136661529541)
[2024-12-17 01:42:51,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:52,231][root][INFO] - Training Epoch: 1/2, step 1544/7134 completed (loss: 0.13758496940135956, acc: 0.9648058414459229)
[2024-12-17 01:42:52,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:52,548][root][INFO] - Training Epoch: 1/2, step 1545/7134 completed (loss: 0.08583758771419525, acc: 0.9698708653450012)
[2024-12-17 01:42:52,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:52,915][root][INFO] - Training Epoch: 1/2, step 1546/7134 completed (loss: 0.21203967928886414, acc: 0.946704089641571)
[2024-12-17 01:42:53,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:53,262][root][INFO] - Training Epoch: 1/2, step 1547/7134 completed (loss: 0.14554964005947113, acc: 0.9567164182662964)
[2024-12-17 01:42:53,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:53,621][root][INFO] - Training Epoch: 1/2, step 1548/7134 completed (loss: 0.14514553546905518, acc: 0.9624573588371277)
[2024-12-17 01:42:53,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:53,981][root][INFO] - Training Epoch: 1/2, step 1549/7134 completed (loss: 0.11974538117647171, acc: 0.961240291595459)
[2024-12-17 01:42:54,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:54,334][root][INFO] - Training Epoch: 1/2, step 1550/7134 completed (loss: 0.10826205462217331, acc: 0.9708491563796997)
[2024-12-17 01:42:54,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:54,663][root][INFO] - Training Epoch: 1/2, step 1551/7134 completed (loss: 0.1405767947435379, acc: 0.9584415555000305)
[2024-12-17 01:42:54,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:55,027][root][INFO] - Training Epoch: 1/2, step 1552/7134 completed (loss: 0.1718316227197647, acc: 0.9568965435028076)
[2024-12-17 01:42:55,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:55,346][root][INFO] - Training Epoch: 1/2, step 1553/7134 completed (loss: 0.10867703706026077, acc: 0.9726918339729309)
[2024-12-17 01:42:55,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:55,711][root][INFO] - Training Epoch: 1/2, step 1554/7134 completed (loss: 0.11107055097818375, acc: 0.9661781191825867)
[2024-12-17 01:42:55,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:56,056][root][INFO] - Training Epoch: 1/2, step 1555/7134 completed (loss: 0.11044985800981522, acc: 0.9742441177368164)
[2024-12-17 01:42:56,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:56,410][root][INFO] - Training Epoch: 1/2, step 1556/7134 completed (loss: 0.11548536270856857, acc: 0.9741480350494385)
[2024-12-17 01:42:56,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:56,771][root][INFO] - Training Epoch: 1/2, step 1557/7134 completed (loss: 0.1153920441865921, acc: 0.9697986841201782)
[2024-12-17 01:42:56,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:57,098][root][INFO] - Training Epoch: 1/2, step 1558/7134 completed (loss: 0.13233400881290436, acc: 0.9648382663726807)
[2024-12-17 01:42:57,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:57,440][root][INFO] - Training Epoch: 1/2, step 1559/7134 completed (loss: 0.13742417097091675, acc: 0.9585006833076477)
[2024-12-17 01:42:57,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:57,788][root][INFO] - Training Epoch: 1/2, step 1560/7134 completed (loss: 0.31262919306755066, acc: 0.9275730848312378)
[2024-12-17 01:42:57,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:58,141][root][INFO] - Training Epoch: 1/2, step 1561/7134 completed (loss: 0.24571219086647034, acc: 0.9425785541534424)
[2024-12-17 01:42:58,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:58,488][root][INFO] - Training Epoch: 1/2, step 1562/7134 completed (loss: 0.17698627710342407, acc: 0.9652042388916016)
[2024-12-17 01:42:58,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:58,825][root][INFO] - Training Epoch: 1/2, step 1563/7134 completed (loss: 0.18226991593837738, acc: 0.9497143030166626)
[2024-12-17 01:42:58,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:59,170][root][INFO] - Training Epoch: 1/2, step 1564/7134 completed (loss: 0.2351377308368683, acc: 0.9467821717262268)
[2024-12-17 01:42:59,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:59,487][root][INFO] - Training Epoch: 1/2, step 1565/7134 completed (loss: 0.22783371806144714, acc: 0.9478991627693176)
[2024-12-17 01:42:59,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:59,813][root][INFO] - Training Epoch: 1/2, step 1566/7134 completed (loss: 0.22014746069908142, acc: 0.9411764740943909)
[2024-12-17 01:42:59,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:00,200][root][INFO] - Training Epoch: 1/2, step 1567/7134 completed (loss: 0.19724301993846893, acc: 0.9451371431350708)
[2024-12-17 01:43:00,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:00,573][root][INFO] - Training Epoch: 1/2, step 1568/7134 completed (loss: 0.20093874633312225, acc: 0.9502958655357361)
[2024-12-17 01:43:00,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:00,919][root][INFO] - Training Epoch: 1/2, step 1569/7134 completed (loss: 0.25052589178085327, acc: 0.9459064602851868)
[2024-12-17 01:43:01,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:01,286][root][INFO] - Training Epoch: 1/2, step 1570/7134 completed (loss: 0.22197726368904114, acc: 0.9426681399345398)
[2024-12-17 01:43:01,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:01,622][root][INFO] - Training Epoch: 1/2, step 1571/7134 completed (loss: 0.23210647702217102, acc: 0.9466192126274109)
[2024-12-17 01:43:01,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:01,994][root][INFO] - Training Epoch: 1/2, step 1572/7134 completed (loss: 0.19669343531131744, acc: 0.9575971961021423)
[2024-12-17 01:43:02,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:02,318][root][INFO] - Training Epoch: 1/2, step 1573/7134 completed (loss: 0.16418080031871796, acc: 0.9550072550773621)
[2024-12-17 01:43:02,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:02,680][root][INFO] - Training Epoch: 1/2, step 1574/7134 completed (loss: 0.20403248071670532, acc: 0.9551422595977783)
[2024-12-17 01:43:02,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:03,016][root][INFO] - Training Epoch: 1/2, step 1575/7134 completed (loss: 0.20907197892665863, acc: 0.9512194991111755)
[2024-12-17 01:43:03,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:03,360][root][INFO] - Training Epoch: 1/2, step 1576/7134 completed (loss: 0.1772792637348175, acc: 0.9626168012619019)
[2024-12-17 01:43:03,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:03,722][root][INFO] - Training Epoch: 1/2, step 1577/7134 completed (loss: 0.18948319554328918, acc: 0.9528857469558716)
[2024-12-17 01:43:03,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:04,067][root][INFO] - Training Epoch: 1/2, step 1578/7134 completed (loss: 0.17073722183704376, acc: 0.9431664347648621)
[2024-12-17 01:43:04,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:04,440][root][INFO] - Training Epoch: 1/2, step 1579/7134 completed (loss: 0.14816206693649292, acc: 0.9596773982048035)
[2024-12-17 01:43:04,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:04,791][root][INFO] - Training Epoch: 1/2, step 1580/7134 completed (loss: 0.23723773658275604, acc: 0.9394273161888123)
[2024-12-17 01:43:04,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:05,092][root][INFO] - Training Epoch: 1/2, step 1581/7134 completed (loss: 0.2825104892253876, acc: 0.9243826866149902)
[2024-12-17 01:43:05,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:05,435][root][INFO] - Training Epoch: 1/2, step 1582/7134 completed (loss: 0.23989330232143402, acc: 0.9358372688293457)
[2024-12-17 01:43:05,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:05,761][root][INFO] - Training Epoch: 1/2, step 1583/7134 completed (loss: 0.15079669654369354, acc: 0.9570200443267822)
[2024-12-17 01:43:05,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:06,133][root][INFO] - Training Epoch: 1/2, step 1584/7134 completed (loss: 0.1670445203781128, acc: 0.9528908133506775)
[2024-12-17 01:43:06,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:06,475][root][INFO] - Training Epoch: 1/2, step 1585/7134 completed (loss: 0.14922674000263214, acc: 0.9575971961021423)
[2024-12-17 01:43:06,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:06,820][root][INFO] - Training Epoch: 1/2, step 1586/7134 completed (loss: 0.2070251852273941, acc: 0.9453681707382202)
[2024-12-17 01:43:06,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:07,163][root][INFO] - Training Epoch: 1/2, step 1587/7134 completed (loss: 0.13564829528331757, acc: 0.9638932347297668)
[2024-12-17 01:43:07,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:07,511][root][INFO] - Training Epoch: 1/2, step 1588/7134 completed (loss: 0.1185871809720993, acc: 0.9733688235282898)
[2024-12-17 01:43:07,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:07,846][root][INFO] - Training Epoch: 1/2, step 1589/7134 completed (loss: 0.11322575062513351, acc: 0.9659949541091919)
[2024-12-17 01:43:07,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:08,168][root][INFO] - Training Epoch: 1/2, step 1590/7134 completed (loss: 0.10683877766132355, acc: 0.9712991118431091)
[2024-12-17 01:43:08,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:08,483][root][INFO] - Training Epoch: 1/2, step 1591/7134 completed (loss: 0.08646945655345917, acc: 0.9780033826828003)
[2024-12-17 01:43:08,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:08,838][root][INFO] - Training Epoch: 1/2, step 1592/7134 completed (loss: 0.13925310969352722, acc: 0.9557774662971497)
[2024-12-17 01:43:08,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:09,207][root][INFO] - Training Epoch: 1/2, step 1593/7134 completed (loss: 0.12090642005205154, acc: 0.9747126698493958)
[2024-12-17 01:43:09,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:09,541][root][INFO] - Training Epoch: 1/2, step 1594/7134 completed (loss: 0.09563276916742325, acc: 0.968595027923584)
[2024-12-17 01:43:09,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:09,879][root][INFO] - Training Epoch: 1/2, step 1595/7134 completed (loss: 0.1002851203083992, acc: 0.9731183052062988)
[2024-12-17 01:43:09,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:10,212][root][INFO] - Training Epoch: 1/2, step 1596/7134 completed (loss: 0.16509723663330078, acc: 0.965354323387146)
[2024-12-17 01:43:10,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:10,546][root][INFO] - Training Epoch: 1/2, step 1597/7134 completed (loss: 0.06529651582241058, acc: 0.982807993888855)
[2024-12-17 01:43:10,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:10,860][root][INFO] - Training Epoch: 1/2, step 1598/7134 completed (loss: 0.1919437050819397, acc: 0.9540917873382568)
[2024-12-17 01:43:10,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:11,194][root][INFO] - Training Epoch: 1/2, step 1599/7134 completed (loss: 0.23669002950191498, acc: 0.9487603306770325)
[2024-12-17 01:43:11,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:11,556][root][INFO] - Training Epoch: 1/2, step 1600/7134 completed (loss: 0.14806856215000153, acc: 0.9642032384872437)
[2024-12-17 01:43:11,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:11,882][root][INFO] - Training Epoch: 1/2, step 1601/7134 completed (loss: 0.0777420699596405, acc: 0.9807427525520325)
[2024-12-17 01:43:12,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:12,237][root][INFO] - Training Epoch: 1/2, step 1602/7134 completed (loss: 0.13381826877593994, acc: 0.9698340892791748)
[2024-12-17 01:43:12,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:12,547][root][INFO] - Training Epoch: 1/2, step 1603/7134 completed (loss: 0.1567026972770691, acc: 0.9769821166992188)
[2024-12-17 01:43:12,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:12,893][root][INFO] - Training Epoch: 1/2, step 1604/7134 completed (loss: 0.08900205045938492, acc: 0.9814323782920837)
[2024-12-17 01:43:13,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:13,227][root][INFO] - Training Epoch: 1/2, step 1605/7134 completed (loss: 0.15229038894176483, acc: 0.9634941220283508)
[2024-12-17 01:43:13,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:13,551][root][INFO] - Training Epoch: 1/2, step 1606/7134 completed (loss: 0.0766400694847107, acc: 0.9846860766410828)
[2024-12-17 01:43:13,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:13,867][root][INFO] - Training Epoch: 1/2, step 1607/7134 completed (loss: 0.07283960282802582, acc: 0.9837067127227783)
[2024-12-17 01:43:14,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:14,230][root][INFO] - Training Epoch: 1/2, step 1608/7134 completed (loss: 0.07886109501123428, acc: 0.9814126491546631)
[2024-12-17 01:43:14,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:14,577][root][INFO] - Training Epoch: 1/2, step 1609/7134 completed (loss: 0.10246997326612473, acc: 0.9735202789306641)
[2024-12-17 01:43:14,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:14,904][root][INFO] - Training Epoch: 1/2, step 1610/7134 completed (loss: 0.1145433709025383, acc: 0.9716193675994873)
[2024-12-17 01:43:15,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:15,234][root][INFO] - Training Epoch: 1/2, step 1611/7134 completed (loss: 0.14174914360046387, acc: 0.9788359999656677)
[2024-12-17 01:43:15,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:15,570][root][INFO] - Training Epoch: 1/2, step 1612/7134 completed (loss: 0.15686072409152985, acc: 0.9720101952552795)
[2024-12-17 01:43:15,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:15,900][root][INFO] - Training Epoch: 1/2, step 1613/7134 completed (loss: 0.1300666630268097, acc: 0.9710144996643066)
[2024-12-17 01:43:16,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:16,236][root][INFO] - Training Epoch: 1/2, step 1614/7134 completed (loss: 0.15278205275535583, acc: 0.9711664319038391)
[2024-12-17 01:43:16,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:16,610][root][INFO] - Training Epoch: 1/2, step 1615/7134 completed (loss: 0.12634168565273285, acc: 0.9651006460189819)
[2024-12-17 01:43:16,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:16,949][root][INFO] - Training Epoch: 1/2, step 1616/7134 completed (loss: 0.09171827137470245, acc: 0.9783549904823303)
[2024-12-17 01:43:17,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:17,280][root][INFO] - Training Epoch: 1/2, step 1617/7134 completed (loss: 0.1275060772895813, acc: 0.9672386646270752)
[2024-12-17 01:43:17,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:17,610][root][INFO] - Training Epoch: 1/2, step 1618/7134 completed (loss: 0.1821800172328949, acc: 0.9508771896362305)
[2024-12-17 01:43:17,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:17,950][root][INFO] - Training Epoch: 1/2, step 1619/7134 completed (loss: 0.1344449520111084, acc: 0.9604904651641846)
[2024-12-17 01:43:18,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:18,300][root][INFO] - Training Epoch: 1/2, step 1620/7134 completed (loss: 0.17184476554393768, acc: 0.9576399326324463)
[2024-12-17 01:43:18,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:18,660][root][INFO] - Training Epoch: 1/2, step 1621/7134 completed (loss: 0.16656389832496643, acc: 0.9594594836235046)
[2024-12-17 01:43:18,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:18,988][root][INFO] - Training Epoch: 1/2, step 1622/7134 completed (loss: 0.12228231132030487, acc: 0.9749303460121155)
[2024-12-17 01:43:19,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:19,341][root][INFO] - Training Epoch: 1/2, step 1623/7134 completed (loss: 0.1403806060552597, acc: 0.9719101190567017)
[2024-12-17 01:43:19,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:19,695][root][INFO] - Training Epoch: 1/2, step 1624/7134 completed (loss: 0.14570164680480957, acc: 0.9662261605262756)
[2024-12-17 01:43:19,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:20,032][root][INFO] - Training Epoch: 1/2, step 1625/7134 completed (loss: 0.11847920715808868, acc: 0.9757834672927856)
[2024-12-17 01:43:20,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:20,362][root][INFO] - Training Epoch: 1/2, step 1626/7134 completed (loss: 0.18596050143241882, acc: 0.9629629850387573)
[2024-12-17 01:43:20,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:20,679][root][INFO] - Training Epoch: 1/2, step 1627/7134 completed (loss: 0.060184333473443985, acc: 0.9872262477874756)
[2024-12-17 01:43:20,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:21,016][root][INFO] - Training Epoch: 1/2, step 1628/7134 completed (loss: 0.06006081774830818, acc: 0.9810495376586914)
[2024-12-17 01:43:21,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:21,340][root][INFO] - Training Epoch: 1/2, step 1629/7134 completed (loss: 0.09368081390857697, acc: 0.9727272987365723)
[2024-12-17 01:43:21,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:21,672][root][INFO] - Training Epoch: 1/2, step 1630/7134 completed (loss: 0.12343991547822952, acc: 0.9733333587646484)
[2024-12-17 01:43:21,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:22,007][root][INFO] - Training Epoch: 1/2, step 1631/7134 completed (loss: 0.14442496001720428, acc: 0.9678456783294678)
[2024-12-17 01:43:22,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:22,328][root][INFO] - Training Epoch: 1/2, step 1632/7134 completed (loss: 0.12379073351621628, acc: 0.9767827391624451)
[2024-12-17 01:43:22,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:22,652][root][INFO] - Training Epoch: 1/2, step 1633/7134 completed (loss: 0.08282990753650665, acc: 0.9811617136001587)
[2024-12-17 01:43:22,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:22,981][root][INFO] - Training Epoch: 1/2, step 1634/7134 completed (loss: 0.13204160332679749, acc: 0.9693721532821655)
[2024-12-17 01:43:23,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:23,296][root][INFO] - Training Epoch: 1/2, step 1635/7134 completed (loss: 0.10011066496372223, acc: 0.9633401036262512)
[2024-12-17 01:43:23,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:23,624][root][INFO] - Training Epoch: 1/2, step 1636/7134 completed (loss: 0.13583755493164062, acc: 0.9676190614700317)
[2024-12-17 01:43:23,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:23,957][root][INFO] - Training Epoch: 1/2, step 1637/7134 completed (loss: 0.11237286776304245, acc: 0.9703390002250671)
[2024-12-17 01:43:24,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:24,291][root][INFO] - Training Epoch: 1/2, step 1638/7134 completed (loss: 0.15073652565479279, acc: 0.9643463492393494)
[2024-12-17 01:43:24,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:24,632][root][INFO] - Training Epoch: 1/2, step 1639/7134 completed (loss: 0.25508931279182434, acc: 0.9350073933601379)
[2024-12-17 01:43:24,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:24,983][root][INFO] - Training Epoch: 1/2, step 1640/7134 completed (loss: 0.15244334936141968, acc: 0.9512194991111755)
[2024-12-17 01:43:25,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:25,310][root][INFO] - Training Epoch: 1/2, step 1641/7134 completed (loss: 0.13749942183494568, acc: 0.9683908224105835)
[2024-12-17 01:43:25,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:25,656][root][INFO] - Training Epoch: 1/2, step 1642/7134 completed (loss: 0.19440582394599915, acc: 0.9447368383407593)
[2024-12-17 01:43:25,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:25,975][root][INFO] - Training Epoch: 1/2, step 1643/7134 completed (loss: 0.21411897242069244, acc: 0.9584055542945862)
[2024-12-17 01:43:26,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:26,328][root][INFO] - Training Epoch: 1/2, step 1644/7134 completed (loss: 0.1762247234582901, acc: 0.9595828056335449)
[2024-12-17 01:43:26,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:26,679][root][INFO] - Training Epoch: 1/2, step 1645/7134 completed (loss: 0.17762082815170288, acc: 0.9612069129943848)
[2024-12-17 01:43:26,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:27,045][root][INFO] - Training Epoch: 1/2, step 1646/7134 completed (loss: 0.21099314093589783, acc: 0.9536741375923157)
[2024-12-17 01:43:27,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:27,391][root][INFO] - Training Epoch: 1/2, step 1647/7134 completed (loss: 0.14400064945220947, acc: 0.957446813583374)
[2024-12-17 01:43:27,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:27,739][root][INFO] - Training Epoch: 1/2, step 1648/7134 completed (loss: 0.16699713468551636, acc: 0.958776593208313)
[2024-12-17 01:43:27,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:28,087][root][INFO] - Training Epoch: 1/2, step 1649/7134 completed (loss: 0.12989261746406555, acc: 0.973362922668457)
[2024-12-17 01:43:28,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:28,447][root][INFO] - Training Epoch: 1/2, step 1650/7134 completed (loss: 0.2561562657356262, acc: 0.9317010045051575)
[2024-12-17 01:43:28,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:28,802][root][INFO] - Training Epoch: 1/2, step 1651/7134 completed (loss: 0.23015472292900085, acc: 0.9391592741012573)
[2024-12-17 01:43:28,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:29,191][root][INFO] - Training Epoch: 1/2, step 1652/7134 completed (loss: 0.09400168806314468, acc: 0.9760087132453918)
[2024-12-17 01:43:29,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:29,542][root][INFO] - Training Epoch: 1/2, step 1653/7134 completed (loss: 0.15871281921863556, acc: 0.9589040875434875)
[2024-12-17 01:43:29,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:29,932][root][INFO] - Training Epoch: 1/2, step 1654/7134 completed (loss: 0.2378649115562439, acc: 0.9449541568756104)
[2024-12-17 01:43:30,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:30,297][root][INFO] - Training Epoch: 1/2, step 1655/7134 completed (loss: 0.1987140029668808, acc: 0.9479553699493408)
[2024-12-17 01:43:30,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:30,645][root][INFO] - Training Epoch: 1/2, step 1656/7134 completed (loss: 0.2640596926212311, acc: 0.9335585832595825)
[2024-12-17 01:43:30,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:31,033][root][INFO] - Training Epoch: 1/2, step 1657/7134 completed (loss: 0.16829964518547058, acc: 0.9506849050521851)
[2024-12-17 01:43:31,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:31,400][root][INFO] - Training Epoch: 1/2, step 1658/7134 completed (loss: 0.1106162965297699, acc: 0.972449004650116)
[2024-12-17 01:43:31,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:31,757][root][INFO] - Training Epoch: 1/2, step 1659/7134 completed (loss: 0.24523977935314178, acc: 0.9336493015289307)
[2024-12-17 01:43:31,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:32,128][root][INFO] - Training Epoch: 1/2, step 1660/7134 completed (loss: 0.19384747743606567, acc: 0.9492753744125366)
[2024-12-17 01:43:32,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:32,498][root][INFO] - Training Epoch: 1/2, step 1661/7134 completed (loss: 0.1914825737476349, acc: 0.9463894963264465)
[2024-12-17 01:43:32,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:32,853][root][INFO] - Training Epoch: 1/2, step 1662/7134 completed (loss: 0.15432924032211304, acc: 0.95652174949646)
[2024-12-17 01:43:32,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:33,230][root][INFO] - Training Epoch: 1/2, step 1663/7134 completed (loss: 0.19072012603282928, acc: 0.9486125111579895)
[2024-12-17 01:43:33,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:33,576][root][INFO] - Training Epoch: 1/2, step 1664/7134 completed (loss: 0.15725135803222656, acc: 0.959475576877594)
[2024-12-17 01:43:33,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:33,929][root][INFO] - Training Epoch: 1/2, step 1665/7134 completed (loss: 0.1832207292318344, acc: 0.9525179862976074)
[2024-12-17 01:43:34,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:34,334][root][INFO] - Training Epoch: 1/2, step 1666/7134 completed (loss: 0.19693705439567566, acc: 0.9421157836914062)
[2024-12-17 01:43:34,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:34,715][root][INFO] - Training Epoch: 1/2, step 1667/7134 completed (loss: 0.2907533645629883, acc: 0.9204275608062744)
[2024-12-17 01:43:34,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:35,079][root][INFO] - Training Epoch: 1/2, step 1668/7134 completed (loss: 0.16058789193630219, acc: 0.9548319578170776)
[2024-12-17 01:43:35,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:35,487][root][INFO] - Training Epoch: 1/2, step 1669/7134 completed (loss: 0.1938503086566925, acc: 0.9510357975959778)
[2024-12-17 01:43:35,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:35,880][root][INFO] - Training Epoch: 1/2, step 1670/7134 completed (loss: 0.23803843557834625, acc: 0.9398854970932007)
[2024-12-17 01:43:35,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:36,254][root][INFO] - Training Epoch: 1/2, step 1671/7134 completed (loss: 0.1760537326335907, acc: 0.9545997381210327)
[2024-12-17 01:43:36,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:36,607][root][INFO] - Training Epoch: 1/2, step 1672/7134 completed (loss: 0.18610017001628876, acc: 0.9548472762107849)
[2024-12-17 01:43:36,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:36,963][root][INFO] - Training Epoch: 1/2, step 1673/7134 completed (loss: 0.16082094609737396, acc: 0.9556451439857483)
[2024-12-17 01:43:37,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:37,281][root][INFO] - Training Epoch: 1/2, step 1674/7134 completed (loss: 0.1754661202430725, acc: 0.9622905254364014)
[2024-12-17 01:43:37,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:37,632][root][INFO] - Training Epoch: 1/2, step 1675/7134 completed (loss: 0.20484106242656708, acc: 0.9537414908409119)
[2024-12-17 01:43:37,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:37,964][root][INFO] - Training Epoch: 1/2, step 1676/7134 completed (loss: 0.16081854701042175, acc: 0.9544199109077454)
[2024-12-17 01:43:38,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:38,287][root][INFO] - Training Epoch: 1/2, step 1677/7134 completed (loss: 0.2135712206363678, acc: 0.9443535208702087)
[2024-12-17 01:43:38,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:38,653][root][INFO] - Training Epoch: 1/2, step 1678/7134 completed (loss: 0.11111904680728912, acc: 0.9712328910827637)
[2024-12-17 01:43:38,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:38,984][root][INFO] - Training Epoch: 1/2, step 1679/7134 completed (loss: 0.17947335541248322, acc: 0.9575402736663818)
[2024-12-17 01:43:39,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:39,344][root][INFO] - Training Epoch: 1/2, step 1680/7134 completed (loss: 0.16727043688297272, acc: 0.9624664783477783)
[2024-12-17 01:43:39,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:39,678][root][INFO] - Training Epoch: 1/2, step 1681/7134 completed (loss: 0.16597050428390503, acc: 0.9644886255264282)
[2024-12-17 01:43:39,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:40,031][root][INFO] - Training Epoch: 1/2, step 1682/7134 completed (loss: 0.19853751361370087, acc: 0.9510086178779602)
[2024-12-17 01:43:40,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:40,387][root][INFO] - Training Epoch: 1/2, step 1683/7134 completed (loss: 0.15787748992443085, acc: 0.9611650705337524)
[2024-12-17 01:43:40,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:40,721][root][INFO] - Training Epoch: 1/2, step 1684/7134 completed (loss: 0.13131099939346313, acc: 0.9640411138534546)
[2024-12-17 01:43:40,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:41,058][root][INFO] - Training Epoch: 1/2, step 1685/7134 completed (loss: 0.20698288083076477, acc: 0.9568845629692078)
[2024-12-17 01:43:41,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:41,382][root][INFO] - Training Epoch: 1/2, step 1686/7134 completed (loss: 0.11257768422365189, acc: 0.9729729890823364)
[2024-12-17 01:43:41,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:41,753][root][INFO] - Training Epoch: 1/2, step 1687/7134 completed (loss: 0.12785892188549042, acc: 0.963878333568573)
[2024-12-17 01:43:41,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:42,066][root][INFO] - Training Epoch: 1/2, step 1688/7134 completed (loss: 0.11439967155456543, acc: 0.9706336855888367)
[2024-12-17 01:43:42,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:42,407][root][INFO] - Training Epoch: 1/2, step 1689/7134 completed (loss: 0.12183429300785065, acc: 0.9783549904823303)
[2024-12-17 01:43:42,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:42,730][root][INFO] - Training Epoch: 1/2, step 1690/7134 completed (loss: 0.08256617188453674, acc: 0.9857723712921143)
[2024-12-17 01:43:42,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:43,059][root][INFO] - Training Epoch: 1/2, step 1691/7134 completed (loss: 0.06366319209337234, acc: 0.9850993156433105)
[2024-12-17 01:43:43,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:43,386][root][INFO] - Training Epoch: 1/2, step 1692/7134 completed (loss: 0.14093922078609467, acc: 0.9629005193710327)
[2024-12-17 01:43:43,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:43,721][root][INFO] - Training Epoch: 1/2, step 1693/7134 completed (loss: 0.10704357177019119, acc: 0.970059871673584)
[2024-12-17 01:43:43,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:44,055][root][INFO] - Training Epoch: 1/2, step 1694/7134 completed (loss: 0.11779056489467621, acc: 0.9671361446380615)
[2024-12-17 01:43:44,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:44,400][root][INFO] - Training Epoch: 1/2, step 1695/7134 completed (loss: 0.0838218480348587, acc: 0.976576566696167)
[2024-12-17 01:43:44,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:44,714][root][INFO] - Training Epoch: 1/2, step 1696/7134 completed (loss: 0.11747528612613678, acc: 0.9698492288589478)
[2024-12-17 01:43:44,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:45,028][root][INFO] - Training Epoch: 1/2, step 1697/7134 completed (loss: 0.1596703678369522, acc: 0.9624413251876831)
[2024-12-17 01:43:45,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:45,376][root][INFO] - Training Epoch: 1/2, step 1698/7134 completed (loss: 0.09244876354932785, acc: 0.9764890074729919)
[2024-12-17 01:43:45,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:45,732][root][INFO] - Training Epoch: 1/2, step 1699/7134 completed (loss: 0.11892211437225342, acc: 0.9636678099632263)
[2024-12-17 01:43:45,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:46,092][root][INFO] - Training Epoch: 1/2, step 1700/7134 completed (loss: 0.21872578561306, acc: 0.9481216669082642)
[2024-12-17 01:43:46,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:46,429][root][INFO] - Training Epoch: 1/2, step 1701/7134 completed (loss: 0.19832244515419006, acc: 0.9388039112091064)
[2024-12-17 01:43:46,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:46,810][root][INFO] - Training Epoch: 1/2, step 1702/7134 completed (loss: 0.19427579641342163, acc: 0.9515528082847595)
[2024-12-17 01:43:46,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:47,149][root][INFO] - Training Epoch: 1/2, step 1703/7134 completed (loss: 0.21618211269378662, acc: 0.9488950371742249)
[2024-12-17 01:43:47,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:47,492][root][INFO] - Training Epoch: 1/2, step 1704/7134 completed (loss: 0.20554913580417633, acc: 0.94701087474823)
[2024-12-17 01:43:47,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:47,885][root][INFO] - Training Epoch: 1/2, step 1705/7134 completed (loss: 0.14942970871925354, acc: 0.9605522751808167)
[2024-12-17 01:43:47,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:48,089][root][INFO] - Training Epoch: 1/2, step 1706/7134 completed (loss: 0.14314615726470947, acc: 0.9583333134651184)
[2024-12-17 01:43:48,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:48,418][root][INFO] - Training Epoch: 1/2, step 1707/7134 completed (loss: 0.11648647487163544, acc: 0.972515881061554)
[2024-12-17 01:43:48,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:48,768][root][INFO] - Training Epoch: 1/2, step 1708/7134 completed (loss: 0.12464820593595505, acc: 0.9642276167869568)
[2024-12-17 01:43:48,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:49,122][root][INFO] - Training Epoch: 1/2, step 1709/7134 completed (loss: 0.18015943467617035, acc: 0.9448275566101074)
[2024-12-17 01:43:49,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:49,526][root][INFO] - Training Epoch: 1/2, step 1710/7134 completed (loss: 0.2033511847257614, acc: 0.9568965435028076)
[2024-12-17 01:43:49,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:49,882][root][INFO] - Training Epoch: 1/2, step 1711/7134 completed (loss: 0.15008242428302765, acc: 0.9671847820281982)
[2024-12-17 01:43:50,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:50,261][root][INFO] - Training Epoch: 1/2, step 1712/7134 completed (loss: 0.21617253124713898, acc: 0.9491227865219116)
[2024-12-17 01:43:50,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:50,602][root][INFO] - Training Epoch: 1/2, step 1713/7134 completed (loss: 0.10908978432416916, acc: 0.970059871673584)
[2024-12-17 01:43:50,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:50,942][root][INFO] - Training Epoch: 1/2, step 1714/7134 completed (loss: 0.21091783046722412, acc: 0.9457237124443054)
[2024-12-17 01:43:51,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:51,285][root][INFO] - Training Epoch: 1/2, step 1715/7134 completed (loss: 0.2032873034477234, acc: 0.9432048797607422)
[2024-12-17 01:43:51,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:51,598][root][INFO] - Training Epoch: 1/2, step 1716/7134 completed (loss: 0.2072889804840088, acc: 0.9399999976158142)
[2024-12-17 01:43:51,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:51,919][root][INFO] - Training Epoch: 1/2, step 1717/7134 completed (loss: 0.1406751573085785, acc: 0.9630350470542908)
[2024-12-17 01:43:52,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:52,300][root][INFO] - Training Epoch: 1/2, step 1718/7134 completed (loss: 0.18054141104221344, acc: 0.9465478658676147)
[2024-12-17 01:43:52,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:52,648][root][INFO] - Training Epoch: 1/2, step 1719/7134 completed (loss: 0.18303059041500092, acc: 0.9643835425376892)
[2024-12-17 01:43:52,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:52,948][root][INFO] - Training Epoch: 1/2, step 1720/7134 completed (loss: 0.2240840494632721, acc: 0.9440993666648865)
[2024-12-17 01:43:53,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:53,227][root][INFO] - Training Epoch: 1/2, step 1721/7134 completed (loss: 0.1353185474872589, acc: 0.9578414559364319)
[2024-12-17 01:43:53,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:53,514][root][INFO] - Training Epoch: 1/2, step 1722/7134 completed (loss: 0.11550625413656235, acc: 0.9710526466369629)
[2024-12-17 01:43:53,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:53,845][root][INFO] - Training Epoch: 1/2, step 1723/7134 completed (loss: 0.1755780726671219, acc: 0.9448584318161011)
[2024-12-17 01:43:53,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:54,175][root][INFO] - Training Epoch: 1/2, step 1724/7134 completed (loss: 0.20855559408664703, acc: 0.9497645497322083)
[2024-12-17 01:43:54,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:54,448][root][INFO] - Training Epoch: 1/2, step 1725/7134 completed (loss: 0.13609157502651215, acc: 0.9614148139953613)
[2024-12-17 01:43:54,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:54,757][root][INFO] - Training Epoch: 1/2, step 1726/7134 completed (loss: 0.13617202639579773, acc: 0.9641255736351013)
[2024-12-17 01:43:54,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:55,078][root][INFO] - Training Epoch: 1/2, step 1727/7134 completed (loss: 0.15126799046993256, acc: 0.9580292105674744)
[2024-12-17 01:43:55,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:55,429][root][INFO] - Training Epoch: 1/2, step 1728/7134 completed (loss: 0.10621856898069382, acc: 0.9751655459403992)
[2024-12-17 01:43:55,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:55,734][root][INFO] - Training Epoch: 1/2, step 1729/7134 completed (loss: 0.17861370742321014, acc: 0.9613034725189209)
[2024-12-17 01:43:55,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:56,063][root][INFO] - Training Epoch: 1/2, step 1730/7134 completed (loss: 0.13800813257694244, acc: 0.9635974168777466)
[2024-12-17 01:43:56,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:56,311][root][INFO] - Training Epoch: 1/2, step 1731/7134 completed (loss: 0.25236570835113525, acc: 0.9479768872261047)
[2024-12-17 01:43:56,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:56,606][root][INFO] - Training Epoch: 1/2, step 1732/7134 completed (loss: 0.1691470444202423, acc: 0.9609856009483337)
[2024-12-17 01:43:56,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:56,880][root][INFO] - Training Epoch: 1/2, step 1733/7134 completed (loss: 0.20754869282245636, acc: 0.9362139701843262)
[2024-12-17 01:43:56,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:57,243][root][INFO] - Training Epoch: 1/2, step 1734/7134 completed (loss: 0.14879445731639862, acc: 0.9582309722900391)
[2024-12-17 01:43:57,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:57,591][root][INFO] - Training Epoch: 1/2, step 1735/7134 completed (loss: 0.11622440814971924, acc: 0.9775596261024475)
[2024-12-17 01:43:57,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:57,947][root][INFO] - Training Epoch: 1/2, step 1736/7134 completed (loss: 0.1401604413986206, acc: 0.9709091186523438)
[2024-12-17 01:43:58,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:58,306][root][INFO] - Training Epoch: 1/2, step 1737/7134 completed (loss: 0.10794632136821747, acc: 0.966292142868042)
[2024-12-17 01:43:58,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:58,662][root][INFO] - Training Epoch: 1/2, step 1738/7134 completed (loss: 0.09717495739459991, acc: 0.9758745431900024)
[2024-12-17 01:43:58,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:59,019][root][INFO] - Training Epoch: 1/2, step 1739/7134 completed (loss: 0.15575024485588074, acc: 0.9580838084220886)
[2024-12-17 01:43:59,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:59,375][root][INFO] - Training Epoch: 1/2, step 1740/7134 completed (loss: 0.0848642960190773, acc: 0.9766082167625427)
[2024-12-17 01:43:59,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:59,798][root][INFO] - Training Epoch: 1/2, step 1741/7134 completed (loss: 0.16754738986492157, acc: 0.9550264477729797)
[2024-12-17 01:43:59,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:00,125][root][INFO] - Training Epoch: 1/2, step 1742/7134 completed (loss: 0.13309648633003235, acc: 0.9617021083831787)
[2024-12-17 01:44:00,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:00,491][root][INFO] - Training Epoch: 1/2, step 1743/7134 completed (loss: 0.1690826416015625, acc: 0.9593837261199951)
[2024-12-17 01:44:00,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:00,823][root][INFO] - Training Epoch: 1/2, step 1744/7134 completed (loss: 0.1468229442834854, acc: 0.9641693830490112)
[2024-12-17 01:44:00,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:01,170][root][INFO] - Training Epoch: 1/2, step 1745/7134 completed (loss: 0.13362598419189453, acc: 0.9686716794967651)
[2024-12-17 01:44:01,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:01,519][root][INFO] - Training Epoch: 1/2, step 1746/7134 completed (loss: 0.08873272687196732, acc: 0.9752907156944275)
[2024-12-17 01:44:01,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:01,881][root][INFO] - Training Epoch: 1/2, step 1747/7134 completed (loss: 0.12664952874183655, acc: 0.9624530673027039)
[2024-12-17 01:44:01,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:02,239][root][INFO] - Training Epoch: 1/2, step 1748/7134 completed (loss: 0.15414907038211823, acc: 0.96277916431427)
[2024-12-17 01:44:02,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:02,618][root][INFO] - Training Epoch: 1/2, step 1749/7134 completed (loss: 0.1086154580116272, acc: 0.9727582335472107)
[2024-12-17 01:44:02,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:03,003][root][INFO] - Training Epoch: 1/2, step 1750/7134 completed (loss: 0.1138920858502388, acc: 0.9652278423309326)
[2024-12-17 01:44:03,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:03,351][root][INFO] - Training Epoch: 1/2, step 1751/7134 completed (loss: 0.16937769949436188, acc: 0.9527272582054138)
[2024-12-17 01:44:03,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:03,703][root][INFO] - Training Epoch: 1/2, step 1752/7134 completed (loss: 0.15893906354904175, acc: 0.9626288414001465)
[2024-12-17 01:44:03,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:04,034][root][INFO] - Training Epoch: 1/2, step 1753/7134 completed (loss: 0.12798351049423218, acc: 0.9726918339729309)
[2024-12-17 01:44:04,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:04,363][root][INFO] - Training Epoch: 1/2, step 1754/7134 completed (loss: 0.10883983969688416, acc: 0.9711815714836121)
[2024-12-17 01:44:04,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:04,693][root][INFO] - Training Epoch: 1/2, step 1755/7134 completed (loss: 0.1278390735387802, acc: 0.9629629850387573)
[2024-12-17 01:44:04,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:05,033][root][INFO] - Training Epoch: 1/2, step 1756/7134 completed (loss: 0.1660241037607193, acc: 0.9596878886222839)
[2024-12-17 01:44:05,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:05,352][root][INFO] - Training Epoch: 1/2, step 1757/7134 completed (loss: 0.15316636860370636, acc: 0.9683859944343567)
[2024-12-17 01:44:05,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:05,708][root][INFO] - Training Epoch: 1/2, step 1758/7134 completed (loss: 0.09995845705270767, acc: 0.9760100841522217)
[2024-12-17 01:44:05,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:06,049][root][INFO] - Training Epoch: 1/2, step 1759/7134 completed (loss: 0.11624543368816376, acc: 0.976356029510498)
[2024-12-17 01:44:06,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:06,375][root][INFO] - Training Epoch: 1/2, step 1760/7134 completed (loss: 0.07394341379404068, acc: 0.9747899174690247)
[2024-12-17 01:44:06,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:06,691][root][INFO] - Training Epoch: 1/2, step 1761/7134 completed (loss: 0.08063406497240067, acc: 0.9786931872367859)
[2024-12-17 01:44:06,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:07,021][root][INFO] - Training Epoch: 1/2, step 1762/7134 completed (loss: 0.08265819400548935, acc: 0.9793814420700073)
[2024-12-17 01:44:07,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:07,341][root][INFO] - Training Epoch: 1/2, step 1763/7134 completed (loss: 0.12071508914232254, acc: 0.9711538553237915)
[2024-12-17 01:44:07,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:07,674][root][INFO] - Training Epoch: 1/2, step 1764/7134 completed (loss: 0.12380710244178772, acc: 0.9665427803993225)
[2024-12-17 01:44:07,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:08,017][root][INFO] - Training Epoch: 1/2, step 1765/7134 completed (loss: 0.10419473797082901, acc: 0.9753086566925049)
[2024-12-17 01:44:08,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:08,339][root][INFO] - Training Epoch: 1/2, step 1766/7134 completed (loss: 0.13996554911136627, acc: 0.9677419066429138)
[2024-12-17 01:44:08,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:08,679][root][INFO] - Training Epoch: 1/2, step 1767/7134 completed (loss: 0.22333751618862152, acc: 0.9420084953308105)
[2024-12-17 01:44:08,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:09,013][root][INFO] - Training Epoch: 1/2, step 1768/7134 completed (loss: 0.16600584983825684, acc: 0.9691714644432068)
[2024-12-17 01:44:09,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:09,397][root][INFO] - Training Epoch: 1/2, step 1769/7134 completed (loss: 0.11790335178375244, acc: 0.9676470756530762)
[2024-12-17 01:44:09,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:09,716][root][INFO] - Training Epoch: 1/2, step 1770/7134 completed (loss: 0.08623252063989639, acc: 0.9802731275558472)
[2024-12-17 01:44:09,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:10,047][root][INFO] - Training Epoch: 1/2, step 1771/7134 completed (loss: 0.08496229350566864, acc: 0.9790502786636353)
[2024-12-17 01:44:10,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:10,380][root][INFO] - Training Epoch: 1/2, step 1772/7134 completed (loss: 0.11260661482810974, acc: 0.9614740610122681)
[2024-12-17 01:44:10,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:10,720][root][INFO] - Training Epoch: 1/2, step 1773/7134 completed (loss: 0.0829472541809082, acc: 0.9738371968269348)
[2024-12-17 01:44:10,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:11,045][root][INFO] - Training Epoch: 1/2, step 1774/7134 completed (loss: 0.08086483925580978, acc: 0.9717608094215393)
[2024-12-17 01:44:11,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:11,376][root][INFO] - Training Epoch: 1/2, step 1775/7134 completed (loss: 0.09914005547761917, acc: 0.9703124761581421)
[2024-12-17 01:44:11,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:11,706][root][INFO] - Training Epoch: 1/2, step 1776/7134 completed (loss: 0.09798427671194077, acc: 0.9745509028434753)
[2024-12-17 01:44:11,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:12,026][root][INFO] - Training Epoch: 1/2, step 1777/7134 completed (loss: 0.07028423249721527, acc: 0.9852070808410645)
[2024-12-17 01:44:12,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:12,358][root][INFO] - Training Epoch: 1/2, step 1778/7134 completed (loss: 0.13285653293132782, acc: 0.9748520851135254)
[2024-12-17 01:44:12,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:12,675][root][INFO] - Training Epoch: 1/2, step 1779/7134 completed (loss: 0.07756657153367996, acc: 0.9777777791023254)
[2024-12-17 01:44:12,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:13,099][root][INFO] - Training Epoch: 1/2, step 1780/7134 completed (loss: 0.1299472153186798, acc: 0.9759547114372253)
[2024-12-17 01:44:13,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:13,417][root][INFO] - Training Epoch: 1/2, step 1781/7134 completed (loss: 0.10470139235258102, acc: 0.970992386341095)
[2024-12-17 01:44:13,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:13,734][root][INFO] - Training Epoch: 1/2, step 1782/7134 completed (loss: 0.1020938977599144, acc: 0.9832572340965271)
[2024-12-17 01:44:14,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:14,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:15,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:15,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:16,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:16,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:16,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:17,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:17,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:17,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:18,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:18,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:18,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:18,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:19,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:19,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:19,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:20,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:20,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:20,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:21,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:21,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:21,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:22,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:22,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:22,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:22,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:23,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:23,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:24,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:24,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:24,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:25,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:25,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:25,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:25,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:26,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:26,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:26,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:26,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:27,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:27,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:27,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:27,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:28,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:28,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:29,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:29,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:29,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:29,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:30,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:30,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:30,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:31,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:31,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:31,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:32,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:32,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:32,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:32,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:33,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:33,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:33,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:34,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:34,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:34,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:35,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:35,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:35,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:36,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:36,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:36,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:37,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:37,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:37,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:38,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:38,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:38,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:39,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:39,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:39,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:40,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:40,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:40,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:40,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:41,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:41,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:42,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:42,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:42,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:42,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:43,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:43,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:43,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:44,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:44,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:44,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:45,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:45,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:45,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:45,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:46,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:46,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:46,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:47,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:47,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:47,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:48,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:48,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:48,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:49,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:49,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:49,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:50,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:50,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:50,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:51,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:51,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:51,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:51,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:52,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:52,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:52,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:53,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:53,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:53,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:53,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:54,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:54,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:54,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:55,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:55,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:55,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:56,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:56,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:56,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:57,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:57,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:57,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:58,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:58,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:58,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:59,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:59,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:59,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:59,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:00,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:00,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:00,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:01,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:01,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:01,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:01,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:02,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:02,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:02,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:02,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:03,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:03,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:03,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:03,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:04,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:04,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:04,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:05,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:05,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:05,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:06,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:06,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:06,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:07,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:07,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:07,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:08,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:08,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:08,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:08,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:09,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:09,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:09,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:09,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:10,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:10,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:10,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:11,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:11,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:11,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:12,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:12,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:12,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:12,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:13,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:13,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:13,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:14,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:14,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:14,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:14,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:15,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:15,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:15,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:16,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:16,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:16,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:16,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:17,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:17,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:17,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:18,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:18,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:18,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:19,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:19,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:19,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:20,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:20,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:20,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:21,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:21,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:21,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:21,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:22,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:22,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:22,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:23,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:23,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:23,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:24,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:24,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:24,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:24,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:25,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:25,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:25,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:25,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:26,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:26,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:26,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:26,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:27,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:27,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:27,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:28,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:28,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:28,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:29,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:29,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:29,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:30,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:30,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:30,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:31,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:31,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:31,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:31,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:32,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:32,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:32,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:33,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:33,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:33,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:34,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:34,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:34,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:35,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:35,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:35,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:36,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:36,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:36,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:37,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:37,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:37,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:38,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:38,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:38,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:39,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:39,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:39,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:39,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:40,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:40,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:41,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:41,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:41,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:41,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:42,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:42,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:42,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:43,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:43,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:43,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:44,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:44,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:44,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:45,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:45,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:45,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:46,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:46,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:46,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:47,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:47,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:47,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:47,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:48,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:48,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:48,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:48,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:49,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:49,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:49,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:49,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:50,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:50,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:50,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:50,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:51,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:51,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:51,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:52,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:52,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:52,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:53,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:53,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:53,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:54,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:54,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:54,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:55,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:55,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:55,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:56,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:56,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:56,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:56,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:57,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:57,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:57,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:57,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:58,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:58,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:59,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:59,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:59,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:59,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:00,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:00,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:00,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:01,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:01,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:01,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:02,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:02,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:02,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:02,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:03,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:03,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:03,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:03,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:04,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:04,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:05,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:05,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:06,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:06,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:07,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:07,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:07,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:07,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:08,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:08,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:08,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:09,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:09,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:09,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:09,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:09,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:10,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:10,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:10,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:11,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:11,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:11,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:11,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:12,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:12,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:12,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:12,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:13,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:13,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:13,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:13,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:14,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:14,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:14,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:14,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:15,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:15,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:15,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:15,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:15,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:16,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:16,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:16,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:16,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:17,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:17,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:17,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:18,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:18,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:18,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:18,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:19,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:19,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:19,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:20,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:20,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:20,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:21,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:21,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:21,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:21,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:22,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:22,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:22,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:22,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:23,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:23,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:23,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:24,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:24,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:24,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:24,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:25,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:25,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:25,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:25,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:26,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:26,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:26,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:27,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:27,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:27,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:28,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:28,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:28,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:28,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:29,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:29,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:29,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:30,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:30,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:30,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:30,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:31,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:31,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:31,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:32,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:32,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:32,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:32,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:33,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:33,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:33,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:33,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:34,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:34,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:34,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:35,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:35,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:35,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:35,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:35,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:36,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:36,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:36,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:37,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:37,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:37,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:38,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:38,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:38,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:39,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:39,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:39,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:39,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:40,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:40,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:40,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:40,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:41,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:41,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:41,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:42,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:42,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:42,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:42,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:43,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:43,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:43,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:44,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:44,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:44,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:45,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:45,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:45,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:45,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:46,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:46,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:46,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:47,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:47,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:47,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:47,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:48,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:48,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:48,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:48,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:49,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:49,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:49,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:50,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:50,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:50,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:50,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:51,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:51,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:51,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:52,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:52,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:52,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:52,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:53,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:53,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:53,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:54,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:54,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:54,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:55,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:55,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:55,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:56,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:56,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:56,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:57,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:57,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:57,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:57,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:58,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:58,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:58,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:59,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:59,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:59,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:59,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:00,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:00,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:00,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:00,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:01,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:01,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:02,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:02,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:02,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:02,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:03,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:03,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:03,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:03,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:04,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:04,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:04,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:05,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:05,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:05,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:06,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:06,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:06,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:07,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:07,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:07,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:08,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:08,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:08,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:09,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:09,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:10,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:10,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:10,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:10,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:11,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:11,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:11,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:11,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:12,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:12,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:12,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:13,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:13,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:13,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:14,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:14,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:14,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:14,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:15,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:15,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:15,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:15,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:16,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:16,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:16,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:16,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:17,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:17,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:17,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:17,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:18,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:18,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:18,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:19,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:19,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:19,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:20,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:20,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:20,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:21,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:22,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:22,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:22,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:23,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:23,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:23,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:24,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:24,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:24,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:25,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:25,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:25,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:26,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:26,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:26,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:27,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:27,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:27,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:27,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:28,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:28,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:29,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:29,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:29,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:29,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:30,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:30,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:30,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:31,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:31,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:31,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:31,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:32,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:32,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:32,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:33,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:33,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:33,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:34,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:34,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:34,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:34,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:35,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:35,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:35,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:36,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:36,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:36,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:37,356][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.1979, device='cuda:0') eval_epoch_loss=tensor(0.1806, device='cuda:0') eval_epoch_acc=tensor(0.9550, device='cuda:0')
[2024-12-17 01:47:37,358][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-12-17 01:47:37,359][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 01:47:37,626][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_1_step_1783_loss_0.18061041831970215/model.pt
[2024-12-17 01:47:37,633][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 0.18061041831970215
[2024-12-17 01:47:37,634][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.9550448656082153
[2024-12-17 01:47:37,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:38,029][root][INFO] - Training Epoch: 1/2, step 1783/7134 completed (loss: 0.1152060404419899, acc: 0.9729729890823364)
[2024-12-17 01:47:38,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:38,380][root][INFO] - Training Epoch: 1/2, step 1784/7134 completed (loss: 0.08422168344259262, acc: 0.9750733375549316)
[2024-12-17 01:47:38,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:38,732][root][INFO] - Training Epoch: 1/2, step 1785/7134 completed (loss: 0.09410720318555832, acc: 0.9793672561645508)
[2024-12-17 01:47:38,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:39,053][root][INFO] - Training Epoch: 1/2, step 1786/7134 completed (loss: 0.0990278571844101, acc: 0.9734789133071899)
[2024-12-17 01:47:39,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:39,406][root][INFO] - Training Epoch: 1/2, step 1787/7134 completed (loss: 0.08002554625272751, acc: 0.987500011920929)
[2024-12-17 01:47:39,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:39,726][root][INFO] - Training Epoch: 1/2, step 1788/7134 completed (loss: 0.0833115428686142, acc: 0.978723406791687)
[2024-12-17 01:47:39,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:40,057][root][INFO] - Training Epoch: 1/2, step 1789/7134 completed (loss: 0.0963187888264656, acc: 0.9784946441650391)
[2024-12-17 01:47:40,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:40,423][root][INFO] - Training Epoch: 1/2, step 1790/7134 completed (loss: 0.24952609837055206, acc: 0.9549114108085632)
[2024-12-17 01:47:40,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:40,748][root][INFO] - Training Epoch: 1/2, step 1791/7134 completed (loss: 0.3278402090072632, acc: 0.9400855898857117)
[2024-12-17 01:47:40,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:41,104][root][INFO] - Training Epoch: 1/2, step 1792/7134 completed (loss: 0.3459230661392212, acc: 0.93360435962677)
[2024-12-17 01:47:41,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:41,464][root][INFO] - Training Epoch: 1/2, step 1793/7134 completed (loss: 0.28489893674850464, acc: 0.9391891956329346)
[2024-12-17 01:47:41,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:41,824][root][INFO] - Training Epoch: 1/2, step 1794/7134 completed (loss: 0.2730801999568939, acc: 0.9386792182922363)
[2024-12-17 01:47:41,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:42,156][root][INFO] - Training Epoch: 1/2, step 1795/7134 completed (loss: 0.32948043942451477, acc: 0.932624101638794)
[2024-12-17 01:47:42,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:42,488][root][INFO] - Training Epoch: 1/2, step 1796/7134 completed (loss: 0.3063390552997589, acc: 0.92476487159729)
[2024-12-17 01:47:42,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:42,824][root][INFO] - Training Epoch: 1/2, step 1797/7134 completed (loss: 0.1967068910598755, acc: 0.9523809552192688)
[2024-12-17 01:47:42,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:43,182][root][INFO] - Training Epoch: 1/2, step 1798/7134 completed (loss: 0.2127903699874878, acc: 0.953667938709259)
[2024-12-17 01:47:43,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:43,547][root][INFO] - Training Epoch: 1/2, step 1799/7134 completed (loss: 0.2680751383304596, acc: 0.9371859431266785)
[2024-12-17 01:47:43,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:43,945][root][INFO] - Training Epoch: 1/2, step 1800/7134 completed (loss: 0.3182664215564728, acc: 0.922897219657898)
[2024-12-17 01:47:44,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:44,296][root][INFO] - Training Epoch: 1/2, step 1801/7134 completed (loss: 0.2680356204509735, acc: 0.9406779408454895)
[2024-12-17 01:47:44,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:44,637][root][INFO] - Training Epoch: 1/2, step 1802/7134 completed (loss: 0.17662620544433594, acc: 0.9586983919143677)
[2024-12-17 01:47:44,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:44,964][root][INFO] - Training Epoch: 1/2, step 1803/7134 completed (loss: 0.15561816096305847, acc: 0.964560866355896)
[2024-12-17 01:47:45,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:45,303][root][INFO] - Training Epoch: 1/2, step 1804/7134 completed (loss: 0.08607276529073715, acc: 0.9754299521446228)
[2024-12-17 01:47:45,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:45,625][root][INFO] - Training Epoch: 1/2, step 1805/7134 completed (loss: 0.16981397569179535, acc: 0.9639249444007874)
[2024-12-17 01:47:45,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:45,963][root][INFO] - Training Epoch: 1/2, step 1806/7134 completed (loss: 0.1364355981349945, acc: 0.9697368144989014)
[2024-12-17 01:47:46,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:46,287][root][INFO] - Training Epoch: 1/2, step 1807/7134 completed (loss: 0.08673398941755295, acc: 0.9787836074829102)
[2024-12-17 01:47:46,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:46,610][root][INFO] - Training Epoch: 1/2, step 1808/7134 completed (loss: 0.10952906310558319, acc: 0.9752925634384155)
[2024-12-17 01:47:46,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:46,982][root][INFO] - Training Epoch: 1/2, step 1809/7134 completed (loss: 0.17175710201263428, acc: 0.9513513445854187)
[2024-12-17 01:47:47,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:47,341][root][INFO] - Training Epoch: 1/2, step 1810/7134 completed (loss: 0.10742834210395813, acc: 0.967783510684967)
[2024-12-17 01:47:47,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:47,684][root][INFO] - Training Epoch: 1/2, step 1811/7134 completed (loss: 0.26248008012771606, acc: 0.9294437170028687)
[2024-12-17 01:47:47,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:48,036][root][INFO] - Training Epoch: 1/2, step 1812/7134 completed (loss: 0.14463968575000763, acc: 0.9706632494926453)
[2024-12-17 01:47:48,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:48,393][root][INFO] - Training Epoch: 1/2, step 1813/7134 completed (loss: 0.16696928441524506, acc: 0.9712575078010559)
[2024-12-17 01:47:48,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:48,754][root][INFO] - Training Epoch: 1/2, step 1814/7134 completed (loss: 0.09894431382417679, acc: 0.9696969985961914)
[2024-12-17 01:47:48,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:49,095][root][INFO] - Training Epoch: 1/2, step 1815/7134 completed (loss: 0.11417747288942337, acc: 0.9640804529190063)
[2024-12-17 01:47:49,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:49,420][root][INFO] - Training Epoch: 1/2, step 1816/7134 completed (loss: 0.11913279443979263, acc: 0.9733959436416626)
[2024-12-17 01:47:49,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:49,778][root][INFO] - Training Epoch: 1/2, step 1817/7134 completed (loss: 0.17076382040977478, acc: 0.9606205224990845)
[2024-12-17 01:47:49,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:50,139][root][INFO] - Training Epoch: 1/2, step 1818/7134 completed (loss: 0.14098888635635376, acc: 0.9653035998344421)
[2024-12-17 01:47:50,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:50,488][root][INFO] - Training Epoch: 1/2, step 1819/7134 completed (loss: 0.09709382802248001, acc: 0.9650872945785522)
[2024-12-17 01:47:50,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:50,886][root][INFO] - Training Epoch: 1/2, step 1820/7134 completed (loss: 0.12867873907089233, acc: 0.97052401304245)
[2024-12-17 01:47:51,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:51,230][root][INFO] - Training Epoch: 1/2, step 1821/7134 completed (loss: 0.13400880992412567, acc: 0.9682713150978088)
[2024-12-17 01:47:51,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:51,549][root][INFO] - Training Epoch: 1/2, step 1822/7134 completed (loss: 0.05256236344575882, acc: 0.9839181303977966)
[2024-12-17 01:47:51,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:51,900][root][INFO] - Training Epoch: 1/2, step 1823/7134 completed (loss: 0.10783766955137253, acc: 0.9699863791465759)
[2024-12-17 01:47:52,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:52,251][root][INFO] - Training Epoch: 1/2, step 1824/7134 completed (loss: 0.11816360801458359, acc: 0.9641532897949219)
[2024-12-17 01:47:52,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:52,610][root][INFO] - Training Epoch: 1/2, step 1825/7134 completed (loss: 0.0984475165605545, acc: 0.9719731211662292)
[2024-12-17 01:47:52,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:52,968][root][INFO] - Training Epoch: 1/2, step 1826/7134 completed (loss: 0.10452010482549667, acc: 0.9757738709449768)
[2024-12-17 01:47:53,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:53,327][root][INFO] - Training Epoch: 1/2, step 1827/7134 completed (loss: 0.11932801455259323, acc: 0.9691290259361267)
[2024-12-17 01:47:53,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:53,680][root][INFO] - Training Epoch: 1/2, step 1828/7134 completed (loss: 0.047804661095142365, acc: 0.9897040128707886)
[2024-12-17 01:47:53,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:54,036][root][INFO] - Training Epoch: 1/2, step 1829/7134 completed (loss: 0.09616222232580185, acc: 0.9801242351531982)
[2024-12-17 01:47:54,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:54,420][root][INFO] - Training Epoch: 1/2, step 1830/7134 completed (loss: 0.11850696057081223, acc: 0.9673123359680176)
[2024-12-17 01:47:54,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:54,750][root][INFO] - Training Epoch: 1/2, step 1831/7134 completed (loss: 0.07522416859865189, acc: 0.9703124761581421)
[2024-12-17 01:47:54,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:55,078][root][INFO] - Training Epoch: 1/2, step 1832/7134 completed (loss: 0.15359823405742645, acc: 0.9611307382583618)
[2024-12-17 01:47:55,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:55,426][root][INFO] - Training Epoch: 1/2, step 1833/7134 completed (loss: 0.3568187952041626, acc: 0.9323467016220093)
[2024-12-17 01:47:55,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:55,783][root][INFO] - Training Epoch: 1/2, step 1834/7134 completed (loss: 0.1299196034669876, acc: 0.9676056504249573)
[2024-12-17 01:47:55,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:56,123][root][INFO] - Training Epoch: 1/2, step 1835/7134 completed (loss: 0.19057708978652954, acc: 0.9563953280448914)
[2024-12-17 01:47:56,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:56,473][root][INFO] - Training Epoch: 1/2, step 1836/7134 completed (loss: 0.1335393190383911, acc: 0.9669030904769897)
[2024-12-17 01:47:56,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:56,822][root][INFO] - Training Epoch: 1/2, step 1837/7134 completed (loss: 0.13083991408348083, acc: 0.9680589437484741)
[2024-12-17 01:47:56,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:57,123][root][INFO] - Training Epoch: 1/2, step 1838/7134 completed (loss: 0.07871032506227493, acc: 0.981632649898529)
[2024-12-17 01:47:57,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:57,487][root][INFO] - Training Epoch: 1/2, step 1839/7134 completed (loss: 0.10490725934505463, acc: 0.9740932583808899)
[2024-12-17 01:47:57,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:57,853][root][INFO] - Training Epoch: 1/2, step 1840/7134 completed (loss: 0.18522459268569946, acc: 0.9456067085266113)
[2024-12-17 01:47:57,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:58,185][root][INFO] - Training Epoch: 1/2, step 1841/7134 completed (loss: 0.11496073752641678, acc: 0.9659574627876282)
[2024-12-17 01:47:58,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:58,546][root][INFO] - Training Epoch: 1/2, step 1842/7134 completed (loss: 0.13907437026500702, acc: 0.9673469662666321)
[2024-12-17 01:47:58,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:58,881][root][INFO] - Training Epoch: 1/2, step 1843/7134 completed (loss: 0.16472791135311127, acc: 0.956250011920929)
[2024-12-17 01:47:59,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:59,307][root][INFO] - Training Epoch: 1/2, step 1844/7134 completed (loss: 0.11845308542251587, acc: 0.9707317352294922)
[2024-12-17 01:47:59,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:59,676][root][INFO] - Training Epoch: 1/2, step 1845/7134 completed (loss: 0.1397031992673874, acc: 0.9707724452018738)
[2024-12-17 01:47:59,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:00,013][root][INFO] - Training Epoch: 1/2, step 1846/7134 completed (loss: 0.09719335287809372, acc: 0.9800570011138916)
[2024-12-17 01:48:00,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:00,385][root][INFO] - Training Epoch: 1/2, step 1847/7134 completed (loss: 0.14085090160369873, acc: 0.9646697640419006)
[2024-12-17 01:48:00,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:00,750][root][INFO] - Training Epoch: 1/2, step 1848/7134 completed (loss: 0.16783127188682556, acc: 0.9632768630981445)
[2024-12-17 01:48:00,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:01,094][root][INFO] - Training Epoch: 1/2, step 1849/7134 completed (loss: 0.1481810212135315, acc: 0.9736379384994507)
[2024-12-17 01:48:01,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:01,455][root][INFO] - Training Epoch: 1/2, step 1850/7134 completed (loss: 0.0955917239189148, acc: 0.9779950976371765)
[2024-12-17 01:48:01,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:01,811][root][INFO] - Training Epoch: 1/2, step 1851/7134 completed (loss: 0.1191544234752655, acc: 0.9755799770355225)
[2024-12-17 01:48:01,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:02,137][root][INFO] - Training Epoch: 1/2, step 1852/7134 completed (loss: 0.09309016913175583, acc: 0.9751552939414978)
[2024-12-17 01:48:02,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:02,495][root][INFO] - Training Epoch: 1/2, step 1853/7134 completed (loss: 0.09296189248561859, acc: 0.9796651005744934)
[2024-12-17 01:48:02,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:02,855][root][INFO] - Training Epoch: 1/2, step 1854/7134 completed (loss: 0.16205386817455292, acc: 0.9619500637054443)
[2024-12-17 01:48:02,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:03,218][root][INFO] - Training Epoch: 1/2, step 1855/7134 completed (loss: 0.11311128735542297, acc: 0.9768785834312439)
[2024-12-17 01:48:03,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:03,555][root][INFO] - Training Epoch: 1/2, step 1856/7134 completed (loss: 0.10609927028417587, acc: 0.9741697311401367)
[2024-12-17 01:48:03,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:03,969][root][INFO] - Training Epoch: 1/2, step 1857/7134 completed (loss: 0.17942656576633453, acc: 0.9667487740516663)
[2024-12-17 01:48:04,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:04,323][root][INFO] - Training Epoch: 1/2, step 1858/7134 completed (loss: 0.09393413364887238, acc: 0.9748803973197937)
[2024-12-17 01:48:04,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:04,689][root][INFO] - Training Epoch: 1/2, step 1859/7134 completed (loss: 0.07621980458498001, acc: 0.9852104783058167)
[2024-12-17 01:48:04,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:05,042][root][INFO] - Training Epoch: 1/2, step 1860/7134 completed (loss: 0.08010547608137131, acc: 0.9759493470191956)
[2024-12-17 01:48:05,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:05,415][root][INFO] - Training Epoch: 1/2, step 1861/7134 completed (loss: 0.13075187802314758, acc: 0.975452184677124)
[2024-12-17 01:48:05,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:05,778][root][INFO] - Training Epoch: 1/2, step 1862/7134 completed (loss: 0.1308055818080902, acc: 0.9633650183677673)
[2024-12-17 01:48:05,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:06,129][root][INFO] - Training Epoch: 1/2, step 1863/7134 completed (loss: 0.14146889746189117, acc: 0.9676259160041809)
[2024-12-17 01:48:06,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:06,460][root][INFO] - Training Epoch: 1/2, step 1864/7134 completed (loss: 0.26084673404693604, acc: 0.9319728016853333)
[2024-12-17 01:48:06,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:06,786][root][INFO] - Training Epoch: 1/2, step 1865/7134 completed (loss: 0.17123329639434814, acc: 0.952622652053833)
[2024-12-17 01:48:06,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:07,129][root][INFO] - Training Epoch: 1/2, step 1866/7134 completed (loss: 0.07984954118728638, acc: 0.9775910377502441)
[2024-12-17 01:48:07,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:07,496][root][INFO] - Training Epoch: 1/2, step 1867/7134 completed (loss: 0.10856334120035172, acc: 0.9672130942344666)
[2024-12-17 01:48:07,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:07,883][root][INFO] - Training Epoch: 1/2, step 1868/7134 completed (loss: 0.2178838700056076, acc: 0.9438943862915039)
[2024-12-17 01:48:07,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:08,214][root][INFO] - Training Epoch: 1/2, step 1869/7134 completed (loss: 0.1555820256471634, acc: 0.9641109108924866)
[2024-12-17 01:48:08,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:08,535][root][INFO] - Training Epoch: 1/2, step 1870/7134 completed (loss: 0.10482726246118546, acc: 0.97265625)
[2024-12-17 01:48:08,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:08,913][root][INFO] - Training Epoch: 1/2, step 1871/7134 completed (loss: 0.17247967422008514, acc: 0.9641109108924866)
[2024-12-17 01:48:09,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:09,160][root][INFO] - Training Epoch: 1/2, step 1872/7134 completed (loss: 0.734686553478241, acc: 0.8453038930892944)
[2024-12-17 01:48:09,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:09,498][root][INFO] - Training Epoch: 1/2, step 1873/7134 completed (loss: 0.27651312947273254, acc: 0.9239904880523682)
[2024-12-17 01:48:09,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:09,857][root][INFO] - Training Epoch: 1/2, step 1874/7134 completed (loss: 0.1398160308599472, acc: 0.9698558449745178)
[2024-12-17 01:48:09,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:10,187][root][INFO] - Training Epoch: 1/2, step 1875/7134 completed (loss: 0.10502360761165619, acc: 0.9694322943687439)
[2024-12-17 01:48:10,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:10,517][root][INFO] - Training Epoch: 1/2, step 1876/7134 completed (loss: 0.2517085075378418, acc: 0.9405772686004639)
[2024-12-17 01:48:10,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:10,871][root][INFO] - Training Epoch: 1/2, step 1877/7134 completed (loss: 0.18390478193759918, acc: 0.9571788311004639)
[2024-12-17 01:48:11,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:11,227][root][INFO] - Training Epoch: 1/2, step 1878/7134 completed (loss: 0.17896944284439087, acc: 0.9476116895675659)
[2024-12-17 01:48:11,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:11,568][root][INFO] - Training Epoch: 1/2, step 1879/7134 completed (loss: 0.16989058256149292, acc: 0.9494290351867676)
[2024-12-17 01:48:11,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:11,874][root][INFO] - Training Epoch: 1/2, step 1880/7134 completed (loss: 0.13599498569965363, acc: 0.9718309640884399)
[2024-12-17 01:48:11,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:12,208][root][INFO] - Training Epoch: 1/2, step 1881/7134 completed (loss: 0.19329199194908142, acc: 0.9542483687400818)
[2024-12-17 01:48:12,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:12,477][root][INFO] - Training Epoch: 1/2, step 1882/7134 completed (loss: 0.19818371534347534, acc: 0.9458128213882446)
[2024-12-17 01:48:12,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:12,806][root][INFO] - Training Epoch: 1/2, step 1883/7134 completed (loss: 0.15648587048053741, acc: 0.9685039520263672)
[2024-12-17 01:48:12,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:13,129][root][INFO] - Training Epoch: 1/2, step 1884/7134 completed (loss: 0.19487987458705902, acc: 0.9557662010192871)
[2024-12-17 01:48:13,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:13,450][root][INFO] - Training Epoch: 1/2, step 1885/7134 completed (loss: 0.13880902528762817, acc: 0.9606003761291504)
[2024-12-17 01:48:13,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:13,781][root][INFO] - Training Epoch: 1/2, step 1886/7134 completed (loss: 0.2031647115945816, acc: 0.9519832730293274)
[2024-12-17 01:48:13,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:14,104][root][INFO] - Training Epoch: 1/2, step 1887/7134 completed (loss: 0.18010446429252625, acc: 0.9506641626358032)
[2024-12-17 01:48:14,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:14,457][root][INFO] - Training Epoch: 1/2, step 1888/7134 completed (loss: 0.13507041335105896, acc: 0.9673704504966736)
[2024-12-17 01:48:14,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:14,857][root][INFO] - Training Epoch: 1/2, step 1889/7134 completed (loss: 0.13248538970947266, acc: 0.9653179049491882)
[2024-12-17 01:48:14,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:15,200][root][INFO] - Training Epoch: 1/2, step 1890/7134 completed (loss: 0.0881846621632576, acc: 0.9829721450805664)
[2024-12-17 01:48:15,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:15,528][root][INFO] - Training Epoch: 1/2, step 1891/7134 completed (loss: 0.17721422016620636, acc: 0.9577922224998474)
[2024-12-17 01:48:15,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:15,862][root][INFO] - Training Epoch: 1/2, step 1892/7134 completed (loss: 0.14853830635547638, acc: 0.9629057049751282)
[2024-12-17 01:48:15,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:16,176][root][INFO] - Training Epoch: 1/2, step 1893/7134 completed (loss: 0.1304612010717392, acc: 0.9672386646270752)
[2024-12-17 01:48:16,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:16,502][root][INFO] - Training Epoch: 1/2, step 1894/7134 completed (loss: 0.1959236115217209, acc: 0.9583333134651184)
[2024-12-17 01:48:16,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:16,795][root][INFO] - Training Epoch: 1/2, step 1895/7134 completed (loss: 0.40442705154418945, acc: 0.915032684803009)
[2024-12-17 01:48:16,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:17,121][root][INFO] - Training Epoch: 1/2, step 1896/7134 completed (loss: 0.15699024498462677, acc: 0.9647058844566345)
[2024-12-17 01:48:17,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:17,463][root][INFO] - Training Epoch: 1/2, step 1897/7134 completed (loss: 0.09358642995357513, acc: 0.979629635810852)
[2024-12-17 01:48:17,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:17,788][root][INFO] - Training Epoch: 1/2, step 1898/7134 completed (loss: 0.13488464057445526, acc: 0.9618573784828186)
[2024-12-17 01:48:17,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:18,073][root][INFO] - Training Epoch: 1/2, step 1899/7134 completed (loss: 0.17940451204776764, acc: 0.965641975402832)
[2024-12-17 01:48:18,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:18,398][root][INFO] - Training Epoch: 1/2, step 1900/7134 completed (loss: 0.1101924404501915, acc: 0.9757281541824341)
[2024-12-17 01:48:18,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:18,726][root][INFO] - Training Epoch: 1/2, step 1901/7134 completed (loss: 0.1454179435968399, acc: 0.97074955701828)
[2024-12-17 01:48:18,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:19,043][root][INFO] - Training Epoch: 1/2, step 1902/7134 completed (loss: 0.09800156950950623, acc: 0.9753954410552979)
[2024-12-17 01:48:19,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:19,392][root][INFO] - Training Epoch: 1/2, step 1903/7134 completed (loss: 0.1295391470193863, acc: 0.9618055820465088)
[2024-12-17 01:48:19,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:19,707][root][INFO] - Training Epoch: 1/2, step 1904/7134 completed (loss: 0.10311309248209, acc: 0.9661017060279846)
[2024-12-17 01:48:19,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:20,028][root][INFO] - Training Epoch: 1/2, step 1905/7134 completed (loss: 0.13364124298095703, acc: 0.9591001868247986)
[2024-12-17 01:48:20,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:20,382][root][INFO] - Training Epoch: 1/2, step 1906/7134 completed (loss: 0.10120241343975067, acc: 0.9785575270652771)
[2024-12-17 01:48:20,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:20,706][root][INFO] - Training Epoch: 1/2, step 1907/7134 completed (loss: 0.11073029786348343, acc: 0.9764705896377563)
[2024-12-17 01:48:20,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:21,050][root][INFO] - Training Epoch: 1/2, step 1908/7134 completed (loss: 0.1049845740199089, acc: 0.9720730185508728)
[2024-12-17 01:48:21,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:21,380][root][INFO] - Training Epoch: 1/2, step 1909/7134 completed (loss: 0.11921728402376175, acc: 0.9708608984947205)
[2024-12-17 01:48:21,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:21,741][root][INFO] - Training Epoch: 1/2, step 1910/7134 completed (loss: 0.14389857649803162, acc: 0.9660087823867798)
[2024-12-17 01:48:21,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:22,091][root][INFO] - Training Epoch: 1/2, step 1911/7134 completed (loss: 0.11933252960443497, acc: 0.9793689250946045)
[2024-12-17 01:48:22,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:22,443][root][INFO] - Training Epoch: 1/2, step 1912/7134 completed (loss: 0.08611041307449341, acc: 0.9826897382736206)
[2024-12-17 01:48:22,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:22,802][root][INFO] - Training Epoch: 1/2, step 1913/7134 completed (loss: 0.14169783890247345, acc: 0.9740259647369385)
[2024-12-17 01:48:22,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:23,158][root][INFO] - Training Epoch: 1/2, step 1914/7134 completed (loss: 0.1335020363330841, acc: 0.9715832471847534)
[2024-12-17 01:48:23,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:23,467][root][INFO] - Training Epoch: 1/2, step 1915/7134 completed (loss: 0.0987376868724823, acc: 0.980424165725708)
[2024-12-17 01:48:23,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:23,787][root][INFO] - Training Epoch: 1/2, step 1916/7134 completed (loss: 0.09783323854207993, acc: 0.9744214415550232)
[2024-12-17 01:48:23,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:24,136][root][INFO] - Training Epoch: 1/2, step 1917/7134 completed (loss: 0.1037544459104538, acc: 0.9803921580314636)
[2024-12-17 01:48:24,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:24,442][root][INFO] - Training Epoch: 1/2, step 1918/7134 completed (loss: 0.11832747608423233, acc: 0.9717868566513062)
[2024-12-17 01:48:24,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:24,815][root][INFO] - Training Epoch: 1/2, step 1919/7134 completed (loss: 0.11940076947212219, acc: 0.9756097793579102)
[2024-12-17 01:48:24,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:25,149][root][INFO] - Training Epoch: 1/2, step 1920/7134 completed (loss: 0.08775658160448074, acc: 0.9737654328346252)
[2024-12-17 01:48:25,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:25,467][root][INFO] - Training Epoch: 1/2, step 1921/7134 completed (loss: 0.12026866525411606, acc: 0.9806094169616699)
[2024-12-17 01:48:25,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:25,831][root][INFO] - Training Epoch: 1/2, step 1922/7134 completed (loss: 0.10948698222637177, acc: 0.9771371483802795)
[2024-12-17 01:48:25,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:26,166][root][INFO] - Training Epoch: 1/2, step 1923/7134 completed (loss: 0.13226091861724854, acc: 0.9698492288589478)
[2024-12-17 01:48:26,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:26,506][root][INFO] - Training Epoch: 1/2, step 1924/7134 completed (loss: 0.1698177456855774, acc: 0.9656652212142944)
[2024-12-17 01:48:26,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:26,886][root][INFO] - Training Epoch: 1/2, step 1925/7134 completed (loss: 0.18002544343471527, acc: 0.9576719403266907)
[2024-12-17 01:48:27,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:27,248][root][INFO] - Training Epoch: 1/2, step 1926/7134 completed (loss: 0.06504818052053452, acc: 0.9826353192329407)
[2024-12-17 01:48:27,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:27,620][root][INFO] - Training Epoch: 1/2, step 1927/7134 completed (loss: 0.12410049885511398, acc: 0.9745856523513794)
[2024-12-17 01:48:27,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:27,986][root][INFO] - Training Epoch: 1/2, step 1928/7134 completed (loss: 0.10405970364809036, acc: 0.9741641283035278)
[2024-12-17 01:48:28,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:28,329][root][INFO] - Training Epoch: 1/2, step 1929/7134 completed (loss: 0.07119995355606079, acc: 0.9872881174087524)
[2024-12-17 01:48:28,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:28,680][root][INFO] - Training Epoch: 1/2, step 1930/7134 completed (loss: 0.16290690004825592, acc: 0.960629940032959)
[2024-12-17 01:48:28,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:29,044][root][INFO] - Training Epoch: 1/2, step 1931/7134 completed (loss: 0.20496246218681335, acc: 0.9595448970794678)
[2024-12-17 01:48:29,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:29,351][root][INFO] - Training Epoch: 1/2, step 1932/7134 completed (loss: 0.19764356315135956, acc: 0.9507462978363037)
[2024-12-17 01:48:29,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:29,695][root][INFO] - Training Epoch: 1/2, step 1933/7134 completed (loss: 0.3085325062274933, acc: 0.9327731132507324)
[2024-12-17 01:48:29,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:30,028][root][INFO] - Training Epoch: 1/2, step 1934/7134 completed (loss: 0.10603885352611542, acc: 0.9703390002250671)
[2024-12-17 01:48:30,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:30,388][root][INFO] - Training Epoch: 1/2, step 1935/7134 completed (loss: 0.22785010933876038, acc: 0.9534206986427307)
[2024-12-17 01:48:30,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:30,744][root][INFO] - Training Epoch: 1/2, step 1936/7134 completed (loss: 0.07372269779443741, acc: 0.9842022061347961)
[2024-12-17 01:48:30,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:31,072][root][INFO] - Training Epoch: 1/2, step 1937/7134 completed (loss: 0.15731249749660492, acc: 0.9594155550003052)
[2024-12-17 01:48:31,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:31,405][root][INFO] - Training Epoch: 1/2, step 1938/7134 completed (loss: 0.19713830947875977, acc: 0.9572649598121643)
[2024-12-17 01:48:31,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:31,728][root][INFO] - Training Epoch: 1/2, step 1939/7134 completed (loss: 0.11700340360403061, acc: 0.9745762944221497)
[2024-12-17 01:48:31,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:32,070][root][INFO] - Training Epoch: 1/2, step 1940/7134 completed (loss: 0.1680135875940323, acc: 0.9591836929321289)
[2024-12-17 01:48:32,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:32,421][root][INFO] - Training Epoch: 1/2, step 1941/7134 completed (loss: 0.2353469580411911, acc: 0.9385026693344116)
[2024-12-17 01:48:32,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:32,740][root][INFO] - Training Epoch: 1/2, step 1942/7134 completed (loss: 0.12059026956558228, acc: 0.9715447425842285)
[2024-12-17 01:48:32,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:33,102][root][INFO] - Training Epoch: 1/2, step 1943/7134 completed (loss: 0.24743549525737762, acc: 0.9304878115653992)
[2024-12-17 01:48:33,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:33,447][root][INFO] - Training Epoch: 1/2, step 1944/7134 completed (loss: 0.19317400455474854, acc: 0.9488117098808289)
[2024-12-17 01:48:33,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:33,783][root][INFO] - Training Epoch: 1/2, step 1945/7134 completed (loss: 0.19335001707077026, acc: 0.9527559280395508)
[2024-12-17 01:48:33,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:34,122][root][INFO] - Training Epoch: 1/2, step 1946/7134 completed (loss: 0.17099536955356598, acc: 0.9575551748275757)
[2024-12-17 01:48:34,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:34,459][root][INFO] - Training Epoch: 1/2, step 1947/7134 completed (loss: 0.213646799325943, acc: 0.949999988079071)
[2024-12-17 01:48:34,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:34,784][root][INFO] - Training Epoch: 1/2, step 1948/7134 completed (loss: 0.23444639146327972, acc: 0.9392789602279663)
[2024-12-17 01:48:34,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:35,066][root][INFO] - Training Epoch: 1/2, step 1949/7134 completed (loss: 0.10615313798189163, acc: 0.9732441306114197)
[2024-12-17 01:48:35,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:35,414][root][INFO] - Training Epoch: 1/2, step 1950/7134 completed (loss: 0.16855916380882263, acc: 0.956204354763031)
[2024-12-17 01:48:35,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:35,783][root][INFO] - Training Epoch: 1/2, step 1951/7134 completed (loss: 0.1571844071149826, acc: 0.9598662257194519)
[2024-12-17 01:48:35,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:36,111][root][INFO] - Training Epoch: 1/2, step 1952/7134 completed (loss: 0.2343524992465973, acc: 0.9284525513648987)
[2024-12-17 01:48:36,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:36,450][root][INFO] - Training Epoch: 1/2, step 1953/7134 completed (loss: 0.14103104174137115, acc: 0.9597523212432861)
[2024-12-17 01:48:36,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:36,734][root][INFO] - Training Epoch: 1/2, step 1954/7134 completed (loss: 0.13544867932796478, acc: 0.9512194991111755)
[2024-12-17 01:48:36,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:37,076][root][INFO] - Training Epoch: 1/2, step 1955/7134 completed (loss: 0.1512671709060669, acc: 0.95782071352005)
[2024-12-17 01:48:37,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:37,336][root][INFO] - Training Epoch: 1/2, step 1956/7134 completed (loss: 0.0913519635796547, acc: 0.9731183052062988)
[2024-12-17 01:48:37,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:37,649][root][INFO] - Training Epoch: 1/2, step 1957/7134 completed (loss: 0.12970831990242004, acc: 0.9629629850387573)
[2024-12-17 01:48:37,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:37,854][root][INFO] - Training Epoch: 1/2, step 1958/7134 completed (loss: 0.1840067207813263, acc: 0.9570200443267822)
[2024-12-17 01:48:37,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:38,178][root][INFO] - Training Epoch: 1/2, step 1959/7134 completed (loss: 0.096781425178051, acc: 0.9765458703041077)
[2024-12-17 01:48:38,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:38,502][root][INFO] - Training Epoch: 1/2, step 1960/7134 completed (loss: 0.09129698574542999, acc: 0.981203019618988)
[2024-12-17 01:48:38,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:38,785][root][INFO] - Training Epoch: 1/2, step 1961/7134 completed (loss: 0.14630362391471863, acc: 0.9665551781654358)
[2024-12-17 01:48:38,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:39,116][root][INFO] - Training Epoch: 1/2, step 1962/7134 completed (loss: 0.11551066488027573, acc: 0.9748603105545044)
[2024-12-17 01:48:39,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:39,432][root][INFO] - Training Epoch: 1/2, step 1963/7134 completed (loss: 0.16032107174396515, acc: 0.9499136209487915)
[2024-12-17 01:48:39,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:39,771][root][INFO] - Training Epoch: 1/2, step 1964/7134 completed (loss: 0.13869597017765045, acc: 0.970695972442627)
[2024-12-17 01:48:39,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:40,096][root][INFO] - Training Epoch: 1/2, step 1965/7134 completed (loss: 0.14041221141815186, acc: 0.956764280796051)
[2024-12-17 01:48:40,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:40,421][root][INFO] - Training Epoch: 1/2, step 1966/7134 completed (loss: 0.10498744249343872, acc: 0.9785932898521423)
[2024-12-17 01:48:40,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:40,773][root][INFO] - Training Epoch: 1/2, step 1967/7134 completed (loss: 0.14667639136314392, acc: 0.9668790102005005)
[2024-12-17 01:48:40,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:41,124][root][INFO] - Training Epoch: 1/2, step 1968/7134 completed (loss: 0.11791502684354782, acc: 0.9617283940315247)
[2024-12-17 01:48:41,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:41,451][root][INFO] - Training Epoch: 1/2, step 1969/7134 completed (loss: 0.1492539644241333, acc: 0.9613333344459534)
[2024-12-17 01:48:41,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:41,798][root][INFO] - Training Epoch: 1/2, step 1970/7134 completed (loss: 0.13857696950435638, acc: 0.9677914381027222)
[2024-12-17 01:48:41,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:42,123][root][INFO] - Training Epoch: 1/2, step 1971/7134 completed (loss: 0.14898474514484406, acc: 0.9694960117340088)
[2024-12-17 01:48:42,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:42,396][root][INFO] - Training Epoch: 1/2, step 1972/7134 completed (loss: 0.4587298035621643, acc: 0.8894348740577698)
[2024-12-17 01:48:42,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:42,716][root][INFO] - Training Epoch: 1/2, step 1973/7134 completed (loss: 0.2792949080467224, acc: 0.9142857193946838)
[2024-12-17 01:48:42,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:43,073][root][INFO] - Training Epoch: 1/2, step 1974/7134 completed (loss: 0.11342848837375641, acc: 0.9685929417610168)
[2024-12-17 01:48:43,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:43,395][root][INFO] - Training Epoch: 1/2, step 1975/7134 completed (loss: 0.1453475058078766, acc: 0.9590908885002136)
[2024-12-17 01:48:43,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:43,747][root][INFO] - Training Epoch: 1/2, step 1976/7134 completed (loss: 0.12804846465587616, acc: 0.9614949226379395)
[2024-12-17 01:48:43,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:44,097][root][INFO] - Training Epoch: 1/2, step 1977/7134 completed (loss: 0.1948646456003189, acc: 0.9492753744125366)
[2024-12-17 01:48:44,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:44,437][root][INFO] - Training Epoch: 1/2, step 1978/7134 completed (loss: 0.07415477931499481, acc: 0.9838926196098328)
[2024-12-17 01:48:44,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:44,792][root][INFO] - Training Epoch: 1/2, step 1979/7134 completed (loss: 0.14637577533721924, acc: 0.9700520634651184)
[2024-12-17 01:48:44,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:45,149][root][INFO] - Training Epoch: 1/2, step 1980/7134 completed (loss: 0.24757584929466248, acc: 0.9478487372398376)
[2024-12-17 01:48:45,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:45,505][root][INFO] - Training Epoch: 1/2, step 1981/7134 completed (loss: 0.13573002815246582, acc: 0.9650349617004395)
[2024-12-17 01:48:45,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:45,832][root][INFO] - Training Epoch: 1/2, step 1982/7134 completed (loss: 0.14688773453235626, acc: 0.9678249955177307)
[2024-12-17 01:48:45,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:46,160][root][INFO] - Training Epoch: 1/2, step 1983/7134 completed (loss: 0.0893394947052002, acc: 0.9758269786834717)
[2024-12-17 01:48:46,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:46,484][root][INFO] - Training Epoch: 1/2, step 1984/7134 completed (loss: 0.07445891201496124, acc: 0.982503354549408)
[2024-12-17 01:48:46,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:46,806][root][INFO] - Training Epoch: 1/2, step 1985/7134 completed (loss: 0.11958154290914536, acc: 0.9693593382835388)
[2024-12-17 01:48:46,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:47,146][root][INFO] - Training Epoch: 1/2, step 1986/7134 completed (loss: 0.1148250550031662, acc: 0.9729729890823364)
[2024-12-17 01:48:47,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:47,497][root][INFO] - Training Epoch: 1/2, step 1987/7134 completed (loss: 0.14489562809467316, acc: 0.9688385128974915)
[2024-12-17 01:48:47,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:47,839][root][INFO] - Training Epoch: 1/2, step 1988/7134 completed (loss: 0.14768575131893158, acc: 0.9572039842605591)
[2024-12-17 01:48:47,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:48,149][root][INFO] - Training Epoch: 1/2, step 1989/7134 completed (loss: 0.1080339178442955, acc: 0.980861246585846)
[2024-12-17 01:48:48,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:48,507][root][INFO] - Training Epoch: 1/2, step 1990/7134 completed (loss: 0.08876122534275055, acc: 0.9757281541824341)
[2024-12-17 01:48:48,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:48,858][root][INFO] - Training Epoch: 1/2, step 1991/7134 completed (loss: 0.08441341668367386, acc: 0.9767441749572754)
[2024-12-17 01:48:48,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:49,190][root][INFO] - Training Epoch: 1/2, step 1992/7134 completed (loss: 0.09787634015083313, acc: 0.9798449873924255)
[2024-12-17 01:48:49,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:49,513][root][INFO] - Training Epoch: 1/2, step 1993/7134 completed (loss: 0.05980825051665306, acc: 0.9894551634788513)
[2024-12-17 01:48:49,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:49,841][root][INFO] - Training Epoch: 1/2, step 1994/7134 completed (loss: 0.04080505669116974, acc: 0.9896551966667175)
[2024-12-17 01:48:49,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:50,169][root][INFO] - Training Epoch: 1/2, step 1995/7134 completed (loss: 0.05905603617429733, acc: 0.984544038772583)
[2024-12-17 01:48:50,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:50,497][root][INFO] - Training Epoch: 1/2, step 1996/7134 completed (loss: 0.07305283099412918, acc: 0.9851239919662476)
[2024-12-17 01:48:50,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:50,820][root][INFO] - Training Epoch: 1/2, step 1997/7134 completed (loss: 0.05614706873893738, acc: 0.9825327396392822)
[2024-12-17 01:48:50,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:51,141][root][INFO] - Training Epoch: 1/2, step 1998/7134 completed (loss: 0.038854170590639114, acc: 0.9905808568000793)
[2024-12-17 01:48:51,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:51,467][root][INFO] - Training Epoch: 1/2, step 1999/7134 completed (loss: 0.09903587400913239, acc: 0.9694397449493408)
[2024-12-17 01:48:51,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:51,791][root][INFO] - Training Epoch: 1/2, step 2000/7134 completed (loss: 0.09391716867685318, acc: 0.9810725450515747)
[2024-12-17 01:48:51,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:52,102][root][INFO] - Training Epoch: 1/2, step 2001/7134 completed (loss: 0.0660317912697792, acc: 0.9848484992980957)
[2024-12-17 01:48:52,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:52,423][root][INFO] - Training Epoch: 1/2, step 2002/7134 completed (loss: 0.05164242908358574, acc: 0.9878261089324951)
[2024-12-17 01:48:52,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:52,698][root][INFO] - Training Epoch: 1/2, step 2003/7134 completed (loss: 0.12144151329994202, acc: 0.9750000238418579)
[2024-12-17 01:48:52,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:52,982][root][INFO] - Training Epoch: 1/2, step 2004/7134 completed (loss: 0.34494534134864807, acc: 0.9345991611480713)
[2024-12-17 01:48:53,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:53,348][root][INFO] - Training Epoch: 1/2, step 2005/7134 completed (loss: 0.18603353202342987, acc: 0.9616438150405884)
[2024-12-17 01:48:53,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:53,626][root][INFO] - Training Epoch: 1/2, step 2006/7134 completed (loss: 0.20485123991966248, acc: 0.9538905024528503)
[2024-12-17 01:48:53,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:53,943][root][INFO] - Training Epoch: 1/2, step 2007/7134 completed (loss: 0.1061861664056778, acc: 0.9799196720123291)
[2024-12-17 01:48:54,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:54,257][root][INFO] - Training Epoch: 1/2, step 2008/7134 completed (loss: 0.12461696565151215, acc: 0.9679715037345886)
[2024-12-17 01:48:54,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:54,546][root][INFO] - Training Epoch: 1/2, step 2009/7134 completed (loss: 0.10442029684782028, acc: 0.9747292399406433)
[2024-12-17 01:48:54,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:54,859][root][INFO] - Training Epoch: 1/2, step 2010/7134 completed (loss: 0.08193846046924591, acc: 0.9879931211471558)
[2024-12-17 01:48:54,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:55,185][root][INFO] - Training Epoch: 1/2, step 2011/7134 completed (loss: 0.09094301611185074, acc: 0.9745596647262573)
[2024-12-17 01:48:55,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:55,501][root][INFO] - Training Epoch: 1/2, step 2012/7134 completed (loss: 0.12057548016309738, acc: 0.9640591740608215)
[2024-12-17 01:48:55,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:55,840][root][INFO] - Training Epoch: 1/2, step 2013/7134 completed (loss: 0.09821254760026932, acc: 0.984000027179718)
[2024-12-17 01:48:55,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:56,177][root][INFO] - Training Epoch: 1/2, step 2014/7134 completed (loss: 0.11910224705934525, acc: 0.9685039520263672)
[2024-12-17 01:48:56,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:56,506][root][INFO] - Training Epoch: 1/2, step 2015/7134 completed (loss: 0.1289019137620926, acc: 0.9671052694320679)
[2024-12-17 01:48:56,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:56,854][root][INFO] - Training Epoch: 1/2, step 2016/7134 completed (loss: 0.15871520340442657, acc: 0.9615384340286255)
[2024-12-17 01:48:56,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:57,189][root][INFO] - Training Epoch: 1/2, step 2017/7134 completed (loss: 0.14758725464344025, acc: 0.9635134935379028)
[2024-12-17 01:48:57,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:57,519][root][INFO] - Training Epoch: 1/2, step 2018/7134 completed (loss: 0.08225735276937485, acc: 0.9692307710647583)
[2024-12-17 01:48:57,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:57,838][root][INFO] - Training Epoch: 1/2, step 2019/7134 completed (loss: 0.12698602676391602, acc: 0.9641379117965698)
[2024-12-17 01:48:57,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:58,174][root][INFO] - Training Epoch: 1/2, step 2020/7134 completed (loss: 0.059634387493133545, acc: 0.9830795526504517)
[2024-12-17 01:48:58,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:58,515][root][INFO] - Training Epoch: 1/2, step 2021/7134 completed (loss: 0.1157224252820015, acc: 0.9688311815261841)
[2024-12-17 01:48:58,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:58,831][root][INFO] - Training Epoch: 1/2, step 2022/7134 completed (loss: 0.1043158620595932, acc: 0.9826689958572388)
[2024-12-17 01:48:58,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:59,162][root][INFO] - Training Epoch: 1/2, step 2023/7134 completed (loss: 0.10470576584339142, acc: 0.9810218811035156)
[2024-12-17 01:48:59,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:59,507][root][INFO] - Training Epoch: 1/2, step 2024/7134 completed (loss: 0.15258288383483887, acc: 0.9611111283302307)
[2024-12-17 01:48:59,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:59,860][root][INFO] - Training Epoch: 1/2, step 2025/7134 completed (loss: 0.07922615855932236, acc: 0.984000027179718)
[2024-12-17 01:48:59,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:00,192][root][INFO] - Training Epoch: 1/2, step 2026/7134 completed (loss: 0.14176617562770844, acc: 0.9713855385780334)
[2024-12-17 01:49:00,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:00,516][root][INFO] - Training Epoch: 1/2, step 2027/7134 completed (loss: 0.1246420368552208, acc: 0.9634551405906677)
[2024-12-17 01:49:00,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:00,849][root][INFO] - Training Epoch: 1/2, step 2028/7134 completed (loss: 0.11404313892126083, acc: 0.9663742780685425)
[2024-12-17 01:49:00,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:01,180][root][INFO] - Training Epoch: 1/2, step 2029/7134 completed (loss: 0.12916496396064758, acc: 0.9744318127632141)
[2024-12-17 01:49:01,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:01,501][root][INFO] - Training Epoch: 1/2, step 2030/7134 completed (loss: 0.20177455246448517, acc: 0.953987717628479)
[2024-12-17 01:49:01,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:01,856][root][INFO] - Training Epoch: 1/2, step 2031/7134 completed (loss: 0.12612082064151764, acc: 0.9754601120948792)
[2024-12-17 01:49:01,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:02,188][root][INFO] - Training Epoch: 1/2, step 2032/7134 completed (loss: 0.11638910323381424, acc: 0.9690860509872437)
[2024-12-17 01:49:02,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:02,543][root][INFO] - Training Epoch: 1/2, step 2033/7134 completed (loss: 0.097770094871521, acc: 0.9742709994316101)
[2024-12-17 01:49:02,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:02,863][root][INFO] - Training Epoch: 1/2, step 2034/7134 completed (loss: 0.12771521508693695, acc: 0.9770290851593018)
[2024-12-17 01:49:02,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:03,216][root][INFO] - Training Epoch: 1/2, step 2035/7134 completed (loss: 0.08099866658449173, acc: 0.9788293838500977)
[2024-12-17 01:49:03,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:03,534][root][INFO] - Training Epoch: 1/2, step 2036/7134 completed (loss: 0.09562063217163086, acc: 0.9826989769935608)
[2024-12-17 01:49:03,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:03,885][root][INFO] - Training Epoch: 1/2, step 2037/7134 completed (loss: 0.0739336609840393, acc: 0.9777448177337646)
[2024-12-17 01:49:03,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:04,239][root][INFO] - Training Epoch: 1/2, step 2038/7134 completed (loss: 0.11293898522853851, acc: 0.9657210111618042)
[2024-12-17 01:49:04,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:04,569][root][INFO] - Training Epoch: 1/2, step 2039/7134 completed (loss: 0.07243639975786209, acc: 0.9783783555030823)
[2024-12-17 01:49:04,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:04,842][root][INFO] - Training Epoch: 1/2, step 2040/7134 completed (loss: 0.09218235313892365, acc: 0.9814814925193787)
[2024-12-17 01:49:04,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:05,182][root][INFO] - Training Epoch: 1/2, step 2041/7134 completed (loss: 0.06552544981241226, acc: 0.9848901033401489)
[2024-12-17 01:49:05,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:05,494][root][INFO] - Training Epoch: 1/2, step 2042/7134 completed (loss: 0.10379160195589066, acc: 0.9717742204666138)
[2024-12-17 01:49:05,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:05,806][root][INFO] - Training Epoch: 1/2, step 2043/7134 completed (loss: 0.11060385406017303, acc: 0.9765625)
[2024-12-17 01:49:05,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:06,148][root][INFO] - Training Epoch: 1/2, step 2044/7134 completed (loss: 0.10171222686767578, acc: 0.9785330891609192)
[2024-12-17 01:49:06,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:06,462][root][INFO] - Training Epoch: 1/2, step 2045/7134 completed (loss: 0.07425899058580399, acc: 0.978300154209137)
[2024-12-17 01:49:06,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:06,737][root][INFO] - Training Epoch: 1/2, step 2046/7134 completed (loss: 0.08029468357563019, acc: 0.9756097793579102)
[2024-12-17 01:49:06,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:07,073][root][INFO] - Training Epoch: 1/2, step 2047/7134 completed (loss: 0.09906640648841858, acc: 0.9716193675994873)
[2024-12-17 01:49:07,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:07,430][root][INFO] - Training Epoch: 1/2, step 2048/7134 completed (loss: 0.11315619200468063, acc: 0.9715994000434875)
[2024-12-17 01:49:07,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:07,754][root][INFO] - Training Epoch: 1/2, step 2049/7134 completed (loss: 0.18512894213199615, acc: 0.9599999785423279)
[2024-12-17 01:49:07,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:08,067][root][INFO] - Training Epoch: 1/2, step 2050/7134 completed (loss: 0.1806749850511551, acc: 0.964102566242218)
[2024-12-17 01:49:08,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:08,385][root][INFO] - Training Epoch: 1/2, step 2051/7134 completed (loss: 0.11318053305149078, acc: 0.966796875)
[2024-12-17 01:49:08,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:08,713][root][INFO] - Training Epoch: 1/2, step 2052/7134 completed (loss: 0.19803932309150696, acc: 0.9590443968772888)
[2024-12-17 01:49:08,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:09,034][root][INFO] - Training Epoch: 1/2, step 2053/7134 completed (loss: 0.11402560025453568, acc: 0.972000002861023)
[2024-12-17 01:49:09,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:09,372][root][INFO] - Training Epoch: 1/2, step 2054/7134 completed (loss: 0.2121218591928482, acc: 0.9458598494529724)
[2024-12-17 01:49:09,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:09,710][root][INFO] - Training Epoch: 1/2, step 2055/7134 completed (loss: 0.2156858891248703, acc: 0.9527559280395508)
[2024-12-17 01:49:09,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:10,086][root][INFO] - Training Epoch: 1/2, step 2056/7134 completed (loss: 0.18823955953121185, acc: 0.9533073902130127)
[2024-12-17 01:49:10,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:10,420][root][INFO] - Training Epoch: 1/2, step 2057/7134 completed (loss: 0.16558115184307098, acc: 0.9633650183677673)
[2024-12-17 01:49:10,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:10,783][root][INFO] - Training Epoch: 1/2, step 2058/7134 completed (loss: 0.2106381058692932, acc: 0.952654242515564)
[2024-12-17 01:49:10,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:11,122][root][INFO] - Training Epoch: 1/2, step 2059/7134 completed (loss: 0.22307240962982178, acc: 0.9428076148033142)
[2024-12-17 01:49:11,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:11,462][root][INFO] - Training Epoch: 1/2, step 2060/7134 completed (loss: 0.13450869917869568, acc: 0.9685264825820923)
[2024-12-17 01:49:11,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:11,815][root][INFO] - Training Epoch: 1/2, step 2061/7134 completed (loss: 0.14111922681331635, acc: 0.9688385128974915)
[2024-12-17 01:49:11,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:12,130][root][INFO] - Training Epoch: 1/2, step 2062/7134 completed (loss: 0.15097995102405548, acc: 0.9639468789100647)
[2024-12-17 01:49:12,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:12,440][root][INFO] - Training Epoch: 1/2, step 2063/7134 completed (loss: 0.15719418227672577, acc: 0.9720149040222168)
[2024-12-17 01:49:12,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:12,778][root][INFO] - Training Epoch: 1/2, step 2064/7134 completed (loss: 0.06630946695804596, acc: 0.9828125238418579)
[2024-12-17 01:49:12,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:13,103][root][INFO] - Training Epoch: 1/2, step 2065/7134 completed (loss: 0.17851291596889496, acc: 0.9511811137199402)
[2024-12-17 01:49:13,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:13,394][root][INFO] - Training Epoch: 1/2, step 2066/7134 completed (loss: 0.1050674170255661, acc: 0.9719439148902893)
[2024-12-17 01:49:13,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:13,718][root][INFO] - Training Epoch: 1/2, step 2067/7134 completed (loss: 0.08921591937541962, acc: 0.9753320813179016)
[2024-12-17 01:49:13,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:14,040][root][INFO] - Training Epoch: 1/2, step 2068/7134 completed (loss: 0.14207112789154053, acc: 0.9648711681365967)
[2024-12-17 01:49:14,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:14,408][root][INFO] - Training Epoch: 1/2, step 2069/7134 completed (loss: 0.12739180028438568, acc: 0.9599999785423279)
[2024-12-17 01:49:14,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:14,725][root][INFO] - Training Epoch: 1/2, step 2070/7134 completed (loss: 0.1091887578368187, acc: 0.9733840227127075)
[2024-12-17 01:49:14,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:15,046][root][INFO] - Training Epoch: 1/2, step 2071/7134 completed (loss: 0.14320528507232666, acc: 0.9672130942344666)
[2024-12-17 01:49:15,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:15,357][root][INFO] - Training Epoch: 1/2, step 2072/7134 completed (loss: 0.07141967117786407, acc: 0.9801980257034302)
[2024-12-17 01:49:15,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:15,666][root][INFO] - Training Epoch: 1/2, step 2073/7134 completed (loss: 0.12278677523136139, acc: 0.9730769395828247)
[2024-12-17 01:49:15,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:16,028][root][INFO] - Training Epoch: 1/2, step 2074/7134 completed (loss: 0.1231406182050705, acc: 0.9718309640884399)
[2024-12-17 01:49:16,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:16,352][root][INFO] - Training Epoch: 1/2, step 2075/7134 completed (loss: 0.2261531800031662, acc: 0.9465776085853577)
[2024-12-17 01:49:16,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:16,711][root][INFO] - Training Epoch: 1/2, step 2076/7134 completed (loss: 0.09614909440279007, acc: 0.9769230484962463)
[2024-12-17 01:49:16,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:17,059][root][INFO] - Training Epoch: 1/2, step 2077/7134 completed (loss: 0.0911867544054985, acc: 0.9734395742416382)
[2024-12-17 01:49:17,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:17,424][root][INFO] - Training Epoch: 1/2, step 2078/7134 completed (loss: 0.08211982995271683, acc: 0.9813953638076782)
[2024-12-17 01:49:17,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:17,773][root][INFO] - Training Epoch: 1/2, step 2079/7134 completed (loss: 0.08374961465597153, acc: 0.976190447807312)
[2024-12-17 01:49:17,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:18,109][root][INFO] - Training Epoch: 1/2, step 2080/7134 completed (loss: 0.07201939076185226, acc: 0.9838235378265381)
[2024-12-17 01:49:18,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:18,448][root][INFO] - Training Epoch: 1/2, step 2081/7134 completed (loss: 0.09667877852916718, acc: 0.972423791885376)
[2024-12-17 01:49:18,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:18,811][root][INFO] - Training Epoch: 1/2, step 2082/7134 completed (loss: 0.1900801658630371, acc: 0.9601677060127258)
[2024-12-17 01:49:18,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:19,117][root][INFO] - Training Epoch: 1/2, step 2083/7134 completed (loss: 0.09965512901544571, acc: 0.9851852059364319)
[2024-12-17 01:49:19,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:19,444][root][INFO] - Training Epoch: 1/2, step 2084/7134 completed (loss: 0.07673389464616776, acc: 0.9798136353492737)
[2024-12-17 01:49:19,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:19,775][root][INFO] - Training Epoch: 1/2, step 2085/7134 completed (loss: 0.0603715181350708, acc: 0.9870610237121582)
[2024-12-17 01:49:19,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:20,090][root][INFO] - Training Epoch: 1/2, step 2086/7134 completed (loss: 0.0785825103521347, acc: 0.9771689772605896)
[2024-12-17 01:49:20,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:20,442][root][INFO] - Training Epoch: 1/2, step 2087/7134 completed (loss: 0.05662601813673973, acc: 0.991465151309967)
[2024-12-17 01:49:20,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:20,781][root][INFO] - Training Epoch: 1/2, step 2088/7134 completed (loss: 0.10634802281856537, acc: 0.9726224541664124)
[2024-12-17 01:49:20,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:21,126][root][INFO] - Training Epoch: 1/2, step 2089/7134 completed (loss: 0.1070120632648468, acc: 0.9763407111167908)
[2024-12-17 01:49:21,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:21,451][root][INFO] - Training Epoch: 1/2, step 2090/7134 completed (loss: 0.05351902171969414, acc: 0.9873617887496948)
[2024-12-17 01:49:21,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:21,777][root][INFO] - Training Epoch: 1/2, step 2091/7134 completed (loss: 0.1005021184682846, acc: 0.9763513803482056)
[2024-12-17 01:49:21,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:22,133][root][INFO] - Training Epoch: 1/2, step 2092/7134 completed (loss: 0.07325464487075806, acc: 0.9763407111167908)
[2024-12-17 01:49:22,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:22,510][root][INFO] - Training Epoch: 1/2, step 2093/7134 completed (loss: 0.07873192429542542, acc: 0.9769335389137268)
[2024-12-17 01:49:22,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:22,794][root][INFO] - Training Epoch: 1/2, step 2094/7134 completed (loss: 0.18230505287647247, acc: 0.9675456285476685)
[2024-12-17 01:49:22,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:23,145][root][INFO] - Training Epoch: 1/2, step 2095/7134 completed (loss: 0.11503750085830688, acc: 0.9722955226898193)
[2024-12-17 01:49:23,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:23,460][root][INFO] - Training Epoch: 1/2, step 2096/7134 completed (loss: 0.08260983973741531, acc: 0.9793103337287903)
[2024-12-17 01:49:23,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:23,791][root][INFO] - Training Epoch: 1/2, step 2097/7134 completed (loss: 0.0467657633125782, acc: 0.9859747290611267)
[2024-12-17 01:49:23,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:24,114][root][INFO] - Training Epoch: 1/2, step 2098/7134 completed (loss: 0.06071026250720024, acc: 0.9887459874153137)
[2024-12-17 01:49:24,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:24,435][root][INFO] - Training Epoch: 1/2, step 2099/7134 completed (loss: 0.09224822372198105, acc: 0.9724770784378052)
[2024-12-17 01:49:24,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:24,784][root][INFO] - Training Epoch: 1/2, step 2100/7134 completed (loss: 0.0808866024017334, acc: 0.9814077019691467)
[2024-12-17 01:49:24,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:25,119][root][INFO] - Training Epoch: 1/2, step 2101/7134 completed (loss: 0.08463890105485916, acc: 0.9760705232620239)
[2024-12-17 01:49:25,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:25,451][root][INFO] - Training Epoch: 1/2, step 2102/7134 completed (loss: 0.10285492241382599, acc: 0.9744898080825806)
[2024-12-17 01:49:25,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:25,783][root][INFO] - Training Epoch: 1/2, step 2103/7134 completed (loss: 0.11958782374858856, acc: 0.9616564512252808)
[2024-12-17 01:49:25,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:26,143][root][INFO] - Training Epoch: 1/2, step 2104/7134 completed (loss: 0.11775084584951401, acc: 0.9639175534248352)
[2024-12-17 01:49:26,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:26,480][root][INFO] - Training Epoch: 1/2, step 2105/7134 completed (loss: 0.20493322610855103, acc: 0.956181526184082)
[2024-12-17 01:49:26,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:26,814][root][INFO] - Training Epoch: 1/2, step 2106/7134 completed (loss: 0.14954860508441925, acc: 0.959770143032074)
[2024-12-17 01:49:26,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:27,173][root][INFO] - Training Epoch: 1/2, step 2107/7134 completed (loss: 0.1358720064163208, acc: 0.9649122953414917)
[2024-12-17 01:49:27,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:27,527][root][INFO] - Training Epoch: 1/2, step 2108/7134 completed (loss: 0.1382085084915161, acc: 0.9656203389167786)
[2024-12-17 01:49:27,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:27,846][root][INFO] - Training Epoch: 1/2, step 2109/7134 completed (loss: 0.12112672626972198, acc: 0.971781313419342)
[2024-12-17 01:49:27,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:28,210][root][INFO] - Training Epoch: 1/2, step 2110/7134 completed (loss: 0.16670770943164825, acc: 0.9622092843055725)
[2024-12-17 01:49:28,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:28,547][root][INFO] - Training Epoch: 1/2, step 2111/7134 completed (loss: 0.17161452770233154, acc: 0.9597924947738647)
[2024-12-17 01:49:28,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:28,866][root][INFO] - Training Epoch: 1/2, step 2112/7134 completed (loss: 0.2587774991989136, acc: 0.9394904375076294)
[2024-12-17 01:49:28,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:29,194][root][INFO] - Training Epoch: 1/2, step 2113/7134 completed (loss: 0.08103826642036438, acc: 0.9731743931770325)
[2024-12-17 01:49:29,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:29,529][root][INFO] - Training Epoch: 1/2, step 2114/7134 completed (loss: 0.06390353292226791, acc: 0.9816993474960327)
[2024-12-17 01:49:29,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:29,881][root][INFO] - Training Epoch: 1/2, step 2115/7134 completed (loss: 0.0871398001909256, acc: 0.9762202501296997)
[2024-12-17 01:49:29,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:30,210][root][INFO] - Training Epoch: 1/2, step 2116/7134 completed (loss: 0.10397384315729141, acc: 0.9677914381027222)
[2024-12-17 01:49:30,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:30,557][root][INFO] - Training Epoch: 1/2, step 2117/7134 completed (loss: 0.09212039411067963, acc: 0.9800994992256165)
[2024-12-17 01:49:30,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:30,895][root][INFO] - Training Epoch: 1/2, step 2118/7134 completed (loss: 0.09796588867902756, acc: 0.9795361757278442)
[2024-12-17 01:49:31,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:31,226][root][INFO] - Training Epoch: 1/2, step 2119/7134 completed (loss: 0.09686266630887985, acc: 0.9737532734870911)
[2024-12-17 01:49:31,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:31,550][root][INFO] - Training Epoch: 1/2, step 2120/7134 completed (loss: 0.1252121925354004, acc: 0.969558596611023)
[2024-12-17 01:49:31,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:31,868][root][INFO] - Training Epoch: 1/2, step 2121/7134 completed (loss: 0.15469150245189667, acc: 0.9714285731315613)
[2024-12-17 01:49:31,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:32,221][root][INFO] - Training Epoch: 1/2, step 2122/7134 completed (loss: 0.07773997634649277, acc: 0.9778645634651184)
[2024-12-17 01:49:32,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:32,542][root][INFO] - Training Epoch: 1/2, step 2123/7134 completed (loss: 0.09073881804943085, acc: 0.9764150977134705)
[2024-12-17 01:49:32,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:32,872][root][INFO] - Training Epoch: 1/2, step 2124/7134 completed (loss: 0.10205355286598206, acc: 0.9750778675079346)
[2024-12-17 01:49:33,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:33,214][root][INFO] - Training Epoch: 1/2, step 2125/7134 completed (loss: 0.06885089725255966, acc: 0.9878787994384766)
[2024-12-17 01:49:33,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:33,557][root][INFO] - Training Epoch: 1/2, step 2126/7134 completed (loss: 0.09018950909376144, acc: 0.9798319339752197)
[2024-12-17 01:49:33,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:33,880][root][INFO] - Training Epoch: 1/2, step 2127/7134 completed (loss: 0.10277362912893295, acc: 0.9719763994216919)
[2024-12-17 01:49:34,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:34,230][root][INFO] - Training Epoch: 1/2, step 2128/7134 completed (loss: 0.13188661634922028, acc: 0.9658792614936829)
[2024-12-17 01:49:34,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:34,563][root][INFO] - Training Epoch: 1/2, step 2129/7134 completed (loss: 0.12912912666797638, acc: 0.9638009071350098)
[2024-12-17 01:49:34,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:34,883][root][INFO] - Training Epoch: 1/2, step 2130/7134 completed (loss: 0.08122546970844269, acc: 0.9768977165222168)
[2024-12-17 01:49:34,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:35,188][root][INFO] - Training Epoch: 1/2, step 2131/7134 completed (loss: 0.06439682841300964, acc: 0.9814241528511047)
[2024-12-17 01:49:35,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:35,514][root][INFO] - Training Epoch: 1/2, step 2132/7134 completed (loss: 0.040412403643131256, acc: 0.9878706336021423)
[2024-12-17 01:49:35,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:35,850][root][INFO] - Training Epoch: 1/2, step 2133/7134 completed (loss: 0.07346724718809128, acc: 0.9801849126815796)
[2024-12-17 01:49:35,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:36,188][root][INFO] - Training Epoch: 1/2, step 2134/7134 completed (loss: 0.07475792616605759, acc: 0.9799196720123291)
[2024-12-17 01:49:36,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:36,513][root][INFO] - Training Epoch: 1/2, step 2135/7134 completed (loss: 0.09602959454059601, acc: 0.9668674468994141)
[2024-12-17 01:49:36,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:36,863][root][INFO] - Training Epoch: 1/2, step 2136/7134 completed (loss: 0.08250239491462708, acc: 0.9759679436683655)
[2024-12-17 01:49:36,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:37,233][root][INFO] - Training Epoch: 1/2, step 2137/7134 completed (loss: 0.07377341389656067, acc: 0.9845161437988281)
[2024-12-17 01:49:37,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:37,551][root][INFO] - Training Epoch: 1/2, step 2138/7134 completed (loss: 0.044033877551555634, acc: 0.9862805008888245)
[2024-12-17 01:49:37,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:37,886][root][INFO] - Training Epoch: 1/2, step 2139/7134 completed (loss: 0.09198973327875137, acc: 0.9722607731819153)
[2024-12-17 01:49:38,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:38,264][root][INFO] - Training Epoch: 1/2, step 2140/7134 completed (loss: 0.1305370330810547, acc: 0.9696969985961914)
[2024-12-17 01:49:38,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:38,529][root][INFO] - Training Epoch: 1/2, step 2141/7134 completed (loss: 0.06982088834047318, acc: 0.9824561476707458)
[2024-12-17 01:49:38,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:38,885][root][INFO] - Training Epoch: 1/2, step 2142/7134 completed (loss: 0.10402998328208923, acc: 0.9674220681190491)
[2024-12-17 01:49:38,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:39,239][root][INFO] - Training Epoch: 1/2, step 2143/7134 completed (loss: 0.1463221311569214, acc: 0.9666666388511658)
[2024-12-17 01:49:39,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:39,601][root][INFO] - Training Epoch: 1/2, step 2144/7134 completed (loss: 0.05862957611680031, acc: 0.9853917956352234)
[2024-12-17 01:49:39,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:39,956][root][INFO] - Training Epoch: 1/2, step 2145/7134 completed (loss: 0.13818445801734924, acc: 0.9642346501350403)
[2024-12-17 01:49:40,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:40,286][root][INFO] - Training Epoch: 1/2, step 2146/7134 completed (loss: 0.16972704231739044, acc: 0.9436619877815247)
[2024-12-17 01:49:40,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:40,649][root][INFO] - Training Epoch: 1/2, step 2147/7134 completed (loss: 0.112253338098526, acc: 0.9688279032707214)
[2024-12-17 01:49:40,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:40,986][root][INFO] - Training Epoch: 1/2, step 2148/7134 completed (loss: 0.12520265579223633, acc: 0.9694322943687439)
[2024-12-17 01:49:41,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:41,325][root][INFO] - Training Epoch: 1/2, step 2149/7134 completed (loss: 0.09297150373458862, acc: 0.9732394218444824)
[2024-12-17 01:49:41,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:41,649][root][INFO] - Training Epoch: 1/2, step 2150/7134 completed (loss: 0.11529923230409622, acc: 0.9693333506584167)
[2024-12-17 01:49:41,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:41,981][root][INFO] - Training Epoch: 1/2, step 2151/7134 completed (loss: 0.10476133227348328, acc: 0.9785714149475098)
[2024-12-17 01:49:42,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:42,315][root][INFO] - Training Epoch: 1/2, step 2152/7134 completed (loss: 0.22272172570228577, acc: 0.9485294222831726)
[2024-12-17 01:49:42,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:42,718][root][INFO] - Training Epoch: 1/2, step 2153/7134 completed (loss: 0.12641321122646332, acc: 0.9655937552452087)
[2024-12-17 01:49:42,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:43,089][root][INFO] - Training Epoch: 1/2, step 2154/7134 completed (loss: 0.14840450882911682, acc: 0.9608091115951538)
[2024-12-17 01:49:43,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:43,402][root][INFO] - Training Epoch: 1/2, step 2155/7134 completed (loss: 0.14486968517303467, acc: 0.9752747416496277)
[2024-12-17 01:49:43,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:43,721][root][INFO] - Training Epoch: 1/2, step 2156/7134 completed (loss: 0.13678602874279022, acc: 0.9548611044883728)
[2024-12-17 01:49:43,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:44,090][root][INFO] - Training Epoch: 1/2, step 2157/7134 completed (loss: 0.11461715400218964, acc: 0.9687150716781616)
[2024-12-17 01:49:44,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:44,454][root][INFO] - Training Epoch: 1/2, step 2158/7134 completed (loss: 0.1491088569164276, acc: 0.9659863710403442)
[2024-12-17 01:49:44,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:44,805][root][INFO] - Training Epoch: 1/2, step 2159/7134 completed (loss: 0.09815041720867157, acc: 0.9706258177757263)
[2024-12-17 01:49:44,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:45,163][root][INFO] - Training Epoch: 1/2, step 2160/7134 completed (loss: 0.12649144232273102, acc: 0.9724896550178528)
[2024-12-17 01:49:45,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:45,517][root][INFO] - Training Epoch: 1/2, step 2161/7134 completed (loss: 0.13681548833847046, acc: 0.9654289484024048)
[2024-12-17 01:49:45,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:45,872][root][INFO] - Training Epoch: 1/2, step 2162/7134 completed (loss: 0.13316060602664948, acc: 0.97579425573349)
[2024-12-17 01:49:45,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:46,238][root][INFO] - Training Epoch: 1/2, step 2163/7134 completed (loss: 0.1165689080953598, acc: 0.9637795090675354)
[2024-12-17 01:49:46,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:46,561][root][INFO] - Training Epoch: 1/2, step 2164/7134 completed (loss: 0.08734728395938873, acc: 0.9794167876243591)
[2024-12-17 01:49:46,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:46,923][root][INFO] - Training Epoch: 1/2, step 2165/7134 completed (loss: 0.08895526826381683, acc: 0.9756097793579102)
[2024-12-17 01:49:47,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:47,271][root][INFO] - Training Epoch: 1/2, step 2166/7134 completed (loss: 0.12100289016962051, acc: 0.9700520634651184)
[2024-12-17 01:49:47,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:47,622][root][INFO] - Training Epoch: 1/2, step 2167/7134 completed (loss: 0.1549832969903946, acc: 0.955456554889679)
[2024-12-17 01:49:47,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:47,974][root][INFO] - Training Epoch: 1/2, step 2168/7134 completed (loss: 0.10238891839981079, acc: 0.9746031761169434)
[2024-12-17 01:49:48,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:48,327][root][INFO] - Training Epoch: 1/2, step 2169/7134 completed (loss: 0.12359661608934402, acc: 0.9605568647384644)
[2024-12-17 01:49:48,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:48,665][root][INFO] - Training Epoch: 1/2, step 2170/7134 completed (loss: 0.10638744384050369, acc: 0.976710319519043)
[2024-12-17 01:49:48,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:49,030][root][INFO] - Training Epoch: 1/2, step 2171/7134 completed (loss: 0.09930695593357086, acc: 0.9750849604606628)
[2024-12-17 01:49:49,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:49,399][root][INFO] - Training Epoch: 1/2, step 2172/7134 completed (loss: 0.06342270225286484, acc: 0.9834710955619812)
[2024-12-17 01:49:49,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:49,743][root][INFO] - Training Epoch: 1/2, step 2173/7134 completed (loss: 0.12859421968460083, acc: 0.9743202328681946)
[2024-12-17 01:49:49,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:50,079][root][INFO] - Training Epoch: 1/2, step 2174/7134 completed (loss: 0.09813903272151947, acc: 0.978723406791687)
[2024-12-17 01:49:50,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:50,422][root][INFO] - Training Epoch: 1/2, step 2175/7134 completed (loss: 0.1611270308494568, acc: 0.9695290923118591)
[2024-12-17 01:49:50,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:50,809][root][INFO] - Training Epoch: 1/2, step 2176/7134 completed (loss: 0.08771640807390213, acc: 0.9798578023910522)
[2024-12-17 01:49:50,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:51,181][root][INFO] - Training Epoch: 1/2, step 2177/7134 completed (loss: 0.12319187074899673, acc: 0.9675324559211731)
[2024-12-17 01:49:51,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:51,530][root][INFO] - Training Epoch: 1/2, step 2178/7134 completed (loss: 0.07718688994646072, acc: 0.9768211841583252)
[2024-12-17 01:49:51,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:51,886][root][INFO] - Training Epoch: 1/2, step 2179/7134 completed (loss: 0.08239921927452087, acc: 0.9810126423835754)
[2024-12-17 01:49:52,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:52,249][root][INFO] - Training Epoch: 1/2, step 2180/7134 completed (loss: 0.09736476093530655, acc: 0.9728132486343384)
[2024-12-17 01:49:52,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:52,626][root][INFO] - Training Epoch: 1/2, step 2181/7134 completed (loss: 0.049886319786310196, acc: 0.9899857044219971)
[2024-12-17 01:49:52,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:52,978][root][INFO] - Training Epoch: 1/2, step 2182/7134 completed (loss: 0.1494739055633545, acc: 0.9619377255439758)
[2024-12-17 01:49:53,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:53,357][root][INFO] - Training Epoch: 1/2, step 2183/7134 completed (loss: 0.0952952578663826, acc: 0.974388837814331)
[2024-12-17 01:49:53,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:53,718][root][INFO] - Training Epoch: 1/2, step 2184/7134 completed (loss: 0.10414369404315948, acc: 0.9728434681892395)
[2024-12-17 01:49:53,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:54,067][root][INFO] - Training Epoch: 1/2, step 2185/7134 completed (loss: 0.12139088660478592, acc: 0.9702549576759338)
[2024-12-17 01:49:54,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:54,422][root][INFO] - Training Epoch: 1/2, step 2186/7134 completed (loss: 0.1950663924217224, acc: 0.9432739019393921)
[2024-12-17 01:49:54,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:54,761][root][INFO] - Training Epoch: 1/2, step 2187/7134 completed (loss: 0.22641006112098694, acc: 0.9455999732017517)
[2024-12-17 01:49:54,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:55,153][root][INFO] - Training Epoch: 1/2, step 2188/7134 completed (loss: 0.11082351952791214, acc: 0.9699042439460754)
[2024-12-17 01:49:55,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:55,480][root][INFO] - Training Epoch: 1/2, step 2189/7134 completed (loss: 0.15991581976413727, acc: 0.9602446556091309)
[2024-12-17 01:49:55,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:55,836][root][INFO] - Training Epoch: 1/2, step 2190/7134 completed (loss: 0.10337591171264648, acc: 0.9749340415000916)
[2024-12-17 01:49:55,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:56,124][root][INFO] - Training Epoch: 1/2, step 2191/7134 completed (loss: 0.1208842545747757, acc: 0.9620596170425415)
[2024-12-17 01:49:56,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:56,441][root][INFO] - Training Epoch: 1/2, step 2192/7134 completed (loss: 0.05835113301873207, acc: 0.9774011373519897)
[2024-12-17 01:49:56,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:56,786][root][INFO] - Training Epoch: 1/2, step 2193/7134 completed (loss: 0.08592566102743149, acc: 0.9840425252914429)
[2024-12-17 01:49:56,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:57,114][root][INFO] - Training Epoch: 1/2, step 2194/7134 completed (loss: 0.15928471088409424, acc: 0.9530988335609436)
[2024-12-17 01:49:57,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:57,455][root][INFO] - Training Epoch: 1/2, step 2195/7134 completed (loss: 0.07781383395195007, acc: 0.9760000109672546)
[2024-12-17 01:49:57,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:57,814][root][INFO] - Training Epoch: 1/2, step 2196/7134 completed (loss: 0.15406161546707153, acc: 0.9598445892333984)
[2024-12-17 01:49:57,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:58,145][root][INFO] - Training Epoch: 1/2, step 2197/7134 completed (loss: 0.1181601956486702, acc: 0.9726775884628296)
[2024-12-17 01:49:58,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:58,484][root][INFO] - Training Epoch: 1/2, step 2198/7134 completed (loss: 0.14438791573047638, acc: 0.9638009071350098)
[2024-12-17 01:49:58,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:58,813][root][INFO] - Training Epoch: 1/2, step 2199/7134 completed (loss: 0.0923856720328331, acc: 0.9758307933807373)
[2024-12-17 01:49:58,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:59,148][root][INFO] - Training Epoch: 1/2, step 2200/7134 completed (loss: 0.1242021694779396, acc: 0.965641975402832)
[2024-12-17 01:49:59,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:59,486][root][INFO] - Training Epoch: 1/2, step 2201/7134 completed (loss: 0.07680411636829376, acc: 0.9757575988769531)
[2024-12-17 01:49:59,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:59,816][root][INFO] - Training Epoch: 1/2, step 2202/7134 completed (loss: 0.09946473687887192, acc: 0.9766277074813843)
[2024-12-17 01:49:59,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:00,175][root][INFO] - Training Epoch: 1/2, step 2203/7134 completed (loss: 0.06830567866563797, acc: 0.9767123460769653)
[2024-12-17 01:50:00,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:00,498][root][INFO] - Training Epoch: 1/2, step 2204/7134 completed (loss: 0.09646913409233093, acc: 0.9722222089767456)
[2024-12-17 01:50:00,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:00,828][root][INFO] - Training Epoch: 1/2, step 2205/7134 completed (loss: 0.07250209897756577, acc: 0.9824561476707458)
[2024-12-17 01:50:00,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:01,150][root][INFO] - Training Epoch: 1/2, step 2206/7134 completed (loss: 0.14153625071048737, acc: 0.9666081070899963)
[2024-12-17 01:50:01,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:01,471][root][INFO] - Training Epoch: 1/2, step 2207/7134 completed (loss: 0.08076953142881393, acc: 0.9822294116020203)
[2024-12-17 01:50:01,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:01,793][root][INFO] - Training Epoch: 1/2, step 2208/7134 completed (loss: 0.10874088853597641, acc: 0.9768595099449158)
[2024-12-17 01:50:01,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:02,122][root][INFO] - Training Epoch: 1/2, step 2209/7134 completed (loss: 0.08546507358551025, acc: 0.9830268621444702)
[2024-12-17 01:50:02,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:02,445][root][INFO] - Training Epoch: 1/2, step 2210/7134 completed (loss: 0.0913938656449318, acc: 0.9726858735084534)
[2024-12-17 01:50:02,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:02,783][root][INFO] - Training Epoch: 1/2, step 2211/7134 completed (loss: 0.053120747208595276, acc: 0.9889196753501892)
[2024-12-17 01:50:02,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:03,122][root][INFO] - Training Epoch: 1/2, step 2212/7134 completed (loss: 0.044434186071157455, acc: 0.987500011920929)
[2024-12-17 01:50:03,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:03,457][root][INFO] - Training Epoch: 1/2, step 2213/7134 completed (loss: 0.06618282943964005, acc: 0.9802259802818298)
[2024-12-17 01:50:03,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:03,785][root][INFO] - Training Epoch: 1/2, step 2214/7134 completed (loss: 0.07617837190628052, acc: 0.9776119589805603)
[2024-12-17 01:50:03,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:04,108][root][INFO] - Training Epoch: 1/2, step 2215/7134 completed (loss: 0.06934066116809845, acc: 0.9803370833396912)
[2024-12-17 01:50:04,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:04,439][root][INFO] - Training Epoch: 1/2, step 2216/7134 completed (loss: 0.04132474213838577, acc: 0.9933244585990906)
[2024-12-17 01:50:04,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:04,798][root][INFO] - Training Epoch: 1/2, step 2217/7134 completed (loss: 0.0599885992705822, acc: 0.9863013625144958)
[2024-12-17 01:50:04,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:05,151][root][INFO] - Training Epoch: 1/2, step 2218/7134 completed (loss: 0.09369602054357529, acc: 0.9755747318267822)
[2024-12-17 01:50:05,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:05,487][root][INFO] - Training Epoch: 1/2, step 2219/7134 completed (loss: 0.04648432508111, acc: 0.9860896468162537)
[2024-12-17 01:50:05,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:05,825][root][INFO] - Training Epoch: 1/2, step 2220/7134 completed (loss: 0.049895938485860825, acc: 0.9858490824699402)
[2024-12-17 01:50:05,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:06,208][root][INFO] - Training Epoch: 1/2, step 2221/7134 completed (loss: 0.08142907917499542, acc: 0.9792208075523376)
[2024-12-17 01:50:06,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:06,538][root][INFO] - Training Epoch: 1/2, step 2222/7134 completed (loss: 0.10232826322317123, acc: 0.97398841381073)
[2024-12-17 01:50:06,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:06,877][root][INFO] - Training Epoch: 1/2, step 2223/7134 completed (loss: 0.08678476512432098, acc: 0.9790794849395752)
[2024-12-17 01:50:07,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:07,231][root][INFO] - Training Epoch: 1/2, step 2224/7134 completed (loss: 0.08300686627626419, acc: 0.9725651741027832)
[2024-12-17 01:50:07,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:07,572][root][INFO] - Training Epoch: 1/2, step 2225/7134 completed (loss: 0.07966288924217224, acc: 0.9826338887214661)
[2024-12-17 01:50:07,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:07,904][root][INFO] - Training Epoch: 1/2, step 2226/7134 completed (loss: 0.06243373826146126, acc: 0.978691041469574)
[2024-12-17 01:50:08,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:08,233][root][INFO] - Training Epoch: 1/2, step 2227/7134 completed (loss: 0.05740514025092125, acc: 0.9838945865631104)
[2024-12-17 01:50:08,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:08,550][root][INFO] - Training Epoch: 1/2, step 2228/7134 completed (loss: 0.045368630439043045, acc: 0.9869918823242188)
[2024-12-17 01:50:08,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:08,888][root][INFO] - Training Epoch: 1/2, step 2229/7134 completed (loss: 0.0940500944852829, acc: 0.9819999933242798)
[2024-12-17 01:50:09,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:09,209][root][INFO] - Training Epoch: 1/2, step 2230/7134 completed (loss: 0.054920744150877, acc: 0.9822006225585938)
[2024-12-17 01:50:09,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:09,528][root][INFO] - Training Epoch: 1/2, step 2231/7134 completed (loss: 0.07340656965970993, acc: 0.980079710483551)
[2024-12-17 01:50:09,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:09,868][root][INFO] - Training Epoch: 1/2, step 2232/7134 completed (loss: 0.039506182074546814, acc: 0.9933155179023743)
[2024-12-17 01:50:09,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:10,208][root][INFO] - Training Epoch: 1/2, step 2233/7134 completed (loss: 0.07324931025505066, acc: 0.9843527674674988)
[2024-12-17 01:50:10,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:10,585][root][INFO] - Training Epoch: 1/2, step 2234/7134 completed (loss: 0.03757338598370552, acc: 0.9959016442298889)
[2024-12-17 01:50:10,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:10,924][root][INFO] - Training Epoch: 1/2, step 2235/7134 completed (loss: 0.08579421043395996, acc: 0.9858934283256531)
[2024-12-17 01:50:11,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:11,241][root][INFO] - Training Epoch: 1/2, step 2236/7134 completed (loss: 0.051836978644132614, acc: 0.9865067601203918)
[2024-12-17 01:50:11,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:11,584][root][INFO] - Training Epoch: 1/2, step 2237/7134 completed (loss: 0.0953201875090599, acc: 0.9816124439239502)
[2024-12-17 01:50:11,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:11,945][root][INFO] - Training Epoch: 1/2, step 2238/7134 completed (loss: 0.1553700864315033, acc: 0.9580318331718445)
[2024-12-17 01:50:12,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:12,301][root][INFO] - Training Epoch: 1/2, step 2239/7134 completed (loss: 0.16582943499088287, acc: 0.9571428298950195)
[2024-12-17 01:50:12,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:12,658][root][INFO] - Training Epoch: 1/2, step 2240/7134 completed (loss: 0.12303369492292404, acc: 0.9727272987365723)
[2024-12-17 01:50:12,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:12,967][root][INFO] - Training Epoch: 1/2, step 2241/7134 completed (loss: 0.16930371522903442, acc: 0.9527186751365662)
[2024-12-17 01:50:13,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:13,295][root][INFO] - Training Epoch: 1/2, step 2242/7134 completed (loss: 0.24635808169841766, acc: 0.9429928660392761)
[2024-12-17 01:50:13,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:13,676][root][INFO] - Training Epoch: 1/2, step 2243/7134 completed (loss: 0.26282185316085815, acc: 0.943511426448822)
[2024-12-17 01:50:13,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:14,035][root][INFO] - Training Epoch: 1/2, step 2244/7134 completed (loss: 0.1504896879196167, acc: 0.954402506351471)
[2024-12-17 01:50:14,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:14,364][root][INFO] - Training Epoch: 1/2, step 2245/7134 completed (loss: 0.2218206524848938, acc: 0.946601927280426)
[2024-12-17 01:50:14,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:14,721][root][INFO] - Training Epoch: 1/2, step 2246/7134 completed (loss: 0.23943066596984863, acc: 0.929729700088501)
[2024-12-17 01:50:14,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:15,054][root][INFO] - Training Epoch: 1/2, step 2247/7134 completed (loss: 0.20404930412769318, acc: 0.9554597735404968)
[2024-12-17 01:50:15,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:15,405][root][INFO] - Training Epoch: 1/2, step 2248/7134 completed (loss: 0.17102454602718353, acc: 0.9571231007575989)
[2024-12-17 01:50:15,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:15,763][root][INFO] - Training Epoch: 1/2, step 2249/7134 completed (loss: 0.11673392355442047, acc: 0.9622905254364014)
[2024-12-17 01:50:15,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:16,110][root][INFO] - Training Epoch: 1/2, step 2250/7134 completed (loss: 0.1701614111661911, acc: 0.9612299203872681)
[2024-12-17 01:50:16,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:16,419][root][INFO] - Training Epoch: 1/2, step 2251/7134 completed (loss: 0.1802968978881836, acc: 0.9478458166122437)
[2024-12-17 01:50:16,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:16,742][root][INFO] - Training Epoch: 1/2, step 2252/7134 completed (loss: 0.1722414195537567, acc: 0.9579831957817078)
[2024-12-17 01:50:16,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:17,066][root][INFO] - Training Epoch: 1/2, step 2253/7134 completed (loss: 0.16552631556987762, acc: 0.9464883208274841)
[2024-12-17 01:50:17,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:17,371][root][INFO] - Training Epoch: 1/2, step 2254/7134 completed (loss: 0.20735213160514832, acc: 0.9442231059074402)
[2024-12-17 01:50:17,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:17,709][root][INFO] - Training Epoch: 1/2, step 2255/7134 completed (loss: 0.12329404801130295, acc: 0.9666160941123962)
[2024-12-17 01:50:17,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:17,984][root][INFO] - Training Epoch: 1/2, step 2256/7134 completed (loss: 0.2708933651447296, acc: 0.9292035102844238)
[2024-12-17 01:50:18,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:18,324][root][INFO] - Training Epoch: 1/2, step 2257/7134 completed (loss: 0.10064324736595154, acc: 0.9728096723556519)
[2024-12-17 01:50:18,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:18,648][root][INFO] - Training Epoch: 1/2, step 2258/7134 completed (loss: 0.10229209810495377, acc: 0.9711538553237915)
[2024-12-17 01:50:18,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:18,954][root][INFO] - Training Epoch: 1/2, step 2259/7134 completed (loss: 0.06941428780555725, acc: 0.9866666793823242)
[2024-12-17 01:50:19,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:19,273][root][INFO] - Training Epoch: 1/2, step 2260/7134 completed (loss: 0.13339686393737793, acc: 0.9712121486663818)
[2024-12-17 01:50:19,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:19,564][root][INFO] - Training Epoch: 1/2, step 2261/7134 completed (loss: 0.2191137671470642, acc: 0.9489051103591919)
[2024-12-17 01:50:19,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:19,878][root][INFO] - Training Epoch: 1/2, step 2262/7134 completed (loss: 0.09218890964984894, acc: 0.970534086227417)
[2024-12-17 01:50:20,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:20,249][root][INFO] - Training Epoch: 1/2, step 2263/7134 completed (loss: 0.11474306136369705, acc: 0.9693693518638611)
[2024-12-17 01:50:20,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:20,566][root][INFO] - Training Epoch: 1/2, step 2264/7134 completed (loss: 0.15961207449436188, acc: 0.954992949962616)
[2024-12-17 01:50:20,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:20,908][root][INFO] - Training Epoch: 1/2, step 2265/7134 completed (loss: 0.21394149959087372, acc: 0.9450171589851379)
[2024-12-17 01:50:21,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:21,245][root][INFO] - Training Epoch: 1/2, step 2266/7134 completed (loss: 0.11170580238103867, acc: 0.9731903672218323)
[2024-12-17 01:50:21,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:21,570][root][INFO] - Training Epoch: 1/2, step 2267/7134 completed (loss: 0.09841355681419373, acc: 0.9732510447502136)
[2024-12-17 01:50:21,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:21,933][root][INFO] - Training Epoch: 1/2, step 2268/7134 completed (loss: 0.09215769916772842, acc: 0.9827833771705627)
[2024-12-17 01:50:22,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:22,289][root][INFO] - Training Epoch: 1/2, step 2269/7134 completed (loss: 0.06580396741628647, acc: 0.9861634969711304)
[2024-12-17 01:50:22,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:22,617][root][INFO] - Training Epoch: 1/2, step 2270/7134 completed (loss: 0.12112332135438919, acc: 0.9668325185775757)
[2024-12-17 01:50:22,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:22,993][root][INFO] - Training Epoch: 1/2, step 2271/7134 completed (loss: 0.14564242959022522, acc: 0.9608745574951172)
[2024-12-17 01:50:23,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:23,343][root][INFO] - Training Epoch: 1/2, step 2272/7134 completed (loss: 0.10256398469209671, acc: 0.9792175889015198)
[2024-12-17 01:50:23,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:23,698][root][INFO] - Training Epoch: 1/2, step 2273/7134 completed (loss: 0.06432634592056274, acc: 0.9808382987976074)
[2024-12-17 01:50:23,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:24,058][root][INFO] - Training Epoch: 1/2, step 2274/7134 completed (loss: 0.23738665878772736, acc: 0.950318455696106)
[2024-12-17 01:50:24,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:24,409][root][INFO] - Training Epoch: 1/2, step 2275/7134 completed (loss: 0.08913115411996841, acc: 0.9730046987533569)
[2024-12-17 01:50:24,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:24,817][root][INFO] - Training Epoch: 1/2, step 2276/7134 completed (loss: 0.11811831593513489, acc: 0.9668246507644653)
[2024-12-17 01:50:24,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:25,178][root][INFO] - Training Epoch: 1/2, step 2277/7134 completed (loss: 0.13697779178619385, acc: 0.960739016532898)
[2024-12-17 01:50:25,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:25,522][root][INFO] - Training Epoch: 1/2, step 2278/7134 completed (loss: 0.214403435587883, acc: 0.9504792094230652)
[2024-12-17 01:50:25,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:25,873][root][INFO] - Training Epoch: 1/2, step 2279/7134 completed (loss: 0.11978843808174133, acc: 0.9657614827156067)
[2024-12-17 01:50:25,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:26,233][root][INFO] - Training Epoch: 1/2, step 2280/7134 completed (loss: 0.21129338443279266, acc: 0.9456906914710999)
[2024-12-17 01:50:26,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:26,558][root][INFO] - Training Epoch: 1/2, step 2281/7134 completed (loss: 0.2059050351381302, acc: 0.9520000219345093)
[2024-12-17 01:50:26,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:26,912][root][INFO] - Training Epoch: 1/2, step 2282/7134 completed (loss: 0.04857301712036133, acc: 0.988875150680542)
[2024-12-17 01:50:27,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:27,264][root][INFO] - Training Epoch: 1/2, step 2283/7134 completed (loss: 0.14287897944450378, acc: 0.9572126865386963)
[2024-12-17 01:50:27,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:27,605][root][INFO] - Training Epoch: 1/2, step 2284/7134 completed (loss: 0.1214267835021019, acc: 0.9660266041755676)
[2024-12-17 01:50:27,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:27,978][root][INFO] - Training Epoch: 1/2, step 2285/7134 completed (loss: 0.11358251422643661, acc: 0.9620958566665649)
[2024-12-17 01:50:28,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:28,352][root][INFO] - Training Epoch: 1/2, step 2286/7134 completed (loss: 0.14972621202468872, acc: 0.9533073902130127)
[2024-12-17 01:50:28,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:28,720][root][INFO] - Training Epoch: 1/2, step 2287/7134 completed (loss: 0.08943195641040802, acc: 0.974530816078186)
[2024-12-17 01:50:28,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:29,085][root][INFO] - Training Epoch: 1/2, step 2288/7134 completed (loss: 0.07789509743452072, acc: 0.9776207208633423)
[2024-12-17 01:50:29,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:29,411][root][INFO] - Training Epoch: 1/2, step 2289/7134 completed (loss: 0.1257002055644989, acc: 0.9666239023208618)
[2024-12-17 01:50:29,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:29,750][root][INFO] - Training Epoch: 1/2, step 2290/7134 completed (loss: 0.13049007952213287, acc: 0.9681528806686401)
[2024-12-17 01:50:29,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:30,099][root][INFO] - Training Epoch: 1/2, step 2291/7134 completed (loss: 0.15329709649085999, acc: 0.9541160464286804)
[2024-12-17 01:50:30,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:30,443][root][INFO] - Training Epoch: 1/2, step 2292/7134 completed (loss: 0.2298257201910019, acc: 0.944516122341156)
[2024-12-17 01:50:30,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:30,818][root][INFO] - Training Epoch: 1/2, step 2293/7134 completed (loss: 0.1536378711462021, acc: 0.9621380567550659)
[2024-12-17 01:50:30,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:31,172][root][INFO] - Training Epoch: 1/2, step 2294/7134 completed (loss: 0.15827447175979614, acc: 0.9640045166015625)
[2024-12-17 01:50:31,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:31,576][root][INFO] - Training Epoch: 1/2, step 2295/7134 completed (loss: 0.11541525274515152, acc: 0.9696106314659119)
[2024-12-17 01:50:31,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:31,938][root][INFO] - Training Epoch: 1/2, step 2296/7134 completed (loss: 0.07257722318172455, acc: 0.9819148778915405)
[2024-12-17 01:50:32,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:32,308][root][INFO] - Training Epoch: 1/2, step 2297/7134 completed (loss: 0.09855275601148605, acc: 0.9735772609710693)
[2024-12-17 01:50:32,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:32,663][root][INFO] - Training Epoch: 1/2, step 2298/7134 completed (loss: 0.13071927428245544, acc: 0.9642481803894043)
[2024-12-17 01:50:32,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:33,036][root][INFO] - Training Epoch: 1/2, step 2299/7134 completed (loss: 0.10146871954202652, acc: 0.9658703207969666)
[2024-12-17 01:50:33,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:33,419][root][INFO] - Training Epoch: 1/2, step 2300/7134 completed (loss: 0.06485258787870407, acc: 0.9808342456817627)
[2024-12-17 01:50:33,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:33,781][root][INFO] - Training Epoch: 1/2, step 2301/7134 completed (loss: 0.10258965939283371, acc: 0.9748344421386719)
[2024-12-17 01:50:33,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:34,140][root][INFO] - Training Epoch: 1/2, step 2302/7134 completed (loss: 0.12032007426023483, acc: 0.968137264251709)
[2024-12-17 01:50:34,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:34,492][root][INFO] - Training Epoch: 1/2, step 2303/7134 completed (loss: 0.11865881085395813, acc: 0.965831458568573)
[2024-12-17 01:50:34,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:34,860][root][INFO] - Training Epoch: 1/2, step 2304/7134 completed (loss: 0.13744337856769562, acc: 0.9609455466270447)
[2024-12-17 01:50:34,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:35,232][root][INFO] - Training Epoch: 1/2, step 2305/7134 completed (loss: 0.09899157285690308, acc: 0.9648562073707581)
[2024-12-17 01:50:35,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:35,586][root][INFO] - Training Epoch: 1/2, step 2306/7134 completed (loss: 0.1128150075674057, acc: 0.9745011329650879)
[2024-12-17 01:50:35,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:35,947][root][INFO] - Training Epoch: 1/2, step 2307/7134 completed (loss: 0.11330250650644302, acc: 0.9772727489471436)
[2024-12-17 01:50:36,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:36,311][root][INFO] - Training Epoch: 1/2, step 2308/7134 completed (loss: 0.12578901648521423, acc: 0.9652706980705261)
[2024-12-17 01:50:36,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:36,667][root][INFO] - Training Epoch: 1/2, step 2309/7134 completed (loss: 0.08075737953186035, acc: 0.9796162843704224)
[2024-12-17 01:50:36,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:37,015][root][INFO] - Training Epoch: 1/2, step 2310/7134 completed (loss: 0.07430542260408401, acc: 0.9819208979606628)
[2024-12-17 01:50:37,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:37,361][root][INFO] - Training Epoch: 1/2, step 2311/7134 completed (loss: 0.08620698004961014, acc: 0.98050457239151)
[2024-12-17 01:50:37,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:37,731][root][INFO] - Training Epoch: 1/2, step 2312/7134 completed (loss: 0.10457567125558853, acc: 0.9784017205238342)
[2024-12-17 01:50:37,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:38,087][root][INFO] - Training Epoch: 1/2, step 2313/7134 completed (loss: 0.12719608843326569, acc: 0.9714611768722534)
[2024-12-17 01:50:38,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:38,471][root][INFO] - Training Epoch: 1/2, step 2314/7134 completed (loss: 0.07850068062543869, acc: 0.9822419285774231)
[2024-12-17 01:50:38,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:38,842][root][INFO] - Training Epoch: 1/2, step 2315/7134 completed (loss: 0.09431498497724533, acc: 0.9752941131591797)
[2024-12-17 01:50:38,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:39,192][root][INFO] - Training Epoch: 1/2, step 2316/7134 completed (loss: 0.08202440291643143, acc: 0.9792865514755249)
[2024-12-17 01:50:39,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:39,564][root][INFO] - Training Epoch: 1/2, step 2317/7134 completed (loss: 0.10389156639575958, acc: 0.9798941612243652)
[2024-12-17 01:50:39,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:39,940][root][INFO] - Training Epoch: 1/2, step 2318/7134 completed (loss: 0.0652349591255188, acc: 0.9811715483665466)
[2024-12-17 01:50:40,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:40,295][root][INFO] - Training Epoch: 1/2, step 2319/7134 completed (loss: 0.08928224444389343, acc: 0.9770240783691406)
[2024-12-17 01:50:40,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:40,658][root][INFO] - Training Epoch: 1/2, step 2320/7134 completed (loss: 0.07029756903648376, acc: 0.9772727489471436)
[2024-12-17 01:50:40,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:40,994][root][INFO] - Training Epoch: 1/2, step 2321/7134 completed (loss: 0.07321199774742126, acc: 0.980555534362793)
[2024-12-17 01:50:41,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:41,332][root][INFO] - Training Epoch: 1/2, step 2322/7134 completed (loss: 0.06317388266324997, acc: 0.9792592525482178)
[2024-12-17 01:50:41,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:41,653][root][INFO] - Training Epoch: 1/2, step 2323/7134 completed (loss: 0.12477286159992218, acc: 0.9668769836425781)
[2024-12-17 01:50:41,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:41,992][root][INFO] - Training Epoch: 1/2, step 2324/7134 completed (loss: 0.1299244612455368, acc: 0.9772079586982727)
[2024-12-17 01:50:42,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:42,335][root][INFO] - Training Epoch: 1/2, step 2325/7134 completed (loss: 0.11308392882347107, acc: 0.9692307710647583)
[2024-12-17 01:50:42,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:42,653][root][INFO] - Training Epoch: 1/2, step 2326/7134 completed (loss: 0.06225712224841118, acc: 0.9834558963775635)
[2024-12-17 01:50:42,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:42,971][root][INFO] - Training Epoch: 1/2, step 2327/7134 completed (loss: 0.06413847208023071, acc: 0.980327844619751)
[2024-12-17 01:50:43,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:43,306][root][INFO] - Training Epoch: 1/2, step 2328/7134 completed (loss: 0.15247973799705505, acc: 0.9695340394973755)
[2024-12-17 01:50:43,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:43,641][root][INFO] - Training Epoch: 1/2, step 2329/7134 completed (loss: 0.054510366171598434, acc: 0.987596869468689)
[2024-12-17 01:50:43,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:43,966][root][INFO] - Training Epoch: 1/2, step 2330/7134 completed (loss: 0.05074537545442581, acc: 0.9862595200538635)
[2024-12-17 01:50:44,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:44,295][root][INFO] - Training Epoch: 1/2, step 2331/7134 completed (loss: 0.06081255152821541, acc: 0.9815950989723206)
[2024-12-17 01:50:44,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:44,636][root][INFO] - Training Epoch: 1/2, step 2332/7134 completed (loss: 0.08671978861093521, acc: 0.9836552739143372)
[2024-12-17 01:50:44,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:44,968][root][INFO] - Training Epoch: 1/2, step 2333/7134 completed (loss: 0.06175301596522331, acc: 0.980654776096344)
[2024-12-17 01:50:45,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:45,304][root][INFO] - Training Epoch: 1/2, step 2334/7134 completed (loss: 0.07023332267999649, acc: 0.9791044592857361)
[2024-12-17 01:50:45,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:45,657][root][INFO] - Training Epoch: 1/2, step 2335/7134 completed (loss: 0.1559445559978485, acc: 0.9629032015800476)
[2024-12-17 01:50:45,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:45,974][root][INFO] - Training Epoch: 1/2, step 2336/7134 completed (loss: 0.07563288509845734, acc: 0.984544038772583)
[2024-12-17 01:50:46,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:46,310][root][INFO] - Training Epoch: 1/2, step 2337/7134 completed (loss: 0.021197985857725143, acc: 0.9950576424598694)
[2024-12-17 01:50:46,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:46,650][root][INFO] - Training Epoch: 1/2, step 2338/7134 completed (loss: 0.07505397498607635, acc: 0.9814528822898865)
[2024-12-17 01:50:46,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:46,984][root][INFO] - Training Epoch: 1/2, step 2339/7134 completed (loss: 0.07438662648200989, acc: 0.9820554852485657)
[2024-12-17 01:50:47,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:47,320][root][INFO] - Training Epoch: 1/2, step 2340/7134 completed (loss: 0.06539637595415115, acc: 0.9834087491035461)
[2024-12-17 01:50:47,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:47,653][root][INFO] - Training Epoch: 1/2, step 2341/7134 completed (loss: 0.04211125150322914, acc: 0.9868420958518982)
[2024-12-17 01:50:47,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:47,988][root][INFO] - Training Epoch: 1/2, step 2342/7134 completed (loss: 0.06514983624219894, acc: 0.9763663411140442)
[2024-12-17 01:50:48,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:48,321][root][INFO] - Training Epoch: 1/2, step 2343/7134 completed (loss: 0.05327564850449562, acc: 0.979200005531311)
[2024-12-17 01:50:48,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:48,653][root][INFO] - Training Epoch: 1/2, step 2344/7134 completed (loss: 0.07092795521020889, acc: 0.9812206625938416)
[2024-12-17 01:50:48,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:48,987][root][INFO] - Training Epoch: 1/2, step 2345/7134 completed (loss: 0.08728236705064774, acc: 0.9706293940544128)
[2024-12-17 01:50:49,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:49,327][root][INFO] - Training Epoch: 1/2, step 2346/7134 completed (loss: 0.07101443409919739, acc: 0.9759206771850586)
[2024-12-17 01:50:49,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:49,662][root][INFO] - Training Epoch: 1/2, step 2347/7134 completed (loss: 0.10661210864782333, acc: 0.9720394611358643)
[2024-12-17 01:50:49,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:50,015][root][INFO] - Training Epoch: 1/2, step 2348/7134 completed (loss: 0.1886575073003769, acc: 0.9520807266235352)
[2024-12-17 01:50:50,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:50,353][root][INFO] - Training Epoch: 1/2, step 2349/7134 completed (loss: 0.13076002895832062, acc: 0.9597222208976746)
[2024-12-17 01:50:50,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:50,734][root][INFO] - Training Epoch: 1/2, step 2350/7134 completed (loss: 0.14261481165885925, acc: 0.9603658318519592)
[2024-12-17 01:50:50,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:51,090][root][INFO] - Training Epoch: 1/2, step 2351/7134 completed (loss: 0.1309238076210022, acc: 0.9713114500045776)
[2024-12-17 01:50:51,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:51,419][root][INFO] - Training Epoch: 1/2, step 2352/7134 completed (loss: 0.11767130345106125, acc: 0.9647436141967773)
[2024-12-17 01:50:51,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:51,782][root][INFO] - Training Epoch: 1/2, step 2353/7134 completed (loss: 0.11181948333978653, acc: 0.9659574627876282)
[2024-12-17 01:50:51,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:52,125][root][INFO] - Training Epoch: 1/2, step 2354/7134 completed (loss: 0.08291680365800858, acc: 0.9797468185424805)
[2024-12-17 01:50:52,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:52,473][root][INFO] - Training Epoch: 1/2, step 2355/7134 completed (loss: 0.09819190204143524, acc: 0.9753086566925049)
[2024-12-17 01:50:52,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:52,802][root][INFO] - Training Epoch: 1/2, step 2356/7134 completed (loss: 0.10561337321996689, acc: 0.9752650260925293)
[2024-12-17 01:50:52,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:53,115][root][INFO] - Training Epoch: 1/2, step 2357/7134 completed (loss: 0.150502011179924, acc: 0.9623016119003296)
[2024-12-17 01:50:53,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:53,472][root][INFO] - Training Epoch: 1/2, step 2358/7134 completed (loss: 0.19628551602363586, acc: 0.9518072009086609)
[2024-12-17 01:50:53,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:53,802][root][INFO] - Training Epoch: 1/2, step 2359/7134 completed (loss: 0.1271079033613205, acc: 0.9662261605262756)
[2024-12-17 01:50:53,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:54,168][root][INFO] - Training Epoch: 1/2, step 2360/7134 completed (loss: 0.12348609417676926, acc: 0.9707174301147461)
[2024-12-17 01:50:54,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:54,502][root][INFO] - Training Epoch: 1/2, step 2361/7134 completed (loss: 0.10857560485601425, acc: 0.973372757434845)
[2024-12-17 01:50:54,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:54,776][root][INFO] - Training Epoch: 1/2, step 2362/7134 completed (loss: 0.13793246448040009, acc: 0.9641255736351013)
[2024-12-17 01:50:54,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:55,160][root][INFO] - Training Epoch: 1/2, step 2363/7134 completed (loss: 0.1358693391084671, acc: 0.962920069694519)
[2024-12-17 01:50:55,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:55,483][root][INFO] - Training Epoch: 1/2, step 2364/7134 completed (loss: 0.10657130926847458, acc: 0.9726027250289917)
[2024-12-17 01:50:55,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:55,805][root][INFO] - Training Epoch: 1/2, step 2365/7134 completed (loss: 0.14461840689182281, acc: 0.9683195352554321)
[2024-12-17 01:50:55,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:56,154][root][INFO] - Training Epoch: 1/2, step 2366/7134 completed (loss: 0.09782792627811432, acc: 0.9791666865348816)
[2024-12-17 01:50:56,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:56,516][root][INFO] - Training Epoch: 1/2, step 2367/7134 completed (loss: 0.16621245443820953, acc: 0.9660804271697998)
[2024-12-17 01:50:56,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:56,875][root][INFO] - Training Epoch: 1/2, step 2368/7134 completed (loss: 0.09358813613653183, acc: 0.9733333587646484)
[2024-12-17 01:50:57,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:57,242][root][INFO] - Training Epoch: 1/2, step 2369/7134 completed (loss: 0.07082568109035492, acc: 0.9823529124259949)
[2024-12-17 01:50:57,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:57,532][root][INFO] - Training Epoch: 1/2, step 2370/7134 completed (loss: 0.08643209934234619, acc: 0.979938268661499)
[2024-12-17 01:50:57,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:57,894][root][INFO] - Training Epoch: 1/2, step 2371/7134 completed (loss: 0.11802206933498383, acc: 0.9682996869087219)
[2024-12-17 01:50:58,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:58,242][root][INFO] - Training Epoch: 1/2, step 2372/7134 completed (loss: 0.054157812148332596, acc: 0.9863945841789246)
[2024-12-17 01:50:58,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:58,569][root][INFO] - Training Epoch: 1/2, step 2373/7134 completed (loss: 0.06941547989845276, acc: 0.9789081811904907)
[2024-12-17 01:50:58,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:58,910][root][INFO] - Training Epoch: 1/2, step 2374/7134 completed (loss: 0.07475362718105316, acc: 0.9825970530509949)
[2024-12-17 01:50:58,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:59,267][root][INFO] - Training Epoch: 1/2, step 2375/7134 completed (loss: 0.14121729135513306, acc: 0.9651514887809753)
[2024-12-17 01:50:59,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:59,604][root][INFO] - Training Epoch: 1/2, step 2376/7134 completed (loss: 0.16311785578727722, acc: 0.9574105739593506)
[2024-12-17 01:50:59,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:59,961][root][INFO] - Training Epoch: 1/2, step 2377/7134 completed (loss: 0.1261531263589859, acc: 0.9749103784561157)
[2024-12-17 01:51:00,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:00,310][root][INFO] - Training Epoch: 1/2, step 2378/7134 completed (loss: 0.09726747125387192, acc: 0.9741784334182739)
[2024-12-17 01:51:00,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:00,670][root][INFO] - Training Epoch: 1/2, step 2379/7134 completed (loss: 0.17355546355247498, acc: 0.9558620452880859)
[2024-12-17 01:51:00,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:01,026][root][INFO] - Training Epoch: 1/2, step 2380/7134 completed (loss: 0.07721030712127686, acc: 0.9794437885284424)
[2024-12-17 01:51:01,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:01,340][root][INFO] - Training Epoch: 1/2, step 2381/7134 completed (loss: 0.21405130624771118, acc: 0.942470371723175)
[2024-12-17 01:51:01,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:01,660][root][INFO] - Training Epoch: 1/2, step 2382/7134 completed (loss: 0.12557464838027954, acc: 0.9740061163902283)
[2024-12-17 01:51:01,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:01,979][root][INFO] - Training Epoch: 1/2, step 2383/7134 completed (loss: 0.17483671009540558, acc: 0.9622926115989685)
[2024-12-17 01:51:02,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:02,310][root][INFO] - Training Epoch: 1/2, step 2384/7134 completed (loss: 0.137361541390419, acc: 0.9647058844566345)
[2024-12-17 01:51:02,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:02,667][root][INFO] - Training Epoch: 1/2, step 2385/7134 completed (loss: 0.09358014911413193, acc: 0.980663001537323)
[2024-12-17 01:51:02,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:02,997][root][INFO] - Training Epoch: 1/2, step 2386/7134 completed (loss: 0.1168329194188118, acc: 0.9712041616439819)
[2024-12-17 01:51:03,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:03,369][root][INFO] - Training Epoch: 1/2, step 2387/7134 completed (loss: 0.11148648709058762, acc: 0.9721577763557434)
[2024-12-17 01:51:03,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:03,722][root][INFO] - Training Epoch: 1/2, step 2388/7134 completed (loss: 0.1689843386411667, acc: 0.9582836627960205)
[2024-12-17 01:51:03,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:04,142][root][INFO] - Training Epoch: 1/2, step 2389/7134 completed (loss: 0.10579951852560043, acc: 0.9770379066467285)
[2024-12-17 01:51:04,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:04,498][root][INFO] - Training Epoch: 1/2, step 2390/7134 completed (loss: 0.15026412904262543, acc: 0.9641577005386353)
[2024-12-17 01:51:04,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:04,853][root][INFO] - Training Epoch: 1/2, step 2391/7134 completed (loss: 0.15593811869621277, acc: 0.9707750678062439)
[2024-12-17 01:51:04,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:05,201][root][INFO] - Training Epoch: 1/2, step 2392/7134 completed (loss: 0.10209594666957855, acc: 0.9746328592300415)
[2024-12-17 01:51:05,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:05,544][root][INFO] - Training Epoch: 1/2, step 2393/7134 completed (loss: 0.10308811813592911, acc: 0.9740596413612366)
[2024-12-17 01:51:05,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:05,906][root][INFO] - Training Epoch: 1/2, step 2394/7134 completed (loss: 0.11513430625200272, acc: 0.9781818389892578)
[2024-12-17 01:51:06,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:06,244][root][INFO] - Training Epoch: 1/2, step 2395/7134 completed (loss: 0.30016082525253296, acc: 0.9364820718765259)
[2024-12-17 01:51:06,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:06,608][root][INFO] - Training Epoch: 1/2, step 2396/7134 completed (loss: 0.17536021769046783, acc: 0.9545454382896423)
[2024-12-17 01:51:06,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:06,916][root][INFO] - Training Epoch: 1/2, step 2397/7134 completed (loss: 0.17041443288326263, acc: 0.960698664188385)
[2024-12-17 01:51:07,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:07,255][root][INFO] - Training Epoch: 1/2, step 2398/7134 completed (loss: 0.09437641501426697, acc: 0.9683631658554077)
[2024-12-17 01:51:07,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:07,594][root][INFO] - Training Epoch: 1/2, step 2399/7134 completed (loss: 0.17766830325126648, acc: 0.9556509256362915)
[2024-12-17 01:51:07,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:07,957][root][INFO] - Training Epoch: 1/2, step 2400/7134 completed (loss: 0.12058914452791214, acc: 0.9696551561355591)
[2024-12-17 01:51:08,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:08,292][root][INFO] - Training Epoch: 1/2, step 2401/7134 completed (loss: 0.21503499150276184, acc: 0.9430379867553711)
[2024-12-17 01:51:08,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:08,640][root][INFO] - Training Epoch: 1/2, step 2402/7134 completed (loss: 0.17259672284126282, acc: 0.9442231059074402)
[2024-12-17 01:51:08,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:08,979][root][INFO] - Training Epoch: 1/2, step 2403/7134 completed (loss: 0.09637642651796341, acc: 0.9744681119918823)
[2024-12-17 01:51:09,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:09,316][root][INFO] - Training Epoch: 1/2, step 2404/7134 completed (loss: 0.08779039233922958, acc: 0.9767759442329407)
[2024-12-17 01:51:09,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:09,636][root][INFO] - Training Epoch: 1/2, step 2405/7134 completed (loss: 0.1489500105381012, acc: 0.9515050053596497)
[2024-12-17 01:51:09,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:09,971][root][INFO] - Training Epoch: 1/2, step 2406/7134 completed (loss: 0.07306957989931107, acc: 0.9813829660415649)
[2024-12-17 01:51:10,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:10,326][root][INFO] - Training Epoch: 1/2, step 2407/7134 completed (loss: 0.16124491393566132, acc: 0.9635258316993713)
[2024-12-17 01:51:10,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:10,689][root][INFO] - Training Epoch: 1/2, step 2408/7134 completed (loss: 0.21581894159317017, acc: 0.949999988079071)
[2024-12-17 01:51:10,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:11,037][root][INFO] - Training Epoch: 1/2, step 2409/7134 completed (loss: 0.09713859856128693, acc: 0.9713114500045776)
[2024-12-17 01:51:11,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:11,368][root][INFO] - Training Epoch: 1/2, step 2410/7134 completed (loss: 0.10228593647480011, acc: 0.9684361815452576)
[2024-12-17 01:51:11,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:11,719][root][INFO] - Training Epoch: 1/2, step 2411/7134 completed (loss: 0.13769668340682983, acc: 0.963777482509613)
[2024-12-17 01:51:11,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:12,044][root][INFO] - Training Epoch: 1/2, step 2412/7134 completed (loss: 0.10663103312253952, acc: 0.9730769395828247)
[2024-12-17 01:51:12,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:12,392][root][INFO] - Training Epoch: 1/2, step 2413/7134 completed (loss: 0.10132238268852234, acc: 0.9656925201416016)
[2024-12-17 01:51:12,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:12,751][root][INFO] - Training Epoch: 1/2, step 2414/7134 completed (loss: 0.07093937695026398, acc: 0.9800994992256165)
[2024-12-17 01:51:12,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:13,128][root][INFO] - Training Epoch: 1/2, step 2415/7134 completed (loss: 0.15265564620494843, acc: 0.9602195024490356)
[2024-12-17 01:51:13,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:13,468][root][INFO] - Training Epoch: 1/2, step 2416/7134 completed (loss: 0.09425584226846695, acc: 0.9709543585777283)
[2024-12-17 01:51:13,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:13,849][root][INFO] - Training Epoch: 1/2, step 2417/7134 completed (loss: 0.11828696727752686, acc: 0.9654403328895569)
[2024-12-17 01:51:13,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:14,161][root][INFO] - Training Epoch: 1/2, step 2418/7134 completed (loss: 0.08605149388313293, acc: 0.9690576791763306)
[2024-12-17 01:51:14,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:14,503][root][INFO] - Training Epoch: 1/2, step 2419/7134 completed (loss: 0.07988490164279938, acc: 0.9771101474761963)
[2024-12-17 01:51:14,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:14,842][root][INFO] - Training Epoch: 1/2, step 2420/7134 completed (loss: 0.07172922790050507, acc: 0.9817578792572021)
[2024-12-17 01:51:14,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:15,211][root][INFO] - Training Epoch: 1/2, step 2421/7134 completed (loss: 0.16500072181224823, acc: 0.9577114582061768)
[2024-12-17 01:51:15,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:15,604][root][INFO] - Training Epoch: 1/2, step 2422/7134 completed (loss: 0.09967644512653351, acc: 0.9716312289237976)
[2024-12-17 01:51:15,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:15,921][root][INFO] - Training Epoch: 1/2, step 2423/7134 completed (loss: 0.0815524086356163, acc: 0.9790794849395752)
[2024-12-17 01:51:16,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:16,252][root][INFO] - Training Epoch: 1/2, step 2424/7134 completed (loss: 0.09152530133724213, acc: 0.9719101190567017)
[2024-12-17 01:51:16,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:16,589][root][INFO] - Training Epoch: 1/2, step 2425/7134 completed (loss: 0.08917239308357239, acc: 0.9746666550636292)
[2024-12-17 01:51:16,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:16,952][root][INFO] - Training Epoch: 1/2, step 2426/7134 completed (loss: 0.08686573058366776, acc: 0.9774078726768494)
[2024-12-17 01:51:17,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:17,310][root][INFO] - Training Epoch: 1/2, step 2427/7134 completed (loss: 0.07920020818710327, acc: 0.9721577763557434)
[2024-12-17 01:51:17,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:17,672][root][INFO] - Training Epoch: 1/2, step 2428/7134 completed (loss: 0.09345165640115738, acc: 0.9770700931549072)
[2024-12-17 01:51:17,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:18,015][root][INFO] - Training Epoch: 1/2, step 2429/7134 completed (loss: 0.12157582491636276, acc: 0.9781931638717651)
[2024-12-17 01:51:18,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:18,335][root][INFO] - Training Epoch: 1/2, step 2430/7134 completed (loss: 0.09502197802066803, acc: 0.9716840386390686)
[2024-12-17 01:51:18,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:18,679][root][INFO] - Training Epoch: 1/2, step 2431/7134 completed (loss: 0.1556091457605362, acc: 0.9692082405090332)
[2024-12-17 01:51:18,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:19,027][root][INFO] - Training Epoch: 1/2, step 2432/7134 completed (loss: 0.24179312586784363, acc: 0.9575551748275757)
[2024-12-17 01:51:19,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:19,372][root][INFO] - Training Epoch: 1/2, step 2433/7134 completed (loss: 0.15020014345645905, acc: 0.9659090638160706)
[2024-12-17 01:51:19,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:19,693][root][INFO] - Training Epoch: 1/2, step 2434/7134 completed (loss: 0.12874671816825867, acc: 0.9720497131347656)
[2024-12-17 01:51:19,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:20,055][root][INFO] - Training Epoch: 1/2, step 2435/7134 completed (loss: 0.12351533025503159, acc: 0.9657443761825562)
[2024-12-17 01:51:20,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:20,398][root][INFO] - Training Epoch: 1/2, step 2436/7134 completed (loss: 0.08539291471242905, acc: 0.9767171144485474)
[2024-12-17 01:51:20,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:20,726][root][INFO] - Training Epoch: 1/2, step 2437/7134 completed (loss: 0.0962255597114563, acc: 0.9713423848152161)
[2024-12-17 01:51:20,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:21,086][root][INFO] - Training Epoch: 1/2, step 2438/7134 completed (loss: 0.15722104907035828, acc: 0.9724880456924438)
[2024-12-17 01:51:21,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:21,445][root][INFO] - Training Epoch: 1/2, step 2439/7134 completed (loss: 0.14481544494628906, acc: 0.9590957760810852)
[2024-12-17 01:51:21,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:21,757][root][INFO] - Training Epoch: 1/2, step 2440/7134 completed (loss: 0.10352932661771774, acc: 0.9686098694801331)
[2024-12-17 01:51:21,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:22,089][root][INFO] - Training Epoch: 1/2, step 2441/7134 completed (loss: 0.22645743191242218, acc: 0.9577735066413879)
[2024-12-17 01:51:22,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:22,429][root][INFO] - Training Epoch: 1/2, step 2442/7134 completed (loss: 0.13302081823349, acc: 0.9678321480751038)
[2024-12-17 01:51:22,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:22,793][root][INFO] - Training Epoch: 1/2, step 2443/7134 completed (loss: 0.15105745196342468, acc: 0.9638386368751526)
[2024-12-17 01:51:22,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:23,123][root][INFO] - Training Epoch: 1/2, step 2444/7134 completed (loss: 0.11500723659992218, acc: 0.9734848737716675)
[2024-12-17 01:51:23,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:23,470][root][INFO] - Training Epoch: 1/2, step 2445/7134 completed (loss: 0.1597604900598526, acc: 0.9619289636611938)
[2024-12-17 01:51:23,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:23,844][root][INFO] - Training Epoch: 1/2, step 2446/7134 completed (loss: 0.18500714004039764, acc: 0.9555555582046509)
[2024-12-17 01:51:23,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:24,213][root][INFO] - Training Epoch: 1/2, step 2447/7134 completed (loss: 0.12532836198806763, acc: 0.9611542820930481)
[2024-12-17 01:51:24,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:24,554][root][INFO] - Training Epoch: 1/2, step 2448/7134 completed (loss: 0.11471747606992722, acc: 0.9719251394271851)
[2024-12-17 01:51:24,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:24,866][root][INFO] - Training Epoch: 1/2, step 2449/7134 completed (loss: 0.1306227445602417, acc: 0.9615384340286255)
[2024-12-17 01:51:24,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:25,207][root][INFO] - Training Epoch: 1/2, step 2450/7134 completed (loss: 0.11442858725786209, acc: 0.9669631719589233)
[2024-12-17 01:51:25,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:25,559][root][INFO] - Training Epoch: 1/2, step 2451/7134 completed (loss: 0.08623885363340378, acc: 0.9757961630821228)
[2024-12-17 01:51:25,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:25,907][root][INFO] - Training Epoch: 1/2, step 2452/7134 completed (loss: 0.13042229413986206, acc: 0.9570870995521545)
[2024-12-17 01:51:26,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:26,276][root][INFO] - Training Epoch: 1/2, step 2453/7134 completed (loss: 0.1298694908618927, acc: 0.9638709425926208)
[2024-12-17 01:51:26,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:26,620][root][INFO] - Training Epoch: 1/2, step 2454/7134 completed (loss: 0.10747718065977097, acc: 0.9682274460792542)
[2024-12-17 01:51:26,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:26,988][root][INFO] - Training Epoch: 1/2, step 2455/7134 completed (loss: 0.1150304451584816, acc: 0.9716714024543762)
[2024-12-17 01:51:27,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:27,327][root][INFO] - Training Epoch: 1/2, step 2456/7134 completed (loss: 0.18330562114715576, acc: 0.9468222856521606)
[2024-12-17 01:51:27,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:27,696][root][INFO] - Training Epoch: 1/2, step 2457/7134 completed (loss: 0.12869597971439362, acc: 0.9633943438529968)
[2024-12-17 01:51:27,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:28,021][root][INFO] - Training Epoch: 1/2, step 2458/7134 completed (loss: 0.17358843982219696, acc: 0.954402506351471)
[2024-12-17 01:51:28,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:28,385][root][INFO] - Training Epoch: 1/2, step 2459/7134 completed (loss: 0.07398485392332077, acc: 0.9837278127670288)
[2024-12-17 01:51:28,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:28,737][root][INFO] - Training Epoch: 1/2, step 2460/7134 completed (loss: 0.09650464355945587, acc: 0.9737206101417542)
[2024-12-17 01:51:28,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:29,073][root][INFO] - Training Epoch: 1/2, step 2461/7134 completed (loss: 0.07076611369848251, acc: 0.9739130139350891)
[2024-12-17 01:51:29,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:29,415][root][INFO] - Training Epoch: 1/2, step 2462/7134 completed (loss: 0.0935426875948906, acc: 0.9806896448135376)
[2024-12-17 01:51:29,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:29,773][root][INFO] - Training Epoch: 1/2, step 2463/7134 completed (loss: 0.09393385797739029, acc: 0.9788199663162231)
[2024-12-17 01:51:29,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:30,074][root][INFO] - Training Epoch: 1/2, step 2464/7134 completed (loss: 0.1094210222363472, acc: 0.9700374603271484)
[2024-12-17 01:51:30,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:30,419][root][INFO] - Training Epoch: 1/2, step 2465/7134 completed (loss: 0.08209765702486038, acc: 0.9788079261779785)
[2024-12-17 01:51:30,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:30,776][root][INFO] - Training Epoch: 1/2, step 2466/7134 completed (loss: 0.05385429784655571, acc: 0.9867549538612366)
[2024-12-17 01:51:30,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:31,122][root][INFO] - Training Epoch: 1/2, step 2467/7134 completed (loss: 0.08199708163738251, acc: 0.980719804763794)
[2024-12-17 01:51:31,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:31,472][root][INFO] - Training Epoch: 1/2, step 2468/7134 completed (loss: 0.07695700973272324, acc: 0.9790209531784058)
[2024-12-17 01:51:31,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:31,830][root][INFO] - Training Epoch: 1/2, step 2469/7134 completed (loss: 0.04323694109916687, acc: 0.9877216815948486)
[2024-12-17 01:51:31,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:32,163][root][INFO] - Training Epoch: 1/2, step 2470/7134 completed (loss: 0.0856492891907692, acc: 0.9781144857406616)
[2024-12-17 01:51:32,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:32,488][root][INFO] - Training Epoch: 1/2, step 2471/7134 completed (loss: 0.06350923329591751, acc: 0.9832776188850403)
[2024-12-17 01:51:32,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:32,805][root][INFO] - Training Epoch: 1/2, step 2472/7134 completed (loss: 0.05944623798131943, acc: 0.989393949508667)
[2024-12-17 01:51:32,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:33,142][root][INFO] - Training Epoch: 1/2, step 2473/7134 completed (loss: 0.09894519299268723, acc: 0.9774590134620667)
[2024-12-17 01:51:33,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:33,478][root][INFO] - Training Epoch: 1/2, step 2474/7134 completed (loss: 0.05621493235230446, acc: 0.983098566532135)
[2024-12-17 01:51:33,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:33,791][root][INFO] - Training Epoch: 1/2, step 2475/7134 completed (loss: 0.05688752606511116, acc: 0.9879931211471558)
[2024-12-17 01:51:33,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:34,125][root][INFO] - Training Epoch: 1/2, step 2476/7134 completed (loss: 0.09374000132083893, acc: 0.9777158498764038)
[2024-12-17 01:51:34,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:34,448][root][INFO] - Training Epoch: 1/2, step 2477/7134 completed (loss: 0.06870745867490768, acc: 0.9792817831039429)
[2024-12-17 01:51:34,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:34,771][root][INFO] - Training Epoch: 1/2, step 2478/7134 completed (loss: 0.04792899265885353, acc: 0.9875389337539673)
[2024-12-17 01:51:34,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:35,107][root][INFO] - Training Epoch: 1/2, step 2479/7134 completed (loss: 0.14304563403129578, acc: 0.9666136503219604)
[2024-12-17 01:51:35,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:35,425][root][INFO] - Training Epoch: 1/2, step 2480/7134 completed (loss: 0.030735889449715614, acc: 0.9933333396911621)
[2024-12-17 01:51:35,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:35,746][root][INFO] - Training Epoch: 1/2, step 2481/7134 completed (loss: 0.07136263698339462, acc: 0.9776119589805603)
[2024-12-17 01:51:35,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:36,082][root][INFO] - Training Epoch: 1/2, step 2482/7134 completed (loss: 0.12525442242622375, acc: 0.966292142868042)
[2024-12-17 01:51:36,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:36,423][root][INFO] - Training Epoch: 1/2, step 2483/7134 completed (loss: 0.08772990852594376, acc: 0.9805825352668762)
[2024-12-17 01:51:36,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:36,759][root][INFO] - Training Epoch: 1/2, step 2484/7134 completed (loss: 0.06416447460651398, acc: 0.9861111044883728)
[2024-12-17 01:51:36,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:37,089][root][INFO] - Training Epoch: 1/2, step 2485/7134 completed (loss: 0.07146202772855759, acc: 0.9809523820877075)
[2024-12-17 01:51:37,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:37,427][root][INFO] - Training Epoch: 1/2, step 2486/7134 completed (loss: 0.0722133219242096, acc: 0.9899425506591797)
[2024-12-17 01:51:37,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:37,758][root][INFO] - Training Epoch: 1/2, step 2487/7134 completed (loss: 0.14266405999660492, acc: 0.977952778339386)
[2024-12-17 01:51:37,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:38,092][root][INFO] - Training Epoch: 1/2, step 2488/7134 completed (loss: 0.05241546407341957, acc: 0.988950252532959)
[2024-12-17 01:51:38,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:38,449][root][INFO] - Training Epoch: 1/2, step 2489/7134 completed (loss: 0.05908588320016861, acc: 0.9749303460121155)
[2024-12-17 01:51:38,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:38,786][root][INFO] - Training Epoch: 1/2, step 2490/7134 completed (loss: 0.07868608832359314, acc: 0.9743223786354065)
[2024-12-17 01:51:38,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:39,113][root][INFO] - Training Epoch: 1/2, step 2491/7134 completed (loss: 0.1824944168329239, acc: 0.9603174328804016)
[2024-12-17 01:51:39,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:39,448][root][INFO] - Training Epoch: 1/2, step 2492/7134 completed (loss: 0.08202212303876877, acc: 0.9789081811904907)
[2024-12-17 01:51:39,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:39,808][root][INFO] - Training Epoch: 1/2, step 2493/7134 completed (loss: 0.12330225110054016, acc: 0.9600939154624939)
[2024-12-17 01:51:39,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:40,151][root][INFO] - Training Epoch: 1/2, step 2494/7134 completed (loss: 0.09613756090402603, acc: 0.9737171530723572)
[2024-12-17 01:51:40,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:40,503][root][INFO] - Training Epoch: 1/2, step 2495/7134 completed (loss: 0.11410794407129288, acc: 0.9674355387687683)
[2024-12-17 01:51:40,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:40,849][root][INFO] - Training Epoch: 1/2, step 2496/7134 completed (loss: 0.05320524424314499, acc: 0.9887640476226807)
[2024-12-17 01:51:40,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:41,196][root][INFO] - Training Epoch: 1/2, step 2497/7134 completed (loss: 0.08382165431976318, acc: 0.9805352687835693)
[2024-12-17 01:51:41,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:41,552][root][INFO] - Training Epoch: 1/2, step 2498/7134 completed (loss: 0.09058056026697159, acc: 0.9783845543861389)
[2024-12-17 01:51:41,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:41,909][root][INFO] - Training Epoch: 1/2, step 2499/7134 completed (loss: 0.06525833159685135, acc: 0.9806763529777527)
[2024-12-17 01:51:42,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:42,256][root][INFO] - Training Epoch: 1/2, step 2500/7134 completed (loss: 0.050541214644908905, acc: 0.9858430027961731)
[2024-12-17 01:51:42,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:42,599][root][INFO] - Training Epoch: 1/2, step 2501/7134 completed (loss: 0.08014461398124695, acc: 0.9759725332260132)
[2024-12-17 01:51:42,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:42,951][root][INFO] - Training Epoch: 1/2, step 2502/7134 completed (loss: 0.0686168298125267, acc: 0.9787985682487488)
[2024-12-17 01:51:43,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:43,260][root][INFO] - Training Epoch: 1/2, step 2503/7134 completed (loss: 0.06840015202760696, acc: 0.9800570011138916)
[2024-12-17 01:51:43,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:43,598][root][INFO] - Training Epoch: 1/2, step 2504/7134 completed (loss: 0.04462490230798721, acc: 0.9906666874885559)
[2024-12-17 01:51:43,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:43,948][root][INFO] - Training Epoch: 1/2, step 2505/7134 completed (loss: 0.08577761799097061, acc: 0.9783845543861389)
[2024-12-17 01:51:44,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:44,327][root][INFO] - Training Epoch: 1/2, step 2506/7134 completed (loss: 0.07443729043006897, acc: 0.9839743375778198)
[2024-12-17 01:51:44,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:44,676][root][INFO] - Training Epoch: 1/2, step 2507/7134 completed (loss: 0.0459168404340744, acc: 0.9860627055168152)
[2024-12-17 01:51:44,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:45,043][root][INFO] - Training Epoch: 1/2, step 2508/7134 completed (loss: 0.09398167580366135, acc: 0.9711981415748596)
[2024-12-17 01:51:45,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:45,382][root][INFO] - Training Epoch: 1/2, step 2509/7134 completed (loss: 0.0611773356795311, acc: 0.9804161787033081)
[2024-12-17 01:51:45,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:45,729][root][INFO] - Training Epoch: 1/2, step 2510/7134 completed (loss: 0.04799101501703262, acc: 0.987860381603241)
[2024-12-17 01:51:45,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:46,071][root][INFO] - Training Epoch: 1/2, step 2511/7134 completed (loss: 0.10230172425508499, acc: 0.9753363132476807)
[2024-12-17 01:51:46,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:46,402][root][INFO] - Training Epoch: 1/2, step 2512/7134 completed (loss: 0.13428926467895508, acc: 0.9689608812332153)
[2024-12-17 01:51:46,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:46,761][root][INFO] - Training Epoch: 1/2, step 2513/7134 completed (loss: 0.0754559338092804, acc: 0.978672981262207)
[2024-12-17 01:51:46,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:47,111][root][INFO] - Training Epoch: 1/2, step 2514/7134 completed (loss: 0.05210017412900925, acc: 0.9871645569801331)
[2024-12-17 01:51:47,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:47,459][root][INFO] - Training Epoch: 1/2, step 2515/7134 completed (loss: 0.061226412653923035, acc: 0.9882965087890625)
[2024-12-17 01:51:47,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:47,850][root][INFO] - Training Epoch: 1/2, step 2516/7134 completed (loss: 0.04231097921729088, acc: 0.9886363744735718)
[2024-12-17 01:51:47,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:48,217][root][INFO] - Training Epoch: 1/2, step 2517/7134 completed (loss: 0.06368227303028107, acc: 0.9850746393203735)
[2024-12-17 01:51:48,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:48,556][root][INFO] - Training Epoch: 1/2, step 2518/7134 completed (loss: 0.08663424849510193, acc: 0.9756795167922974)
[2024-12-17 01:51:48,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:48,912][root][INFO] - Training Epoch: 1/2, step 2519/7134 completed (loss: 0.05051378160715103, acc: 0.9847856163978577)
[2024-12-17 01:51:49,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:49,259][root][INFO] - Training Epoch: 1/2, step 2520/7134 completed (loss: 0.04549166187644005, acc: 0.9857549667358398)
[2024-12-17 01:51:49,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:49,613][root][INFO] - Training Epoch: 1/2, step 2521/7134 completed (loss: 0.11835841089487076, acc: 0.9781209826469421)
[2024-12-17 01:51:49,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:49,938][root][INFO] - Training Epoch: 1/2, step 2522/7134 completed (loss: 0.07021640241146088, acc: 0.984240710735321)
[2024-12-17 01:51:50,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:50,275][root][INFO] - Training Epoch: 1/2, step 2523/7134 completed (loss: 0.10390514135360718, acc: 0.9803664684295654)
[2024-12-17 01:51:50,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:50,610][root][INFO] - Training Epoch: 1/2, step 2524/7134 completed (loss: 0.033081308007240295, acc: 0.9903314709663391)
[2024-12-17 01:51:50,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:50,935][root][INFO] - Training Epoch: 1/2, step 2525/7134 completed (loss: 0.1138918548822403, acc: 0.9699499011039734)
[2024-12-17 01:51:51,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:51,191][root][INFO] - Training Epoch: 1/2, step 2526/7134 completed (loss: 0.03975993022322655, acc: 0.9882352948188782)
[2024-12-17 01:51:51,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:51,539][root][INFO] - Training Epoch: 1/2, step 2527/7134 completed (loss: 0.08094695210456848, acc: 0.9780488014221191)
[2024-12-17 01:51:51,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:51,874][root][INFO] - Training Epoch: 1/2, step 2528/7134 completed (loss: 0.062402911484241486, acc: 0.9863201379776001)
[2024-12-17 01:51:51,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:52,226][root][INFO] - Training Epoch: 1/2, step 2529/7134 completed (loss: 0.04647132754325867, acc: 0.9906914830207825)
[2024-12-17 01:51:52,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:52,585][root][INFO] - Training Epoch: 1/2, step 2530/7134 completed (loss: 0.06326738744974136, acc: 0.9805194735527039)
[2024-12-17 01:51:52,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:52,913][root][INFO] - Training Epoch: 1/2, step 2531/7134 completed (loss: 0.05349821597337723, acc: 0.988950252532959)
[2024-12-17 01:51:53,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:53,241][root][INFO] - Training Epoch: 1/2, step 2532/7134 completed (loss: 0.05225420370697975, acc: 0.9815100431442261)
[2024-12-17 01:51:53,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:53,567][root][INFO] - Training Epoch: 1/2, step 2533/7134 completed (loss: 0.09207384288311005, acc: 0.9728506803512573)
[2024-12-17 01:51:53,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:53,894][root][INFO] - Training Epoch: 1/2, step 2534/7134 completed (loss: 0.06197219714522362, acc: 0.9859872460365295)
[2024-12-17 01:51:54,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:54,227][root][INFO] - Training Epoch: 1/2, step 2535/7134 completed (loss: 0.09314487874507904, acc: 0.9768785834312439)
[2024-12-17 01:51:54,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:54,593][root][INFO] - Training Epoch: 1/2, step 2536/7134 completed (loss: 0.10696360468864441, acc: 0.9766297936439514)
[2024-12-17 01:51:54,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:54,915][root][INFO] - Training Epoch: 1/2, step 2537/7134 completed (loss: 0.14424501359462738, acc: 0.9694189429283142)
[2024-12-17 01:51:55,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:55,245][root][INFO] - Training Epoch: 1/2, step 2538/7134 completed (loss: 0.17801737785339355, acc: 0.954674243927002)
[2024-12-17 01:51:55,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:55,525][root][INFO] - Training Epoch: 1/2, step 2539/7134 completed (loss: 0.06451008468866348, acc: 0.9821428656578064)
[2024-12-17 01:51:55,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:55,858][root][INFO] - Training Epoch: 1/2, step 2540/7134 completed (loss: 0.1197843998670578, acc: 0.9724770784378052)
[2024-12-17 01:51:55,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:56,184][root][INFO] - Training Epoch: 1/2, step 2541/7134 completed (loss: 0.0821705088019371, acc: 0.9784768223762512)
[2024-12-17 01:51:56,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:56,506][root][INFO] - Training Epoch: 1/2, step 2542/7134 completed (loss: 0.14761511981487274, acc: 0.9748520851135254)
[2024-12-17 01:51:56,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:56,863][root][INFO] - Training Epoch: 1/2, step 2543/7134 completed (loss: 0.16175411641597748, acc: 0.9685792326927185)
[2024-12-17 01:51:56,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:57,213][root][INFO] - Training Epoch: 1/2, step 2544/7134 completed (loss: 0.07860693335533142, acc: 0.9819587469100952)
[2024-12-17 01:51:57,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:57,557][root][INFO] - Training Epoch: 1/2, step 2545/7134 completed (loss: 0.13765856623649597, acc: 0.9720767736434937)
[2024-12-17 01:51:57,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:57,946][root][INFO] - Training Epoch: 1/2, step 2546/7134 completed (loss: 0.19195681810379028, acc: 0.953181266784668)
[2024-12-17 01:51:58,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:58,272][root][INFO] - Training Epoch: 1/2, step 2547/7134 completed (loss: 0.0973874181509018, acc: 0.9758453965187073)
[2024-12-17 01:51:58,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:58,583][root][INFO] - Training Epoch: 1/2, step 2548/7134 completed (loss: 0.0775512084364891, acc: 0.9862204790115356)
[2024-12-17 01:51:58,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:58,908][root][INFO] - Training Epoch: 1/2, step 2549/7134 completed (loss: 0.10688265413045883, acc: 0.979742169380188)
[2024-12-17 01:51:58,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:59,226][root][INFO] - Training Epoch: 1/2, step 2550/7134 completed (loss: 0.0564228892326355, acc: 0.9836868047714233)
[2024-12-17 01:51:59,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:59,548][root][INFO] - Training Epoch: 1/2, step 2551/7134 completed (loss: 0.10297223925590515, acc: 0.9768977165222168)
[2024-12-17 01:51:59,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:59,839][root][INFO] - Training Epoch: 1/2, step 2552/7134 completed (loss: 0.04094995930790901, acc: 0.9905362725257874)
[2024-12-17 01:51:59,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:00,118][root][INFO] - Training Epoch: 1/2, step 2553/7134 completed (loss: 0.08531251549720764, acc: 0.9788519740104675)
[2024-12-17 01:52:00,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:00,460][root][INFO] - Training Epoch: 1/2, step 2554/7134 completed (loss: 0.13479585945606232, acc: 0.9648241400718689)
[2024-12-17 01:52:00,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:00,772][root][INFO] - Training Epoch: 1/2, step 2555/7134 completed (loss: 0.11030372977256775, acc: 0.9772727489471436)
[2024-12-17 01:52:00,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:01,096][root][INFO] - Training Epoch: 1/2, step 2556/7134 completed (loss: 0.09211164712905884, acc: 0.9811320900917053)
[2024-12-17 01:52:01,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:01,440][root][INFO] - Training Epoch: 1/2, step 2557/7134 completed (loss: 0.09368474036455154, acc: 0.9737704992294312)
[2024-12-17 01:52:01,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:01,777][root][INFO] - Training Epoch: 1/2, step 2558/7134 completed (loss: 0.03603903949260712, acc: 0.991909384727478)
[2024-12-17 01:52:01,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:02,139][root][INFO] - Training Epoch: 1/2, step 2559/7134 completed (loss: 0.0516388900578022, acc: 0.9918808937072754)
[2024-12-17 01:52:02,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:02,498][root][INFO] - Training Epoch: 1/2, step 2560/7134 completed (loss: 0.10899882763624191, acc: 0.9674796462059021)
[2024-12-17 01:52:02,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:02,825][root][INFO] - Training Epoch: 1/2, step 2561/7134 completed (loss: 0.1272982656955719, acc: 0.9716775417327881)
[2024-12-17 01:52:02,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:03,141][root][INFO] - Training Epoch: 1/2, step 2562/7134 completed (loss: 0.07838740199804306, acc: 0.9794871807098389)
[2024-12-17 01:52:03,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:03,483][root][INFO] - Training Epoch: 1/2, step 2563/7134 completed (loss: 0.06680970638990402, acc: 0.9838709831237793)
[2024-12-17 01:52:03,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:03,835][root][INFO] - Training Epoch: 1/2, step 2564/7134 completed (loss: 0.21604253351688385, acc: 0.9513422846794128)
[2024-12-17 01:52:03,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:04,168][root][INFO] - Training Epoch: 1/2, step 2565/7134 completed (loss: 0.05060403794050217, acc: 0.9864048361778259)
[2024-12-17 01:52:04,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:04,528][root][INFO] - Training Epoch: 1/2, step 2566/7134 completed (loss: 0.07596409320831299, acc: 0.9789325594902039)
[2024-12-17 01:52:04,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:04,810][root][INFO] - Training Epoch: 1/2, step 2567/7134 completed (loss: 0.0718749463558197, acc: 0.9805996417999268)
[2024-12-17 01:52:04,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:05,141][root][INFO] - Training Epoch: 1/2, step 2568/7134 completed (loss: 0.08528784662485123, acc: 0.9754335284233093)
[2024-12-17 01:52:05,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:05,481][root][INFO] - Training Epoch: 1/2, step 2569/7134 completed (loss: 0.09699905663728714, acc: 0.9713855385780334)
[2024-12-17 01:52:05,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:05,819][root][INFO] - Training Epoch: 1/2, step 2570/7134 completed (loss: 0.06422057747840881, acc: 0.9865067601203918)
[2024-12-17 01:52:05,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:06,134][root][INFO] - Training Epoch: 1/2, step 2571/7134 completed (loss: 0.04256153106689453, acc: 0.9912126660346985)
[2024-12-17 01:52:06,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:06,468][root][INFO] - Training Epoch: 1/2, step 2572/7134 completed (loss: 0.07971964031457901, acc: 0.9794952869415283)
[2024-12-17 01:52:06,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:06,798][root][INFO] - Training Epoch: 1/2, step 2573/7134 completed (loss: 0.16480739414691925, acc: 0.9704918265342712)
[2024-12-17 01:52:06,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:07,105][root][INFO] - Training Epoch: 1/2, step 2574/7134 completed (loss: 0.11224579811096191, acc: 0.960698664188385)
[2024-12-17 01:52:07,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:07,431][root][INFO] - Training Epoch: 1/2, step 2575/7134 completed (loss: 0.08739445358514786, acc: 0.9776951670646667)
[2024-12-17 01:52:07,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:07,758][root][INFO] - Training Epoch: 1/2, step 2576/7134 completed (loss: 0.08907457441091537, acc: 0.9810344576835632)
[2024-12-17 01:52:07,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:08,085][root][INFO] - Training Epoch: 1/2, step 2577/7134 completed (loss: 0.1693035364151001, acc: 0.9572649598121643)
[2024-12-17 01:52:08,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:08,407][root][INFO] - Training Epoch: 1/2, step 2578/7134 completed (loss: 0.12191695719957352, acc: 0.9754977226257324)
[2024-12-17 01:52:08,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:08,730][root][INFO] - Training Epoch: 1/2, step 2579/7134 completed (loss: 0.18676342070102692, acc: 0.9651898741722107)
[2024-12-17 01:52:08,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:09,081][root][INFO] - Training Epoch: 1/2, step 2580/7134 completed (loss: 0.12972846627235413, acc: 0.9647519588470459)
[2024-12-17 01:52:09,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:09,417][root][INFO] - Training Epoch: 1/2, step 2581/7134 completed (loss: 0.09210683405399323, acc: 0.9798115491867065)
[2024-12-17 01:52:09,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:09,765][root][INFO] - Training Epoch: 1/2, step 2582/7134 completed (loss: 0.07293234765529633, acc: 0.9837398529052734)
[2024-12-17 01:52:09,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:10,085][root][INFO] - Training Epoch: 1/2, step 2583/7134 completed (loss: 0.10182349383831024, acc: 0.9701279997825623)
[2024-12-17 01:52:10,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:10,389][root][INFO] - Training Epoch: 1/2, step 2584/7134 completed (loss: 0.14719226956367493, acc: 0.9650959968566895)
[2024-12-17 01:52:10,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:10,751][root][INFO] - Training Epoch: 1/2, step 2585/7134 completed (loss: 0.10819423198699951, acc: 0.971222996711731)
[2024-12-17 01:52:10,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:11,093][root][INFO] - Training Epoch: 1/2, step 2586/7134 completed (loss: 0.11048394441604614, acc: 0.9753521084785461)
[2024-12-17 01:52:11,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:11,441][root][INFO] - Training Epoch: 1/2, step 2587/7134 completed (loss: 0.11268153041601181, acc: 0.9717444777488708)
[2024-12-17 01:52:11,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:11,785][root][INFO] - Training Epoch: 1/2, step 2588/7134 completed (loss: 0.06940704584121704, acc: 0.9809004068374634)
[2024-12-17 01:52:11,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:12,109][root][INFO] - Training Epoch: 1/2, step 2589/7134 completed (loss: 0.12202348560094833, acc: 0.9699646830558777)
[2024-12-17 01:52:12,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:12,418][root][INFO] - Training Epoch: 1/2, step 2590/7134 completed (loss: 0.11996549367904663, acc: 0.9689542651176453)
[2024-12-17 01:52:12,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:12,760][root][INFO] - Training Epoch: 1/2, step 2591/7134 completed (loss: 0.11610865592956543, acc: 0.9731457829475403)
[2024-12-17 01:52:12,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:13,116][root][INFO] - Training Epoch: 1/2, step 2592/7134 completed (loss: 0.11077228933572769, acc: 0.9692496657371521)
[2024-12-17 01:52:13,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:13,471][root][INFO] - Training Epoch: 1/2, step 2593/7134 completed (loss: 0.1257740706205368, acc: 0.967277467250824)
[2024-12-17 01:52:13,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:13,798][root][INFO] - Training Epoch: 1/2, step 2594/7134 completed (loss: 0.08210474252700806, acc: 0.9801223278045654)
[2024-12-17 01:52:13,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:14,145][root][INFO] - Training Epoch: 1/2, step 2595/7134 completed (loss: 0.0877690240740776, acc: 0.9731183052062988)
[2024-12-17 01:52:14,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:14,516][root][INFO] - Training Epoch: 1/2, step 2596/7134 completed (loss: 0.11921204626560211, acc: 0.9736841917037964)
[2024-12-17 01:52:14,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:14,862][root][INFO] - Training Epoch: 1/2, step 2597/7134 completed (loss: 0.11518397927284241, acc: 0.9756757020950317)
[2024-12-17 01:52:14,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:15,196][root][INFO] - Training Epoch: 1/2, step 2598/7134 completed (loss: 0.15916799008846283, acc: 0.9613003134727478)
[2024-12-17 01:52:15,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:15,519][root][INFO] - Training Epoch: 1/2, step 2599/7134 completed (loss: 0.03857199475169182, acc: 0.9907651543617249)
[2024-12-17 01:52:15,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:15,882][root][INFO] - Training Epoch: 1/2, step 2600/7134 completed (loss: 0.09786085784435272, acc: 0.9705505967140198)
[2024-12-17 01:52:15,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:16,234][root][INFO] - Training Epoch: 1/2, step 2601/7134 completed (loss: 0.12351673096418381, acc: 0.9729363918304443)
[2024-12-17 01:52:16,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:16,576][root][INFO] - Training Epoch: 1/2, step 2602/7134 completed (loss: 0.08992880582809448, acc: 0.9757869243621826)
[2024-12-17 01:52:16,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:16,939][root][INFO] - Training Epoch: 1/2, step 2603/7134 completed (loss: 0.11877162009477615, acc: 0.97364342212677)
[2024-12-17 01:52:17,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:17,302][root][INFO] - Training Epoch: 1/2, step 2604/7134 completed (loss: 0.1674722582101822, acc: 0.9561403393745422)
[2024-12-17 01:52:17,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:17,639][root][INFO] - Training Epoch: 1/2, step 2605/7134 completed (loss: 0.2531485855579376, acc: 0.9422382712364197)
[2024-12-17 01:52:17,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:17,984][root][INFO] - Training Epoch: 1/2, step 2606/7134 completed (loss: 0.11693557351827621, acc: 0.965467631816864)
[2024-12-17 01:52:18,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:18,332][root][INFO] - Training Epoch: 1/2, step 2607/7134 completed (loss: 0.143941268324852, acc: 0.9541176557540894)
[2024-12-17 01:52:18,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:18,675][root][INFO] - Training Epoch: 1/2, step 2608/7134 completed (loss: 0.20505517721176147, acc: 0.9493201375007629)
[2024-12-17 01:52:18,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:19,017][root][INFO] - Training Epoch: 1/2, step 2609/7134 completed (loss: 0.1813582479953766, acc: 0.9582172632217407)
[2024-12-17 01:52:19,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:19,301][root][INFO] - Training Epoch: 1/2, step 2610/7134 completed (loss: 0.1719837635755539, acc: 0.9526717662811279)
[2024-12-17 01:52:19,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:19,666][root][INFO] - Training Epoch: 1/2, step 2611/7134 completed (loss: 0.15621596574783325, acc: 0.9586681723594666)
[2024-12-17 01:52:19,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:20,029][root][INFO] - Training Epoch: 1/2, step 2612/7134 completed (loss: 0.1654946506023407, acc: 0.9601366519927979)
[2024-12-17 01:52:20,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:20,405][root][INFO] - Training Epoch: 1/2, step 2613/7134 completed (loss: 0.07916533946990967, acc: 0.9746835231781006)
[2024-12-17 01:52:20,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:20,768][root][INFO] - Training Epoch: 1/2, step 2614/7134 completed (loss: 0.1946113258600235, acc: 0.9521639943122864)
[2024-12-17 01:52:20,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:21,116][root][INFO] - Training Epoch: 1/2, step 2615/7134 completed (loss: 0.17299452424049377, acc: 0.9511567950248718)
[2024-12-17 01:52:21,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:21,443][root][INFO] - Training Epoch: 1/2, step 2616/7134 completed (loss: 0.19948813319206238, acc: 0.9547325372695923)
[2024-12-17 01:52:21,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:21,799][root][INFO] - Training Epoch: 1/2, step 2617/7134 completed (loss: 0.2933427691459656, acc: 0.9244264364242554)
[2024-12-17 01:52:21,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:22,085][root][INFO] - Training Epoch: 1/2, step 2618/7134 completed (loss: 0.19759701192378998, acc: 0.9589322209358215)
[2024-12-17 01:52:22,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:22,417][root][INFO] - Training Epoch: 1/2, step 2619/7134 completed (loss: 0.1336456835269928, acc: 0.968120813369751)
[2024-12-17 01:52:22,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:22,765][root][INFO] - Training Epoch: 1/2, step 2620/7134 completed (loss: 0.17548514902591705, acc: 0.9479553699493408)
[2024-12-17 01:52:22,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:23,113][root][INFO] - Training Epoch: 1/2, step 2621/7134 completed (loss: 0.10295826196670532, acc: 0.9668246507644653)
[2024-12-17 01:52:23,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:23,474][root][INFO] - Training Epoch: 1/2, step 2622/7134 completed (loss: 0.1358749270439148, acc: 0.9705401062965393)
[2024-12-17 01:52:23,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:23,836][root][INFO] - Training Epoch: 1/2, step 2623/7134 completed (loss: 0.18664096295833588, acc: 0.9505746960639954)
[2024-12-17 01:52:23,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:24,189][root][INFO] - Training Epoch: 1/2, step 2624/7134 completed (loss: 0.1417611688375473, acc: 0.9651293754577637)
[2024-12-17 01:52:24,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:24,539][root][INFO] - Training Epoch: 1/2, step 2625/7134 completed (loss: 0.13446129858493805, acc: 0.9638888835906982)
[2024-12-17 01:52:24,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:24,893][root][INFO] - Training Epoch: 1/2, step 2626/7134 completed (loss: 0.15973854064941406, acc: 0.9591584205627441)
[2024-12-17 01:52:24,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:25,250][root][INFO] - Training Epoch: 1/2, step 2627/7134 completed (loss: 0.12019889801740646, acc: 0.9621109366416931)
[2024-12-17 01:52:25,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:25,580][root][INFO] - Training Epoch: 1/2, step 2628/7134 completed (loss: 0.1330191045999527, acc: 0.9671717286109924)
[2024-12-17 01:52:25,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:25,983][root][INFO] - Training Epoch: 1/2, step 2629/7134 completed (loss: 0.0894821509718895, acc: 0.9709228873252869)
[2024-12-17 01:52:26,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:26,306][root][INFO] - Training Epoch: 1/2, step 2630/7134 completed (loss: 0.16298694908618927, acc: 0.9520766735076904)
[2024-12-17 01:52:26,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:26,655][root][INFO] - Training Epoch: 1/2, step 2631/7134 completed (loss: 0.1383192241191864, acc: 0.9602339267730713)
[2024-12-17 01:52:26,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:27,002][root][INFO] - Training Epoch: 1/2, step 2632/7134 completed (loss: 0.10315384715795517, acc: 0.9705304503440857)
[2024-12-17 01:52:27,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:27,351][root][INFO] - Training Epoch: 1/2, step 2633/7134 completed (loss: 0.2193680703639984, acc: 0.954674243927002)
[2024-12-17 01:52:27,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:27,668][root][INFO] - Training Epoch: 1/2, step 2634/7134 completed (loss: 0.05153629556298256, acc: 0.9880059957504272)
[2024-12-17 01:52:27,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:28,022][root][INFO] - Training Epoch: 1/2, step 2635/7134 completed (loss: 0.1821683645248413, acc: 0.9527778029441833)
[2024-12-17 01:52:28,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:28,376][root][INFO] - Training Epoch: 1/2, step 2636/7134 completed (loss: 0.20164842903614044, acc: 0.9402560591697693)
[2024-12-17 01:52:28,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:28,706][root][INFO] - Training Epoch: 1/2, step 2637/7134 completed (loss: 0.3344312310218811, acc: 0.9083191752433777)
[2024-12-17 01:52:28,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:29,065][root][INFO] - Training Epoch: 1/2, step 2638/7134 completed (loss: 0.1955467164516449, acc: 0.9517601132392883)
[2024-12-17 01:52:29,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:29,388][root][INFO] - Training Epoch: 1/2, step 2639/7134 completed (loss: 0.19559788703918457, acc: 0.9481327533721924)
[2024-12-17 01:52:29,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:29,731][root][INFO] - Training Epoch: 1/2, step 2640/7134 completed (loss: 0.17065007984638214, acc: 0.9650437235832214)
[2024-12-17 01:52:29,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:30,077][root][INFO] - Training Epoch: 1/2, step 2641/7134 completed (loss: 0.16372454166412354, acc: 0.9602356553077698)
[2024-12-17 01:52:30,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:30,393][root][INFO] - Training Epoch: 1/2, step 2642/7134 completed (loss: 0.19310615956783295, acc: 0.9537366628646851)
[2024-12-17 01:52:30,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:30,735][root][INFO] - Training Epoch: 1/2, step 2643/7134 completed (loss: 0.20234167575836182, acc: 0.9534883499145508)
[2024-12-17 01:52:30,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:31,121][root][INFO] - Training Epoch: 1/2, step 2644/7134 completed (loss: 0.1305994689464569, acc: 0.9720873832702637)
[2024-12-17 01:52:31,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:31,450][root][INFO] - Training Epoch: 1/2, step 2645/7134 completed (loss: 0.1348653882741928, acc: 0.966472327709198)
[2024-12-17 01:52:31,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:31,768][root][INFO] - Training Epoch: 1/2, step 2646/7134 completed (loss: 0.25051572918891907, acc: 0.9506369233131409)
[2024-12-17 01:52:31,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:32,119][root][INFO] - Training Epoch: 1/2, step 2647/7134 completed (loss: 0.10421402752399445, acc: 0.9752925634384155)
[2024-12-17 01:52:32,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:32,455][root][INFO] - Training Epoch: 1/2, step 2648/7134 completed (loss: 0.09879226982593536, acc: 0.9729032516479492)
[2024-12-17 01:52:32,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:32,798][root][INFO] - Training Epoch: 1/2, step 2649/7134 completed (loss: 0.28667861223220825, acc: 0.9388971924781799)
[2024-12-17 01:52:32,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:33,113][root][INFO] - Training Epoch: 1/2, step 2650/7134 completed (loss: 0.22016221284866333, acc: 0.9394856095314026)
[2024-12-17 01:52:33,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:33,459][root][INFO] - Training Epoch: 1/2, step 2651/7134 completed (loss: 0.11202472448348999, acc: 0.9749702215194702)
[2024-12-17 01:52:33,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:33,791][root][INFO] - Training Epoch: 1/2, step 2652/7134 completed (loss: 0.11417579650878906, acc: 0.9709962010383606)
[2024-12-17 01:52:33,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:34,097][root][INFO] - Training Epoch: 1/2, step 2653/7134 completed (loss: 0.13433554768562317, acc: 0.9621710777282715)
[2024-12-17 01:52:34,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:34,425][root][INFO] - Training Epoch: 1/2, step 2654/7134 completed (loss: 0.11700190603733063, acc: 0.9737704992294312)
[2024-12-17 01:52:34,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:34,747][root][INFO] - Training Epoch: 1/2, step 2655/7134 completed (loss: 0.06761490553617477, acc: 0.9833585619926453)
[2024-12-17 01:52:34,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:35,081][root][INFO] - Training Epoch: 1/2, step 2656/7134 completed (loss: 0.11880367249250412, acc: 0.9721835851669312)
[2024-12-17 01:52:35,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:35,408][root][INFO] - Training Epoch: 1/2, step 2657/7134 completed (loss: 0.11482957750558853, acc: 0.9661290049552917)
[2024-12-17 01:52:35,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:35,735][root][INFO] - Training Epoch: 1/2, step 2658/7134 completed (loss: 0.22202405333518982, acc: 0.9492656588554382)
[2024-12-17 01:52:35,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:36,034][root][INFO] - Training Epoch: 1/2, step 2659/7134 completed (loss: 0.10907623916864395, acc: 0.9731800556182861)
[2024-12-17 01:52:36,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:36,321][root][INFO] - Training Epoch: 1/2, step 2660/7134 completed (loss: 0.09012667089700699, acc: 0.9778226017951965)
[2024-12-17 01:52:36,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:36,650][root][INFO] - Training Epoch: 1/2, step 2661/7134 completed (loss: 0.08947285264730453, acc: 0.9845722317695618)
[2024-12-17 01:52:36,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:37,001][root][INFO] - Training Epoch: 1/2, step 2662/7134 completed (loss: 0.053692277520895004, acc: 0.9800853729248047)
[2024-12-17 01:52:37,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:37,368][root][INFO] - Training Epoch: 1/2, step 2663/7134 completed (loss: 0.10637259483337402, acc: 0.9754385948181152)
[2024-12-17 01:52:37,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:37,720][root][INFO] - Training Epoch: 1/2, step 2664/7134 completed (loss: 0.08049016445875168, acc: 0.9806451797485352)
[2024-12-17 01:52:37,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:38,055][root][INFO] - Training Epoch: 1/2, step 2665/7134 completed (loss: 0.05971530079841614, acc: 0.9817708134651184)
[2024-12-17 01:52:38,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:38,420][root][INFO] - Training Epoch: 1/2, step 2666/7134 completed (loss: 0.07298116385936737, acc: 0.9804161787033081)
[2024-12-17 01:52:38,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:38,764][root][INFO] - Training Epoch: 1/2, step 2667/7134 completed (loss: 0.04121600091457367, acc: 0.9900850057601929)
[2024-12-17 01:52:38,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:39,096][root][INFO] - Training Epoch: 1/2, step 2668/7134 completed (loss: 0.050736863166093826, acc: 0.9865410327911377)
[2024-12-17 01:52:39,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:39,457][root][INFO] - Training Epoch: 1/2, step 2669/7134 completed (loss: 0.03856208920478821, acc: 0.9907940030097961)
[2024-12-17 01:52:39,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:39,792][root][INFO] - Training Epoch: 1/2, step 2670/7134 completed (loss: 0.07431339472532272, acc: 0.9803407788276672)
[2024-12-17 01:52:39,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:40,123][root][INFO] - Training Epoch: 1/2, step 2671/7134 completed (loss: 0.07559382915496826, acc: 0.9745989441871643)
[2024-12-17 01:52:40,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:40,474][root][INFO] - Training Epoch: 1/2, step 2672/7134 completed (loss: 0.05310064181685448, acc: 0.9868804812431335)
[2024-12-17 01:52:40,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:40,837][root][INFO] - Training Epoch: 1/2, step 2673/7134 completed (loss: 0.05093979090452194, acc: 0.9886363744735718)
[2024-12-17 01:52:40,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:41,155][root][INFO] - Training Epoch: 1/2, step 2674/7134 completed (loss: 0.04682084918022156, acc: 0.9888424277305603)
[2024-12-17 01:52:41,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:41,511][root][INFO] - Training Epoch: 1/2, step 2675/7134 completed (loss: 0.041050881147384644, acc: 0.9904109835624695)
[2024-12-17 01:52:41,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:41,847][root][INFO] - Training Epoch: 1/2, step 2676/7134 completed (loss: 0.053912535309791565, acc: 0.9896103739738464)
[2024-12-17 01:52:41,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:42,194][root][INFO] - Training Epoch: 1/2, step 2677/7134 completed (loss: 0.059156376868486404, acc: 0.9836309552192688)
[2024-12-17 01:52:42,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:42,551][root][INFO] - Training Epoch: 1/2, step 2678/7134 completed (loss: 0.022694198414683342, acc: 0.9947229623794556)
[2024-12-17 01:52:42,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:42,914][root][INFO] - Training Epoch: 1/2, step 2679/7134 completed (loss: 0.03230489790439606, acc: 0.9876543283462524)
[2024-12-17 01:52:42,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:43,263][root][INFO] - Training Epoch: 1/2, step 2680/7134 completed (loss: 0.060246989130973816, acc: 0.9839704036712646)
[2024-12-17 01:52:43,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:43,580][root][INFO] - Training Epoch: 1/2, step 2681/7134 completed (loss: 0.030664782971143723, acc: 0.9863429665565491)
[2024-12-17 01:52:43,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:43,880][root][INFO] - Training Epoch: 1/2, step 2682/7134 completed (loss: 0.029413841664791107, acc: 0.9920254945755005)
[2024-12-17 01:52:43,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:44,186][root][INFO] - Training Epoch: 1/2, step 2683/7134 completed (loss: 0.04037375748157501, acc: 0.987860381603241)
[2024-12-17 01:52:44,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:44,516][root][INFO] - Training Epoch: 1/2, step 2684/7134 completed (loss: 0.08988558501005173, acc: 0.9820788502693176)
[2024-12-17 01:52:44,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:44,879][root][INFO] - Training Epoch: 1/2, step 2685/7134 completed (loss: 0.04503869637846947, acc: 0.9869961142539978)
[2024-12-17 01:52:45,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:45,250][root][INFO] - Training Epoch: 1/2, step 2686/7134 completed (loss: 0.14679133892059326, acc: 0.9652777910232544)
[2024-12-17 01:52:45,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:45,589][root][INFO] - Training Epoch: 1/2, step 2687/7134 completed (loss: 0.1531512588262558, acc: 0.9646643400192261)
[2024-12-17 01:52:45,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:45,937][root][INFO] - Training Epoch: 1/2, step 2688/7134 completed (loss: 0.1667076051235199, acc: 0.9528301954269409)
[2024-12-17 01:52:46,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:46,231][root][INFO] - Training Epoch: 1/2, step 2689/7134 completed (loss: 0.12085267156362534, acc: 0.9692586064338684)
[2024-12-17 01:52:46,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:46,575][root][INFO] - Training Epoch: 1/2, step 2690/7134 completed (loss: 0.23285935819149017, acc: 0.942812979221344)
[2024-12-17 01:52:46,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:46,868][root][INFO] - Training Epoch: 1/2, step 2691/7134 completed (loss: 0.21570883691310883, acc: 0.951171875)
[2024-12-17 01:52:46,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:47,207][root][INFO] - Training Epoch: 1/2, step 2692/7134 completed (loss: 0.192463219165802, acc: 0.9459962844848633)
[2024-12-17 01:52:47,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:47,477][root][INFO] - Training Epoch: 1/2, step 2693/7134 completed (loss: 0.2737179100513458, acc: 0.932692289352417)
[2024-12-17 01:52:47,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:47,806][root][INFO] - Training Epoch: 1/2, step 2694/7134 completed (loss: 0.24898803234100342, acc: 0.9441176652908325)
[2024-12-17 01:52:47,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:48,180][root][INFO] - Training Epoch: 1/2, step 2695/7134 completed (loss: 0.18683652579784393, acc: 0.9497487545013428)
[2024-12-17 01:52:48,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:48,534][root][INFO] - Training Epoch: 1/2, step 2696/7134 completed (loss: 0.22987107932567596, acc: 0.9491255879402161)
[2024-12-17 01:52:48,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:48,859][root][INFO] - Training Epoch: 1/2, step 2697/7134 completed (loss: 0.2834247946739197, acc: 0.9306625723838806)
[2024-12-17 01:52:48,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:49,215][root][INFO] - Training Epoch: 1/2, step 2698/7134 completed (loss: 0.24735702574253082, acc: 0.9299145340919495)
[2024-12-17 01:52:49,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:49,564][root][INFO] - Training Epoch: 1/2, step 2699/7134 completed (loss: 0.1848486363887787, acc: 0.9448123574256897)
[2024-12-17 01:52:49,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:49,864][root][INFO] - Training Epoch: 1/2, step 2700/7134 completed (loss: 0.17460136115550995, acc: 0.9554896354675293)
[2024-12-17 01:52:50,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:50,218][root][INFO] - Training Epoch: 1/2, step 2701/7134 completed (loss: 0.17060044407844543, acc: 0.9495798349380493)
[2024-12-17 01:52:50,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:50,468][root][INFO] - Training Epoch: 1/2, step 2702/7134 completed (loss: 0.25378406047821045, acc: 0.9427083134651184)
[2024-12-17 01:52:50,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:50,774][root][INFO] - Training Epoch: 1/2, step 2703/7134 completed (loss: 0.1346074789762497, acc: 0.9617834687232971)
[2024-12-17 01:52:50,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:51,132][root][INFO] - Training Epoch: 1/2, step 2704/7134 completed (loss: 0.14572517573833466, acc: 0.9649595618247986)
[2024-12-17 01:52:51,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:51,485][root][INFO] - Training Epoch: 1/2, step 2705/7134 completed (loss: 0.17298907041549683, acc: 0.9614197611808777)
[2024-12-17 01:52:51,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:51,874][root][INFO] - Training Epoch: 1/2, step 2706/7134 completed (loss: 0.14656297862529755, acc: 0.9637155532836914)
[2024-12-17 01:52:51,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:52,237][root][INFO] - Training Epoch: 1/2, step 2707/7134 completed (loss: 0.13327883183956146, acc: 0.9672414064407349)
[2024-12-17 01:52:52,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:52,600][root][INFO] - Training Epoch: 1/2, step 2708/7134 completed (loss: 0.16718263924121857, acc: 0.948106586933136)
[2024-12-17 01:52:52,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:52,964][root][INFO] - Training Epoch: 1/2, step 2709/7134 completed (loss: 0.1296360343694687, acc: 0.9626623392105103)
[2024-12-17 01:52:53,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:53,301][root][INFO] - Training Epoch: 1/2, step 2710/7134 completed (loss: 0.11953630298376083, acc: 0.9580419659614563)
[2024-12-17 01:52:53,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:53,624][root][INFO] - Training Epoch: 1/2, step 2711/7134 completed (loss: 0.12805072963237762, acc: 0.9646226167678833)
[2024-12-17 01:52:53,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:53,971][root][INFO] - Training Epoch: 1/2, step 2712/7134 completed (loss: 0.1735793650150299, acc: 0.9575892686843872)
[2024-12-17 01:52:54,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:54,326][root][INFO] - Training Epoch: 1/2, step 2713/7134 completed (loss: 0.15928693115711212, acc: 0.9777158498764038)
[2024-12-17 01:52:54,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:54,678][root][INFO] - Training Epoch: 1/2, step 2714/7134 completed (loss: 0.12705455720424652, acc: 0.9667221307754517)
[2024-12-17 01:52:54,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:55,023][root][INFO] - Training Epoch: 1/2, step 2715/7134 completed (loss: 0.10974618047475815, acc: 0.969924807548523)
[2024-12-17 01:52:55,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:55,367][root][INFO] - Training Epoch: 1/2, step 2716/7134 completed (loss: 0.14171360433101654, acc: 0.963302731513977)
[2024-12-17 01:52:55,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:55,706][root][INFO] - Training Epoch: 1/2, step 2717/7134 completed (loss: 0.1875714361667633, acc: 0.9466118812561035)
[2024-12-17 01:52:55,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:56,051][root][INFO] - Training Epoch: 1/2, step 2718/7134 completed (loss: 0.3386683464050293, acc: 0.9137324094772339)
[2024-12-17 01:52:56,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:56,401][root][INFO] - Training Epoch: 1/2, step 2719/7134 completed (loss: 0.15483319759368896, acc: 0.9576988220214844)
[2024-12-17 01:52:56,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:56,743][root][INFO] - Training Epoch: 1/2, step 2720/7134 completed (loss: 0.1720041036605835, acc: 0.9542586803436279)
[2024-12-17 01:52:56,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:57,052][root][INFO] - Training Epoch: 1/2, step 2721/7134 completed (loss: 0.12855198979377747, acc: 0.9739130139350891)
[2024-12-17 01:52:57,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:57,307][root][INFO] - Training Epoch: 1/2, step 2722/7134 completed (loss: 0.22971054911613464, acc: 0.949999988079071)
[2024-12-17 01:52:57,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:57,651][root][INFO] - Training Epoch: 1/2, step 2723/7134 completed (loss: 0.2759033143520355, acc: 0.9335793256759644)
[2024-12-17 01:52:57,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:58,005][root][INFO] - Training Epoch: 1/2, step 2724/7134 completed (loss: 0.1976998746395111, acc: 0.9416767954826355)
[2024-12-17 01:52:58,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:58,346][root][INFO] - Training Epoch: 1/2, step 2725/7134 completed (loss: 0.13985054194927216, acc: 0.9556650519371033)
[2024-12-17 01:52:58,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:58,667][root][INFO] - Training Epoch: 1/2, step 2726/7134 completed (loss: 0.1713949739933014, acc: 0.9538745284080505)
[2024-12-17 01:52:58,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:59,040][root][INFO] - Training Epoch: 1/2, step 2727/7134 completed (loss: 0.19079653918743134, acc: 0.9444444179534912)
[2024-12-17 01:52:59,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:59,375][root][INFO] - Training Epoch: 1/2, step 2728/7134 completed (loss: 0.23868420720100403, acc: 0.9472476840019226)
[2024-12-17 01:52:59,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:59,758][root][INFO] - Training Epoch: 1/2, step 2729/7134 completed (loss: 0.2237384021282196, acc: 0.9477351903915405)
[2024-12-17 01:52:59,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:00,090][root][INFO] - Training Epoch: 1/2, step 2730/7134 completed (loss: 0.1647300273180008, acc: 0.956250011920929)
[2024-12-17 01:53:00,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:00,399][root][INFO] - Training Epoch: 1/2, step 2731/7134 completed (loss: 0.23806215822696686, acc: 0.9367396831512451)
[2024-12-17 01:53:00,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:00,756][root][INFO] - Training Epoch: 1/2, step 2732/7134 completed (loss: 0.14592593908309937, acc: 0.9619289636611938)
[2024-12-17 01:53:00,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:01,110][root][INFO] - Training Epoch: 1/2, step 2733/7134 completed (loss: 0.16595155000686646, acc: 0.9511533379554749)
[2024-12-17 01:53:01,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:01,437][root][INFO] - Training Epoch: 1/2, step 2734/7134 completed (loss: 0.16928981244564056, acc: 0.9577465057373047)
[2024-12-17 01:53:01,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:01,840][root][INFO] - Training Epoch: 1/2, step 2735/7134 completed (loss: 0.13272976875305176, acc: 0.9661246538162231)
[2024-12-17 01:53:01,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:02,157][root][INFO] - Training Epoch: 1/2, step 2736/7134 completed (loss: 0.2424371987581253, acc: 0.9291045069694519)
[2024-12-17 01:53:02,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:02,483][root][INFO] - Training Epoch: 1/2, step 2737/7134 completed (loss: 0.15245115756988525, acc: 0.9603960514068604)
[2024-12-17 01:53:02,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:02,819][root][INFO] - Training Epoch: 1/2, step 2738/7134 completed (loss: 0.14493708312511444, acc: 0.9628571271896362)
[2024-12-17 01:53:02,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:03,150][root][INFO] - Training Epoch: 1/2, step 2739/7134 completed (loss: 0.20799407362937927, acc: 0.9509090781211853)
[2024-12-17 01:53:03,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:03,478][root][INFO] - Training Epoch: 1/2, step 2740/7134 completed (loss: 0.1248404011130333, acc: 0.972423791885376)
[2024-12-17 01:53:03,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:03,783][root][INFO] - Training Epoch: 1/2, step 2741/7134 completed (loss: 0.1828831136226654, acc: 0.9415887594223022)
[2024-12-17 01:53:03,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:04,135][root][INFO] - Training Epoch: 1/2, step 2742/7134 completed (loss: 0.1696292906999588, acc: 0.949999988079071)
[2024-12-17 01:53:04,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:04,440][root][INFO] - Training Epoch: 1/2, step 2743/7134 completed (loss: 0.07246740907430649, acc: 0.9789473414421082)
[2024-12-17 01:53:04,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:04,687][root][INFO] - Training Epoch: 1/2, step 2744/7134 completed (loss: 0.10420215874910355, acc: 0.9578543901443481)
[2024-12-17 01:53:04,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:04,966][root][INFO] - Training Epoch: 1/2, step 2745/7134 completed (loss: 0.16628015041351318, acc: 0.9547038078308105)
[2024-12-17 01:53:05,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:05,280][root][INFO] - Training Epoch: 1/2, step 2746/7134 completed (loss: 0.091610386967659, acc: 0.9839743375778198)
[2024-12-17 01:53:05,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:05,595][root][INFO] - Training Epoch: 1/2, step 2747/7134 completed (loss: 0.10223835706710815, acc: 0.9729729890823364)
[2024-12-17 01:53:05,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:05,809][root][INFO] - Training Epoch: 1/2, step 2748/7134 completed (loss: 0.118553027510643, acc: 0.9745222926139832)
[2024-12-17 01:53:05,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:06,079][root][INFO] - Training Epoch: 1/2, step 2749/7134 completed (loss: 0.10399765521287918, acc: 0.9726775884628296)
[2024-12-17 01:53:06,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:06,403][root][INFO] - Training Epoch: 1/2, step 2750/7134 completed (loss: 0.1001625657081604, acc: 0.9714285731315613)
[2024-12-17 01:53:06,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:06,706][root][INFO] - Training Epoch: 1/2, step 2751/7134 completed (loss: 0.12447670847177505, acc: 0.9620253443717957)
[2024-12-17 01:53:06,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:07,029][root][INFO] - Training Epoch: 1/2, step 2752/7134 completed (loss: 0.12358490377664566, acc: 0.9714828729629517)
[2024-12-17 01:53:07,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:07,355][root][INFO] - Training Epoch: 1/2, step 2753/7134 completed (loss: 0.1781449317932129, acc: 0.9498746991157532)
[2024-12-17 01:53:07,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:07,705][root][INFO] - Training Epoch: 1/2, step 2754/7134 completed (loss: 0.17580530047416687, acc: 0.9492900371551514)
[2024-12-17 01:53:07,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:08,028][root][INFO] - Training Epoch: 1/2, step 2755/7134 completed (loss: 0.05717692896723747, acc: 0.9864341020584106)
[2024-12-17 01:53:08,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:08,333][root][INFO] - Training Epoch: 1/2, step 2756/7134 completed (loss: 0.1232721358537674, acc: 0.961904764175415)
[2024-12-17 01:53:08,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:08,582][root][INFO] - Training Epoch: 1/2, step 2757/7134 completed (loss: 0.1321590691804886, acc: 0.9726775884628296)
[2024-12-17 01:53:08,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:08,894][root][INFO] - Training Epoch: 1/2, step 2758/7134 completed (loss: 0.15905380249023438, acc: 0.9634703397750854)
[2024-12-17 01:53:09,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:09,186][root][INFO] - Training Epoch: 1/2, step 2759/7134 completed (loss: 0.1310087889432907, acc: 0.9698996543884277)
[2024-12-17 01:53:09,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:09,482][root][INFO] - Training Epoch: 1/2, step 2760/7134 completed (loss: 0.14864623546600342, acc: 0.9650793671607971)
[2024-12-17 01:53:09,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:09,830][root][INFO] - Training Epoch: 1/2, step 2761/7134 completed (loss: 0.19489313662052155, acc: 0.9545454382896423)
[2024-12-17 01:53:09,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:10,201][root][INFO] - Training Epoch: 1/2, step 2762/7134 completed (loss: 0.15414930880069733, acc: 0.958573043346405)
[2024-12-17 01:53:10,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:10,556][root][INFO] - Training Epoch: 1/2, step 2763/7134 completed (loss: 0.12573233246803284, acc: 0.9673366546630859)
[2024-12-17 01:53:10,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:10,906][root][INFO] - Training Epoch: 1/2, step 2764/7134 completed (loss: 0.13823789358139038, acc: 0.95652174949646)
[2024-12-17 01:53:11,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:11,258][root][INFO] - Training Epoch: 1/2, step 2765/7134 completed (loss: 0.14073917269706726, acc: 0.959770143032074)
[2024-12-17 01:53:11,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:11,623][root][INFO] - Training Epoch: 1/2, step 2766/7134 completed (loss: 0.10321485251188278, acc: 0.9725363254547119)
[2024-12-17 01:53:11,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:11,972][root][INFO] - Training Epoch: 1/2, step 2767/7134 completed (loss: 0.18646694719791412, acc: 0.9543209671974182)
[2024-12-17 01:53:12,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:12,309][root][INFO] - Training Epoch: 1/2, step 2768/7134 completed (loss: 0.12604141235351562, acc: 0.9575672149658203)
[2024-12-17 01:53:12,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:12,660][root][INFO] - Training Epoch: 1/2, step 2769/7134 completed (loss: 0.1393125057220459, acc: 0.9662162065505981)
[2024-12-17 01:53:12,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:13,024][root][INFO] - Training Epoch: 1/2, step 2770/7134 completed (loss: 0.11072257906198502, acc: 0.9749652147293091)
[2024-12-17 01:53:13,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:13,426][root][INFO] - Training Epoch: 1/2, step 2771/7134 completed (loss: 0.15672899782657623, acc: 0.9592711925506592)
[2024-12-17 01:53:13,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:13,807][root][INFO] - Training Epoch: 1/2, step 2772/7134 completed (loss: 0.10320138931274414, acc: 0.9742729067802429)
[2024-12-17 01:53:13,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:14,176][root][INFO] - Training Epoch: 1/2, step 2773/7134 completed (loss: 0.1346462070941925, acc: 0.9611428380012512)
[2024-12-17 01:53:14,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:14,542][root][INFO] - Training Epoch: 1/2, step 2774/7134 completed (loss: 0.12768618762493134, acc: 0.9649122953414917)
[2024-12-17 01:53:14,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:14,887][root][INFO] - Training Epoch: 1/2, step 2775/7134 completed (loss: 0.10265829414129257, acc: 0.9754601120948792)
[2024-12-17 01:53:15,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:15,281][root][INFO] - Training Epoch: 1/2, step 2776/7134 completed (loss: 0.09491890668869019, acc: 0.976482629776001)
[2024-12-17 01:53:15,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:15,627][root][INFO] - Training Epoch: 1/2, step 2777/7134 completed (loss: 0.11144186556339264, acc: 0.9695122241973877)
[2024-12-17 01:53:15,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:15,987][root][INFO] - Training Epoch: 1/2, step 2778/7134 completed (loss: 0.08879710733890533, acc: 0.9768250584602356)
[2024-12-17 01:53:16,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:16,351][root][INFO] - Training Epoch: 1/2, step 2779/7134 completed (loss: 0.16653227806091309, acc: 0.9641350507736206)
[2024-12-17 01:53:16,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:16,713][root][INFO] - Training Epoch: 1/2, step 2780/7134 completed (loss: 0.15361489355564117, acc: 0.9546413421630859)
[2024-12-17 01:53:16,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:17,082][root][INFO] - Training Epoch: 1/2, step 2781/7134 completed (loss: 0.09391971677541733, acc: 0.9766839146614075)
[2024-12-17 01:53:17,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:17,447][root][INFO] - Training Epoch: 1/2, step 2782/7134 completed (loss: 0.06836973130702972, acc: 0.980042040348053)
[2024-12-17 01:53:17,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:17,815][root][INFO] - Training Epoch: 1/2, step 2783/7134 completed (loss: 0.08288461714982986, acc: 0.9804804921150208)
[2024-12-17 01:53:17,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:18,186][root][INFO] - Training Epoch: 1/2, step 2784/7134 completed (loss: 0.08900333940982819, acc: 0.9768664836883545)
[2024-12-17 01:53:18,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:18,563][root][INFO] - Training Epoch: 1/2, step 2785/7134 completed (loss: 0.0642004907131195, acc: 0.9770742654800415)
[2024-12-17 01:53:18,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:18,927][root][INFO] - Training Epoch: 1/2, step 2786/7134 completed (loss: 0.11451299488544464, acc: 0.9719626307487488)
[2024-12-17 01:53:19,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:19,308][root][INFO] - Training Epoch: 1/2, step 2787/7134 completed (loss: 0.11727508157491684, acc: 0.9681274890899658)
[2024-12-17 01:53:19,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:19,657][root][INFO] - Training Epoch: 1/2, step 2788/7134 completed (loss: 0.07454974204301834, acc: 0.9751309156417847)
[2024-12-17 01:53:19,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:19,953][root][INFO] - Training Epoch: 1/2, step 2789/7134 completed (loss: 0.29189515113830566, acc: 0.9250720739364624)
[2024-12-17 01:53:20,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:20,258][root][INFO] - Training Epoch: 1/2, step 2790/7134 completed (loss: 0.22522881627082825, acc: 0.9492273926734924)
[2024-12-17 01:53:20,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:20,611][root][INFO] - Training Epoch: 1/2, step 2791/7134 completed (loss: 0.10540511459112167, acc: 0.9715994000434875)
[2024-12-17 01:53:20,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:20,981][root][INFO] - Training Epoch: 1/2, step 2792/7134 completed (loss: 0.08587498962879181, acc: 0.9767171144485474)
[2024-12-17 01:53:21,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:21,338][root][INFO] - Training Epoch: 1/2, step 2793/7134 completed (loss: 0.1013178825378418, acc: 0.9676113128662109)
[2024-12-17 01:53:21,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:21,607][root][INFO] - Training Epoch: 1/2, step 2794/7134 completed (loss: 0.16802500188350677, acc: 0.9446253776550293)
[2024-12-17 01:53:21,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:21,939][root][INFO] - Training Epoch: 1/2, step 2795/7134 completed (loss: 0.3984106183052063, acc: 0.8932714462280273)
[2024-12-17 01:53:22,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:22,225][root][INFO] - Training Epoch: 1/2, step 2796/7134 completed (loss: 0.3887272775173187, acc: 0.9032257795333862)
[2024-12-17 01:53:22,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:22,515][root][INFO] - Training Epoch: 1/2, step 2797/7134 completed (loss: 0.3428243398666382, acc: 0.8987341523170471)
[2024-12-17 01:53:22,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:22,840][root][INFO] - Training Epoch: 1/2, step 2798/7134 completed (loss: 0.2784891426563263, acc: 0.9327731132507324)
[2024-12-17 01:53:22,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:23,155][root][INFO] - Training Epoch: 1/2, step 2799/7134 completed (loss: 0.2291857898235321, acc: 0.9352014064788818)
[2024-12-17 01:53:23,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:23,448][root][INFO] - Training Epoch: 1/2, step 2800/7134 completed (loss: 0.2144753783941269, acc: 0.9543058276176453)
[2024-12-17 01:53:23,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:23,805][root][INFO] - Training Epoch: 1/2, step 2801/7134 completed (loss: 0.1304227113723755, acc: 0.9616368412971497)
[2024-12-17 01:53:23,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:24,169][root][INFO] - Training Epoch: 1/2, step 2802/7134 completed (loss: 0.14034266769886017, acc: 0.9725343585014343)
[2024-12-17 01:53:24,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:24,515][root][INFO] - Training Epoch: 1/2, step 2803/7134 completed (loss: 0.0760597512125969, acc: 0.9787836074829102)
[2024-12-17 01:53:24,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:24,890][root][INFO] - Training Epoch: 1/2, step 2804/7134 completed (loss: 0.14050862193107605, acc: 0.9665841460227966)
[2024-12-17 01:53:24,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:25,226][root][INFO] - Training Epoch: 1/2, step 2805/7134 completed (loss: 0.08481374382972717, acc: 0.9802371263504028)
[2024-12-17 01:53:25,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:25,556][root][INFO] - Training Epoch: 1/2, step 2806/7134 completed (loss: 0.1524474024772644, acc: 0.9557377099990845)
[2024-12-17 01:53:25,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:25,873][root][INFO] - Training Epoch: 1/2, step 2807/7134 completed (loss: 0.28527137637138367, acc: 0.9126819372177124)
[2024-12-17 01:53:25,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:26,221][root][INFO] - Training Epoch: 1/2, step 2808/7134 completed (loss: 0.09964381903409958, acc: 0.9760000109672546)
[2024-12-17 01:53:26,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:26,561][root][INFO] - Training Epoch: 1/2, step 2809/7134 completed (loss: 0.12453524768352509, acc: 0.9714794754981995)
[2024-12-17 01:53:26,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:26,952][root][INFO] - Training Epoch: 1/2, step 2810/7134 completed (loss: 0.08432338386774063, acc: 0.9762470126152039)
[2024-12-17 01:53:27,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:27,307][root][INFO] - Training Epoch: 1/2, step 2811/7134 completed (loss: 0.06577488780021667, acc: 0.9856801629066467)
[2024-12-17 01:53:27,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:27,658][root][INFO] - Training Epoch: 1/2, step 2812/7134 completed (loss: 0.09187866747379303, acc: 0.970678985118866)
[2024-12-17 01:53:27,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:28,026][root][INFO] - Training Epoch: 1/2, step 2813/7134 completed (loss: 0.060282617807388306, acc: 0.986146092414856)
[2024-12-17 01:53:28,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:28,354][root][INFO] - Training Epoch: 1/2, step 2814/7134 completed (loss: 0.13111713528633118, acc: 0.9688311815261841)
[2024-12-17 01:53:28,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:28,701][root][INFO] - Training Epoch: 1/2, step 2815/7134 completed (loss: 0.12284278869628906, acc: 0.9715302586555481)
[2024-12-17 01:53:28,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:29,081][root][INFO] - Training Epoch: 1/2, step 2816/7134 completed (loss: 0.11244664341211319, acc: 0.9723320007324219)
[2024-12-17 01:53:29,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:29,469][root][INFO] - Training Epoch: 1/2, step 2817/7134 completed (loss: 0.105373315513134, acc: 0.9758909940719604)
[2024-12-17 01:53:29,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:29,830][root][INFO] - Training Epoch: 1/2, step 2818/7134 completed (loss: 0.07713904976844788, acc: 0.9802631735801697)
[2024-12-17 01:53:29,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:30,147][root][INFO] - Training Epoch: 1/2, step 2819/7134 completed (loss: 0.08376577496528625, acc: 0.9806138873100281)
[2024-12-17 01:53:30,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:30,483][root][INFO] - Training Epoch: 1/2, step 2820/7134 completed (loss: 0.21758165955543518, acc: 0.9513990879058838)
[2024-12-17 01:53:30,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:30,829][root][INFO] - Training Epoch: 1/2, step 2821/7134 completed (loss: 0.25579702854156494, acc: 0.937873363494873)
[2024-12-17 01:53:30,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:31,179][root][INFO] - Training Epoch: 1/2, step 2822/7134 completed (loss: 0.24751190841197968, acc: 0.9380530714988708)
[2024-12-17 01:53:31,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:31,580][root][INFO] - Training Epoch: 1/2, step 2823/7134 completed (loss: 0.33504027128219604, acc: 0.9234042763710022)
[2024-12-17 01:53:31,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:31,921][root][INFO] - Training Epoch: 1/2, step 2824/7134 completed (loss: 0.3171082139015198, acc: 0.9107142686843872)
[2024-12-17 01:53:32,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:32,268][root][INFO] - Training Epoch: 1/2, step 2825/7134 completed (loss: 0.18943451344966888, acc: 0.9570469856262207)
[2024-12-17 01:53:32,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:32,618][root][INFO] - Training Epoch: 1/2, step 2826/7134 completed (loss: 0.19740796089172363, acc: 0.9487951993942261)
[2024-12-17 01:53:32,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:32,971][root][INFO] - Training Epoch: 1/2, step 2827/7134 completed (loss: 0.20741352438926697, acc: 0.9399744868278503)
[2024-12-17 01:53:33,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:33,322][root][INFO] - Training Epoch: 1/2, step 2828/7134 completed (loss: 0.1377146989107132, acc: 0.9584000110626221)
[2024-12-17 01:53:33,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:33,683][root][INFO] - Training Epoch: 1/2, step 2829/7134 completed (loss: 0.17489805817604065, acc: 0.9549795389175415)
[2024-12-17 01:53:33,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:34,032][root][INFO] - Training Epoch: 1/2, step 2830/7134 completed (loss: 0.07761047035455704, acc: 0.9781420826911926)
[2024-12-17 01:53:34,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:34,362][root][INFO] - Training Epoch: 1/2, step 2831/7134 completed (loss: 0.12310907989740372, acc: 0.9636650681495667)
[2024-12-17 01:53:34,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:34,715][root][INFO] - Training Epoch: 1/2, step 2832/7134 completed (loss: 0.11480654031038284, acc: 0.9752747416496277)
[2024-12-17 01:53:34,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:35,070][root][INFO] - Training Epoch: 1/2, step 2833/7134 completed (loss: 0.11971926689147949, acc: 0.9684210419654846)
[2024-12-17 01:53:35,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:35,424][root][INFO] - Training Epoch: 1/2, step 2834/7134 completed (loss: 0.15221843123435974, acc: 0.9644669890403748)
[2024-12-17 01:53:35,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:35,772][root][INFO] - Training Epoch: 1/2, step 2835/7134 completed (loss: 0.16651159524917603, acc: 0.9612277746200562)
[2024-12-17 01:53:35,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:36,087][root][INFO] - Training Epoch: 1/2, step 2836/7134 completed (loss: 0.1619538813829422, acc: 0.9549763202667236)
[2024-12-17 01:53:36,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:36,446][root][INFO] - Training Epoch: 1/2, step 2837/7134 completed (loss: 0.17254632711410522, acc: 0.9554054141044617)
[2024-12-17 01:53:36,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:36,826][root][INFO] - Training Epoch: 1/2, step 2838/7134 completed (loss: 0.17174066603183746, acc: 0.9560669660568237)
[2024-12-17 01:53:36,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:37,164][root][INFO] - Training Epoch: 1/2, step 2839/7134 completed (loss: 0.11164361238479614, acc: 0.9711684584617615)
[2024-12-17 01:53:37,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:37,538][root][INFO] - Training Epoch: 1/2, step 2840/7134 completed (loss: 0.055462438613176346, acc: 0.9820442199707031)
[2024-12-17 01:53:37,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:37,905][root][INFO] - Training Epoch: 1/2, step 2841/7134 completed (loss: 0.20355311036109924, acc: 0.942396342754364)
[2024-12-17 01:53:38,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:38,269][root][INFO] - Training Epoch: 1/2, step 2842/7134 completed (loss: 0.18603992462158203, acc: 0.9467532634735107)
[2024-12-17 01:53:38,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:38,598][root][INFO] - Training Epoch: 1/2, step 2843/7134 completed (loss: 0.13764168322086334, acc: 0.9632353186607361)
[2024-12-17 01:53:38,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:38,958][root][INFO] - Training Epoch: 1/2, step 2844/7134 completed (loss: 0.27372458577156067, acc: 0.9357045292854309)
[2024-12-17 01:53:39,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:39,282][root][INFO] - Training Epoch: 1/2, step 2845/7134 completed (loss: 0.08399947732686996, acc: 0.9757365584373474)
[2024-12-17 01:53:39,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:39,618][root][INFO] - Training Epoch: 1/2, step 2846/7134 completed (loss: 0.20869125425815582, acc: 0.9423393607139587)
[2024-12-17 01:53:39,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:39,977][root][INFO] - Training Epoch: 1/2, step 2847/7134 completed (loss: 0.21683382987976074, acc: 0.9354838728904724)
[2024-12-17 01:53:40,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:40,231][root][INFO] - Training Epoch: 1/2, step 2848/7134 completed (loss: 0.20446719229221344, acc: 0.9440559148788452)
[2024-12-17 01:53:40,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:40,574][root][INFO] - Training Epoch: 1/2, step 2849/7134 completed (loss: 0.12208572775125504, acc: 0.9709543585777283)
[2024-12-17 01:53:40,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:40,904][root][INFO] - Training Epoch: 1/2, step 2850/7134 completed (loss: 0.08333291858434677, acc: 0.9698925018310547)
[2024-12-17 01:53:41,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:41,235][root][INFO] - Training Epoch: 1/2, step 2851/7134 completed (loss: 0.10222069919109344, acc: 0.979742169380188)
[2024-12-17 01:53:41,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:41,553][root][INFO] - Training Epoch: 1/2, step 2852/7134 completed (loss: 0.07236975431442261, acc: 0.9860835075378418)
[2024-12-17 01:53:41,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:41,843][root][INFO] - Training Epoch: 1/2, step 2853/7134 completed (loss: 0.08665795624256134, acc: 0.9796954393386841)
[2024-12-17 01:53:41,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:42,180][root][INFO] - Training Epoch: 1/2, step 2854/7134 completed (loss: 0.08689884841442108, acc: 0.9762258529663086)
[2024-12-17 01:53:42,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:42,504][root][INFO] - Training Epoch: 1/2, step 2855/7134 completed (loss: 0.07963819801807404, acc: 0.9806138873100281)
[2024-12-17 01:53:42,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:42,914][root][INFO] - Training Epoch: 1/2, step 2856/7134 completed (loss: 0.05558323860168457, acc: 0.9844852089881897)
[2024-12-17 01:53:43,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:43,256][root][INFO] - Training Epoch: 1/2, step 2857/7134 completed (loss: 0.08108755201101303, acc: 0.9855491518974304)
[2024-12-17 01:53:43,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:43,567][root][INFO] - Training Epoch: 1/2, step 2858/7134 completed (loss: 0.03591490536928177, acc: 0.9905362725257874)
[2024-12-17 01:53:43,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:43,905][root][INFO] - Training Epoch: 1/2, step 2859/7134 completed (loss: 0.11742394417524338, acc: 0.965132474899292)
[2024-12-17 01:53:43,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:44,226][root][INFO] - Training Epoch: 1/2, step 2860/7134 completed (loss: 0.09976764768362045, acc: 0.9706422090530396)
[2024-12-17 01:53:44,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:44,547][root][INFO] - Training Epoch: 1/2, step 2861/7134 completed (loss: 0.05505133047699928, acc: 0.9858012199401855)
[2024-12-17 01:53:44,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:44,866][root][INFO] - Training Epoch: 1/2, step 2862/7134 completed (loss: 0.058908041566610336, acc: 0.9794167876243591)
[2024-12-17 01:53:44,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:45,225][root][INFO] - Training Epoch: 1/2, step 2863/7134 completed (loss: 0.031109480187296867, acc: 0.9923567175865173)
[2024-12-17 01:53:45,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:45,485][root][INFO] - Training Epoch: 1/2, step 2864/7134 completed (loss: 0.0930195078253746, acc: 0.984415590763092)
[2024-12-17 01:53:45,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:45,820][root][INFO] - Training Epoch: 1/2, step 2865/7134 completed (loss: 0.08905578404664993, acc: 0.9760869741439819)
[2024-12-17 01:53:45,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:46,157][root][INFO] - Training Epoch: 1/2, step 2866/7134 completed (loss: 0.14617450535297394, acc: 0.9715994000434875)
[2024-12-17 01:53:46,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:46,461][root][INFO] - Training Epoch: 1/2, step 2867/7134 completed (loss: 0.06277681887149811, acc: 0.9815950989723206)
[2024-12-17 01:53:46,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:46,775][root][INFO] - Training Epoch: 1/2, step 2868/7134 completed (loss: 0.07481031119823456, acc: 0.9775280952453613)
[2024-12-17 01:53:46,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:47,093][root][INFO] - Training Epoch: 1/2, step 2869/7134 completed (loss: 0.10324472934007645, acc: 0.9824304580688477)
[2024-12-17 01:53:47,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:47,426][root][INFO] - Training Epoch: 1/2, step 2870/7134 completed (loss: 0.1470317244529724, acc: 0.9748427867889404)
[2024-12-17 01:53:47,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:47,750][root][INFO] - Training Epoch: 1/2, step 2871/7134 completed (loss: 0.08586979657411575, acc: 0.9828392863273621)
[2024-12-17 01:53:47,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:48,080][root][INFO] - Training Epoch: 1/2, step 2872/7134 completed (loss: 0.04523814842104912, acc: 0.98828125)
[2024-12-17 01:53:48,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:48,402][root][INFO] - Training Epoch: 1/2, step 2873/7134 completed (loss: 0.06657197326421738, acc: 0.9835766553878784)
[2024-12-17 01:53:48,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:48,739][root][INFO] - Training Epoch: 1/2, step 2874/7134 completed (loss: 0.07141228765249252, acc: 0.9797191619873047)
[2024-12-17 01:53:48,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:49,082][root][INFO] - Training Epoch: 1/2, step 2875/7134 completed (loss: 0.06967191398143768, acc: 0.9829303026199341)
[2024-12-17 01:53:49,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:49,403][root][INFO] - Training Epoch: 1/2, step 2876/7134 completed (loss: 0.18342307209968567, acc: 0.9631336331367493)
[2024-12-17 01:53:49,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:49,729][root][INFO] - Training Epoch: 1/2, step 2877/7134 completed (loss: 0.06077931448817253, acc: 0.9803493618965149)
[2024-12-17 01:53:49,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:50,047][root][INFO] - Training Epoch: 1/2, step 2878/7134 completed (loss: 0.06351019442081451, acc: 0.9830508232116699)
[2024-12-17 01:53:50,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:50,358][root][INFO] - Training Epoch: 1/2, step 2879/7134 completed (loss: 0.035392992198467255, acc: 0.9921630024909973)
[2024-12-17 01:53:50,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:50,692][root][INFO] - Training Epoch: 1/2, step 2880/7134 completed (loss: 0.052312444895505905, acc: 0.981249988079071)
[2024-12-17 01:53:50,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:51,008][root][INFO] - Training Epoch: 1/2, step 2881/7134 completed (loss: 0.07993447780609131, acc: 0.9856887459754944)
[2024-12-17 01:53:51,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:51,357][root][INFO] - Training Epoch: 1/2, step 2882/7134 completed (loss: 0.11120648682117462, acc: 0.9679408073425293)
[2024-12-17 01:53:51,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:51,690][root][INFO] - Training Epoch: 1/2, step 2883/7134 completed (loss: 0.09695311635732651, acc: 0.9708994626998901)
[2024-12-17 01:53:51,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:52,012][root][INFO] - Training Epoch: 1/2, step 2884/7134 completed (loss: 0.15189212560653687, acc: 0.9683257937431335)
[2024-12-17 01:53:52,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:52,334][root][INFO] - Training Epoch: 1/2, step 2885/7134 completed (loss: 0.12554757297039032, acc: 0.9681335091590881)
[2024-12-17 01:53:52,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:52,666][root][INFO] - Training Epoch: 1/2, step 2886/7134 completed (loss: 0.16672483086585999, acc: 0.9656716585159302)
[2024-12-17 01:53:52,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:53,044][root][INFO] - Training Epoch: 1/2, step 2887/7134 completed (loss: 0.18871602416038513, acc: 0.9562129974365234)
[2024-12-17 01:53:53,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:53,401][root][INFO] - Training Epoch: 1/2, step 2888/7134 completed (loss: 0.14330603182315826, acc: 0.96809983253479)
[2024-12-17 01:53:53,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:53,738][root][INFO] - Training Epoch: 1/2, step 2889/7134 completed (loss: 0.11170876771211624, acc: 0.9764543175697327)
[2024-12-17 01:53:53,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:54,091][root][INFO] - Training Epoch: 1/2, step 2890/7134 completed (loss: 0.11285363137722015, acc: 0.964047908782959)
[2024-12-17 01:53:54,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:54,441][root][INFO] - Training Epoch: 1/2, step 2891/7134 completed (loss: 0.17421302199363708, acc: 0.9569230675697327)
[2024-12-17 01:53:54,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:54,795][root][INFO] - Training Epoch: 1/2, step 2892/7134 completed (loss: 0.15412618219852448, acc: 0.9596977233886719)
[2024-12-17 01:53:54,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:55,146][root][INFO] - Training Epoch: 1/2, step 2893/7134 completed (loss: 0.17202545702457428, acc: 0.9470365643501282)
[2024-12-17 01:53:55,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:55,474][root][INFO] - Training Epoch: 1/2, step 2894/7134 completed (loss: 0.10058294981718063, acc: 0.9680672287940979)
[2024-12-17 01:53:55,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:55,774][root][INFO] - Training Epoch: 1/2, step 2895/7134 completed (loss: 0.0889759212732315, acc: 0.9810963869094849)
[2024-12-17 01:53:55,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:56,121][root][INFO] - Training Epoch: 1/2, step 2896/7134 completed (loss: 0.07767300307750702, acc: 0.974554717540741)
[2024-12-17 01:53:56,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:56,439][root][INFO] - Training Epoch: 1/2, step 2897/7134 completed (loss: 0.18138620257377625, acc: 0.950266420841217)
[2024-12-17 01:53:56,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:56,768][root][INFO] - Training Epoch: 1/2, step 2898/7134 completed (loss: 0.12527312338352203, acc: 0.9725490212440491)
[2024-12-17 01:53:56,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:57,094][root][INFO] - Training Epoch: 1/2, step 2899/7134 completed (loss: 0.14007197320461273, acc: 0.9680232405662537)
[2024-12-17 01:53:57,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:57,444][root][INFO] - Training Epoch: 1/2, step 2900/7134 completed (loss: 0.09154258668422699, acc: 0.9765431880950928)
[2024-12-17 01:53:57,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:57,772][root][INFO] - Training Epoch: 1/2, step 2901/7134 completed (loss: 0.10778648406267166, acc: 0.9681528806686401)
[2024-12-17 01:53:57,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:58,063][root][INFO] - Training Epoch: 1/2, step 2902/7134 completed (loss: 0.10082311928272247, acc: 0.9755638837814331)
[2024-12-17 01:53:58,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:58,409][root][INFO] - Training Epoch: 1/2, step 2903/7134 completed (loss: 0.1215561181306839, acc: 0.9743589758872986)
[2024-12-17 01:53:58,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:58,761][root][INFO] - Training Epoch: 1/2, step 2904/7134 completed (loss: 0.06734490394592285, acc: 0.9787765145301819)
[2024-12-17 01:53:58,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:59,114][root][INFO] - Training Epoch: 1/2, step 2905/7134 completed (loss: 0.0976799800992012, acc: 0.9712139964103699)
[2024-12-17 01:53:59,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:59,472][root][INFO] - Training Epoch: 1/2, step 2906/7134 completed (loss: 0.06523366272449493, acc: 0.9880239367485046)
[2024-12-17 01:53:59,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:59,812][root][INFO] - Training Epoch: 1/2, step 2907/7134 completed (loss: 0.13966310024261475, acc: 0.9596231579780579)
[2024-12-17 01:53:59,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:00,159][root][INFO] - Training Epoch: 1/2, step 2908/7134 completed (loss: 0.07773981988430023, acc: 0.9780077338218689)
[2024-12-17 01:54:00,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:00,517][root][INFO] - Training Epoch: 1/2, step 2909/7134 completed (loss: 0.11685321480035782, acc: 0.9760192036628723)
[2024-12-17 01:54:00,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:00,874][root][INFO] - Training Epoch: 1/2, step 2910/7134 completed (loss: 0.1467566192150116, acc: 0.9582440853118896)
[2024-12-17 01:54:00,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:01,247][root][INFO] - Training Epoch: 1/2, step 2911/7134 completed (loss: 0.0889313593506813, acc: 0.9758388996124268)
[2024-12-17 01:54:01,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:01,622][root][INFO] - Training Epoch: 1/2, step 2912/7134 completed (loss: 0.09634458273649216, acc: 0.9696551561355591)
[2024-12-17 01:54:01,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:01,981][root][INFO] - Training Epoch: 1/2, step 2913/7134 completed (loss: 0.11716561019420624, acc: 0.9686609506607056)
[2024-12-17 01:54:02,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:02,353][root][INFO] - Training Epoch: 1/2, step 2914/7134 completed (loss: 0.08776421844959259, acc: 0.9746682643890381)
[2024-12-17 01:54:02,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:02,689][root][INFO] - Training Epoch: 1/2, step 2915/7134 completed (loss: 0.14433617889881134, acc: 0.9625360369682312)
[2024-12-17 01:54:02,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:03,013][root][INFO] - Training Epoch: 1/2, step 2916/7134 completed (loss: 0.13689285516738892, acc: 0.962199330329895)
[2024-12-17 01:54:03,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:03,361][root][INFO] - Training Epoch: 1/2, step 2917/7134 completed (loss: 0.09027032554149628, acc: 0.9664991497993469)
[2024-12-17 01:54:03,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:03,704][root][INFO] - Training Epoch: 1/2, step 2918/7134 completed (loss: 0.08377081155776978, acc: 0.9731934666633606)
[2024-12-17 01:54:03,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:04,037][root][INFO] - Training Epoch: 1/2, step 2919/7134 completed (loss: 0.1150277704000473, acc: 0.9647473692893982)
[2024-12-17 01:54:04,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:04,420][root][INFO] - Training Epoch: 1/2, step 2920/7134 completed (loss: 0.08573749661445618, acc: 0.9761589169502258)
[2024-12-17 01:54:04,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:04,764][root][INFO] - Training Epoch: 1/2, step 2921/7134 completed (loss: 0.07339675724506378, acc: 0.9798850417137146)
[2024-12-17 01:54:04,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:05,090][root][INFO] - Training Epoch: 1/2, step 2922/7134 completed (loss: 0.1253291517496109, acc: 0.9685929417610168)
[2024-12-17 01:54:05,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:05,437][root][INFO] - Training Epoch: 1/2, step 2923/7134 completed (loss: 0.23534494638442993, acc: 0.9554531574249268)
[2024-12-17 01:54:05,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:05,762][root][INFO] - Training Epoch: 1/2, step 2924/7134 completed (loss: 0.08032494783401489, acc: 0.9823113083839417)
[2024-12-17 01:54:05,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:06,154][root][INFO] - Training Epoch: 1/2, step 2925/7134 completed (loss: 0.09699616581201553, acc: 0.9803439974784851)
[2024-12-17 01:54:06,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:06,526][root][INFO] - Training Epoch: 1/2, step 2926/7134 completed (loss: 0.1920042783021927, acc: 0.9663461446762085)
[2024-12-17 01:54:06,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:06,882][root][INFO] - Training Epoch: 1/2, step 2927/7134 completed (loss: 0.05978734791278839, acc: 0.987908124923706)
[2024-12-17 01:54:06,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:07,229][root][INFO] - Training Epoch: 1/2, step 2928/7134 completed (loss: 0.09819314628839493, acc: 0.9710366129875183)
[2024-12-17 01:54:07,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:07,621][root][INFO] - Training Epoch: 1/2, step 2929/7134 completed (loss: 0.0686098113656044, acc: 0.9843342304229736)
[2024-12-17 01:54:07,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:07,983][root][INFO] - Training Epoch: 1/2, step 2930/7134 completed (loss: 0.08885035663843155, acc: 0.9794420003890991)
[2024-12-17 01:54:08,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:08,313][root][INFO] - Training Epoch: 1/2, step 2931/7134 completed (loss: 0.12861211597919464, acc: 0.9656203389167786)
[2024-12-17 01:54:08,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:08,652][root][INFO] - Training Epoch: 1/2, step 2932/7134 completed (loss: 0.07279588282108307, acc: 0.9826187491416931)
[2024-12-17 01:54:08,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:09,006][root][INFO] - Training Epoch: 1/2, step 2933/7134 completed (loss: 0.08666384220123291, acc: 0.9711399674415588)
[2024-12-17 01:54:09,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:09,370][root][INFO] - Training Epoch: 1/2, step 2934/7134 completed (loss: 0.05151049792766571, acc: 0.9901269674301147)
[2024-12-17 01:54:09,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:09,718][root][INFO] - Training Epoch: 1/2, step 2935/7134 completed (loss: 0.07825405895709991, acc: 0.9768722653388977)
[2024-12-17 01:54:09,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:10,088][root][INFO] - Training Epoch: 1/2, step 2936/7134 completed (loss: 0.10755671560764313, acc: 0.9745676517486572)
[2024-12-17 01:54:10,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:10,413][root][INFO] - Training Epoch: 1/2, step 2937/7134 completed (loss: 0.12322103977203369, acc: 0.9670014381408691)
[2024-12-17 01:54:10,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:10,751][root][INFO] - Training Epoch: 1/2, step 2938/7134 completed (loss: 0.08789370954036713, acc: 0.9787709712982178)
[2024-12-17 01:54:10,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:11,033][root][INFO] - Training Epoch: 1/2, step 2939/7134 completed (loss: 0.045722488313913345, acc: 0.9903846383094788)
[2024-12-17 01:54:11,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:11,366][root][INFO] - Training Epoch: 1/2, step 2940/7134 completed (loss: 0.12424974143505096, acc: 0.9658002853393555)
[2024-12-17 01:54:11,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:11,679][root][INFO] - Training Epoch: 1/2, step 2941/7134 completed (loss: 0.08045637607574463, acc: 0.9840348362922668)
[2024-12-17 01:54:11,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:11,979][root][INFO] - Training Epoch: 1/2, step 2942/7134 completed (loss: 0.08388257771730423, acc: 0.9866270422935486)
[2024-12-17 01:54:12,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:12,301][root][INFO] - Training Epoch: 1/2, step 2943/7134 completed (loss: 0.050728846341371536, acc: 0.9865092635154724)
[2024-12-17 01:54:12,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:12,632][root][INFO] - Training Epoch: 1/2, step 2944/7134 completed (loss: 0.07524163275957108, acc: 0.9838472604751587)
[2024-12-17 01:54:12,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:12,968][root][INFO] - Training Epoch: 1/2, step 2945/7134 completed (loss: 0.05840045213699341, acc: 0.9813374876976013)
[2024-12-17 01:54:13,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:13,269][root][INFO] - Training Epoch: 1/2, step 2946/7134 completed (loss: 0.06979016214609146, acc: 0.9811046719551086)
[2024-12-17 01:54:13,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:13,594][root][INFO] - Training Epoch: 1/2, step 2947/7134 completed (loss: 0.09062131494283676, acc: 0.9685534834861755)
[2024-12-17 01:54:13,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:13,926][root][INFO] - Training Epoch: 1/2, step 2948/7134 completed (loss: 0.10333052277565002, acc: 0.967051088809967)
[2024-12-17 01:54:14,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:14,263][root][INFO] - Training Epoch: 1/2, step 2949/7134 completed (loss: 0.04358280450105667, acc: 0.9847095012664795)
[2024-12-17 01:54:14,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:14,592][root][INFO] - Training Epoch: 1/2, step 2950/7134 completed (loss: 0.04841282218694687, acc: 0.9862068891525269)
[2024-12-17 01:54:14,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:14,920][root][INFO] - Training Epoch: 1/2, step 2951/7134 completed (loss: 0.034488484263420105, acc: 0.991304337978363)
[2024-12-17 01:54:15,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:15,251][root][INFO] - Training Epoch: 1/2, step 2952/7134 completed (loss: 0.026992153376340866, acc: 0.9955489635467529)
[2024-12-17 01:54:15,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:15,569][root][INFO] - Training Epoch: 1/2, step 2953/7134 completed (loss: 0.06635076552629471, acc: 0.9831081032752991)
[2024-12-17 01:54:15,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:15,912][root][INFO] - Training Epoch: 1/2, step 2954/7134 completed (loss: 0.06002522259950638, acc: 0.9832689762115479)
[2024-12-17 01:54:16,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:16,218][root][INFO] - Training Epoch: 1/2, step 2955/7134 completed (loss: 0.08670786023139954, acc: 0.984375)
[2024-12-17 01:54:16,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:16,561][root][INFO] - Training Epoch: 1/2, step 2956/7134 completed (loss: 0.052547477185726166, acc: 0.9838945865631104)
[2024-12-17 01:54:16,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:16,904][root][INFO] - Training Epoch: 1/2, step 2957/7134 completed (loss: 0.03794213756918907, acc: 0.9919785857200623)
[2024-12-17 01:54:17,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:17,228][root][INFO] - Training Epoch: 1/2, step 2958/7134 completed (loss: 0.05761054903268814, acc: 0.9914529919624329)
[2024-12-17 01:54:17,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:17,551][root][INFO] - Training Epoch: 1/2, step 2959/7134 completed (loss: 0.05050182342529297, acc: 0.9839181303977966)
[2024-12-17 01:54:17,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:17,888][root][INFO] - Training Epoch: 1/2, step 2960/7134 completed (loss: 0.06893057376146317, acc: 0.9820936918258667)
[2024-12-17 01:54:18,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:18,241][root][INFO] - Training Epoch: 1/2, step 2961/7134 completed (loss: 0.06622697412967682, acc: 0.9809523820877075)
[2024-12-17 01:54:18,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:18,566][root][INFO] - Training Epoch: 1/2, step 2962/7134 completed (loss: 0.06042703613638878, acc: 0.9805951118469238)
[2024-12-17 01:54:18,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:18,928][root][INFO] - Training Epoch: 1/2, step 2963/7134 completed (loss: 0.050287876278162, acc: 0.985602080821991)
[2024-12-17 01:54:19,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:19,259][root][INFO] - Training Epoch: 1/2, step 2964/7134 completed (loss: 0.057064350694417953, acc: 0.9838945865631104)
[2024-12-17 01:54:19,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:19,587][root][INFO] - Training Epoch: 1/2, step 2965/7134 completed (loss: 0.13167859613895416, acc: 0.9686567187309265)
[2024-12-17 01:54:19,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:19,924][root][INFO] - Training Epoch: 1/2, step 2966/7134 completed (loss: 0.03292354568839073, acc: 0.9936034083366394)
[2024-12-17 01:54:20,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:20,260][root][INFO] - Training Epoch: 1/2, step 2967/7134 completed (loss: 0.06936805695295334, acc: 0.9846368432044983)
[2024-12-17 01:54:20,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:20,627][root][INFO] - Training Epoch: 1/2, step 2968/7134 completed (loss: 0.18086595833301544, acc: 0.9533762335777283)
[2024-12-17 01:54:20,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:20,954][root][INFO] - Training Epoch: 1/2, step 2969/7134 completed (loss: 0.3601154386997223, acc: 0.9097633361816406)
[2024-12-17 01:54:21,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:21,289][root][INFO] - Training Epoch: 1/2, step 2970/7134 completed (loss: 0.4210568070411682, acc: 0.9172113537788391)
[2024-12-17 01:54:21,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:21,635][root][INFO] - Training Epoch: 1/2, step 2971/7134 completed (loss: 0.11625586450099945, acc: 0.9710906744003296)
[2024-12-17 01:54:21,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:21,966][root][INFO] - Training Epoch: 1/2, step 2972/7134 completed (loss: 0.08655499666929245, acc: 0.9762611389160156)
[2024-12-17 01:54:22,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:22,314][root][INFO] - Training Epoch: 1/2, step 2973/7134 completed (loss: 0.12506572902202606, acc: 0.9696202278137207)
[2024-12-17 01:54:22,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:22,663][root][INFO] - Training Epoch: 1/2, step 2974/7134 completed (loss: 0.08904361724853516, acc: 0.9740596413612366)
[2024-12-17 01:54:22,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:23,009][root][INFO] - Training Epoch: 1/2, step 2975/7134 completed (loss: 0.10666117817163467, acc: 0.9723756909370422)
[2024-12-17 01:54:23,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:23,381][root][INFO] - Training Epoch: 1/2, step 2976/7134 completed (loss: 0.09399084001779556, acc: 0.9819148778915405)
[2024-12-17 01:54:23,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:23,721][root][INFO] - Training Epoch: 1/2, step 2977/7134 completed (loss: 0.10248547792434692, acc: 0.9725433588027954)
[2024-12-17 01:54:23,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:24,067][root][INFO] - Training Epoch: 1/2, step 2978/7134 completed (loss: 0.08966881781816483, acc: 0.980141818523407)
[2024-12-17 01:54:24,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:24,385][root][INFO] - Training Epoch: 1/2, step 2979/7134 completed (loss: 0.03319307416677475, acc: 0.9890965819358826)
[2024-12-17 01:54:24,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:24,741][root][INFO] - Training Epoch: 1/2, step 2980/7134 completed (loss: 0.1090536117553711, acc: 0.9707006216049194)
[2024-12-17 01:54:24,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:25,089][root][INFO] - Training Epoch: 1/2, step 2981/7134 completed (loss: 0.1418146938085556, acc: 0.9687923789024353)
[2024-12-17 01:54:25,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:25,420][root][INFO] - Training Epoch: 1/2, step 2982/7134 completed (loss: 0.10178949683904648, acc: 0.9738219976425171)
[2024-12-17 01:54:25,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:25,763][root][INFO] - Training Epoch: 1/2, step 2983/7134 completed (loss: 0.14294378459453583, acc: 0.9682539701461792)
[2024-12-17 01:54:25,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:26,138][root][INFO] - Training Epoch: 1/2, step 2984/7134 completed (loss: 0.07008793950080872, acc: 0.9849056601524353)
[2024-12-17 01:54:26,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:26,498][root][INFO] - Training Epoch: 1/2, step 2985/7134 completed (loss: 0.09846976399421692, acc: 0.9737783074378967)
[2024-12-17 01:54:26,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:26,870][root][INFO] - Training Epoch: 1/2, step 2986/7134 completed (loss: 0.055195774883031845, acc: 0.986997663974762)
[2024-12-17 01:54:26,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:27,216][root][INFO] - Training Epoch: 1/2, step 2987/7134 completed (loss: 0.10144273936748505, acc: 0.9776207208633423)
[2024-12-17 01:54:27,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:27,572][root][INFO] - Training Epoch: 1/2, step 2988/7134 completed (loss: 0.1012076884508133, acc: 0.974452555179596)
[2024-12-17 01:54:27,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:27,931][root][INFO] - Training Epoch: 1/2, step 2989/7134 completed (loss: 0.11438781023025513, acc: 0.9725490212440491)
[2024-12-17 01:54:28,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:28,241][root][INFO] - Training Epoch: 1/2, step 2990/7134 completed (loss: 0.2208000272512436, acc: 0.9562937021255493)
[2024-12-17 01:54:28,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:28,564][root][INFO] - Training Epoch: 1/2, step 2991/7134 completed (loss: 0.31306543946266174, acc: 0.933425784111023)
[2024-12-17 01:54:28,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:28,879][root][INFO] - Training Epoch: 1/2, step 2992/7134 completed (loss: 0.11019878834486008, acc: 0.9788838624954224)
[2024-12-17 01:54:29,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:29,245][root][INFO] - Training Epoch: 1/2, step 2993/7134 completed (loss: 0.08010038733482361, acc: 0.9816625714302063)
[2024-12-17 01:54:29,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:29,578][root][INFO] - Training Epoch: 1/2, step 2994/7134 completed (loss: 0.08597905933856964, acc: 0.9748201370239258)
[2024-12-17 01:54:29,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:29,958][root][INFO] - Training Epoch: 1/2, step 2995/7134 completed (loss: 0.058985766023397446, acc: 0.9864406585693359)
[2024-12-17 01:54:30,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:30,295][root][INFO] - Training Epoch: 1/2, step 2996/7134 completed (loss: 0.12009711563587189, acc: 0.9742690324783325)
[2024-12-17 01:54:30,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:30,660][root][INFO] - Training Epoch: 1/2, step 2997/7134 completed (loss: 0.07060126960277557, acc: 0.982328474521637)
[2024-12-17 01:54:30,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:30,971][root][INFO] - Training Epoch: 1/2, step 2998/7134 completed (loss: 0.07675890624523163, acc: 0.9830303192138672)
[2024-12-17 01:54:31,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:31,357][root][INFO] - Training Epoch: 1/2, step 2999/7134 completed (loss: 0.07000582665205002, acc: 0.9826338887214661)
[2024-12-17 01:54:31,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:31,726][root][INFO] - Training Epoch: 1/2, step 3000/7134 completed (loss: 0.07937004417181015, acc: 0.9732334017753601)
[2024-12-17 01:54:31,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:32,089][root][INFO] - Training Epoch: 1/2, step 3001/7134 completed (loss: 0.09197556972503662, acc: 0.971563994884491)
[2024-12-17 01:54:32,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:32,439][root][INFO] - Training Epoch: 1/2, step 3002/7134 completed (loss: 0.11118967086076736, acc: 0.9727891087532043)
[2024-12-17 01:54:32,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:32,804][root][INFO] - Training Epoch: 1/2, step 3003/7134 completed (loss: 0.06763855367898941, acc: 0.9837586879730225)
[2024-12-17 01:54:32,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:33,159][root][INFO] - Training Epoch: 1/2, step 3004/7134 completed (loss: 0.045013364404439926, acc: 0.9888268113136292)
[2024-12-17 01:54:33,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:33,531][root][INFO] - Training Epoch: 1/2, step 3005/7134 completed (loss: 0.03987054526805878, acc: 0.9897377490997314)
[2024-12-17 01:54:33,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:33,896][root][INFO] - Training Epoch: 1/2, step 3006/7134 completed (loss: 0.06998834013938904, acc: 0.9821200370788574)
[2024-12-17 01:54:33,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:34,239][root][INFO] - Training Epoch: 1/2, step 3007/7134 completed (loss: 0.09495658427476883, acc: 0.9777517318725586)
[2024-12-17 01:54:34,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:34,565][root][INFO] - Training Epoch: 1/2, step 3008/7134 completed (loss: 0.11633963137865067, acc: 0.9734265804290771)
[2024-12-17 01:54:34,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:34,890][root][INFO] - Training Epoch: 1/2, step 3009/7134 completed (loss: 0.16943307220935822, acc: 0.9645569324493408)
[2024-12-17 01:54:35,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:35,246][root][INFO] - Training Epoch: 1/2, step 3010/7134 completed (loss: 0.09971757233142853, acc: 0.9823204278945923)
[2024-12-17 01:54:35,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:35,594][root][INFO] - Training Epoch: 1/2, step 3011/7134 completed (loss: 0.1516696959733963, acc: 0.9614835977554321)
[2024-12-17 01:54:35,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:35,936][root][INFO] - Training Epoch: 1/2, step 3012/7134 completed (loss: 0.12979592382907867, acc: 0.9556260108947754)
[2024-12-17 01:54:36,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:36,307][root][INFO] - Training Epoch: 1/2, step 3013/7134 completed (loss: 0.07571189850568771, acc: 0.9781106114387512)
[2024-12-17 01:54:36,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:36,652][root][INFO] - Training Epoch: 1/2, step 3014/7134 completed (loss: 0.07937491685152054, acc: 0.9824150204658508)
[2024-12-17 01:54:36,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:36,964][root][INFO] - Training Epoch: 1/2, step 3015/7134 completed (loss: 0.06799977272748947, acc: 0.9807162284851074)
[2024-12-17 01:54:37,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:37,317][root][INFO] - Training Epoch: 1/2, step 3016/7134 completed (loss: 0.06754861772060394, acc: 0.9845288395881653)
[2024-12-17 01:54:37,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:37,651][root][INFO] - Training Epoch: 1/2, step 3017/7134 completed (loss: 0.22949647903442383, acc: 0.9372881650924683)
[2024-12-17 01:54:37,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:37,962][root][INFO] - Training Epoch: 1/2, step 3018/7134 completed (loss: 0.07054813206195831, acc: 0.9818181991577148)
[2024-12-17 01:54:38,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:38,303][root][INFO] - Training Epoch: 1/2, step 3019/7134 completed (loss: 0.09261127561330795, acc: 0.9803921580314636)
[2024-12-17 01:54:38,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:38,632][root][INFO] - Training Epoch: 1/2, step 3020/7134 completed (loss: 0.10997156798839569, acc: 0.976827085018158)
[2024-12-17 01:54:38,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:38,970][root][INFO] - Training Epoch: 1/2, step 3021/7134 completed (loss: 0.05293181911110878, acc: 0.9890909194946289)
[2024-12-17 01:54:39,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:39,310][root][INFO] - Training Epoch: 1/2, step 3022/7134 completed (loss: 0.07817976921796799, acc: 0.9823151230812073)
[2024-12-17 01:54:39,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:39,603][root][INFO] - Training Epoch: 1/2, step 3023/7134 completed (loss: 0.10628073662519455, acc: 0.974155068397522)
[2024-12-17 01:54:39,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:39,946][root][INFO] - Training Epoch: 1/2, step 3024/7134 completed (loss: 0.046124380081892014, acc: 0.9865900278091431)
[2024-12-17 01:54:40,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:40,298][root][INFO] - Training Epoch: 1/2, step 3025/7134 completed (loss: 0.11692725867033005, acc: 0.9758620858192444)
[2024-12-17 01:54:40,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:40,628][root][INFO] - Training Epoch: 1/2, step 3026/7134 completed (loss: 0.0966954156756401, acc: 0.9784560203552246)
[2024-12-17 01:54:40,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:40,965][root][INFO] - Training Epoch: 1/2, step 3027/7134 completed (loss: 0.07741089910268784, acc: 0.9858585596084595)
[2024-12-17 01:54:41,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:41,252][root][INFO] - Training Epoch: 1/2, step 3028/7134 completed (loss: 0.04506979510188103, acc: 0.9931972622871399)
[2024-12-17 01:54:41,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:41,568][root][INFO] - Training Epoch: 1/2, step 3029/7134 completed (loss: 0.09032505750656128, acc: 0.9814528822898865)
[2024-12-17 01:54:41,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:41,932][root][INFO] - Training Epoch: 1/2, step 3030/7134 completed (loss: 0.08221167325973511, acc: 0.981679379940033)
[2024-12-17 01:54:42,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:42,244][root][INFO] - Training Epoch: 1/2, step 3031/7134 completed (loss: 0.053423088043928146, acc: 0.9851694703102112)
[2024-12-17 01:54:42,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:42,575][root][INFO] - Training Epoch: 1/2, step 3032/7134 completed (loss: 0.08912333101034164, acc: 0.9854809641838074)
[2024-12-17 01:54:42,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:42,895][root][INFO] - Training Epoch: 1/2, step 3033/7134 completed (loss: 0.0693417638540268, acc: 0.9805996417999268)
[2024-12-17 01:54:43,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:43,223][root][INFO] - Training Epoch: 1/2, step 3034/7134 completed (loss: 0.08447448909282684, acc: 0.9851064085960388)
[2024-12-17 01:54:43,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:43,535][root][INFO] - Training Epoch: 1/2, step 3035/7134 completed (loss: 0.06214579939842224, acc: 0.9811023473739624)
[2024-12-17 01:54:43,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:43,862][root][INFO] - Training Epoch: 1/2, step 3036/7134 completed (loss: 0.11035367101430893, acc: 0.974916398525238)
[2024-12-17 01:54:43,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:44,218][root][INFO] - Training Epoch: 1/2, step 3037/7134 completed (loss: 0.11646740883588791, acc: 0.9722650051116943)
[2024-12-17 01:54:44,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:44,555][root][INFO] - Training Epoch: 1/2, step 3038/7134 completed (loss: 0.0325164720416069, acc: 0.9930434823036194)
[2024-12-17 01:54:44,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:44,888][root][INFO] - Training Epoch: 1/2, step 3039/7134 completed (loss: 0.09525644034147263, acc: 0.9800918698310852)
[2024-12-17 01:54:45,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:45,217][root][INFO] - Training Epoch: 1/2, step 3040/7134 completed (loss: 0.09108346700668335, acc: 0.9740259647369385)
[2024-12-17 01:54:45,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:45,549][root][INFO] - Training Epoch: 1/2, step 3041/7134 completed (loss: 0.1605243980884552, acc: 0.9649122953414917)
[2024-12-17 01:54:45,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:45,875][root][INFO] - Training Epoch: 1/2, step 3042/7134 completed (loss: 0.05611608549952507, acc: 0.9793205261230469)
[2024-12-17 01:54:46,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:46,189][root][INFO] - Training Epoch: 1/2, step 3043/7134 completed (loss: 0.10067672282457352, acc: 0.9771863222122192)
[2024-12-17 01:54:46,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:46,507][root][INFO] - Training Epoch: 1/2, step 3044/7134 completed (loss: 0.03880593180656433, acc: 0.9913644194602966)
[2024-12-17 01:54:46,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:46,842][root][INFO] - Training Epoch: 1/2, step 3045/7134 completed (loss: 0.040385883301496506, acc: 0.9864406585693359)
[2024-12-17 01:54:46,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:47,202][root][INFO] - Training Epoch: 1/2, step 3046/7134 completed (loss: 0.074592225253582, acc: 0.9808743000030518)
[2024-12-17 01:54:47,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:47,544][root][INFO] - Training Epoch: 1/2, step 3047/7134 completed (loss: 0.06634500622749329, acc: 0.9798741936683655)
[2024-12-17 01:54:47,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:47,943][root][INFO] - Training Epoch: 1/2, step 3048/7134 completed (loss: 0.044589851051568985, acc: 0.984886646270752)
[2024-12-17 01:54:48,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:48,271][root][INFO] - Training Epoch: 1/2, step 3049/7134 completed (loss: 0.05060329660773277, acc: 0.9869186282157898)
[2024-12-17 01:54:48,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:48,629][root][INFO] - Training Epoch: 1/2, step 3050/7134 completed (loss: 0.08958002179861069, acc: 0.9726840853691101)
[2024-12-17 01:54:48,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:48,958][root][INFO] - Training Epoch: 1/2, step 3051/7134 completed (loss: 0.10959918051958084, acc: 0.9729323387145996)
[2024-12-17 01:54:49,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:49,306][root][INFO] - Training Epoch: 1/2, step 3052/7134 completed (loss: 0.059365686029195786, acc: 0.9858247637748718)
[2024-12-17 01:54:49,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:49,653][root][INFO] - Training Epoch: 1/2, step 3053/7134 completed (loss: 0.06184353679418564, acc: 0.9818840622901917)
[2024-12-17 01:54:49,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:49,992][root][INFO] - Training Epoch: 1/2, step 3054/7134 completed (loss: 0.10274569690227509, acc: 0.9805194735527039)
[2024-12-17 01:54:50,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:50,325][root][INFO] - Training Epoch: 1/2, step 3055/7134 completed (loss: 0.06822771579027176, acc: 0.988034188747406)
[2024-12-17 01:54:50,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:50,675][root][INFO] - Training Epoch: 1/2, step 3056/7134 completed (loss: 0.05789485573768616, acc: 0.9884318709373474)
[2024-12-17 01:54:50,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:51,043][root][INFO] - Training Epoch: 1/2, step 3057/7134 completed (loss: 0.040356989949941635, acc: 0.9861303567886353)
[2024-12-17 01:54:51,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:51,388][root][INFO] - Training Epoch: 1/2, step 3058/7134 completed (loss: 0.1353183537721634, acc: 0.962435245513916)
[2024-12-17 01:54:51,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:51,733][root][INFO] - Training Epoch: 1/2, step 3059/7134 completed (loss: 0.048738159239292145, acc: 0.9876712560653687)
[2024-12-17 01:54:51,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:52,088][root][INFO] - Training Epoch: 1/2, step 3060/7134 completed (loss: 0.05915889889001846, acc: 0.9844868779182434)
[2024-12-17 01:54:52,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:52,433][root][INFO] - Training Epoch: 1/2, step 3061/7134 completed (loss: 0.05826810747385025, acc: 0.9863636493682861)
[2024-12-17 01:54:52,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:52,788][root][INFO] - Training Epoch: 1/2, step 3062/7134 completed (loss: 0.049392297863960266, acc: 0.9878706336021423)
[2024-12-17 01:54:52,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:53,131][root][INFO] - Training Epoch: 1/2, step 3063/7134 completed (loss: 0.08628860116004944, acc: 0.976893424987793)
[2024-12-17 01:54:53,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:53,467][root][INFO] - Training Epoch: 1/2, step 3064/7134 completed (loss: 0.049274928867816925, acc: 0.9887323975563049)
[2024-12-17 01:54:53,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:53,822][root][INFO] - Training Epoch: 1/2, step 3065/7134 completed (loss: 0.05315137282013893, acc: 0.9879032373428345)
[2024-12-17 01:54:53,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:54,154][root][INFO] - Training Epoch: 1/2, step 3066/7134 completed (loss: 0.041623763740062714, acc: 0.9903225898742676)
[2024-12-17 01:54:54,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:54,481][root][INFO] - Training Epoch: 1/2, step 3067/7134 completed (loss: 0.04781453683972359, acc: 0.9818181991577148)
[2024-12-17 01:54:54,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:54,837][root][INFO] - Training Epoch: 1/2, step 3068/7134 completed (loss: 0.06062319502234459, acc: 0.9837618470191956)
[2024-12-17 01:54:54,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:55,189][root][INFO] - Training Epoch: 1/2, step 3069/7134 completed (loss: 0.06050544232130051, acc: 0.9873272180557251)
[2024-12-17 01:54:55,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:55,565][root][INFO] - Training Epoch: 1/2, step 3070/7134 completed (loss: 0.04113679379224777, acc: 0.9893955588340759)
[2024-12-17 01:54:55,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:55,919][root][INFO] - Training Epoch: 1/2, step 3071/7134 completed (loss: 0.07989612221717834, acc: 0.9768339991569519)
[2024-12-17 01:54:56,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:56,274][root][INFO] - Training Epoch: 1/2, step 3072/7134 completed (loss: 0.04498820751905441, acc: 0.9871645569801331)
[2024-12-17 01:54:56,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:56,603][root][INFO] - Training Epoch: 1/2, step 3073/7134 completed (loss: 0.054370757192373276, acc: 0.983460545539856)
[2024-12-17 01:54:56,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:56,933][root][INFO] - Training Epoch: 1/2, step 3074/7134 completed (loss: 0.0519566684961319, acc: 0.9883527159690857)
[2024-12-17 01:54:57,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:57,267][root][INFO] - Training Epoch: 1/2, step 3075/7134 completed (loss: 0.04553881287574768, acc: 0.987500011920929)
[2024-12-17 01:54:57,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:57,619][root][INFO] - Training Epoch: 1/2, step 3076/7134 completed (loss: 0.0739891454577446, acc: 0.9755826592445374)
[2024-12-17 01:54:57,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:58,001][root][INFO] - Training Epoch: 1/2, step 3077/7134 completed (loss: 0.14781704545021057, acc: 0.9683060050010681)
[2024-12-17 01:54:58,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:58,361][root][INFO] - Training Epoch: 1/2, step 3078/7134 completed (loss: 0.1320285052061081, acc: 0.9595628380775452)
[2024-12-17 01:54:58,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:58,712][root][INFO] - Training Epoch: 1/2, step 3079/7134 completed (loss: 0.07975151389837265, acc: 0.980246901512146)
[2024-12-17 01:54:58,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:59,079][root][INFO] - Training Epoch: 1/2, step 3080/7134 completed (loss: 0.12719687819480896, acc: 0.9596510529518127)
[2024-12-17 01:54:59,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:59,380][root][INFO] - Training Epoch: 1/2, step 3081/7134 completed (loss: 0.07111948728561401, acc: 0.9806034564971924)
[2024-12-17 01:54:59,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:59,728][root][INFO] - Training Epoch: 1/2, step 3082/7134 completed (loss: 0.14155730605125427, acc: 0.9578820466995239)
[2024-12-17 01:54:59,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:00,085][root][INFO] - Training Epoch: 1/2, step 3083/7134 completed (loss: 0.12751337885856628, acc: 0.9594240784645081)
[2024-12-17 01:55:00,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:00,433][root][INFO] - Training Epoch: 1/2, step 3084/7134 completed (loss: 0.10612708330154419, acc: 0.9702380895614624)
[2024-12-17 01:55:00,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:00,824][root][INFO] - Training Epoch: 1/2, step 3085/7134 completed (loss: 0.15260647237300873, acc: 0.9649634957313538)
[2024-12-17 01:55:00,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:01,203][root][INFO] - Training Epoch: 1/2, step 3086/7134 completed (loss: 0.13192050158977509, acc: 0.9652076363563538)
[2024-12-17 01:55:01,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:01,565][root][INFO] - Training Epoch: 1/2, step 3087/7134 completed (loss: 0.13111768662929535, acc: 0.9612625241279602)
[2024-12-17 01:55:01,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:01,931][root][INFO] - Training Epoch: 1/2, step 3088/7134 completed (loss: 0.08451282978057861, acc: 0.9774520993232727)
[2024-12-17 01:55:02,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:02,308][root][INFO] - Training Epoch: 1/2, step 3089/7134 completed (loss: 0.07553573697805405, acc: 0.9784250259399414)
[2024-12-17 01:55:02,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:02,673][root][INFO] - Training Epoch: 1/2, step 3090/7134 completed (loss: 0.16655604541301727, acc: 0.9510869383811951)
[2024-12-17 01:55:02,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:03,057][root][INFO] - Training Epoch: 1/2, step 3091/7134 completed (loss: 0.11094998568296432, acc: 0.9631336331367493)
[2024-12-17 01:55:03,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:03,373][root][INFO] - Training Epoch: 1/2, step 3092/7134 completed (loss: 0.13559703528881073, acc: 0.9593345522880554)
[2024-12-17 01:55:03,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:03,731][root][INFO] - Training Epoch: 1/2, step 3093/7134 completed (loss: 0.131389319896698, acc: 0.9735099077224731)
[2024-12-17 01:55:03,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:04,097][root][INFO] - Training Epoch: 1/2, step 3094/7134 completed (loss: 0.09017838537693024, acc: 0.975476861000061)
[2024-12-17 01:55:04,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:04,426][root][INFO] - Training Epoch: 1/2, step 3095/7134 completed (loss: 0.1505233496427536, acc: 0.9680555462837219)
[2024-12-17 01:55:04,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:04,774][root][INFO] - Training Epoch: 1/2, step 3096/7134 completed (loss: 0.17344366014003754, acc: 0.9614890813827515)
[2024-12-17 01:55:04,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:05,136][root][INFO] - Training Epoch: 1/2, step 3097/7134 completed (loss: 0.14713913202285767, acc: 0.9501424431800842)
[2024-12-17 01:55:05,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:05,489][root][INFO] - Training Epoch: 1/2, step 3098/7134 completed (loss: 0.11896470189094543, acc: 0.9654088020324707)
[2024-12-17 01:55:05,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:05,809][root][INFO] - Training Epoch: 1/2, step 3099/7134 completed (loss: 0.09840990602970123, acc: 0.9724473357200623)
[2024-12-17 01:55:05,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:06,186][root][INFO] - Training Epoch: 1/2, step 3100/7134 completed (loss: 0.0921890065073967, acc: 0.9776595830917358)
[2024-12-17 01:55:06,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:06,539][root][INFO] - Training Epoch: 1/2, step 3101/7134 completed (loss: 0.09752049297094345, acc: 0.9671533107757568)
[2024-12-17 01:55:06,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:06,904][root][INFO] - Training Epoch: 1/2, step 3102/7134 completed (loss: 0.08870621025562286, acc: 0.9762963056564331)
[2024-12-17 01:55:07,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:07,276][root][INFO] - Training Epoch: 1/2, step 3103/7134 completed (loss: 0.1526026427745819, acc: 0.9542065858840942)
[2024-12-17 01:55:07,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:07,555][root][INFO] - Training Epoch: 1/2, step 3104/7134 completed (loss: 0.09268604964017868, acc: 0.9770992398262024)
[2024-12-17 01:55:07,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:07,901][root][INFO] - Training Epoch: 1/2, step 3105/7134 completed (loss: 0.12172745168209076, acc: 0.9615384340286255)
[2024-12-17 01:55:08,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:08,269][root][INFO] - Training Epoch: 1/2, step 3106/7134 completed (loss: 0.07113316655158997, acc: 0.9816053509712219)
[2024-12-17 01:55:08,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:08,606][root][INFO] - Training Epoch: 1/2, step 3107/7134 completed (loss: 0.05993916466832161, acc: 0.9803921580314636)
[2024-12-17 01:55:08,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:08,959][root][INFO] - Training Epoch: 1/2, step 3108/7134 completed (loss: 0.1162715032696724, acc: 0.9661538600921631)
[2024-12-17 01:55:09,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:09,292][root][INFO] - Training Epoch: 1/2, step 3109/7134 completed (loss: 0.07762075960636139, acc: 0.9778597950935364)
[2024-12-17 01:55:09,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:09,626][root][INFO] - Training Epoch: 1/2, step 3110/7134 completed (loss: 0.09991031140089035, acc: 0.9731707572937012)
[2024-12-17 01:55:09,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:09,952][root][INFO] - Training Epoch: 1/2, step 3111/7134 completed (loss: 0.20174534618854523, acc: 0.9467353820800781)
[2024-12-17 01:55:10,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:10,272][root][INFO] - Training Epoch: 1/2, step 3112/7134 completed (loss: 0.09104851633310318, acc: 0.9754385948181152)
[2024-12-17 01:55:10,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:10,662][root][INFO] - Training Epoch: 1/2, step 3113/7134 completed (loss: 0.0647854283452034, acc: 0.9845505356788635)
[2024-12-17 01:55:10,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:10,997][root][INFO] - Training Epoch: 1/2, step 3114/7134 completed (loss: 0.10864036530256271, acc: 0.9689655303955078)
[2024-12-17 01:55:11,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:11,323][root][INFO] - Training Epoch: 1/2, step 3115/7134 completed (loss: 0.1026824563741684, acc: 0.9845678806304932)
[2024-12-17 01:55:11,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:11,682][root][INFO] - Training Epoch: 1/2, step 3116/7134 completed (loss: 0.07890485227108002, acc: 0.9769230484962463)
[2024-12-17 01:55:11,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:12,033][root][INFO] - Training Epoch: 1/2, step 3117/7134 completed (loss: 0.1474093198776245, acc: 0.9633151888847351)
[2024-12-17 01:55:12,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:12,374][root][INFO] - Training Epoch: 1/2, step 3118/7134 completed (loss: 0.10222163051366806, acc: 0.9762845635414124)
[2024-12-17 01:55:12,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:12,725][root][INFO] - Training Epoch: 1/2, step 3119/7134 completed (loss: 0.08776000142097473, acc: 0.9753566980361938)
[2024-12-17 01:55:12,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:13,048][root][INFO] - Training Epoch: 1/2, step 3120/7134 completed (loss: 0.09817197918891907, acc: 0.9844852089881897)
[2024-12-17 01:55:13,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:13,390][root][INFO] - Training Epoch: 1/2, step 3121/7134 completed (loss: 0.09994129091501236, acc: 0.9730077385902405)
[2024-12-17 01:55:13,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:13,755][root][INFO] - Training Epoch: 1/2, step 3122/7134 completed (loss: 0.08037777990102768, acc: 0.9813953638076782)
[2024-12-17 01:55:13,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:14,109][root][INFO] - Training Epoch: 1/2, step 3123/7134 completed (loss: 0.11393372714519501, acc: 0.9751243591308594)
[2024-12-17 01:55:14,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:14,446][root][INFO] - Training Epoch: 1/2, step 3124/7134 completed (loss: 0.08546178042888641, acc: 0.9764851331710815)
[2024-12-17 01:55:14,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:14,771][root][INFO] - Training Epoch: 1/2, step 3125/7134 completed (loss: 0.04210705682635307, acc: 0.9848713874816895)
[2024-12-17 01:55:14,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:15,148][root][INFO] - Training Epoch: 1/2, step 3126/7134 completed (loss: 0.0981006771326065, acc: 0.9733163714408875)
[2024-12-17 01:55:15,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:15,507][root][INFO] - Training Epoch: 1/2, step 3127/7134 completed (loss: 0.07784369587898254, acc: 0.9720930457115173)
[2024-12-17 01:55:15,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:15,848][root][INFO] - Training Epoch: 1/2, step 3128/7134 completed (loss: 0.06285467743873596, acc: 0.9806451797485352)
[2024-12-17 01:55:15,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:16,213][root][INFO] - Training Epoch: 1/2, step 3129/7134 completed (loss: 0.0603867806494236, acc: 0.983930766582489)
[2024-12-17 01:55:16,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:16,593][root][INFO] - Training Epoch: 1/2, step 3130/7134 completed (loss: 0.08283600956201553, acc: 0.9713302850723267)
[2024-12-17 01:55:16,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:16,935][root][INFO] - Training Epoch: 1/2, step 3131/7134 completed (loss: 0.12137212604284286, acc: 0.9666666388511658)
[2024-12-17 01:55:17,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:17,226][root][INFO] - Training Epoch: 1/2, step 3132/7134 completed (loss: 0.05327808856964111, acc: 0.9848155975341797)
[2024-12-17 01:55:17,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:17,590][root][INFO] - Training Epoch: 1/2, step 3133/7134 completed (loss: 0.16881458461284637, acc: 0.9656593203544617)
[2024-12-17 01:55:17,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:17,946][root][INFO] - Training Epoch: 1/2, step 3134/7134 completed (loss: 0.07334339618682861, acc: 0.976190447807312)
[2024-12-17 01:55:18,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:18,247][root][INFO] - Training Epoch: 1/2, step 3135/7134 completed (loss: 0.09708866477012634, acc: 0.9699769020080566)
[2024-12-17 01:55:18,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:18,584][root][INFO] - Training Epoch: 1/2, step 3136/7134 completed (loss: 0.07739239931106567, acc: 0.9721739292144775)
[2024-12-17 01:55:18,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:18,915][root][INFO] - Training Epoch: 1/2, step 3137/7134 completed (loss: 0.16456648707389832, acc: 0.9583333134651184)
[2024-12-17 01:55:19,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:19,226][root][INFO] - Training Epoch: 1/2, step 3138/7134 completed (loss: 0.16229641437530518, acc: 0.9764705896377563)
[2024-12-17 01:55:19,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:19,500][root][INFO] - Training Epoch: 1/2, step 3139/7134 completed (loss: 0.21506424248218536, acc: 0.942060112953186)
[2024-12-17 01:55:19,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:19,818][root][INFO] - Training Epoch: 1/2, step 3140/7134 completed (loss: 0.1321875900030136, acc: 0.9688715934753418)
[2024-12-17 01:55:19,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:20,146][root][INFO] - Training Epoch: 1/2, step 3141/7134 completed (loss: 0.12813378870487213, acc: 0.9667832255363464)
[2024-12-17 01:55:20,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:20,474][root][INFO] - Training Epoch: 1/2, step 3142/7134 completed (loss: 0.08752063661813736, acc: 0.9790732264518738)
[2024-12-17 01:55:20,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:20,805][root][INFO] - Training Epoch: 1/2, step 3143/7134 completed (loss: 0.0885409563779831, acc: 0.9694533944129944)
[2024-12-17 01:55:20,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:21,144][root][INFO] - Training Epoch: 1/2, step 3144/7134 completed (loss: 0.07768169790506363, acc: 0.9764150977134705)
[2024-12-17 01:55:21,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:21,475][root][INFO] - Training Epoch: 1/2, step 3145/7134 completed (loss: 0.10457097738981247, acc: 0.9737417697906494)
[2024-12-17 01:55:21,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:21,813][root][INFO] - Training Epoch: 1/2, step 3146/7134 completed (loss: 0.0919671431183815, acc: 0.9739583134651184)
[2024-12-17 01:55:21,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:22,139][root][INFO] - Training Epoch: 1/2, step 3147/7134 completed (loss: 0.10447761416435242, acc: 0.971107542514801)
[2024-12-17 01:55:22,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:22,493][root][INFO] - Training Epoch: 1/2, step 3148/7134 completed (loss: 0.09711123257875443, acc: 0.9783163070678711)
[2024-12-17 01:55:22,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:22,828][root][INFO] - Training Epoch: 1/2, step 3149/7134 completed (loss: 0.06534445285797119, acc: 0.9868228435516357)
[2024-12-17 01:55:22,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:23,164][root][INFO] - Training Epoch: 1/2, step 3150/7134 completed (loss: 0.2526308596134186, acc: 0.9349112510681152)
[2024-12-17 01:55:23,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:23,483][root][INFO] - Training Epoch: 1/2, step 3151/7134 completed (loss: 0.19543294608592987, acc: 0.954023003578186)
[2024-12-17 01:55:23,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:23,807][root][INFO] - Training Epoch: 1/2, step 3152/7134 completed (loss: 0.12911051511764526, acc: 0.9696969985961914)
[2024-12-17 01:55:23,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:24,150][root][INFO] - Training Epoch: 1/2, step 3153/7134 completed (loss: 0.120746910572052, acc: 0.9624060392379761)
[2024-12-17 01:55:24,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:24,479][root][INFO] - Training Epoch: 1/2, step 3154/7134 completed (loss: 0.1047215536236763, acc: 0.9715808033943176)
[2024-12-17 01:55:24,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:24,795][root][INFO] - Training Epoch: 1/2, step 3155/7134 completed (loss: 0.17413723468780518, acc: 0.959432065486908)
[2024-12-17 01:55:24,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:25,139][root][INFO] - Training Epoch: 1/2, step 3156/7134 completed (loss: 0.1808437705039978, acc: 0.9569093585014343)
[2024-12-17 01:55:25,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:25,459][root][INFO] - Training Epoch: 1/2, step 3157/7134 completed (loss: 0.06925810128450394, acc: 0.9849462509155273)
[2024-12-17 01:55:25,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:25,778][root][INFO] - Training Epoch: 1/2, step 3158/7134 completed (loss: 0.06862196326255798, acc: 0.9803921580314636)
[2024-12-17 01:55:25,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:26,102][root][INFO] - Training Epoch: 1/2, step 3159/7134 completed (loss: 0.15099528431892395, acc: 0.9632353186607361)
[2024-12-17 01:55:26,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:26,445][root][INFO] - Training Epoch: 1/2, step 3160/7134 completed (loss: 0.048388272523880005, acc: 0.9889349937438965)
[2024-12-17 01:55:26,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:26,795][root][INFO] - Training Epoch: 1/2, step 3161/7134 completed (loss: 0.09217384457588196, acc: 0.9803921580314636)
[2024-12-17 01:55:26,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:27,123][root][INFO] - Training Epoch: 1/2, step 3162/7134 completed (loss: 0.051908303052186966, acc: 0.9868804812431335)
[2024-12-17 01:55:27,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:27,443][root][INFO] - Training Epoch: 1/2, step 3163/7134 completed (loss: 0.08404218405485153, acc: 0.9866443872451782)
[2024-12-17 01:55:27,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:27,769][root][INFO] - Training Epoch: 1/2, step 3164/7134 completed (loss: 0.11782368272542953, acc: 0.9748743772506714)
[2024-12-17 01:55:27,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:28,097][root][INFO] - Training Epoch: 1/2, step 3165/7134 completed (loss: 0.04920853301882744, acc: 0.989983320236206)
[2024-12-17 01:55:28,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:28,428][root][INFO] - Training Epoch: 1/2, step 3166/7134 completed (loss: 0.1326398402452469, acc: 0.969924807548523)
[2024-12-17 01:55:28,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:28,774][root][INFO] - Training Epoch: 1/2, step 3167/7134 completed (loss: 0.15904605388641357, acc: 0.965624988079071)
[2024-12-17 01:55:28,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:29,099][root][INFO] - Training Epoch: 1/2, step 3168/7134 completed (loss: 0.1642969399690628, acc: 0.9664633870124817)
[2024-12-17 01:55:29,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:29,417][root][INFO] - Training Epoch: 1/2, step 3169/7134 completed (loss: 0.1131727546453476, acc: 0.9692623019218445)
[2024-12-17 01:55:29,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:29,745][root][INFO] - Training Epoch: 1/2, step 3170/7134 completed (loss: 0.0766855925321579, acc: 0.9818181991577148)
[2024-12-17 01:55:29,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:30,080][root][INFO] - Training Epoch: 1/2, step 3171/7134 completed (loss: 0.09543033689260483, acc: 0.9737876653671265)
[2024-12-17 01:55:30,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:30,401][root][INFO] - Training Epoch: 1/2, step 3172/7134 completed (loss: 0.06528884172439575, acc: 0.975095808506012)
[2024-12-17 01:55:30,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:30,719][root][INFO] - Training Epoch: 1/2, step 3173/7134 completed (loss: 0.08327838033437729, acc: 0.9744898080825806)
[2024-12-17 01:55:30,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:31,058][root][INFO] - Training Epoch: 1/2, step 3174/7134 completed (loss: 0.10309986025094986, acc: 0.9704142212867737)
[2024-12-17 01:55:31,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:31,395][root][INFO] - Training Epoch: 1/2, step 3175/7134 completed (loss: 0.08985110372304916, acc: 0.9760563373565674)
[2024-12-17 01:55:31,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:31,733][root][INFO] - Training Epoch: 1/2, step 3176/7134 completed (loss: 0.14936740696430206, acc: 0.965413510799408)
[2024-12-17 01:55:31,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:32,049][root][INFO] - Training Epoch: 1/2, step 3177/7134 completed (loss: 0.13985075056552887, acc: 0.9652777910232544)
[2024-12-17 01:55:32,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:32,372][root][INFO] - Training Epoch: 1/2, step 3178/7134 completed (loss: 0.04888555034995079, acc: 0.9885057210922241)
[2024-12-17 01:55:32,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:32,726][root][INFO] - Training Epoch: 1/2, step 3179/7134 completed (loss: 0.13645966351032257, acc: 0.9684908986091614)
[2024-12-17 01:55:32,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:33,049][root][INFO] - Training Epoch: 1/2, step 3180/7134 completed (loss: 0.11485245823860168, acc: 0.977142870426178)
[2024-12-17 01:55:33,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:33,381][root][INFO] - Training Epoch: 1/2, step 3181/7134 completed (loss: 0.1226620152592659, acc: 0.975039005279541)
[2024-12-17 01:55:33,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:33,720][root][INFO] - Training Epoch: 1/2, step 3182/7134 completed (loss: 0.056786224246025085, acc: 0.9895678162574768)
[2024-12-17 01:55:33,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:34,034][root][INFO] - Training Epoch: 1/2, step 3183/7134 completed (loss: 0.11046943813562393, acc: 0.9729272127151489)
[2024-12-17 01:55:34,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:34,379][root][INFO] - Training Epoch: 1/2, step 3184/7134 completed (loss: 0.11513213068246841, acc: 0.9791666865348816)
[2024-12-17 01:55:34,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:34,717][root][INFO] - Training Epoch: 1/2, step 3185/7134 completed (loss: 0.026418935507535934, acc: 0.9914529919624329)
[2024-12-17 01:55:34,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:35,053][root][INFO] - Training Epoch: 1/2, step 3186/7134 completed (loss: 0.05964038521051407, acc: 0.9792592525482178)
[2024-12-17 01:55:35,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:35,365][root][INFO] - Training Epoch: 1/2, step 3187/7134 completed (loss: 0.10210913419723511, acc: 0.9715189933776855)
[2024-12-17 01:55:35,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:35,716][root][INFO] - Training Epoch: 1/2, step 3188/7134 completed (loss: 0.0885087251663208, acc: 0.9754204154014587)
[2024-12-17 01:55:35,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:36,052][root][INFO] - Training Epoch: 1/2, step 3189/7134 completed (loss: 0.0938970223069191, acc: 0.9782923460006714)
[2024-12-17 01:55:36,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:36,405][root][INFO] - Training Epoch: 1/2, step 3190/7134 completed (loss: 0.10070784389972687, acc: 0.9797468185424805)
[2024-12-17 01:55:36,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:36,715][root][INFO] - Training Epoch: 1/2, step 3191/7134 completed (loss: 0.07540635764598846, acc: 0.9857142567634583)
[2024-12-17 01:55:36,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:37,031][root][INFO] - Training Epoch: 1/2, step 3192/7134 completed (loss: 0.08011685311794281, acc: 0.9848771095275879)
[2024-12-17 01:55:37,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:37,355][root][INFO] - Training Epoch: 1/2, step 3193/7134 completed (loss: 0.11354461312294006, acc: 0.9677891731262207)
[2024-12-17 01:55:37,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:37,677][root][INFO] - Training Epoch: 1/2, step 3194/7134 completed (loss: 0.1026342585682869, acc: 0.9787581562995911)
[2024-12-17 01:55:37,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:37,997][root][INFO] - Training Epoch: 1/2, step 3195/7134 completed (loss: 0.05472360551357269, acc: 0.9845626354217529)
[2024-12-17 01:55:38,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:38,312][root][INFO] - Training Epoch: 1/2, step 3196/7134 completed (loss: 0.048812974244356155, acc: 0.9869158864021301)
[2024-12-17 01:55:38,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:38,621][root][INFO] - Training Epoch: 1/2, step 3197/7134 completed (loss: 0.09827566146850586, acc: 0.9704225063323975)
[2024-12-17 01:55:38,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:38,953][root][INFO] - Training Epoch: 1/2, step 3198/7134 completed (loss: 0.09672261029481888, acc: 0.9803328514099121)
[2024-12-17 01:55:39,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:39,271][root][INFO] - Training Epoch: 1/2, step 3199/7134 completed (loss: 0.10284207761287689, acc: 0.9706314206123352)
[2024-12-17 01:55:39,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:39,558][root][INFO] - Training Epoch: 1/2, step 3200/7134 completed (loss: 0.07755821198225021, acc: 0.9806678295135498)
[2024-12-17 01:55:39,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:39,899][root][INFO] - Training Epoch: 1/2, step 3201/7134 completed (loss: 0.21802997589111328, acc: 0.9544468522071838)
[2024-12-17 01:55:40,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:40,233][root][INFO] - Training Epoch: 1/2, step 3202/7134 completed (loss: 0.05642468109726906, acc: 0.9847856163978577)
[2024-12-17 01:55:40,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:40,552][root][INFO] - Training Epoch: 1/2, step 3203/7134 completed (loss: 0.08961018919944763, acc: 0.9810426831245422)
[2024-12-17 01:55:40,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:40,866][root][INFO] - Training Epoch: 1/2, step 3204/7134 completed (loss: 0.14347387850284576, acc: 0.9567669034004211)
[2024-12-17 01:55:40,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:41,192][root][INFO] - Training Epoch: 1/2, step 3205/7134 completed (loss: 0.04336096718907356, acc: 0.9858657121658325)
[2024-12-17 01:55:41,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:41,552][root][INFO] - Training Epoch: 1/2, step 3206/7134 completed (loss: 0.05542093887925148, acc: 0.9898697733879089)
[2024-12-17 01:55:41,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:41,878][root][INFO] - Training Epoch: 1/2, step 3207/7134 completed (loss: 0.10896199941635132, acc: 0.9693721532821655)
[2024-12-17 01:55:41,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:42,222][root][INFO] - Training Epoch: 1/2, step 3208/7134 completed (loss: 0.10587247461080551, acc: 0.9787581562995911)
[2024-12-17 01:55:42,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:42,553][root][INFO] - Training Epoch: 1/2, step 3209/7134 completed (loss: 0.07567472755908966, acc: 0.9836309552192688)
[2024-12-17 01:55:42,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:42,887][root][INFO] - Training Epoch: 1/2, step 3210/7134 completed (loss: 0.035416752099990845, acc: 0.990963876247406)
[2024-12-17 01:55:43,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:43,204][root][INFO] - Training Epoch: 1/2, step 3211/7134 completed (loss: 0.0730489119887352, acc: 0.9854469895362854)
[2024-12-17 01:55:43,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:43,537][root][INFO] - Training Epoch: 1/2, step 3212/7134 completed (loss: 0.03193310648202896, acc: 0.9930070042610168)
[2024-12-17 01:55:43,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:43,875][root][INFO] - Training Epoch: 1/2, step 3213/7134 completed (loss: 0.05495641753077507, acc: 0.9856528043746948)
[2024-12-17 01:55:43,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:44,231][root][INFO] - Training Epoch: 1/2, step 3214/7134 completed (loss: 0.09333745390176773, acc: 0.9759036302566528)
[2024-12-17 01:55:44,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:44,580][root][INFO] - Training Epoch: 1/2, step 3215/7134 completed (loss: 0.07218483090400696, acc: 0.9859943985939026)
[2024-12-17 01:55:44,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:44,925][root][INFO] - Training Epoch: 1/2, step 3216/7134 completed (loss: 0.022863036021590233, acc: 0.9942693114280701)
[2024-12-17 01:55:45,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:45,284][root][INFO] - Training Epoch: 1/2, step 3217/7134 completed (loss: 0.07567623257637024, acc: 0.9793548583984375)
[2024-12-17 01:55:45,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:45,602][root][INFO] - Training Epoch: 1/2, step 3218/7134 completed (loss: 0.06911347061395645, acc: 0.9843505620956421)
[2024-12-17 01:55:45,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:45,932][root][INFO] - Training Epoch: 1/2, step 3219/7134 completed (loss: 0.11118019372224808, acc: 0.9675036668777466)
[2024-12-17 01:55:46,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:46,272][root][INFO] - Training Epoch: 1/2, step 3220/7134 completed (loss: 0.11445489525794983, acc: 0.9732977151870728)
[2024-12-17 01:55:46,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:46,624][root][INFO] - Training Epoch: 1/2, step 3221/7134 completed (loss: 0.12303327023983002, acc: 0.9726027250289917)
[2024-12-17 01:55:46,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:46,974][root][INFO] - Training Epoch: 1/2, step 3222/7134 completed (loss: 0.12044396996498108, acc: 0.9674593210220337)
[2024-12-17 01:55:47,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:47,304][root][INFO] - Training Epoch: 1/2, step 3223/7134 completed (loss: 0.1123945564031601, acc: 0.976190447807312)
[2024-12-17 01:55:47,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:47,667][root][INFO] - Training Epoch: 1/2, step 3224/7134 completed (loss: 0.1396649181842804, acc: 0.969609260559082)
[2024-12-17 01:55:47,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:48,020][root][INFO] - Training Epoch: 1/2, step 3225/7134 completed (loss: 0.09259495884180069, acc: 0.9785082340240479)
[2024-12-17 01:55:48,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:48,335][root][INFO] - Training Epoch: 1/2, step 3226/7134 completed (loss: 0.13371290266513824, acc: 0.9622980356216431)
[2024-12-17 01:55:48,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:48,712][root][INFO] - Training Epoch: 1/2, step 3227/7134 completed (loss: 0.14455029368400574, acc: 0.9549450278282166)
[2024-12-17 01:55:48,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:49,071][root][INFO] - Training Epoch: 1/2, step 3228/7134 completed (loss: 0.07529684901237488, acc: 0.9829171895980835)
[2024-12-17 01:55:49,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:49,414][root][INFO] - Training Epoch: 1/2, step 3229/7134 completed (loss: 0.10454188287258148, acc: 0.9742962121963501)
[2024-12-17 01:55:49,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:49,741][root][INFO] - Training Epoch: 1/2, step 3230/7134 completed (loss: 0.13587309420108795, acc: 0.9644970297813416)
[2024-12-17 01:55:49,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:50,050][root][INFO] - Training Epoch: 1/2, step 3231/7134 completed (loss: 0.14434170722961426, acc: 0.9589665532112122)
[2024-12-17 01:55:50,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:50,399][root][INFO] - Training Epoch: 1/2, step 3232/7134 completed (loss: 0.10068619251251221, acc: 0.9753086566925049)
[2024-12-17 01:55:50,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:50,719][root][INFO] - Training Epoch: 1/2, step 3233/7134 completed (loss: 0.14336282014846802, acc: 0.9704142212867737)
[2024-12-17 01:55:50,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:51,033][root][INFO] - Training Epoch: 1/2, step 3234/7134 completed (loss: 0.08125469088554382, acc: 0.9810426831245422)
[2024-12-17 01:55:51,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:51,365][root][INFO] - Training Epoch: 1/2, step 3235/7134 completed (loss: 0.08046125620603561, acc: 0.9733333587646484)
[2024-12-17 01:55:51,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:51,678][root][INFO] - Training Epoch: 1/2, step 3236/7134 completed (loss: 0.17398828268051147, acc: 0.9602356553077698)
[2024-12-17 01:55:51,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:52,007][root][INFO] - Training Epoch: 1/2, step 3237/7134 completed (loss: 0.06002822890877724, acc: 0.9806763529777527)
[2024-12-17 01:55:52,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:52,342][root][INFO] - Training Epoch: 1/2, step 3238/7134 completed (loss: 0.11568967998027802, acc: 0.9631901979446411)
[2024-12-17 01:55:52,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:52,676][root][INFO] - Training Epoch: 1/2, step 3239/7134 completed (loss: 0.05674944072961807, acc: 0.9842271208763123)
[2024-12-17 01:55:52,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:53,004][root][INFO] - Training Epoch: 1/2, step 3240/7134 completed (loss: 0.0885733962059021, acc: 0.980567991733551)
[2024-12-17 01:55:53,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:53,328][root][INFO] - Training Epoch: 1/2, step 3241/7134 completed (loss: 0.05865080654621124, acc: 0.9866468906402588)
[2024-12-17 01:55:53,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:53,655][root][INFO] - Training Epoch: 1/2, step 3242/7134 completed (loss: 0.05574795976281166, acc: 0.9885621070861816)
[2024-12-17 01:55:53,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:53,996][root][INFO] - Training Epoch: 1/2, step 3243/7134 completed (loss: 0.06696049124002457, acc: 0.9822888374328613)
[2024-12-17 01:55:54,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:54,314][root][INFO] - Training Epoch: 1/2, step 3244/7134 completed (loss: 0.05124136060476303, acc: 0.9885222315788269)
[2024-12-17 01:55:54,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:54,669][root][INFO] - Training Epoch: 1/2, step 3245/7134 completed (loss: 0.0996941402554512, acc: 0.9755154848098755)
[2024-12-17 01:55:54,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:55,017][root][INFO] - Training Epoch: 1/2, step 3246/7134 completed (loss: 0.11931058764457703, acc: 0.971794843673706)
[2024-12-17 01:55:55,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:55,350][root][INFO] - Training Epoch: 1/2, step 3247/7134 completed (loss: 0.08102762699127197, acc: 0.9789302945137024)
[2024-12-17 01:55:55,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:55,674][root][INFO] - Training Epoch: 1/2, step 3248/7134 completed (loss: 0.0350133441388607, acc: 0.9901477694511414)
[2024-12-17 01:55:55,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:56,009][root][INFO] - Training Epoch: 1/2, step 3249/7134 completed (loss: 0.05592772737145424, acc: 0.9916782379150391)
[2024-12-17 01:55:56,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:56,345][root][INFO] - Training Epoch: 1/2, step 3250/7134 completed (loss: 0.048555679619312286, acc: 0.9841726422309875)
[2024-12-17 01:55:56,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:56,675][root][INFO] - Training Epoch: 1/2, step 3251/7134 completed (loss: 0.019993897527456284, acc: 0.9942938685417175)
[2024-12-17 01:55:56,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:57,018][root][INFO] - Training Epoch: 1/2, step 3252/7134 completed (loss: 0.03352842852473259, acc: 0.9900709390640259)
[2024-12-17 01:55:57,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:57,349][root][INFO] - Training Epoch: 1/2, step 3253/7134 completed (loss: 0.034980472177267075, acc: 0.9903692007064819)
[2024-12-17 01:55:57,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:57,693][root][INFO] - Training Epoch: 1/2, step 3254/7134 completed (loss: 0.03263784199953079, acc: 0.9865092635154724)
[2024-12-17 01:55:57,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:58,020][root][INFO] - Training Epoch: 1/2, step 3255/7134 completed (loss: 0.027096368372440338, acc: 0.9880159497261047)
[2024-12-17 01:55:58,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:58,349][root][INFO] - Training Epoch: 1/2, step 3256/7134 completed (loss: 0.0278314258903265, acc: 0.9940740466117859)
[2024-12-17 01:55:58,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:58,681][root][INFO] - Training Epoch: 1/2, step 3257/7134 completed (loss: 0.04106339439749718, acc: 0.9889042973518372)
[2024-12-17 01:55:58,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:59,020][root][INFO] - Training Epoch: 1/2, step 3258/7134 completed (loss: 0.0634494423866272, acc: 0.982692301273346)
[2024-12-17 01:55:59,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:59,349][root][INFO] - Training Epoch: 1/2, step 3259/7134 completed (loss: 0.04374745488166809, acc: 0.9926470518112183)
[2024-12-17 01:55:59,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:59,669][root][INFO] - Training Epoch: 1/2, step 3260/7134 completed (loss: 0.14746779203414917, acc: 0.9777448177337646)
[2024-12-17 01:55:59,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:59,998][root][INFO] - Training Epoch: 1/2, step 3261/7134 completed (loss: 0.10855254530906677, acc: 0.9697986841201782)
[2024-12-17 01:56:00,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:00,336][root][INFO] - Training Epoch: 1/2, step 3262/7134 completed (loss: 0.060493115335702896, acc: 0.9826338887214661)
[2024-12-17 01:56:00,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:00,665][root][INFO] - Training Epoch: 1/2, step 3263/7134 completed (loss: 0.08758198469877243, acc: 0.9750367403030396)
[2024-12-17 01:56:00,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:00,989][root][INFO] - Training Epoch: 1/2, step 3264/7134 completed (loss: 0.05124117434024811, acc: 0.9847221970558167)
[2024-12-17 01:56:01,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:01,332][root][INFO] - Training Epoch: 1/2, step 3265/7134 completed (loss: 0.13819754123687744, acc: 0.9814814925193787)
[2024-12-17 01:56:01,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:01,669][root][INFO] - Training Epoch: 1/2, step 3266/7134 completed (loss: 0.0711853951215744, acc: 0.9819819927215576)
[2024-12-17 01:56:01,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:02,008][root][INFO] - Training Epoch: 1/2, step 3267/7134 completed (loss: 0.11515668034553528, acc: 0.9770773649215698)
[2024-12-17 01:56:02,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:02,325][root][INFO] - Training Epoch: 1/2, step 3268/7134 completed (loss: 0.09962711483240128, acc: 0.9799692034721375)
[2024-12-17 01:56:02,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:02,672][root][INFO] - Training Epoch: 1/2, step 3269/7134 completed (loss: 0.06276741623878479, acc: 0.9823232293128967)
[2024-12-17 01:56:02,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:03,024][root][INFO] - Training Epoch: 1/2, step 3270/7134 completed (loss: 0.03897906839847565, acc: 0.989234447479248)
[2024-12-17 01:56:03,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:03,294][root][INFO] - Training Epoch: 1/2, step 3271/7134 completed (loss: 0.015529538504779339, acc: 1.0)
[2024-12-17 01:56:03,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:03,625][root][INFO] - Training Epoch: 1/2, step 3272/7134 completed (loss: 0.05538858845829964, acc: 0.989313006401062)
[2024-12-17 01:56:03,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:03,974][root][INFO] - Training Epoch: 1/2, step 3273/7134 completed (loss: 0.08307966589927673, acc: 0.9757343530654907)
[2024-12-17 01:56:04,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:04,322][root][INFO] - Training Epoch: 1/2, step 3274/7134 completed (loss: 0.0805545225739479, acc: 0.9779735803604126)
[2024-12-17 01:56:04,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:04,665][root][INFO] - Training Epoch: 1/2, step 3275/7134 completed (loss: 0.23079346120357513, acc: 0.9415204524993896)
[2024-12-17 01:56:04,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:04,996][root][INFO] - Training Epoch: 1/2, step 3276/7134 completed (loss: 0.10689373314380646, acc: 0.9710744023323059)
[2024-12-17 01:56:05,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:05,338][root][INFO] - Training Epoch: 1/2, step 3277/7134 completed (loss: 0.12896323204040527, acc: 0.9664633870124817)
[2024-12-17 01:56:05,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:05,614][root][INFO] - Training Epoch: 1/2, step 3278/7134 completed (loss: 0.08790595084428787, acc: 0.9732313752174377)
[2024-12-17 01:56:05,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:05,966][root][INFO] - Training Epoch: 1/2, step 3279/7134 completed (loss: 0.1169448122382164, acc: 0.9652174115180969)
[2024-12-17 01:56:06,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:06,289][root][INFO] - Training Epoch: 1/2, step 3280/7134 completed (loss: 0.2734394371509552, acc: 0.9502074718475342)
[2024-12-17 01:56:06,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:06,633][root][INFO] - Training Epoch: 1/2, step 3281/7134 completed (loss: 0.1181962713599205, acc: 0.9666666388511658)
[2024-12-17 01:56:06,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:06,965][root][INFO] - Training Epoch: 1/2, step 3282/7134 completed (loss: 0.05941929295659065, acc: 0.9920886158943176)
[2024-12-17 01:56:07,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:07,312][root][INFO] - Training Epoch: 1/2, step 3283/7134 completed (loss: 0.08654552698135376, acc: 0.977319598197937)
[2024-12-17 01:56:07,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:07,638][root][INFO] - Training Epoch: 1/2, step 3284/7134 completed (loss: 0.13856922090053558, acc: 0.9634703397750854)
[2024-12-17 01:56:07,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:07,961][root][INFO] - Training Epoch: 1/2, step 3285/7134 completed (loss: 0.07891015708446503, acc: 0.9752321839332581)
[2024-12-17 01:56:08,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:08,291][root][INFO] - Training Epoch: 1/2, step 3286/7134 completed (loss: 0.10471737384796143, acc: 0.9729323387145996)
[2024-12-17 01:56:08,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:08,615][root][INFO] - Training Epoch: 1/2, step 3287/7134 completed (loss: 0.16820691525936127, acc: 0.9572368264198303)
[2024-12-17 01:56:08,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:08,954][root][INFO] - Training Epoch: 1/2, step 3288/7134 completed (loss: 0.0922243669629097, acc: 0.9790419340133667)
[2024-12-17 01:56:09,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:09,245][root][INFO] - Training Epoch: 1/2, step 3289/7134 completed (loss: 0.12571462988853455, acc: 0.9649122953414917)
[2024-12-17 01:56:09,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:09,562][root][INFO] - Training Epoch: 1/2, step 3290/7134 completed (loss: 0.14572221040725708, acc: 0.9670138955116272)
[2024-12-17 01:56:09,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:09,883][root][INFO] - Training Epoch: 1/2, step 3291/7134 completed (loss: 0.11325553059577942, acc: 0.9710467457771301)
[2024-12-17 01:56:09,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:10,203][root][INFO] - Training Epoch: 1/2, step 3292/7134 completed (loss: 0.09886455535888672, acc: 0.9753086566925049)
[2024-12-17 01:56:10,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:10,565][root][INFO] - Training Epoch: 1/2, step 3293/7134 completed (loss: 0.07125016301870346, acc: 0.983775794506073)
[2024-12-17 01:56:10,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:10,896][root][INFO] - Training Epoch: 1/2, step 3294/7134 completed (loss: 0.10664855688810349, acc: 0.9739663004875183)
[2024-12-17 01:56:10,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:11,194][root][INFO] - Training Epoch: 1/2, step 3295/7134 completed (loss: 0.05060642957687378, acc: 0.9829351305961609)
[2024-12-17 01:56:11,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:11,509][root][INFO] - Training Epoch: 1/2, step 3296/7134 completed (loss: 0.11065121740102768, acc: 0.972577691078186)
[2024-12-17 01:56:11,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:11,790][root][INFO] - Training Epoch: 1/2, step 3297/7134 completed (loss: 0.10848700255155563, acc: 0.9694835543632507)
[2024-12-17 01:56:11,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:12,110][root][INFO] - Training Epoch: 1/2, step 3298/7134 completed (loss: 0.13893277943134308, acc: 0.9840255379676819)
[2024-12-17 01:56:12,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:12,430][root][INFO] - Training Epoch: 1/2, step 3299/7134 completed (loss: 0.08033009618520737, acc: 0.9714764952659607)
[2024-12-17 01:56:12,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:12,745][root][INFO] - Training Epoch: 1/2, step 3300/7134 completed (loss: 0.13895925879478455, acc: 0.9607843160629272)
[2024-12-17 01:56:12,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:13,023][root][INFO] - Training Epoch: 1/2, step 3301/7134 completed (loss: 0.12049739062786102, acc: 0.9709543585777283)
[2024-12-17 01:56:13,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:13,334][root][INFO] - Training Epoch: 1/2, step 3302/7134 completed (loss: 0.14032961428165436, acc: 0.9730639457702637)
[2024-12-17 01:56:13,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:13,591][root][INFO] - Training Epoch: 1/2, step 3303/7134 completed (loss: 0.12415340542793274, acc: 0.9735682606697083)
[2024-12-17 01:56:13,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:13,941][root][INFO] - Training Epoch: 1/2, step 3304/7134 completed (loss: 0.06463208049535751, acc: 0.9880668520927429)
[2024-12-17 01:56:14,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:14,272][root][INFO] - Training Epoch: 1/2, step 3305/7134 completed (loss: 0.10052932053804398, acc: 0.9743589758872986)
[2024-12-17 01:56:14,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:14,647][root][INFO] - Training Epoch: 1/2, step 3306/7134 completed (loss: 0.1102733314037323, acc: 0.966277539730072)
[2024-12-17 01:56:14,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:14,979][root][INFO] - Training Epoch: 1/2, step 3307/7134 completed (loss: 0.13150955736637115, acc: 0.9712352156639099)
[2024-12-17 01:56:15,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:15,306][root][INFO] - Training Epoch: 1/2, step 3308/7134 completed (loss: 0.09528734534978867, acc: 0.9754335284233093)
[2024-12-17 01:56:15,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:15,617][root][INFO] - Training Epoch: 1/2, step 3309/7134 completed (loss: 0.11580625176429749, acc: 0.9675516486167908)
[2024-12-17 01:56:15,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:15,967][root][INFO] - Training Epoch: 1/2, step 3310/7134 completed (loss: 0.10768865793943405, acc: 0.9722814559936523)
[2024-12-17 01:56:16,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:16,246][root][INFO] - Training Epoch: 1/2, step 3311/7134 completed (loss: 0.10085437446832657, acc: 0.9784946441650391)
[2024-12-17 01:56:16,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:16,595][root][INFO] - Training Epoch: 1/2, step 3312/7134 completed (loss: 0.10075735300779343, acc: 0.9818181991577148)
[2024-12-17 01:56:16,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:16,927][root][INFO] - Training Epoch: 1/2, step 3313/7134 completed (loss: 0.07391758263111115, acc: 0.9880668520927429)
[2024-12-17 01:56:17,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:17,256][root][INFO] - Training Epoch: 1/2, step 3314/7134 completed (loss: 0.11085417121648788, acc: 0.9746376872062683)
[2024-12-17 01:56:17,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:17,620][root][INFO] - Training Epoch: 1/2, step 3315/7134 completed (loss: 0.16005468368530273, acc: 0.9674355387687683)
[2024-12-17 01:56:17,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:17,983][root][INFO] - Training Epoch: 1/2, step 3316/7134 completed (loss: 0.08008641004562378, acc: 0.9798319339752197)
[2024-12-17 01:56:18,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:18,315][root][INFO] - Training Epoch: 1/2, step 3317/7134 completed (loss: 0.14066267013549805, acc: 0.9576923251152039)
[2024-12-17 01:56:18,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:18,537][root][INFO] - Training Epoch: 1/2, step 3318/7134 completed (loss: 0.13517335057258606, acc: 0.9602888226509094)
[2024-12-17 01:56:18,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:18,891][root][INFO] - Training Epoch: 1/2, step 3319/7134 completed (loss: 0.13550788164138794, acc: 0.9690553545951843)
[2024-12-17 01:56:19,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:19,242][root][INFO] - Training Epoch: 1/2, step 3320/7134 completed (loss: 0.18089036643505096, acc: 0.9685863852500916)
[2024-12-17 01:56:19,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:19,566][root][INFO] - Training Epoch: 1/2, step 3321/7134 completed (loss: 0.18680009245872498, acc: 0.9541284441947937)
[2024-12-17 01:56:19,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:19,930][root][INFO] - Training Epoch: 1/2, step 3322/7134 completed (loss: 0.102909155189991, acc: 0.9729729890823364)
[2024-12-17 01:56:20,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:20,278][root][INFO] - Training Epoch: 1/2, step 3323/7134 completed (loss: 0.08458931744098663, acc: 0.9806896448135376)
[2024-12-17 01:56:20,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:20,650][root][INFO] - Training Epoch: 1/2, step 3324/7134 completed (loss: 0.156830295920372, acc: 0.9564192891120911)
[2024-12-17 01:56:20,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:21,005][root][INFO] - Training Epoch: 1/2, step 3325/7134 completed (loss: 0.10072637349367142, acc: 0.9784946441650391)
[2024-12-17 01:56:21,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:21,344][root][INFO] - Training Epoch: 1/2, step 3326/7134 completed (loss: 0.11915843188762665, acc: 0.9795275330543518)
[2024-12-17 01:56:21,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:21,671][root][INFO] - Training Epoch: 1/2, step 3327/7134 completed (loss: 0.11860901117324829, acc: 0.97428959608078)
[2024-12-17 01:56:21,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:22,032][root][INFO] - Training Epoch: 1/2, step 3328/7134 completed (loss: 0.11206483095884323, acc: 0.976190447807312)
[2024-12-17 01:56:22,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:22,374][root][INFO] - Training Epoch: 1/2, step 3329/7134 completed (loss: 0.06776808947324753, acc: 0.9841656684875488)
[2024-12-17 01:56:22,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:22,733][root][INFO] - Training Epoch: 1/2, step 3330/7134 completed (loss: 0.136752188205719, acc: 0.9654377698898315)
[2024-12-17 01:56:22,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:23,058][root][INFO] - Training Epoch: 1/2, step 3331/7134 completed (loss: 0.2038067728281021, acc: 0.9593023061752319)
[2024-12-17 01:56:23,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:23,421][root][INFO] - Training Epoch: 1/2, step 3332/7134 completed (loss: 0.2330179214477539, acc: 0.9498270153999329)
[2024-12-17 01:56:23,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:23,729][root][INFO] - Training Epoch: 1/2, step 3333/7134 completed (loss: 0.15680474042892456, acc: 0.9590163826942444)
[2024-12-17 01:56:23,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:24,060][root][INFO] - Training Epoch: 1/2, step 3334/7134 completed (loss: 0.17854216694831848, acc: 0.9527027010917664)
[2024-12-17 01:56:24,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:24,415][root][INFO] - Training Epoch: 1/2, step 3335/7134 completed (loss: 0.09327077865600586, acc: 0.9762658476829529)
[2024-12-17 01:56:24,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:24,742][root][INFO] - Training Epoch: 1/2, step 3336/7134 completed (loss: 0.05571244657039642, acc: 0.991253674030304)
[2024-12-17 01:56:24,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:25,069][root][INFO] - Training Epoch: 1/2, step 3337/7134 completed (loss: 0.03586755320429802, acc: 0.9940828680992126)
[2024-12-17 01:56:25,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:25,419][root][INFO] - Training Epoch: 1/2, step 3338/7134 completed (loss: 0.04238520935177803, acc: 0.9900621175765991)
[2024-12-17 01:56:25,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:25,786][root][INFO] - Training Epoch: 1/2, step 3339/7134 completed (loss: 0.16923213005065918, acc: 0.9630071520805359)
[2024-12-17 01:56:25,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:26,117][root][INFO] - Training Epoch: 1/2, step 3340/7134 completed (loss: 0.18595346808433533, acc: 0.9457013607025146)
[2024-12-17 01:56:26,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:26,465][root][INFO] - Training Epoch: 1/2, step 3341/7134 completed (loss: 0.15040045976638794, acc: 0.9644444584846497)
[2024-12-17 01:56:26,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:26,801][root][INFO] - Training Epoch: 1/2, step 3342/7134 completed (loss: 0.10449721664190292, acc: 0.9797297120094299)
[2024-12-17 01:56:26,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:27,143][root][INFO] - Training Epoch: 1/2, step 3343/7134 completed (loss: 0.07517264038324356, acc: 0.975806474685669)
[2024-12-17 01:56:27,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:27,479][root][INFO] - Training Epoch: 1/2, step 3344/7134 completed (loss: 0.08052660524845123, acc: 0.9777015447616577)
[2024-12-17 01:56:27,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:27,818][root][INFO] - Training Epoch: 1/2, step 3345/7134 completed (loss: 0.11291706562042236, acc: 0.9773095846176147)
[2024-12-17 01:56:27,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:28,160][root][INFO] - Training Epoch: 1/2, step 3346/7134 completed (loss: 0.05463957041501999, acc: 0.9853801131248474)
[2024-12-17 01:56:28,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:28,481][root][INFO] - Training Epoch: 1/2, step 3347/7134 completed (loss: 0.14983686804771423, acc: 0.965798020362854)
[2024-12-17 01:56:28,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:28,802][root][INFO] - Training Epoch: 1/2, step 3348/7134 completed (loss: 0.09344089776277542, acc: 0.9733333587646484)
[2024-12-17 01:56:28,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:29,092][root][INFO] - Training Epoch: 1/2, step 3349/7134 completed (loss: 0.04657965153455734, acc: 0.9876543283462524)
[2024-12-17 01:56:29,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:29,427][root][INFO] - Training Epoch: 1/2, step 3350/7134 completed (loss: 0.07539930939674377, acc: 0.9817073345184326)
[2024-12-17 01:56:29,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:29,752][root][INFO] - Training Epoch: 1/2, step 3351/7134 completed (loss: 0.14528660476207733, acc: 0.970822274684906)
[2024-12-17 01:56:29,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:30,073][root][INFO] - Training Epoch: 1/2, step 3352/7134 completed (loss: 0.0435774065554142, acc: 0.991304337978363)
[2024-12-17 01:56:30,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:30,395][root][INFO] - Training Epoch: 1/2, step 3353/7134 completed (loss: 0.11792820692062378, acc: 0.9822485446929932)
[2024-12-17 01:56:30,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:30,718][root][INFO] - Training Epoch: 1/2, step 3354/7134 completed (loss: 0.05337400734424591, acc: 0.9891473054885864)
[2024-12-17 01:56:30,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:31,049][root][INFO] - Training Epoch: 1/2, step 3355/7134 completed (loss: 0.04766998440027237, acc: 0.9901269674301147)
[2024-12-17 01:56:31,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:31,375][root][INFO] - Training Epoch: 1/2, step 3356/7134 completed (loss: 0.029028262943029404, acc: 0.9930555820465088)
[2024-12-17 01:56:31,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:31,709][root][INFO] - Training Epoch: 1/2, step 3357/7134 completed (loss: 0.07583442330360413, acc: 0.9797979593276978)
[2024-12-17 01:56:31,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:32,023][root][INFO] - Training Epoch: 1/2, step 3358/7134 completed (loss: 0.11422514170408249, acc: 0.979238748550415)
[2024-12-17 01:56:32,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:32,343][root][INFO] - Training Epoch: 1/2, step 3359/7134 completed (loss: 0.07335318624973297, acc: 0.9870550036430359)
[2024-12-17 01:56:32,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:32,659][root][INFO] - Training Epoch: 1/2, step 3360/7134 completed (loss: 0.10872218012809753, acc: 0.9678111672401428)
[2024-12-17 01:56:32,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:32,980][root][INFO] - Training Epoch: 1/2, step 3361/7134 completed (loss: 0.10862889885902405, acc: 0.9686800837516785)
[2024-12-17 01:56:33,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:33,298][root][INFO] - Training Epoch: 1/2, step 3362/7134 completed (loss: 0.08605026453733444, acc: 0.9818593859672546)
[2024-12-17 01:56:33,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:33,591][root][INFO] - Training Epoch: 1/2, step 3363/7134 completed (loss: 0.0391530841588974, acc: 0.9882628917694092)
[2024-12-17 01:56:33,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:33,930][root][INFO] - Training Epoch: 1/2, step 3364/7134 completed (loss: 0.14296983182430267, acc: 0.9662058353424072)
[2024-12-17 01:56:34,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:34,255][root][INFO] - Training Epoch: 1/2, step 3365/7134 completed (loss: 0.08842986077070236, acc: 0.983132541179657)
[2024-12-17 01:56:34,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:34,577][root][INFO] - Training Epoch: 1/2, step 3366/7134 completed (loss: 0.04593943431973457, acc: 0.9865471124649048)
[2024-12-17 01:56:34,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:34,898][root][INFO] - Training Epoch: 1/2, step 3367/7134 completed (loss: 0.08171385526657104, acc: 0.9724518060684204)
[2024-12-17 01:56:35,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:35,238][root][INFO] - Training Epoch: 1/2, step 3368/7134 completed (loss: 0.11619462072849274, acc: 0.9703587889671326)
[2024-12-17 01:56:35,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:35,608][root][INFO] - Training Epoch: 1/2, step 3369/7134 completed (loss: 0.11666692048311234, acc: 0.971222996711731)
[2024-12-17 01:56:35,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:35,939][root][INFO] - Training Epoch: 1/2, step 3370/7134 completed (loss: 0.08940494805574417, acc: 0.9699570536613464)
[2024-12-17 01:56:36,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:36,260][root][INFO] - Training Epoch: 1/2, step 3371/7134 completed (loss: 0.06453423202037811, acc: 0.9802631735801697)
[2024-12-17 01:56:36,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:36,594][root][INFO] - Training Epoch: 1/2, step 3372/7134 completed (loss: 0.07853282988071442, acc: 0.9890282154083252)
[2024-12-17 01:56:36,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:36,920][root][INFO] - Training Epoch: 1/2, step 3373/7134 completed (loss: 0.06023833900690079, acc: 0.9830247163772583)
[2024-12-17 01:56:37,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:37,280][root][INFO] - Training Epoch: 1/2, step 3374/7134 completed (loss: 0.07758398354053497, acc: 0.9860724210739136)
[2024-12-17 01:56:37,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:37,638][root][INFO] - Training Epoch: 1/2, step 3375/7134 completed (loss: 0.07201588898897171, acc: 0.9840810298919678)
[2024-12-17 01:56:37,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:37,986][root][INFO] - Training Epoch: 1/2, step 3376/7134 completed (loss: 0.03633403033018112, acc: 0.9910600185394287)
[2024-12-17 01:56:38,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:38,359][root][INFO] - Training Epoch: 1/2, step 3377/7134 completed (loss: 0.05649707093834877, acc: 0.9880810379981995)
[2024-12-17 01:56:38,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:38,706][root][INFO] - Training Epoch: 1/2, step 3378/7134 completed (loss: 0.04744761064648628, acc: 0.9895833134651184)
[2024-12-17 01:56:38,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:39,033][root][INFO] - Training Epoch: 1/2, step 3379/7134 completed (loss: 0.07536715269088745, acc: 0.9759398698806763)
[2024-12-17 01:56:39,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:39,360][root][INFO] - Training Epoch: 1/2, step 3380/7134 completed (loss: 0.09848440438508987, acc: 0.9784615635871887)
[2024-12-17 01:56:39,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:39,715][root][INFO] - Training Epoch: 1/2, step 3381/7134 completed (loss: 0.08083624392747879, acc: 0.9819121360778809)
[2024-12-17 01:56:39,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:40,048][root][INFO] - Training Epoch: 1/2, step 3382/7134 completed (loss: 0.04015554487705231, acc: 0.987889289855957)
[2024-12-17 01:56:40,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:40,404][root][INFO] - Training Epoch: 1/2, step 3383/7134 completed (loss: 0.08118164539337158, acc: 0.9770444631576538)
[2024-12-17 01:56:40,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:40,716][root][INFO] - Training Epoch: 1/2, step 3384/7134 completed (loss: 0.05523836612701416, acc: 0.9847095012664795)
[2024-12-17 01:56:40,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:41,053][root][INFO] - Training Epoch: 1/2, step 3385/7134 completed (loss: 0.06504429131746292, acc: 0.9784172773361206)
[2024-12-17 01:56:41,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:41,388][root][INFO] - Training Epoch: 1/2, step 3386/7134 completed (loss: 0.04787110537290573, acc: 0.9901130199432373)
[2024-12-17 01:56:41,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:41,721][root][INFO] - Training Epoch: 1/2, step 3387/7134 completed (loss: 0.11343008279800415, acc: 0.9741496443748474)
[2024-12-17 01:56:41,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:42,055][root][INFO] - Training Epoch: 1/2, step 3388/7134 completed (loss: 0.10512149333953857, acc: 0.978300154209137)
[2024-12-17 01:56:42,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:42,384][root][INFO] - Training Epoch: 1/2, step 3389/7134 completed (loss: 0.05606979876756668, acc: 0.9881423115730286)
[2024-12-17 01:56:42,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:42,726][root][INFO] - Training Epoch: 1/2, step 3390/7134 completed (loss: 0.06984961777925491, acc: 0.9818652868270874)
[2024-12-17 01:56:42,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:43,035][root][INFO] - Training Epoch: 1/2, step 3391/7134 completed (loss: 0.029863819479942322, acc: 0.9903846383094788)
[2024-12-17 01:56:43,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:43,340][root][INFO] - Training Epoch: 1/2, step 3392/7134 completed (loss: 0.053754422813653946, acc: 0.9827044010162354)
[2024-12-17 01:56:43,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:43,654][root][INFO] - Training Epoch: 1/2, step 3393/7134 completed (loss: 0.08321896195411682, acc: 0.9783950448036194)
[2024-12-17 01:56:43,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:43,994][root][INFO] - Training Epoch: 1/2, step 3394/7134 completed (loss: 0.0700487345457077, acc: 0.9810126423835754)
[2024-12-17 01:56:44,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:44,318][root][INFO] - Training Epoch: 1/2, step 3395/7134 completed (loss: 0.13316883146762848, acc: 0.9594155550003052)
[2024-12-17 01:56:44,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:44,670][root][INFO] - Training Epoch: 1/2, step 3396/7134 completed (loss: 0.054606884717941284, acc: 0.9868263602256775)
[2024-12-17 01:56:44,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:45,027][root][INFO] - Training Epoch: 1/2, step 3397/7134 completed (loss: 0.06464525312185287, acc: 0.9889975786209106)
[2024-12-17 01:56:45,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:45,362][root][INFO] - Training Epoch: 1/2, step 3398/7134 completed (loss: 0.09736426919698715, acc: 0.9767025113105774)
[2024-12-17 01:56:45,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:45,683][root][INFO] - Training Epoch: 1/2, step 3399/7134 completed (loss: 0.19087058305740356, acc: 0.9613970518112183)
[2024-12-17 01:56:45,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:46,015][root][INFO] - Training Epoch: 1/2, step 3400/7134 completed (loss: 0.14703260362148285, acc: 0.9655172228813171)
[2024-12-17 01:56:46,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:46,340][root][INFO] - Training Epoch: 1/2, step 3401/7134 completed (loss: 0.15393546223640442, acc: 0.9597902297973633)
[2024-12-17 01:56:46,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:46,727][root][INFO] - Training Epoch: 1/2, step 3402/7134 completed (loss: 0.18020449578762054, acc: 0.9617918133735657)
[2024-12-17 01:56:46,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:47,149][root][INFO] - Training Epoch: 1/2, step 3403/7134 completed (loss: 0.1592358499765396, acc: 0.9596354365348816)
[2024-12-17 01:56:47,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:47,476][root][INFO] - Training Epoch: 1/2, step 3404/7134 completed (loss: 0.06353821605443954, acc: 0.9895366430282593)
[2024-12-17 01:56:47,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:47,848][root][INFO] - Training Epoch: 1/2, step 3405/7134 completed (loss: 0.14621829986572266, acc: 0.9730215668678284)
[2024-12-17 01:56:47,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:48,197][root][INFO] - Training Epoch: 1/2, step 3406/7134 completed (loss: 0.09006362408399582, acc: 0.9780927896499634)
[2024-12-17 01:56:48,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:48,497][root][INFO] - Training Epoch: 1/2, step 3407/7134 completed (loss: 0.08779372274875641, acc: 0.9859594106674194)
[2024-12-17 01:56:48,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:48,808][root][INFO] - Training Epoch: 1/2, step 3408/7134 completed (loss: 0.0905146524310112, acc: 0.97926265001297)
[2024-12-17 01:56:48,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:49,162][root][INFO] - Training Epoch: 1/2, step 3409/7134 completed (loss: 0.11119268834590912, acc: 0.9702300429344177)
[2024-12-17 01:56:49,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:49,492][root][INFO] - Training Epoch: 1/2, step 3410/7134 completed (loss: 0.07792992889881134, acc: 0.9876033067703247)
[2024-12-17 01:56:49,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:49,841][root][INFO] - Training Epoch: 1/2, step 3411/7134 completed (loss: 0.10466988384723663, acc: 0.9728330969810486)
[2024-12-17 01:56:49,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:50,151][root][INFO] - Training Epoch: 1/2, step 3412/7134 completed (loss: 0.10118917375802994, acc: 0.9697542786598206)
[2024-12-17 01:56:50,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:50,481][root][INFO] - Training Epoch: 1/2, step 3413/7134 completed (loss: 0.07318463921546936, acc: 0.9760000109672546)
[2024-12-17 01:56:50,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:50,805][root][INFO] - Training Epoch: 1/2, step 3414/7134 completed (loss: 0.0825846865773201, acc: 0.9799666404724121)
[2024-12-17 01:56:50,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:51,160][root][INFO] - Training Epoch: 1/2, step 3415/7134 completed (loss: 0.0906609520316124, acc: 0.9727563858032227)
[2024-12-17 01:56:51,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:51,526][root][INFO] - Training Epoch: 1/2, step 3416/7134 completed (loss: 0.09544441103935242, acc: 0.971188485622406)
[2024-12-17 01:56:51,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:51,874][root][INFO] - Training Epoch: 1/2, step 3417/7134 completed (loss: 0.0441562794148922, acc: 0.9865047335624695)
[2024-12-17 01:56:51,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:52,205][root][INFO] - Training Epoch: 1/2, step 3418/7134 completed (loss: 0.045857928693294525, acc: 0.9882179498672485)
[2024-12-17 01:56:52,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:52,522][root][INFO] - Training Epoch: 1/2, step 3419/7134 completed (loss: 0.020249774679541588, acc: 0.9956772327423096)
[2024-12-17 01:56:52,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:52,858][root][INFO] - Training Epoch: 1/2, step 3420/7134 completed (loss: 0.04198545962572098, acc: 0.9873617887496948)
[2024-12-17 01:56:52,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:53,198][root][INFO] - Training Epoch: 1/2, step 3421/7134 completed (loss: 0.06217221915721893, acc: 0.9813374876976013)
[2024-12-17 01:56:53,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:53,508][root][INFO] - Training Epoch: 1/2, step 3422/7134 completed (loss: 0.01908167265355587, acc: 0.9947460889816284)
[2024-12-17 01:56:53,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:53,847][root][INFO] - Training Epoch: 1/2, step 3423/7134 completed (loss: 0.03151820972561836, acc: 0.9909090995788574)
[2024-12-17 01:56:53,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:54,173][root][INFO] - Training Epoch: 1/2, step 3424/7134 completed (loss: 0.10196393728256226, acc: 0.9728915691375732)
[2024-12-17 01:56:54,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:54,497][root][INFO] - Training Epoch: 1/2, step 3425/7134 completed (loss: 0.06638841331005096, acc: 0.9871794581413269)
[2024-12-17 01:56:54,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:54,845][root][INFO] - Training Epoch: 1/2, step 3426/7134 completed (loss: 0.07392068952322006, acc: 0.9875862002372742)
[2024-12-17 01:56:54,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:55,171][root][INFO] - Training Epoch: 1/2, step 3427/7134 completed (loss: 0.06692834198474884, acc: 0.9921011328697205)
[2024-12-17 01:56:55,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:55,518][root][INFO] - Training Epoch: 1/2, step 3428/7134 completed (loss: 0.026798026636242867, acc: 0.9928366541862488)
[2024-12-17 01:56:55,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:55,877][root][INFO] - Training Epoch: 1/2, step 3429/7134 completed (loss: 0.08517243713140488, acc: 0.9789643883705139)
[2024-12-17 01:56:56,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:56,207][root][INFO] - Training Epoch: 1/2, step 3430/7134 completed (loss: 0.1471131145954132, acc: 0.9643436074256897)
[2024-12-17 01:56:56,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:56,551][root][INFO] - Training Epoch: 1/2, step 3431/7134 completed (loss: 0.0794830173254013, acc: 0.9813242554664612)
[2024-12-17 01:56:56,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:56,905][root][INFO] - Training Epoch: 1/2, step 3432/7134 completed (loss: 0.08339827507734299, acc: 0.9780521392822266)
[2024-12-17 01:56:57,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:57,266][root][INFO] - Training Epoch: 1/2, step 3433/7134 completed (loss: 0.11443662643432617, acc: 0.970588207244873)
[2024-12-17 01:56:57,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:57,592][root][INFO] - Training Epoch: 1/2, step 3434/7134 completed (loss: 0.06821401417255402, acc: 0.9745628237724304)
[2024-12-17 01:56:57,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:57,927][root][INFO] - Training Epoch: 1/2, step 3435/7134 completed (loss: 0.09729143977165222, acc: 0.9726688265800476)
[2024-12-17 01:56:58,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:58,265][root][INFO] - Training Epoch: 1/2, step 3436/7134 completed (loss: 0.10049227625131607, acc: 0.9739837646484375)
[2024-12-17 01:56:58,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:58,559][root][INFO] - Training Epoch: 1/2, step 3437/7134 completed (loss: 0.06262631714344025, acc: 0.984375)
[2024-12-17 01:56:58,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:58,894][root][INFO] - Training Epoch: 1/2, step 3438/7134 completed (loss: 0.07778488844633102, acc: 0.9757575988769531)
[2024-12-17 01:56:59,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:59,198][root][INFO] - Training Epoch: 1/2, step 3439/7134 completed (loss: 0.0932319164276123, acc: 0.978300154209137)
[2024-12-17 01:56:59,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:59,522][root][INFO] - Training Epoch: 1/2, step 3440/7134 completed (loss: 0.1355023831129074, acc: 0.9650205969810486)
[2024-12-17 01:56:59,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:59,856][root][INFO] - Training Epoch: 1/2, step 3441/7134 completed (loss: 0.1296551376581192, acc: 0.9710982441902161)
[2024-12-17 01:56:59,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:00,184][root][INFO] - Training Epoch: 1/2, step 3442/7134 completed (loss: 0.04543907940387726, acc: 0.989051103591919)
[2024-12-17 01:57:00,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:00,470][root][INFO] - Training Epoch: 1/2, step 3443/7134 completed (loss: 0.13542450964450836, acc: 0.9719101190567017)
[2024-12-17 01:57:00,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:00,799][root][INFO] - Training Epoch: 1/2, step 3444/7134 completed (loss: 0.0918102115392685, acc: 0.982594907283783)
[2024-12-17 01:57:00,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:01,094][root][INFO] - Training Epoch: 1/2, step 3445/7134 completed (loss: 0.2231038361787796, acc: 0.9440860152244568)
[2024-12-17 01:57:01,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:01,440][root][INFO] - Training Epoch: 1/2, step 3446/7134 completed (loss: 0.160254567861557, acc: 0.9648829698562622)
[2024-12-17 01:57:01,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:01,778][root][INFO] - Training Epoch: 1/2, step 3447/7134 completed (loss: 0.12008833140134811, acc: 0.965798020362854)
[2024-12-17 01:57:01,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:02,100][root][INFO] - Training Epoch: 1/2, step 3448/7134 completed (loss: 0.07646354287862778, acc: 0.9834834933280945)
[2024-12-17 01:57:02,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:02,458][root][INFO] - Training Epoch: 1/2, step 3449/7134 completed (loss: 0.110498808324337, acc: 0.9846938848495483)
[2024-12-17 01:57:02,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:02,790][root][INFO] - Training Epoch: 1/2, step 3450/7134 completed (loss: 0.11798107624053955, acc: 0.9746835231781006)
[2024-12-17 01:57:02,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:03,113][root][INFO] - Training Epoch: 1/2, step 3451/7134 completed (loss: 0.10442779958248138, acc: 0.971731424331665)
[2024-12-17 01:57:03,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:03,437][root][INFO] - Training Epoch: 1/2, step 3452/7134 completed (loss: 0.1107780858874321, acc: 0.9739696383476257)
[2024-12-17 01:57:03,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:03,759][root][INFO] - Training Epoch: 1/2, step 3453/7134 completed (loss: 0.09082827717065811, acc: 0.9779286980628967)
[2024-12-17 01:57:03,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:04,101][root][INFO] - Training Epoch: 1/2, step 3454/7134 completed (loss: 0.08932618796825409, acc: 0.9774330258369446)
[2024-12-17 01:57:04,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:04,450][root][INFO] - Training Epoch: 1/2, step 3455/7134 completed (loss: 0.05486207455396652, acc: 0.9855072498321533)
[2024-12-17 01:57:04,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:04,803][root][INFO] - Training Epoch: 1/2, step 3456/7134 completed (loss: 0.05620361864566803, acc: 0.9882352948188782)
[2024-12-17 01:57:04,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:05,146][root][INFO] - Training Epoch: 1/2, step 3457/7134 completed (loss: 0.0773378238081932, acc: 0.9796609878540039)
[2024-12-17 01:57:05,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:05,501][root][INFO] - Training Epoch: 1/2, step 3458/7134 completed (loss: 0.1165119931101799, acc: 0.9783491492271423)
[2024-12-17 01:57:05,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:05,824][root][INFO] - Training Epoch: 1/2, step 3459/7134 completed (loss: 0.08363775163888931, acc: 0.9863013625144958)
[2024-12-17 01:57:05,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:06,104][root][INFO] - Training Epoch: 1/2, step 3460/7134 completed (loss: 0.3277681767940521, acc: 0.9294871687889099)
[2024-12-17 01:57:06,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:06,368][root][INFO] - Training Epoch: 1/2, step 3461/7134 completed (loss: 0.29085731506347656, acc: 0.9402298927307129)
[2024-12-17 01:57:06,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:06,688][root][INFO] - Training Epoch: 1/2, step 3462/7134 completed (loss: 0.157188281416893, acc: 0.9686028361320496)
[2024-12-17 01:57:06,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:07,052][root][INFO] - Training Epoch: 1/2, step 3463/7134 completed (loss: 0.06896420568227768, acc: 0.9849170446395874)
[2024-12-17 01:57:07,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:07,395][root][INFO] - Training Epoch: 1/2, step 3464/7134 completed (loss: 0.10779973119497299, acc: 0.9731903672218323)
[2024-12-17 01:57:07,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:07,707][root][INFO] - Training Epoch: 1/2, step 3465/7134 completed (loss: 0.1097203865647316, acc: 0.9735234379768372)
[2024-12-17 01:57:07,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:08,025][root][INFO] - Training Epoch: 1/2, step 3466/7134 completed (loss: 0.05242210254073143, acc: 0.9857369065284729)
[2024-12-17 01:57:08,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:08,351][root][INFO] - Training Epoch: 1/2, step 3467/7134 completed (loss: 0.09799475967884064, acc: 0.9808917045593262)
[2024-12-17 01:57:08,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:08,688][root][INFO] - Training Epoch: 1/2, step 3468/7134 completed (loss: 0.022346386685967445, acc: 0.9956584572792053)
[2024-12-17 01:57:08,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:09,015][root][INFO] - Training Epoch: 1/2, step 3469/7134 completed (loss: 0.0625501200556755, acc: 0.9849056601524353)
[2024-12-17 01:57:09,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:09,342][root][INFO] - Training Epoch: 1/2, step 3470/7134 completed (loss: 0.04853782057762146, acc: 0.9907833933830261)
[2024-12-17 01:57:09,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:09,661][root][INFO] - Training Epoch: 1/2, step 3471/7134 completed (loss: 0.1145428791642189, acc: 0.9861878156661987)
[2024-12-17 01:57:09,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:10,004][root][INFO] - Training Epoch: 1/2, step 3472/7134 completed (loss: 0.04100377857685089, acc: 0.9895678162574768)
[2024-12-17 01:57:10,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:10,388][root][INFO] - Training Epoch: 1/2, step 3473/7134 completed (loss: 0.06107711046934128, acc: 0.9867549538612366)
[2024-12-17 01:57:10,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:10,702][root][INFO] - Training Epoch: 1/2, step 3474/7134 completed (loss: 0.08233578503131866, acc: 0.9858657121658325)
[2024-12-17 01:57:10,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:11,032][root][INFO] - Training Epoch: 1/2, step 3475/7134 completed (loss: 0.0591653510928154, acc: 0.9857904314994812)
[2024-12-17 01:57:11,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:11,368][root][INFO] - Training Epoch: 1/2, step 3476/7134 completed (loss: 0.09505320340394974, acc: 0.9726027250289917)
[2024-12-17 01:57:11,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:11,690][root][INFO] - Training Epoch: 1/2, step 3477/7134 completed (loss: 0.07028911262750626, acc: 0.9851973652839661)
[2024-12-17 01:57:11,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:12,024][root][INFO] - Training Epoch: 1/2, step 3478/7134 completed (loss: 0.04487285390496254, acc: 0.992514967918396)
[2024-12-17 01:57:12,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:12,352][root][INFO] - Training Epoch: 1/2, step 3479/7134 completed (loss: 0.03145403042435646, acc: 0.9924356937408447)
[2024-12-17 01:57:12,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:12,704][root][INFO] - Training Epoch: 1/2, step 3480/7134 completed (loss: 0.08988384902477264, acc: 0.9795640110969543)
[2024-12-17 01:57:12,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:13,032][root][INFO] - Training Epoch: 1/2, step 3481/7134 completed (loss: 0.0592949241399765, acc: 0.9929078221321106)
[2024-12-17 01:57:13,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:13,363][root][INFO] - Training Epoch: 1/2, step 3482/7134 completed (loss: 0.044370777904987335, acc: 0.9892086386680603)
[2024-12-17 01:57:13,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:13,707][root][INFO] - Training Epoch: 1/2, step 3483/7134 completed (loss: 0.02012450248003006, acc: 0.9938367009162903)
[2024-12-17 01:57:13,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:14,027][root][INFO] - Training Epoch: 1/2, step 3484/7134 completed (loss: 0.0414276048541069, acc: 0.991150438785553)
[2024-12-17 01:57:14,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:14,343][root][INFO] - Training Epoch: 1/2, step 3485/7134 completed (loss: 0.05372488126158714, acc: 0.9855700135231018)
[2024-12-17 01:57:14,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:14,674][root][INFO] - Training Epoch: 1/2, step 3486/7134 completed (loss: 0.06431839615106583, acc: 0.9874100685119629)
[2024-12-17 01:57:14,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:15,009][root][INFO] - Training Epoch: 1/2, step 3487/7134 completed (loss: 0.11269333958625793, acc: 0.9720176458358765)
[2024-12-17 01:57:15,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:15,346][root][INFO] - Training Epoch: 1/2, step 3488/7134 completed (loss: 0.06971054524183273, acc: 0.9802631735801697)
[2024-12-17 01:57:15,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:15,655][root][INFO] - Training Epoch: 1/2, step 3489/7134 completed (loss: 0.11272483319044113, acc: 0.970534086227417)
[2024-12-17 01:57:15,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:16,019][root][INFO] - Training Epoch: 1/2, step 3490/7134 completed (loss: 0.09281127154827118, acc: 0.9793205261230469)
[2024-12-17 01:57:16,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:16,347][root][INFO] - Training Epoch: 1/2, step 3491/7134 completed (loss: 0.10196071118116379, acc: 0.9758865237236023)
[2024-12-17 01:57:16,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:16,631][root][INFO] - Training Epoch: 1/2, step 3492/7134 completed (loss: 0.10548369586467743, acc: 0.9835729002952576)
[2024-12-17 01:57:16,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:16,975][root][INFO] - Training Epoch: 1/2, step 3493/7134 completed (loss: 0.05940183624625206, acc: 0.981792688369751)
[2024-12-17 01:57:17,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:17,293][root][INFO] - Training Epoch: 1/2, step 3494/7134 completed (loss: 0.06309930980205536, acc: 0.9879310131072998)
[2024-12-17 01:57:17,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:17,611][root][INFO] - Training Epoch: 1/2, step 3495/7134 completed (loss: 0.06494747847318649, acc: 0.9832134246826172)
[2024-12-17 01:57:17,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:17,913][root][INFO] - Training Epoch: 1/2, step 3496/7134 completed (loss: 0.1031402125954628, acc: 0.9752252101898193)
[2024-12-17 01:57:18,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:18,232][root][INFO] - Training Epoch: 1/2, step 3497/7134 completed (loss: 0.09417425096035004, acc: 0.9732937812805176)
[2024-12-17 01:57:18,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:18,567][root][INFO] - Training Epoch: 1/2, step 3498/7134 completed (loss: 0.0811205804347992, acc: 0.9817073345184326)
[2024-12-17 01:57:18,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:18,895][root][INFO] - Training Epoch: 1/2, step 3499/7134 completed (loss: 0.05411283299326897, acc: 0.9854133129119873)
[2024-12-17 01:57:19,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:19,223][root][INFO] - Training Epoch: 1/2, step 3500/7134 completed (loss: 0.12714605033397675, acc: 0.9603524208068848)
[2024-12-17 01:57:19,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:19,553][root][INFO] - Training Epoch: 1/2, step 3501/7134 completed (loss: 0.14420650899410248, acc: 0.9557344317436218)
[2024-12-17 01:57:19,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:19,865][root][INFO] - Training Epoch: 1/2, step 3502/7134 completed (loss: 0.1627276986837387, acc: 0.9649122953414917)
[2024-12-17 01:57:19,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:20,206][root][INFO] - Training Epoch: 1/2, step 3503/7134 completed (loss: 0.1422438770532608, acc: 0.9688041806221008)
[2024-12-17 01:57:20,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:20,543][root][INFO] - Training Epoch: 1/2, step 3504/7134 completed (loss: 0.04110534116625786, acc: 0.9924585223197937)
[2024-12-17 01:57:20,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:20,875][root][INFO] - Training Epoch: 1/2, step 3505/7134 completed (loss: 0.07129557430744171, acc: 0.9821109175682068)
[2024-12-17 01:57:20,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:21,168][root][INFO] - Training Epoch: 1/2, step 3506/7134 completed (loss: 0.09258397668600082, acc: 0.9754253029823303)
[2024-12-17 01:57:21,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:21,507][root][INFO] - Training Epoch: 1/2, step 3507/7134 completed (loss: 0.040054801851511, acc: 0.9867549538612366)
[2024-12-17 01:57:21,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:21,839][root][INFO] - Training Epoch: 1/2, step 3508/7134 completed (loss: 0.06527382880449295, acc: 0.9839181303977966)
[2024-12-17 01:57:21,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:22,181][root][INFO] - Training Epoch: 1/2, step 3509/7134 completed (loss: 0.06665895879268646, acc: 0.9792817831039429)
[2024-12-17 01:57:22,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:22,497][root][INFO] - Training Epoch: 1/2, step 3510/7134 completed (loss: 0.09944019466638565, acc: 0.9708404541015625)
[2024-12-17 01:57:22,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:22,837][root][INFO] - Training Epoch: 1/2, step 3511/7134 completed (loss: 0.0262546855956316, acc: 0.9927927851676941)
[2024-12-17 01:57:22,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:23,162][root][INFO] - Training Epoch: 1/2, step 3512/7134 completed (loss: 0.06450209021568298, acc: 0.9793977737426758)
[2024-12-17 01:57:23,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:23,495][root][INFO] - Training Epoch: 1/2, step 3513/7134 completed (loss: 0.0779443234205246, acc: 0.9858406782150269)
[2024-12-17 01:57:23,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:23,850][root][INFO] - Training Epoch: 1/2, step 3514/7134 completed (loss: 0.07233204692602158, acc: 0.97926265001297)
[2024-12-17 01:57:23,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:24,176][root][INFO] - Training Epoch: 1/2, step 3515/7134 completed (loss: 0.03650183230638504, acc: 0.9902234673500061)
[2024-12-17 01:57:24,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:24,546][root][INFO] - Training Epoch: 1/2, step 3516/7134 completed (loss: 0.041637782007455826, acc: 0.9880823493003845)
[2024-12-17 01:57:24,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:24,900][root][INFO] - Training Epoch: 1/2, step 3517/7134 completed (loss: 0.04914846271276474, acc: 0.9833134412765503)
[2024-12-17 01:57:25,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:25,251][root][INFO] - Training Epoch: 1/2, step 3518/7134 completed (loss: 0.047805123031139374, acc: 0.9870610237121582)
[2024-12-17 01:57:25,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:25,606][root][INFO] - Training Epoch: 1/2, step 3519/7134 completed (loss: 0.06916457414627075, acc: 0.983146071434021)
[2024-12-17 01:57:25,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:25,968][root][INFO] - Training Epoch: 1/2, step 3520/7134 completed (loss: 0.11891967803239822, acc: 0.977647066116333)
[2024-12-17 01:57:26,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:26,321][root][INFO] - Training Epoch: 1/2, step 3521/7134 completed (loss: 0.05832749232649803, acc: 0.9857752323150635)
[2024-12-17 01:57:26,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:26,627][root][INFO] - Training Epoch: 1/2, step 3522/7134 completed (loss: 0.06985557824373245, acc: 0.98128342628479)
[2024-12-17 01:57:26,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:26,980][root][INFO] - Training Epoch: 1/2, step 3523/7134 completed (loss: 0.042029477655887604, acc: 0.9876733422279358)
[2024-12-17 01:57:27,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:27,331][root][INFO] - Training Epoch: 1/2, step 3524/7134 completed (loss: 0.0809665396809578, acc: 0.9778645634651184)
[2024-12-17 01:57:27,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:27,678][root][INFO] - Training Epoch: 1/2, step 3525/7134 completed (loss: 0.04940246790647507, acc: 0.9868203997612)
[2024-12-17 01:57:27,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:28,026][root][INFO] - Training Epoch: 1/2, step 3526/7134 completed (loss: 0.10292739421129227, acc: 0.9746514558792114)
[2024-12-17 01:57:28,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:28,392][root][INFO] - Training Epoch: 1/2, step 3527/7134 completed (loss: 0.08520181477069855, acc: 0.97567218542099)
[2024-12-17 01:57:28,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:28,744][root][INFO] - Training Epoch: 1/2, step 3528/7134 completed (loss: 0.06494057923555374, acc: 0.9826989769935608)
[2024-12-17 01:57:28,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:29,085][root][INFO] - Training Epoch: 1/2, step 3529/7134 completed (loss: 0.07110892236232758, acc: 0.981176495552063)
[2024-12-17 01:57:29,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:29,462][root][INFO] - Training Epoch: 1/2, step 3530/7134 completed (loss: 0.08149142563343048, acc: 0.98050457239151)
[2024-12-17 01:57:29,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:29,810][root][INFO] - Training Epoch: 1/2, step 3531/7134 completed (loss: 0.05968644842505455, acc: 0.9894578456878662)
[2024-12-17 01:57:29,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:30,162][root][INFO] - Training Epoch: 1/2, step 3532/7134 completed (loss: 0.045749977231025696, acc: 0.9865319728851318)
[2024-12-17 01:57:30,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:30,510][root][INFO] - Training Epoch: 1/2, step 3533/7134 completed (loss: 0.07750701904296875, acc: 0.9802095293998718)
[2024-12-17 01:57:30,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:30,848][root][INFO] - Training Epoch: 1/2, step 3534/7134 completed (loss: 0.07084918767213821, acc: 0.9805285334587097)
[2024-12-17 01:57:30,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:31,186][root][INFO] - Training Epoch: 1/2, step 3535/7134 completed (loss: 0.061223674565553665, acc: 0.9846389889717102)
[2024-12-17 01:57:31,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:31,527][root][INFO] - Training Epoch: 1/2, step 3536/7134 completed (loss: 0.08134392648935318, acc: 0.9781420826911926)
[2024-12-17 01:57:31,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:31,841][root][INFO] - Training Epoch: 1/2, step 3537/7134 completed (loss: 0.05928822234272957, acc: 0.9815436005592346)
[2024-12-17 01:57:31,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:32,163][root][INFO] - Training Epoch: 1/2, step 3538/7134 completed (loss: 0.08997662365436554, acc: 0.982889711856842)
[2024-12-17 01:57:32,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:32,436][root][INFO] - Training Epoch: 1/2, step 3539/7134 completed (loss: 0.04922586306929588, acc: 0.9854369163513184)
[2024-12-17 01:57:32,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:32,759][root][INFO] - Training Epoch: 1/2, step 3540/7134 completed (loss: 0.08998482674360275, acc: 0.9757207632064819)
[2024-12-17 01:57:32,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:33,098][root][INFO] - Training Epoch: 1/2, step 3541/7134 completed (loss: 0.08440612256526947, acc: 0.9720998406410217)
[2024-12-17 01:57:33,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:33,425][root][INFO] - Training Epoch: 1/2, step 3542/7134 completed (loss: 0.06569194048643112, acc: 0.9846153855323792)
[2024-12-17 01:57:33,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:33,735][root][INFO] - Training Epoch: 1/2, step 3543/7134 completed (loss: 0.10002534836530685, acc: 0.9735915660858154)
[2024-12-17 01:57:33,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:34,087][root][INFO] - Training Epoch: 1/2, step 3544/7134 completed (loss: 0.10286755859851837, acc: 0.9692307710647583)
[2024-12-17 01:57:34,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:34,446][root][INFO] - Training Epoch: 1/2, step 3545/7134 completed (loss: 0.04661659151315689, acc: 0.9829192757606506)
[2024-12-17 01:57:34,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:34,780][root][INFO] - Training Epoch: 1/2, step 3546/7134 completed (loss: 0.06705909222364426, acc: 0.9818481802940369)
[2024-12-17 01:57:34,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:35,138][root][INFO] - Training Epoch: 1/2, step 3547/7134 completed (loss: 0.11441489309072495, acc: 0.9692307710647583)
[2024-12-17 01:57:35,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:35,473][root][INFO] - Training Epoch: 1/2, step 3548/7134 completed (loss: 0.09230415523052216, acc: 0.9734513163566589)
[2024-12-17 01:57:35,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:35,797][root][INFO] - Training Epoch: 1/2, step 3549/7134 completed (loss: 0.08934877067804337, acc: 0.9700176119804382)
[2024-12-17 01:57:35,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:36,119][root][INFO] - Training Epoch: 1/2, step 3550/7134 completed (loss: 0.07084612548351288, acc: 0.9772329330444336)
[2024-12-17 01:57:36,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:36,444][root][INFO] - Training Epoch: 1/2, step 3551/7134 completed (loss: 0.07748527079820633, acc: 0.9831649661064148)
[2024-12-17 01:57:36,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:36,790][root][INFO] - Training Epoch: 1/2, step 3552/7134 completed (loss: 0.22884534299373627, acc: 0.9456928968429565)
[2024-12-17 01:57:36,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:37,113][root][INFO] - Training Epoch: 1/2, step 3553/7134 completed (loss: 0.09918827563524246, acc: 0.9769737124443054)
[2024-12-17 01:57:37,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:37,440][root][INFO] - Training Epoch: 1/2, step 3554/7134 completed (loss: 0.0811094418168068, acc: 0.9819276928901672)
[2024-12-17 01:57:37,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:37,758][root][INFO] - Training Epoch: 1/2, step 3555/7134 completed (loss: 0.07482446730136871, acc: 0.9748822450637817)
[2024-12-17 01:57:37,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:38,070][root][INFO] - Training Epoch: 1/2, step 3556/7134 completed (loss: 0.09458072483539581, acc: 0.9750480055809021)
[2024-12-17 01:57:38,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:38,423][root][INFO] - Training Epoch: 1/2, step 3557/7134 completed (loss: 0.0763823464512825, acc: 0.9836660623550415)
[2024-12-17 01:57:38,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:38,748][root][INFO] - Training Epoch: 1/2, step 3558/7134 completed (loss: 0.11431436985731125, acc: 0.9731958508491516)
[2024-12-17 01:57:38,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:39,085][root][INFO] - Training Epoch: 1/2, step 3559/7134 completed (loss: 0.05008348077535629, acc: 0.9869186282157898)
[2024-12-17 01:57:39,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:39,408][root][INFO] - Training Epoch: 1/2, step 3560/7134 completed (loss: 0.04735483601689339, acc: 0.9876712560653687)
[2024-12-17 01:57:39,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:39,749][root][INFO] - Training Epoch: 1/2, step 3561/7134 completed (loss: 0.06331782042980194, acc: 0.9789915680885315)
[2024-12-17 01:57:39,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:40,068][root][INFO] - Training Epoch: 1/2, step 3562/7134 completed (loss: 0.0771988108754158, acc: 0.9732142686843872)
[2024-12-17 01:57:40,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:40,393][root][INFO] - Training Epoch: 1/2, step 3563/7134 completed (loss: 0.06750830262899399, acc: 0.9841017723083496)
[2024-12-17 01:57:40,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:40,743][root][INFO] - Training Epoch: 1/2, step 3564/7134 completed (loss: 0.13163024187088013, acc: 0.9793233275413513)
[2024-12-17 01:57:40,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:41,071][root][INFO] - Training Epoch: 1/2, step 3565/7134 completed (loss: 0.14971303939819336, acc: 0.9605262875556946)
[2024-12-17 01:57:41,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:42,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:42,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:42,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:42,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:43,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:43,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:43,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:44,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:44,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:44,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:45,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:45,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:45,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:45,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:46,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:46,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:46,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:47,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:47,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:47,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:47,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:48,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:48,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:48,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:48,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:49,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:49,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:49,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:50,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:50,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:50,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:51,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:51,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:51,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:52,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:52,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:52,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:52,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:52,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:53,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:53,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:53,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:53,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:54,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:54,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:54,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:55,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:55,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:55,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:56,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:56,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:56,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:56,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:57,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:57,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:57,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:58,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:58,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:58,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:58,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:59,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:59,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:59,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:59,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:00,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:00,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:00,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:00,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:01,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:01,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:01,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:01,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:02,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:02,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:02,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:03,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:03,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:03,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:04,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:04,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:04,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:04,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:05,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:05,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:05,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:05,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:06,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:06,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:06,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:07,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:07,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:07,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:07,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:08,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:08,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:08,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:09,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:09,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:09,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:10,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:10,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:10,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:10,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:11,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:11,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:11,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:11,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:12,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:12,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:12,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:12,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:13,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:13,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:13,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:14,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:14,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:14,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:14,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:14,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:15,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:15,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:15,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:16,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:16,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:16,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:16,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:17,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:17,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:17,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:18,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:18,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:18,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:18,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:19,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:19,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:19,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:20,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:20,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:20,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:21,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:21,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:21,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:22,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:22,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:22,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:22,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:23,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:23,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:23,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:23,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:24,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:24,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:24,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:24,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:25,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:25,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:25,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:26,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:26,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:26,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:26,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:27,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:27,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:27,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:27,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:28,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:28,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:28,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:29,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:29,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:29,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:29,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:30,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:30,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:30,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:30,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:31,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:31,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:31,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:32,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:32,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:32,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:32,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:33,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:33,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:33,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:34,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:34,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:34,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:34,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:35,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:35,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:35,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:36,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:36,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:36,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:36,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:36,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:37,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:37,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:37,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:37,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:38,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:38,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:38,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:38,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:39,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:39,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:39,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:40,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:40,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:40,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:40,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:41,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:41,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:41,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:42,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:42,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:42,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:42,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:43,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:43,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:43,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:43,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:44,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:44,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:44,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:44,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:45,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:45,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:45,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:46,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:46,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:46,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:46,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:46,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:47,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:47,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:47,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:48,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:48,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:48,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:48,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:49,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:49,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:49,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:50,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:50,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:51,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:51,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:51,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:51,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:52,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:52,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:52,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:52,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:53,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:53,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:53,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:54,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:54,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:54,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:54,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:55,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:55,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:55,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:55,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:56,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:56,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:56,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:56,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:57,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:57,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:58,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:58,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:58,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:58,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:59,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:59,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:59,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:59,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:00,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:00,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:01,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:01,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:01,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:02,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:02,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:02,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:02,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:03,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:03,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:03,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:04,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:04,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:05,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:05,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:05,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:05,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:06,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:06,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:06,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:06,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:07,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:07,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:07,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:07,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:08,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:08,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:08,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:09,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:09,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:09,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:09,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:10,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:10,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:10,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:10,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:11,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:11,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:11,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:12,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:12,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:12,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:12,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:13,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:13,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:13,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:14,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:14,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:14,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:15,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:15,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:15,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:16,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:16,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:16,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:16,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:17,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:17,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:17,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:18,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:18,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:19,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:19,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:19,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:20,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:20,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:20,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:21,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:21,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:21,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:21,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:22,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:22,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:22,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:23,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:23,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:23,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:24,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:24,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:25,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:25,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:26,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:26,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:26,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:27,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:27,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:27,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:28,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:28,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:28,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:28,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:29,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:29,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:29,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:29,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:30,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:30,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:30,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:30,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:31,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:31,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:31,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:31,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:32,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:32,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:32,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:33,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:33,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:33,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:33,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:34,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:34,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:34,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:35,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:35,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:35,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:35,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:36,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:36,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:36,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:36,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:37,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:37,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:37,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:38,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:38,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:38,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:38,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:39,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:39,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:39,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:39,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:40,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:40,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:40,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:40,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:41,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:41,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:41,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:42,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:42,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:42,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:43,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:43,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:43,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:43,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:44,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:44,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:44,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:44,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:45,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:45,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:45,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:45,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:46,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:46,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:46,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:46,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:47,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:47,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:47,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:48,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:48,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:48,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:49,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:49,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:49,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:49,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:49,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:50,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:50,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:50,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:51,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:51,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:51,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:51,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:52,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:52,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:52,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:53,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:53,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:53,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:54,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:54,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:54,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:54,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:55,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:55,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:55,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:55,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:56,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:56,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:56,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:56,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:57,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:57,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:57,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:57,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:58,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:58,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:58,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:59,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:59,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:59,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:00,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:00,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:00,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:01,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:01,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:01,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:01,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:02,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:02,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:02,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:03,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:03,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:03,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:03,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:04,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:04,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:04,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:05,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:05,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:05,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:06,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:06,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:06,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:06,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:07,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:07,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:07,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:07,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:07,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:08,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:08,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:08,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:08,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:09,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:09,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:09,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:10,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:10,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:10,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:10,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:11,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:11,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:11,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:12,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:12,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:12,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:12,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:13,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:13,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:13,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:14,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:14,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:14,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:14,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:15,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:15,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:15,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:15,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:16,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:16,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:16,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:16,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:17,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:17,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:17,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:17,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:18,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:18,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:18,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:19,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:19,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:19,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:19,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:20,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:20,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:20,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:20,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:21,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:21,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:21,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:21,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:22,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:22,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:22,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:23,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:23,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:23,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:24,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:24,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:24,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:25,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:25,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:25,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:26,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:26,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:26,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:27,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:27,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:27,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:28,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:28,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:28,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:29,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:29,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:29,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:29,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:30,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:30,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:30,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:31,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:31,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:31,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:31,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:31,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:32,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:32,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:32,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:33,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:33,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:33,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:33,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:34,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:34,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:34,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:34,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:35,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:35,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:35,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:36,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:36,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:36,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:36,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:37,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:37,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:37,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:37,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:38,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:38,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:38,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:39,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:40,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:40,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:40,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:41,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:41,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:41,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:42,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:42,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:42,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:43,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:43,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:44,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:44,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:44,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:44,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:45,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:45,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:45,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:45,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:46,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:46,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:46,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:47,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:47,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:47,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:47,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:48,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:48,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:48,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:48,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:49,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:49,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:49,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:49,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:50,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:50,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:50,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:51,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:51,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:51,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:52,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:52,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:52,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:52,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:53,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:53,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:53,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:54,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:54,866][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.1145, device='cuda:0') eval_epoch_loss=tensor(0.1084, device='cuda:0') eval_epoch_acc=tensor(0.9731, device='cuda:0')
[2024-12-17 02:00:54,868][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-12-17 02:00:54,868][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 02:00:55,100][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_1_step_3566_loss_0.10844611376523972/model.pt
[2024-12-17 02:00:55,104][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 0.10844611376523972
[2024-12-17 02:00:55,104][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.9730581045150757
[2024-12-17 02:00:55,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:55,443][root][INFO] - Training Epoch: 1/2, step 3566/7134 completed (loss: 0.1366419792175293, acc: 0.9701195359230042)
[2024-12-17 02:00:55,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:55,768][root][INFO] - Training Epoch: 1/2, step 3567/7134 completed (loss: 0.15879397094249725, acc: 0.9728330969810486)
[2024-12-17 02:00:55,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:56,097][root][INFO] - Training Epoch: 1/2, step 3568/7134 completed (loss: 0.14087188243865967, acc: 0.972176730632782)
[2024-12-17 02:00:56,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:56,411][root][INFO] - Training Epoch: 1/2, step 3569/7134 completed (loss: 0.10113786906003952, acc: 0.9677419066429138)
[2024-12-17 02:00:56,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:56,759][root][INFO] - Training Epoch: 1/2, step 3570/7134 completed (loss: 0.14970596134662628, acc: 0.9652892351150513)
[2024-12-17 02:00:56,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:57,094][root][INFO] - Training Epoch: 1/2, step 3571/7134 completed (loss: 0.1341390460729599, acc: 0.9774535894393921)
[2024-12-17 02:00:57,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:57,451][root][INFO] - Training Epoch: 1/2, step 3572/7134 completed (loss: 0.07129310071468353, acc: 0.9802371263504028)
[2024-12-17 02:00:57,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:57,797][root][INFO] - Training Epoch: 1/2, step 3573/7134 completed (loss: 0.10100413858890533, acc: 0.970370352268219)
[2024-12-17 02:00:57,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:58,118][root][INFO] - Training Epoch: 1/2, step 3574/7134 completed (loss: 0.1937190741300583, acc: 0.9521072506904602)
[2024-12-17 02:00:58,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:58,446][root][INFO] - Training Epoch: 1/2, step 3575/7134 completed (loss: 0.18719547986984253, acc: 0.9468267560005188)
[2024-12-17 02:00:58,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:58,766][root][INFO] - Training Epoch: 1/2, step 3576/7134 completed (loss: 0.14564231038093567, acc: 0.9521178603172302)
[2024-12-17 02:00:58,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:59,152][root][INFO] - Training Epoch: 1/2, step 3577/7134 completed (loss: 0.09687372297048569, acc: 0.9797724485397339)
[2024-12-17 02:00:59,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:59,504][root][INFO] - Training Epoch: 1/2, step 3578/7134 completed (loss: 0.07218382507562637, acc: 0.9825327396392822)
[2024-12-17 02:00:59,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:59,848][root][INFO] - Training Epoch: 1/2, step 3579/7134 completed (loss: 0.11194424331188202, acc: 0.9786666631698608)
[2024-12-17 02:00:59,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:00,179][root][INFO] - Training Epoch: 1/2, step 3580/7134 completed (loss: 0.13922469317913055, acc: 0.9669291377067566)
[2024-12-17 02:01:00,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:00,519][root][INFO] - Training Epoch: 1/2, step 3581/7134 completed (loss: 0.14205405116081238, acc: 0.9631811380386353)
[2024-12-17 02:01:00,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:00,859][root][INFO] - Training Epoch: 1/2, step 3582/7134 completed (loss: 0.10559301823377609, acc: 0.978672981262207)
[2024-12-17 02:01:00,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:01,217][root][INFO] - Training Epoch: 1/2, step 3583/7134 completed (loss: 0.10074536502361298, acc: 0.9726443886756897)
[2024-12-17 02:01:01,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:01,553][root][INFO] - Training Epoch: 1/2, step 3584/7134 completed (loss: 0.10103939473628998, acc: 0.976190447807312)
[2024-12-17 02:01:01,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:01,893][root][INFO] - Training Epoch: 1/2, step 3585/7134 completed (loss: 0.15459388494491577, acc: 0.9600694179534912)
[2024-12-17 02:01:02,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:02,216][root][INFO] - Training Epoch: 1/2, step 3586/7134 completed (loss: 0.1437913030385971, acc: 0.9646869897842407)
[2024-12-17 02:01:02,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:02,548][root][INFO] - Training Epoch: 1/2, step 3587/7134 completed (loss: 0.08718694001436234, acc: 0.9796954393386841)
[2024-12-17 02:01:02,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:02,912][root][INFO] - Training Epoch: 1/2, step 3588/7134 completed (loss: 0.14921815693378448, acc: 0.9630177617073059)
[2024-12-17 02:01:03,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:03,258][root][INFO] - Training Epoch: 1/2, step 3589/7134 completed (loss: 0.1668020486831665, acc: 0.9591528177261353)
[2024-12-17 02:01:03,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:03,611][root][INFO] - Training Epoch: 1/2, step 3590/7134 completed (loss: 0.06693114340305328, acc: 0.9803370833396912)
[2024-12-17 02:01:03,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:03,924][root][INFO] - Training Epoch: 1/2, step 3591/7134 completed (loss: 0.09098271280527115, acc: 0.9744744896888733)
[2024-12-17 02:01:04,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:04,251][root][INFO] - Training Epoch: 1/2, step 3592/7134 completed (loss: 0.042990729212760925, acc: 0.9834710955619812)
[2024-12-17 02:01:04,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:04,600][root][INFO] - Training Epoch: 1/2, step 3593/7134 completed (loss: 0.1437205821275711, acc: 0.9579684734344482)
[2024-12-17 02:01:04,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:04,928][root][INFO] - Training Epoch: 1/2, step 3594/7134 completed (loss: 0.06380466371774673, acc: 0.9821428656578064)
[2024-12-17 02:01:05,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:05,269][root][INFO] - Training Epoch: 1/2, step 3595/7134 completed (loss: 0.09548292309045792, acc: 0.9709035158157349)
[2024-12-17 02:01:05,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:05,602][root][INFO] - Training Epoch: 1/2, step 3596/7134 completed (loss: 0.07208003848791122, acc: 0.9848693013191223)
[2024-12-17 02:01:05,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:05,959][root][INFO] - Training Epoch: 1/2, step 3597/7134 completed (loss: 0.09430785477161407, acc: 0.9784172773361206)
[2024-12-17 02:01:06,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:06,351][root][INFO] - Training Epoch: 1/2, step 3598/7134 completed (loss: 0.12895220518112183, acc: 0.970251739025116)
[2024-12-17 02:01:06,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:06,705][root][INFO] - Training Epoch: 1/2, step 3599/7134 completed (loss: 0.15744875371456146, acc: 0.9659520983695984)
[2024-12-17 02:01:06,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:07,068][root][INFO] - Training Epoch: 1/2, step 3600/7134 completed (loss: 0.10194218158721924, acc: 0.9685746431350708)
[2024-12-17 02:01:07,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:07,422][root][INFO] - Training Epoch: 1/2, step 3601/7134 completed (loss: 0.20511986315250397, acc: 0.9489654898643494)
[2024-12-17 02:01:07,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:07,784][root][INFO] - Training Epoch: 1/2, step 3602/7134 completed (loss: 0.19356785714626312, acc: 0.9533255696296692)
[2024-12-17 02:01:07,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:08,108][root][INFO] - Training Epoch: 1/2, step 3603/7134 completed (loss: 0.09520171582698822, acc: 0.9781249761581421)
[2024-12-17 02:01:08,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:08,430][root][INFO] - Training Epoch: 1/2, step 3604/7134 completed (loss: 0.08642082661390305, acc: 0.9774859547615051)
[2024-12-17 02:01:08,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:08,803][root][INFO] - Training Epoch: 1/2, step 3605/7134 completed (loss: 0.12248308211565018, acc: 0.9699792861938477)
[2024-12-17 02:01:08,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:09,157][root][INFO] - Training Epoch: 1/2, step 3606/7134 completed (loss: 0.1271093189716339, acc: 0.9680284261703491)
[2024-12-17 02:01:09,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:09,502][root][INFO] - Training Epoch: 1/2, step 3607/7134 completed (loss: 0.07021418958902359, acc: 0.9815436005592346)
[2024-12-17 02:01:09,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:09,862][root][INFO] - Training Epoch: 1/2, step 3608/7134 completed (loss: 0.18372078239917755, acc: 0.9579645991325378)
[2024-12-17 02:01:09,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:10,229][root][INFO] - Training Epoch: 1/2, step 3609/7134 completed (loss: 0.1254340261220932, acc: 0.970812201499939)
[2024-12-17 02:01:10,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:10,588][root][INFO] - Training Epoch: 1/2, step 3610/7134 completed (loss: 0.18274761736392975, acc: 0.9532467722892761)
[2024-12-17 02:01:10,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:10,951][root][INFO] - Training Epoch: 1/2, step 3611/7134 completed (loss: 0.14340214431285858, acc: 0.9610214829444885)
[2024-12-17 02:01:11,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:11,323][root][INFO] - Training Epoch: 1/2, step 3612/7134 completed (loss: 0.18169787526130676, acc: 0.9502074718475342)
[2024-12-17 02:01:11,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:11,688][root][INFO] - Training Epoch: 1/2, step 3613/7134 completed (loss: 0.13361629843711853, acc: 0.9605597853660583)
[2024-12-17 02:01:11,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:12,021][root][INFO] - Training Epoch: 1/2, step 3614/7134 completed (loss: 0.12358401715755463, acc: 0.9651941061019897)
[2024-12-17 02:01:12,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:12,368][root][INFO] - Training Epoch: 1/2, step 3615/7134 completed (loss: 0.06729786098003387, acc: 0.9801223278045654)
[2024-12-17 02:01:12,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:12,704][root][INFO] - Training Epoch: 1/2, step 3616/7134 completed (loss: 0.08187614381313324, acc: 0.976452112197876)
[2024-12-17 02:01:12,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:13,068][root][INFO] - Training Epoch: 1/2, step 3617/7134 completed (loss: 0.09766501188278198, acc: 0.9702970385551453)
[2024-12-17 02:01:13,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:13,399][root][INFO] - Training Epoch: 1/2, step 3618/7134 completed (loss: 0.20031028985977173, acc: 0.9477124214172363)
[2024-12-17 02:01:13,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:13,755][root][INFO] - Training Epoch: 1/2, step 3619/7134 completed (loss: 0.17506800591945648, acc: 0.9583333134651184)
[2024-12-17 02:01:13,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:14,125][root][INFO] - Training Epoch: 1/2, step 3620/7134 completed (loss: 0.12864863872528076, acc: 0.9676511883735657)
[2024-12-17 02:01:14,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:14,455][root][INFO] - Training Epoch: 1/2, step 3621/7134 completed (loss: 0.08277618139982224, acc: 0.9736477136611938)
[2024-12-17 02:01:14,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:14,814][root][INFO] - Training Epoch: 1/2, step 3622/7134 completed (loss: 0.0837021991610527, acc: 0.9729729890823364)
[2024-12-17 02:01:14,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:15,092][root][INFO] - Training Epoch: 1/2, step 3623/7134 completed (loss: 0.04642559587955475, acc: 0.9925650358200073)
[2024-12-17 02:01:15,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:15,431][root][INFO] - Training Epoch: 1/2, step 3624/7134 completed (loss: 0.11438927054405212, acc: 0.9633333086967468)
[2024-12-17 02:01:15,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:15,725][root][INFO] - Training Epoch: 1/2, step 3625/7134 completed (loss: 0.12895016372203827, acc: 0.9577465057373047)
[2024-12-17 02:01:15,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:16,051][root][INFO] - Training Epoch: 1/2, step 3626/7134 completed (loss: 0.2624889016151428, acc: 0.9386666417121887)
[2024-12-17 02:01:16,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:16,380][root][INFO] - Training Epoch: 1/2, step 3627/7134 completed (loss: 0.1532263457775116, acc: 0.9669030904769897)
[2024-12-17 02:01:16,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:16,682][root][INFO] - Training Epoch: 1/2, step 3628/7134 completed (loss: 0.2505648732185364, acc: 0.9431818127632141)
[2024-12-17 02:01:16,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:16,965][root][INFO] - Training Epoch: 1/2, step 3629/7134 completed (loss: 0.20856860280036926, acc: 0.9552845358848572)
[2024-12-17 02:01:17,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:17,239][root][INFO] - Training Epoch: 1/2, step 3630/7134 completed (loss: 0.1709582656621933, acc: 0.9638242721557617)
[2024-12-17 02:01:17,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:17,577][root][INFO] - Training Epoch: 1/2, step 3631/7134 completed (loss: 0.2354118525981903, acc: 0.94590163230896)
[2024-12-17 02:01:17,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:17,914][root][INFO] - Training Epoch: 1/2, step 3632/7134 completed (loss: 0.14353449642658234, acc: 0.9597585797309875)
[2024-12-17 02:01:18,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:18,237][root][INFO] - Training Epoch: 1/2, step 3633/7134 completed (loss: 0.14297963678836823, acc: 0.9684361815452576)
[2024-12-17 02:01:18,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:18,556][root][INFO] - Training Epoch: 1/2, step 3634/7134 completed (loss: 0.19003751873970032, acc: 0.9574899077415466)
[2024-12-17 02:01:18,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:18,882][root][INFO] - Training Epoch: 1/2, step 3635/7134 completed (loss: 0.09427375346422195, acc: 0.9767025113105774)
[2024-12-17 02:01:19,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:19,231][root][INFO] - Training Epoch: 1/2, step 3636/7134 completed (loss: 0.09431249648332596, acc: 0.9822834730148315)
[2024-12-17 02:01:19,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:19,571][root][INFO] - Training Epoch: 1/2, step 3637/7134 completed (loss: 0.10359469056129456, acc: 0.9818913340568542)
[2024-12-17 02:01:19,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:19,895][root][INFO] - Training Epoch: 1/2, step 3638/7134 completed (loss: 0.08280196785926819, acc: 0.9764705896377563)
[2024-12-17 02:01:20,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:20,223][root][INFO] - Training Epoch: 1/2, step 3639/7134 completed (loss: 0.08155690133571625, acc: 0.9797297120094299)
[2024-12-17 02:01:20,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:20,562][root][INFO] - Training Epoch: 1/2, step 3640/7134 completed (loss: 0.0905778780579567, acc: 0.9790076613426208)
[2024-12-17 02:01:20,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:20,838][root][INFO] - Training Epoch: 1/2, step 3641/7134 completed (loss: 0.07691840082406998, acc: 0.9844357967376709)
[2024-12-17 02:01:20,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:21,173][root][INFO] - Training Epoch: 1/2, step 3642/7134 completed (loss: 0.075293630361557, acc: 0.973724901676178)
[2024-12-17 02:01:21,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:21,503][root][INFO] - Training Epoch: 1/2, step 3643/7134 completed (loss: 0.07534193247556686, acc: 0.9845361113548279)
[2024-12-17 02:01:21,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:21,830][root][INFO] - Training Epoch: 1/2, step 3644/7134 completed (loss: 0.09774858504533768, acc: 0.9739837646484375)
[2024-12-17 02:01:21,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:22,165][root][INFO] - Training Epoch: 1/2, step 3645/7134 completed (loss: 0.1383347511291504, acc: 0.9718309640884399)
[2024-12-17 02:01:22,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:22,494][root][INFO] - Training Epoch: 1/2, step 3646/7134 completed (loss: 0.2064143419265747, acc: 0.9461805820465088)
[2024-12-17 02:01:22,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:22,816][root][INFO] - Training Epoch: 1/2, step 3647/7134 completed (loss: 0.04151169955730438, acc: 0.9870800971984863)
[2024-12-17 02:01:22,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:23,182][root][INFO] - Training Epoch: 1/2, step 3648/7134 completed (loss: 0.12811654806137085, acc: 0.9698216915130615)
[2024-12-17 02:01:23,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:23,525][root][INFO] - Training Epoch: 1/2, step 3649/7134 completed (loss: 0.13765665888786316, acc: 0.9691876769065857)
[2024-12-17 02:01:23,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:23,877][root][INFO] - Training Epoch: 1/2, step 3650/7134 completed (loss: 0.1544623225927353, acc: 0.9555555582046509)
[2024-12-17 02:01:23,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:24,229][root][INFO] - Training Epoch: 1/2, step 3651/7134 completed (loss: 0.1115885078907013, acc: 0.974530816078186)
[2024-12-17 02:01:24,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:24,565][root][INFO] - Training Epoch: 1/2, step 3652/7134 completed (loss: 0.1088675931096077, acc: 0.9728506803512573)
[2024-12-17 02:01:24,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:24,921][root][INFO] - Training Epoch: 1/2, step 3653/7134 completed (loss: 0.15094248950481415, acc: 0.965309202671051)
[2024-12-17 02:01:25,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:25,256][root][INFO] - Training Epoch: 1/2, step 3654/7134 completed (loss: 0.07503972202539444, acc: 0.9792746305465698)
[2024-12-17 02:01:25,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:25,607][root][INFO] - Training Epoch: 1/2, step 3655/7134 completed (loss: 0.1259245127439499, acc: 0.9725274443626404)
[2024-12-17 02:01:25,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:25,909][root][INFO] - Training Epoch: 1/2, step 3656/7134 completed (loss: 0.17293116450309753, acc: 0.9599999785423279)
[2024-12-17 02:01:26,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:26,261][root][INFO] - Training Epoch: 1/2, step 3657/7134 completed (loss: 0.036196932196617126, acc: 0.9919871687889099)
[2024-12-17 02:01:26,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:26,609][root][INFO] - Training Epoch: 1/2, step 3658/7134 completed (loss: 0.08549503237009048, acc: 0.9688473343849182)
[2024-12-17 02:01:26,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:26,946][root][INFO] - Training Epoch: 1/2, step 3659/7134 completed (loss: 0.07346267253160477, acc: 0.9790732264518738)
[2024-12-17 02:01:27,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:27,213][root][INFO] - Training Epoch: 1/2, step 3660/7134 completed (loss: 0.0913311019539833, acc: 0.9737704992294312)
[2024-12-17 02:01:27,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:27,486][root][INFO] - Training Epoch: 1/2, step 3661/7134 completed (loss: 0.10470632463693619, acc: 0.9678571224212646)
[2024-12-17 02:01:27,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:27,854][root][INFO] - Training Epoch: 1/2, step 3662/7134 completed (loss: 0.12515896558761597, acc: 0.9649389982223511)
[2024-12-17 02:01:28,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:28,209][root][INFO] - Training Epoch: 1/2, step 3663/7134 completed (loss: 0.11533017456531525, acc: 0.9633699655532837)
[2024-12-17 02:01:28,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:28,551][root][INFO] - Training Epoch: 1/2, step 3664/7134 completed (loss: 0.10968559235334396, acc: 0.975683867931366)
[2024-12-17 02:01:28,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:28,895][root][INFO] - Training Epoch: 1/2, step 3665/7134 completed (loss: 0.05762410908937454, acc: 0.9868637323379517)
[2024-12-17 02:01:29,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:29,228][root][INFO] - Training Epoch: 1/2, step 3666/7134 completed (loss: 0.10173017531633377, acc: 0.9762773513793945)
[2024-12-17 02:01:29,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:29,534][root][INFO] - Training Epoch: 1/2, step 3667/7134 completed (loss: 0.30244213342666626, acc: 0.9362186789512634)
[2024-12-17 02:01:29,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:29,864][root][INFO] - Training Epoch: 1/2, step 3668/7134 completed (loss: 0.06128542870283127, acc: 0.9895287752151489)
[2024-12-17 02:01:29,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:30,202][root][INFO] - Training Epoch: 1/2, step 3669/7134 completed (loss: 0.03481050208210945, acc: 0.9886578321456909)
[2024-12-17 02:01:30,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:30,533][root][INFO] - Training Epoch: 1/2, step 3670/7134 completed (loss: 0.04000694677233696, acc: 0.9931318759918213)
[2024-12-17 02:01:30,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:30,857][root][INFO] - Training Epoch: 1/2, step 3671/7134 completed (loss: 0.06329459697008133, acc: 0.9855491518974304)
[2024-12-17 02:01:30,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:31,221][root][INFO] - Training Epoch: 1/2, step 3672/7134 completed (loss: 0.059114255011081696, acc: 0.9835858345031738)
[2024-12-17 02:01:31,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:31,549][root][INFO] - Training Epoch: 1/2, step 3673/7134 completed (loss: 0.10577602684497833, acc: 0.9665551781654358)
[2024-12-17 02:01:31,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:31,882][root][INFO] - Training Epoch: 1/2, step 3674/7134 completed (loss: 0.04797166585922241, acc: 0.9889763593673706)
[2024-12-17 02:01:31,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:32,222][root][INFO] - Training Epoch: 1/2, step 3675/7134 completed (loss: 0.05009714514017105, acc: 0.9859693646430969)
[2024-12-17 02:01:32,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:32,559][root][INFO] - Training Epoch: 1/2, step 3676/7134 completed (loss: 0.06521361321210861, acc: 0.9766764044761658)
[2024-12-17 02:01:32,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:32,917][root][INFO] - Training Epoch: 1/2, step 3677/7134 completed (loss: 0.06539721041917801, acc: 0.9808219075202942)
[2024-12-17 02:01:33,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:33,256][root][INFO] - Training Epoch: 1/2, step 3678/7134 completed (loss: 0.09209393709897995, acc: 0.9743589758872986)
[2024-12-17 02:01:33,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:33,619][root][INFO] - Training Epoch: 1/2, step 3679/7134 completed (loss: 0.057119227945804596, acc: 0.9884297251701355)
[2024-12-17 02:01:33,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:33,967][root][INFO] - Training Epoch: 1/2, step 3680/7134 completed (loss: 0.12623558938503265, acc: 0.9659090638160706)
[2024-12-17 02:01:34,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:34,294][root][INFO] - Training Epoch: 1/2, step 3681/7134 completed (loss: 0.07668332010507584, acc: 0.9818435907363892)
[2024-12-17 02:01:34,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:34,633][root][INFO] - Training Epoch: 1/2, step 3682/7134 completed (loss: 0.040584977716207504, acc: 0.9881423115730286)
[2024-12-17 02:01:34,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:34,997][root][INFO] - Training Epoch: 1/2, step 3683/7134 completed (loss: 0.05838999152183533, acc: 0.9811023473739624)
[2024-12-17 02:01:35,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:35,313][root][INFO] - Training Epoch: 1/2, step 3684/7134 completed (loss: 0.08215518295764923, acc: 0.98124098777771)
[2024-12-17 02:01:35,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:35,630][root][INFO] - Training Epoch: 1/2, step 3685/7134 completed (loss: 0.07124760746955872, acc: 0.978805422782898)
[2024-12-17 02:01:35,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:35,960][root][INFO] - Training Epoch: 1/2, step 3686/7134 completed (loss: 0.05718017369508743, acc: 0.9895052313804626)
[2024-12-17 02:01:36,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:36,298][root][INFO] - Training Epoch: 1/2, step 3687/7134 completed (loss: 0.03498292341828346, acc: 0.9923076629638672)
[2024-12-17 02:01:36,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:36,630][root][INFO] - Training Epoch: 1/2, step 3688/7134 completed (loss: 0.04807552322745323, acc: 0.9918864369392395)
[2024-12-17 02:01:36,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:36,974][root][INFO] - Training Epoch: 1/2, step 3689/7134 completed (loss: 0.043208591639995575, acc: 0.9901960492134094)
[2024-12-17 02:01:37,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:37,327][root][INFO] - Training Epoch: 1/2, step 3690/7134 completed (loss: 0.054767806082963943, acc: 0.9799714088439941)
[2024-12-17 02:01:37,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:37,642][root][INFO] - Training Epoch: 1/2, step 3691/7134 completed (loss: 0.09118127822875977, acc: 0.9727047085762024)
[2024-12-17 02:01:37,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:37,980][root][INFO] - Training Epoch: 1/2, step 3692/7134 completed (loss: 0.10217617452144623, acc: 0.978691041469574)
[2024-12-17 02:01:38,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:38,322][root][INFO] - Training Epoch: 1/2, step 3693/7134 completed (loss: 0.08377626538276672, acc: 0.9763407111167908)
[2024-12-17 02:01:38,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:38,659][root][INFO] - Training Epoch: 1/2, step 3694/7134 completed (loss: 0.05832478404045105, acc: 0.9857752323150635)
[2024-12-17 02:01:38,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:38,999][root][INFO] - Training Epoch: 1/2, step 3695/7134 completed (loss: 0.05789514631032944, acc: 0.9815863966941833)
[2024-12-17 02:01:39,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:39,354][root][INFO] - Training Epoch: 1/2, step 3696/7134 completed (loss: 0.06555026769638062, acc: 0.9781491160392761)
[2024-12-17 02:01:39,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:39,673][root][INFO] - Training Epoch: 1/2, step 3697/7134 completed (loss: 0.05036436393857002, acc: 0.9854227304458618)
[2024-12-17 02:01:39,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:40,005][root][INFO] - Training Epoch: 1/2, step 3698/7134 completed (loss: 0.08218507468700409, acc: 0.9775280952453613)
[2024-12-17 02:01:40,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:40,335][root][INFO] - Training Epoch: 1/2, step 3699/7134 completed (loss: 0.038951002061367035, acc: 0.9881756901741028)
[2024-12-17 02:01:40,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:40,677][root][INFO] - Training Epoch: 1/2, step 3700/7134 completed (loss: 0.05404110997915268, acc: 0.9839650392532349)
[2024-12-17 02:01:40,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:41,033][root][INFO] - Training Epoch: 1/2, step 3701/7134 completed (loss: 0.06895653903484344, acc: 0.9850993156433105)
[2024-12-17 02:01:41,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:41,361][root][INFO] - Training Epoch: 1/2, step 3702/7134 completed (loss: 0.07115288823843002, acc: 0.9793388247489929)
[2024-12-17 02:01:41,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:41,718][root][INFO] - Training Epoch: 1/2, step 3703/7134 completed (loss: 0.0718611478805542, acc: 0.9833971858024597)
[2024-12-17 02:01:41,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:42,045][root][INFO] - Training Epoch: 1/2, step 3704/7134 completed (loss: 0.03901347145438194, acc: 0.991631805896759)
[2024-12-17 02:01:42,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:42,370][root][INFO] - Training Epoch: 1/2, step 3705/7134 completed (loss: 0.1339746117591858, acc: 0.9649681448936462)
[2024-12-17 02:01:42,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:42,701][root][INFO] - Training Epoch: 1/2, step 3706/7134 completed (loss: 0.1810014843940735, acc: 0.9594095945358276)
[2024-12-17 02:01:42,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:43,039][root][INFO] - Training Epoch: 1/2, step 3707/7134 completed (loss: 0.04942746087908745, acc: 0.9845722317695618)
[2024-12-17 02:01:43,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:43,391][root][INFO] - Training Epoch: 1/2, step 3708/7134 completed (loss: 0.09577561914920807, acc: 0.9785714149475098)
[2024-12-17 02:01:43,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:43,775][root][INFO] - Training Epoch: 1/2, step 3709/7134 completed (loss: 0.06647861003875732, acc: 0.9847870469093323)
[2024-12-17 02:01:43,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:44,155][root][INFO] - Training Epoch: 1/2, step 3710/7134 completed (loss: 0.09438289701938629, acc: 0.9754098653793335)
[2024-12-17 02:01:44,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:44,483][root][INFO] - Training Epoch: 1/2, step 3711/7134 completed (loss: 0.06267370283603668, acc: 0.9826302528381348)
[2024-12-17 02:01:44,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:44,850][root][INFO] - Training Epoch: 1/2, step 3712/7134 completed (loss: 0.09783859550952911, acc: 0.9784946441650391)
[2024-12-17 02:01:44,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:45,191][root][INFO] - Training Epoch: 1/2, step 3713/7134 completed (loss: 0.08804100751876831, acc: 0.9802955389022827)
[2024-12-17 02:01:45,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:45,536][root][INFO] - Training Epoch: 1/2, step 3714/7134 completed (loss: 0.07473951578140259, acc: 0.9845303893089294)
[2024-12-17 02:01:45,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:45,891][root][INFO] - Training Epoch: 1/2, step 3715/7134 completed (loss: 0.06234493851661682, acc: 0.9806529879570007)
[2024-12-17 02:01:46,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:46,254][root][INFO] - Training Epoch: 1/2, step 3716/7134 completed (loss: 0.1010972186923027, acc: 0.9716399312019348)
[2024-12-17 02:01:46,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:46,603][root][INFO] - Training Epoch: 1/2, step 3717/7134 completed (loss: 0.07807191461324692, acc: 0.9822404384613037)
[2024-12-17 02:01:46,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:46,972][root][INFO] - Training Epoch: 1/2, step 3718/7134 completed (loss: 0.08615091443061829, acc: 0.9753810167312622)
[2024-12-17 02:01:47,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:47,329][root][INFO] - Training Epoch: 1/2, step 3719/7134 completed (loss: 0.10370301455259323, acc: 0.9750000238418579)
[2024-12-17 02:01:47,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:47,654][root][INFO] - Training Epoch: 1/2, step 3720/7134 completed (loss: 0.03343210369348526, acc: 0.992668628692627)
[2024-12-17 02:01:47,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:48,022][root][INFO] - Training Epoch: 1/2, step 3721/7134 completed (loss: 0.09933292120695114, acc: 0.9786950945854187)
[2024-12-17 02:01:48,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:48,373][root][INFO] - Training Epoch: 1/2, step 3722/7134 completed (loss: 0.06959281116724014, acc: 0.9852216839790344)
[2024-12-17 02:01:48,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:48,702][root][INFO] - Training Epoch: 1/2, step 3723/7134 completed (loss: 0.10612121969461441, acc: 0.9784172773361206)
[2024-12-17 02:01:48,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:49,043][root][INFO] - Training Epoch: 1/2, step 3724/7134 completed (loss: 0.09112309664487839, acc: 0.9741379022598267)
[2024-12-17 02:01:49,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:49,404][root][INFO] - Training Epoch: 1/2, step 3725/7134 completed (loss: 0.1811116486787796, acc: 0.9557521939277649)
[2024-12-17 02:01:49,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:49,766][root][INFO] - Training Epoch: 1/2, step 3726/7134 completed (loss: 0.0746595710515976, acc: 0.9798086881637573)
[2024-12-17 02:01:49,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:50,107][root][INFO] - Training Epoch: 1/2, step 3727/7134 completed (loss: 0.057624451816082, acc: 0.9893190860748291)
[2024-12-17 02:01:50,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:50,465][root][INFO] - Training Epoch: 1/2, step 3728/7134 completed (loss: 0.03415795415639877, acc: 0.9921082258224487)
[2024-12-17 02:01:50,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:50,824][root][INFO] - Training Epoch: 1/2, step 3729/7134 completed (loss: 0.08660122007131577, acc: 0.9795454740524292)
[2024-12-17 02:01:50,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:51,180][root][INFO] - Training Epoch: 1/2, step 3730/7134 completed (loss: 0.04089951887726784, acc: 0.9877883195877075)
[2024-12-17 02:01:51,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:51,529][root][INFO] - Training Epoch: 1/2, step 3731/7134 completed (loss: 0.04427262768149376, acc: 0.9875466823577881)
[2024-12-17 02:01:51,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:51,879][root][INFO] - Training Epoch: 1/2, step 3732/7134 completed (loss: 0.029177995398640633, acc: 0.9920544624328613)
[2024-12-17 02:01:51,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:52,215][root][INFO] - Training Epoch: 1/2, step 3733/7134 completed (loss: 0.09960596263408661, acc: 0.9747545719146729)
[2024-12-17 02:01:52,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:52,545][root][INFO] - Training Epoch: 1/2, step 3734/7134 completed (loss: 0.10813359171152115, acc: 0.9708737730979919)
[2024-12-17 02:01:52,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:52,872][root][INFO] - Training Epoch: 1/2, step 3735/7134 completed (loss: 0.12370416522026062, acc: 0.974397599697113)
[2024-12-17 02:01:52,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:53,220][root][INFO] - Training Epoch: 1/2, step 3736/7134 completed (loss: 0.21979478001594543, acc: 0.9443477988243103)
[2024-12-17 02:01:53,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:53,553][root][INFO] - Training Epoch: 1/2, step 3737/7134 completed (loss: 0.12278645485639572, acc: 0.9668174982070923)
[2024-12-17 02:01:53,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:53,884][root][INFO] - Training Epoch: 1/2, step 3738/7134 completed (loss: 0.11107609421014786, acc: 0.9735973477363586)
[2024-12-17 02:01:53,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:54,181][root][INFO] - Training Epoch: 1/2, step 3739/7134 completed (loss: 0.2273591309785843, acc: 0.9382022619247437)
[2024-12-17 02:01:54,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:54,503][root][INFO] - Training Epoch: 1/2, step 3740/7134 completed (loss: 0.09949847310781479, acc: 0.975649356842041)
[2024-12-17 02:01:54,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:54,840][root][INFO] - Training Epoch: 1/2, step 3741/7134 completed (loss: 0.12594103813171387, acc: 0.9714693427085876)
[2024-12-17 02:01:54,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:55,127][root][INFO] - Training Epoch: 1/2, step 3742/7134 completed (loss: 0.11148712784051895, acc: 0.9692307710647583)
[2024-12-17 02:01:55,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:55,475][root][INFO] - Training Epoch: 1/2, step 3743/7134 completed (loss: 0.11609607934951782, acc: 0.9705014824867249)
[2024-12-17 02:01:55,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:55,829][root][INFO] - Training Epoch: 1/2, step 3744/7134 completed (loss: 0.13511931896209717, acc: 0.9631093740463257)
[2024-12-17 02:01:55,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:56,136][root][INFO] - Training Epoch: 1/2, step 3745/7134 completed (loss: 0.14874869585037231, acc: 0.9675173759460449)
[2024-12-17 02:01:56,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:56,488][root][INFO] - Training Epoch: 1/2, step 3746/7134 completed (loss: 0.10769440978765488, acc: 0.9659686088562012)
[2024-12-17 02:01:56,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:56,834][root][INFO] - Training Epoch: 1/2, step 3747/7134 completed (loss: 0.10475082695484161, acc: 0.9708454608917236)
[2024-12-17 02:01:56,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:57,116][root][INFO] - Training Epoch: 1/2, step 3748/7134 completed (loss: 0.14139322936534882, acc: 0.966549277305603)
[2024-12-17 02:01:57,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:57,444][root][INFO] - Training Epoch: 1/2, step 3749/7134 completed (loss: 0.15515141189098358, acc: 0.9640179872512817)
[2024-12-17 02:01:57,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:57,778][root][INFO] - Training Epoch: 1/2, step 3750/7134 completed (loss: 0.0717729926109314, acc: 0.9818689227104187)
[2024-12-17 02:01:57,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:58,117][root][INFO] - Training Epoch: 1/2, step 3751/7134 completed (loss: 0.13612782955169678, acc: 0.9630156755447388)
[2024-12-17 02:01:58,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:58,464][root][INFO] - Training Epoch: 1/2, step 3752/7134 completed (loss: 0.11768021434545517, acc: 0.9731343388557434)
[2024-12-17 02:01:58,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:58,800][root][INFO] - Training Epoch: 1/2, step 3753/7134 completed (loss: 0.16235962510108948, acc: 0.9596412777900696)
[2024-12-17 02:01:58,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:59,141][root][INFO] - Training Epoch: 1/2, step 3754/7134 completed (loss: 0.09168863296508789, acc: 0.9802731275558472)
[2024-12-17 02:01:59,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:59,468][root][INFO] - Training Epoch: 1/2, step 3755/7134 completed (loss: 0.06445178389549255, acc: 0.9870129823684692)
[2024-12-17 02:01:59,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:59,802][root][INFO] - Training Epoch: 1/2, step 3756/7134 completed (loss: 0.08942975848913193, acc: 0.9806094169616699)
[2024-12-17 02:01:59,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:00,143][root][INFO] - Training Epoch: 1/2, step 3757/7134 completed (loss: 0.15198871493339539, acc: 0.9605911374092102)
[2024-12-17 02:02:00,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:00,445][root][INFO] - Training Epoch: 1/2, step 3758/7134 completed (loss: 0.11451910436153412, acc: 0.9729729890823364)
[2024-12-17 02:02:00,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:00,765][root][INFO] - Training Epoch: 1/2, step 3759/7134 completed (loss: 0.18011192977428436, acc: 0.9510135054588318)
[2024-12-17 02:02:00,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:01,123][root][INFO] - Training Epoch: 1/2, step 3760/7134 completed (loss: 0.11616115272045135, acc: 0.9703390002250671)
[2024-12-17 02:02:01,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:01,456][root][INFO] - Training Epoch: 1/2, step 3761/7134 completed (loss: 0.09918417781591415, acc: 0.9799072742462158)
[2024-12-17 02:02:01,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:01,805][root][INFO] - Training Epoch: 1/2, step 3762/7134 completed (loss: 0.09406211227178574, acc: 0.9793672561645508)
[2024-12-17 02:02:01,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:02,140][root][INFO] - Training Epoch: 1/2, step 3763/7134 completed (loss: 0.05520069599151611, acc: 0.9814814925193787)
[2024-12-17 02:02:02,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:02,484][root][INFO] - Training Epoch: 1/2, step 3764/7134 completed (loss: 0.08871851116418839, acc: 0.9794801473617554)
[2024-12-17 02:02:02,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:02,914][root][INFO] - Training Epoch: 1/2, step 3765/7134 completed (loss: 0.059055328369140625, acc: 0.9831932783126831)
[2024-12-17 02:02:02,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:03,229][root][INFO] - Training Epoch: 1/2, step 3766/7134 completed (loss: 0.13591280579566956, acc: 0.9772079586982727)
[2024-12-17 02:02:03,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:03,587][root][INFO] - Training Epoch: 1/2, step 3767/7134 completed (loss: 0.05845440924167633, acc: 0.9862843155860901)
[2024-12-17 02:02:03,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:03,924][root][INFO] - Training Epoch: 1/2, step 3768/7134 completed (loss: 0.04741167649626732, acc: 0.9854771494865417)
[2024-12-17 02:02:04,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:04,281][root][INFO] - Training Epoch: 1/2, step 3769/7134 completed (loss: 0.06261847913265228, acc: 0.982367753982544)
[2024-12-17 02:02:04,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:04,610][root][INFO] - Training Epoch: 1/2, step 3770/7134 completed (loss: 0.08770919591188431, acc: 0.9844632744789124)
[2024-12-17 02:02:04,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:04,960][root][INFO] - Training Epoch: 1/2, step 3771/7134 completed (loss: 0.05809016153216362, acc: 0.984415590763092)
[2024-12-17 02:02:05,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:05,302][root][INFO] - Training Epoch: 1/2, step 3772/7134 completed (loss: 0.11095823347568512, acc: 0.974588930606842)
[2024-12-17 02:02:05,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:05,669][root][INFO] - Training Epoch: 1/2, step 3773/7134 completed (loss: 0.06740919500589371, acc: 0.9854910969734192)
[2024-12-17 02:02:05,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:06,034][root][INFO] - Training Epoch: 1/2, step 3774/7134 completed (loss: 0.05430169776082039, acc: 0.9872390031814575)
[2024-12-17 02:02:06,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:06,382][root][INFO] - Training Epoch: 1/2, step 3775/7134 completed (loss: 0.040789730846881866, acc: 0.9871060252189636)
[2024-12-17 02:02:06,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:06,742][root][INFO] - Training Epoch: 1/2, step 3776/7134 completed (loss: 0.07600262016057968, acc: 0.9777777791023254)
[2024-12-17 02:02:06,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:07,083][root][INFO] - Training Epoch: 1/2, step 3777/7134 completed (loss: 0.07220720499753952, acc: 0.981203019618988)
[2024-12-17 02:02:07,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:07,418][root][INFO] - Training Epoch: 1/2, step 3778/7134 completed (loss: 0.1393153816461563, acc: 0.9772403836250305)
[2024-12-17 02:02:07,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:07,740][root][INFO] - Training Epoch: 1/2, step 3779/7134 completed (loss: 0.061090871691703796, acc: 0.9800570011138916)
[2024-12-17 02:02:07,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:08,083][root][INFO] - Training Epoch: 1/2, step 3780/7134 completed (loss: 0.06589032709598541, acc: 0.9827089309692383)
[2024-12-17 02:02:08,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:08,409][root][INFO] - Training Epoch: 1/2, step 3781/7134 completed (loss: 0.11075354367494583, acc: 0.9780521392822266)
[2024-12-17 02:02:08,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:08,729][root][INFO] - Training Epoch: 1/2, step 3782/7134 completed (loss: 0.07899503409862518, acc: 0.9757834672927856)
[2024-12-17 02:02:08,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:09,079][root][INFO] - Training Epoch: 1/2, step 3783/7134 completed (loss: 0.09766970574855804, acc: 0.9741935729980469)
[2024-12-17 02:02:09,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:09,420][root][INFO] - Training Epoch: 1/2, step 3784/7134 completed (loss: 0.07293955981731415, acc: 0.9860896468162537)
[2024-12-17 02:02:09,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:09,750][root][INFO] - Training Epoch: 1/2, step 3785/7134 completed (loss: 0.030583487823605537, acc: 0.9906396269798279)
[2024-12-17 02:02:09,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:10,071][root][INFO] - Training Epoch: 1/2, step 3786/7134 completed (loss: 0.08259960263967514, acc: 0.9793014526367188)
[2024-12-17 02:02:10,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:10,451][root][INFO] - Training Epoch: 1/2, step 3787/7134 completed (loss: 0.0748043954372406, acc: 0.9776714444160461)
[2024-12-17 02:02:10,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:10,831][root][INFO] - Training Epoch: 1/2, step 3788/7134 completed (loss: 0.08091326802968979, acc: 0.9770580530166626)
[2024-12-17 02:02:10,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:11,173][root][INFO] - Training Epoch: 1/2, step 3789/7134 completed (loss: 0.10895438492298126, acc: 0.9732770919799805)
[2024-12-17 02:02:11,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:11,524][root][INFO] - Training Epoch: 1/2, step 3790/7134 completed (loss: 0.1591598391532898, acc: 0.963244616985321)
[2024-12-17 02:02:11,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:11,850][root][INFO] - Training Epoch: 1/2, step 3791/7134 completed (loss: 0.0796533077955246, acc: 0.9845161437988281)
[2024-12-17 02:02:11,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:12,175][root][INFO] - Training Epoch: 1/2, step 3792/7134 completed (loss: 0.07532650977373123, acc: 0.9753694534301758)
[2024-12-17 02:02:12,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:12,517][root][INFO] - Training Epoch: 1/2, step 3793/7134 completed (loss: 0.08202539384365082, acc: 0.9783783555030823)
[2024-12-17 02:02:12,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:12,847][root][INFO] - Training Epoch: 1/2, step 3794/7134 completed (loss: 0.08397810906171799, acc: 0.9805447459220886)
[2024-12-17 02:02:12,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:13,208][root][INFO] - Training Epoch: 1/2, step 3795/7134 completed (loss: 0.10550940036773682, acc: 0.9783132672309875)
[2024-12-17 02:02:13,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:13,554][root][INFO] - Training Epoch: 1/2, step 3796/7134 completed (loss: 0.0838453397154808, acc: 0.9748743772506714)
[2024-12-17 02:02:13,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:13,881][root][INFO] - Training Epoch: 1/2, step 3797/7134 completed (loss: 0.07730177044868469, acc: 0.979139506816864)
[2024-12-17 02:02:13,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:14,210][root][INFO] - Training Epoch: 1/2, step 3798/7134 completed (loss: 0.0910295695066452, acc: 0.9798850417137146)
[2024-12-17 02:02:14,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:14,545][root][INFO] - Training Epoch: 1/2, step 3799/7134 completed (loss: 0.0820530578494072, acc: 0.9742599725723267)
[2024-12-17 02:02:14,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:14,884][root][INFO] - Training Epoch: 1/2, step 3800/7134 completed (loss: 0.11631929129362106, acc: 0.9709480404853821)
[2024-12-17 02:02:14,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:15,242][root][INFO] - Training Epoch: 1/2, step 3801/7134 completed (loss: 0.05349142849445343, acc: 0.990123450756073)
[2024-12-17 02:02:15,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:15,592][root][INFO] - Training Epoch: 1/2, step 3802/7134 completed (loss: 0.06691333651542664, acc: 0.9846335649490356)
[2024-12-17 02:02:15,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:15,931][root][INFO] - Training Epoch: 1/2, step 3803/7134 completed (loss: 0.08630192279815674, acc: 0.9775910377502441)
[2024-12-17 02:02:16,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:16,288][root][INFO] - Training Epoch: 1/2, step 3804/7134 completed (loss: 0.05497705563902855, acc: 0.9891135096549988)
[2024-12-17 02:02:16,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:16,641][root][INFO] - Training Epoch: 1/2, step 3805/7134 completed (loss: 0.040643248707056046, acc: 0.9908376932144165)
[2024-12-17 02:02:16,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:16,979][root][INFO] - Training Epoch: 1/2, step 3806/7134 completed (loss: 0.0827353447675705, acc: 0.9723865985870361)
[2024-12-17 02:02:17,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:17,321][root][INFO] - Training Epoch: 1/2, step 3807/7134 completed (loss: 0.034489549696445465, acc: 0.9941520690917969)
[2024-12-17 02:02:17,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:17,691][root][INFO] - Training Epoch: 1/2, step 3808/7134 completed (loss: 0.06650850921869278, acc: 0.9835442900657654)
[2024-12-17 02:02:17,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:18,028][root][INFO] - Training Epoch: 1/2, step 3809/7134 completed (loss: 0.11902492493391037, acc: 0.9631979465484619)
[2024-12-17 02:02:18,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:18,356][root][INFO] - Training Epoch: 1/2, step 3810/7134 completed (loss: 0.08513959497213364, acc: 0.9747023582458496)
[2024-12-17 02:02:18,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:18,716][root][INFO] - Training Epoch: 1/2, step 3811/7134 completed (loss: 0.08393966406583786, acc: 0.9751724004745483)
[2024-12-17 02:02:18,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:19,068][root][INFO] - Training Epoch: 1/2, step 3812/7134 completed (loss: 0.10868950188159943, acc: 0.9639794230461121)
[2024-12-17 02:02:19,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:19,421][root][INFO] - Training Epoch: 1/2, step 3813/7134 completed (loss: 0.1026206985116005, acc: 0.9670184850692749)
[2024-12-17 02:02:19,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:19,779][root][INFO] - Training Epoch: 1/2, step 3814/7134 completed (loss: 0.03094596415758133, acc: 0.9932975769042969)
[2024-12-17 02:02:19,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:20,107][root][INFO] - Training Epoch: 1/2, step 3815/7134 completed (loss: 0.0657007023692131, acc: 0.9792592525482178)
[2024-12-17 02:02:20,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:20,506][root][INFO] - Training Epoch: 1/2, step 3816/7134 completed (loss: 0.06686419993638992, acc: 0.9794952869415283)
[2024-12-17 02:02:20,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:20,838][root][INFO] - Training Epoch: 1/2, step 3817/7134 completed (loss: 0.11078472435474396, acc: 0.973621129989624)
[2024-12-17 02:02:20,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:21,157][root][INFO] - Training Epoch: 1/2, step 3818/7134 completed (loss: 0.12085708975791931, acc: 0.9777777791023254)
[2024-12-17 02:02:21,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:21,475][root][INFO] - Training Epoch: 1/2, step 3819/7134 completed (loss: 0.11848273128271103, acc: 0.9638554453849792)
[2024-12-17 02:02:21,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:21,801][root][INFO] - Training Epoch: 1/2, step 3820/7134 completed (loss: 0.13716909289360046, acc: 0.9643705487251282)
[2024-12-17 02:02:21,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:22,119][root][INFO] - Training Epoch: 1/2, step 3821/7134 completed (loss: 0.096938356757164, acc: 0.9695431590080261)
[2024-12-17 02:02:22,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:22,446][root][INFO] - Training Epoch: 1/2, step 3822/7134 completed (loss: 0.1072230190038681, acc: 0.9724950790405273)
[2024-12-17 02:02:22,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:22,795][root][INFO] - Training Epoch: 1/2, step 3823/7134 completed (loss: 0.06538225710391998, acc: 0.9875518679618835)
[2024-12-17 02:02:22,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:23,114][root][INFO] - Training Epoch: 1/2, step 3824/7134 completed (loss: 0.14918076992034912, acc: 0.9629005193710327)
[2024-12-17 02:02:23,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:23,454][root][INFO] - Training Epoch: 1/2, step 3825/7134 completed (loss: 0.08064232021570206, acc: 0.9780439138412476)
[2024-12-17 02:02:23,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:23,822][root][INFO] - Training Epoch: 1/2, step 3826/7134 completed (loss: 0.10478132963180542, acc: 0.9602941274642944)
[2024-12-17 02:02:23,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:24,174][root][INFO] - Training Epoch: 1/2, step 3827/7134 completed (loss: 0.09032496064901352, acc: 0.9775910377502441)
[2024-12-17 02:02:24,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:24,462][root][INFO] - Training Epoch: 1/2, step 3828/7134 completed (loss: 0.09705240279436111, acc: 0.9761273264884949)
[2024-12-17 02:02:24,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:24,822][root][INFO] - Training Epoch: 1/2, step 3829/7134 completed (loss: 0.048113733530044556, acc: 0.9879336357116699)
[2024-12-17 02:02:24,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:25,156][root][INFO] - Training Epoch: 1/2, step 3830/7134 completed (loss: 0.10685912519693375, acc: 0.9698492288589478)
[2024-12-17 02:02:25,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:25,497][root][INFO] - Training Epoch: 1/2, step 3831/7134 completed (loss: 0.10267861187458038, acc: 0.9759759902954102)
[2024-12-17 02:02:25,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:25,891][root][INFO] - Training Epoch: 1/2, step 3832/7134 completed (loss: 0.0696219801902771, acc: 0.9862475395202637)
[2024-12-17 02:02:25,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:26,243][root][INFO] - Training Epoch: 1/2, step 3833/7134 completed (loss: 0.03617541864514351, acc: 0.9888613820075989)
[2024-12-17 02:02:26,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:26,576][root][INFO] - Training Epoch: 1/2, step 3834/7134 completed (loss: 0.033583566546440125, acc: 0.9883117079734802)
[2024-12-17 02:02:26,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:26,928][root][INFO] - Training Epoch: 1/2, step 3835/7134 completed (loss: 0.035841137170791626, acc: 0.9866504669189453)
[2024-12-17 02:02:27,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:27,192][root][INFO] - Training Epoch: 1/2, step 3836/7134 completed (loss: 0.11134851723909378, acc: 0.9797101616859436)
[2024-12-17 02:02:27,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:27,506][root][INFO] - Training Epoch: 1/2, step 3837/7134 completed (loss: 0.06777115166187286, acc: 0.9841954112052917)
[2024-12-17 02:02:27,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:27,847][root][INFO] - Training Epoch: 1/2, step 3838/7134 completed (loss: 0.041908182203769684, acc: 0.9907038807868958)
[2024-12-17 02:02:27,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:28,218][root][INFO] - Training Epoch: 1/2, step 3839/7134 completed (loss: 0.059809520840644836, acc: 0.9834254384040833)
[2024-12-17 02:02:28,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:28,537][root][INFO] - Training Epoch: 1/2, step 3840/7134 completed (loss: 0.053653184324502945, acc: 0.9852744340896606)
[2024-12-17 02:02:28,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:28,913][root][INFO] - Training Epoch: 1/2, step 3841/7134 completed (loss: 0.07636991143226624, acc: 0.9800221920013428)
[2024-12-17 02:02:29,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:29,191][root][INFO] - Training Epoch: 1/2, step 3842/7134 completed (loss: 0.03372826799750328, acc: 0.9901960492134094)
[2024-12-17 02:02:29,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:29,579][root][INFO] - Training Epoch: 1/2, step 3843/7134 completed (loss: 0.06877698004245758, acc: 0.9822732210159302)
[2024-12-17 02:02:29,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:29,948][root][INFO] - Training Epoch: 1/2, step 3844/7134 completed (loss: 0.06126883998513222, acc: 0.9834815859794617)
[2024-12-17 02:02:30,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:30,281][root][INFO] - Training Epoch: 1/2, step 3845/7134 completed (loss: 0.08060438930988312, acc: 0.9781144857406616)
[2024-12-17 02:02:30,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:30,601][root][INFO] - Training Epoch: 1/2, step 3846/7134 completed (loss: 0.037969257682561874, acc: 0.9881154298782349)
[2024-12-17 02:02:30,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:30,951][root][INFO] - Training Epoch: 1/2, step 3847/7134 completed (loss: 0.05013582482933998, acc: 0.9824000000953674)
[2024-12-17 02:02:31,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:31,319][root][INFO] - Training Epoch: 1/2, step 3848/7134 completed (loss: 0.06483092904090881, acc: 0.991094172000885)
[2024-12-17 02:02:31,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:31,640][root][INFO] - Training Epoch: 1/2, step 3849/7134 completed (loss: 0.09807905554771423, acc: 0.9714794754981995)
[2024-12-17 02:02:31,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:31,974][root][INFO] - Training Epoch: 1/2, step 3850/7134 completed (loss: 0.15183119475841522, acc: 0.9694376587867737)
[2024-12-17 02:02:32,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:32,338][root][INFO] - Training Epoch: 1/2, step 3851/7134 completed (loss: 0.09900563955307007, acc: 0.9748954176902771)
[2024-12-17 02:02:32,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:32,660][root][INFO] - Training Epoch: 1/2, step 3852/7134 completed (loss: 0.07353800535202026, acc: 0.9823151230812073)
[2024-12-17 02:02:32,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:32,986][root][INFO] - Training Epoch: 1/2, step 3853/7134 completed (loss: 0.09879568219184875, acc: 0.9704641103744507)
[2024-12-17 02:02:33,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:33,319][root][INFO] - Training Epoch: 1/2, step 3854/7134 completed (loss: 0.046505190432071686, acc: 0.9901685118675232)
[2024-12-17 02:02:33,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:33,673][root][INFO] - Training Epoch: 1/2, step 3855/7134 completed (loss: 0.10273684561252594, acc: 0.975062370300293)
[2024-12-17 02:02:33,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:33,998][root][INFO] - Training Epoch: 1/2, step 3856/7134 completed (loss: 0.09758137911558151, acc: 0.9790794849395752)
[2024-12-17 02:02:34,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:34,302][root][INFO] - Training Epoch: 1/2, step 3857/7134 completed (loss: 0.09116548299789429, acc: 0.9726688265800476)
[2024-12-17 02:02:34,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:34,656][root][INFO] - Training Epoch: 1/2, step 3858/7134 completed (loss: 0.12889277935028076, acc: 0.9716714024543762)
[2024-12-17 02:02:34,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:35,017][root][INFO] - Training Epoch: 1/2, step 3859/7134 completed (loss: 0.10791198164224625, acc: 0.9669210910797119)
[2024-12-17 02:02:35,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:35,380][root][INFO] - Training Epoch: 1/2, step 3860/7134 completed (loss: 0.06851354241371155, acc: 0.9787709712982178)
[2024-12-17 02:02:35,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:35,722][root][INFO] - Training Epoch: 1/2, step 3861/7134 completed (loss: 0.102979876101017, acc: 0.9755101799964905)
[2024-12-17 02:02:35,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:36,025][root][INFO] - Training Epoch: 1/2, step 3862/7134 completed (loss: 0.13221269845962524, acc: 0.9638752341270447)
[2024-12-17 02:02:36,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:36,412][root][INFO] - Training Epoch: 1/2, step 3863/7134 completed (loss: 0.08572427183389664, acc: 0.9777777791023254)
[2024-12-17 02:02:36,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:36,760][root][INFO] - Training Epoch: 1/2, step 3864/7134 completed (loss: 0.08546332269906998, acc: 0.9751958250999451)
[2024-12-17 02:02:36,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:37,108][root][INFO] - Training Epoch: 1/2, step 3865/7134 completed (loss: 0.062337975949048996, acc: 0.9860557913780212)
[2024-12-17 02:02:37,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:37,440][root][INFO] - Training Epoch: 1/2, step 3866/7134 completed (loss: 0.10056702047586441, acc: 0.9755799770355225)
[2024-12-17 02:02:37,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:37,805][root][INFO] - Training Epoch: 1/2, step 3867/7134 completed (loss: 0.08727693557739258, acc: 0.9696969985961914)
[2024-12-17 02:02:37,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:38,142][root][INFO] - Training Epoch: 1/2, step 3868/7134 completed (loss: 0.06422053277492523, acc: 0.9830795526504517)
[2024-12-17 02:02:38,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:38,478][root][INFO] - Training Epoch: 1/2, step 3869/7134 completed (loss: 0.09772226214408875, acc: 0.9803328514099121)
[2024-12-17 02:02:38,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:38,803][root][INFO] - Training Epoch: 1/2, step 3870/7134 completed (loss: 0.11148091405630112, acc: 0.9736111164093018)
[2024-12-17 02:02:38,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:39,129][root][INFO] - Training Epoch: 1/2, step 3871/7134 completed (loss: 0.11201424896717072, acc: 0.9688279032707214)
[2024-12-17 02:02:39,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:39,517][root][INFO] - Training Epoch: 1/2, step 3872/7134 completed (loss: 0.12220699340105057, acc: 0.9689507484436035)
[2024-12-17 02:02:39,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:39,864][root][INFO] - Training Epoch: 1/2, step 3873/7134 completed (loss: 0.09327786415815353, acc: 0.970588207244873)
[2024-12-17 02:02:39,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:40,196][root][INFO] - Training Epoch: 1/2, step 3874/7134 completed (loss: 0.12235531210899353, acc: 0.9723374843597412)
[2024-12-17 02:02:40,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:40,562][root][INFO] - Training Epoch: 1/2, step 3875/7134 completed (loss: 0.10980632156133652, acc: 0.9734042286872864)
[2024-12-17 02:02:40,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:40,888][root][INFO] - Training Epoch: 1/2, step 3876/7134 completed (loss: 0.11520501226186752, acc: 0.9756097793579102)
[2024-12-17 02:02:40,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:41,217][root][INFO] - Training Epoch: 1/2, step 3877/7134 completed (loss: 0.08894161134958267, acc: 0.9843342304229736)
[2024-12-17 02:02:41,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:41,541][root][INFO] - Training Epoch: 1/2, step 3878/7134 completed (loss: 0.11001989245414734, acc: 0.9716981053352356)
[2024-12-17 02:02:41,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:41,932][root][INFO] - Training Epoch: 1/2, step 3879/7134 completed (loss: 0.05471518263220787, acc: 0.9852125644683838)
[2024-12-17 02:02:42,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:42,285][root][INFO] - Training Epoch: 1/2, step 3880/7134 completed (loss: 0.15289713442325592, acc: 0.9676945805549622)
[2024-12-17 02:02:42,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:42,624][root][INFO] - Training Epoch: 1/2, step 3881/7134 completed (loss: 0.17080767452716827, acc: 0.9559999704360962)
[2024-12-17 02:02:42,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:42,970][root][INFO] - Training Epoch: 1/2, step 3882/7134 completed (loss: 0.13294699788093567, acc: 0.9700000286102295)
[2024-12-17 02:02:43,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:43,315][root][INFO] - Training Epoch: 1/2, step 3883/7134 completed (loss: 0.05942432954907417, acc: 0.9846153855323792)
[2024-12-17 02:02:43,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:43,652][root][INFO] - Training Epoch: 1/2, step 3884/7134 completed (loss: 0.06777414679527283, acc: 0.9823129177093506)
[2024-12-17 02:02:43,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:43,975][root][INFO] - Training Epoch: 1/2, step 3885/7134 completed (loss: 0.07643027603626251, acc: 0.9791122674942017)
[2024-12-17 02:02:44,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:44,326][root][INFO] - Training Epoch: 1/2, step 3886/7134 completed (loss: 0.07302147150039673, acc: 0.9746376872062683)
[2024-12-17 02:02:44,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:44,652][root][INFO] - Training Epoch: 1/2, step 3887/7134 completed (loss: 0.05178804323077202, acc: 0.9879336357116699)
[2024-12-17 02:02:44,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:45,003][root][INFO] - Training Epoch: 1/2, step 3888/7134 completed (loss: 0.08109351992607117, acc: 0.9825000166893005)
[2024-12-17 02:02:45,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:45,376][root][INFO] - Training Epoch: 1/2, step 3889/7134 completed (loss: 0.056743208318948746, acc: 0.9859514832496643)
[2024-12-17 02:02:45,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:45,732][root][INFO] - Training Epoch: 1/2, step 3890/7134 completed (loss: 0.047220781445503235, acc: 0.9891696572303772)
[2024-12-17 02:02:45,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:46,092][root][INFO] - Training Epoch: 1/2, step 3891/7134 completed (loss: 0.07201555371284485, acc: 0.9751634001731873)
[2024-12-17 02:02:46,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:46,450][root][INFO] - Training Epoch: 1/2, step 3892/7134 completed (loss: 0.07402797788381577, acc: 0.9784615635871887)
[2024-12-17 02:02:46,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:46,788][root][INFO] - Training Epoch: 1/2, step 3893/7134 completed (loss: 0.13816101849079132, acc: 0.9626288414001465)
[2024-12-17 02:02:46,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:47,106][root][INFO] - Training Epoch: 1/2, step 3894/7134 completed (loss: 0.045166801661252975, acc: 0.9873595237731934)
[2024-12-17 02:02:47,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:47,451][root][INFO] - Training Epoch: 1/2, step 3895/7134 completed (loss: 0.07423121482133865, acc: 0.9793548583984375)
[2024-12-17 02:02:47,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:47,811][root][INFO] - Training Epoch: 1/2, step 3896/7134 completed (loss: 0.039131127297878265, acc: 0.9887133240699768)
[2024-12-17 02:02:47,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:48,167][root][INFO] - Training Epoch: 1/2, step 3897/7134 completed (loss: 0.12174016237258911, acc: 0.9732394218444824)
[2024-12-17 02:02:48,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:48,506][root][INFO] - Training Epoch: 1/2, step 3898/7134 completed (loss: 0.12508603930473328, acc: 0.9732824563980103)
[2024-12-17 02:02:48,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:48,854][root][INFO] - Training Epoch: 1/2, step 3899/7134 completed (loss: 0.06539735198020935, acc: 0.9870634078979492)
[2024-12-17 02:02:48,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:49,240][root][INFO] - Training Epoch: 1/2, step 3900/7134 completed (loss: 0.07260757684707642, acc: 0.9791425466537476)
[2024-12-17 02:02:49,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:49,564][root][INFO] - Training Epoch: 1/2, step 3901/7134 completed (loss: 0.14260169863700867, acc: 0.9690027236938477)
[2024-12-17 02:02:49,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:49,909][root][INFO] - Training Epoch: 1/2, step 3902/7134 completed (loss: 0.14616355299949646, acc: 0.9642384052276611)
[2024-12-17 02:02:50,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:50,279][root][INFO] - Training Epoch: 1/2, step 3903/7134 completed (loss: 0.18038396537303925, acc: 0.959785521030426)
[2024-12-17 02:02:50,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:50,598][root][INFO] - Training Epoch: 1/2, step 3904/7134 completed (loss: 0.10199242830276489, acc: 0.9756468534469604)
[2024-12-17 02:02:50,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:50,951][root][INFO] - Training Epoch: 1/2, step 3905/7134 completed (loss: 0.13773216307163239, acc: 0.9633286595344543)
[2024-12-17 02:02:51,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:51,302][root][INFO] - Training Epoch: 1/2, step 3906/7134 completed (loss: 0.07916277647018433, acc: 0.9798850417137146)
[2024-12-17 02:02:51,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:51,634][root][INFO] - Training Epoch: 1/2, step 3907/7134 completed (loss: 0.059412773698568344, acc: 0.9871465563774109)
[2024-12-17 02:02:51,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:51,980][root][INFO] - Training Epoch: 1/2, step 3908/7134 completed (loss: 0.10518098622560501, acc: 0.9754977226257324)
[2024-12-17 02:02:52,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:52,321][root][INFO] - Training Epoch: 1/2, step 3909/7134 completed (loss: 0.0739096850156784, acc: 0.9757673740386963)
[2024-12-17 02:02:52,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:52,674][root][INFO] - Training Epoch: 1/2, step 3910/7134 completed (loss: 0.07471734285354614, acc: 0.9791377186775208)
[2024-12-17 02:02:52,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:53,033][root][INFO] - Training Epoch: 1/2, step 3911/7134 completed (loss: 0.0681174248456955, acc: 0.9854369163513184)
[2024-12-17 02:02:53,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:53,373][root][INFO] - Training Epoch: 1/2, step 3912/7134 completed (loss: 0.04400242120027542, acc: 0.9866071343421936)
[2024-12-17 02:02:53,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:53,723][root][INFO] - Training Epoch: 1/2, step 3913/7134 completed (loss: 0.08706923574209213, acc: 0.9756410121917725)
[2024-12-17 02:02:53,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:54,047][root][INFO] - Training Epoch: 1/2, step 3914/7134 completed (loss: 0.08314148336648941, acc: 0.9797979593276978)
[2024-12-17 02:02:54,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:54,399][root][INFO] - Training Epoch: 1/2, step 3915/7134 completed (loss: 0.055580537766218185, acc: 0.9887164831161499)
[2024-12-17 02:02:54,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:54,750][root][INFO] - Training Epoch: 1/2, step 3916/7134 completed (loss: 0.07301539927721024, acc: 0.9770700931549072)
[2024-12-17 02:02:54,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:55,107][root][INFO] - Training Epoch: 1/2, step 3917/7134 completed (loss: 0.06432750821113586, acc: 0.9807460904121399)
[2024-12-17 02:02:55,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:55,463][root][INFO] - Training Epoch: 1/2, step 3918/7134 completed (loss: 0.09393296390771866, acc: 0.9791666865348816)
[2024-12-17 02:02:55,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:55,818][root][INFO] - Training Epoch: 1/2, step 3919/7134 completed (loss: 0.14823749661445618, acc: 0.9625407457351685)
[2024-12-17 02:02:55,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:56,181][root][INFO] - Training Epoch: 1/2, step 3920/7134 completed (loss: 0.10073890537023544, acc: 0.9719626307487488)
[2024-12-17 02:02:56,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:56,509][root][INFO] - Training Epoch: 1/2, step 3921/7134 completed (loss: 0.16310778260231018, acc: 0.949999988079071)
[2024-12-17 02:02:56,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:56,831][root][INFO] - Training Epoch: 1/2, step 3922/7134 completed (loss: 0.2579387426376343, acc: 0.9245283007621765)
[2024-12-17 02:02:56,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:57,158][root][INFO] - Training Epoch: 1/2, step 3923/7134 completed (loss: 0.23437725007534027, acc: 0.9554794430732727)
[2024-12-17 02:02:57,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:57,510][root][INFO] - Training Epoch: 1/2, step 3924/7134 completed (loss: 0.17731834948062897, acc: 0.9525862336158752)
[2024-12-17 02:02:57,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:57,867][root][INFO] - Training Epoch: 1/2, step 3925/7134 completed (loss: 0.15139815211296082, acc: 0.9604685306549072)
[2024-12-17 02:02:58,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:58,243][root][INFO] - Training Epoch: 1/2, step 3926/7134 completed (loss: 0.10716342180967331, acc: 0.9683453440666199)
[2024-12-17 02:02:58,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:58,620][root][INFO] - Training Epoch: 1/2, step 3927/7134 completed (loss: 0.06658659130334854, acc: 0.9807427525520325)
[2024-12-17 02:02:58,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:58,977][root][INFO] - Training Epoch: 1/2, step 3928/7134 completed (loss: 0.10566666722297668, acc: 0.9727011322975159)
[2024-12-17 02:02:59,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:59,291][root][INFO] - Training Epoch: 1/2, step 3929/7134 completed (loss: 0.054058924317359924, acc: 0.9904610514640808)
[2024-12-17 02:02:59,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:59,628][root][INFO] - Training Epoch: 1/2, step 3930/7134 completed (loss: 0.126352459192276, acc: 0.9663865566253662)
[2024-12-17 02:02:59,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:59,954][root][INFO] - Training Epoch: 1/2, step 3931/7134 completed (loss: 0.05839046463370323, acc: 0.9820627570152283)
[2024-12-17 02:03:00,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:00,291][root][INFO] - Training Epoch: 1/2, step 3932/7134 completed (loss: 0.07444627583026886, acc: 0.9743083119392395)
[2024-12-17 02:03:00,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:00,581][root][INFO] - Training Epoch: 1/2, step 3933/7134 completed (loss: 0.04538683965802193, acc: 0.9934210777282715)
[2024-12-17 02:03:00,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:00,900][root][INFO] - Training Epoch: 1/2, step 3934/7134 completed (loss: 0.08906123787164688, acc: 0.9789227247238159)
[2024-12-17 02:03:00,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:01,213][root][INFO] - Training Epoch: 1/2, step 3935/7134 completed (loss: 0.03258201852440834, acc: 0.9858657121658325)
[2024-12-17 02:03:01,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:01,536][root][INFO] - Training Epoch: 1/2, step 3936/7134 completed (loss: 0.09628419578075409, acc: 0.9754716753959656)
[2024-12-17 02:03:01,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:01,859][root][INFO] - Training Epoch: 1/2, step 3937/7134 completed (loss: 0.08238111436367035, acc: 0.9795918464660645)
[2024-12-17 02:03:01,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:02,159][root][INFO] - Training Epoch: 1/2, step 3938/7134 completed (loss: 0.05224663391709328, acc: 0.9841628670692444)
[2024-12-17 02:03:02,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:02,471][root][INFO] - Training Epoch: 1/2, step 3939/7134 completed (loss: 0.11978285014629364, acc: 0.9729272127151489)
[2024-12-17 02:03:02,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:02,733][root][INFO] - Training Epoch: 1/2, step 3940/7134 completed (loss: 0.09830987453460693, acc: 0.9773869514465332)
[2024-12-17 02:03:02,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:02,987][root][INFO] - Training Epoch: 1/2, step 3941/7134 completed (loss: 0.08266159892082214, acc: 0.9786585569381714)
[2024-12-17 02:03:03,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:03,320][root][INFO] - Training Epoch: 1/2, step 3942/7134 completed (loss: 0.05532648041844368, acc: 0.9877049326896667)
[2024-12-17 02:03:03,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:03,624][root][INFO] - Training Epoch: 1/2, step 3943/7134 completed (loss: 0.07150246948003769, acc: 0.9845559597015381)
[2024-12-17 02:03:03,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:03,980][root][INFO] - Training Epoch: 1/2, step 3944/7134 completed (loss: 0.05898967757821083, acc: 0.9852398633956909)
[2024-12-17 02:03:04,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:04,301][root][INFO] - Training Epoch: 1/2, step 3945/7134 completed (loss: 0.08877803385257721, acc: 0.9771341681480408)
[2024-12-17 02:03:04,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:04,583][root][INFO] - Training Epoch: 1/2, step 3946/7134 completed (loss: 0.05980425700545311, acc: 0.9853861927986145)
[2024-12-17 02:03:04,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:04,879][root][INFO] - Training Epoch: 1/2, step 3947/7134 completed (loss: 0.09044086188077927, acc: 0.9870466589927673)
[2024-12-17 02:03:04,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:05,194][root][INFO] - Training Epoch: 1/2, step 3948/7134 completed (loss: 0.06937643140554428, acc: 0.9899497628211975)
[2024-12-17 02:03:05,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:05,521][root][INFO] - Training Epoch: 1/2, step 3949/7134 completed (loss: 0.060137778520584106, acc: 0.97947758436203)
[2024-12-17 02:03:05,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:05,790][root][INFO] - Training Epoch: 1/2, step 3950/7134 completed (loss: 0.09459911286830902, acc: 0.9776785969734192)
[2024-12-17 02:03:05,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:06,116][root][INFO] - Training Epoch: 1/2, step 3951/7134 completed (loss: 0.08747517317533493, acc: 0.9774436354637146)
[2024-12-17 02:03:06,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:06,440][root][INFO] - Training Epoch: 1/2, step 3952/7134 completed (loss: 0.06637626886367798, acc: 0.9794871807098389)
[2024-12-17 02:03:06,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:06,741][root][INFO] - Training Epoch: 1/2, step 3953/7134 completed (loss: 0.06781817227602005, acc: 0.9829221963882446)
[2024-12-17 02:03:06,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:07,036][root][INFO] - Training Epoch: 1/2, step 3954/7134 completed (loss: 0.06085629388689995, acc: 0.9819587469100952)
[2024-12-17 02:03:07,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:07,357][root][INFO] - Training Epoch: 1/2, step 3955/7134 completed (loss: 0.06922396272420883, acc: 0.9763912558555603)
[2024-12-17 02:03:07,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:07,683][root][INFO] - Training Epoch: 1/2, step 3956/7134 completed (loss: 0.04839421063661575, acc: 0.9904000163078308)
[2024-12-17 02:03:07,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:08,004][root][INFO] - Training Epoch: 1/2, step 3957/7134 completed (loss: 0.0771552249789238, acc: 0.9797297120094299)
[2024-12-17 02:03:08,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:08,294][root][INFO] - Training Epoch: 1/2, step 3958/7134 completed (loss: 0.1476791799068451, acc: 0.9679487347602844)
[2024-12-17 02:03:08,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:08,626][root][INFO] - Training Epoch: 1/2, step 3959/7134 completed (loss: 0.04442029446363449, acc: 0.9846153855323792)
[2024-12-17 02:03:08,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:08,974][root][INFO] - Training Epoch: 1/2, step 3960/7134 completed (loss: 0.07670122385025024, acc: 0.9800570011138916)
[2024-12-17 02:03:09,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:09,313][root][INFO] - Training Epoch: 1/2, step 3961/7134 completed (loss: 0.039763402193784714, acc: 0.9880059957504272)
[2024-12-17 02:03:09,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:09,639][root][INFO] - Training Epoch: 1/2, step 3962/7134 completed (loss: 0.05050639063119888, acc: 0.9805825352668762)
[2024-12-17 02:03:09,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:09,975][root][INFO] - Training Epoch: 1/2, step 3963/7134 completed (loss: 0.1422915756702423, acc: 0.973607063293457)
[2024-12-17 02:03:10,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:10,292][root][INFO] - Training Epoch: 1/2, step 3964/7134 completed (loss: 0.1460183560848236, acc: 0.9685184955596924)
[2024-12-17 02:03:10,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:10,615][root][INFO] - Training Epoch: 1/2, step 3965/7134 completed (loss: 0.10490323603153229, acc: 0.9756795167922974)
[2024-12-17 02:03:10,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:10,937][root][INFO] - Training Epoch: 1/2, step 3966/7134 completed (loss: 0.07655499875545502, acc: 0.9783393740653992)
[2024-12-17 02:03:11,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:11,281][root][INFO] - Training Epoch: 1/2, step 3967/7134 completed (loss: 0.17082007229328156, acc: 0.9618717432022095)
[2024-12-17 02:03:11,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:11,633][root][INFO] - Training Epoch: 1/2, step 3968/7134 completed (loss: 0.07029089331626892, acc: 0.981794536113739)
[2024-12-17 02:03:11,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:11,888][root][INFO] - Training Epoch: 1/2, step 3969/7134 completed (loss: 0.15690714120864868, acc: 0.9502617716789246)
[2024-12-17 02:03:11,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:12,212][root][INFO] - Training Epoch: 1/2, step 3970/7134 completed (loss: 0.11342982202768326, acc: 0.9769784212112427)
[2024-12-17 02:03:12,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:12,567][root][INFO] - Training Epoch: 1/2, step 3971/7134 completed (loss: 0.2225247323513031, acc: 0.9578005075454712)
[2024-12-17 02:03:12,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:12,899][root][INFO] - Training Epoch: 1/2, step 3972/7134 completed (loss: 0.2805226445198059, acc: 0.9329897165298462)
[2024-12-17 02:03:12,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:13,239][root][INFO] - Training Epoch: 1/2, step 3973/7134 completed (loss: 0.07511460036039352, acc: 0.9792746305465698)
[2024-12-17 02:03:13,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:13,587][root][INFO] - Training Epoch: 1/2, step 3974/7134 completed (loss: 0.16977177560329437, acc: 0.9593495726585388)
[2024-12-17 02:03:13,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:13,914][root][INFO] - Training Epoch: 1/2, step 3975/7134 completed (loss: 0.10285359621047974, acc: 0.9728096723556519)
[2024-12-17 02:03:14,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:14,265][root][INFO] - Training Epoch: 1/2, step 3976/7134 completed (loss: 0.21170386672019958, acc: 0.9572271108627319)
[2024-12-17 02:03:14,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:14,619][root][INFO] - Training Epoch: 1/2, step 3977/7134 completed (loss: 0.07465437799692154, acc: 0.9826086759567261)
[2024-12-17 02:03:14,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:14,948][root][INFO] - Training Epoch: 1/2, step 3978/7134 completed (loss: 0.053092729300260544, acc: 0.9818887710571289)
[2024-12-17 02:03:15,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:15,303][root][INFO] - Training Epoch: 1/2, step 3979/7134 completed (loss: 0.1368110328912735, acc: 0.9653916358947754)
[2024-12-17 02:03:15,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:15,643][root][INFO] - Training Epoch: 1/2, step 3980/7134 completed (loss: 0.06876610219478607, acc: 0.9832317233085632)
[2024-12-17 02:03:15,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:15,967][root][INFO] - Training Epoch: 1/2, step 3981/7134 completed (loss: 0.08691444247961044, acc: 0.9801223278045654)
[2024-12-17 02:03:16,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:16,301][root][INFO] - Training Epoch: 1/2, step 3982/7134 completed (loss: 0.16428574919700623, acc: 0.9684361815452576)
[2024-12-17 02:03:16,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:16,627][root][INFO] - Training Epoch: 1/2, step 3983/7134 completed (loss: 0.45917075872421265, acc: 0.9042553305625916)
[2024-12-17 02:03:16,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:16,969][root][INFO] - Training Epoch: 1/2, step 3984/7134 completed (loss: 0.1513998806476593, acc: 0.9675324559211731)
[2024-12-17 02:03:17,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:17,286][root][INFO] - Training Epoch: 1/2, step 3985/7134 completed (loss: 0.07874990999698639, acc: 0.9821746945381165)
[2024-12-17 02:03:17,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:17,632][root][INFO] - Training Epoch: 1/2, step 3986/7134 completed (loss: 0.2768285274505615, acc: 0.9409090876579285)
[2024-12-17 02:03:17,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:17,979][root][INFO] - Training Epoch: 1/2, step 3987/7134 completed (loss: 0.1677878201007843, acc: 0.9616122841835022)
[2024-12-17 02:03:18,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:18,330][root][INFO] - Training Epoch: 1/2, step 3988/7134 completed (loss: 0.15983892977237701, acc: 0.9608091115951538)
[2024-12-17 02:03:18,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:18,581][root][INFO] - Training Epoch: 1/2, step 3989/7134 completed (loss: 0.315184623003006, acc: 0.9402984976768494)
[2024-12-17 02:03:18,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:18,915][root][INFO] - Training Epoch: 1/2, step 3990/7134 completed (loss: 0.11251694709062576, acc: 0.9701492786407471)
[2024-12-17 02:03:19,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:19,181][root][INFO] - Training Epoch: 1/2, step 3991/7134 completed (loss: 0.07729438692331314, acc: 0.9834983348846436)
[2024-12-17 02:03:19,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:19,490][root][INFO] - Training Epoch: 1/2, step 3992/7134 completed (loss: 0.14997631311416626, acc: 0.9648648500442505)
[2024-12-17 02:03:19,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:19,784][root][INFO] - Training Epoch: 1/2, step 3993/7134 completed (loss: 0.11418818682432175, acc: 0.9747706651687622)
[2024-12-17 02:03:19,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:20,070][root][INFO] - Training Epoch: 1/2, step 3994/7134 completed (loss: 0.1188584715127945, acc: 0.976190447807312)
[2024-12-17 02:03:20,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:20,360][root][INFO] - Training Epoch: 1/2, step 3995/7134 completed (loss: 0.16665314137935638, acc: 0.9593023061752319)
[2024-12-17 02:03:20,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:20,650][root][INFO] - Training Epoch: 1/2, step 3996/7134 completed (loss: 0.0877305194735527, acc: 0.9794661402702332)
[2024-12-17 02:03:20,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:20,951][root][INFO] - Training Epoch: 1/2, step 3997/7134 completed (loss: 0.29527103900909424, acc: 0.9428571462631226)
[2024-12-17 02:03:21,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:21,219][root][INFO] - Training Epoch: 1/2, step 3998/7134 completed (loss: 0.14943400025367737, acc: 0.9628008604049683)
[2024-12-17 02:03:21,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:21,518][root][INFO] - Training Epoch: 1/2, step 3999/7134 completed (loss: 0.0986795425415039, acc: 0.976047933101654)
[2024-12-17 02:03:21,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:21,840][root][INFO] - Training Epoch: 1/2, step 4000/7134 completed (loss: 0.13605336844921112, acc: 0.9749034643173218)
[2024-12-17 02:03:21,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:22,169][root][INFO] - Training Epoch: 1/2, step 4001/7134 completed (loss: 0.15218660235404968, acc: 0.9701789021492004)
[2024-12-17 02:03:22,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:22,493][root][INFO] - Training Epoch: 1/2, step 4002/7134 completed (loss: 0.18401430547237396, acc: 0.9590361714363098)
[2024-12-17 02:03:22,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:22,835][root][INFO] - Training Epoch: 1/2, step 4003/7134 completed (loss: 0.20272260904312134, acc: 0.9612545967102051)
[2024-12-17 02:03:22,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:23,132][root][INFO] - Training Epoch: 1/2, step 4004/7134 completed (loss: 0.12453050911426544, acc: 0.9696969985961914)
[2024-12-17 02:03:23,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:23,461][root][INFO] - Training Epoch: 1/2, step 4005/7134 completed (loss: 0.06721901148557663, acc: 0.9874411225318909)
[2024-12-17 02:03:23,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:23,837][root][INFO] - Training Epoch: 1/2, step 4006/7134 completed (loss: 0.08612535148859024, acc: 0.9791883230209351)
[2024-12-17 02:03:23,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:24,178][root][INFO] - Training Epoch: 1/2, step 4007/7134 completed (loss: 0.08969176560640335, acc: 0.9760119915008545)
[2024-12-17 02:03:24,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:24,542][root][INFO] - Training Epoch: 1/2, step 4008/7134 completed (loss: 0.05684104934334755, acc: 0.9841437339782715)
[2024-12-17 02:03:24,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:24,899][root][INFO] - Training Epoch: 1/2, step 4009/7134 completed (loss: 0.046245280653238297, acc: 0.9853528738021851)
[2024-12-17 02:03:25,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:25,262][root][INFO] - Training Epoch: 1/2, step 4010/7134 completed (loss: 0.03548053652048111, acc: 0.991051435470581)
[2024-12-17 02:03:25,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:25,618][root][INFO] - Training Epoch: 1/2, step 4011/7134 completed (loss: 0.07919260114431381, acc: 0.9827357530593872)
[2024-12-17 02:03:25,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:25,935][root][INFO] - Training Epoch: 1/2, step 4012/7134 completed (loss: 0.04819965362548828, acc: 0.9858757257461548)
[2024-12-17 02:03:26,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:26,290][root][INFO] - Training Epoch: 1/2, step 4013/7134 completed (loss: 0.05003685876727104, acc: 0.9855305552482605)
[2024-12-17 02:03:26,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:26,649][root][INFO] - Training Epoch: 1/2, step 4014/7134 completed (loss: 0.03800014406442642, acc: 0.9905956387519836)
[2024-12-17 02:03:26,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:26,982][root][INFO] - Training Epoch: 1/2, step 4015/7134 completed (loss: 0.03893114626407623, acc: 0.9831029176712036)
[2024-12-17 02:03:27,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:27,361][root][INFO] - Training Epoch: 1/2, step 4016/7134 completed (loss: 0.09606527537107468, acc: 0.9821428656578064)
[2024-12-17 02:03:27,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:27,720][root][INFO] - Training Epoch: 1/2, step 4017/7134 completed (loss: 0.08109918981790543, acc: 0.9815242290496826)
[2024-12-17 02:03:27,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:28,074][root][INFO] - Training Epoch: 1/2, step 4018/7134 completed (loss: 0.06945743411779404, acc: 0.9793939590454102)
[2024-12-17 02:03:28,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:28,413][root][INFO] - Training Epoch: 1/2, step 4019/7134 completed (loss: 0.06758727878332138, acc: 0.9835025668144226)
[2024-12-17 02:03:28,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:28,733][root][INFO] - Training Epoch: 1/2, step 4020/7134 completed (loss: 0.07075348496437073, acc: 0.9795082211494446)
[2024-12-17 02:03:28,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:29,064][root][INFO] - Training Epoch: 1/2, step 4021/7134 completed (loss: 0.088935486972332, acc: 0.9839572310447693)
[2024-12-17 02:03:29,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:29,411][root][INFO] - Training Epoch: 1/2, step 4022/7134 completed (loss: 0.07792378216981888, acc: 0.9889570474624634)
[2024-12-17 02:03:29,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:29,783][root][INFO] - Training Epoch: 1/2, step 4023/7134 completed (loss: 0.08290893584489822, acc: 0.9773585200309753)
[2024-12-17 02:03:29,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:30,126][root][INFO] - Training Epoch: 1/2, step 4024/7134 completed (loss: 0.11508037894964218, acc: 0.9790025949478149)
[2024-12-17 02:03:30,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:30,479][root][INFO] - Training Epoch: 1/2, step 4025/7134 completed (loss: 0.13672801852226257, acc: 0.9716874361038208)
[2024-12-17 02:03:30,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:30,819][root][INFO] - Training Epoch: 1/2, step 4026/7134 completed (loss: 0.17407344281673431, acc: 0.9631268382072449)
[2024-12-17 02:03:30,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:31,177][root][INFO] - Training Epoch: 1/2, step 4027/7134 completed (loss: 0.07884028553962708, acc: 0.9820144176483154)
[2024-12-17 02:03:31,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:31,522][root][INFO] - Training Epoch: 1/2, step 4028/7134 completed (loss: 0.09528789669275284, acc: 0.9672977328300476)
[2024-12-17 02:03:31,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:31,882][root][INFO] - Training Epoch: 1/2, step 4029/7134 completed (loss: 0.06551411002874374, acc: 0.9790897965431213)
[2024-12-17 02:03:31,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:32,221][root][INFO] - Training Epoch: 1/2, step 4030/7134 completed (loss: 0.05560087412595749, acc: 0.987679660320282)
[2024-12-17 02:03:32,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:32,543][root][INFO] - Training Epoch: 1/2, step 4031/7134 completed (loss: 0.07708047330379486, acc: 0.9780058860778809)
[2024-12-17 02:03:32,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:32,882][root][INFO] - Training Epoch: 1/2, step 4032/7134 completed (loss: 0.12696515023708344, acc: 0.9799196720123291)
[2024-12-17 02:03:33,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:33,214][root][INFO] - Training Epoch: 1/2, step 4033/7134 completed (loss: 0.041807450354099274, acc: 0.9874213933944702)
[2024-12-17 02:03:33,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:33,557][root][INFO] - Training Epoch: 1/2, step 4034/7134 completed (loss: 0.0340096578001976, acc: 0.9926918148994446)
[2024-12-17 02:03:33,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:33,965][root][INFO] - Training Epoch: 1/2, step 4035/7134 completed (loss: 0.08005325496196747, acc: 0.9846516847610474)
[2024-12-17 02:03:34,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:34,286][root][INFO] - Training Epoch: 1/2, step 4036/7134 completed (loss: 0.06140873208642006, acc: 0.9725274443626404)
[2024-12-17 02:03:34,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:34,653][root][INFO] - Training Epoch: 1/2, step 4037/7134 completed (loss: 0.04037139192223549, acc: 0.9891696572303772)
[2024-12-17 02:03:34,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:34,982][root][INFO] - Training Epoch: 1/2, step 4038/7134 completed (loss: 0.09995292872190475, acc: 0.9724896550178528)
[2024-12-17 02:03:35,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:35,294][root][INFO] - Training Epoch: 1/2, step 4039/7134 completed (loss: 0.08974141627550125, acc: 0.9702127575874329)
[2024-12-17 02:03:35,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:35,628][root][INFO] - Training Epoch: 1/2, step 4040/7134 completed (loss: 0.058085616677999496, acc: 0.9802955389022827)
[2024-12-17 02:03:35,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:35,983][root][INFO] - Training Epoch: 1/2, step 4041/7134 completed (loss: 0.07876680046319962, acc: 0.9811828136444092)
[2024-12-17 02:03:36,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:36,316][root][INFO] - Training Epoch: 1/2, step 4042/7134 completed (loss: 0.047243326902389526, acc: 0.9867647290229797)
[2024-12-17 02:03:36,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:36,624][root][INFO] - Training Epoch: 1/2, step 4043/7134 completed (loss: 0.0478711798787117, acc: 0.9823788404464722)
[2024-12-17 02:03:36,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:36,967][root][INFO] - Training Epoch: 1/2, step 4044/7134 completed (loss: 0.03732508420944214, acc: 0.9886363744735718)
[2024-12-17 02:03:37,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:37,316][root][INFO] - Training Epoch: 1/2, step 4045/7134 completed (loss: 0.09714455157518387, acc: 0.9708333611488342)
[2024-12-17 02:03:37,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:37,667][root][INFO] - Training Epoch: 1/2, step 4046/7134 completed (loss: 0.055645618587732315, acc: 0.9862637519836426)
[2024-12-17 02:03:37,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:38,023][root][INFO] - Training Epoch: 1/2, step 4047/7134 completed (loss: 0.08740825206041336, acc: 0.9809069037437439)
[2024-12-17 02:03:38,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:38,386][root][INFO] - Training Epoch: 1/2, step 4048/7134 completed (loss: 0.049384694546461105, acc: 0.9883449673652649)
[2024-12-17 02:03:38,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:38,785][root][INFO] - Training Epoch: 1/2, step 4049/7134 completed (loss: 0.05833262577652931, acc: 0.9850574731826782)
[2024-12-17 02:03:38,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:39,117][root][INFO] - Training Epoch: 1/2, step 4050/7134 completed (loss: 0.09778884053230286, acc: 0.980141818523407)
[2024-12-17 02:03:39,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:39,473][root][INFO] - Training Epoch: 1/2, step 4051/7134 completed (loss: 0.1266852617263794, acc: 0.9677033424377441)
[2024-12-17 02:03:39,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:39,787][root][INFO] - Training Epoch: 1/2, step 4052/7134 completed (loss: 0.052515849471092224, acc: 0.9832041263580322)
[2024-12-17 02:03:39,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:40,140][root][INFO] - Training Epoch: 1/2, step 4053/7134 completed (loss: 0.08293966203927994, acc: 0.9774535894393921)
[2024-12-17 02:03:40,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:40,492][root][INFO] - Training Epoch: 1/2, step 4054/7134 completed (loss: 0.061788998544216156, acc: 0.9860000014305115)
[2024-12-17 02:03:40,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:40,866][root][INFO] - Training Epoch: 1/2, step 4055/7134 completed (loss: 0.08869346231222153, acc: 0.9745145440101624)
[2024-12-17 02:03:40,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:41,226][root][INFO] - Training Epoch: 1/2, step 4056/7134 completed (loss: 0.057494524866342545, acc: 0.9830303192138672)
[2024-12-17 02:03:41,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:41,581][root][INFO] - Training Epoch: 1/2, step 4057/7134 completed (loss: 0.10051574558019638, acc: 0.977746844291687)
[2024-12-17 02:03:41,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:41,895][root][INFO] - Training Epoch: 1/2, step 4058/7134 completed (loss: 0.16025495529174805, acc: 0.9694072604179382)
[2024-12-17 02:03:42,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:42,218][root][INFO] - Training Epoch: 1/2, step 4059/7134 completed (loss: 0.09556053578853607, acc: 0.974452555179596)
[2024-12-17 02:03:42,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:42,549][root][INFO] - Training Epoch: 1/2, step 4060/7134 completed (loss: 0.06331469118595123, acc: 0.984544038772583)
[2024-12-17 02:03:42,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:42,912][root][INFO] - Training Epoch: 1/2, step 4061/7134 completed (loss: 0.04680223762989044, acc: 0.9871794581413269)
[2024-12-17 02:03:43,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:43,238][root][INFO] - Training Epoch: 1/2, step 4062/7134 completed (loss: 0.030214764177799225, acc: 0.9905511736869812)
[2024-12-17 02:03:43,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:43,578][root][INFO] - Training Epoch: 1/2, step 4063/7134 completed (loss: 0.05313185602426529, acc: 0.9858657121658325)
[2024-12-17 02:03:43,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:43,934][root][INFO] - Training Epoch: 1/2, step 4064/7134 completed (loss: 0.037080761045217514, acc: 0.9848713874816895)
[2024-12-17 02:03:44,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:44,280][root][INFO] - Training Epoch: 1/2, step 4065/7134 completed (loss: 0.0875018760561943, acc: 0.977931022644043)
[2024-12-17 02:03:44,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:44,642][root][INFO] - Training Epoch: 1/2, step 4066/7134 completed (loss: 0.043666642159223557, acc: 0.987500011920929)
[2024-12-17 02:03:44,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:44,970][root][INFO] - Training Epoch: 1/2, step 4067/7134 completed (loss: 0.049143336713314056, acc: 0.991830050945282)
[2024-12-17 02:03:45,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:45,300][root][INFO] - Training Epoch: 1/2, step 4068/7134 completed (loss: 0.049725331366062164, acc: 0.9851852059364319)
[2024-12-17 02:03:45,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:45,632][root][INFO] - Training Epoch: 1/2, step 4069/7134 completed (loss: 0.06212906539440155, acc: 0.9874804615974426)
[2024-12-17 02:03:45,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:45,963][root][INFO] - Training Epoch: 1/2, step 4070/7134 completed (loss: 0.04934819042682648, acc: 0.9878234267234802)
[2024-12-17 02:03:46,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:46,285][root][INFO] - Training Epoch: 1/2, step 4071/7134 completed (loss: 0.06778383255004883, acc: 0.9802306294441223)
[2024-12-17 02:03:46,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:46,628][root][INFO] - Training Epoch: 1/2, step 4072/7134 completed (loss: 0.03345753625035286, acc: 0.9927849769592285)
[2024-12-17 02:03:46,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:46,987][root][INFO] - Training Epoch: 1/2, step 4073/7134 completed (loss: 0.04349273070693016, acc: 0.9942528605461121)
[2024-12-17 02:03:47,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:47,331][root][INFO] - Training Epoch: 1/2, step 4074/7134 completed (loss: 0.05083555728197098, acc: 0.991416335105896)
[2024-12-17 02:03:47,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:47,671][root][INFO] - Training Epoch: 1/2, step 4075/7134 completed (loss: 0.04089757427573204, acc: 0.9925037622451782)
[2024-12-17 02:03:47,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:48,031][root][INFO] - Training Epoch: 1/2, step 4076/7134 completed (loss: 0.032368551939725876, acc: 0.9942113161087036)
[2024-12-17 02:03:48,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:48,386][root][INFO] - Training Epoch: 1/2, step 4077/7134 completed (loss: 0.07222942262887955, acc: 0.9813874959945679)
[2024-12-17 02:03:48,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:48,715][root][INFO] - Training Epoch: 1/2, step 4078/7134 completed (loss: 0.04216032475233078, acc: 0.9857549667358398)
[2024-12-17 02:03:48,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:48,982][root][INFO] - Training Epoch: 1/2, step 4079/7134 completed (loss: 0.09291426837444305, acc: 0.9839572310447693)
[2024-12-17 02:03:49,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:49,300][root][INFO] - Training Epoch: 1/2, step 4080/7134 completed (loss: 0.04358697682619095, acc: 0.9889240264892578)
[2024-12-17 02:03:49,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:49,609][root][INFO] - Training Epoch: 1/2, step 4081/7134 completed (loss: 0.021602943539619446, acc: 0.9933993220329285)
[2024-12-17 02:03:49,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:49,925][root][INFO] - Training Epoch: 1/2, step 4082/7134 completed (loss: 0.16387252509593964, acc: 0.9667282700538635)
[2024-12-17 02:03:50,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:50,257][root][INFO] - Training Epoch: 1/2, step 4083/7134 completed (loss: 0.07973843812942505, acc: 0.9790419340133667)
[2024-12-17 02:03:50,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:50,596][root][INFO] - Training Epoch: 1/2, step 4084/7134 completed (loss: 0.18619190156459808, acc: 0.9431372284889221)
[2024-12-17 02:03:50,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:50,952][root][INFO] - Training Epoch: 1/2, step 4085/7134 completed (loss: 0.0876062884926796, acc: 0.979784369468689)
[2024-12-17 02:03:51,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:51,279][root][INFO] - Training Epoch: 1/2, step 4086/7134 completed (loss: 0.12935549020767212, acc: 0.9705401062965393)
[2024-12-17 02:03:51,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:51,631][root][INFO] - Training Epoch: 1/2, step 4087/7134 completed (loss: 0.06021086126565933, acc: 0.9896640777587891)
[2024-12-17 02:03:51,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:51,978][root][INFO] - Training Epoch: 1/2, step 4088/7134 completed (loss: 0.1420658826828003, acc: 0.9601989984512329)
[2024-12-17 02:03:52,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:52,309][root][INFO] - Training Epoch: 1/2, step 4089/7134 completed (loss: 0.11561698466539383, acc: 0.9644760489463806)
[2024-12-17 02:03:52,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:52,641][root][INFO] - Training Epoch: 1/2, step 4090/7134 completed (loss: 0.15876199305057526, acc: 0.960422158241272)
[2024-12-17 02:03:52,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:52,963][root][INFO] - Training Epoch: 1/2, step 4091/7134 completed (loss: 0.19780908524990082, acc: 0.9578414559364319)
[2024-12-17 02:03:53,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:53,315][root][INFO] - Training Epoch: 1/2, step 4092/7134 completed (loss: 0.1257927268743515, acc: 0.9678249955177307)
[2024-12-17 02:03:53,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:53,618][root][INFO] - Training Epoch: 1/2, step 4093/7134 completed (loss: 0.08607564866542816, acc: 0.9799635410308838)
[2024-12-17 02:03:53,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:53,948][root][INFO] - Training Epoch: 1/2, step 4094/7134 completed (loss: 0.10978837311267853, acc: 0.9744744896888733)
[2024-12-17 02:03:54,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:54,313][root][INFO] - Training Epoch: 1/2, step 4095/7134 completed (loss: 0.06877819448709488, acc: 0.9797394871711731)
[2024-12-17 02:03:54,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:54,601][root][INFO] - Training Epoch: 1/2, step 4096/7134 completed (loss: 0.13247963786125183, acc: 0.9701492786407471)
[2024-12-17 02:03:54,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:54,992][root][INFO] - Training Epoch: 1/2, step 4097/7134 completed (loss: 0.13571619987487793, acc: 0.975806474685669)
[2024-12-17 02:03:55,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:55,332][root][INFO] - Training Epoch: 1/2, step 4098/7134 completed (loss: 0.09997335076332092, acc: 0.9796748161315918)
[2024-12-17 02:03:55,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:55,662][root][INFO] - Training Epoch: 1/2, step 4099/7134 completed (loss: 0.10309527814388275, acc: 0.9771126508712769)
[2024-12-17 02:03:55,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:56,039][root][INFO] - Training Epoch: 1/2, step 4100/7134 completed (loss: 0.03919666260480881, acc: 0.9909228682518005)
[2024-12-17 02:03:56,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:56,356][root][INFO] - Training Epoch: 1/2, step 4101/7134 completed (loss: 0.05603284016251564, acc: 0.982889711856842)
[2024-12-17 02:03:56,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:56,696][root][INFO] - Training Epoch: 1/2, step 4102/7134 completed (loss: 0.08906394988298416, acc: 0.9817184805870056)
[2024-12-17 02:03:56,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:57,034][root][INFO] - Training Epoch: 1/2, step 4103/7134 completed (loss: 0.016715126112103462, acc: 0.9970104694366455)
[2024-12-17 02:03:57,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:57,370][root][INFO] - Training Epoch: 1/2, step 4104/7134 completed (loss: 0.04742663726210594, acc: 0.9881556630134583)
[2024-12-17 02:03:57,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:57,708][root][INFO] - Training Epoch: 1/2, step 4105/7134 completed (loss: 0.057670898735523224, acc: 0.9848942756652832)
[2024-12-17 02:03:57,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:58,040][root][INFO] - Training Epoch: 1/2, step 4106/7134 completed (loss: 0.06776761263608932, acc: 0.9846625924110413)
[2024-12-17 02:03:58,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:58,357][root][INFO] - Training Epoch: 1/2, step 4107/7134 completed (loss: 0.05821516364812851, acc: 0.9932773113250732)
[2024-12-17 02:03:58,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:58,699][root][INFO] - Training Epoch: 1/2, step 4108/7134 completed (loss: 0.04663044959306717, acc: 0.9854369163513184)
[2024-12-17 02:03:58,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:59,060][root][INFO] - Training Epoch: 1/2, step 4109/7134 completed (loss: 0.03548954427242279, acc: 0.9935794472694397)
[2024-12-17 02:03:59,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:59,404][root][INFO] - Training Epoch: 1/2, step 4110/7134 completed (loss: 0.019428879022598267, acc: 0.9948979616165161)
[2024-12-17 02:03:59,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:59,755][root][INFO] - Training Epoch: 1/2, step 4111/7134 completed (loss: 0.034721288830041885, acc: 0.9858044385910034)
[2024-12-17 02:03:59,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:00,112][root][INFO] - Training Epoch: 1/2, step 4112/7134 completed (loss: 0.06504750996828079, acc: 0.9892473220825195)
[2024-12-17 02:04:00,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:00,453][root][INFO] - Training Epoch: 1/2, step 4113/7134 completed (loss: 0.08786981552839279, acc: 0.9751937985420227)
[2024-12-17 02:04:00,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:00,778][root][INFO] - Training Epoch: 1/2, step 4114/7134 completed (loss: 0.15709218382835388, acc: 0.9674796462059021)
[2024-12-17 02:04:00,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:01,105][root][INFO] - Training Epoch: 1/2, step 4115/7134 completed (loss: 0.15805530548095703, acc: 0.9514925479888916)
[2024-12-17 02:04:01,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:01,454][root][INFO] - Training Epoch: 1/2, step 4116/7134 completed (loss: 0.03800242021679878, acc: 0.9951140284538269)
[2024-12-17 02:04:01,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:01,790][root][INFO] - Training Epoch: 1/2, step 4117/7134 completed (loss: 0.06904244422912598, acc: 0.988959014415741)
[2024-12-17 02:04:01,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:02,065][root][INFO] - Training Epoch: 1/2, step 4118/7134 completed (loss: 0.050502415746450424, acc: 0.9877150058746338)
[2024-12-17 02:04:02,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:02,402][root][INFO] - Training Epoch: 1/2, step 4119/7134 completed (loss: 0.06623464822769165, acc: 0.9854604005813599)
[2024-12-17 02:04:02,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:02,720][root][INFO] - Training Epoch: 1/2, step 4120/7134 completed (loss: 0.05658428370952606, acc: 0.9884678721427917)
[2024-12-17 02:04:02,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:03,066][root][INFO] - Training Epoch: 1/2, step 4121/7134 completed (loss: 0.0677514374256134, acc: 0.9886363744735718)
[2024-12-17 02:04:03,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:03,393][root][INFO] - Training Epoch: 1/2, step 4122/7134 completed (loss: 0.03802400082349777, acc: 0.9904580116271973)
[2024-12-17 02:04:03,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:03,730][root][INFO] - Training Epoch: 1/2, step 4123/7134 completed (loss: 0.043138228356838226, acc: 0.9909502267837524)
[2024-12-17 02:04:03,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:04,073][root][INFO] - Training Epoch: 1/2, step 4124/7134 completed (loss: 0.057736121118068695, acc: 0.9900990128517151)
[2024-12-17 02:04:04,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:04,400][root][INFO] - Training Epoch: 1/2, step 4125/7134 completed (loss: 0.047097329050302505, acc: 0.9838235378265381)
[2024-12-17 02:04:04,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:04,734][root][INFO] - Training Epoch: 1/2, step 4126/7134 completed (loss: 0.0435846783220768, acc: 0.9957507252693176)
[2024-12-17 02:04:04,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:05,059][root][INFO] - Training Epoch: 1/2, step 4127/7134 completed (loss: 0.07181015610694885, acc: 0.9859374761581421)
[2024-12-17 02:04:05,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:05,390][root][INFO] - Training Epoch: 1/2, step 4128/7134 completed (loss: 0.028757842257618904, acc: 0.992175281047821)
[2024-12-17 02:04:05,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:05,760][root][INFO] - Training Epoch: 1/2, step 4129/7134 completed (loss: 0.033549025654792786, acc: 0.9910979270935059)
[2024-12-17 02:04:05,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:06,092][root][INFO] - Training Epoch: 1/2, step 4130/7134 completed (loss: 0.0480748675763607, acc: 0.9807322025299072)
[2024-12-17 02:04:06,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:06,411][root][INFO] - Training Epoch: 1/2, step 4131/7134 completed (loss: 0.02770826779305935, acc: 0.9907578825950623)
[2024-12-17 02:04:06,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:06,726][root][INFO] - Training Epoch: 1/2, step 4132/7134 completed (loss: 0.07015012949705124, acc: 0.9754464030265808)
[2024-12-17 02:04:06,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:07,019][root][INFO] - Training Epoch: 1/2, step 4133/7134 completed (loss: 0.08934993296861649, acc: 0.9777777791023254)
[2024-12-17 02:04:07,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:07,310][root][INFO] - Training Epoch: 1/2, step 4134/7134 completed (loss: 0.15489746630191803, acc: 0.9526066184043884)
[2024-12-17 02:04:07,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:07,645][root][INFO] - Training Epoch: 1/2, step 4135/7134 completed (loss: 0.04516751319169998, acc: 0.9857904314994812)
[2024-12-17 02:04:07,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:08,008][root][INFO] - Training Epoch: 1/2, step 4136/7134 completed (loss: 0.031157050281763077, acc: 0.991150438785553)
[2024-12-17 02:04:08,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:08,344][root][INFO] - Training Epoch: 1/2, step 4137/7134 completed (loss: 0.06107049807906151, acc: 0.98828125)
[2024-12-17 02:04:08,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:08,669][root][INFO] - Training Epoch: 1/2, step 4138/7134 completed (loss: 0.05381058529019356, acc: 0.9843260049819946)
[2024-12-17 02:04:08,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:08,974][root][INFO] - Training Epoch: 1/2, step 4139/7134 completed (loss: 0.043682195246219635, acc: 0.9892703890800476)
[2024-12-17 02:04:09,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:09,322][root][INFO] - Training Epoch: 1/2, step 4140/7134 completed (loss: 0.0860743522644043, acc: 0.9724137783050537)
[2024-12-17 02:04:09,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:09,713][root][INFO] - Training Epoch: 1/2, step 4141/7134 completed (loss: 0.22874940931797028, acc: 0.9512894153594971)
[2024-12-17 02:04:09,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:10,072][root][INFO] - Training Epoch: 1/2, step 4142/7134 completed (loss: 0.17287056148052216, acc: 0.9519450664520264)
[2024-12-17 02:04:10,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:10,447][root][INFO] - Training Epoch: 1/2, step 4143/7134 completed (loss: 0.09057221561670303, acc: 0.9765306115150452)
[2024-12-17 02:04:10,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:10,833][root][INFO] - Training Epoch: 1/2, step 4144/7134 completed (loss: 0.1627160608768463, acc: 0.9567198157310486)
[2024-12-17 02:04:11,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:11,229][root][INFO] - Training Epoch: 1/2, step 4145/7134 completed (loss: 0.15993958711624146, acc: 0.9548736214637756)
[2024-12-17 02:04:11,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:11,520][root][INFO] - Training Epoch: 1/2, step 4146/7134 completed (loss: 0.16633088886737823, acc: 0.9636363387107849)
[2024-12-17 02:04:11,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:11,861][root][INFO] - Training Epoch: 1/2, step 4147/7134 completed (loss: 0.16999126970767975, acc: 0.961685836315155)
[2024-12-17 02:04:11,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:12,188][root][INFO] - Training Epoch: 1/2, step 4148/7134 completed (loss: 0.31791478395462036, acc: 0.9247104525566101)
[2024-12-17 02:04:12,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:12,497][root][INFO] - Training Epoch: 1/2, step 4149/7134 completed (loss: 0.23386187851428986, acc: 0.9466666579246521)
[2024-12-17 02:04:12,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:12,820][root][INFO] - Training Epoch: 1/2, step 4150/7134 completed (loss: 0.22953347861766815, acc: 0.9376257658004761)
[2024-12-17 02:04:12,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:13,195][root][INFO] - Training Epoch: 1/2, step 4151/7134 completed (loss: 0.3165340721607208, acc: 0.9329710006713867)
[2024-12-17 02:04:13,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:13,543][root][INFO] - Training Epoch: 1/2, step 4152/7134 completed (loss: 0.14196176826953888, acc: 0.9598145484924316)
[2024-12-17 02:04:13,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:13,893][root][INFO] - Training Epoch: 1/2, step 4153/7134 completed (loss: 0.1958477795124054, acc: 0.9524539709091187)
[2024-12-17 02:04:13,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:14,276][root][INFO] - Training Epoch: 1/2, step 4154/7134 completed (loss: 0.16021960973739624, acc: 0.9594907164573669)
[2024-12-17 02:04:14,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:14,596][root][INFO] - Training Epoch: 1/2, step 4155/7134 completed (loss: 0.17469696700572968, acc: 0.9485419988632202)
[2024-12-17 02:04:14,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:14,951][root][INFO] - Training Epoch: 1/2, step 4156/7134 completed (loss: 0.1687835454940796, acc: 0.9513213038444519)
[2024-12-17 02:04:15,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:15,275][root][INFO] - Training Epoch: 1/2, step 4157/7134 completed (loss: 0.12047674506902695, acc: 0.9740518927574158)
[2024-12-17 02:04:15,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:15,611][root][INFO] - Training Epoch: 1/2, step 4158/7134 completed (loss: 0.28754451870918274, acc: 0.9331619739532471)
[2024-12-17 02:04:15,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:15,968][root][INFO] - Training Epoch: 1/2, step 4159/7134 completed (loss: 0.16893044114112854, acc: 0.9626485705375671)
[2024-12-17 02:04:16,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:16,321][root][INFO] - Training Epoch: 1/2, step 4160/7134 completed (loss: 0.19249935448169708, acc: 0.9358490705490112)
[2024-12-17 02:04:16,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:16,700][root][INFO] - Training Epoch: 1/2, step 4161/7134 completed (loss: 0.20896126329898834, acc: 0.9437751173973083)
[2024-12-17 02:04:16,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:17,031][root][INFO] - Training Epoch: 1/2, step 4162/7134 completed (loss: 0.15189018845558167, acc: 0.9642325043678284)
[2024-12-17 02:04:17,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:17,372][root][INFO] - Training Epoch: 1/2, step 4163/7134 completed (loss: 0.16162791848182678, acc: 0.9636913537979126)
[2024-12-17 02:04:17,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:17,703][root][INFO] - Training Epoch: 1/2, step 4164/7134 completed (loss: 0.14370664954185486, acc: 0.9738751649856567)
[2024-12-17 02:04:17,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:18,078][root][INFO] - Training Epoch: 1/2, step 4165/7134 completed (loss: 0.1129414513707161, acc: 0.9787765145301819)
[2024-12-17 02:04:18,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:18,432][root][INFO] - Training Epoch: 1/2, step 4166/7134 completed (loss: 0.09727499634027481, acc: 0.9735682606697083)
[2024-12-17 02:04:18,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:18,809][root][INFO] - Training Epoch: 1/2, step 4167/7134 completed (loss: 0.08275464177131653, acc: 0.9704861044883728)
[2024-12-17 02:04:18,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:19,174][root][INFO] - Training Epoch: 1/2, step 4168/7134 completed (loss: 0.09004748612642288, acc: 0.9704861044883728)
[2024-12-17 02:04:19,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:19,559][root][INFO] - Training Epoch: 1/2, step 4169/7134 completed (loss: 0.15684710443019867, acc: 0.9640971422195435)
[2024-12-17 02:04:19,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:19,947][root][INFO] - Training Epoch: 1/2, step 4170/7134 completed (loss: 0.21075282990932465, acc: 0.9554139971733093)
[2024-12-17 02:04:20,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:20,335][root][INFO] - Training Epoch: 1/2, step 4171/7134 completed (loss: 0.08224263042211533, acc: 0.9780853390693665)
[2024-12-17 02:04:20,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:20,674][root][INFO] - Training Epoch: 1/2, step 4172/7134 completed (loss: 0.13020600378513336, acc: 0.9638404250144958)
[2024-12-17 02:04:20,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:21,009][root][INFO] - Training Epoch: 1/2, step 4173/7134 completed (loss: 0.13230028748512268, acc: 0.9721029996871948)
[2024-12-17 02:04:21,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:21,323][root][INFO] - Training Epoch: 1/2, step 4174/7134 completed (loss: 0.03856533765792847, acc: 0.992337167263031)
[2024-12-17 02:04:21,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:21,685][root][INFO] - Training Epoch: 1/2, step 4175/7134 completed (loss: 0.06276694685220718, acc: 0.9879724979400635)
[2024-12-17 02:04:21,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:22,043][root][INFO] - Training Epoch: 1/2, step 4176/7134 completed (loss: 0.06196679547429085, acc: 0.9836065769195557)
[2024-12-17 02:04:22,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:22,421][root][INFO] - Training Epoch: 1/2, step 4177/7134 completed (loss: 0.051215142011642456, acc: 0.9908015727996826)
[2024-12-17 02:04:22,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:22,774][root][INFO] - Training Epoch: 1/2, step 4178/7134 completed (loss: 0.05399967357516289, acc: 0.9848942756652832)
[2024-12-17 02:04:22,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:23,149][root][INFO] - Training Epoch: 1/2, step 4179/7134 completed (loss: 0.05326709523797035, acc: 0.9816272854804993)
[2024-12-17 02:04:23,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:23,501][root][INFO] - Training Epoch: 1/2, step 4180/7134 completed (loss: 0.03899719938635826, acc: 0.991525411605835)
[2024-12-17 02:04:23,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:23,837][root][INFO] - Training Epoch: 1/2, step 4181/7134 completed (loss: 0.04708360508084297, acc: 0.985318124294281)
[2024-12-17 02:04:23,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:24,178][root][INFO] - Training Epoch: 1/2, step 4182/7134 completed (loss: 0.024983711540699005, acc: 0.9916550517082214)
[2024-12-17 02:04:24,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:24,548][root][INFO] - Training Epoch: 1/2, step 4183/7134 completed (loss: 0.06632528454065323, acc: 0.9833101630210876)
[2024-12-17 02:04:24,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:24,877][root][INFO] - Training Epoch: 1/2, step 4184/7134 completed (loss: 0.06972555816173553, acc: 0.9761273264884949)
[2024-12-17 02:04:24,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:25,233][root][INFO] - Training Epoch: 1/2, step 4185/7134 completed (loss: 0.021452926099300385, acc: 0.9954338073730469)
[2024-12-17 02:04:25,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:25,602][root][INFO] - Training Epoch: 1/2, step 4186/7134 completed (loss: 0.11736448109149933, acc: 0.9759325981140137)
[2024-12-17 02:04:25,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:25,923][root][INFO] - Training Epoch: 1/2, step 4187/7134 completed (loss: 0.019919758662581444, acc: 0.994140625)
[2024-12-17 02:04:26,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:26,279][root][INFO] - Training Epoch: 1/2, step 4188/7134 completed (loss: 0.030892806127667427, acc: 0.9925000071525574)
[2024-12-17 02:04:26,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:26,628][root][INFO] - Training Epoch: 1/2, step 4189/7134 completed (loss: 0.04449877515435219, acc: 0.9958041906356812)
[2024-12-17 02:04:26,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:26,975][root][INFO] - Training Epoch: 1/2, step 4190/7134 completed (loss: 0.04083205759525299, acc: 0.9886363744735718)
[2024-12-17 02:04:27,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:27,269][root][INFO] - Training Epoch: 1/2, step 4191/7134 completed (loss: 0.04646238684654236, acc: 0.9884792566299438)
[2024-12-17 02:04:27,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:27,629][root][INFO] - Training Epoch: 1/2, step 4192/7134 completed (loss: 0.060006942600011826, acc: 0.9840255379676819)
[2024-12-17 02:04:27,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:27,996][root][INFO] - Training Epoch: 1/2, step 4193/7134 completed (loss: 0.0575823113322258, acc: 0.9866310358047485)
[2024-12-17 02:04:28,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:28,352][root][INFO] - Training Epoch: 1/2, step 4194/7134 completed (loss: 0.015683365985751152, acc: 0.9939485788345337)
[2024-12-17 02:04:28,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:28,688][root][INFO] - Training Epoch: 1/2, step 4195/7134 completed (loss: 0.08835803717374802, acc: 0.9823848009109497)
[2024-12-17 02:04:28,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:29,017][root][INFO] - Training Epoch: 1/2, step 4196/7134 completed (loss: 0.04297705739736557, acc: 0.987889289855957)
[2024-12-17 02:04:29,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:29,404][root][INFO] - Training Epoch: 1/2, step 4197/7134 completed (loss: 0.08287597447633743, acc: 0.9793014526367188)
[2024-12-17 02:04:29,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:29,765][root][INFO] - Training Epoch: 1/2, step 4198/7134 completed (loss: 0.04795314371585846, acc: 0.9916666746139526)
[2024-12-17 02:04:29,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:30,102][root][INFO] - Training Epoch: 1/2, step 4199/7134 completed (loss: 0.0793115645647049, acc: 0.9817517995834351)
[2024-12-17 02:04:30,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:30,431][root][INFO] - Training Epoch: 1/2, step 4200/7134 completed (loss: 0.0714019238948822, acc: 0.9820788502693176)
[2024-12-17 02:04:30,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:30,772][root][INFO] - Training Epoch: 1/2, step 4201/7134 completed (loss: 0.03571216017007828, acc: 0.9880136847496033)
[2024-12-17 02:04:30,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:31,128][root][INFO] - Training Epoch: 1/2, step 4202/7134 completed (loss: 0.10108976811170578, acc: 0.9709302186965942)
[2024-12-17 02:04:31,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:31,500][root][INFO] - Training Epoch: 1/2, step 4203/7134 completed (loss: 0.09239259362220764, acc: 0.9765990376472473)
[2024-12-17 02:04:31,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:31,834][root][INFO] - Training Epoch: 1/2, step 4204/7134 completed (loss: 0.1383582055568695, acc: 0.9605262875556946)
[2024-12-17 02:04:31,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:32,152][root][INFO] - Training Epoch: 1/2, step 4205/7134 completed (loss: 0.12051335722208023, acc: 0.9669064879417419)
[2024-12-17 02:04:32,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:32,510][root][INFO] - Training Epoch: 1/2, step 4206/7134 completed (loss: 0.16563691198825836, acc: 0.9576869010925293)
[2024-12-17 02:04:32,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:32,846][root][INFO] - Training Epoch: 1/2, step 4207/7134 completed (loss: 0.1700892150402069, acc: 0.9633758068084717)
[2024-12-17 02:04:32,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:33,162][root][INFO] - Training Epoch: 1/2, step 4208/7134 completed (loss: 0.17229889333248138, acc: 0.9633173942565918)
[2024-12-17 02:04:33,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:33,492][root][INFO] - Training Epoch: 1/2, step 4209/7134 completed (loss: 0.16785727441310883, acc: 0.9645892381668091)
[2024-12-17 02:04:33,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:33,853][root][INFO] - Training Epoch: 1/2, step 4210/7134 completed (loss: 0.031743451952934265, acc: 0.9938650131225586)
[2024-12-17 02:04:33,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:34,118][root][INFO] - Training Epoch: 1/2, step 4211/7134 completed (loss: 0.08143309503793716, acc: 0.981566846370697)
[2024-12-17 02:04:34,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:34,418][root][INFO] - Training Epoch: 1/2, step 4212/7134 completed (loss: 0.07125569880008698, acc: 0.9819967150688171)
[2024-12-17 02:04:34,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:34,775][root][INFO] - Training Epoch: 1/2, step 4213/7134 completed (loss: 0.04780250042676926, acc: 0.9899857044219971)
[2024-12-17 02:04:34,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:35,138][root][INFO] - Training Epoch: 1/2, step 4214/7134 completed (loss: 0.1434573382139206, acc: 0.9626865386962891)
[2024-12-17 02:04:35,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:35,452][root][INFO] - Training Epoch: 1/2, step 4215/7134 completed (loss: 0.09565693140029907, acc: 0.9846153855323792)
[2024-12-17 02:04:35,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:35,778][root][INFO] - Training Epoch: 1/2, step 4216/7134 completed (loss: 0.08883487433195114, acc: 0.9835466146469116)
[2024-12-17 02:04:35,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:36,098][root][INFO] - Training Epoch: 1/2, step 4217/7134 completed (loss: 0.0562664270401001, acc: 0.9874125719070435)
[2024-12-17 02:04:36,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:36,423][root][INFO] - Training Epoch: 1/2, step 4218/7134 completed (loss: 0.17368756234645844, acc: 0.9628865718841553)
[2024-12-17 02:04:36,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:36,689][root][INFO] - Training Epoch: 1/2, step 4219/7134 completed (loss: 0.13558833301067352, acc: 0.9518072009086609)
[2024-12-17 02:04:36,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:37,047][root][INFO] - Training Epoch: 1/2, step 4220/7134 completed (loss: 0.08394897729158401, acc: 0.9798561334609985)
[2024-12-17 02:04:37,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:37,399][root][INFO] - Training Epoch: 1/2, step 4221/7134 completed (loss: 0.08359745144844055, acc: 0.9787610769271851)
[2024-12-17 02:04:37,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:37,705][root][INFO] - Training Epoch: 1/2, step 4222/7134 completed (loss: 0.18482628464698792, acc: 0.9688888788223267)
[2024-12-17 02:04:37,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:38,033][root][INFO] - Training Epoch: 1/2, step 4223/7134 completed (loss: 0.12869542837142944, acc: 0.9629139304161072)
[2024-12-17 02:04:38,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:38,353][root][INFO] - Training Epoch: 1/2, step 4224/7134 completed (loss: 0.14442899823188782, acc: 0.9676026105880737)
[2024-12-17 02:04:38,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:38,707][root][INFO] - Training Epoch: 1/2, step 4225/7134 completed (loss: 0.1250079870223999, acc: 0.9762309193611145)
[2024-12-17 02:04:38,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:39,067][root][INFO] - Training Epoch: 1/2, step 4226/7134 completed (loss: 0.12447521835565567, acc: 0.9655172228813171)
[2024-12-17 02:04:39,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:39,362][root][INFO] - Training Epoch: 1/2, step 4227/7134 completed (loss: 0.1568736732006073, acc: 0.9656019806861877)
[2024-12-17 02:04:39,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:39,685][root][INFO] - Training Epoch: 1/2, step 4228/7134 completed (loss: 0.1902635395526886, acc: 0.949999988079071)
[2024-12-17 02:04:39,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:40,002][root][INFO] - Training Epoch: 1/2, step 4229/7134 completed (loss: 0.1698986142873764, acc: 0.9643605947494507)
[2024-12-17 02:04:40,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:40,248][root][INFO] - Training Epoch: 1/2, step 4230/7134 completed (loss: 0.11449213325977325, acc: 0.9735293984413147)
[2024-12-17 02:04:40,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:40,585][root][INFO] - Training Epoch: 1/2, step 4231/7134 completed (loss: 0.22086329758167267, acc: 0.950276255607605)
[2024-12-17 02:04:40,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:40,915][root][INFO] - Training Epoch: 1/2, step 4232/7134 completed (loss: 0.20915086567401886, acc: 0.9511450529098511)
[2024-12-17 02:04:41,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:41,250][root][INFO] - Training Epoch: 1/2, step 4233/7134 completed (loss: 0.12698020040988922, acc: 0.9699499011039734)
[2024-12-17 02:04:41,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:41,587][root][INFO] - Training Epoch: 1/2, step 4234/7134 completed (loss: 0.1046505868434906, acc: 0.9841017723083496)
[2024-12-17 02:04:41,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:41,939][root][INFO] - Training Epoch: 1/2, step 4235/7134 completed (loss: 0.09737864881753922, acc: 0.9778831005096436)
[2024-12-17 02:04:42,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:42,251][root][INFO] - Training Epoch: 1/2, step 4236/7134 completed (loss: 0.035960521548986435, acc: 0.9949495196342468)
[2024-12-17 02:04:42,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:42,573][root][INFO] - Training Epoch: 1/2, step 4237/7134 completed (loss: 0.15162290632724762, acc: 0.9628865718841553)
[2024-12-17 02:04:42,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:42,916][root][INFO] - Training Epoch: 1/2, step 4238/7134 completed (loss: 0.1276734471321106, acc: 0.9754500985145569)
[2024-12-17 02:04:43,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:43,231][root][INFO] - Training Epoch: 1/2, step 4239/7134 completed (loss: 0.05679137632250786, acc: 0.9872000217437744)
[2024-12-17 02:04:43,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:43,578][root][INFO] - Training Epoch: 1/2, step 4240/7134 completed (loss: 0.10009942203760147, acc: 0.9806138873100281)
[2024-12-17 02:04:43,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:43,928][root][INFO] - Training Epoch: 1/2, step 4241/7134 completed (loss: 0.03192571923136711, acc: 0.9934924244880676)
[2024-12-17 02:04:44,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:44,215][root][INFO] - Training Epoch: 1/2, step 4242/7134 completed (loss: 0.087127685546875, acc: 0.9755011200904846)
[2024-12-17 02:04:44,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:44,562][root][INFO] - Training Epoch: 1/2, step 4243/7134 completed (loss: 0.12566424906253815, acc: 0.9746835231781006)
[2024-12-17 02:04:44,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:44,870][root][INFO] - Training Epoch: 1/2, step 4244/7134 completed (loss: 0.09219254553318024, acc: 0.9844789505004883)
[2024-12-17 02:04:44,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:45,163][root][INFO] - Training Epoch: 1/2, step 4245/7134 completed (loss: 0.08989723026752472, acc: 0.9877750873565674)
[2024-12-17 02:04:45,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:45,506][root][INFO] - Training Epoch: 1/2, step 4246/7134 completed (loss: 0.0919976681470871, acc: 0.9809825420379639)
[2024-12-17 02:04:45,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:45,825][root][INFO] - Training Epoch: 1/2, step 4247/7134 completed (loss: 0.09498811513185501, acc: 0.9732620120048523)
[2024-12-17 02:04:45,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:46,159][root][INFO] - Training Epoch: 1/2, step 4248/7134 completed (loss: 0.1287175863981247, acc: 0.9663461446762085)
[2024-12-17 02:04:46,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:46,533][root][INFO] - Training Epoch: 1/2, step 4249/7134 completed (loss: 0.09663332998752594, acc: 0.9793650507926941)
[2024-12-17 02:04:46,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:46,797][root][INFO] - Training Epoch: 1/2, step 4250/7134 completed (loss: 0.1261911541223526, acc: 0.9787685871124268)
[2024-12-17 02:04:46,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:47,121][root][INFO] - Training Epoch: 1/2, step 4251/7134 completed (loss: 0.08653255552053452, acc: 0.9819079041481018)
[2024-12-17 02:04:47,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:47,448][root][INFO] - Training Epoch: 1/2, step 4252/7134 completed (loss: 0.0866146981716156, acc: 0.9761525988578796)
[2024-12-17 02:04:47,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:47,778][root][INFO] - Training Epoch: 1/2, step 4253/7134 completed (loss: 0.08701718598604202, acc: 0.9761388301849365)
[2024-12-17 02:04:47,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:48,081][root][INFO] - Training Epoch: 1/2, step 4254/7134 completed (loss: 0.059897471219301224, acc: 0.9800498485565186)
[2024-12-17 02:04:48,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:48,432][root][INFO] - Training Epoch: 1/2, step 4255/7134 completed (loss: 0.08025114983320236, acc: 0.982876718044281)
[2024-12-17 02:04:48,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:48,758][root][INFO] - Training Epoch: 1/2, step 4256/7134 completed (loss: 0.06835462898015976, acc: 0.9796379804611206)
[2024-12-17 02:04:48,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:49,092][root][INFO] - Training Epoch: 1/2, step 4257/7134 completed (loss: 0.06089003384113312, acc: 0.9803921580314636)
[2024-12-17 02:04:49,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:49,425][root][INFO] - Training Epoch: 1/2, step 4258/7134 completed (loss: 0.03772556409239769, acc: 0.9866412281990051)
[2024-12-17 02:04:49,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:49,774][root][INFO] - Training Epoch: 1/2, step 4259/7134 completed (loss: 0.14382009208202362, acc: 0.9742120504379272)
[2024-12-17 02:04:49,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:50,121][root][INFO] - Training Epoch: 1/2, step 4260/7134 completed (loss: 0.050021253526210785, acc: 0.9855072498321533)
[2024-12-17 02:04:50,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:50,440][root][INFO] - Training Epoch: 1/2, step 4261/7134 completed (loss: 0.05847467854619026, acc: 0.9789674878120422)
[2024-12-17 02:04:50,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:50,782][root][INFO] - Training Epoch: 1/2, step 4262/7134 completed (loss: 0.10079575330018997, acc: 0.978090763092041)
[2024-12-17 02:04:50,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:51,110][root][INFO] - Training Epoch: 1/2, step 4263/7134 completed (loss: 0.11059769988059998, acc: 0.9831081032752991)
[2024-12-17 02:04:51,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:51,430][root][INFO] - Training Epoch: 1/2, step 4264/7134 completed (loss: 0.12517908215522766, acc: 0.9674593210220337)
[2024-12-17 02:04:51,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:51,771][root][INFO] - Training Epoch: 1/2, step 4265/7134 completed (loss: 0.07148229330778122, acc: 0.9823232293128967)
[2024-12-17 02:04:51,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:52,137][root][INFO] - Training Epoch: 1/2, step 4266/7134 completed (loss: 0.06770878285169601, acc: 0.9832335114479065)
[2024-12-17 02:04:52,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:52,504][root][INFO] - Training Epoch: 1/2, step 4267/7134 completed (loss: 0.07934889942407608, acc: 0.9793939590454102)
[2024-12-17 02:04:52,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:52,843][root][INFO] - Training Epoch: 1/2, step 4268/7134 completed (loss: 0.1722557097673416, acc: 0.9498997926712036)
[2024-12-17 02:04:52,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:53,210][root][INFO] - Training Epoch: 1/2, step 4269/7134 completed (loss: 0.29437127709388733, acc: 0.9266186952590942)
[2024-12-17 02:04:53,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:53,556][root][INFO] - Training Epoch: 1/2, step 4270/7134 completed (loss: 0.14540138840675354, acc: 0.9609375)
[2024-12-17 02:04:53,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:53,909][root][INFO] - Training Epoch: 1/2, step 4271/7134 completed (loss: 0.08662088960409164, acc: 0.9738480448722839)
[2024-12-17 02:04:53,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:54,277][root][INFO] - Training Epoch: 1/2, step 4272/7134 completed (loss: 0.09451661258935928, acc: 0.9788732528686523)
[2024-12-17 02:04:54,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:54,632][root][INFO] - Training Epoch: 1/2, step 4273/7134 completed (loss: 0.1079595610499382, acc: 0.9736511707305908)
[2024-12-17 02:04:54,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:55,003][root][INFO] - Training Epoch: 1/2, step 4274/7134 completed (loss: 0.1643364131450653, acc: 0.9579439163208008)
[2024-12-17 02:04:55,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:55,345][root][INFO] - Training Epoch: 1/2, step 4275/7134 completed (loss: 0.06143986061215401, acc: 0.9848484992980957)
[2024-12-17 02:04:55,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:55,697][root][INFO] - Training Epoch: 1/2, step 4276/7134 completed (loss: 0.10796750336885452, acc: 0.9664948582649231)
[2024-12-17 02:04:55,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:56,015][root][INFO] - Training Epoch: 1/2, step 4277/7134 completed (loss: 0.07302466779947281, acc: 0.9841269850730896)
[2024-12-17 02:04:56,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:56,366][root][INFO] - Training Epoch: 1/2, step 4278/7134 completed (loss: 0.1161075085401535, acc: 0.9691358208656311)
[2024-12-17 02:04:56,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:56,697][root][INFO] - Training Epoch: 1/2, step 4279/7134 completed (loss: 0.09489355981349945, acc: 0.9717261791229248)
[2024-12-17 02:04:56,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:57,051][root][INFO] - Training Epoch: 1/2, step 4280/7134 completed (loss: 0.053578440099954605, acc: 0.9841269850730896)
[2024-12-17 02:04:57,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:57,416][root][INFO] - Training Epoch: 1/2, step 4281/7134 completed (loss: 0.11457186192274094, acc: 0.9702970385551453)
[2024-12-17 02:04:57,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:57,760][root][INFO] - Training Epoch: 1/2, step 4282/7134 completed (loss: 0.030550656840205193, acc: 0.9925925731658936)
[2024-12-17 02:04:57,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:58,122][root][INFO] - Training Epoch: 1/2, step 4283/7134 completed (loss: 0.0644729882478714, acc: 0.9816513657569885)
[2024-12-17 02:04:58,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:58,415][root][INFO] - Training Epoch: 1/2, step 4284/7134 completed (loss: 0.12448220700025558, acc: 0.9728260636329651)
[2024-12-17 02:04:58,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:58,759][root][INFO] - Training Epoch: 1/2, step 4285/7134 completed (loss: 0.08200453966856003, acc: 0.9777397513389587)
[2024-12-17 02:04:58,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:59,068][root][INFO] - Training Epoch: 1/2, step 4286/7134 completed (loss: 0.07862351834774017, acc: 0.980215847492218)
[2024-12-17 02:04:59,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:59,410][root][INFO] - Training Epoch: 1/2, step 4287/7134 completed (loss: 0.11065156012773514, acc: 0.9703608155250549)
[2024-12-17 02:04:59,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:59,763][root][INFO] - Training Epoch: 1/2, step 4288/7134 completed (loss: 0.12316124141216278, acc: 0.9645389914512634)
[2024-12-17 02:04:59,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:00,130][root][INFO] - Training Epoch: 1/2, step 4289/7134 completed (loss: 0.09734752774238586, acc: 0.9729323387145996)
[2024-12-17 02:05:00,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:00,482][root][INFO] - Training Epoch: 1/2, step 4290/7134 completed (loss: 0.08096512407064438, acc: 0.981055498123169)
[2024-12-17 02:05:00,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:00,832][root][INFO] - Training Epoch: 1/2, step 4291/7134 completed (loss: 0.05792771652340889, acc: 0.9856972694396973)
[2024-12-17 02:05:00,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:01,163][root][INFO] - Training Epoch: 1/2, step 4292/7134 completed (loss: 0.04617544636130333, acc: 0.9894578456878662)
[2024-12-17 02:05:01,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:01,488][root][INFO] - Training Epoch: 1/2, step 4293/7134 completed (loss: 0.034253332763910294, acc: 0.9899193644523621)
[2024-12-17 02:05:01,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:01,812][root][INFO] - Training Epoch: 1/2, step 4294/7134 completed (loss: 0.06722621619701385, acc: 0.9810771346092224)
[2024-12-17 02:05:01,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:02,155][root][INFO] - Training Epoch: 1/2, step 4295/7134 completed (loss: 0.03931071609258652, acc: 0.9908758997917175)
[2024-12-17 02:05:02,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:02,478][root][INFO] - Training Epoch: 1/2, step 4296/7134 completed (loss: 0.055461276322603226, acc: 0.9878345727920532)
[2024-12-17 02:05:02,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:02,803][root][INFO] - Training Epoch: 1/2, step 4297/7134 completed (loss: 0.045281782746315, acc: 0.98591548204422)
[2024-12-17 02:05:02,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:03,139][root][INFO] - Training Epoch: 1/2, step 4298/7134 completed (loss: 0.06774629652500153, acc: 0.9862448573112488)
[2024-12-17 02:05:03,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:03,454][root][INFO] - Training Epoch: 1/2, step 4299/7134 completed (loss: 0.05892925709486008, acc: 0.9914039969444275)
[2024-12-17 02:05:03,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:03,775][root][INFO] - Training Epoch: 1/2, step 4300/7134 completed (loss: 0.04429683834314346, acc: 0.9890350699424744)
[2024-12-17 02:05:03,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:04,116][root][INFO] - Training Epoch: 1/2, step 4301/7134 completed (loss: 0.07558497786521912, acc: 0.980327844619751)
[2024-12-17 02:05:04,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:04,450][root][INFO] - Training Epoch: 1/2, step 4302/7134 completed (loss: 0.04595852643251419, acc: 0.9865671396255493)
[2024-12-17 02:05:04,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:04,804][root][INFO] - Training Epoch: 1/2, step 4303/7134 completed (loss: 0.07936921715736389, acc: 0.9809069037437439)
[2024-12-17 02:05:04,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:05,160][root][INFO] - Training Epoch: 1/2, step 4304/7134 completed (loss: 0.05806656926870346, acc: 0.98959881067276)
[2024-12-17 02:05:05,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:05,529][root][INFO] - Training Epoch: 1/2, step 4305/7134 completed (loss: 0.0758802741765976, acc: 0.98591548204422)
[2024-12-17 02:05:05,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:05,887][root][INFO] - Training Epoch: 1/2, step 4306/7134 completed (loss: 0.10976605117321014, acc: 0.9763469099998474)
[2024-12-17 02:05:05,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:06,234][root][INFO] - Training Epoch: 1/2, step 4307/7134 completed (loss: 0.13892069458961487, acc: 0.971107542514801)
[2024-12-17 02:05:06,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:06,599][root][INFO] - Training Epoch: 1/2, step 4308/7134 completed (loss: 0.059234194457530975, acc: 0.9872390031814575)
[2024-12-17 02:05:06,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:06,955][root][INFO] - Training Epoch: 1/2, step 4309/7134 completed (loss: 0.06261950731277466, acc: 0.9876695275306702)
[2024-12-17 02:05:07,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:07,304][root][INFO] - Training Epoch: 1/2, step 4310/7134 completed (loss: 0.05542528256773949, acc: 0.9847238659858704)
[2024-12-17 02:05:07,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:07,628][root][INFO] - Training Epoch: 1/2, step 4311/7134 completed (loss: 0.06505030393600464, acc: 0.9855072498321533)
[2024-12-17 02:05:07,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:07,951][root][INFO] - Training Epoch: 1/2, step 4312/7134 completed (loss: 0.039456311613321304, acc: 0.9850136041641235)
[2024-12-17 02:05:08,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:08,284][root][INFO] - Training Epoch: 1/2, step 4313/7134 completed (loss: 0.06298816949129105, acc: 0.9883117079734802)
[2024-12-17 02:05:08,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:08,614][root][INFO] - Training Epoch: 1/2, step 4314/7134 completed (loss: 0.05720935016870499, acc: 0.9833837151527405)
[2024-12-17 02:05:08,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:08,958][root][INFO] - Training Epoch: 1/2, step 4315/7134 completed (loss: 0.0742681547999382, acc: 0.9803921580314636)
[2024-12-17 02:05:09,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:09,305][root][INFO] - Training Epoch: 1/2, step 4316/7134 completed (loss: 0.077484630048275, acc: 0.9846938848495483)
[2024-12-17 02:05:09,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:09,653][root][INFO] - Training Epoch: 1/2, step 4317/7134 completed (loss: 0.07976198941469193, acc: 0.9801734685897827)
[2024-12-17 02:05:09,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:09,999][root][INFO] - Training Epoch: 1/2, step 4318/7134 completed (loss: 0.059599146246910095, acc: 0.9876681566238403)
[2024-12-17 02:05:10,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:10,375][root][INFO] - Training Epoch: 1/2, step 4319/7134 completed (loss: 0.031088899821043015, acc: 0.9955406785011292)
[2024-12-17 02:05:10,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:10,697][root][INFO] - Training Epoch: 1/2, step 4320/7134 completed (loss: 0.0389784537255764, acc: 0.9891892075538635)
[2024-12-17 02:05:10,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:10,979][root][INFO] - Training Epoch: 1/2, step 4321/7134 completed (loss: 0.0915965810418129, acc: 0.9653579592704773)
[2024-12-17 02:05:11,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:11,326][root][INFO] - Training Epoch: 1/2, step 4322/7134 completed (loss: 0.0938388928771019, acc: 0.9748427867889404)
[2024-12-17 02:05:11,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:11,641][root][INFO] - Training Epoch: 1/2, step 4323/7134 completed (loss: 0.1168384701013565, acc: 0.9749518036842346)
[2024-12-17 02:05:11,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:11,946][root][INFO] - Training Epoch: 1/2, step 4324/7134 completed (loss: 0.048466797918081284, acc: 0.9825581312179565)
[2024-12-17 02:05:12,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:12,276][root][INFO] - Training Epoch: 1/2, step 4325/7134 completed (loss: 0.04203687608242035, acc: 0.9856459498405457)
[2024-12-17 02:05:12,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:12,607][root][INFO] - Training Epoch: 1/2, step 4326/7134 completed (loss: 0.046197310090065, acc: 0.9894366264343262)
[2024-12-17 02:05:12,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:12,942][root][INFO] - Training Epoch: 1/2, step 4327/7134 completed (loss: 0.059323765337467194, acc: 0.9807692170143127)
[2024-12-17 02:05:13,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:13,296][root][INFO] - Training Epoch: 1/2, step 4328/7134 completed (loss: 0.09822475165128708, acc: 0.9793233275413513)
[2024-12-17 02:05:13,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:13,663][root][INFO] - Training Epoch: 1/2, step 4329/7134 completed (loss: 0.06486291438341141, acc: 0.9855832457542419)
[2024-12-17 02:05:13,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:13,960][root][INFO] - Training Epoch: 1/2, step 4330/7134 completed (loss: 0.08275377005338669, acc: 0.9765458703041077)
[2024-12-17 02:05:14,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:14,268][root][INFO] - Training Epoch: 1/2, step 4331/7134 completed (loss: 0.03124830685555935, acc: 0.9915013909339905)
[2024-12-17 02:05:14,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:14,594][root][INFO] - Training Epoch: 1/2, step 4332/7134 completed (loss: 0.1001194417476654, acc: 0.9733840227127075)
[2024-12-17 02:05:14,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:14,921][root][INFO] - Training Epoch: 1/2, step 4333/7134 completed (loss: 0.06859803199768066, acc: 0.9848254919052124)
[2024-12-17 02:05:15,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:15,275][root][INFO] - Training Epoch: 1/2, step 4334/7134 completed (loss: 0.12335249781608582, acc: 0.970059871673584)
[2024-12-17 02:05:15,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:15,596][root][INFO] - Training Epoch: 1/2, step 4335/7134 completed (loss: 0.06318257004022598, acc: 0.9858871102333069)
[2024-12-17 02:05:15,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:15,924][root][INFO] - Training Epoch: 1/2, step 4336/7134 completed (loss: 0.03672882542014122, acc: 0.9886731505393982)
[2024-12-17 02:05:16,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:16,249][root][INFO] - Training Epoch: 1/2, step 4337/7134 completed (loss: 0.044284068048000336, acc: 0.9889240264892578)
[2024-12-17 02:05:16,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:16,573][root][INFO] - Training Epoch: 1/2, step 4338/7134 completed (loss: 0.03672560304403305, acc: 0.9936808943748474)
[2024-12-17 02:05:16,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:16,902][root][INFO] - Training Epoch: 1/2, step 4339/7134 completed (loss: 0.07867488265037537, acc: 0.9795918464660645)
[2024-12-17 02:05:16,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:17,269][root][INFO] - Training Epoch: 1/2, step 4340/7134 completed (loss: 0.06269900500774384, acc: 0.9780405163764954)
[2024-12-17 02:05:17,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:17,600][root][INFO] - Training Epoch: 1/2, step 4341/7134 completed (loss: 0.10257181525230408, acc: 0.9777117371559143)
[2024-12-17 02:05:17,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:17,967][root][INFO] - Training Epoch: 1/2, step 4342/7134 completed (loss: 0.07881408929824829, acc: 0.9791666865348816)
[2024-12-17 02:05:18,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:18,308][root][INFO] - Training Epoch: 1/2, step 4343/7134 completed (loss: 0.04699358344078064, acc: 0.9900166392326355)
[2024-12-17 02:05:18,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:18,617][root][INFO] - Training Epoch: 1/2, step 4344/7134 completed (loss: 0.029748892411589622, acc: 0.9854469895362854)
[2024-12-17 02:05:18,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:18,914][root][INFO] - Training Epoch: 1/2, step 4345/7134 completed (loss: 0.04961176961660385, acc: 0.9813664555549622)
[2024-12-17 02:05:19,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:19,211][root][INFO] - Training Epoch: 1/2, step 4346/7134 completed (loss: 0.025631148368120193, acc: 0.9958592057228088)
[2024-12-17 02:05:19,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:19,535][root][INFO] - Training Epoch: 1/2, step 4347/7134 completed (loss: 0.08570868521928787, acc: 0.9787836074829102)
[2024-12-17 02:05:19,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:19,847][root][INFO] - Training Epoch: 1/2, step 4348/7134 completed (loss: 0.04644183814525604, acc: 0.9872000217437744)
[2024-12-17 02:05:19,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:20,135][root][INFO] - Training Epoch: 1/2, step 4349/7134 completed (loss: 0.06321068108081818, acc: 0.9792147874832153)
[2024-12-17 02:05:20,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:20,483][root][INFO] - Training Epoch: 1/2, step 4350/7134 completed (loss: 0.05875929445028305, acc: 0.9882199168205261)
[2024-12-17 02:05:20,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:20,812][root][INFO] - Training Epoch: 1/2, step 4351/7134 completed (loss: 0.09504484385251999, acc: 0.9753086566925049)
[2024-12-17 02:05:20,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:21,164][root][INFO] - Training Epoch: 1/2, step 4352/7134 completed (loss: 0.07559342682361603, acc: 0.9759188890457153)
[2024-12-17 02:05:21,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:21,514][root][INFO] - Training Epoch: 1/2, step 4353/7134 completed (loss: 0.07223186641931534, acc: 0.9801324605941772)
[2024-12-17 02:05:21,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:21,856][root][INFO] - Training Epoch: 1/2, step 4354/7134 completed (loss: 0.07048965245485306, acc: 0.981333315372467)
[2024-12-17 02:05:21,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:22,180][root][INFO] - Training Epoch: 1/2, step 4355/7134 completed (loss: 0.071450375020504, acc: 0.9799749851226807)
[2024-12-17 02:05:22,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:22,529][root][INFO] - Training Epoch: 1/2, step 4356/7134 completed (loss: 0.054866060614585876, acc: 0.9868578314781189)
[2024-12-17 02:05:22,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:22,872][root][INFO] - Training Epoch: 1/2, step 4357/7134 completed (loss: 0.09123128652572632, acc: 0.9748031497001648)
[2024-12-17 02:05:23,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:23,235][root][INFO] - Training Epoch: 1/2, step 4358/7134 completed (loss: 0.07876399904489517, acc: 0.973652720451355)
[2024-12-17 02:05:23,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:23,568][root][INFO] - Training Epoch: 1/2, step 4359/7134 completed (loss: 0.08267576992511749, acc: 0.9762282371520996)
[2024-12-17 02:05:23,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:23,884][root][INFO] - Training Epoch: 1/2, step 4360/7134 completed (loss: 0.09212924540042877, acc: 0.9776536226272583)
[2024-12-17 02:05:23,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:24,224][root][INFO] - Training Epoch: 1/2, step 4361/7134 completed (loss: 0.05463551729917526, acc: 0.9826589822769165)
[2024-12-17 02:05:24,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:24,573][root][INFO] - Training Epoch: 1/2, step 4362/7134 completed (loss: 0.07066972553730011, acc: 0.9839704036712646)
[2024-12-17 02:05:24,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:24,919][root][INFO] - Training Epoch: 1/2, step 4363/7134 completed (loss: 0.06935799866914749, acc: 0.9801653027534485)
[2024-12-17 02:05:25,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:25,233][root][INFO] - Training Epoch: 1/2, step 4364/7134 completed (loss: 0.054719261825084686, acc: 0.9828125238418579)
[2024-12-17 02:05:25,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:25,577][root][INFO] - Training Epoch: 1/2, step 4365/7134 completed (loss: 0.06865587085485458, acc: 0.9779874086380005)
[2024-12-17 02:05:25,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:25,933][root][INFO] - Training Epoch: 1/2, step 4366/7134 completed (loss: 0.10178542137145996, acc: 0.9729381203651428)
[2024-12-17 02:05:26,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:26,275][root][INFO] - Training Epoch: 1/2, step 4367/7134 completed (loss: 0.0654449537396431, acc: 0.982807993888855)
[2024-12-17 02:05:26,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:26,638][root][INFO] - Training Epoch: 1/2, step 4368/7134 completed (loss: 0.05515686050057411, acc: 0.988664984703064)
[2024-12-17 02:05:26,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:26,983][root][INFO] - Training Epoch: 1/2, step 4369/7134 completed (loss: 0.05384216457605362, acc: 0.9866666793823242)
[2024-12-17 02:05:27,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:27,343][root][INFO] - Training Epoch: 1/2, step 4370/7134 completed (loss: 0.08181753754615784, acc: 0.9810844659805298)
[2024-12-17 02:05:27,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:27,698][root][INFO] - Training Epoch: 1/2, step 4371/7134 completed (loss: 0.06923512369394302, acc: 0.9762532711029053)
[2024-12-17 02:05:27,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:28,021][root][INFO] - Training Epoch: 1/2, step 4372/7134 completed (loss: 0.07850785553455353, acc: 0.977624773979187)
[2024-12-17 02:05:28,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:28,360][root][INFO] - Training Epoch: 1/2, step 4373/7134 completed (loss: 0.07805929332971573, acc: 0.9774078726768494)
[2024-12-17 02:05:28,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:28,695][root][INFO] - Training Epoch: 1/2, step 4374/7134 completed (loss: 0.06163724139332771, acc: 0.9827337861061096)
[2024-12-17 02:05:28,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:29,047][root][INFO] - Training Epoch: 1/2, step 4375/7134 completed (loss: 0.03459024429321289, acc: 0.9909909963607788)
[2024-12-17 02:05:29,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:29,359][root][INFO] - Training Epoch: 1/2, step 4376/7134 completed (loss: 0.07594185322523117, acc: 0.970588207244873)
[2024-12-17 02:05:29,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:29,707][root][INFO] - Training Epoch: 1/2, step 4377/7134 completed (loss: 0.11224319785833359, acc: 0.9740419983863831)
[2024-12-17 02:05:29,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:30,045][root][INFO] - Training Epoch: 1/2, step 4378/7134 completed (loss: 0.07850655913352966, acc: 0.9803921580314636)
[2024-12-17 02:05:30,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:30,413][root][INFO] - Training Epoch: 1/2, step 4379/7134 completed (loss: 0.12730030715465546, acc: 0.9659090638160706)
[2024-12-17 02:05:30,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:30,722][root][INFO] - Training Epoch: 1/2, step 4380/7134 completed (loss: 0.08481881022453308, acc: 0.9737303256988525)
[2024-12-17 02:05:30,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:31,073][root][INFO] - Training Epoch: 1/2, step 4381/7134 completed (loss: 0.04753202199935913, acc: 0.9875862002372742)
[2024-12-17 02:05:31,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:31,381][root][INFO] - Training Epoch: 1/2, step 4382/7134 completed (loss: 0.06288667768239975, acc: 0.9761525988578796)
[2024-12-17 02:05:31,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:31,728][root][INFO] - Training Epoch: 1/2, step 4383/7134 completed (loss: 0.10424873977899551, acc: 0.9697386622428894)
[2024-12-17 02:05:31,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:32,048][root][INFO] - Training Epoch: 1/2, step 4384/7134 completed (loss: 0.07063157856464386, acc: 0.9824120402336121)
[2024-12-17 02:05:32,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:32,382][root][INFO] - Training Epoch: 1/2, step 4385/7134 completed (loss: 0.10375534743070602, acc: 0.9778357148170471)
[2024-12-17 02:05:32,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:32,725][root][INFO] - Training Epoch: 1/2, step 4386/7134 completed (loss: 0.11314716935157776, acc: 0.971563994884491)
[2024-12-17 02:05:32,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:33,079][root][INFO] - Training Epoch: 1/2, step 4387/7134 completed (loss: 0.1047205924987793, acc: 0.977455735206604)
[2024-12-17 02:05:33,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:33,403][root][INFO] - Training Epoch: 1/2, step 4388/7134 completed (loss: 0.10208871215581894, acc: 0.9658384919166565)
[2024-12-17 02:05:33,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:33,727][root][INFO] - Training Epoch: 1/2, step 4389/7134 completed (loss: 0.12993299961090088, acc: 0.9624795913696289)
[2024-12-17 02:05:33,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:34,086][root][INFO] - Training Epoch: 1/2, step 4390/7134 completed (loss: 0.1386185884475708, acc: 0.9677419066429138)
[2024-12-17 02:05:34,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:34,411][root][INFO] - Training Epoch: 1/2, step 4391/7134 completed (loss: 0.15141087770462036, acc: 0.9462540745735168)
[2024-12-17 02:05:34,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:34,765][root][INFO] - Training Epoch: 1/2, step 4392/7134 completed (loss: 0.0582193098962307, acc: 0.9877451062202454)
[2024-12-17 02:05:34,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:35,122][root][INFO] - Training Epoch: 1/2, step 4393/7134 completed (loss: 0.04668543115258217, acc: 0.9915611743927002)
[2024-12-17 02:05:35,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:35,474][root][INFO] - Training Epoch: 1/2, step 4394/7134 completed (loss: 0.06793969124555588, acc: 0.9858956336975098)
[2024-12-17 02:05:35,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:35,798][root][INFO] - Training Epoch: 1/2, step 4395/7134 completed (loss: 0.12463229149580002, acc: 0.9623233675956726)
[2024-12-17 02:05:35,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:36,113][root][INFO] - Training Epoch: 1/2, step 4396/7134 completed (loss: 0.17457208037376404, acc: 0.9579945802688599)
[2024-12-17 02:05:36,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:36,446][root][INFO] - Training Epoch: 1/2, step 4397/7134 completed (loss: 0.11605435609817505, acc: 0.9694117903709412)
[2024-12-17 02:05:36,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:36,782][root][INFO] - Training Epoch: 1/2, step 4398/7134 completed (loss: 0.039505816996097565, acc: 0.9848484992980957)
[2024-12-17 02:05:36,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:37,110][root][INFO] - Training Epoch: 1/2, step 4399/7134 completed (loss: 0.08302964270114899, acc: 0.979099690914154)
[2024-12-17 02:05:37,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:37,474][root][INFO] - Training Epoch: 1/2, step 4400/7134 completed (loss: 0.16217708587646484, acc: 0.9677819013595581)
[2024-12-17 02:05:37,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:37,782][root][INFO] - Training Epoch: 1/2, step 4401/7134 completed (loss: 0.15643325448036194, acc: 0.9637681245803833)
[2024-12-17 02:05:37,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:38,117][root][INFO] - Training Epoch: 1/2, step 4402/7134 completed (loss: 0.24384893476963043, acc: 0.9418604373931885)
[2024-12-17 02:05:38,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:38,462][root][INFO] - Training Epoch: 1/2, step 4403/7134 completed (loss: 0.37253203988075256, acc: 0.9183937907218933)
[2024-12-17 02:05:38,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:38,789][root][INFO] - Training Epoch: 1/2, step 4404/7134 completed (loss: 0.1893494576215744, acc: 0.958776593208313)
[2024-12-17 02:05:38,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:39,163][root][INFO] - Training Epoch: 1/2, step 4405/7134 completed (loss: 0.08523551374673843, acc: 0.9784017205238342)
[2024-12-17 02:05:39,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:39,542][root][INFO] - Training Epoch: 1/2, step 4406/7134 completed (loss: 0.08808575570583344, acc: 0.9732739329338074)
[2024-12-17 02:05:39,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:39,902][root][INFO] - Training Epoch: 1/2, step 4407/7134 completed (loss: 0.09915879368782043, acc: 0.973410427570343)
[2024-12-17 02:05:40,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:40,272][root][INFO] - Training Epoch: 1/2, step 4408/7134 completed (loss: 0.17275258898735046, acc: 0.9545983672142029)
[2024-12-17 02:05:40,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:40,627][root][INFO] - Training Epoch: 1/2, step 4409/7134 completed (loss: 0.19282343983650208, acc: 0.955990195274353)
[2024-12-17 02:05:40,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:40,940][root][INFO] - Training Epoch: 1/2, step 4410/7134 completed (loss: 0.16226419806480408, acc: 0.9623655676841736)
[2024-12-17 02:05:41,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:41,274][root][INFO] - Training Epoch: 1/2, step 4411/7134 completed (loss: 0.25644516944885254, acc: 0.9438849091529846)
[2024-12-17 02:05:41,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:41,605][root][INFO] - Training Epoch: 1/2, step 4412/7134 completed (loss: 0.33216577768325806, acc: 0.9266467094421387)
[2024-12-17 02:05:41,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:41,949][root][INFO] - Training Epoch: 1/2, step 4413/7134 completed (loss: 0.21602696180343628, acc: 0.9537414908409119)
[2024-12-17 02:05:42,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:42,273][root][INFO] - Training Epoch: 1/2, step 4414/7134 completed (loss: 0.0777713805437088, acc: 0.978672981262207)
[2024-12-17 02:05:42,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:42,625][root][INFO] - Training Epoch: 1/2, step 4415/7134 completed (loss: 0.15432673692703247, acc: 0.9576587677001953)
[2024-12-17 02:05:42,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:42,994][root][INFO] - Training Epoch: 1/2, step 4416/7134 completed (loss: 0.13071143627166748, acc: 0.967327892780304)
[2024-12-17 02:05:43,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:43,348][root][INFO] - Training Epoch: 1/2, step 4417/7134 completed (loss: 0.17165468633174896, acc: 0.9603365659713745)
[2024-12-17 02:05:43,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:43,698][root][INFO] - Training Epoch: 1/2, step 4418/7134 completed (loss: 0.13807453215122223, acc: 0.96875)
[2024-12-17 02:05:43,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:44,025][root][INFO] - Training Epoch: 1/2, step 4419/7134 completed (loss: 0.18033559620380402, acc: 0.9459134340286255)
[2024-12-17 02:05:44,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:44,375][root][INFO] - Training Epoch: 1/2, step 4420/7134 completed (loss: 0.1660211831331253, acc: 0.9598893523216248)
[2024-12-17 02:05:44,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:44,726][root][INFO] - Training Epoch: 1/2, step 4421/7134 completed (loss: 0.13547785580158234, acc: 0.9617547988891602)
[2024-12-17 02:05:44,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:45,074][root][INFO] - Training Epoch: 1/2, step 4422/7134 completed (loss: 0.1337737739086151, acc: 0.9623233675956726)
[2024-12-17 02:05:45,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:45,426][root][INFO] - Training Epoch: 1/2, step 4423/7134 completed (loss: 0.1465202271938324, acc: 0.9611872434616089)
[2024-12-17 02:05:45,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:45,781][root][INFO] - Training Epoch: 1/2, step 4424/7134 completed (loss: 0.1375429481267929, acc: 0.9594594836235046)
[2024-12-17 02:05:45,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:46,137][root][INFO] - Training Epoch: 1/2, step 4425/7134 completed (loss: 0.07992972433567047, acc: 0.973099410533905)
[2024-12-17 02:05:46,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:46,510][root][INFO] - Training Epoch: 1/2, step 4426/7134 completed (loss: 0.13717317581176758, acc: 0.9679421186447144)
[2024-12-17 02:05:46,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:46,793][root][INFO] - Training Epoch: 1/2, step 4427/7134 completed (loss: 0.2698517441749573, acc: 0.9542168378829956)
[2024-12-17 02:05:46,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:47,158][root][INFO] - Training Epoch: 1/2, step 4428/7134 completed (loss: 0.06270675361156464, acc: 0.9802817106246948)
[2024-12-17 02:05:47,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:47,422][root][INFO] - Training Epoch: 1/2, step 4429/7134 completed (loss: 0.20422275364398956, acc: 0.9536082744598389)
[2024-12-17 02:05:47,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:47,755][root][INFO] - Training Epoch: 1/2, step 4430/7134 completed (loss: 0.16423502564430237, acc: 0.9649389982223511)
[2024-12-17 02:05:47,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:48,070][root][INFO] - Training Epoch: 1/2, step 4431/7134 completed (loss: 0.14766794443130493, acc: 0.9595645666122437)
[2024-12-17 02:05:48,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:48,383][root][INFO] - Training Epoch: 1/2, step 4432/7134 completed (loss: 0.0734269842505455, acc: 0.981566846370697)
[2024-12-17 02:05:48,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:48,759][root][INFO] - Training Epoch: 1/2, step 4433/7134 completed (loss: 0.11606696248054504, acc: 0.9731934666633606)
[2024-12-17 02:05:48,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:49,104][root][INFO] - Training Epoch: 1/2, step 4434/7134 completed (loss: 0.10859833657741547, acc: 0.9744744896888733)
[2024-12-17 02:05:49,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:49,425][root][INFO] - Training Epoch: 1/2, step 4435/7134 completed (loss: 0.11889757215976715, acc: 0.972273588180542)
[2024-12-17 02:05:49,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:49,795][root][INFO] - Training Epoch: 1/2, step 4436/7134 completed (loss: 0.12742997705936432, acc: 0.9692737460136414)
[2024-12-17 02:05:49,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:50,138][root][INFO] - Training Epoch: 1/2, step 4437/7134 completed (loss: 0.04888766258955002, acc: 0.9868766665458679)
[2024-12-17 02:05:50,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:50,473][root][INFO] - Training Epoch: 1/2, step 4438/7134 completed (loss: 0.07158135622739792, acc: 0.9796609878540039)
[2024-12-17 02:05:50,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:50,807][root][INFO] - Training Epoch: 1/2, step 4439/7134 completed (loss: 0.05456271767616272, acc: 0.9886178970336914)
[2024-12-17 02:05:50,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:51,132][root][INFO] - Training Epoch: 1/2, step 4440/7134 completed (loss: 0.0529337078332901, acc: 0.9820442199707031)
[2024-12-17 02:05:51,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:51,519][root][INFO] - Training Epoch: 1/2, step 4441/7134 completed (loss: 0.09649673104286194, acc: 0.9708141088485718)
[2024-12-17 02:05:51,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:51,876][root][INFO] - Training Epoch: 1/2, step 4442/7134 completed (loss: 0.1222420185804367, acc: 0.9703989624977112)
[2024-12-17 02:05:52,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:52,237][root][INFO] - Training Epoch: 1/2, step 4443/7134 completed (loss: 0.07025118917226791, acc: 0.9807692170143127)
[2024-12-17 02:05:52,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:52,578][root][INFO] - Training Epoch: 1/2, step 4444/7134 completed (loss: 0.07495665550231934, acc: 0.9771615266799927)
[2024-12-17 02:05:52,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:52,907][root][INFO] - Training Epoch: 1/2, step 4445/7134 completed (loss: 0.13374119997024536, acc: 0.9692737460136414)
[2024-12-17 02:05:53,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:53,249][root][INFO] - Training Epoch: 1/2, step 4446/7134 completed (loss: 0.06509311497211456, acc: 0.9822866320610046)
[2024-12-17 02:05:53,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:53,618][root][INFO] - Training Epoch: 1/2, step 4447/7134 completed (loss: 0.06123088300228119, acc: 0.9834905862808228)
[2024-12-17 02:05:53,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:53,972][root][INFO] - Training Epoch: 1/2, step 4448/7134 completed (loss: 0.07387908548116684, acc: 0.9780621528625488)
[2024-12-17 02:05:54,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:54,278][root][INFO] - Training Epoch: 1/2, step 4449/7134 completed (loss: 0.18191775679588318, acc: 0.9591078162193298)
[2024-12-17 02:05:54,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:54,628][root][INFO] - Training Epoch: 1/2, step 4450/7134 completed (loss: 0.17383818328380585, acc: 0.9525926113128662)
[2024-12-17 02:05:54,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:54,954][root][INFO] - Training Epoch: 1/2, step 4451/7134 completed (loss: 0.17153459787368774, acc: 0.9618573784828186)
[2024-12-17 02:05:55,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:55,303][root][INFO] - Training Epoch: 1/2, step 4452/7134 completed (loss: 0.03757943958044052, acc: 0.9904000163078308)
[2024-12-17 02:05:55,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:55,650][root][INFO] - Training Epoch: 1/2, step 4453/7134 completed (loss: 0.07131969928741455, acc: 0.9808743000030518)
[2024-12-17 02:05:55,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:55,988][root][INFO] - Training Epoch: 1/2, step 4454/7134 completed (loss: 0.07874477654695511, acc: 0.9787535667419434)
[2024-12-17 02:05:56,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:56,295][root][INFO] - Training Epoch: 1/2, step 4455/7134 completed (loss: 0.20156188309192657, acc: 0.950276255607605)
[2024-12-17 02:05:56,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:56,637][root][INFO] - Training Epoch: 1/2, step 4456/7134 completed (loss: 0.0648658350110054, acc: 0.983818769454956)
[2024-12-17 02:05:56,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:56,921][root][INFO] - Training Epoch: 1/2, step 4457/7134 completed (loss: 0.14081856608390808, acc: 0.9588015079498291)
[2024-12-17 02:05:57,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:57,258][root][INFO] - Training Epoch: 1/2, step 4458/7134 completed (loss: 0.02777320332825184, acc: 0.9950900077819824)
[2024-12-17 02:05:57,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:57,609][root][INFO] - Training Epoch: 1/2, step 4459/7134 completed (loss: 0.040898531675338745, acc: 0.9876373410224915)
[2024-12-17 02:05:57,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:57,949][root][INFO] - Training Epoch: 1/2, step 4460/7134 completed (loss: 0.04875253140926361, acc: 0.9889975786209106)
[2024-12-17 02:05:58,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:58,290][root][INFO] - Training Epoch: 1/2, step 4461/7134 completed (loss: 0.10300234705209732, acc: 0.9827798008918762)
[2024-12-17 02:05:58,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:58,635][root][INFO] - Training Epoch: 1/2, step 4462/7134 completed (loss: 0.05102917551994324, acc: 0.9877384305000305)
[2024-12-17 02:05:58,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:58,993][root][INFO] - Training Epoch: 1/2, step 4463/7134 completed (loss: 0.06905670464038849, acc: 0.9823899269104004)
[2024-12-17 02:05:59,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:59,362][root][INFO] - Training Epoch: 1/2, step 4464/7134 completed (loss: 0.06749748438596725, acc: 0.9831365942955017)
[2024-12-17 02:05:59,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:59,717][root][INFO] - Training Epoch: 1/2, step 4465/7134 completed (loss: 0.07621481269598007, acc: 0.9832473993301392)
[2024-12-17 02:05:59,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:00,073][root][INFO] - Training Epoch: 1/2, step 4466/7134 completed (loss: 0.03989114239811897, acc: 0.9876543283462524)
[2024-12-17 02:06:00,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:00,434][root][INFO] - Training Epoch: 1/2, step 4467/7134 completed (loss: 0.06739170849323273, acc: 0.9824120402336121)
[2024-12-17 02:06:00,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:00,773][root][INFO] - Training Epoch: 1/2, step 4468/7134 completed (loss: 0.03358981013298035, acc: 0.9928656220436096)
[2024-12-17 02:06:00,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:01,125][root][INFO] - Training Epoch: 1/2, step 4469/7134 completed (loss: 0.08685457706451416, acc: 0.9780346751213074)
[2024-12-17 02:06:01,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:01,496][root][INFO] - Training Epoch: 1/2, step 4470/7134 completed (loss: 0.05576735734939575, acc: 0.9856353402137756)
[2024-12-17 02:06:01,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:01,844][root][INFO] - Training Epoch: 1/2, step 4471/7134 completed (loss: 0.032413750886917114, acc: 0.9901719689369202)
[2024-12-17 02:06:01,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:02,166][root][INFO] - Training Epoch: 1/2, step 4472/7134 completed (loss: 0.059722766280174255, acc: 0.9828721880912781)
[2024-12-17 02:06:02,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:02,496][root][INFO] - Training Epoch: 1/2, step 4473/7134 completed (loss: 0.11621339619159698, acc: 0.9677870869636536)
[2024-12-17 02:06:02,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:02,822][root][INFO] - Training Epoch: 1/2, step 4474/7134 completed (loss: 0.12157593667507172, acc: 0.9679219126701355)
[2024-12-17 02:06:02,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:03,176][root][INFO] - Training Epoch: 1/2, step 4475/7134 completed (loss: 0.16672059893608093, acc: 0.96277916431427)
[2024-12-17 02:06:03,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:03,534][root][INFO] - Training Epoch: 1/2, step 4476/7134 completed (loss: 0.09299008548259735, acc: 0.9794238805770874)
[2024-12-17 02:06:03,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:03,882][root][INFO] - Training Epoch: 1/2, step 4477/7134 completed (loss: 0.029578551650047302, acc: 0.9914425611495972)
[2024-12-17 02:06:03,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:04,236][root][INFO] - Training Epoch: 1/2, step 4478/7134 completed (loss: 0.04396602511405945, acc: 0.990111231803894)
[2024-12-17 02:06:04,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:04,567][root][INFO] - Training Epoch: 1/2, step 4479/7134 completed (loss: 0.04112551733851433, acc: 0.9878706336021423)
[2024-12-17 02:06:04,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:04,926][root][INFO] - Training Epoch: 1/2, step 4480/7134 completed (loss: 0.055602796375751495, acc: 0.9848130941390991)
[2024-12-17 02:06:05,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:05,285][root][INFO] - Training Epoch: 1/2, step 4481/7134 completed (loss: 0.0548228845000267, acc: 0.9871495366096497)
[2024-12-17 02:06:05,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:05,644][root][INFO] - Training Epoch: 1/2, step 4482/7134 completed (loss: 0.028562083840370178, acc: 0.9928057789802551)
[2024-12-17 02:06:05,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:05,970][root][INFO] - Training Epoch: 1/2, step 4483/7134 completed (loss: 0.03893430903553963, acc: 0.9910846948623657)
[2024-12-17 02:06:06,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:06,334][root][INFO] - Training Epoch: 1/2, step 4484/7134 completed (loss: 0.029978565871715546, acc: 0.9894179701805115)
[2024-12-17 02:06:06,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:06,662][root][INFO] - Training Epoch: 1/2, step 4485/7134 completed (loss: 0.016951264813542366, acc: 0.9969372153282166)
[2024-12-17 02:06:06,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:06,981][root][INFO] - Training Epoch: 1/2, step 4486/7134 completed (loss: 0.023351872339844704, acc: 0.9940298795700073)
[2024-12-17 02:06:07,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:07,319][root][INFO] - Training Epoch: 1/2, step 4487/7134 completed (loss: 0.03861137852072716, acc: 0.9889655113220215)
[2024-12-17 02:06:07,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:07,591][root][INFO] - Training Epoch: 1/2, step 4488/7134 completed (loss: 0.022756794467568398, acc: 0.9964028596878052)
[2024-12-17 02:06:07,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:07,936][root][INFO] - Training Epoch: 1/2, step 4489/7134 completed (loss: 0.04963923245668411, acc: 0.9845361113548279)
[2024-12-17 02:06:08,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:08,278][root][INFO] - Training Epoch: 1/2, step 4490/7134 completed (loss: 0.05636446923017502, acc: 0.9814814925193787)
[2024-12-17 02:06:08,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:08,605][root][INFO] - Training Epoch: 1/2, step 4491/7134 completed (loss: 0.030862608924508095, acc: 0.9906890392303467)
[2024-12-17 02:06:08,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:08,935][root][INFO] - Training Epoch: 1/2, step 4492/7134 completed (loss: 0.042408570647239685, acc: 0.9871323704719543)
[2024-12-17 02:06:09,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:09,259][root][INFO] - Training Epoch: 1/2, step 4493/7134 completed (loss: 0.04056825488805771, acc: 0.9903714060783386)
[2024-12-17 02:06:09,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:09,606][root][INFO] - Training Epoch: 1/2, step 4494/7134 completed (loss: 0.07220429927110672, acc: 0.9797394871711731)
[2024-12-17 02:06:09,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:09,958][root][INFO] - Training Epoch: 1/2, step 4495/7134 completed (loss: 0.05588160827755928, acc: 0.9910600185394287)
[2024-12-17 02:06:10,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:10,288][root][INFO] - Training Epoch: 1/2, step 4496/7134 completed (loss: 0.03970605507493019, acc: 0.9886040091514587)
[2024-12-17 02:06:10,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:10,612][root][INFO] - Training Epoch: 1/2, step 4497/7134 completed (loss: 0.03386962413787842, acc: 0.9920529723167419)
[2024-12-17 02:06:10,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:10,955][root][INFO] - Training Epoch: 1/2, step 4498/7134 completed (loss: 0.07737996429204941, acc: 0.9869375824928284)
[2024-12-17 02:06:11,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:11,227][root][INFO] - Training Epoch: 1/2, step 4499/7134 completed (loss: 0.06634876132011414, acc: 0.9843478202819824)
[2024-12-17 02:06:11,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:11,580][root][INFO] - Training Epoch: 1/2, step 4500/7134 completed (loss: 0.05239011347293854, acc: 0.9874125719070435)
[2024-12-17 02:06:11,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:11,925][root][INFO] - Training Epoch: 1/2, step 4501/7134 completed (loss: 0.031414009630680084, acc: 0.9917920827865601)
[2024-12-17 02:06:12,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:12,236][root][INFO] - Training Epoch: 1/2, step 4502/7134 completed (loss: 0.04301590099930763, acc: 0.9910045266151428)
[2024-12-17 02:06:12,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:12,564][root][INFO] - Training Epoch: 1/2, step 4503/7134 completed (loss: 0.019878026098012924, acc: 0.9967897534370422)
[2024-12-17 02:06:12,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:12,898][root][INFO] - Training Epoch: 1/2, step 4504/7134 completed (loss: 0.08782479166984558, acc: 0.974588930606842)
[2024-12-17 02:06:13,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:13,265][root][INFO] - Training Epoch: 1/2, step 4505/7134 completed (loss: 0.0702575296163559, acc: 0.9852579832077026)
[2024-12-17 02:06:13,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:13,595][root][INFO] - Training Epoch: 1/2, step 4506/7134 completed (loss: 0.048227738589048386, acc: 0.9845559597015381)
[2024-12-17 02:06:13,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:13,914][root][INFO] - Training Epoch: 1/2, step 4507/7134 completed (loss: 0.051675040274858475, acc: 0.9829303026199341)
[2024-12-17 02:06:14,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:14,246][root][INFO] - Training Epoch: 1/2, step 4508/7134 completed (loss: 0.0488864965736866, acc: 0.9914529919624329)
[2024-12-17 02:06:14,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:14,608][root][INFO] - Training Epoch: 1/2, step 4509/7134 completed (loss: 0.07127995043992996, acc: 0.9758388996124268)
[2024-12-17 02:06:14,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:14,966][root][INFO] - Training Epoch: 1/2, step 4510/7134 completed (loss: 0.07590977102518082, acc: 0.9816642999649048)
[2024-12-17 02:06:15,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:15,328][root][INFO] - Training Epoch: 1/2, step 4511/7134 completed (loss: 0.12520912289619446, acc: 0.9690576791763306)
[2024-12-17 02:06:15,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:15,659][root][INFO] - Training Epoch: 1/2, step 4512/7134 completed (loss: 0.11133093386888504, acc: 0.958781361579895)
[2024-12-17 02:06:15,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:16,014][root][INFO] - Training Epoch: 1/2, step 4513/7134 completed (loss: 0.049962397664785385, acc: 0.9859550595283508)
[2024-12-17 02:06:16,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:16,355][root][INFO] - Training Epoch: 1/2, step 4514/7134 completed (loss: 0.16727232933044434, acc: 0.9591240882873535)
[2024-12-17 02:06:16,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:16,702][root][INFO] - Training Epoch: 1/2, step 4515/7134 completed (loss: 0.10875992476940155, acc: 0.9686567187309265)
[2024-12-17 02:06:16,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:17,045][root][INFO] - Training Epoch: 1/2, step 4516/7134 completed (loss: 0.075625941157341, acc: 0.9767441749572754)
[2024-12-17 02:06:17,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:17,391][root][INFO] - Training Epoch: 1/2, step 4517/7134 completed (loss: 0.06308902055025101, acc: 0.9782330393791199)
[2024-12-17 02:06:17,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:17,744][root][INFO] - Training Epoch: 1/2, step 4518/7134 completed (loss: 0.12515489757061005, acc: 0.9681122303009033)
[2024-12-17 02:06:17,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:18,107][root][INFO] - Training Epoch: 1/2, step 4519/7134 completed (loss: 0.0662367045879364, acc: 0.9854897260665894)
[2024-12-17 02:06:18,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:18,454][root][INFO] - Training Epoch: 1/2, step 4520/7134 completed (loss: 0.10816626995801926, acc: 0.9632768630981445)
[2024-12-17 02:06:18,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:18,821][root][INFO] - Training Epoch: 1/2, step 4521/7134 completed (loss: 0.08480078727006912, acc: 0.9759325981140137)
[2024-12-17 02:06:18,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:19,187][root][INFO] - Training Epoch: 1/2, step 4522/7134 completed (loss: 0.11000716686248779, acc: 0.9672544002532959)
[2024-12-17 02:06:19,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:19,535][root][INFO] - Training Epoch: 1/2, step 4523/7134 completed (loss: 0.06969468295574188, acc: 0.9822485446929932)
[2024-12-17 02:06:19,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:19,903][root][INFO] - Training Epoch: 1/2, step 4524/7134 completed (loss: 0.08618470281362534, acc: 0.9797570705413818)
[2024-12-17 02:06:19,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:20,245][root][INFO] - Training Epoch: 1/2, step 4525/7134 completed (loss: 0.07607181370258331, acc: 0.9744444489479065)
[2024-12-17 02:06:20,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:20,565][root][INFO] - Training Epoch: 1/2, step 4526/7134 completed (loss: 0.11605460196733475, acc: 0.9703226089477539)
[2024-12-17 02:06:20,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:20,942][root][INFO] - Training Epoch: 1/2, step 4527/7134 completed (loss: 0.07916295528411865, acc: 0.9788182973861694)
[2024-12-17 02:06:21,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:21,302][root][INFO] - Training Epoch: 1/2, step 4528/7134 completed (loss: 0.1282678246498108, acc: 0.9678663015365601)
[2024-12-17 02:06:21,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:21,618][root][INFO] - Training Epoch: 1/2, step 4529/7134 completed (loss: 0.12007686495780945, acc: 0.9753885865211487)
[2024-12-17 02:06:21,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:21,953][root][INFO] - Training Epoch: 1/2, step 4530/7134 completed (loss: 0.0811280831694603, acc: 0.9719887971878052)
[2024-12-17 02:06:22,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:22,318][root][INFO] - Training Epoch: 1/2, step 4531/7134 completed (loss: 0.06313949078321457, acc: 0.9802513718605042)
[2024-12-17 02:06:22,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:22,686][root][INFO] - Training Epoch: 1/2, step 4532/7134 completed (loss: 0.09567265212535858, acc: 0.9760956168174744)
[2024-12-17 02:06:22,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:23,035][root][INFO] - Training Epoch: 1/2, step 4533/7134 completed (loss: 0.0745655968785286, acc: 0.9798339009284973)
[2024-12-17 02:06:23,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:23,375][root][INFO] - Training Epoch: 1/2, step 4534/7134 completed (loss: 0.05702144280076027, acc: 0.9882628917694092)
[2024-12-17 02:06:23,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:23,710][root][INFO] - Training Epoch: 1/2, step 4535/7134 completed (loss: 0.077938973903656, acc: 0.9760820269584656)
[2024-12-17 02:06:23,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:24,099][root][INFO] - Training Epoch: 1/2, step 4536/7134 completed (loss: 0.10567397624254227, acc: 0.9722222089767456)
[2024-12-17 02:06:24,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:24,465][root][INFO] - Training Epoch: 1/2, step 4537/7134 completed (loss: 0.040413133800029755, acc: 0.9888268113136292)
[2024-12-17 02:06:24,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:24,831][root][INFO] - Training Epoch: 1/2, step 4538/7134 completed (loss: 0.10185253620147705, acc: 0.9747126698493958)
[2024-12-17 02:06:24,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:25,198][root][INFO] - Training Epoch: 1/2, step 4539/7134 completed (loss: 0.06659164279699326, acc: 0.982740044593811)
[2024-12-17 02:06:25,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:25,558][root][INFO] - Training Epoch: 1/2, step 4540/7134 completed (loss: 0.07695358246564865, acc: 0.9783236980438232)
[2024-12-17 02:06:25,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:25,875][root][INFO] - Training Epoch: 1/2, step 4541/7134 completed (loss: 0.12103573977947235, acc: 0.9691991806030273)
[2024-12-17 02:06:25,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:26,172][root][INFO] - Training Epoch: 1/2, step 4542/7134 completed (loss: 0.11542161554098129, acc: 0.9653679728507996)
[2024-12-17 02:06:26,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:26,464][root][INFO] - Training Epoch: 1/2, step 4543/7134 completed (loss: 0.12908130884170532, acc: 0.9643493890762329)
[2024-12-17 02:06:26,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:26,801][root][INFO] - Training Epoch: 1/2, step 4544/7134 completed (loss: 0.07889427244663239, acc: 0.9771341681480408)
[2024-12-17 02:06:26,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:27,128][root][INFO] - Training Epoch: 1/2, step 4545/7134 completed (loss: 0.13232390582561493, acc: 0.963391125202179)
[2024-12-17 02:06:27,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:27,457][root][INFO] - Training Epoch: 1/2, step 4546/7134 completed (loss: 0.08404770493507385, acc: 0.9848739504814148)
[2024-12-17 02:06:27,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:27,785][root][INFO] - Training Epoch: 1/2, step 4547/7134 completed (loss: 0.04987313225865364, acc: 0.987889289855957)
[2024-12-17 02:06:27,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:28,132][root][INFO] - Training Epoch: 1/2, step 4548/7134 completed (loss: 0.07493278384208679, acc: 0.9784411191940308)
[2024-12-17 02:06:28,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:28,416][root][INFO] - Training Epoch: 1/2, step 4549/7134 completed (loss: 0.0876777246594429, acc: 0.9785407781600952)
[2024-12-17 02:06:28,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:28,788][root][INFO] - Training Epoch: 1/2, step 4550/7134 completed (loss: 0.12905728816986084, acc: 0.9681742191314697)
[2024-12-17 02:06:28,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:29,117][root][INFO] - Training Epoch: 1/2, step 4551/7134 completed (loss: 0.053972210735082626, acc: 0.9857142567634583)
[2024-12-17 02:06:29,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:29,438][root][INFO] - Training Epoch: 1/2, step 4552/7134 completed (loss: 0.08180177211761475, acc: 0.977142870426178)
[2024-12-17 02:06:29,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:29,752][root][INFO] - Training Epoch: 1/2, step 4553/7134 completed (loss: 0.07671136409044266, acc: 0.9864636063575745)
[2024-12-17 02:06:29,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:30,070][root][INFO] - Training Epoch: 1/2, step 4554/7134 completed (loss: 0.09858685731887817, acc: 0.9783783555030823)
[2024-12-17 02:06:30,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:30,410][root][INFO] - Training Epoch: 1/2, step 4555/7134 completed (loss: 0.13876718282699585, acc: 0.9695290923118591)
[2024-12-17 02:06:30,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:30,775][root][INFO] - Training Epoch: 1/2, step 4556/7134 completed (loss: 0.11092665046453476, acc: 0.969924807548523)
[2024-12-17 02:06:30,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:31,060][root][INFO] - Training Epoch: 1/2, step 4557/7134 completed (loss: 0.1280864179134369, acc: 0.970802903175354)
[2024-12-17 02:06:31,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:31,378][root][INFO] - Training Epoch: 1/2, step 4558/7134 completed (loss: 0.07213199138641357, acc: 0.9848484992980957)
[2024-12-17 02:06:31,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:31,708][root][INFO] - Training Epoch: 1/2, step 4559/7134 completed (loss: 0.07898474484682083, acc: 0.9865546226501465)
[2024-12-17 02:06:31,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:32,027][root][INFO] - Training Epoch: 1/2, step 4560/7134 completed (loss: 0.07478591799736023, acc: 0.97826087474823)
[2024-12-17 02:06:32,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:32,321][root][INFO] - Training Epoch: 1/2, step 4561/7134 completed (loss: 0.0821339339017868, acc: 0.9843137264251709)
[2024-12-17 02:06:32,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:32,647][root][INFO] - Training Epoch: 1/2, step 4562/7134 completed (loss: 0.0937308669090271, acc: 0.968692421913147)
[2024-12-17 02:06:32,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:32,996][root][INFO] - Training Epoch: 1/2, step 4563/7134 completed (loss: 0.06955834478139877, acc: 0.9832060933113098)
[2024-12-17 02:06:33,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:33,358][root][INFO] - Training Epoch: 1/2, step 4564/7134 completed (loss: 0.11150166392326355, acc: 0.9746121168136597)
[2024-12-17 02:06:33,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:33,665][root][INFO] - Training Epoch: 1/2, step 4565/7134 completed (loss: 0.08970016241073608, acc: 0.9789674878120422)
[2024-12-17 02:06:33,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:33,996][root][INFO] - Training Epoch: 1/2, step 4566/7134 completed (loss: 0.06110594794154167, acc: 0.9838709831237793)
[2024-12-17 02:06:34,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:34,299][root][INFO] - Training Epoch: 1/2, step 4567/7134 completed (loss: 0.04505689814686775, acc: 0.9908088445663452)
[2024-12-17 02:06:34,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:34,595][root][INFO] - Training Epoch: 1/2, step 4568/7134 completed (loss: 0.08482947945594788, acc: 0.9839449524879456)
[2024-12-17 02:06:34,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:34,920][root][INFO] - Training Epoch: 1/2, step 4569/7134 completed (loss: 0.06747552752494812, acc: 0.9823529124259949)
[2024-12-17 02:06:35,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:35,252][root][INFO] - Training Epoch: 1/2, step 4570/7134 completed (loss: 0.054324280470609665, acc: 0.9854227304458618)
[2024-12-17 02:06:35,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:35,598][root][INFO] - Training Epoch: 1/2, step 4571/7134 completed (loss: 0.05419163405895233, acc: 0.9833119511604309)
[2024-12-17 02:06:35,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:35,927][root][INFO] - Training Epoch: 1/2, step 4572/7134 completed (loss: 0.07595725357532501, acc: 0.9813084006309509)
[2024-12-17 02:06:36,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:36,272][root][INFO] - Training Epoch: 1/2, step 4573/7134 completed (loss: 0.06823183596134186, acc: 0.9831932783126831)
[2024-12-17 02:06:36,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:36,605][root][INFO] - Training Epoch: 1/2, step 4574/7134 completed (loss: 0.03702998906373978, acc: 0.9893993139266968)
[2024-12-17 02:06:36,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:36,951][root][INFO] - Training Epoch: 1/2, step 4575/7134 completed (loss: 0.06828537583351135, acc: 0.9840425252914429)
[2024-12-17 02:06:37,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:37,292][root][INFO] - Training Epoch: 1/2, step 4576/7134 completed (loss: 0.051069408655166626, acc: 0.9899623394012451)
[2024-12-17 02:06:37,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:37,625][root][INFO] - Training Epoch: 1/2, step 4577/7134 completed (loss: 0.07142416387796402, acc: 0.9775280952453613)
[2024-12-17 02:06:37,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:37,957][root][INFO] - Training Epoch: 1/2, step 4578/7134 completed (loss: 0.038428258150815964, acc: 0.9883551597595215)
[2024-12-17 02:06:38,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:38,279][root][INFO] - Training Epoch: 1/2, step 4579/7134 completed (loss: 0.07387388497591019, acc: 0.9841521382331848)
[2024-12-17 02:06:38,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:38,607][root][INFO] - Training Epoch: 1/2, step 4580/7134 completed (loss: 0.051936179399490356, acc: 0.9895522594451904)
[2024-12-17 02:06:38,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:38,937][root][INFO] - Training Epoch: 1/2, step 4581/7134 completed (loss: 0.05941607803106308, acc: 0.9876543283462524)
[2024-12-17 02:06:39,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:39,275][root][INFO] - Training Epoch: 1/2, step 4582/7134 completed (loss: 0.0458785779774189, acc: 0.9835526347160339)
[2024-12-17 02:06:39,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:39,585][root][INFO] - Training Epoch: 1/2, step 4583/7134 completed (loss: 0.056112319231033325, acc: 0.9869281053543091)
[2024-12-17 02:06:39,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:39,913][root][INFO] - Training Epoch: 1/2, step 4584/7134 completed (loss: 0.052981846034526825, acc: 0.9806763529777527)
[2024-12-17 02:06:40,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:40,257][root][INFO] - Training Epoch: 1/2, step 4585/7134 completed (loss: 0.08003289252519608, acc: 0.9757281541824341)
[2024-12-17 02:06:40,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:40,621][root][INFO] - Training Epoch: 1/2, step 4586/7134 completed (loss: 0.059377264231443405, acc: 0.9804941415786743)
[2024-12-17 02:06:40,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:40,969][root][INFO] - Training Epoch: 1/2, step 4587/7134 completed (loss: 0.06809777766466141, acc: 0.982191801071167)
[2024-12-17 02:06:41,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:41,325][root][INFO] - Training Epoch: 1/2, step 4588/7134 completed (loss: 0.08548995852470398, acc: 0.9767441749572754)
[2024-12-17 02:06:41,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:41,646][root][INFO] - Training Epoch: 1/2, step 4589/7134 completed (loss: 0.12189222872257233, acc: 0.9730538725852966)
[2024-12-17 02:06:41,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:41,994][root][INFO] - Training Epoch: 1/2, step 4590/7134 completed (loss: 0.07646487653255463, acc: 0.9820442199707031)
[2024-12-17 02:06:42,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:42,338][root][INFO] - Training Epoch: 1/2, step 4591/7134 completed (loss: 0.056571513414382935, acc: 0.9894459247589111)
[2024-12-17 02:06:42,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:42,661][root][INFO] - Training Epoch: 1/2, step 4592/7134 completed (loss: 0.06254125386476517, acc: 0.9840348362922668)
[2024-12-17 02:06:42,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:42,992][root][INFO] - Training Epoch: 1/2, step 4593/7134 completed (loss: 0.07885328680276871, acc: 0.9777777791023254)
[2024-12-17 02:06:43,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:43,359][root][INFO] - Training Epoch: 1/2, step 4594/7134 completed (loss: 0.0761534795165062, acc: 0.9760000109672546)
[2024-12-17 02:06:43,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:43,704][root][INFO] - Training Epoch: 1/2, step 4595/7134 completed (loss: 0.04092162847518921, acc: 0.98959881067276)
[2024-12-17 02:06:43,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:44,036][root][INFO] - Training Epoch: 1/2, step 4596/7134 completed (loss: 0.07587921619415283, acc: 0.9809523820877075)
[2024-12-17 02:06:44,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:44,383][root][INFO] - Training Epoch: 1/2, step 4597/7134 completed (loss: 0.06755068898200989, acc: 0.9829890727996826)
[2024-12-17 02:06:44,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:44,740][root][INFO] - Training Epoch: 1/2, step 4598/7134 completed (loss: 0.07457637041807175, acc: 0.9852761030197144)
[2024-12-17 02:06:44,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:45,062][root][INFO] - Training Epoch: 1/2, step 4599/7134 completed (loss: 0.04481160640716553, acc: 0.9872813820838928)
[2024-12-17 02:06:45,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:45,416][root][INFO] - Training Epoch: 1/2, step 4600/7134 completed (loss: 0.051029179245233536, acc: 0.9864681959152222)
[2024-12-17 02:06:45,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:45,794][root][INFO] - Training Epoch: 1/2, step 4601/7134 completed (loss: 0.07604033499956131, acc: 0.9817470908164978)
[2024-12-17 02:06:45,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:46,142][root][INFO] - Training Epoch: 1/2, step 4602/7134 completed (loss: 0.08732274174690247, acc: 0.9782016277313232)
[2024-12-17 02:06:46,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:46,491][root][INFO] - Training Epoch: 1/2, step 4603/7134 completed (loss: 0.07344695180654526, acc: 0.9806896448135376)
[2024-12-17 02:06:46,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:46,820][root][INFO] - Training Epoch: 1/2, step 4604/7134 completed (loss: 0.053065378218889236, acc: 0.9823434948921204)
[2024-12-17 02:06:46,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:47,156][root][INFO] - Training Epoch: 1/2, step 4605/7134 completed (loss: 0.100362129509449, acc: 0.9694322943687439)
[2024-12-17 02:06:47,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:47,518][root][INFO] - Training Epoch: 1/2, step 4606/7134 completed (loss: 0.04810023680329323, acc: 0.9831804037094116)
[2024-12-17 02:06:47,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:47,840][root][INFO] - Training Epoch: 1/2, step 4607/7134 completed (loss: 0.05676066502928734, acc: 0.9831649661064148)
[2024-12-17 02:06:47,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:48,182][root][INFO] - Training Epoch: 1/2, step 4608/7134 completed (loss: 0.03035481832921505, acc: 0.9911110997200012)
[2024-12-17 02:06:48,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:48,517][root][INFO] - Training Epoch: 1/2, step 4609/7134 completed (loss: 0.04080377146601677, acc: 0.9908257126808167)
[2024-12-17 02:06:48,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:48,867][root][INFO] - Training Epoch: 1/2, step 4610/7134 completed (loss: 0.03607110306620598, acc: 0.9880478382110596)
[2024-12-17 02:06:48,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:49,208][root][INFO] - Training Epoch: 1/2, step 4611/7134 completed (loss: 0.04385323449969292, acc: 0.9874804615974426)
[2024-12-17 02:06:49,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:49,508][root][INFO] - Training Epoch: 1/2, step 4612/7134 completed (loss: 0.053079068660736084, acc: 0.9851301312446594)
[2024-12-17 02:06:49,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:49,825][root][INFO] - Training Epoch: 1/2, step 4613/7134 completed (loss: 0.05062178149819374, acc: 0.984375)
[2024-12-17 02:06:49,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:50,147][root][INFO] - Training Epoch: 1/2, step 4614/7134 completed (loss: 0.06554242223501205, acc: 0.9848484992980957)
[2024-12-17 02:06:50,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:50,510][root][INFO] - Training Epoch: 1/2, step 4615/7134 completed (loss: 0.07346106320619583, acc: 0.9796472191810608)
[2024-12-17 02:06:50,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:50,846][root][INFO] - Training Epoch: 1/2, step 4616/7134 completed (loss: 0.07918195426464081, acc: 0.9778106212615967)
[2024-12-17 02:06:50,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:51,160][root][INFO] - Training Epoch: 1/2, step 4617/7134 completed (loss: 0.06229424849152565, acc: 0.9789789915084839)
[2024-12-17 02:06:51,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:51,515][root][INFO] - Training Epoch: 1/2, step 4618/7134 completed (loss: 0.07461364567279816, acc: 0.9611650705337524)
[2024-12-17 02:06:51,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:51,875][root][INFO] - Training Epoch: 1/2, step 4619/7134 completed (loss: 0.027889052405953407, acc: 0.9894419312477112)
[2024-12-17 02:06:51,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:52,236][root][INFO] - Training Epoch: 1/2, step 4620/7134 completed (loss: 0.06052461639046669, acc: 0.9797101616859436)
[2024-12-17 02:06:52,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:52,562][root][INFO] - Training Epoch: 1/2, step 4621/7134 completed (loss: 0.043998852372169495, acc: 0.9876543283462524)
[2024-12-17 02:06:52,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:52,898][root][INFO] - Training Epoch: 1/2, step 4622/7134 completed (loss: 0.0715019702911377, acc: 0.9862671494483948)
[2024-12-17 02:06:53,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:53,230][root][INFO] - Training Epoch: 1/2, step 4623/7134 completed (loss: 0.07343500107526779, acc: 0.9816993474960327)
[2024-12-17 02:06:53,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:53,652][root][INFO] - Training Epoch: 1/2, step 4624/7134 completed (loss: 0.11939416080713272, acc: 0.9711934328079224)
[2024-12-17 02:06:53,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:53,976][root][INFO] - Training Epoch: 1/2, step 4625/7134 completed (loss: 0.13866138458251953, acc: 0.9638752341270447)
[2024-12-17 02:06:54,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:54,324][root][INFO] - Training Epoch: 1/2, step 4626/7134 completed (loss: 0.10094261169433594, acc: 0.9731543660163879)
[2024-12-17 02:06:54,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:54,648][root][INFO] - Training Epoch: 1/2, step 4627/7134 completed (loss: 0.16017933189868927, acc: 0.9559939503669739)
[2024-12-17 02:06:54,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:55,009][root][INFO] - Training Epoch: 1/2, step 4628/7134 completed (loss: 0.11138948053121567, acc: 0.9739130139350891)
[2024-12-17 02:06:55,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:55,362][root][INFO] - Training Epoch: 1/2, step 4629/7134 completed (loss: 0.16208979487419128, acc: 0.9658119678497314)
[2024-12-17 02:06:55,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:55,738][root][INFO] - Training Epoch: 1/2, step 4630/7134 completed (loss: 0.09842659533023834, acc: 0.9801849126815796)
[2024-12-17 02:06:55,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:56,099][root][INFO] - Training Epoch: 1/2, step 4631/7134 completed (loss: 0.12174338847398758, acc: 0.9679203629493713)
[2024-12-17 02:06:56,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:56,473][root][INFO] - Training Epoch: 1/2, step 4632/7134 completed (loss: 0.11022964864969254, acc: 0.9779411554336548)
[2024-12-17 02:06:56,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:56,820][root][INFO] - Training Epoch: 1/2, step 4633/7134 completed (loss: 0.1406627744436264, acc: 0.9606936573982239)
[2024-12-17 02:06:56,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:57,153][root][INFO] - Training Epoch: 1/2, step 4634/7134 completed (loss: 0.08821415901184082, acc: 0.9825242757797241)
[2024-12-17 02:06:57,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:57,465][root][INFO] - Training Epoch: 1/2, step 4635/7134 completed (loss: 0.16134382784366608, acc: 0.9679877758026123)
[2024-12-17 02:06:57,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:57,740][root][INFO] - Training Epoch: 1/2, step 4636/7134 completed (loss: 0.03951771557331085, acc: 0.9896907210350037)
[2024-12-17 02:06:57,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:58,096][root][INFO] - Training Epoch: 1/2, step 4637/7134 completed (loss: 0.12026264518499374, acc: 0.9677419066429138)
[2024-12-17 02:06:58,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:58,438][root][INFO] - Training Epoch: 1/2, step 4638/7134 completed (loss: 0.09628267586231232, acc: 0.9643328785896301)
[2024-12-17 02:06:58,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:58,780][root][INFO] - Training Epoch: 1/2, step 4639/7134 completed (loss: 0.0983375683426857, acc: 0.9768856167793274)
[2024-12-17 02:06:58,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:59,161][root][INFO] - Training Epoch: 1/2, step 4640/7134 completed (loss: 0.11752548068761826, acc: 0.971794843673706)
[2024-12-17 02:06:59,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:59,505][root][INFO] - Training Epoch: 1/2, step 4641/7134 completed (loss: 0.07317092269659042, acc: 0.9758522510528564)
[2024-12-17 02:06:59,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:59,851][root][INFO] - Training Epoch: 1/2, step 4642/7134 completed (loss: 0.053621530532836914, acc: 0.9854497313499451)
[2024-12-17 02:06:59,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:00,216][root][INFO] - Training Epoch: 1/2, step 4643/7134 completed (loss: 0.06761123985052109, acc: 0.9869822263717651)
[2024-12-17 02:07:00,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:00,583][root][INFO] - Training Epoch: 1/2, step 4644/7134 completed (loss: 0.06025249883532524, acc: 0.9822485446929932)
[2024-12-17 02:07:00,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:00,939][root][INFO] - Training Epoch: 1/2, step 4645/7134 completed (loss: 0.06509464234113693, acc: 0.9860917925834656)
[2024-12-17 02:07:01,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:01,286][root][INFO] - Training Epoch: 1/2, step 4646/7134 completed (loss: 0.07189076393842697, acc: 0.9858712553977966)
[2024-12-17 02:07:01,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:01,658][root][INFO] - Training Epoch: 1/2, step 4647/7134 completed (loss: 0.11787565797567368, acc: 0.9791666865348816)
[2024-12-17 02:07:01,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:02,011][root][INFO] - Training Epoch: 1/2, step 4648/7134 completed (loss: 0.07913894206285477, acc: 0.9780521392822266)
[2024-12-17 02:07:02,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:02,369][root][INFO] - Training Epoch: 1/2, step 4649/7134 completed (loss: 0.07639414072036743, acc: 0.9807355403900146)
[2024-12-17 02:07:02,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:02,748][root][INFO] - Training Epoch: 1/2, step 4650/7134 completed (loss: 0.10225599259138107, acc: 0.96875)
[2024-12-17 02:07:02,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:03,084][root][INFO] - Training Epoch: 1/2, step 4651/7134 completed (loss: 0.19881245493888855, acc: 0.9493029117584229)
[2024-12-17 02:07:03,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:03,424][root][INFO] - Training Epoch: 1/2, step 4652/7134 completed (loss: 0.07478158921003342, acc: 0.9847561120986938)
[2024-12-17 02:07:03,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:03,794][root][INFO] - Training Epoch: 1/2, step 4653/7134 completed (loss: 0.11861251294612885, acc: 0.9645161032676697)
[2024-12-17 02:07:03,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:04,149][root][INFO] - Training Epoch: 1/2, step 4654/7134 completed (loss: 0.12359674274921417, acc: 0.9671132564544678)
[2024-12-17 02:07:04,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:04,495][root][INFO] - Training Epoch: 1/2, step 4655/7134 completed (loss: 0.07367072999477386, acc: 0.9822161197662354)
[2024-12-17 02:07:04,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:04,865][root][INFO] - Training Epoch: 1/2, step 4656/7134 completed (loss: 0.08204127848148346, acc: 0.9753788113594055)
[2024-12-17 02:07:04,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:05,195][root][INFO] - Training Epoch: 1/2, step 4657/7134 completed (loss: 0.09345448762178421, acc: 0.9759206771850586)
[2024-12-17 02:07:05,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:05,528][root][INFO] - Training Epoch: 1/2, step 4658/7134 completed (loss: 0.10411147028207779, acc: 0.9715832471847534)
[2024-12-17 02:07:05,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:05,902][root][INFO] - Training Epoch: 1/2, step 4659/7134 completed (loss: 0.18029873073101044, acc: 0.9601542353630066)
[2024-12-17 02:07:05,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:06,254][root][INFO] - Training Epoch: 1/2, step 4660/7134 completed (loss: 0.17273280024528503, acc: 0.9545454382896423)
[2024-12-17 02:07:06,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:06,568][root][INFO] - Training Epoch: 1/2, step 4661/7134 completed (loss: 0.09760178625583649, acc: 0.9740853905677795)
[2024-12-17 02:07:06,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:06,882][root][INFO] - Training Epoch: 1/2, step 4662/7134 completed (loss: 0.1347038596868515, acc: 0.9693877696990967)
[2024-12-17 02:07:06,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:07,235][root][INFO] - Training Epoch: 1/2, step 4663/7134 completed (loss: 0.08220928907394409, acc: 0.9799465537071228)
[2024-12-17 02:07:07,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:07,592][root][INFO] - Training Epoch: 1/2, step 4664/7134 completed (loss: 0.07626993209123611, acc: 0.9762219190597534)
[2024-12-17 02:07:07,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:07,925][root][INFO] - Training Epoch: 1/2, step 4665/7134 completed (loss: 0.06723993271589279, acc: 0.9904502034187317)
[2024-12-17 02:07:08,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:08,289][root][INFO] - Training Epoch: 1/2, step 4666/7134 completed (loss: 0.14347997307777405, acc: 0.9647979140281677)
[2024-12-17 02:07:08,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:08,625][root][INFO] - Training Epoch: 1/2, step 4667/7134 completed (loss: 0.10665406286716461, acc: 0.9672977328300476)
[2024-12-17 02:07:08,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:08,957][root][INFO] - Training Epoch: 1/2, step 4668/7134 completed (loss: 0.09950952976942062, acc: 0.9713261723518372)
[2024-12-17 02:07:09,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:09,300][root][INFO] - Training Epoch: 1/2, step 4669/7134 completed (loss: 0.052952490746974945, acc: 0.9881656765937805)
[2024-12-17 02:07:09,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:09,616][root][INFO] - Training Epoch: 1/2, step 4670/7134 completed (loss: 0.12103855609893799, acc: 0.9688109159469604)
[2024-12-17 02:07:09,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:09,957][root][INFO] - Training Epoch: 1/2, step 4671/7134 completed (loss: 0.08510191738605499, acc: 0.9788434505462646)
[2024-12-17 02:07:10,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:10,285][root][INFO] - Training Epoch: 1/2, step 4672/7134 completed (loss: 0.14679090678691864, acc: 0.9651567935943604)
[2024-12-17 02:07:10,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:10,624][root][INFO] - Training Epoch: 1/2, step 4673/7134 completed (loss: 0.09546718001365662, acc: 0.9765990376472473)
[2024-12-17 02:07:10,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:10,953][root][INFO] - Training Epoch: 1/2, step 4674/7134 completed (loss: 0.07368272542953491, acc: 0.9825673699378967)
[2024-12-17 02:07:11,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:11,302][root][INFO] - Training Epoch: 1/2, step 4675/7134 completed (loss: 0.08440195769071579, acc: 0.9770700931549072)
[2024-12-17 02:07:11,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:11,627][root][INFO] - Training Epoch: 1/2, step 4676/7134 completed (loss: 0.057132538408041, acc: 0.9849397540092468)
[2024-12-17 02:07:11,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:11,935][root][INFO] - Training Epoch: 1/2, step 4677/7134 completed (loss: 0.10233929753303528, acc: 0.9780701994895935)
[2024-12-17 02:07:12,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:12,264][root][INFO] - Training Epoch: 1/2, step 4678/7134 completed (loss: 0.1262778788805008, acc: 0.9598811268806458)
[2024-12-17 02:07:12,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:12,604][root][INFO] - Training Epoch: 1/2, step 4679/7134 completed (loss: 0.07105527073144913, acc: 0.977931022644043)
[2024-12-17 02:07:12,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:12,911][root][INFO] - Training Epoch: 1/2, step 4680/7134 completed (loss: 0.09107222408056259, acc: 0.9719626307487488)
[2024-12-17 02:07:13,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:13,254][root][INFO] - Training Epoch: 1/2, step 4681/7134 completed (loss: 0.0777539610862732, acc: 0.9815384745597839)
[2024-12-17 02:07:13,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:13,649][root][INFO] - Training Epoch: 1/2, step 4682/7134 completed (loss: 0.07108715176582336, acc: 0.985401451587677)
[2024-12-17 02:07:13,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:13,977][root][INFO] - Training Epoch: 1/2, step 4683/7134 completed (loss: 0.06525442749261856, acc: 0.9771754741668701)
[2024-12-17 02:07:14,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:14,351][root][INFO] - Training Epoch: 1/2, step 4684/7134 completed (loss: 0.10816942900419235, acc: 0.9654088020324707)
[2024-12-17 02:07:14,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:14,712][root][INFO] - Training Epoch: 1/2, step 4685/7134 completed (loss: 0.06690850853919983, acc: 0.9795082211494446)
[2024-12-17 02:07:14,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:15,089][root][INFO] - Training Epoch: 1/2, step 4686/7134 completed (loss: 0.06541002541780472, acc: 0.9802095293998718)
[2024-12-17 02:07:15,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:15,368][root][INFO] - Training Epoch: 1/2, step 4687/7134 completed (loss: 0.2781004011631012, acc: 0.9386503100395203)
[2024-12-17 02:07:15,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:15,720][root][INFO] - Training Epoch: 1/2, step 4688/7134 completed (loss: 0.3119334280490875, acc: 0.9322382211685181)
[2024-12-17 02:07:15,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:16,088][root][INFO] - Training Epoch: 1/2, step 4689/7134 completed (loss: 0.26091673970222473, acc: 0.9263622760772705)
[2024-12-17 02:07:16,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:16,445][root][INFO] - Training Epoch: 1/2, step 4690/7134 completed (loss: 0.17397424578666687, acc: 0.9643605947494507)
[2024-12-17 02:07:16,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:16,792][root][INFO] - Training Epoch: 1/2, step 4691/7134 completed (loss: 0.10790874063968658, acc: 0.9659863710403442)
[2024-12-17 02:07:16,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:17,063][root][INFO] - Training Epoch: 1/2, step 4692/7134 completed (loss: 0.23932892084121704, acc: 0.9447982907295227)
[2024-12-17 02:07:17,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:17,457][root][INFO] - Training Epoch: 1/2, step 4693/7134 completed (loss: 0.2782473862171173, acc: 0.9338346123695374)
[2024-12-17 02:07:17,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:17,778][root][INFO] - Training Epoch: 1/2, step 4694/7134 completed (loss: 0.24342191219329834, acc: 0.9452332854270935)
[2024-12-17 02:07:17,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:18,116][root][INFO] - Training Epoch: 1/2, step 4695/7134 completed (loss: 0.12007483094930649, acc: 0.9737274050712585)
[2024-12-17 02:07:18,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:18,460][root][INFO] - Training Epoch: 1/2, step 4696/7134 completed (loss: 0.07379697263240814, acc: 0.97919762134552)
[2024-12-17 02:07:18,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:18,739][root][INFO] - Training Epoch: 1/2, step 4697/7134 completed (loss: 0.1090814545750618, acc: 0.969924807548523)
[2024-12-17 02:07:18,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:19,060][root][INFO] - Training Epoch: 1/2, step 4698/7134 completed (loss: 0.20489151775836945, acc: 0.9465649127960205)
[2024-12-17 02:07:19,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:19,426][root][INFO] - Training Epoch: 1/2, step 4699/7134 completed (loss: 0.11921559274196625, acc: 0.9689213633537292)
[2024-12-17 02:07:19,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:19,777][root][INFO] - Training Epoch: 1/2, step 4700/7134 completed (loss: 0.14009875059127808, acc: 0.9627421498298645)
[2024-12-17 02:07:19,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:20,057][root][INFO] - Training Epoch: 1/2, step 4701/7134 completed (loss: 0.18752934038639069, acc: 0.9520766735076904)
[2024-12-17 02:07:20,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:20,426][root][INFO] - Training Epoch: 1/2, step 4702/7134 completed (loss: 0.09457553178071976, acc: 0.9792993664741516)
[2024-12-17 02:07:20,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:20,778][root][INFO] - Training Epoch: 1/2, step 4703/7134 completed (loss: 0.08011772483587265, acc: 0.9837837815284729)
[2024-12-17 02:07:20,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:21,108][root][INFO] - Training Epoch: 1/2, step 4704/7134 completed (loss: 0.06440312415361404, acc: 0.9859319925308228)
[2024-12-17 02:07:21,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:21,462][root][INFO] - Training Epoch: 1/2, step 4705/7134 completed (loss: 0.07460974156856537, acc: 0.9801169633865356)
[2024-12-17 02:07:21,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:21,830][root][INFO] - Training Epoch: 1/2, step 4706/7134 completed (loss: 0.1564597189426422, acc: 0.9563862681388855)
[2024-12-17 02:07:21,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:22,179][root][INFO] - Training Epoch: 1/2, step 4707/7134 completed (loss: 0.3665699064731598, acc: 0.9115646481513977)
[2024-12-17 02:07:22,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:22,525][root][INFO] - Training Epoch: 1/2, step 4708/7134 completed (loss: 0.08408451825380325, acc: 0.9788029789924622)
[2024-12-17 02:07:22,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:22,886][root][INFO] - Training Epoch: 1/2, step 4709/7134 completed (loss: 0.06153387576341629, acc: 0.9802371263504028)
[2024-12-17 02:07:23,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:23,241][root][INFO] - Training Epoch: 1/2, step 4710/7134 completed (loss: 0.0903596505522728, acc: 0.9723435044288635)
[2024-12-17 02:07:23,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:23,608][root][INFO] - Training Epoch: 1/2, step 4711/7134 completed (loss: 0.12944866716861725, acc: 0.9728353023529053)
[2024-12-17 02:07:23,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:23,930][root][INFO] - Training Epoch: 1/2, step 4712/7134 completed (loss: 0.22454775869846344, acc: 0.9469696879386902)
[2024-12-17 02:07:24,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:24,264][root][INFO] - Training Epoch: 1/2, step 4713/7134 completed (loss: 0.07490432262420654, acc: 0.9767857193946838)
[2024-12-17 02:07:24,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:24,544][root][INFO] - Training Epoch: 1/2, step 4714/7134 completed (loss: 0.13625472784042358, acc: 0.9588785171508789)
[2024-12-17 02:07:24,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:24,872][root][INFO] - Training Epoch: 1/2, step 4715/7134 completed (loss: 0.18059124052524567, acc: 0.9573560953140259)
[2024-12-17 02:07:24,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:25,195][root][INFO] - Training Epoch: 1/2, step 4716/7134 completed (loss: 0.028748715296387672, acc: 0.9908536672592163)
[2024-12-17 02:07:25,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:25,523][root][INFO] - Training Epoch: 1/2, step 4717/7134 completed (loss: 0.06439387798309326, acc: 0.9851852059364319)
[2024-12-17 02:07:25,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:25,846][root][INFO] - Training Epoch: 1/2, step 4718/7134 completed (loss: 0.06654883921146393, acc: 0.9817880988121033)
[2024-12-17 02:07:25,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:26,180][root][INFO] - Training Epoch: 1/2, step 4719/7134 completed (loss: 0.060617879033088684, acc: 0.9896755218505859)
[2024-12-17 02:07:26,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:26,522][root][INFO] - Training Epoch: 1/2, step 4720/7134 completed (loss: 0.02648228034377098, acc: 0.9859747290611267)
[2024-12-17 02:07:26,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:26,852][root][INFO] - Training Epoch: 1/2, step 4721/7134 completed (loss: 0.03991886228322983, acc: 0.9899135231971741)
[2024-12-17 02:07:26,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:27,193][root][INFO] - Training Epoch: 1/2, step 4722/7134 completed (loss: 0.028841977939009666, acc: 0.9881656765937805)
[2024-12-17 02:07:27,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:27,520][root][INFO] - Training Epoch: 1/2, step 4723/7134 completed (loss: 0.03259802609682083, acc: 0.9893292784690857)
[2024-12-17 02:07:27,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:27,892][root][INFO] - Training Epoch: 1/2, step 4724/7134 completed (loss: 0.04407361522316933, acc: 0.9926035404205322)
[2024-12-17 02:07:28,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:28,235][root][INFO] - Training Epoch: 1/2, step 4725/7134 completed (loss: 0.0435824878513813, acc: 0.9894459247589111)
[2024-12-17 02:07:28,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:28,579][root][INFO] - Training Epoch: 1/2, step 4726/7134 completed (loss: 0.16136562824249268, acc: 0.9645389914512634)
[2024-12-17 02:07:28,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:28,926][root][INFO] - Training Epoch: 1/2, step 4727/7134 completed (loss: 0.0464349240064621, acc: 0.9921630024909973)
[2024-12-17 02:07:29,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:29,253][root][INFO] - Training Epoch: 1/2, step 4728/7134 completed (loss: 0.06979136914014816, acc: 0.9851729869842529)
[2024-12-17 02:07:29,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:29,577][root][INFO] - Training Epoch: 1/2, step 4729/7134 completed (loss: 0.03357364237308502, acc: 0.98591548204422)
[2024-12-17 02:07:29,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:29,913][root][INFO] - Training Epoch: 1/2, step 4730/7134 completed (loss: 0.04224443808197975, acc: 0.9892802238464355)
[2024-12-17 02:07:30,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:30,235][root][INFO] - Training Epoch: 1/2, step 4731/7134 completed (loss: 0.057093653827905655, acc: 0.9847328066825867)
[2024-12-17 02:07:30,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:30,569][root][INFO] - Training Epoch: 1/2, step 4732/7134 completed (loss: 0.08316466957330704, acc: 0.9818511605262756)
[2024-12-17 02:07:30,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:30,904][root][INFO] - Training Epoch: 1/2, step 4733/7134 completed (loss: 0.0349300317466259, acc: 0.987075924873352)
[2024-12-17 02:07:31,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:31,250][root][INFO] - Training Epoch: 1/2, step 4734/7134 completed (loss: 0.08844218403100967, acc: 0.9777424335479736)
[2024-12-17 02:07:31,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:31,598][root][INFO] - Training Epoch: 1/2, step 4735/7134 completed (loss: 0.05705830082297325, acc: 0.9864864945411682)
[2024-12-17 02:07:31,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:31,893][root][INFO] - Training Epoch: 1/2, step 4736/7134 completed (loss: 0.08436506986618042, acc: 0.9783037304878235)
[2024-12-17 02:07:32,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:32,232][root][INFO] - Training Epoch: 1/2, step 4737/7134 completed (loss: 0.06918320059776306, acc: 0.9874607920646667)
[2024-12-17 02:07:32,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:32,554][root][INFO] - Training Epoch: 1/2, step 4738/7134 completed (loss: 0.05745743215084076, acc: 0.987860381603241)
[2024-12-17 02:07:32,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:32,876][root][INFO] - Training Epoch: 1/2, step 4739/7134 completed (loss: 0.13696181774139404, acc: 0.9632588028907776)
[2024-12-17 02:07:32,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:33,215][root][INFO] - Training Epoch: 1/2, step 4740/7134 completed (loss: 0.1570046842098236, acc: 0.970059871673584)
[2024-12-17 02:07:33,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:33,491][root][INFO] - Training Epoch: 1/2, step 4741/7134 completed (loss: 0.14034372568130493, acc: 0.9593345522880554)
[2024-12-17 02:07:33,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:33,813][root][INFO] - Training Epoch: 1/2, step 4742/7134 completed (loss: 0.1747588813304901, acc: 0.9575220942497253)
[2024-12-17 02:07:33,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:34,162][root][INFO] - Training Epoch: 1/2, step 4743/7134 completed (loss: 0.13872969150543213, acc: 0.9537366628646851)
[2024-12-17 02:07:34,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:34,471][root][INFO] - Training Epoch: 1/2, step 4744/7134 completed (loss: 0.08689802139997482, acc: 0.9814049601554871)
[2024-12-17 02:07:34,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:34,782][root][INFO] - Training Epoch: 1/2, step 4745/7134 completed (loss: 0.12488719075918198, acc: 0.9665551781654358)
[2024-12-17 02:07:34,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:35,128][root][INFO] - Training Epoch: 1/2, step 4746/7134 completed (loss: 0.10172846913337708, acc: 0.9797794222831726)
[2024-12-17 02:07:35,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:35,480][root][INFO] - Training Epoch: 1/2, step 4747/7134 completed (loss: 0.0985952764749527, acc: 0.9689608812332153)
[2024-12-17 02:07:35,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:35,836][root][INFO] - Training Epoch: 1/2, step 4748/7134 completed (loss: 0.1458861380815506, acc: 0.9616519212722778)
[2024-12-17 02:07:35,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:36,185][root][INFO] - Training Epoch: 1/2, step 4749/7134 completed (loss: 0.10773400962352753, acc: 0.9773333072662354)
[2024-12-17 02:07:36,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:36,527][root][INFO] - Training Epoch: 1/2, step 4750/7134 completed (loss: 0.20338819921016693, acc: 0.9576107859611511)
[2024-12-17 02:07:36,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:36,894][root][INFO] - Training Epoch: 1/2, step 4751/7134 completed (loss: 0.060373131185770035, acc: 0.985855758190155)
[2024-12-17 02:07:37,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:37,249][root][INFO] - Training Epoch: 1/2, step 4752/7134 completed (loss: 0.14023204147815704, acc: 0.9754224419593811)
[2024-12-17 02:07:37,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:37,570][root][INFO] - Training Epoch: 1/2, step 4753/7134 completed (loss: 0.14199189841747284, acc: 0.974397599697113)
[2024-12-17 02:07:37,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:37,917][root][INFO] - Training Epoch: 1/2, step 4754/7134 completed (loss: 0.052403632551431656, acc: 0.988252580165863)
[2024-12-17 02:07:38,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:38,267][root][INFO] - Training Epoch: 1/2, step 4755/7134 completed (loss: 0.07770688831806183, acc: 0.9833564758300781)
[2024-12-17 02:07:38,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:38,579][root][INFO] - Training Epoch: 1/2, step 4756/7134 completed (loss: 0.13908424973487854, acc: 0.9728033542633057)
[2024-12-17 02:07:38,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:38,974][root][INFO] - Training Epoch: 1/2, step 4757/7134 completed (loss: 0.0717843770980835, acc: 0.9793341159820557)
[2024-12-17 02:07:39,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:39,317][root][INFO] - Training Epoch: 1/2, step 4758/7134 completed (loss: 0.08090571314096451, acc: 0.9789915680885315)
[2024-12-17 02:07:39,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:39,660][root][INFO] - Training Epoch: 1/2, step 4759/7134 completed (loss: 0.05509297549724579, acc: 0.9879310131072998)
[2024-12-17 02:07:39,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:39,986][root][INFO] - Training Epoch: 1/2, step 4760/7134 completed (loss: 0.07657470554113388, acc: 0.9855072498321533)
[2024-12-17 02:07:40,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:40,312][root][INFO] - Training Epoch: 1/2, step 4761/7134 completed (loss: 0.06447868049144745, acc: 0.9847328066825867)
[2024-12-17 02:07:40,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:40,649][root][INFO] - Training Epoch: 1/2, step 4762/7134 completed (loss: 0.12049143761396408, acc: 0.9743243455886841)
[2024-12-17 02:07:40,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:40,987][root][INFO] - Training Epoch: 1/2, step 4763/7134 completed (loss: 0.10408946126699448, acc: 0.9772036671638489)
[2024-12-17 02:07:41,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:41,350][root][INFO] - Training Epoch: 1/2, step 4764/7134 completed (loss: 0.10024894028902054, acc: 0.9765142202377319)
[2024-12-17 02:07:41,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:41,691][root][INFO] - Training Epoch: 1/2, step 4765/7134 completed (loss: 0.1298200786113739, acc: 0.9784172773361206)
[2024-12-17 02:07:41,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:42,039][root][INFO] - Training Epoch: 1/2, step 4766/7134 completed (loss: 0.0782214105129242, acc: 0.9832689762115479)
[2024-12-17 02:07:42,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:42,326][root][INFO] - Training Epoch: 1/2, step 4767/7134 completed (loss: 0.1361737847328186, acc: 0.9720101952552795)
[2024-12-17 02:07:42,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:42,695][root][INFO] - Training Epoch: 1/2, step 4768/7134 completed (loss: 0.11677945405244827, acc: 0.9661246538162231)
[2024-12-17 02:07:42,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:43,033][root][INFO] - Training Epoch: 1/2, step 4769/7134 completed (loss: 0.10090576857328415, acc: 0.9791332483291626)
[2024-12-17 02:07:43,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:43,355][root][INFO] - Training Epoch: 1/2, step 4770/7134 completed (loss: 0.058121293783187866, acc: 0.9858585596084595)
[2024-12-17 02:07:43,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:43,676][root][INFO] - Training Epoch: 1/2, step 4771/7134 completed (loss: 0.13835085928440094, acc: 0.9665697813034058)
[2024-12-17 02:07:43,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:44,002][root][INFO] - Training Epoch: 1/2, step 4772/7134 completed (loss: 0.11085637658834457, acc: 0.9776714444160461)
[2024-12-17 02:07:44,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:44,314][root][INFO] - Training Epoch: 1/2, step 4773/7134 completed (loss: 0.10570176690816879, acc: 0.9767123460769653)
[2024-12-17 02:07:44,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:44,619][root][INFO] - Training Epoch: 1/2, step 4774/7134 completed (loss: 0.1171526238322258, acc: 0.9775280952453613)
[2024-12-17 02:07:44,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:44,946][root][INFO] - Training Epoch: 1/2, step 4775/7134 completed (loss: 0.10897821187973022, acc: 0.9742351174354553)
[2024-12-17 02:07:45,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:45,287][root][INFO] - Training Epoch: 1/2, step 4776/7134 completed (loss: 0.08603162318468094, acc: 0.9775280952453613)
[2024-12-17 02:07:45,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:45,651][root][INFO] - Training Epoch: 1/2, step 4777/7134 completed (loss: 0.0532321073114872, acc: 0.9849749803543091)
[2024-12-17 02:07:45,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:45,979][root][INFO] - Training Epoch: 1/2, step 4778/7134 completed (loss: 0.08063359558582306, acc: 0.9868708848953247)
[2024-12-17 02:07:46,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:46,347][root][INFO] - Training Epoch: 1/2, step 4779/7134 completed (loss: 0.058519817888736725, acc: 0.979742169380188)
[2024-12-17 02:07:46,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:46,693][root][INFO] - Training Epoch: 1/2, step 4780/7134 completed (loss: 0.027933359146118164, acc: 0.9906542301177979)
[2024-12-17 02:07:46,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:47,026][root][INFO] - Training Epoch: 1/2, step 4781/7134 completed (loss: 0.03686998039484024, acc: 0.9882583022117615)
[2024-12-17 02:07:47,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:47,375][root][INFO] - Training Epoch: 1/2, step 4782/7134 completed (loss: 0.043010227382183075, acc: 0.990275502204895)
[2024-12-17 02:07:47,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:47,707][root][INFO] - Training Epoch: 1/2, step 4783/7134 completed (loss: 0.07730603963136673, acc: 0.9804270267486572)
[2024-12-17 02:07:47,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:48,065][root][INFO] - Training Epoch: 1/2, step 4784/7134 completed (loss: 0.037850189954042435, acc: 0.9890859723091125)
[2024-12-17 02:07:48,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:48,406][root][INFO] - Training Epoch: 1/2, step 4785/7134 completed (loss: 0.12124079465866089, acc: 0.9700374603271484)
[2024-12-17 02:07:48,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:48,749][root][INFO] - Training Epoch: 1/2, step 4786/7134 completed (loss: 0.09803653508424759, acc: 0.9720497131347656)
[2024-12-17 02:07:48,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:49,086][root][INFO] - Training Epoch: 1/2, step 4787/7134 completed (loss: 0.0423247292637825, acc: 0.9920886158943176)
[2024-12-17 02:07:49,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:49,419][root][INFO] - Training Epoch: 1/2, step 4788/7134 completed (loss: 0.04627636447548866, acc: 0.9840425252914429)
[2024-12-17 02:07:49,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:49,748][root][INFO] - Training Epoch: 1/2, step 4789/7134 completed (loss: 0.063253253698349, acc: 0.9888535141944885)
[2024-12-17 02:07:49,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:50,104][root][INFO] - Training Epoch: 1/2, step 4790/7134 completed (loss: 0.06321926414966583, acc: 0.979619562625885)
[2024-12-17 02:07:50,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:50,428][root][INFO] - Training Epoch: 1/2, step 4791/7134 completed (loss: 0.10022377222776413, acc: 0.973929226398468)
[2024-12-17 02:07:50,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:50,767][root][INFO] - Training Epoch: 1/2, step 4792/7134 completed (loss: 0.05533628538250923, acc: 0.9849498271942139)
[2024-12-17 02:07:50,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:51,060][root][INFO] - Training Epoch: 1/2, step 4793/7134 completed (loss: 0.10133084654808044, acc: 0.9753424525260925)
[2024-12-17 02:07:51,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:51,387][root][INFO] - Training Epoch: 1/2, step 4794/7134 completed (loss: 0.12774766981601715, acc: 0.9695237874984741)
[2024-12-17 02:07:51,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:51,740][root][INFO] - Training Epoch: 1/2, step 4795/7134 completed (loss: 0.05280585214495659, acc: 0.9872881174087524)
[2024-12-17 02:07:51,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:52,064][root][INFO] - Training Epoch: 1/2, step 4796/7134 completed (loss: 0.04389302805066109, acc: 0.9874213933944702)
[2024-12-17 02:07:52,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:52,422][root][INFO] - Training Epoch: 1/2, step 4797/7134 completed (loss: 0.05133039131760597, acc: 0.9826086759567261)
[2024-12-17 02:07:52,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:52,775][root][INFO] - Training Epoch: 1/2, step 4798/7134 completed (loss: 0.08013082295656204, acc: 0.9840213060379028)
[2024-12-17 02:07:52,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:53,134][root][INFO] - Training Epoch: 1/2, step 4799/7134 completed (loss: 0.08062508702278137, acc: 0.9773691892623901)
[2024-12-17 02:07:53,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:53,477][root][INFO] - Training Epoch: 1/2, step 4800/7134 completed (loss: 0.0706239566206932, acc: 0.9806259274482727)
[2024-12-17 02:07:53,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:53,835][root][INFO] - Training Epoch: 1/2, step 4801/7134 completed (loss: 0.039539799094200134, acc: 0.9898189902305603)
[2024-12-17 02:07:53,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:54,194][root][INFO] - Training Epoch: 1/2, step 4802/7134 completed (loss: 0.08238581568002701, acc: 0.9764397740364075)
[2024-12-17 02:07:54,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:54,513][root][INFO] - Training Epoch: 1/2, step 4803/7134 completed (loss: 0.1086798831820488, acc: 0.9750000238418579)
[2024-12-17 02:07:54,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:54,867][root][INFO] - Training Epoch: 1/2, step 4804/7134 completed (loss: 0.08339938521385193, acc: 0.9800000190734863)
[2024-12-17 02:07:54,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:55,214][root][INFO] - Training Epoch: 1/2, step 4805/7134 completed (loss: 0.08838765323162079, acc: 0.983818769454956)
[2024-12-17 02:07:55,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:55,555][root][INFO] - Training Epoch: 1/2, step 4806/7134 completed (loss: 0.06240588426589966, acc: 0.9866888523101807)
[2024-12-17 02:07:55,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:55,862][root][INFO] - Training Epoch: 1/2, step 4807/7134 completed (loss: 0.14652852714061737, acc: 0.975683867931366)
[2024-12-17 02:07:55,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:56,193][root][INFO] - Training Epoch: 1/2, step 4808/7134 completed (loss: 0.0800975039601326, acc: 0.9858155846595764)
[2024-12-17 02:07:56,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:56,544][root][INFO] - Training Epoch: 1/2, step 4809/7134 completed (loss: 0.08409830182790756, acc: 0.9777777791023254)
[2024-12-17 02:07:56,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:56,914][root][INFO] - Training Epoch: 1/2, step 4810/7134 completed (loss: 0.09610321372747421, acc: 0.9828816056251526)
[2024-12-17 02:07:57,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:57,228][root][INFO] - Training Epoch: 1/2, step 4811/7134 completed (loss: 0.12176098674535751, acc: 0.9786821603775024)
[2024-12-17 02:07:57,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:57,571][root][INFO] - Training Epoch: 1/2, step 4812/7134 completed (loss: 0.13185174763202667, acc: 0.9721835851669312)
[2024-12-17 02:07:57,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:57,868][root][INFO] - Training Epoch: 1/2, step 4813/7134 completed (loss: 0.0369357131421566, acc: 0.9922077655792236)
[2024-12-17 02:07:57,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:58,210][root][INFO] - Training Epoch: 1/2, step 4814/7134 completed (loss: 0.06386034935712814, acc: 0.9821428656578064)
[2024-12-17 02:07:58,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:58,508][root][INFO] - Training Epoch: 1/2, step 4815/7134 completed (loss: 0.023559609428048134, acc: 0.9937888383865356)
[2024-12-17 02:07:58,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:58,846][root][INFO] - Training Epoch: 1/2, step 4816/7134 completed (loss: 0.027118852362036705, acc: 0.9938119053840637)
[2024-12-17 02:07:58,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:59,169][root][INFO] - Training Epoch: 1/2, step 4817/7134 completed (loss: 0.044486019760370255, acc: 0.9879518151283264)
[2024-12-17 02:07:59,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:59,548][root][INFO] - Training Epoch: 1/2, step 4818/7134 completed (loss: 0.04718370735645294, acc: 0.9907692074775696)
[2024-12-17 02:07:59,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:59,872][root][INFO] - Training Epoch: 1/2, step 4819/7134 completed (loss: 0.04545043408870697, acc: 0.9858012199401855)
[2024-12-17 02:08:00,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:00,228][root][INFO] - Training Epoch: 1/2, step 4820/7134 completed (loss: 0.050959326326847076, acc: 0.9897040128707886)
[2024-12-17 02:08:00,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:00,583][root][INFO] - Training Epoch: 1/2, step 4821/7134 completed (loss: 0.03523670509457588, acc: 0.9902234673500061)
[2024-12-17 02:08:00,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:00,930][root][INFO] - Training Epoch: 1/2, step 4822/7134 completed (loss: 0.04171742498874664, acc: 0.992438554763794)
[2024-12-17 02:08:01,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:01,278][root][INFO] - Training Epoch: 1/2, step 4823/7134 completed (loss: 0.09288177639245987, acc: 0.9778831005096436)
[2024-12-17 02:08:01,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:01,576][root][INFO] - Training Epoch: 1/2, step 4824/7134 completed (loss: 0.10898399353027344, acc: 0.9748858213424683)
[2024-12-17 02:08:01,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:01,911][root][INFO] - Training Epoch: 1/2, step 4825/7134 completed (loss: 0.04578143358230591, acc: 0.985401451587677)
[2024-12-17 02:08:02,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:02,283][root][INFO] - Training Epoch: 1/2, step 4826/7134 completed (loss: 0.063481405377388, acc: 0.9871244430541992)
[2024-12-17 02:08:02,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:02,607][root][INFO] - Training Epoch: 1/2, step 4827/7134 completed (loss: 0.05501067265868187, acc: 0.9844290614128113)
[2024-12-17 02:08:02,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:02,950][root][INFO] - Training Epoch: 1/2, step 4828/7134 completed (loss: 0.051793213933706284, acc: 0.9866342544555664)
[2024-12-17 02:08:03,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:03,327][root][INFO] - Training Epoch: 1/2, step 4829/7134 completed (loss: 0.045483458787202835, acc: 0.985897421836853)
[2024-12-17 02:08:03,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:03,678][root][INFO] - Training Epoch: 1/2, step 4830/7134 completed (loss: 0.03168215602636337, acc: 0.9940828680992126)
[2024-12-17 02:08:03,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:04,025][root][INFO] - Training Epoch: 1/2, step 4831/7134 completed (loss: 0.034308936446905136, acc: 0.9912280440330505)
[2024-12-17 02:08:04,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:04,361][root][INFO] - Training Epoch: 1/2, step 4832/7134 completed (loss: 0.03687979280948639, acc: 0.9934853315353394)
[2024-12-17 02:08:04,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:04,722][root][INFO] - Training Epoch: 1/2, step 4833/7134 completed (loss: 0.02924426458775997, acc: 0.9911054372787476)
[2024-12-17 02:08:04,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:05,069][root][INFO] - Training Epoch: 1/2, step 4834/7134 completed (loss: 0.04289831966161728, acc: 0.9904761910438538)
[2024-12-17 02:08:05,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:05,410][root][INFO] - Training Epoch: 1/2, step 4835/7134 completed (loss: 0.030865361914038658, acc: 0.9932432174682617)
[2024-12-17 02:08:05,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:05,755][root][INFO] - Training Epoch: 1/2, step 4836/7134 completed (loss: 0.047882329672575, acc: 0.9847328066825867)
[2024-12-17 02:08:05,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:06,075][root][INFO] - Training Epoch: 1/2, step 4837/7134 completed (loss: 0.14862173795700073, acc: 0.9632353186607361)
[2024-12-17 02:08:06,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:06,413][root][INFO] - Training Epoch: 1/2, step 4838/7134 completed (loss: 0.06390120089054108, acc: 0.9838969111442566)
[2024-12-17 02:08:06,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:06,722][root][INFO] - Training Epoch: 1/2, step 4839/7134 completed (loss: 0.07527589797973633, acc: 0.979345977306366)
[2024-12-17 02:08:06,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:07,061][root][INFO] - Training Epoch: 1/2, step 4840/7134 completed (loss: 0.09409019351005554, acc: 0.9754335284233093)
[2024-12-17 02:08:07,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:07,406][root][INFO] - Training Epoch: 1/2, step 4841/7134 completed (loss: 0.063613161444664, acc: 0.9865871667861938)
[2024-12-17 02:08:07,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:07,766][root][INFO] - Training Epoch: 1/2, step 4842/7134 completed (loss: 0.09920107573270798, acc: 0.9783163070678711)
[2024-12-17 02:08:07,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:08,123][root][INFO] - Training Epoch: 1/2, step 4843/7134 completed (loss: 0.08103510737419128, acc: 0.9777117371559143)
[2024-12-17 02:08:08,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:08,422][root][INFO] - Training Epoch: 1/2, step 4844/7134 completed (loss: 0.05009554326534271, acc: 0.9854604005813599)
[2024-12-17 02:08:08,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:08,774][root][INFO] - Training Epoch: 1/2, step 4845/7134 completed (loss: 0.08731529116630554, acc: 0.9795082211494446)
[2024-12-17 02:08:08,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:09,112][root][INFO] - Training Epoch: 1/2, step 4846/7134 completed (loss: 0.06979238241910934, acc: 0.9797297120094299)
[2024-12-17 02:08:09,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:09,424][root][INFO] - Training Epoch: 1/2, step 4847/7134 completed (loss: 0.04550065100193024, acc: 0.9892183542251587)
[2024-12-17 02:08:09,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:09,754][root][INFO] - Training Epoch: 1/2, step 4848/7134 completed (loss: 0.05699794739484787, acc: 0.9875690340995789)
[2024-12-17 02:08:09,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:10,067][root][INFO] - Training Epoch: 1/2, step 4849/7134 completed (loss: 0.043778758496046066, acc: 0.98959881067276)
[2024-12-17 02:08:10,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:10,425][root][INFO] - Training Epoch: 1/2, step 4850/7134 completed (loss: 0.0466979518532753, acc: 0.9865360856056213)
[2024-12-17 02:08:10,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:10,784][root][INFO] - Training Epoch: 1/2, step 4851/7134 completed (loss: 0.0882592499256134, acc: 0.980140209197998)
[2024-12-17 02:08:10,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:11,133][root][INFO] - Training Epoch: 1/2, step 4852/7134 completed (loss: 0.07853079587221146, acc: 0.9786950945854187)
[2024-12-17 02:08:11,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:11,459][root][INFO] - Training Epoch: 1/2, step 4853/7134 completed (loss: 0.11440211534500122, acc: 0.9714693427085876)
[2024-12-17 02:08:11,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:11,778][root][INFO] - Training Epoch: 1/2, step 4854/7134 completed (loss: 0.05934607610106468, acc: 0.9853333234786987)
[2024-12-17 02:08:11,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:12,128][root][INFO] - Training Epoch: 1/2, step 4855/7134 completed (loss: 0.06266988813877106, acc: 0.9830713272094727)
[2024-12-17 02:08:12,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:12,490][root][INFO] - Training Epoch: 1/2, step 4856/7134 completed (loss: 0.06893699616193771, acc: 0.9809160232543945)
[2024-12-17 02:08:12,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:12,807][root][INFO] - Training Epoch: 1/2, step 4857/7134 completed (loss: 0.03775012493133545, acc: 0.9884892106056213)
[2024-12-17 02:08:12,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:13,152][root][INFO] - Training Epoch: 1/2, step 4858/7134 completed (loss: 0.05150008574128151, acc: 0.9871794581413269)
[2024-12-17 02:08:13,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:13,503][root][INFO] - Training Epoch: 1/2, step 4859/7134 completed (loss: 0.04064515605568886, acc: 0.992277979850769)
[2024-12-17 02:08:13,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:13,839][root][INFO] - Training Epoch: 1/2, step 4860/7134 completed (loss: 0.07155643403530121, acc: 0.9782016277313232)
[2024-12-17 02:08:13,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:14,173][root][INFO] - Training Epoch: 1/2, step 4861/7134 completed (loss: 0.06473460793495178, acc: 0.9851751923561096)
[2024-12-17 02:08:14,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:14,514][root][INFO] - Training Epoch: 1/2, step 4862/7134 completed (loss: 0.08006207644939423, acc: 0.9814019799232483)
[2024-12-17 02:08:14,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:14,846][root][INFO] - Training Epoch: 1/2, step 4863/7134 completed (loss: 0.06195782497525215, acc: 0.9835766553878784)
[2024-12-17 02:08:14,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:15,171][root][INFO] - Training Epoch: 1/2, step 4864/7134 completed (loss: 0.09075198322534561, acc: 0.9723076820373535)
[2024-12-17 02:08:15,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:15,515][root][INFO] - Training Epoch: 1/2, step 4865/7134 completed (loss: 0.08559481799602509, acc: 0.9792429804801941)
[2024-12-17 02:08:15,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:15,884][root][INFO] - Training Epoch: 1/2, step 4866/7134 completed (loss: 0.08449026942253113, acc: 0.9831387996673584)
[2024-12-17 02:08:15,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:16,232][root][INFO] - Training Epoch: 1/2, step 4867/7134 completed (loss: 0.1051112562417984, acc: 0.9735449552536011)
[2024-12-17 02:08:16,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:16,547][root][INFO] - Training Epoch: 1/2, step 4868/7134 completed (loss: 0.09138872474431992, acc: 0.9709302186965942)
[2024-12-17 02:08:16,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:16,869][root][INFO] - Training Epoch: 1/2, step 4869/7134 completed (loss: 0.12236969918012619, acc: 0.9711111187934875)
[2024-12-17 02:08:16,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:17,219][root][INFO] - Training Epoch: 1/2, step 4870/7134 completed (loss: 0.04238567128777504, acc: 0.9882628917694092)
[2024-12-17 02:08:17,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:17,531][root][INFO] - Training Epoch: 1/2, step 4871/7134 completed (loss: 0.057709306478500366, acc: 0.9891975522041321)
[2024-12-17 02:08:17,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:17,865][root][INFO] - Training Epoch: 1/2, step 4872/7134 completed (loss: 0.03977440670132637, acc: 0.9902642369270325)
[2024-12-17 02:08:17,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:18,230][root][INFO] - Training Epoch: 1/2, step 4873/7134 completed (loss: 0.054591890424489975, acc: 0.9791666865348816)
[2024-12-17 02:08:18,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:18,586][root][INFO] - Training Epoch: 1/2, step 4874/7134 completed (loss: 0.04240647703409195, acc: 0.9851428866386414)
[2024-12-17 02:08:18,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:18,954][root][INFO] - Training Epoch: 1/2, step 4875/7134 completed (loss: 0.06411593407392502, acc: 0.9861303567886353)
[2024-12-17 02:08:19,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:19,244][root][INFO] - Training Epoch: 1/2, step 4876/7134 completed (loss: 0.11498326063156128, acc: 0.9767441749572754)
[2024-12-17 02:08:19,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:19,589][root][INFO] - Training Epoch: 1/2, step 4877/7134 completed (loss: 0.0802522748708725, acc: 0.9793548583984375)
[2024-12-17 02:08:19,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:19,916][root][INFO] - Training Epoch: 1/2, step 4878/7134 completed (loss: 0.08334774523973465, acc: 0.9793814420700073)
[2024-12-17 02:08:20,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:20,274][root][INFO] - Training Epoch: 1/2, step 4879/7134 completed (loss: 0.10619551688432693, acc: 0.9789156913757324)
[2024-12-17 02:08:20,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:20,618][root][INFO] - Training Epoch: 1/2, step 4880/7134 completed (loss: 0.03171330690383911, acc: 0.9922178983688354)
[2024-12-17 02:08:20,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:20,970][root][INFO] - Training Epoch: 1/2, step 4881/7134 completed (loss: 0.10804617404937744, acc: 0.9751824736595154)
[2024-12-17 02:08:21,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:21,300][root][INFO] - Training Epoch: 1/2, step 4882/7134 completed (loss: 0.10592666268348694, acc: 0.9736841917037964)
[2024-12-17 02:08:21,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:21,679][root][INFO] - Training Epoch: 1/2, step 4883/7134 completed (loss: 0.08320944756269455, acc: 0.9810218811035156)
[2024-12-17 02:08:21,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:22,025][root][INFO] - Training Epoch: 1/2, step 4884/7134 completed (loss: 0.03495781868696213, acc: 0.9892473220825195)
[2024-12-17 02:08:22,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:22,356][root][INFO] - Training Epoch: 1/2, step 4885/7134 completed (loss: 0.037182338535785675, acc: 0.9894459247589111)
[2024-12-17 02:08:22,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:22,675][root][INFO] - Training Epoch: 1/2, step 4886/7134 completed (loss: 0.05665039271116257, acc: 0.9820512533187866)
[2024-12-17 02:08:22,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:23,042][root][INFO] - Training Epoch: 1/2, step 4887/7134 completed (loss: 0.04420923441648483, acc: 0.9868578314781189)
[2024-12-17 02:08:23,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:23,408][root][INFO] - Training Epoch: 1/2, step 4888/7134 completed (loss: 0.08206082880496979, acc: 0.9835164546966553)
[2024-12-17 02:08:23,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:23,761][root][INFO] - Training Epoch: 1/2, step 4889/7134 completed (loss: 0.04884811490774155, acc: 0.9891696572303772)
[2024-12-17 02:08:23,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:24,068][root][INFO] - Training Epoch: 1/2, step 4890/7134 completed (loss: 0.07002793997526169, acc: 0.9809523820877075)
[2024-12-17 02:08:24,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:24,415][root][INFO] - Training Epoch: 1/2, step 4891/7134 completed (loss: 0.07854514569044113, acc: 0.9850746393203735)
[2024-12-17 02:08:24,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:24,755][root][INFO] - Training Epoch: 1/2, step 4892/7134 completed (loss: 0.13504821062088013, acc: 0.9664429426193237)
[2024-12-17 02:08:24,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:25,094][root][INFO] - Training Epoch: 1/2, step 4893/7134 completed (loss: 0.34906795620918274, acc: 0.9234828352928162)
[2024-12-17 02:08:25,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:25,442][root][INFO] - Training Epoch: 1/2, step 4894/7134 completed (loss: 0.062240809202194214, acc: 0.9855907559394836)
[2024-12-17 02:08:25,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:25,796][root][INFO] - Training Epoch: 1/2, step 4895/7134 completed (loss: 0.028721340000629425, acc: 0.9937499761581421)
[2024-12-17 02:08:25,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:26,118][root][INFO] - Training Epoch: 1/2, step 4896/7134 completed (loss: 0.03703437000513077, acc: 0.9915730357170105)
[2024-12-17 02:08:26,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:26,477][root][INFO] - Training Epoch: 1/2, step 4897/7134 completed (loss: 0.09598109126091003, acc: 0.9719298481941223)
[2024-12-17 02:08:26,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:26,849][root][INFO] - Training Epoch: 1/2, step 4898/7134 completed (loss: 0.08127893507480621, acc: 0.9811320900917053)
[2024-12-17 02:08:26,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:27,208][root][INFO] - Training Epoch: 1/2, step 4899/7134 completed (loss: 0.08033952116966248, acc: 0.9781659245491028)
[2024-12-17 02:08:27,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:27,551][root][INFO] - Training Epoch: 1/2, step 4900/7134 completed (loss: 0.08609916269779205, acc: 0.9750000238418579)
[2024-12-17 02:08:27,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:27,893][root][INFO] - Training Epoch: 1/2, step 4901/7134 completed (loss: 0.06495684385299683, acc: 0.9864661693572998)
[2024-12-17 02:08:28,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:28,246][root][INFO] - Training Epoch: 1/2, step 4902/7134 completed (loss: 0.06674081087112427, acc: 0.988063633441925)
[2024-12-17 02:08:28,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:28,580][root][INFO] - Training Epoch: 1/2, step 4903/7134 completed (loss: 0.04811359569430351, acc: 0.9838709831237793)
[2024-12-17 02:08:28,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:28,914][root][INFO] - Training Epoch: 1/2, step 4904/7134 completed (loss: 0.05759679153561592, acc: 0.983582079410553)
[2024-12-17 02:08:29,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:29,253][root][INFO] - Training Epoch: 1/2, step 4905/7134 completed (loss: 0.03314851596951485, acc: 0.9952229261398315)
[2024-12-17 02:08:29,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:29,578][root][INFO] - Training Epoch: 1/2, step 4906/7134 completed (loss: 0.03917009010910988, acc: 0.9898819327354431)
[2024-12-17 02:08:29,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:29,909][root][INFO] - Training Epoch: 1/2, step 4907/7134 completed (loss: 0.046222932636737823, acc: 0.9841772317886353)
[2024-12-17 02:08:30,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:30,248][root][INFO] - Training Epoch: 1/2, step 4908/7134 completed (loss: 0.02819395437836647, acc: 0.9919999837875366)
[2024-12-17 02:08:30,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:30,600][root][INFO] - Training Epoch: 1/2, step 4909/7134 completed (loss: 0.03135097771883011, acc: 0.990275502204895)
[2024-12-17 02:08:30,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:30,934][root][INFO] - Training Epoch: 1/2, step 4910/7134 completed (loss: 0.05809924006462097, acc: 0.9874607920646667)
[2024-12-17 02:08:31,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:31,292][root][INFO] - Training Epoch: 1/2, step 4911/7134 completed (loss: 0.049538299441337585, acc: 0.9868074059486389)
[2024-12-17 02:08:31,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:31,637][root][INFO] - Training Epoch: 1/2, step 4912/7134 completed (loss: 0.08208782970905304, acc: 0.981840193271637)
[2024-12-17 02:08:31,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:31,971][root][INFO] - Training Epoch: 1/2, step 4913/7134 completed (loss: 0.0390605553984642, acc: 0.9881756901741028)
[2024-12-17 02:08:32,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:32,305][root][INFO] - Training Epoch: 1/2, step 4914/7134 completed (loss: 0.0586104653775692, acc: 0.9816513657569885)
[2024-12-17 02:08:32,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:32,650][root][INFO] - Training Epoch: 1/2, step 4915/7134 completed (loss: 0.03434697166085243, acc: 0.9936407208442688)
[2024-12-17 02:08:32,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:32,924][root][INFO] - Training Epoch: 1/2, step 4916/7134 completed (loss: 0.08480434119701385, acc: 0.9805825352668762)
[2024-12-17 02:08:33,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:33,273][root][INFO] - Training Epoch: 1/2, step 4917/7134 completed (loss: 0.06621043384075165, acc: 0.9860917925834656)
[2024-12-17 02:08:33,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:33,604][root][INFO] - Training Epoch: 1/2, step 4918/7134 completed (loss: 0.012857516296207905, acc: 0.998633861541748)
[2024-12-17 02:08:33,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:34,014][root][INFO] - Training Epoch: 1/2, step 4919/7134 completed (loss: 0.07167516648769379, acc: 0.9815789461135864)
[2024-12-17 02:08:34,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:34,371][root][INFO] - Training Epoch: 1/2, step 4920/7134 completed (loss: 0.11855386942625046, acc: 0.9780361652374268)
[2024-12-17 02:08:34,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:34,701][root][INFO] - Training Epoch: 1/2, step 4921/7134 completed (loss: 0.05390403792262077, acc: 0.9870874881744385)
[2024-12-17 02:08:34,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:35,052][root][INFO] - Training Epoch: 1/2, step 4922/7134 completed (loss: 0.04479144513607025, acc: 0.9877551198005676)
[2024-12-17 02:08:35,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:35,404][root][INFO] - Training Epoch: 1/2, step 4923/7134 completed (loss: 0.024383382871747017, acc: 0.9955947399139404)
[2024-12-17 02:08:35,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:35,718][root][INFO] - Training Epoch: 1/2, step 4924/7134 completed (loss: 0.06641466915607452, acc: 0.9760000109672546)
[2024-12-17 02:08:35,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:36,046][root][INFO] - Training Epoch: 1/2, step 4925/7134 completed (loss: 0.06034553050994873, acc: 0.9799714088439941)
[2024-12-17 02:08:36,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:36,384][root][INFO] - Training Epoch: 1/2, step 4926/7134 completed (loss: 0.052020616829395294, acc: 0.9827833771705627)
[2024-12-17 02:08:36,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:36,704][root][INFO] - Training Epoch: 1/2, step 4927/7134 completed (loss: 0.07004401087760925, acc: 0.9789915680885315)
[2024-12-17 02:08:36,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:37,039][root][INFO] - Training Epoch: 1/2, step 4928/7134 completed (loss: 0.030016370117664337, acc: 0.9895712733268738)
[2024-12-17 02:08:37,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:37,376][root][INFO] - Training Epoch: 1/2, step 4929/7134 completed (loss: 0.050785455852746964, acc: 0.9860464930534363)
[2024-12-17 02:08:37,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:37,700][root][INFO] - Training Epoch: 1/2, step 4930/7134 completed (loss: 0.045100707560777664, acc: 0.9864253401756287)
[2024-12-17 02:08:37,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:38,035][root][INFO] - Training Epoch: 1/2, step 4931/7134 completed (loss: 0.11042344570159912, acc: 0.978691041469574)
[2024-12-17 02:08:38,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:38,381][root][INFO] - Training Epoch: 1/2, step 4932/7134 completed (loss: 0.04246015474200249, acc: 0.9905533194541931)
[2024-12-17 02:08:38,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:38,726][root][INFO] - Training Epoch: 1/2, step 4933/7134 completed (loss: 0.08034893870353699, acc: 0.982694685459137)
[2024-12-17 02:08:38,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:39,081][root][INFO] - Training Epoch: 1/2, step 4934/7134 completed (loss: 0.027519989758729935, acc: 0.9905277490615845)
[2024-12-17 02:08:39,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:39,434][root][INFO] - Training Epoch: 1/2, step 4935/7134 completed (loss: 0.03601260855793953, acc: 0.9890561103820801)
[2024-12-17 02:08:39,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:39,763][root][INFO] - Training Epoch: 1/2, step 4936/7134 completed (loss: 0.061607860028743744, acc: 0.9861111044883728)
[2024-12-17 02:08:39,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:40,095][root][INFO] - Training Epoch: 1/2, step 4937/7134 completed (loss: 0.04279765486717224, acc: 0.9895366430282593)
[2024-12-17 02:08:40,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:40,430][root][INFO] - Training Epoch: 1/2, step 4938/7134 completed (loss: 0.049726665019989014, acc: 0.9892037510871887)
[2024-12-17 02:08:40,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:40,766][root][INFO] - Training Epoch: 1/2, step 4939/7134 completed (loss: 0.05633874610066414, acc: 0.985318124294281)
[2024-12-17 02:08:40,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:41,103][root][INFO] - Training Epoch: 1/2, step 4940/7134 completed (loss: 0.05217454954981804, acc: 0.9878787994384766)
[2024-12-17 02:08:41,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:41,445][root][INFO] - Training Epoch: 1/2, step 4941/7134 completed (loss: 0.056726016104221344, acc: 0.9865410327911377)
[2024-12-17 02:08:41,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:41,793][root][INFO] - Training Epoch: 1/2, step 4942/7134 completed (loss: 0.04380155727267265, acc: 0.98525470495224)
[2024-12-17 02:08:41,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:42,133][root][INFO] - Training Epoch: 1/2, step 4943/7134 completed (loss: 0.06789529323577881, acc: 0.9808481335639954)
[2024-12-17 02:08:42,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:42,461][root][INFO] - Training Epoch: 1/2, step 4944/7134 completed (loss: 0.07573044300079346, acc: 0.9810526371002197)
[2024-12-17 02:08:42,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:42,756][root][INFO] - Training Epoch: 1/2, step 4945/7134 completed (loss: 0.13879767060279846, acc: 0.9576612710952759)
[2024-12-17 02:08:42,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:43,079][root][INFO] - Training Epoch: 1/2, step 4946/7134 completed (loss: 0.11154690384864807, acc: 0.9692307710647583)
[2024-12-17 02:08:43,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:43,413][root][INFO] - Training Epoch: 1/2, step 4947/7134 completed (loss: 0.059614021331071854, acc: 0.9756097793579102)
[2024-12-17 02:08:43,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:43,707][root][INFO] - Training Epoch: 1/2, step 4948/7134 completed (loss: 0.10423702001571655, acc: 0.970588207244873)
[2024-12-17 02:08:43,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:44,033][root][INFO] - Training Epoch: 1/2, step 4949/7134 completed (loss: 0.09223151206970215, acc: 0.9714285731315613)
[2024-12-17 02:08:44,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:44,369][root][INFO] - Training Epoch: 1/2, step 4950/7134 completed (loss: 0.045818619430065155, acc: 0.9824868440628052)
[2024-12-17 02:08:44,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:44,715][root][INFO] - Training Epoch: 1/2, step 4951/7134 completed (loss: 0.1362062692642212, acc: 0.9629629850387573)
[2024-12-17 02:08:44,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:45,107][root][INFO] - Training Epoch: 1/2, step 4952/7134 completed (loss: 0.07326526939868927, acc: 0.9817880988121033)
[2024-12-17 02:08:45,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:45,391][root][INFO] - Training Epoch: 1/2, step 4953/7134 completed (loss: 0.032057926058769226, acc: 0.9869281053543091)
[2024-12-17 02:08:45,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:45,713][root][INFO] - Training Epoch: 1/2, step 4954/7134 completed (loss: 0.08541803807020187, acc: 0.9800000190734863)
[2024-12-17 02:08:45,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:45,989][root][INFO] - Training Epoch: 1/2, step 4955/7134 completed (loss: 0.0726100504398346, acc: 0.9836065769195557)
[2024-12-17 02:08:46,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:46,316][root][INFO] - Training Epoch: 1/2, step 4956/7134 completed (loss: 0.04464543238282204, acc: 0.9886202216148376)
[2024-12-17 02:08:46,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:46,652][root][INFO] - Training Epoch: 1/2, step 4957/7134 completed (loss: 0.044208426028490067, acc: 0.9911816716194153)
[2024-12-17 02:08:46,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:46,981][root][INFO] - Training Epoch: 1/2, step 4958/7134 completed (loss: 0.021720513701438904, acc: 0.9942445755004883)
[2024-12-17 02:08:47,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:47,314][root][INFO] - Training Epoch: 1/2, step 4959/7134 completed (loss: 0.04222928360104561, acc: 0.9867647290229797)
[2024-12-17 02:08:47,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:47,641][root][INFO] - Training Epoch: 1/2, step 4960/7134 completed (loss: 0.023420123383402824, acc: 0.9948275685310364)
[2024-12-17 02:08:47,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:47,970][root][INFO] - Training Epoch: 1/2, step 4961/7134 completed (loss: 0.03202227130532265, acc: 0.9927140474319458)
[2024-12-17 02:08:48,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:48,293][root][INFO] - Training Epoch: 1/2, step 4962/7134 completed (loss: 0.03367161005735397, acc: 0.9891135096549988)
[2024-12-17 02:08:48,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:48,605][root][INFO] - Training Epoch: 1/2, step 4963/7134 completed (loss: 0.056997355073690414, acc: 0.9788960814476013)
[2024-12-17 02:08:48,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:48,926][root][INFO] - Training Epoch: 1/2, step 4964/7134 completed (loss: 0.04511507600545883, acc: 0.9853658676147461)
[2024-12-17 02:08:49,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:49,264][root][INFO] - Training Epoch: 1/2, step 4965/7134 completed (loss: 0.056589141488075256, acc: 0.9852941036224365)
[2024-12-17 02:08:49,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:49,593][root][INFO] - Training Epoch: 1/2, step 4966/7134 completed (loss: 0.09069839864969254, acc: 0.9778393507003784)
[2024-12-17 02:08:49,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:49,930][root][INFO] - Training Epoch: 1/2, step 4967/7134 completed (loss: 0.07270066440105438, acc: 0.98046875)
[2024-12-17 02:08:50,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:50,271][root][INFO] - Training Epoch: 1/2, step 4968/7134 completed (loss: 0.1021805927157402, acc: 0.9768683314323425)
[2024-12-17 02:08:50,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:50,616][root][INFO] - Training Epoch: 1/2, step 4969/7134 completed (loss: 0.08394566923379898, acc: 0.9776632189750671)
[2024-12-17 02:08:50,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:50,931][root][INFO] - Training Epoch: 1/2, step 4970/7134 completed (loss: 0.04970085993409157, acc: 0.9816053509712219)
[2024-12-17 02:08:51,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:51,258][root][INFO] - Training Epoch: 1/2, step 4971/7134 completed (loss: 0.05119727551937103, acc: 0.9847457408905029)
[2024-12-17 02:08:51,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:51,596][root][INFO] - Training Epoch: 1/2, step 4972/7134 completed (loss: 0.03300081938505173, acc: 0.9915373921394348)
[2024-12-17 02:08:51,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:51,921][root][INFO] - Training Epoch: 1/2, step 4973/7134 completed (loss: 0.10747670382261276, acc: 0.9650205969810486)
[2024-12-17 02:08:52,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:52,220][root][INFO] - Training Epoch: 1/2, step 4974/7134 completed (loss: 0.09154824912548065, acc: 0.9839679598808289)
[2024-12-17 02:08:52,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:52,555][root][INFO] - Training Epoch: 1/2, step 4975/7134 completed (loss: 0.1495680809020996, acc: 0.9632588028907776)
[2024-12-17 02:08:52,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:52,839][root][INFO] - Training Epoch: 1/2, step 4976/7134 completed (loss: 0.05458475649356842, acc: 0.9906322956085205)
[2024-12-17 02:08:52,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:53,186][root][INFO] - Training Epoch: 1/2, step 4977/7134 completed (loss: 0.17380082607269287, acc: 0.9612902998924255)
[2024-12-17 02:08:53,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:53,514][root][INFO] - Training Epoch: 1/2, step 4978/7134 completed (loss: 0.06432120501995087, acc: 0.9813664555549622)
[2024-12-17 02:08:53,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:53,824][root][INFO] - Training Epoch: 1/2, step 4979/7134 completed (loss: 0.12676934897899628, acc: 0.9654036164283752)
[2024-12-17 02:08:53,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:54,180][root][INFO] - Training Epoch: 1/2, step 4980/7134 completed (loss: 0.11098209023475647, acc: 0.9710144996643066)
[2024-12-17 02:08:54,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:54,536][root][INFO] - Training Epoch: 1/2, step 4981/7134 completed (loss: 0.06154331937432289, acc: 0.9840510487556458)
[2024-12-17 02:08:54,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:54,858][root][INFO] - Training Epoch: 1/2, step 4982/7134 completed (loss: 0.1772034615278244, acc: 0.9554656147956848)
[2024-12-17 02:08:54,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:55,206][root][INFO] - Training Epoch: 1/2, step 4983/7134 completed (loss: 0.08103377372026443, acc: 0.9781931638717651)
[2024-12-17 02:08:55,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:55,444][root][INFO] - Training Epoch: 1/2, step 4984/7134 completed (loss: 0.12065505236387253, acc: 0.9791666865348816)
[2024-12-17 02:08:55,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:55,752][root][INFO] - Training Epoch: 1/2, step 4985/7134 completed (loss: 0.08244548738002777, acc: 0.9785932898521423)
[2024-12-17 02:08:55,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:56,074][root][INFO] - Training Epoch: 1/2, step 4986/7134 completed (loss: 0.11745228618383408, acc: 0.96879643201828)
[2024-12-17 02:08:56,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:56,378][root][INFO] - Training Epoch: 1/2, step 4987/7134 completed (loss: 0.08270285278558731, acc: 0.9761431217193604)
[2024-12-17 02:08:56,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:56,715][root][INFO] - Training Epoch: 1/2, step 4988/7134 completed (loss: 0.08038055151700974, acc: 0.9734982252120972)
[2024-12-17 02:08:56,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:57,028][root][INFO] - Training Epoch: 1/2, step 4989/7134 completed (loss: 0.07761767506599426, acc: 0.9752475023269653)
[2024-12-17 02:08:57,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:57,351][root][INFO] - Training Epoch: 1/2, step 4990/7134 completed (loss: 0.0638166144490242, acc: 0.9898648858070374)
[2024-12-17 02:08:57,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:57,681][root][INFO] - Training Epoch: 1/2, step 4991/7134 completed (loss: 0.04556700587272644, acc: 0.9882746934890747)
[2024-12-17 02:08:57,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:58,019][root][INFO] - Training Epoch: 1/2, step 4992/7134 completed (loss: 0.15490898489952087, acc: 0.9693654179573059)
[2024-12-17 02:08:58,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:58,238][root][INFO] - Training Epoch: 1/2, step 4993/7134 completed (loss: 0.08133704215288162, acc: 0.9728506803512573)
[2024-12-17 02:08:58,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:58,597][root][INFO] - Training Epoch: 1/2, step 4994/7134 completed (loss: 0.037924252450466156, acc: 0.9914893507957458)
[2024-12-17 02:08:58,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:58,859][root][INFO] - Training Epoch: 1/2, step 4995/7134 completed (loss: 0.07321050763130188, acc: 0.9714285731315613)
[2024-12-17 02:08:58,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:59,189][root][INFO] - Training Epoch: 1/2, step 4996/7134 completed (loss: 0.07179078459739685, acc: 0.9815497994422913)
[2024-12-17 02:08:59,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:59,556][root][INFO] - Training Epoch: 1/2, step 4997/7134 completed (loss: 0.07024826109409332, acc: 0.9863013625144958)
[2024-12-17 02:08:59,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:59,810][root][INFO] - Training Epoch: 1/2, step 4998/7134 completed (loss: 0.12728364765644073, acc: 0.9699453711509705)
[2024-12-17 02:08:59,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:00,139][root][INFO] - Training Epoch: 1/2, step 4999/7134 completed (loss: 0.04656463861465454, acc: 0.9862306118011475)
[2024-12-17 02:09:00,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:00,446][root][INFO] - Training Epoch: 1/2, step 5000/7134 completed (loss: 0.06503234803676605, acc: 0.9860464930534363)
[2024-12-17 02:09:00,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:00,799][root][INFO] - Training Epoch: 1/2, step 5001/7134 completed (loss: 0.09096664190292358, acc: 0.9767441749572754)
[2024-12-17 02:09:00,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:01,123][root][INFO] - Training Epoch: 1/2, step 5002/7134 completed (loss: 0.0671408474445343, acc: 0.9851301312446594)
[2024-12-17 02:09:01,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:01,436][root][INFO] - Training Epoch: 1/2, step 5003/7134 completed (loss: 0.04946798086166382, acc: 0.9855999946594238)
[2024-12-17 02:09:01,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:01,722][root][INFO] - Training Epoch: 1/2, step 5004/7134 completed (loss: 0.0368802584707737, acc: 0.9911699891090393)
[2024-12-17 02:09:01,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:02,030][root][INFO] - Training Epoch: 1/2, step 5005/7134 completed (loss: 0.07661999762058258, acc: 0.9804878234863281)
[2024-12-17 02:09:02,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:02,374][root][INFO] - Training Epoch: 1/2, step 5006/7134 completed (loss: 0.08892707526683807, acc: 0.9794420003890991)
[2024-12-17 02:09:02,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:02,689][root][INFO] - Training Epoch: 1/2, step 5007/7134 completed (loss: 0.036216117441654205, acc: 0.994350254535675)
[2024-12-17 02:09:02,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:03,057][root][INFO] - Training Epoch: 1/2, step 5008/7134 completed (loss: 0.1205454021692276, acc: 0.9724409580230713)
[2024-12-17 02:09:03,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:03,371][root][INFO] - Training Epoch: 1/2, step 5009/7134 completed (loss: 0.11628183722496033, acc: 0.985111653804779)
[2024-12-17 02:09:03,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:03,672][root][INFO] - Training Epoch: 1/2, step 5010/7134 completed (loss: 0.07842662185430527, acc: 0.9797570705413818)
[2024-12-17 02:09:03,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:04,036][root][INFO] - Training Epoch: 1/2, step 5011/7134 completed (loss: 0.12021631002426147, acc: 0.9691057205200195)
[2024-12-17 02:09:04,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:04,286][root][INFO] - Training Epoch: 1/2, step 5012/7134 completed (loss: 0.1856662780046463, acc: 0.9568965435028076)
[2024-12-17 02:09:04,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:04,603][root][INFO] - Training Epoch: 1/2, step 5013/7134 completed (loss: 0.03841199353337288, acc: 0.991983950138092)
[2024-12-17 02:09:04,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:04,972][root][INFO] - Training Epoch: 1/2, step 5014/7134 completed (loss: 0.09265252202749252, acc: 0.9754098653793335)
[2024-12-17 02:09:05,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:05,314][root][INFO] - Training Epoch: 1/2, step 5015/7134 completed (loss: 0.12937316298484802, acc: 0.9696551561355591)
[2024-12-17 02:09:05,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:05,636][root][INFO] - Training Epoch: 1/2, step 5016/7134 completed (loss: 0.0552370660007, acc: 0.9873417615890503)
[2024-12-17 02:09:05,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:05,964][root][INFO] - Training Epoch: 1/2, step 5017/7134 completed (loss: 0.04608524963259697, acc: 0.9891892075538635)
[2024-12-17 02:09:06,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:06,297][root][INFO] - Training Epoch: 1/2, step 5018/7134 completed (loss: 0.06480923295021057, acc: 0.9769503474235535)
[2024-12-17 02:09:06,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:06,642][root][INFO] - Training Epoch: 1/2, step 5019/7134 completed (loss: 0.06817459315061569, acc: 0.9829059839248657)
[2024-12-17 02:09:06,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:07,014][root][INFO] - Training Epoch: 1/2, step 5020/7134 completed (loss: 0.072394959628582, acc: 0.9775000214576721)
[2024-12-17 02:09:07,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:07,339][root][INFO] - Training Epoch: 1/2, step 5021/7134 completed (loss: 0.06664460897445679, acc: 0.986270010471344)
[2024-12-17 02:09:07,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:07,673][root][INFO] - Training Epoch: 1/2, step 5022/7134 completed (loss: 0.07309658080339432, acc: 0.9814814925193787)
[2024-12-17 02:09:07,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:08,035][root][INFO] - Training Epoch: 1/2, step 5023/7134 completed (loss: 0.0875401720404625, acc: 0.978723406791687)
[2024-12-17 02:09:08,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:08,389][root][INFO] - Training Epoch: 1/2, step 5024/7134 completed (loss: 0.049561772495508194, acc: 0.9909909963607788)
[2024-12-17 02:09:08,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:08,721][root][INFO] - Training Epoch: 1/2, step 5025/7134 completed (loss: 0.06575178354978561, acc: 0.9818840622901917)
[2024-12-17 02:09:08,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:09,034][root][INFO] - Training Epoch: 1/2, step 5026/7134 completed (loss: 0.05866756662726402, acc: 0.985989511013031)
[2024-12-17 02:09:09,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:09,345][root][INFO] - Training Epoch: 1/2, step 5027/7134 completed (loss: 0.04979105293750763, acc: 0.9890710115432739)
[2024-12-17 02:09:09,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:09,662][root][INFO] - Training Epoch: 1/2, step 5028/7134 completed (loss: 0.03660742938518524, acc: 0.9890282154083252)
[2024-12-17 02:09:09,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:09,976][root][INFO] - Training Epoch: 1/2, step 5029/7134 completed (loss: 0.03434699773788452, acc: 0.9905303120613098)
[2024-12-17 02:09:10,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:10,323][root][INFO] - Training Epoch: 1/2, step 5030/7134 completed (loss: 0.025449950248003006, acc: 0.9931787252426147)
[2024-12-17 02:09:10,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:10,646][root][INFO] - Training Epoch: 1/2, step 5031/7134 completed (loss: 0.10767386853694916, acc: 0.9795918464660645)
[2024-12-17 02:09:10,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:10,967][root][INFO] - Training Epoch: 1/2, step 5032/7134 completed (loss: 0.05491228401660919, acc: 0.9918830990791321)
[2024-12-17 02:09:11,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:11,286][root][INFO] - Training Epoch: 1/2, step 5033/7134 completed (loss: 0.029805265367031097, acc: 0.995192289352417)
[2024-12-17 02:09:11,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:11,596][root][INFO] - Training Epoch: 1/2, step 5034/7134 completed (loss: 0.042766500264406204, acc: 0.9840425252914429)
[2024-12-17 02:09:11,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:11,914][root][INFO] - Training Epoch: 1/2, step 5035/7134 completed (loss: 0.010921891778707504, acc: 0.9961389899253845)
[2024-12-17 02:09:12,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:12,248][root][INFO] - Training Epoch: 1/2, step 5036/7134 completed (loss: 0.08014000207185745, acc: 0.9754464030265808)
[2024-12-17 02:09:12,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:12,579][root][INFO] - Training Epoch: 1/2, step 5037/7134 completed (loss: 0.09228675067424774, acc: 0.9812332391738892)
[2024-12-17 02:09:12,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:12,893][root][INFO] - Training Epoch: 1/2, step 5038/7134 completed (loss: 0.08331245183944702, acc: 0.9799554347991943)
[2024-12-17 02:09:12,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:13,193][root][INFO] - Training Epoch: 1/2, step 5039/7134 completed (loss: 0.050125472247600555, acc: 0.9857594966888428)
[2024-12-17 02:09:13,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:13,502][root][INFO] - Training Epoch: 1/2, step 5040/7134 completed (loss: 0.026299038901925087, acc: 0.990439772605896)
[2024-12-17 02:09:13,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:13,844][root][INFO] - Training Epoch: 1/2, step 5041/7134 completed (loss: 0.018874287605285645, acc: 0.9960212111473083)
[2024-12-17 02:09:13,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:14,132][root][INFO] - Training Epoch: 1/2, step 5042/7134 completed (loss: 0.07494141906499863, acc: 0.9883449673652649)
[2024-12-17 02:09:14,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:14,412][root][INFO] - Training Epoch: 1/2, step 5043/7134 completed (loss: 0.08028332144021988, acc: 0.9723320007324219)
[2024-12-17 02:09:14,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:14,764][root][INFO] - Training Epoch: 1/2, step 5044/7134 completed (loss: 0.04408587887883186, acc: 0.9868420958518982)
[2024-12-17 02:09:14,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:15,127][root][INFO] - Training Epoch: 1/2, step 5045/7134 completed (loss: 0.10047762840986252, acc: 0.9798115491867065)
[2024-12-17 02:09:15,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:15,396][root][INFO] - Training Epoch: 1/2, step 5046/7134 completed (loss: 0.11798328906297684, acc: 0.9719298481941223)
[2024-12-17 02:09:15,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:15,667][root][INFO] - Training Epoch: 1/2, step 5047/7134 completed (loss: 0.10138950496912003, acc: 0.9768595099449158)
[2024-12-17 02:09:15,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:16,026][root][INFO] - Training Epoch: 1/2, step 5048/7134 completed (loss: 0.10431449115276337, acc: 0.9726027250289917)
[2024-12-17 02:09:16,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:16,339][root][INFO] - Training Epoch: 1/2, step 5049/7134 completed (loss: 0.10733214020729065, acc: 0.968664824962616)
[2024-12-17 02:09:16,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:16,676][root][INFO] - Training Epoch: 1/2, step 5050/7134 completed (loss: 0.07890599220991135, acc: 0.9760900139808655)
[2024-12-17 02:09:16,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:17,013][root][INFO] - Training Epoch: 1/2, step 5051/7134 completed (loss: 0.10844821482896805, acc: 0.969565212726593)
[2024-12-17 02:09:17,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:17,334][root][INFO] - Training Epoch: 1/2, step 5052/7134 completed (loss: 0.04324037581682205, acc: 0.989393949508667)
[2024-12-17 02:09:17,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:17,661][root][INFO] - Training Epoch: 1/2, step 5053/7134 completed (loss: 0.12380807101726532, acc: 0.9698113203048706)
[2024-12-17 02:09:17,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:18,020][root][INFO] - Training Epoch: 1/2, step 5054/7134 completed (loss: 0.14040671288967133, acc: 0.965299665927887)
[2024-12-17 02:09:18,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:18,289][root][INFO] - Training Epoch: 1/2, step 5055/7134 completed (loss: 0.052563805133104324, acc: 0.981632649898529)
[2024-12-17 02:09:18,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:18,624][root][INFO] - Training Epoch: 1/2, step 5056/7134 completed (loss: 0.15970753133296967, acc: 0.9603174328804016)
[2024-12-17 02:09:18,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:18,966][root][INFO] - Training Epoch: 1/2, step 5057/7134 completed (loss: 0.1331247091293335, acc: 0.9729729890823364)
[2024-12-17 02:09:19,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:19,292][root][INFO] - Training Epoch: 1/2, step 5058/7134 completed (loss: 0.1274346113204956, acc: 0.9710144996643066)
[2024-12-17 02:09:19,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:19,647][root][INFO] - Training Epoch: 1/2, step 5059/7134 completed (loss: 0.08981506526470184, acc: 0.9711664319038391)
[2024-12-17 02:09:19,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:19,985][root][INFO] - Training Epoch: 1/2, step 5060/7134 completed (loss: 0.0720166563987732, acc: 0.9836552739143372)
[2024-12-17 02:09:20,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:20,307][root][INFO] - Training Epoch: 1/2, step 5061/7134 completed (loss: 0.09360019117593765, acc: 0.9719222187995911)
[2024-12-17 02:09:20,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:20,646][root][INFO] - Training Epoch: 1/2, step 5062/7134 completed (loss: 0.10820291936397552, acc: 0.9759863018989563)
[2024-12-17 02:09:20,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:20,987][root][INFO] - Training Epoch: 1/2, step 5063/7134 completed (loss: 0.08357610553503036, acc: 0.9782971739768982)
[2024-12-17 02:09:21,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:21,337][root][INFO] - Training Epoch: 1/2, step 5064/7134 completed (loss: 0.07593507319688797, acc: 0.9897260069847107)
[2024-12-17 02:09:21,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:21,697][root][INFO] - Training Epoch: 1/2, step 5065/7134 completed (loss: 0.08068440854549408, acc: 0.9816642999649048)
[2024-12-17 02:09:21,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:22,031][root][INFO] - Training Epoch: 1/2, step 5066/7134 completed (loss: 0.10174999386072159, acc: 0.9712556600570679)
[2024-12-17 02:09:22,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:22,385][root][INFO] - Training Epoch: 1/2, step 5067/7134 completed (loss: 0.04853958636522293, acc: 0.9844054579734802)
[2024-12-17 02:09:22,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:22,719][root][INFO] - Training Epoch: 1/2, step 5068/7134 completed (loss: 0.07862979918718338, acc: 0.9857819676399231)
[2024-12-17 02:09:22,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:23,055][root][INFO] - Training Epoch: 1/2, step 5069/7134 completed (loss: 0.06016964837908745, acc: 0.9859374761581421)
[2024-12-17 02:09:23,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:23,359][root][INFO] - Training Epoch: 1/2, step 5070/7134 completed (loss: 0.05500560998916626, acc: 0.9885057210922241)
[2024-12-17 02:09:23,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:23,691][root][INFO] - Training Epoch: 1/2, step 5071/7134 completed (loss: 0.11127077788114548, acc: 0.9663394093513489)
[2024-12-17 02:09:23,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:24,029][root][INFO] - Training Epoch: 1/2, step 5072/7134 completed (loss: 0.11908183246850967, acc: 0.9698870778083801)
[2024-12-17 02:09:24,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:24,350][root][INFO] - Training Epoch: 1/2, step 5073/7134 completed (loss: 0.1487002968788147, acc: 0.9555125832557678)
[2024-12-17 02:09:24,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:24,700][root][INFO] - Training Epoch: 1/2, step 5074/7134 completed (loss: 0.0797194391489029, acc: 0.9751243591308594)
[2024-12-17 02:09:24,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:25,017][root][INFO] - Training Epoch: 1/2, step 5075/7134 completed (loss: 0.10732878744602203, acc: 0.9709302186965942)
[2024-12-17 02:09:25,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:25,378][root][INFO] - Training Epoch: 1/2, step 5076/7134 completed (loss: 0.09211291372776031, acc: 0.9748803973197937)
[2024-12-17 02:09:25,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:25,728][root][INFO] - Training Epoch: 1/2, step 5077/7134 completed (loss: 0.08491165935993195, acc: 0.9731012582778931)
[2024-12-17 02:09:25,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:26,055][root][INFO] - Training Epoch: 1/2, step 5078/7134 completed (loss: 0.11740302294492722, acc: 0.9686192274093628)
[2024-12-17 02:09:26,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:26,381][root][INFO] - Training Epoch: 1/2, step 5079/7134 completed (loss: 0.05285757780075073, acc: 0.9850339889526367)
[2024-12-17 02:09:26,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:26,743][root][INFO] - Training Epoch: 1/2, step 5080/7134 completed (loss: 0.07615939527750015, acc: 0.9763593673706055)
[2024-12-17 02:09:26,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:27,082][root][INFO] - Training Epoch: 1/2, step 5081/7134 completed (loss: 0.03421697020530701, acc: 0.989130437374115)
[2024-12-17 02:09:27,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:27,437][root][INFO] - Training Epoch: 1/2, step 5082/7134 completed (loss: 0.05255253612995148, acc: 0.988095223903656)
[2024-12-17 02:09:27,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:27,765][root][INFO] - Training Epoch: 1/2, step 5083/7134 completed (loss: 0.07111018151044846, acc: 0.9873417615890503)
[2024-12-17 02:09:27,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:28,133][root][INFO] - Training Epoch: 1/2, step 5084/7134 completed (loss: 0.04793577641248703, acc: 0.9884259104728699)
[2024-12-17 02:09:28,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:28,502][root][INFO] - Training Epoch: 1/2, step 5085/7134 completed (loss: 0.0562322661280632, acc: 0.9857988357543945)
[2024-12-17 02:09:28,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:28,835][root][INFO] - Training Epoch: 1/2, step 5086/7134 completed (loss: 0.07301722466945648, acc: 0.9809402823448181)
[2024-12-17 02:09:28,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:29,185][root][INFO] - Training Epoch: 1/2, step 5087/7134 completed (loss: 0.022992370650172234, acc: 0.9946452379226685)
[2024-12-17 02:09:29,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:29,519][root][INFO] - Training Epoch: 1/2, step 5088/7134 completed (loss: 0.018604721873998642, acc: 0.9956076145172119)
[2024-12-17 02:09:29,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:29,870][root][INFO] - Training Epoch: 1/2, step 5089/7134 completed (loss: 0.039302460849285126, acc: 0.9912717938423157)
[2024-12-17 02:09:30,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:30,223][root][INFO] - Training Epoch: 1/2, step 5090/7134 completed (loss: 0.034155137836933136, acc: 0.9883313775062561)
[2024-12-17 02:09:30,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:30,554][root][INFO] - Training Epoch: 1/2, step 5091/7134 completed (loss: 0.031086059287190437, acc: 0.9934123754501343)
[2024-12-17 02:09:30,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:30,884][root][INFO] - Training Epoch: 1/2, step 5092/7134 completed (loss: 0.07945192605257034, acc: 0.9806362390518188)
[2024-12-17 02:09:30,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:31,213][root][INFO] - Training Epoch: 1/2, step 5093/7134 completed (loss: 0.05789628624916077, acc: 0.9848066568374634)
[2024-12-17 02:09:31,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:31,545][root][INFO] - Training Epoch: 1/2, step 5094/7134 completed (loss: 0.058995138853788376, acc: 0.9872727394104004)
[2024-12-17 02:09:31,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:31,864][root][INFO] - Training Epoch: 1/2, step 5095/7134 completed (loss: 0.17946620285511017, acc: 0.9656786322593689)
[2024-12-17 02:09:32,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:32,221][root][INFO] - Training Epoch: 1/2, step 5096/7134 completed (loss: 0.07482201606035233, acc: 0.9780346751213074)
[2024-12-17 02:09:32,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:32,574][root][INFO] - Training Epoch: 1/2, step 5097/7134 completed (loss: 0.07811732590198517, acc: 0.9780219793319702)
[2024-12-17 02:09:32,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:32,926][root][INFO] - Training Epoch: 1/2, step 5098/7134 completed (loss: 0.06897075474262238, acc: 0.9786276817321777)
[2024-12-17 02:09:33,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:33,290][root][INFO] - Training Epoch: 1/2, step 5099/7134 completed (loss: 0.07187586277723312, acc: 0.9757505655288696)
[2024-12-17 02:09:33,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:33,650][root][INFO] - Training Epoch: 1/2, step 5100/7134 completed (loss: 0.06433935463428497, acc: 0.9801762104034424)
[2024-12-17 02:09:33,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:33,996][root][INFO] - Training Epoch: 1/2, step 5101/7134 completed (loss: 0.050008490681648254, acc: 0.9825174808502197)
[2024-12-17 02:09:34,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:34,320][root][INFO] - Training Epoch: 1/2, step 5102/7134 completed (loss: 0.08689551800489426, acc: 0.9781718850135803)
[2024-12-17 02:09:34,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:34,691][root][INFO] - Training Epoch: 1/2, step 5103/7134 completed (loss: 0.08117979764938354, acc: 0.9782359600067139)
[2024-12-17 02:09:34,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:35,060][root][INFO] - Training Epoch: 1/2, step 5104/7134 completed (loss: 0.04665596783161163, acc: 0.9867109656333923)
[2024-12-17 02:09:35,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:35,369][root][INFO] - Training Epoch: 1/2, step 5105/7134 completed (loss: 0.051028285175561905, acc: 0.9836065769195557)
[2024-12-17 02:09:35,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:35,710][root][INFO] - Training Epoch: 1/2, step 5106/7134 completed (loss: 0.04248432815074921, acc: 0.9866666793823242)
[2024-12-17 02:09:35,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:36,046][root][INFO] - Training Epoch: 1/2, step 5107/7134 completed (loss: 0.13519537448883057, acc: 0.9778130054473877)
[2024-12-17 02:09:36,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:36,363][root][INFO] - Training Epoch: 1/2, step 5108/7134 completed (loss: 0.12126336246728897, acc: 0.9756097793579102)
[2024-12-17 02:09:36,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:36,734][root][INFO] - Training Epoch: 1/2, step 5109/7134 completed (loss: 0.11376942694187164, acc: 0.971238911151886)
[2024-12-17 02:09:36,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:37,078][root][INFO] - Training Epoch: 1/2, step 5110/7134 completed (loss: 0.11367753893136978, acc: 0.9743589758872986)
[2024-12-17 02:09:37,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:37,408][root][INFO] - Training Epoch: 1/2, step 5111/7134 completed (loss: 0.055855121463537216, acc: 0.983561635017395)
[2024-12-17 02:09:37,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:37,761][root][INFO] - Training Epoch: 1/2, step 5112/7134 completed (loss: 0.06847848743200302, acc: 0.9775840640068054)
[2024-12-17 02:09:37,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:38,074][root][INFO] - Training Epoch: 1/2, step 5113/7134 completed (loss: 0.09415984153747559, acc: 0.9746268391609192)
[2024-12-17 02:09:38,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:38,447][root][INFO] - Training Epoch: 1/2, step 5114/7134 completed (loss: 0.0532449446618557, acc: 0.9833101630210876)
[2024-12-17 02:09:38,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:38,788][root][INFO] - Training Epoch: 1/2, step 5115/7134 completed (loss: 0.03830090910196304, acc: 0.9922580718994141)
[2024-12-17 02:09:38,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:39,157][root][INFO] - Training Epoch: 1/2, step 5116/7134 completed (loss: 0.0418207086622715, acc: 0.9870129823684692)
[2024-12-17 02:09:39,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:39,492][root][INFO] - Training Epoch: 1/2, step 5117/7134 completed (loss: 0.05782490596175194, acc: 0.9846583008766174)
[2024-12-17 02:09:39,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:39,802][root][INFO] - Training Epoch: 1/2, step 5118/7134 completed (loss: 0.09276407212018967, acc: 0.9787557125091553)
[2024-12-17 02:09:39,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:40,145][root][INFO] - Training Epoch: 1/2, step 5119/7134 completed (loss: 0.07191015779972076, acc: 0.9917469024658203)
[2024-12-17 02:09:40,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:40,478][root][INFO] - Training Epoch: 1/2, step 5120/7134 completed (loss: 0.08767952024936676, acc: 0.9790576100349426)
[2024-12-17 02:09:40,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:40,824][root][INFO] - Training Epoch: 1/2, step 5121/7134 completed (loss: 0.05466858670115471, acc: 0.9875173568725586)
[2024-12-17 02:09:40,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:41,156][root][INFO] - Training Epoch: 1/2, step 5122/7134 completed (loss: 0.08826177567243576, acc: 0.9774965047836304)
[2024-12-17 02:09:41,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:41,508][root][INFO] - Training Epoch: 1/2, step 5123/7134 completed (loss: 0.050993017852306366, acc: 0.9867309927940369)
[2024-12-17 02:09:41,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:41,853][root][INFO] - Training Epoch: 1/2, step 5124/7134 completed (loss: 0.08830127865076065, acc: 0.9763975143432617)
[2024-12-17 02:09:41,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:42,191][root][INFO] - Training Epoch: 1/2, step 5125/7134 completed (loss: 0.07327724993228912, acc: 0.9873617887496948)
[2024-12-17 02:09:42,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:42,536][root][INFO] - Training Epoch: 1/2, step 5126/7134 completed (loss: 0.03291049599647522, acc: 0.9931623935699463)
[2024-12-17 02:09:42,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:42,865][root][INFO] - Training Epoch: 1/2, step 5127/7134 completed (loss: 0.08217835426330566, acc: 0.9832167625427246)
[2024-12-17 02:09:42,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:43,218][root][INFO] - Training Epoch: 1/2, step 5128/7134 completed (loss: 0.048908501863479614, acc: 0.9912087917327881)
[2024-12-17 02:09:43,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:43,563][root][INFO] - Training Epoch: 1/2, step 5129/7134 completed (loss: 0.10361133515834808, acc: 0.9725490212440491)
[2024-12-17 02:09:43,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:43,903][root][INFO] - Training Epoch: 1/2, step 5130/7134 completed (loss: 0.04846854880452156, acc: 0.9890795350074768)
[2024-12-17 02:09:44,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:44,255][root][INFO] - Training Epoch: 1/2, step 5131/7134 completed (loss: 0.05432828515768051, acc: 0.9870129823684692)
[2024-12-17 02:09:44,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:44,559][root][INFO] - Training Epoch: 1/2, step 5132/7134 completed (loss: 0.053948719054460526, acc: 0.9841583967208862)
[2024-12-17 02:09:44,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:44,905][root][INFO] - Training Epoch: 1/2, step 5133/7134 completed (loss: 0.09339392185211182, acc: 0.9751552939414978)
[2024-12-17 02:09:45,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:45,291][root][INFO] - Training Epoch: 1/2, step 5134/7134 completed (loss: 0.050537314265966415, acc: 0.9887429475784302)
[2024-12-17 02:09:45,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:45,626][root][INFO] - Training Epoch: 1/2, step 5135/7134 completed (loss: 0.09829128533601761, acc: 0.9757142663002014)
[2024-12-17 02:09:45,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:45,975][root][INFO] - Training Epoch: 1/2, step 5136/7134 completed (loss: 0.0701836422085762, acc: 0.9781420826911926)
[2024-12-17 02:09:46,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:46,326][root][INFO] - Training Epoch: 1/2, step 5137/7134 completed (loss: 0.05213781073689461, acc: 0.988990843296051)
[2024-12-17 02:09:46,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:46,684][root][INFO] - Training Epoch: 1/2, step 5138/7134 completed (loss: 0.043668050318956375, acc: 0.9887499809265137)
[2024-12-17 02:09:46,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:46,996][root][INFO] - Training Epoch: 1/2, step 5139/7134 completed (loss: 0.042143356055021286, acc: 0.991416335105896)
[2024-12-17 02:09:47,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:47,349][root][INFO] - Training Epoch: 1/2, step 5140/7134 completed (loss: 0.051986467093229294, acc: 0.9851537942886353)
[2024-12-17 02:09:47,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:47,621][root][INFO] - Training Epoch: 1/2, step 5141/7134 completed (loss: 0.07649945467710495, acc: 0.9884169697761536)
[2024-12-17 02:09:47,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:47,985][root][INFO] - Training Epoch: 1/2, step 5142/7134 completed (loss: 0.08377177268266678, acc: 0.9823529124259949)
[2024-12-17 02:09:48,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:48,348][root][INFO] - Training Epoch: 1/2, step 5143/7134 completed (loss: 0.08991263061761856, acc: 0.9784263968467712)
[2024-12-17 02:09:48,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:48,694][root][INFO] - Training Epoch: 1/2, step 5144/7134 completed (loss: 0.048048149794340134, acc: 0.9859976768493652)
[2024-12-17 02:09:48,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:49,059][root][INFO] - Training Epoch: 1/2, step 5145/7134 completed (loss: 0.04740389436483383, acc: 0.9856704473495483)
[2024-12-17 02:09:49,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:49,422][root][INFO] - Training Epoch: 1/2, step 5146/7134 completed (loss: 0.0961700826883316, acc: 0.9777034521102905)
[2024-12-17 02:09:49,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:49,767][root][INFO] - Training Epoch: 1/2, step 5147/7134 completed (loss: 0.03982081264257431, acc: 0.9877049326896667)
[2024-12-17 02:09:49,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:50,098][root][INFO] - Training Epoch: 1/2, step 5148/7134 completed (loss: 0.12477587908506393, acc: 0.9786950945854187)
[2024-12-17 02:09:50,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:50,467][root][INFO] - Training Epoch: 1/2, step 5149/7134 completed (loss: 0.0804869756102562, acc: 0.9771144390106201)
[2024-12-17 02:09:50,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:50,803][root][INFO] - Training Epoch: 1/2, step 5150/7134 completed (loss: 0.12396812438964844, acc: 0.9674054980278015)
[2024-12-17 02:09:50,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:51,137][root][INFO] - Training Epoch: 1/2, step 5151/7134 completed (loss: 0.08887312561273575, acc: 0.9740098714828491)
[2024-12-17 02:09:51,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:51,486][root][INFO] - Training Epoch: 1/2, step 5152/7134 completed (loss: 0.07091464102268219, acc: 0.9758713245391846)
[2024-12-17 02:09:51,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:51,836][root][INFO] - Training Epoch: 1/2, step 5153/7134 completed (loss: 0.05142708495259285, acc: 0.9890260696411133)
[2024-12-17 02:09:51,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:52,206][root][INFO] - Training Epoch: 1/2, step 5154/7134 completed (loss: 0.0809524729847908, acc: 0.9817975163459778)
[2024-12-17 02:09:52,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:52,582][root][INFO] - Training Epoch: 1/2, step 5155/7134 completed (loss: 0.06462614238262177, acc: 0.9804216623306274)
[2024-12-17 02:09:52,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:52,983][root][INFO] - Training Epoch: 1/2, step 5156/7134 completed (loss: 0.05801315978169441, acc: 0.9860973358154297)
[2024-12-17 02:09:53,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:53,333][root][INFO] - Training Epoch: 1/2, step 5157/7134 completed (loss: 0.12772178649902344, acc: 0.9621027112007141)
[2024-12-17 02:09:53,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:53,680][root][INFO] - Training Epoch: 1/2, step 5158/7134 completed (loss: 0.11664681881666183, acc: 0.9673590660095215)
[2024-12-17 02:09:53,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:54,022][root][INFO] - Training Epoch: 1/2, step 5159/7134 completed (loss: 0.04159921780228615, acc: 0.9869961142539978)
[2024-12-17 02:09:54,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:54,373][root][INFO] - Training Epoch: 1/2, step 5160/7134 completed (loss: 0.07595490664243698, acc: 0.9769452214241028)
[2024-12-17 02:09:54,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:54,714][root][INFO] - Training Epoch: 1/2, step 5161/7134 completed (loss: 0.09651032835245132, acc: 0.9692307710647583)
[2024-12-17 02:09:54,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:55,041][root][INFO] - Training Epoch: 1/2, step 5162/7134 completed (loss: 0.06936798989772797, acc: 0.9837925434112549)
[2024-12-17 02:09:55,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:55,364][root][INFO] - Training Epoch: 1/2, step 5163/7134 completed (loss: 0.038359466940164566, acc: 0.9915013909339905)
[2024-12-17 02:09:55,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:55,687][root][INFO] - Training Epoch: 1/2, step 5164/7134 completed (loss: 0.036806654185056686, acc: 0.9915966391563416)
[2024-12-17 02:09:55,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:56,054][root][INFO] - Training Epoch: 1/2, step 5165/7134 completed (loss: 0.09207374602556229, acc: 0.9728915691375732)
[2024-12-17 02:09:56,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:56,387][root][INFO] - Training Epoch: 1/2, step 5166/7134 completed (loss: 0.057898614555597305, acc: 0.9863013625144958)
[2024-12-17 02:09:56,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:56,721][root][INFO] - Training Epoch: 1/2, step 5167/7134 completed (loss: 0.09862589836120605, acc: 0.9759615659713745)
[2024-12-17 02:09:56,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:57,052][root][INFO] - Training Epoch: 1/2, step 5168/7134 completed (loss: 0.0770992636680603, acc: 0.9736024737358093)
[2024-12-17 02:09:57,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:57,407][root][INFO] - Training Epoch: 1/2, step 5169/7134 completed (loss: 0.08561591058969498, acc: 0.9797507524490356)
[2024-12-17 02:09:57,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:57,763][root][INFO] - Training Epoch: 1/2, step 5170/7134 completed (loss: 0.0819980651140213, acc: 0.9801324605941772)
[2024-12-17 02:09:57,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:58,043][root][INFO] - Training Epoch: 1/2, step 5171/7134 completed (loss: 0.07211412489414215, acc: 0.9829059839248657)
[2024-12-17 02:09:58,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:58,377][root][INFO] - Training Epoch: 1/2, step 5172/7134 completed (loss: 0.18857301771640778, acc: 0.9608176946640015)
[2024-12-17 02:09:58,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:58,703][root][INFO] - Training Epoch: 1/2, step 5173/7134 completed (loss: 0.0700424462556839, acc: 0.9811023473739624)
[2024-12-17 02:09:58,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:59,056][root][INFO] - Training Epoch: 1/2, step 5174/7134 completed (loss: 0.039361972361803055, acc: 0.9885057210922241)
[2024-12-17 02:09:59,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:59,412][root][INFO] - Training Epoch: 1/2, step 5175/7134 completed (loss: 0.02878333441913128, acc: 0.988950252532959)
[2024-12-17 02:09:59,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:59,766][root][INFO] - Training Epoch: 1/2, step 5176/7134 completed (loss: 0.045903515070676804, acc: 0.9893778562545776)
[2024-12-17 02:09:59,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:00,117][root][INFO] - Training Epoch: 1/2, step 5177/7134 completed (loss: 0.10359695553779602, acc: 0.9686956405639648)
[2024-12-17 02:10:00,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:00,448][root][INFO] - Training Epoch: 1/2, step 5178/7134 completed (loss: 0.14849913120269775, acc: 0.9686411023139954)
[2024-12-17 02:10:00,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:00,789][root][INFO] - Training Epoch: 1/2, step 5179/7134 completed (loss: 0.05792655423283577, acc: 0.9852070808410645)
[2024-12-17 02:10:00,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:01,092][root][INFO] - Training Epoch: 1/2, step 5180/7134 completed (loss: 0.07635282725095749, acc: 0.9812382459640503)
[2024-12-17 02:10:01,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:01,371][root][INFO] - Training Epoch: 1/2, step 5181/7134 completed (loss: 0.12434937804937363, acc: 0.9680851101875305)
[2024-12-17 02:10:01,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:01,678][root][INFO] - Training Epoch: 1/2, step 5182/7134 completed (loss: 0.2469668984413147, acc: 0.9354166388511658)
[2024-12-17 02:10:01,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:02,008][root][INFO] - Training Epoch: 1/2, step 5183/7134 completed (loss: 0.1149967685341835, acc: 0.9785478711128235)
[2024-12-17 02:10:02,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:02,317][root][INFO] - Training Epoch: 1/2, step 5184/7134 completed (loss: 0.09100081771612167, acc: 0.980440080165863)
[2024-12-17 02:10:02,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:02,643][root][INFO] - Training Epoch: 1/2, step 5185/7134 completed (loss: 0.06796683371067047, acc: 0.9879518151283264)
[2024-12-17 02:10:02,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:02,971][root][INFO] - Training Epoch: 1/2, step 5186/7134 completed (loss: 0.0870596244931221, acc: 0.981670081615448)
[2024-12-17 02:10:03,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:03,292][root][INFO] - Training Epoch: 1/2, step 5187/7134 completed (loss: 0.0431925430893898, acc: 0.9904761910438538)
[2024-12-17 02:10:03,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:03,641][root][INFO] - Training Epoch: 1/2, step 5188/7134 completed (loss: 0.2680959105491638, acc: 0.9490908980369568)
[2024-12-17 02:10:03,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:03,880][root][INFO] - Training Epoch: 1/2, step 5189/7134 completed (loss: 0.23284411430358887, acc: 0.9515306353569031)
[2024-12-17 02:10:04,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:04,173][root][INFO] - Training Epoch: 1/2, step 5190/7134 completed (loss: 0.23495259881019592, acc: 0.9548693299293518)
[2024-12-17 02:10:04,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:04,548][root][INFO] - Training Epoch: 1/2, step 5191/7134 completed (loss: 0.16859033703804016, acc: 0.9604685306549072)
[2024-12-17 02:10:04,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:04,897][root][INFO] - Training Epoch: 1/2, step 5192/7134 completed (loss: 0.12086531519889832, acc: 0.9774078726768494)
[2024-12-17 02:10:04,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:05,236][root][INFO] - Training Epoch: 1/2, step 5193/7134 completed (loss: 0.10646256059408188, acc: 0.9704724550247192)
[2024-12-17 02:10:05,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:05,567][root][INFO] - Training Epoch: 1/2, step 5194/7134 completed (loss: 0.18702028691768646, acc: 0.9425742626190186)
[2024-12-17 02:10:05,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:05,846][root][INFO] - Training Epoch: 1/2, step 5195/7134 completed (loss: 0.12012302130460739, acc: 0.9780701994895935)
[2024-12-17 02:10:05,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:06,143][root][INFO] - Training Epoch: 1/2, step 5196/7134 completed (loss: 0.13248206675052643, acc: 0.9712918400764465)
[2024-12-17 02:10:06,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:06,457][root][INFO] - Training Epoch: 1/2, step 5197/7134 completed (loss: 0.08952624350786209, acc: 0.9773662686347961)
[2024-12-17 02:10:06,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:06,764][root][INFO] - Training Epoch: 1/2, step 5198/7134 completed (loss: 0.14793671667575836, acc: 0.9708939790725708)
[2024-12-17 02:10:06,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:07,132][root][INFO] - Training Epoch: 1/2, step 5199/7134 completed (loss: 0.20060910284519196, acc: 0.9520348906517029)
[2024-12-17 02:10:07,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:07,458][root][INFO] - Training Epoch: 1/2, step 5200/7134 completed (loss: 0.09449538588523865, acc: 0.9764243364334106)
[2024-12-17 02:10:07,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:07,815][root][INFO] - Training Epoch: 1/2, step 5201/7134 completed (loss: 0.1394944190979004, acc: 0.9698432087898254)
[2024-12-17 02:10:07,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:08,140][root][INFO] - Training Epoch: 1/2, step 5202/7134 completed (loss: 0.1874450445175171, acc: 0.9519230723381042)
[2024-12-17 02:10:08,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:08,486][root][INFO] - Training Epoch: 1/2, step 5203/7134 completed (loss: 0.1284058839082718, acc: 0.9714285731315613)
[2024-12-17 02:10:08,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:08,800][root][INFO] - Training Epoch: 1/2, step 5204/7134 completed (loss: 0.08131610602140427, acc: 0.9752577543258667)
[2024-12-17 02:10:08,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:09,038][root][INFO] - Training Epoch: 1/2, step 5205/7134 completed (loss: 0.19143818318843842, acc: 0.9475655555725098)
[2024-12-17 02:10:09,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:09,391][root][INFO] - Training Epoch: 1/2, step 5206/7134 completed (loss: 0.18610970675945282, acc: 0.9390048384666443)
[2024-12-17 02:10:09,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:09,709][root][INFO] - Training Epoch: 1/2, step 5207/7134 completed (loss: 0.11423560231924057, acc: 0.9678068161010742)
[2024-12-17 02:10:09,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:10,097][root][INFO] - Training Epoch: 1/2, step 5208/7134 completed (loss: 0.05687202885746956, acc: 0.9815303683280945)
[2024-12-17 02:10:10,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:10,425][root][INFO] - Training Epoch: 1/2, step 5209/7134 completed (loss: 0.14392438530921936, acc: 0.9698795080184937)
[2024-12-17 02:10:10,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:10,797][root][INFO] - Training Epoch: 1/2, step 5210/7134 completed (loss: 0.09386827796697617, acc: 0.9786381721496582)
[2024-12-17 02:10:10,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:11,151][root][INFO] - Training Epoch: 1/2, step 5211/7134 completed (loss: 0.10571638494729996, acc: 0.9670138955116272)
[2024-12-17 02:10:11,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:11,414][root][INFO] - Training Epoch: 1/2, step 5212/7134 completed (loss: 0.15920795500278473, acc: 0.9488054513931274)
[2024-12-17 02:10:11,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:11,741][root][INFO] - Training Epoch: 1/2, step 5213/7134 completed (loss: 0.15615689754486084, acc: 0.9586330652236938)
[2024-12-17 02:10:11,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:12,066][root][INFO] - Training Epoch: 1/2, step 5214/7134 completed (loss: 0.1919364184141159, acc: 0.9527897238731384)
[2024-12-17 02:10:12,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:12,431][root][INFO] - Training Epoch: 1/2, step 5215/7134 completed (loss: 0.19744263589382172, acc: 0.954023003578186)
[2024-12-17 02:10:12,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:12,662][root][INFO] - Training Epoch: 1/2, step 5216/7134 completed (loss: 0.1549552083015442, acc: 0.9505703449249268)
[2024-12-17 02:10:12,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:12,938][root][INFO] - Training Epoch: 1/2, step 5217/7134 completed (loss: 0.1415354609489441, acc: 0.957317054271698)
[2024-12-17 02:10:13,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:13,236][root][INFO] - Training Epoch: 1/2, step 5218/7134 completed (loss: 0.10370951145887375, acc: 0.968539297580719)
[2024-12-17 02:10:13,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:13,540][root][INFO] - Training Epoch: 1/2, step 5219/7134 completed (loss: 0.09982796013355255, acc: 0.9709442853927612)
[2024-12-17 02:10:13,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:13,839][root][INFO] - Training Epoch: 1/2, step 5220/7134 completed (loss: 0.13167835772037506, acc: 0.9624329209327698)
[2024-12-17 02:10:13,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:14,174][root][INFO] - Training Epoch: 1/2, step 5221/7134 completed (loss: 0.12942327558994293, acc: 0.9719626307487488)
[2024-12-17 02:10:14,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:14,422][root][INFO] - Training Epoch: 1/2, step 5222/7134 completed (loss: 0.09489333629608154, acc: 0.9750778675079346)
[2024-12-17 02:10:14,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:14,752][root][INFO] - Training Epoch: 1/2, step 5223/7134 completed (loss: 0.08839385211467743, acc: 0.9723502397537231)
[2024-12-17 02:10:14,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:15,067][root][INFO] - Training Epoch: 1/2, step 5224/7134 completed (loss: 0.09575830399990082, acc: 0.9789103865623474)
[2024-12-17 02:10:15,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:15,419][root][INFO] - Training Epoch: 1/2, step 5225/7134 completed (loss: 0.15942025184631348, acc: 0.9693053364753723)
[2024-12-17 02:10:15,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:15,762][root][INFO] - Training Epoch: 1/2, step 5226/7134 completed (loss: 0.11209110170602798, acc: 0.9752883315086365)
[2024-12-17 02:10:15,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:16,125][root][INFO] - Training Epoch: 1/2, step 5227/7134 completed (loss: 0.06252872198820114, acc: 0.9883117079734802)
[2024-12-17 02:10:16,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:16,449][root][INFO] - Training Epoch: 1/2, step 5228/7134 completed (loss: 0.0937810018658638, acc: 0.9767441749572754)
[2024-12-17 02:10:16,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:16,785][root][INFO] - Training Epoch: 1/2, step 5229/7134 completed (loss: 0.06109621375799179, acc: 0.9851411581039429)
[2024-12-17 02:10:16,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:17,125][root][INFO] - Training Epoch: 1/2, step 5230/7134 completed (loss: 0.045274004340171814, acc: 0.9919137358665466)
[2024-12-17 02:10:17,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:17,484][root][INFO] - Training Epoch: 1/2, step 5231/7134 completed (loss: 0.04747730866074562, acc: 0.9886075854301453)
[2024-12-17 02:10:17,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:17,823][root][INFO] - Training Epoch: 1/2, step 5232/7134 completed (loss: 0.06917865574359894, acc: 0.9820627570152283)
[2024-12-17 02:10:17,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:18,196][root][INFO] - Training Epoch: 1/2, step 5233/7134 completed (loss: 0.10139024257659912, acc: 0.9786036014556885)
[2024-12-17 02:10:18,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:18,557][root][INFO] - Training Epoch: 1/2, step 5234/7134 completed (loss: 0.06871648877859116, acc: 0.9804161787033081)
[2024-12-17 02:10:18,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:18,876][root][INFO] - Training Epoch: 1/2, step 5235/7134 completed (loss: 0.055325232446193695, acc: 0.9865546226501465)
[2024-12-17 02:10:18,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:19,198][root][INFO] - Training Epoch: 1/2, step 5236/7134 completed (loss: 0.027414092794060707, acc: 0.9913194179534912)
[2024-12-17 02:10:19,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:19,528][root][INFO] - Training Epoch: 1/2, step 5237/7134 completed (loss: 0.027140211313962936, acc: 0.9928315281867981)
[2024-12-17 02:10:19,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:19,867][root][INFO] - Training Epoch: 1/2, step 5238/7134 completed (loss: 0.03652843460440636, acc: 0.9894366264343262)
[2024-12-17 02:10:20,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:20,167][root][INFO] - Training Epoch: 1/2, step 5239/7134 completed (loss: 0.05917508155107498, acc: 0.9826254844665527)
[2024-12-17 02:10:20,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:20,501][root][INFO] - Training Epoch: 1/2, step 5240/7134 completed (loss: 0.04888428375124931, acc: 0.9847856163978577)
[2024-12-17 02:10:20,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:20,837][root][INFO] - Training Epoch: 1/2, step 5241/7134 completed (loss: 0.06977179646492004, acc: 0.9858934283256531)
[2024-12-17 02:10:20,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:21,200][root][INFO] - Training Epoch: 1/2, step 5242/7134 completed (loss: 0.03299672156572342, acc: 0.9900826215744019)
[2024-12-17 02:10:21,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:21,527][root][INFO] - Training Epoch: 1/2, step 5243/7134 completed (loss: 0.055439285933971405, acc: 0.9862068891525269)
[2024-12-17 02:10:21,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:21,852][root][INFO] - Training Epoch: 1/2, step 5244/7134 completed (loss: 0.07006023824214935, acc: 0.9889655113220215)
[2024-12-17 02:10:21,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:22,267][root][INFO] - Training Epoch: 1/2, step 5245/7134 completed (loss: 0.0596490278840065, acc: 0.9842932224273682)
[2024-12-17 02:10:22,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:22,589][root][INFO] - Training Epoch: 1/2, step 5246/7134 completed (loss: 0.08162114024162292, acc: 0.9800613522529602)
[2024-12-17 02:10:22,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:22,913][root][INFO] - Training Epoch: 1/2, step 5247/7134 completed (loss: 0.03904200345277786, acc: 0.9907407164573669)
[2024-12-17 02:10:23,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:23,239][root][INFO] - Training Epoch: 1/2, step 5248/7134 completed (loss: 0.10420116782188416, acc: 0.983146071434021)
[2024-12-17 02:10:23,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:23,567][root][INFO] - Training Epoch: 1/2, step 5249/7134 completed (loss: 0.02560841664671898, acc: 0.9889937043190002)
[2024-12-17 02:10:23,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:23,926][root][INFO] - Training Epoch: 1/2, step 5250/7134 completed (loss: 0.05445455014705658, acc: 0.9911727905273438)
[2024-12-17 02:10:24,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:24,276][root][INFO] - Training Epoch: 1/2, step 5251/7134 completed (loss: 0.05624547228217125, acc: 0.9830303192138672)
[2024-12-17 02:10:24,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:24,580][root][INFO] - Training Epoch: 1/2, step 5252/7134 completed (loss: 0.0775805413722992, acc: 0.9813084006309509)
[2024-12-17 02:10:24,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:24,920][root][INFO] - Training Epoch: 1/2, step 5253/7134 completed (loss: 0.054009176790714264, acc: 0.9852941036224365)
[2024-12-17 02:10:25,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:25,272][root][INFO] - Training Epoch: 1/2, step 5254/7134 completed (loss: 0.0721929594874382, acc: 0.9813242554664612)
[2024-12-17 02:10:25,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:25,620][root][INFO] - Training Epoch: 1/2, step 5255/7134 completed (loss: 0.07333514839410782, acc: 0.9876712560653687)
[2024-12-17 02:10:25,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:25,971][root][INFO] - Training Epoch: 1/2, step 5256/7134 completed (loss: 0.08816113322973251, acc: 0.984544038772583)
[2024-12-17 02:10:26,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:26,314][root][INFO] - Training Epoch: 1/2, step 5257/7134 completed (loss: 0.1267968863248825, acc: 0.9680365324020386)
[2024-12-17 02:10:26,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:26,665][root][INFO] - Training Epoch: 1/2, step 5258/7134 completed (loss: 0.09209156781435013, acc: 0.9795918464660645)
[2024-12-17 02:10:26,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:27,001][root][INFO] - Training Epoch: 1/2, step 5259/7134 completed (loss: 0.10769452899694443, acc: 0.9762658476829529)
[2024-12-17 02:10:27,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:27,351][root][INFO] - Training Epoch: 1/2, step 5260/7134 completed (loss: 0.06447003781795502, acc: 0.9804878234863281)
[2024-12-17 02:10:27,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:27,691][root][INFO] - Training Epoch: 1/2, step 5261/7134 completed (loss: 0.10545152425765991, acc: 0.9673076868057251)
[2024-12-17 02:10:27,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:28,056][root][INFO] - Training Epoch: 1/2, step 5262/7134 completed (loss: 0.04984235018491745, acc: 0.9848275780677795)
[2024-12-17 02:10:28,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:28,381][root][INFO] - Training Epoch: 1/2, step 5263/7134 completed (loss: 0.10041996836662292, acc: 0.9754385948181152)
[2024-12-17 02:10:28,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:28,746][root][INFO] - Training Epoch: 1/2, step 5264/7134 completed (loss: 0.06184147670865059, acc: 0.9854192137718201)
[2024-12-17 02:10:28,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:29,107][root][INFO] - Training Epoch: 1/2, step 5265/7134 completed (loss: 0.09576144814491272, acc: 0.9783989787101746)
[2024-12-17 02:10:29,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:29,437][root][INFO] - Training Epoch: 1/2, step 5266/7134 completed (loss: 0.05879748612642288, acc: 0.982191801071167)
[2024-12-17 02:10:29,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:29,764][root][INFO] - Training Epoch: 1/2, step 5267/7134 completed (loss: 0.12601502239704132, acc: 0.9673405885696411)
[2024-12-17 02:10:29,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:30,097][root][INFO] - Training Epoch: 1/2, step 5268/7134 completed (loss: 0.1345905065536499, acc: 0.9577735066413879)
[2024-12-17 02:10:30,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:30,431][root][INFO] - Training Epoch: 1/2, step 5269/7134 completed (loss: 0.14443674683570862, acc: 0.969588577747345)
[2024-12-17 02:10:30,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:30,796][root][INFO] - Training Epoch: 1/2, step 5270/7134 completed (loss: 0.06423287838697433, acc: 0.9839572310447693)
[2024-12-17 02:10:30,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:31,142][root][INFO] - Training Epoch: 1/2, step 5271/7134 completed (loss: 0.16061121225357056, acc: 0.9629629850387573)
[2024-12-17 02:10:31,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:31,472][root][INFO] - Training Epoch: 1/2, step 5272/7134 completed (loss: 0.0620286650955677, acc: 0.9838709831237793)
[2024-12-17 02:10:31,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:31,814][root][INFO] - Training Epoch: 1/2, step 5273/7134 completed (loss: 0.04083278402686119, acc: 0.9898132681846619)
[2024-12-17 02:10:31,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:32,153][root][INFO] - Training Epoch: 1/2, step 5274/7134 completed (loss: 0.12081995606422424, acc: 0.9641790986061096)
[2024-12-17 02:10:32,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:32,495][root][INFO] - Training Epoch: 1/2, step 5275/7134 completed (loss: 0.062480151653289795, acc: 0.9798902869224548)
[2024-12-17 02:10:32,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:32,815][root][INFO] - Training Epoch: 1/2, step 5276/7134 completed (loss: 0.06007668748497963, acc: 0.980567991733551)
[2024-12-17 02:10:32,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:33,135][root][INFO] - Training Epoch: 1/2, step 5277/7134 completed (loss: 0.06009073182940483, acc: 0.9827089309692383)
[2024-12-17 02:10:33,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:33,480][root][INFO] - Training Epoch: 1/2, step 5278/7134 completed (loss: 0.16599270701408386, acc: 0.961773693561554)
[2024-12-17 02:10:33,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:33,825][root][INFO] - Training Epoch: 1/2, step 5279/7134 completed (loss: 0.07019098848104477, acc: 0.9824903011322021)
[2024-12-17 02:10:33,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:34,155][root][INFO] - Training Epoch: 1/2, step 5280/7134 completed (loss: 0.08413664251565933, acc: 0.9850746393203735)
[2024-12-17 02:10:34,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:34,484][root][INFO] - Training Epoch: 1/2, step 5281/7134 completed (loss: 0.05488559603691101, acc: 0.9850249290466309)
[2024-12-17 02:10:34,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:34,804][root][INFO] - Training Epoch: 1/2, step 5282/7134 completed (loss: 0.06288532167673111, acc: 0.9828816056251526)
[2024-12-17 02:10:34,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:35,136][root][INFO] - Training Epoch: 1/2, step 5283/7134 completed (loss: 0.062017980962991714, acc: 0.9835841059684753)
[2024-12-17 02:10:35,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:35,472][root][INFO] - Training Epoch: 1/2, step 5284/7134 completed (loss: 0.06841906905174255, acc: 0.9834024906158447)
[2024-12-17 02:10:35,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:35,832][root][INFO] - Training Epoch: 1/2, step 5285/7134 completed (loss: 0.05742677301168442, acc: 0.9917159676551819)
[2024-12-17 02:10:35,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:36,188][root][INFO] - Training Epoch: 1/2, step 5286/7134 completed (loss: 0.07956074923276901, acc: 0.979411780834198)
[2024-12-17 02:10:36,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:36,543][root][INFO] - Training Epoch: 1/2, step 5287/7134 completed (loss: 0.10553023964166641, acc: 0.9701896905899048)
[2024-12-17 02:10:36,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:36,870][root][INFO] - Training Epoch: 1/2, step 5288/7134 completed (loss: 0.046975087374448776, acc: 0.9861963391304016)
[2024-12-17 02:10:36,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:37,223][root][INFO] - Training Epoch: 1/2, step 5289/7134 completed (loss: 0.08499409258365631, acc: 0.9716714024543762)
[2024-12-17 02:10:37,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:37,588][root][INFO] - Training Epoch: 1/2, step 5290/7134 completed (loss: 0.08636239171028137, acc: 0.9772151708602905)
[2024-12-17 02:10:37,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:37,953][root][INFO] - Training Epoch: 1/2, step 5291/7134 completed (loss: 0.05147663503885269, acc: 0.9842424392700195)
[2024-12-17 02:10:38,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:38,303][root][INFO] - Training Epoch: 1/2, step 5292/7134 completed (loss: 0.047883253544569016, acc: 0.9821882843971252)
[2024-12-17 02:10:38,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:38,653][root][INFO] - Training Epoch: 1/2, step 5293/7134 completed (loss: 0.08220206201076508, acc: 0.9824817776679993)
[2024-12-17 02:10:38,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:39,005][root][INFO] - Training Epoch: 1/2, step 5294/7134 completed (loss: 0.08053485304117203, acc: 0.9776847958564758)
[2024-12-17 02:10:39,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:39,320][root][INFO] - Training Epoch: 1/2, step 5295/7134 completed (loss: 0.06844596564769745, acc: 0.9797794222831726)
[2024-12-17 02:10:39,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:39,661][root][INFO] - Training Epoch: 1/2, step 5296/7134 completed (loss: 0.09417270123958588, acc: 0.9721835851669312)
[2024-12-17 02:10:39,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:39,988][root][INFO] - Training Epoch: 1/2, step 5297/7134 completed (loss: 0.07164271175861359, acc: 0.9755747318267822)
[2024-12-17 02:10:40,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:40,381][root][INFO] - Training Epoch: 1/2, step 5298/7134 completed (loss: 0.07774784415960312, acc: 0.976068377494812)
[2024-12-17 02:10:40,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:40,700][root][INFO] - Training Epoch: 1/2, step 5299/7134 completed (loss: 0.06241186335682869, acc: 0.9791332483291626)
[2024-12-17 02:10:40,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:41,038][root][INFO] - Training Epoch: 1/2, step 5300/7134 completed (loss: 0.08477386832237244, acc: 0.9720998406410217)
[2024-12-17 02:10:41,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:41,358][root][INFO] - Training Epoch: 1/2, step 5301/7134 completed (loss: 0.06822449713945389, acc: 0.9838472604751587)
[2024-12-17 02:10:41,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:41,693][root][INFO] - Training Epoch: 1/2, step 5302/7134 completed (loss: 0.1290564090013504, acc: 0.9726443886756897)
[2024-12-17 02:10:41,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:42,038][root][INFO] - Training Epoch: 1/2, step 5303/7134 completed (loss: 0.12060023099184036, acc: 0.9752212166786194)
[2024-12-17 02:10:42,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:42,369][root][INFO] - Training Epoch: 1/2, step 5304/7134 completed (loss: 0.12444635480642319, acc: 0.9717137813568115)
[2024-12-17 02:10:42,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:42,694][root][INFO] - Training Epoch: 1/2, step 5305/7134 completed (loss: 0.13146835565567017, acc: 0.9591240882873535)
[2024-12-17 02:10:42,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:43,024][root][INFO] - Training Epoch: 1/2, step 5306/7134 completed (loss: 0.07860308885574341, acc: 0.9777777791023254)
[2024-12-17 02:10:43,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:43,348][root][INFO] - Training Epoch: 1/2, step 5307/7134 completed (loss: 0.10136064141988754, acc: 0.9722222089767456)
[2024-12-17 02:10:43,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:43,666][root][INFO] - Training Epoch: 1/2, step 5308/7134 completed (loss: 0.11079798638820648, acc: 0.9728096723556519)
[2024-12-17 02:10:43,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:43,987][root][INFO] - Training Epoch: 1/2, step 5309/7134 completed (loss: 0.20072393119335175, acc: 0.9534883499145508)
[2024-12-17 02:10:44,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:44,329][root][INFO] - Training Epoch: 1/2, step 5310/7134 completed (loss: 0.12669698894023895, acc: 0.9762901067733765)
[2024-12-17 02:10:44,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:44,667][root][INFO] - Training Epoch: 1/2, step 5311/7134 completed (loss: 0.12514132261276245, acc: 0.9695023894309998)
[2024-12-17 02:10:44,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:44,974][root][INFO] - Training Epoch: 1/2, step 5312/7134 completed (loss: 0.0818227156996727, acc: 0.9793621301651001)
[2024-12-17 02:10:45,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:45,312][root][INFO] - Training Epoch: 1/2, step 5313/7134 completed (loss: 0.0766306221485138, acc: 0.9799635410308838)
[2024-12-17 02:10:45,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:45,631][root][INFO] - Training Epoch: 1/2, step 5314/7134 completed (loss: 0.06548089534044266, acc: 0.9843205809593201)
[2024-12-17 02:10:45,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:45,973][root][INFO] - Training Epoch: 1/2, step 5315/7134 completed (loss: 0.06714266538619995, acc: 0.9836333990097046)
[2024-12-17 02:10:46,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:46,299][root][INFO] - Training Epoch: 1/2, step 5316/7134 completed (loss: 0.07408358156681061, acc: 0.9831932783126831)
[2024-12-17 02:10:46,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:46,593][root][INFO] - Training Epoch: 1/2, step 5317/7134 completed (loss: 0.05253380909562111, acc: 0.9874551892280579)
[2024-12-17 02:10:46,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:46,923][root][INFO] - Training Epoch: 1/2, step 5318/7134 completed (loss: 0.05995229631662369, acc: 0.984455943107605)
[2024-12-17 02:10:47,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:47,261][root][INFO] - Training Epoch: 1/2, step 5319/7134 completed (loss: 0.07875287532806396, acc: 0.9817517995834351)
[2024-12-17 02:10:47,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:47,632][root][INFO] - Training Epoch: 1/2, step 5320/7134 completed (loss: 0.058767616748809814, acc: 0.9844720363616943)
[2024-12-17 02:10:47,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:47,971][root][INFO] - Training Epoch: 1/2, step 5321/7134 completed (loss: 0.050406500697135925, acc: 0.9860464930534363)
[2024-12-17 02:10:48,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:48,304][root][INFO] - Training Epoch: 1/2, step 5322/7134 completed (loss: 0.04791341349482536, acc: 0.9894419312477112)
[2024-12-17 02:10:48,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:48,641][root][INFO] - Training Epoch: 1/2, step 5323/7134 completed (loss: 0.06822164356708527, acc: 0.9818181991577148)
[2024-12-17 02:10:48,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:48,962][root][INFO] - Training Epoch: 1/2, step 5324/7134 completed (loss: 0.0779707282781601, acc: 0.9783616662025452)
[2024-12-17 02:10:49,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:49,293][root][INFO] - Training Epoch: 1/2, step 5325/7134 completed (loss: 0.05068465322256088, acc: 0.9846677780151367)
[2024-12-17 02:10:49,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:49,625][root][INFO] - Training Epoch: 1/2, step 5326/7134 completed (loss: 0.0757543221116066, acc: 0.9806451797485352)
[2024-12-17 02:10:49,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:49,950][root][INFO] - Training Epoch: 1/2, step 5327/7134 completed (loss: 0.056770212948322296, acc: 0.9825834631919861)
[2024-12-17 02:10:50,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:50,276][root][INFO] - Training Epoch: 1/2, step 5328/7134 completed (loss: 0.053874023258686066, acc: 0.9816513657569885)
[2024-12-17 02:10:50,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:50,606][root][INFO] - Training Epoch: 1/2, step 5329/7134 completed (loss: 0.09460155665874481, acc: 0.9740680456161499)
[2024-12-17 02:10:50,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:50,941][root][INFO] - Training Epoch: 1/2, step 5330/7134 completed (loss: 0.06846970319747925, acc: 0.979687511920929)
[2024-12-17 02:10:51,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:51,267][root][INFO] - Training Epoch: 1/2, step 5331/7134 completed (loss: 0.07661739736795425, acc: 0.9842382073402405)
[2024-12-17 02:10:51,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:51,611][root][INFO] - Training Epoch: 1/2, step 5332/7134 completed (loss: 0.053294867277145386, acc: 0.9869918823242188)
[2024-12-17 02:10:51,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:51,955][root][INFO] - Training Epoch: 1/2, step 5333/7134 completed (loss: 0.0323592871427536, acc: 0.9906542301177979)
[2024-12-17 02:10:52,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:52,281][root][INFO] - Training Epoch: 1/2, step 5334/7134 completed (loss: 0.10781020671129227, acc: 0.9800918698310852)
[2024-12-17 02:10:52,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:52,599][root][INFO] - Training Epoch: 1/2, step 5335/7134 completed (loss: 0.07078399509191513, acc: 0.9872204661369324)
[2024-12-17 02:10:52,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:52,942][root][INFO] - Training Epoch: 1/2, step 5336/7134 completed (loss: 0.06275884807109833, acc: 0.979687511920929)
[2024-12-17 02:10:53,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:53,299][root][INFO] - Training Epoch: 1/2, step 5337/7134 completed (loss: 0.06342410296201706, acc: 0.9832962155342102)
[2024-12-17 02:10:53,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:53,689][root][INFO] - Training Epoch: 1/2, step 5338/7134 completed (loss: 0.04670017585158348, acc: 0.9863013625144958)
[2024-12-17 02:10:53,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:54,009][root][INFO] - Training Epoch: 1/2, step 5339/7134 completed (loss: 0.10818982124328613, acc: 0.9689119458198547)
[2024-12-17 02:10:54,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:54,357][root][INFO] - Training Epoch: 1/2, step 5340/7134 completed (loss: 0.12556754052639008, acc: 0.9670710563659668)
[2024-12-17 02:10:54,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:54,698][root][INFO] - Training Epoch: 1/2, step 5341/7134 completed (loss: 0.05846522003412247, acc: 0.9807909727096558)
[2024-12-17 02:10:54,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:55,060][root][INFO] - Training Epoch: 1/2, step 5342/7134 completed (loss: 0.16412900388240814, acc: 0.9627164006233215)
[2024-12-17 02:10:55,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:55,411][root][INFO] - Training Epoch: 1/2, step 5343/7134 completed (loss: 0.1289268583059311, acc: 0.9722955226898193)
[2024-12-17 02:10:55,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:55,769][root][INFO] - Training Epoch: 1/2, step 5344/7134 completed (loss: 0.08939304202795029, acc: 0.9768421053886414)
[2024-12-17 02:10:55,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:56,118][root][INFO] - Training Epoch: 1/2, step 5345/7134 completed (loss: 0.09309584647417068, acc: 0.9793103337287903)
[2024-12-17 02:10:56,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:56,464][root][INFO] - Training Epoch: 1/2, step 5346/7134 completed (loss: 0.10550364851951599, acc: 0.9790136218070984)
[2024-12-17 02:10:56,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:56,822][root][INFO] - Training Epoch: 1/2, step 5347/7134 completed (loss: 0.0764031633734703, acc: 0.9748010635375977)
[2024-12-17 02:10:56,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:57,192][root][INFO] - Training Epoch: 1/2, step 5348/7134 completed (loss: 0.08313503116369247, acc: 0.9833794832229614)
[2024-12-17 02:10:57,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:58,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:58,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:58,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:58,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:59,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:59,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:59,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:00,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:00,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:00,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:00,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:01,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:01,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:01,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:01,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:02,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:02,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:02,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:03,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:03,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:03,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:03,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:04,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:04,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:04,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:04,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:05,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:05,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:05,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:06,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:06,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:06,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:06,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:07,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:07,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:07,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:08,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:08,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:08,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:08,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:09,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:09,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:09,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:09,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:10,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:10,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:10,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:11,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:11,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:11,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:11,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:12,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:12,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:12,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:12,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:13,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:13,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:13,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:13,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:14,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:14,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:14,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:15,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:15,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:15,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:15,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:16,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:16,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:16,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:16,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:17,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:17,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:17,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:17,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:18,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:18,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:18,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:18,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:19,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:19,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:19,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:20,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:20,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:20,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:20,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:21,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:21,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:21,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:22,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:22,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:22,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:22,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:23,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:23,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:23,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:23,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:24,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:24,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:24,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:24,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:25,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:25,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:25,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:25,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:26,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:26,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:26,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:26,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:27,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:27,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:27,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:27,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:28,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:28,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:28,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:28,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:29,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:29,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:29,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:29,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:30,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:30,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:30,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:30,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:31,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:31,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:31,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:32,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:32,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:32,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:32,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:33,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:33,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:33,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:34,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:34,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:34,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:34,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:35,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:35,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:35,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:36,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:36,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:36,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:36,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:37,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:37,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:37,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:37,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:38,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:38,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:38,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:39,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:39,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:39,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:39,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:40,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:40,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:40,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:40,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:41,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:41,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:41,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:42,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:42,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:42,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:43,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:43,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:43,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:43,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:44,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:44,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:44,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:45,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:45,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:45,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:45,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:46,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:46,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:46,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:46,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:47,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:47,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:47,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:48,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:48,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:48,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:48,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:49,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:49,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:49,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:50,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:50,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:50,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:50,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:50,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:51,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:51,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:51,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:52,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:52,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:52,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:52,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:53,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:53,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:53,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:53,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:54,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:54,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:54,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:55,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:55,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:55,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:55,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:56,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:56,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:56,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:56,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:57,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:57,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:57,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:57,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:58,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:58,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:58,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:58,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:59,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:59,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:59,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:59,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:00,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:00,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:00,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:00,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:01,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:01,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:01,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:02,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:02,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:02,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:02,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:03,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:03,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:03,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:04,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:04,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:04,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:05,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:05,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:05,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:06,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:06,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:06,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:06,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:07,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:07,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:07,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:08,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:08,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:08,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:09,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:09,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:09,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:09,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:10,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:10,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:10,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:10,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:11,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:11,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:11,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:12,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:12,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:12,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:13,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:13,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:13,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:14,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:14,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:14,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:15,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:15,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:15,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:16,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:16,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:16,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:17,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:17,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:17,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:17,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:18,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:18,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:18,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:19,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:19,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:19,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:20,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:20,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:20,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:20,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:21,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:21,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:21,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:21,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:22,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:22,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:22,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:22,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:23,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:23,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:23,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:23,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:24,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:24,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:24,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:24,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:25,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:25,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:25,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:26,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:26,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:26,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:27,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:27,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:27,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:28,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:28,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:28,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:29,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:29,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:29,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:29,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:30,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:30,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:30,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:31,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:31,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:31,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:32,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:32,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:32,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:33,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:33,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:33,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:33,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:34,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:34,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:34,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:35,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:35,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:35,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:36,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:36,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:36,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:36,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:37,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:37,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:37,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:38,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:38,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:39,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:39,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:40,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:40,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:40,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:41,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:41,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:41,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:42,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:42,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:42,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:42,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:43,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:43,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:43,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:43,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:44,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:44,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:44,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:44,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:45,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:45,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:45,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:46,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:46,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:46,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:46,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:47,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:47,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:47,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:47,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:48,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:48,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:48,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:48,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:49,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:49,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:49,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:50,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:50,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:50,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:50,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:51,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:51,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:51,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:51,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:52,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:52,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:52,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:53,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:53,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:53,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:53,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:54,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:54,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:54,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:55,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:55,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:55,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:55,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:56,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:56,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:56,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:56,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:57,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:57,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:57,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:58,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:58,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:58,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:58,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:59,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:59,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:59,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:59,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:00,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:00,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:00,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:00,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:01,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:01,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:01,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:02,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:02,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:02,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:02,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:03,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:03,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:03,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:03,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:04,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:04,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:04,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:04,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:05,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:05,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:05,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:06,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:06,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:06,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:07,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:07,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:07,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:07,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:07,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:08,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:08,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:08,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:08,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:09,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:09,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:09,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:10,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:10,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:10,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:10,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:10,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:11,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:11,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:11,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:12,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:12,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:12,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:12,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:13,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:13,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:13,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:13,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:14,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:14,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:14,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:15,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:15,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:15,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:15,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:16,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:16,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:16,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:17,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:17,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:17,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:18,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:18,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:18,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:19,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:19,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:19,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:20,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:20,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:20,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:20,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:21,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:21,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:21,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:21,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:22,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:22,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:22,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:22,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:23,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:23,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:23,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:24,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:24,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:24,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:24,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:25,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:25,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:25,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:25,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:26,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:26,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:26,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:27,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:27,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:27,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:28,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:28,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:28,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:28,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:29,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:29,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:29,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:29,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:30,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:30,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:30,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:31,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:31,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:31,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:31,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:32,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:32,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:32,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:32,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:33,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:33,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:33,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:34,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:34,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:34,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:35,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:35,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:35,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:35,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:36,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:36,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:36,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:36,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:37,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:37,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:37,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:38,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:38,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:38,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:39,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:39,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:39,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:40,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:40,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:40,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:41,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:41,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:41,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:42,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:42,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:42,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:42,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:43,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:43,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:43,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:43,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:44,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:44,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:44,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:44,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:45,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:45,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:45,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:45,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:46,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:46,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:46,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:46,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:47,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:47,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:47,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:48,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:48,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:48,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:49,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:49,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:49,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:49,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:50,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:50,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:50,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:51,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:51,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:51,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:52,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:52,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:52,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:52,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:53,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:53,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:54,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:54,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:55,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:55,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:55,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:56,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:56,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:57,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:57,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:57,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:58,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:58,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:58,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:58,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:59,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:59,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:59,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:00,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:00,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:00,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:00,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:01,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:01,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:01,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:02,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:02,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:02,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:02,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:03,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:03,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:03,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:04,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:04,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:04,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:04,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:05,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:05,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:05,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:05,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:06,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:06,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:06,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:07,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:07,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:07,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:08,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:08,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:08,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:09,277][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.0918, device='cuda:0') eval_epoch_loss=tensor(0.0879, device='cuda:0') eval_epoch_acc=tensor(0.9778, device='cuda:0')
[2024-12-17 02:14:09,279][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-12-17 02:14:09,279][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 02:14:09,492][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_1_step_5349_loss_0.08785554766654968/model.pt
[2024-12-17 02:14:09,496][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 0.08785554766654968
[2024-12-17 02:14:09,496][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.9778141975402832
[2024-12-17 02:14:09,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:09,881][root][INFO] - Training Epoch: 1/2, step 5349/7134 completed (loss: 0.1131722703576088, acc: 0.9638242721557617)
[2024-12-17 02:14:10,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:10,228][root][INFO] - Training Epoch: 1/2, step 5350/7134 completed (loss: 0.07349234819412231, acc: 0.9801849126815796)
[2024-12-17 02:14:10,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:10,561][root][INFO] - Training Epoch: 1/2, step 5351/7134 completed (loss: 0.0719451829791069, acc: 0.9838709831237793)
[2024-12-17 02:14:10,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:10,887][root][INFO] - Training Epoch: 1/2, step 5352/7134 completed (loss: 0.057072896510362625, acc: 0.9870634078979492)
[2024-12-17 02:14:11,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:11,249][root][INFO] - Training Epoch: 1/2, step 5353/7134 completed (loss: 0.03475034981966019, acc: 0.9932356476783752)
[2024-12-17 02:14:11,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:11,610][root][INFO] - Training Epoch: 1/2, step 5354/7134 completed (loss: 0.0894649550318718, acc: 0.9768722653388977)
[2024-12-17 02:14:11,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:11,958][root][INFO] - Training Epoch: 1/2, step 5355/7134 completed (loss: 0.12342526763677597, acc: 0.9716312289237976)
[2024-12-17 02:14:12,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:12,312][root][INFO] - Training Epoch: 1/2, step 5356/7134 completed (loss: 0.10704251378774643, acc: 0.9713574051856995)
[2024-12-17 02:14:12,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:12,640][root][INFO] - Training Epoch: 1/2, step 5357/7134 completed (loss: 0.09188280999660492, acc: 0.9773519039154053)
[2024-12-17 02:14:12,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:12,993][root][INFO] - Training Epoch: 1/2, step 5358/7134 completed (loss: 0.09427228569984436, acc: 0.9834482669830322)
[2024-12-17 02:14:13,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:13,334][root][INFO] - Training Epoch: 1/2, step 5359/7134 completed (loss: 0.04524359107017517, acc: 0.9895104765892029)
[2024-12-17 02:14:13,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:13,679][root][INFO] - Training Epoch: 1/2, step 5360/7134 completed (loss: 0.03479617089033127, acc: 0.9876373410224915)
[2024-12-17 02:14:13,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:14,038][root][INFO] - Training Epoch: 1/2, step 5361/7134 completed (loss: 0.07367263734340668, acc: 0.9808382987976074)
[2024-12-17 02:14:14,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:14,397][root][INFO] - Training Epoch: 1/2, step 5362/7134 completed (loss: 0.08695775270462036, acc: 0.9805970191955566)
[2024-12-17 02:14:14,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:14,730][root][INFO] - Training Epoch: 1/2, step 5363/7134 completed (loss: 0.09733284264802933, acc: 0.9723837375640869)
[2024-12-17 02:14:14,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:15,073][root][INFO] - Training Epoch: 1/2, step 5364/7134 completed (loss: 0.05816837027668953, acc: 0.984415590763092)
[2024-12-17 02:14:15,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:15,426][root][INFO] - Training Epoch: 1/2, step 5365/7134 completed (loss: 0.040570806711912155, acc: 0.9876543283462524)
[2024-12-17 02:14:15,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:15,734][root][INFO] - Training Epoch: 1/2, step 5366/7134 completed (loss: 0.08888913691043854, acc: 0.9722222089767456)
[2024-12-17 02:14:15,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:16,089][root][INFO] - Training Epoch: 1/2, step 5367/7134 completed (loss: 0.07301995903253555, acc: 0.983668327331543)
[2024-12-17 02:14:16,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:16,439][root][INFO] - Training Epoch: 1/2, step 5368/7134 completed (loss: 0.04832543805241585, acc: 0.9849498271942139)
[2024-12-17 02:14:16,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:16,746][root][INFO] - Training Epoch: 1/2, step 5369/7134 completed (loss: 0.06226020306348801, acc: 0.9830148816108704)
[2024-12-17 02:14:16,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:17,091][root][INFO] - Training Epoch: 1/2, step 5370/7134 completed (loss: 0.09780168533325195, acc: 0.9811617136001587)
[2024-12-17 02:14:17,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:17,439][root][INFO] - Training Epoch: 1/2, step 5371/7134 completed (loss: 0.13429413735866547, acc: 0.9651162624359131)
[2024-12-17 02:14:17,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:17,791][root][INFO] - Training Epoch: 1/2, step 5372/7134 completed (loss: 0.024165688082575798, acc: 0.9943898916244507)
[2024-12-17 02:14:17,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:18,115][root][INFO] - Training Epoch: 1/2, step 5373/7134 completed (loss: 0.1393248736858368, acc: 0.9644351601600647)
[2024-12-17 02:14:18,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:18,390][root][INFO] - Training Epoch: 1/2, step 5374/7134 completed (loss: 0.1347787231206894, acc: 0.971061110496521)
[2024-12-17 02:14:18,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:18,717][root][INFO] - Training Epoch: 1/2, step 5375/7134 completed (loss: 0.08784529566764832, acc: 0.977011501789093)
[2024-12-17 02:14:18,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:19,040][root][INFO] - Training Epoch: 1/2, step 5376/7134 completed (loss: 0.048887502402067184, acc: 0.9878048896789551)
[2024-12-17 02:14:19,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:19,389][root][INFO] - Training Epoch: 1/2, step 5377/7134 completed (loss: 0.08324719220399857, acc: 0.987860381603241)
[2024-12-17 02:14:19,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:19,738][root][INFO] - Training Epoch: 1/2, step 5378/7134 completed (loss: 0.04687343165278435, acc: 0.9854369163513184)
[2024-12-17 02:14:19,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:20,086][root][INFO] - Training Epoch: 1/2, step 5379/7134 completed (loss: 0.07686399668455124, acc: 0.9805447459220886)
[2024-12-17 02:14:20,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:20,423][root][INFO] - Training Epoch: 1/2, step 5380/7134 completed (loss: 0.07653838396072388, acc: 0.9735449552536011)
[2024-12-17 02:14:20,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:20,745][root][INFO] - Training Epoch: 1/2, step 5381/7134 completed (loss: 0.077740877866745, acc: 0.9790794849395752)
[2024-12-17 02:14:20,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:21,063][root][INFO] - Training Epoch: 1/2, step 5382/7134 completed (loss: 0.04954475164413452, acc: 0.9914675951004028)
[2024-12-17 02:14:21,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:21,407][root][INFO] - Training Epoch: 1/2, step 5383/7134 completed (loss: 0.04626670107245445, acc: 0.9791666865348816)
[2024-12-17 02:14:21,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:21,769][root][INFO] - Training Epoch: 1/2, step 5384/7134 completed (loss: 0.04367252066731453, acc: 0.9845971465110779)
[2024-12-17 02:14:21,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:22,107][root][INFO] - Training Epoch: 1/2, step 5385/7134 completed (loss: 0.06861705332994461, acc: 0.9775429368019104)
[2024-12-17 02:14:22,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:22,449][root][INFO] - Training Epoch: 1/2, step 5386/7134 completed (loss: 0.06333766132593155, acc: 0.9747191071510315)
[2024-12-17 02:14:22,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:22,804][root][INFO] - Training Epoch: 1/2, step 5387/7134 completed (loss: 0.04020624980330467, acc: 0.9885714054107666)
[2024-12-17 02:14:22,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:23,155][root][INFO] - Training Epoch: 1/2, step 5388/7134 completed (loss: 0.047741763293743134, acc: 0.9835858345031738)
[2024-12-17 02:14:23,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:23,480][root][INFO] - Training Epoch: 1/2, step 5389/7134 completed (loss: 0.054243262857198715, acc: 0.9824281334877014)
[2024-12-17 02:14:23,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:23,818][root][INFO] - Training Epoch: 1/2, step 5390/7134 completed (loss: 0.08045952022075653, acc: 0.9793977737426758)
[2024-12-17 02:14:23,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:24,111][root][INFO] - Training Epoch: 1/2, step 5391/7134 completed (loss: 0.11732593178749084, acc: 0.9828473329544067)
[2024-12-17 02:14:24,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:24,437][root][INFO] - Training Epoch: 1/2, step 5392/7134 completed (loss: 0.08105796575546265, acc: 0.9710366129875183)
[2024-12-17 02:14:24,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:24,758][root][INFO] - Training Epoch: 1/2, step 5393/7134 completed (loss: 0.09309300780296326, acc: 0.97265625)
[2024-12-17 02:14:24,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:25,053][root][INFO] - Training Epoch: 1/2, step 5394/7134 completed (loss: 0.11197023838758469, acc: 0.9702380895614624)
[2024-12-17 02:14:25,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:25,399][root][INFO] - Training Epoch: 1/2, step 5395/7134 completed (loss: 0.05227215960621834, acc: 0.9879336357116699)
[2024-12-17 02:14:25,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:25,739][root][INFO] - Training Epoch: 1/2, step 5396/7134 completed (loss: 0.09318507462739944, acc: 0.9759398698806763)
[2024-12-17 02:14:25,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:26,067][root][INFO] - Training Epoch: 1/2, step 5397/7134 completed (loss: 0.07475097477436066, acc: 0.9830795526504517)
[2024-12-17 02:14:26,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:26,397][root][INFO] - Training Epoch: 1/2, step 5398/7134 completed (loss: 0.07353954762220383, acc: 0.9867256879806519)
[2024-12-17 02:14:26,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:26,729][root][INFO] - Training Epoch: 1/2, step 5399/7134 completed (loss: 0.03841117396950722, acc: 0.9890561103820801)
[2024-12-17 02:14:26,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:27,070][root][INFO] - Training Epoch: 1/2, step 5400/7134 completed (loss: 0.17309419810771942, acc: 0.9592476487159729)
[2024-12-17 02:14:27,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:27,411][root][INFO] - Training Epoch: 1/2, step 5401/7134 completed (loss: 0.04819449409842491, acc: 0.9887640476226807)
[2024-12-17 02:14:27,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:27,750][root][INFO] - Training Epoch: 1/2, step 5402/7134 completed (loss: 0.08226735144853592, acc: 0.9794420003890991)
[2024-12-17 02:14:27,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:28,048][root][INFO] - Training Epoch: 1/2, step 5403/7134 completed (loss: 0.09556235373020172, acc: 0.9771615266799927)
[2024-12-17 02:14:28,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:28,394][root][INFO] - Training Epoch: 1/2, step 5404/7134 completed (loss: 0.21073001623153687, acc: 0.9516778588294983)
[2024-12-17 02:14:28,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:28,751][root][INFO] - Training Epoch: 1/2, step 5405/7134 completed (loss: 0.1031978651881218, acc: 0.9616056084632874)
[2024-12-17 02:14:28,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:29,097][root][INFO] - Training Epoch: 1/2, step 5406/7134 completed (loss: 0.06634454429149628, acc: 0.9805068373680115)
[2024-12-17 02:14:29,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:29,414][root][INFO] - Training Epoch: 1/2, step 5407/7134 completed (loss: 0.07789748162031174, acc: 0.97826087474823)
[2024-12-17 02:14:29,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:29,742][root][INFO] - Training Epoch: 1/2, step 5408/7134 completed (loss: 0.1392015814781189, acc: 0.9703587889671326)
[2024-12-17 02:14:29,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:30,076][root][INFO] - Training Epoch: 1/2, step 5409/7134 completed (loss: 0.16909591853618622, acc: 0.9682299494743347)
[2024-12-17 02:14:30,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:30,410][root][INFO] - Training Epoch: 1/2, step 5410/7134 completed (loss: 0.09759911149740219, acc: 0.9763779640197754)
[2024-12-17 02:14:30,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:30,744][root][INFO] - Training Epoch: 1/2, step 5411/7134 completed (loss: 0.13156452775001526, acc: 0.9651669263839722)
[2024-12-17 02:14:30,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:31,096][root][INFO] - Training Epoch: 1/2, step 5412/7134 completed (loss: 0.15714289247989655, acc: 0.9519230723381042)
[2024-12-17 02:14:31,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:31,466][root][INFO] - Training Epoch: 1/2, step 5413/7134 completed (loss: 0.19121725857257843, acc: 0.9585714340209961)
[2024-12-17 02:14:31,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:31,830][root][INFO] - Training Epoch: 1/2, step 5414/7134 completed (loss: 0.2111569046974182, acc: 0.9498714804649353)
[2024-12-17 02:14:31,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:32,165][root][INFO] - Training Epoch: 1/2, step 5415/7134 completed (loss: 0.13369610905647278, acc: 0.9684813618659973)
[2024-12-17 02:14:32,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:32,538][root][INFO] - Training Epoch: 1/2, step 5416/7134 completed (loss: 0.1360306739807129, acc: 0.9628339409828186)
[2024-12-17 02:14:32,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:32,904][root][INFO] - Training Epoch: 1/2, step 5417/7134 completed (loss: 0.09580995887517929, acc: 0.9762796759605408)
[2024-12-17 02:14:33,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:33,233][root][INFO] - Training Epoch: 1/2, step 5418/7134 completed (loss: 0.11248801648616791, acc: 0.9675036668777466)
[2024-12-17 02:14:33,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:33,563][root][INFO] - Training Epoch: 1/2, step 5419/7134 completed (loss: 0.19519689679145813, acc: 0.9491525292396545)
[2024-12-17 02:14:33,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:33,898][root][INFO] - Training Epoch: 1/2, step 5420/7134 completed (loss: 0.17284956574440002, acc: 0.9615384340286255)
[2024-12-17 02:14:34,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:34,251][root][INFO] - Training Epoch: 1/2, step 5421/7134 completed (loss: 0.18002116680145264, acc: 0.9547581672668457)
[2024-12-17 02:14:34,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:34,598][root][INFO] - Training Epoch: 1/2, step 5422/7134 completed (loss: 0.11211491376161575, acc: 0.9674556255340576)
[2024-12-17 02:14:34,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:34,854][root][INFO] - Training Epoch: 1/2, step 5423/7134 completed (loss: 0.12137043476104736, acc: 0.9648093581199646)
[2024-12-17 02:14:34,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:35,178][root][INFO] - Training Epoch: 1/2, step 5424/7134 completed (loss: 0.04968661814928055, acc: 0.9876760840415955)
[2024-12-17 02:14:35,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:35,470][root][INFO] - Training Epoch: 1/2, step 5425/7134 completed (loss: 0.06293884664773941, acc: 0.9825242757797241)
[2024-12-17 02:14:35,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:35,770][root][INFO] - Training Epoch: 1/2, step 5426/7134 completed (loss: 0.10626790672540665, acc: 0.9819276928901672)
[2024-12-17 02:14:35,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:36,096][root][INFO] - Training Epoch: 1/2, step 5427/7134 completed (loss: 0.0541643388569355, acc: 0.9889415502548218)
[2024-12-17 02:14:36,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:36,419][root][INFO] - Training Epoch: 1/2, step 5428/7134 completed (loss: 0.07597919553518295, acc: 0.9812606573104858)
[2024-12-17 02:14:36,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:36,727][root][INFO] - Training Epoch: 1/2, step 5429/7134 completed (loss: 0.11393395066261292, acc: 0.9765343070030212)
[2024-12-17 02:14:36,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:37,061][root][INFO] - Training Epoch: 1/2, step 5430/7134 completed (loss: 0.05958329886198044, acc: 0.982758641242981)
[2024-12-17 02:14:37,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:37,353][root][INFO] - Training Epoch: 1/2, step 5431/7134 completed (loss: 0.05524805188179016, acc: 0.9848771095275879)
[2024-12-17 02:14:37,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:37,672][root][INFO] - Training Epoch: 1/2, step 5432/7134 completed (loss: 0.04015714302659035, acc: 0.9905837774276733)
[2024-12-17 02:14:37,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:37,958][root][INFO] - Training Epoch: 1/2, step 5433/7134 completed (loss: 0.050683166831731796, acc: 0.9878787994384766)
[2024-12-17 02:14:38,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:38,273][root][INFO] - Training Epoch: 1/2, step 5434/7134 completed (loss: 0.053766585886478424, acc: 0.9839034080505371)
[2024-12-17 02:14:38,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:38,564][root][INFO] - Training Epoch: 1/2, step 5435/7134 completed (loss: 0.04293142631649971, acc: 0.9895397424697876)
[2024-12-17 02:14:38,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:38,886][root][INFO] - Training Epoch: 1/2, step 5436/7134 completed (loss: 0.049230944365262985, acc: 0.9866468906402588)
[2024-12-17 02:14:38,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:39,206][root][INFO] - Training Epoch: 1/2, step 5437/7134 completed (loss: 0.030556799843907356, acc: 0.9930192232131958)
[2024-12-17 02:14:39,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:39,561][root][INFO] - Training Epoch: 1/2, step 5438/7134 completed (loss: 0.0484154038131237, acc: 0.9844961166381836)
[2024-12-17 02:14:39,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:39,897][root][INFO] - Training Epoch: 1/2, step 5439/7134 completed (loss: 0.06360121071338654, acc: 0.9825581312179565)
[2024-12-17 02:14:40,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:40,246][root][INFO] - Training Epoch: 1/2, step 5440/7134 completed (loss: 0.08965503424406052, acc: 0.9795657992362976)
[2024-12-17 02:14:40,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:40,591][root][INFO] - Training Epoch: 1/2, step 5441/7134 completed (loss: 0.039109326899051666, acc: 0.9914320707321167)
[2024-12-17 02:14:40,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:40,928][root][INFO] - Training Epoch: 1/2, step 5442/7134 completed (loss: 0.04530031979084015, acc: 0.9878214001655579)
[2024-12-17 02:14:41,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:41,244][root][INFO] - Training Epoch: 1/2, step 5443/7134 completed (loss: 0.06115344539284706, acc: 0.9829545617103577)
[2024-12-17 02:14:41,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:41,581][root][INFO] - Training Epoch: 1/2, step 5444/7134 completed (loss: 0.054185833781957626, acc: 0.985401451587677)
[2024-12-17 02:14:41,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:41,916][root][INFO] - Training Epoch: 1/2, step 5445/7134 completed (loss: 0.09415426105260849, acc: 0.974405825138092)
[2024-12-17 02:14:42,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:42,254][root][INFO] - Training Epoch: 1/2, step 5446/7134 completed (loss: 0.030810195952653885, acc: 0.9957982897758484)
[2024-12-17 02:14:42,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:42,567][root][INFO] - Training Epoch: 1/2, step 5447/7134 completed (loss: 0.05577715113759041, acc: 0.9838969111442566)
[2024-12-17 02:14:42,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:42,935][root][INFO] - Training Epoch: 1/2, step 5448/7134 completed (loss: 0.06321704387664795, acc: 0.9860334992408752)
[2024-12-17 02:14:43,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:43,261][root][INFO] - Training Epoch: 1/2, step 5449/7134 completed (loss: 0.0331282764673233, acc: 0.9894737005233765)
[2024-12-17 02:14:43,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:43,599][root][INFO] - Training Epoch: 1/2, step 5450/7134 completed (loss: 0.03570787236094475, acc: 0.9909909963607788)
[2024-12-17 02:14:43,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:43,926][root][INFO] - Training Epoch: 1/2, step 5451/7134 completed (loss: 0.05639880895614624, acc: 0.9855832457542419)
[2024-12-17 02:14:44,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:44,260][root][INFO] - Training Epoch: 1/2, step 5452/7134 completed (loss: 0.09110864251852036, acc: 0.9806201457977295)
[2024-12-17 02:14:44,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:44,612][root][INFO] - Training Epoch: 1/2, step 5453/7134 completed (loss: 0.06947312504053116, acc: 0.9852761030197144)
[2024-12-17 02:14:44,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:44,971][root][INFO] - Training Epoch: 1/2, step 5454/7134 completed (loss: 0.0714823305606842, acc: 0.9843546152114868)
[2024-12-17 02:14:45,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:45,322][root][INFO] - Training Epoch: 1/2, step 5455/7134 completed (loss: 0.144454225897789, acc: 0.9646464586257935)
[2024-12-17 02:14:45,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:45,674][root][INFO] - Training Epoch: 1/2, step 5456/7134 completed (loss: 0.059725306928157806, acc: 0.986146092414856)
[2024-12-17 02:14:45,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:46,046][root][INFO] - Training Epoch: 1/2, step 5457/7134 completed (loss: 0.08453849703073502, acc: 0.9771811962127686)
[2024-12-17 02:14:46,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:46,398][root][INFO] - Training Epoch: 1/2, step 5458/7134 completed (loss: 0.07454413920640945, acc: 0.9821656346321106)
[2024-12-17 02:14:46,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:46,736][root][INFO] - Training Epoch: 1/2, step 5459/7134 completed (loss: 0.040542349219322205, acc: 0.9895678162574768)
[2024-12-17 02:14:46,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:47,066][root][INFO] - Training Epoch: 1/2, step 5460/7134 completed (loss: 0.059153225272893906, acc: 0.9847009778022766)
[2024-12-17 02:14:47,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:47,392][root][INFO] - Training Epoch: 1/2, step 5461/7134 completed (loss: 0.08539635688066483, acc: 0.9779249429702759)
[2024-12-17 02:14:47,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:47,742][root][INFO] - Training Epoch: 1/2, step 5462/7134 completed (loss: 0.05212301015853882, acc: 0.9856938719749451)
[2024-12-17 02:14:47,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:48,075][root][INFO] - Training Epoch: 1/2, step 5463/7134 completed (loss: 0.04804302379488945, acc: 0.9877862334251404)
[2024-12-17 02:14:48,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:48,419][root][INFO] - Training Epoch: 1/2, step 5464/7134 completed (loss: 0.06442680209875107, acc: 0.9828269481658936)
[2024-12-17 02:14:48,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:48,778][root][INFO] - Training Epoch: 1/2, step 5465/7134 completed (loss: 0.05432117357850075, acc: 0.9910314083099365)
[2024-12-17 02:14:48,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:49,134][root][INFO] - Training Epoch: 1/2, step 5466/7134 completed (loss: 0.0464162603020668, acc: 0.9896432757377625)
[2024-12-17 02:14:49,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:49,505][root][INFO] - Training Epoch: 1/2, step 5467/7134 completed (loss: 0.067082479596138, acc: 0.9835680723190308)
[2024-12-17 02:14:49,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:49,857][root][INFO] - Training Epoch: 1/2, step 5468/7134 completed (loss: 0.05853474140167236, acc: 0.9860788583755493)
[2024-12-17 02:14:49,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:50,206][root][INFO] - Training Epoch: 1/2, step 5469/7134 completed (loss: 0.048335712403059006, acc: 0.9926380515098572)
[2024-12-17 02:14:50,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:50,561][root][INFO] - Training Epoch: 1/2, step 5470/7134 completed (loss: 0.042276374995708466, acc: 0.9891566038131714)
[2024-12-17 02:14:50,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:50,904][root][INFO] - Training Epoch: 1/2, step 5471/7134 completed (loss: 0.03916816785931587, acc: 0.9878378510475159)
[2024-12-17 02:14:50,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:51,251][root][INFO] - Training Epoch: 1/2, step 5472/7134 completed (loss: 0.0560603067278862, acc: 0.9862843155860901)
[2024-12-17 02:14:51,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:51,610][root][INFO] - Training Epoch: 1/2, step 5473/7134 completed (loss: 0.03737136349081993, acc: 0.987730085849762)
[2024-12-17 02:14:51,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:51,943][root][INFO] - Training Epoch: 1/2, step 5474/7134 completed (loss: 0.05761789157986641, acc: 0.9828571677207947)
[2024-12-17 02:14:52,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:52,291][root][INFO] - Training Epoch: 1/2, step 5475/7134 completed (loss: 0.05300083011388779, acc: 0.9886202216148376)
[2024-12-17 02:14:52,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:52,614][root][INFO] - Training Epoch: 1/2, step 5476/7134 completed (loss: 0.03426137566566467, acc: 0.9913169145584106)
[2024-12-17 02:14:52,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:52,967][root][INFO] - Training Epoch: 1/2, step 5477/7134 completed (loss: 0.026214169338345528, acc: 0.993842363357544)
[2024-12-17 02:14:53,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:53,342][root][INFO] - Training Epoch: 1/2, step 5478/7134 completed (loss: 0.09116065502166748, acc: 0.9794167876243591)
[2024-12-17 02:14:53,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:53,703][root][INFO] - Training Epoch: 1/2, step 5479/7134 completed (loss: 0.06019600108265877, acc: 0.9823369383811951)
[2024-12-17 02:14:53,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:54,054][root][INFO] - Training Epoch: 1/2, step 5480/7134 completed (loss: 0.06565462052822113, acc: 0.9815789461135864)
[2024-12-17 02:14:54,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:54,372][root][INFO] - Training Epoch: 1/2, step 5481/7134 completed (loss: 0.058694951236248016, acc: 0.9818181991577148)
[2024-12-17 02:14:54,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:55,015][root][INFO] - Training Epoch: 1/2, step 5482/7134 completed (loss: 0.06520427763462067, acc: 0.9830713272094727)
[2024-12-17 02:14:55,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:55,405][root][INFO] - Training Epoch: 1/2, step 5483/7134 completed (loss: 0.06703544408082962, acc: 0.9832869172096252)
[2024-12-17 02:14:55,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:55,757][root][INFO] - Training Epoch: 1/2, step 5484/7134 completed (loss: 0.07740367203950882, acc: 0.976356029510498)
[2024-12-17 02:14:55,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:56,079][root][INFO] - Training Epoch: 1/2, step 5485/7134 completed (loss: 0.09010431915521622, acc: 0.9691470265388489)
[2024-12-17 02:14:56,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:56,425][root][INFO] - Training Epoch: 1/2, step 5486/7134 completed (loss: 0.10335876792669296, acc: 0.9740484356880188)
[2024-12-17 02:14:56,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:56,748][root][INFO] - Training Epoch: 1/2, step 5487/7134 completed (loss: 0.03243507817387581, acc: 0.9886178970336914)
[2024-12-17 02:14:56,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:57,124][root][INFO] - Training Epoch: 1/2, step 5488/7134 completed (loss: 0.10395657271146774, acc: 0.9631578922271729)
[2024-12-17 02:14:57,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:57,486][root][INFO] - Training Epoch: 1/2, step 5489/7134 completed (loss: 0.08267904818058014, acc: 0.970588207244873)
[2024-12-17 02:14:57,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:57,734][root][INFO] - Training Epoch: 1/2, step 5490/7134 completed (loss: 0.053735438734292984, acc: 0.9794988632202148)
[2024-12-17 02:14:57,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:58,052][root][INFO] - Training Epoch: 1/2, step 5491/7134 completed (loss: 0.047591470181941986, acc: 0.9912023544311523)
[2024-12-17 02:14:58,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:58,376][root][INFO] - Training Epoch: 1/2, step 5492/7134 completed (loss: 0.071709044277668, acc: 0.9881556630134583)
[2024-12-17 02:14:58,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:58,696][root][INFO] - Training Epoch: 1/2, step 5493/7134 completed (loss: 0.09609431028366089, acc: 0.9728260636329651)
[2024-12-17 02:14:58,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:59,057][root][INFO] - Training Epoch: 1/2, step 5494/7134 completed (loss: 0.03529224544763565, acc: 0.9886202216148376)
[2024-12-17 02:14:59,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:59,369][root][INFO] - Training Epoch: 1/2, step 5495/7134 completed (loss: 0.04939050227403641, acc: 0.9874551892280579)
[2024-12-17 02:14:59,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:59,632][root][INFO] - Training Epoch: 1/2, step 5496/7134 completed (loss: 0.12188825756311417, acc: 0.9727626442909241)
[2024-12-17 02:14:59,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:59,953][root][INFO] - Training Epoch: 1/2, step 5497/7134 completed (loss: 0.12178116291761398, acc: 0.9692533016204834)
[2024-12-17 02:15:00,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:00,293][root][INFO] - Training Epoch: 1/2, step 5498/7134 completed (loss: 0.09592977166175842, acc: 0.9787798523902893)
[2024-12-17 02:15:00,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:00,630][root][INFO] - Training Epoch: 1/2, step 5499/7134 completed (loss: 0.08417404443025589, acc: 0.9773869514465332)
[2024-12-17 02:15:00,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:00,963][root][INFO] - Training Epoch: 1/2, step 5500/7134 completed (loss: 0.09647233039140701, acc: 0.9740791320800781)
[2024-12-17 02:15:01,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:01,313][root][INFO] - Training Epoch: 1/2, step 5501/7134 completed (loss: 0.06374605000019073, acc: 0.9777777791023254)
[2024-12-17 02:15:01,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:01,662][root][INFO] - Training Epoch: 1/2, step 5502/7134 completed (loss: 0.05857653543353081, acc: 0.9838056564331055)
[2024-12-17 02:15:01,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:01,982][root][INFO] - Training Epoch: 1/2, step 5503/7134 completed (loss: 0.09245286881923676, acc: 0.9681908488273621)
[2024-12-17 02:15:02,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:02,335][root][INFO] - Training Epoch: 1/2, step 5504/7134 completed (loss: 0.07156664878129959, acc: 0.9757869243621826)
[2024-12-17 02:15:02,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:02,666][root][INFO] - Training Epoch: 1/2, step 5505/7134 completed (loss: 0.08905625343322754, acc: 0.9631205797195435)
[2024-12-17 02:15:02,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:03,011][root][INFO] - Training Epoch: 1/2, step 5506/7134 completed (loss: 0.08212815225124359, acc: 0.9803921580314636)
[2024-12-17 02:15:03,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:03,352][root][INFO] - Training Epoch: 1/2, step 5507/7134 completed (loss: 0.087728351354599, acc: 0.9789915680885315)
[2024-12-17 02:15:03,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:03,712][root][INFO] - Training Epoch: 1/2, step 5508/7134 completed (loss: 0.05091538652777672, acc: 0.9883177280426025)
[2024-12-17 02:15:03,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:04,073][root][INFO] - Training Epoch: 1/2, step 5509/7134 completed (loss: 0.05578635632991791, acc: 0.984795331954956)
[2024-12-17 02:15:04,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:04,426][root][INFO] - Training Epoch: 1/2, step 5510/7134 completed (loss: 0.08344810456037521, acc: 0.9755784273147583)
[2024-12-17 02:15:04,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:04,801][root][INFO] - Training Epoch: 1/2, step 5511/7134 completed (loss: 0.08614761382341385, acc: 0.9796379804611206)
[2024-12-17 02:15:04,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:05,145][root][INFO] - Training Epoch: 1/2, step 5512/7134 completed (loss: 0.052195802330970764, acc: 0.9868247509002686)
[2024-12-17 02:15:05,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:05,473][root][INFO] - Training Epoch: 1/2, step 5513/7134 completed (loss: 0.07830329239368439, acc: 0.979619562625885)
[2024-12-17 02:15:05,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:05,829][root][INFO] - Training Epoch: 1/2, step 5514/7134 completed (loss: 0.2322510927915573, acc: 0.9465174078941345)
[2024-12-17 02:15:05,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:06,157][root][INFO] - Training Epoch: 1/2, step 5515/7134 completed (loss: 0.07785885035991669, acc: 0.980028510093689)
[2024-12-17 02:15:06,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:06,474][root][INFO] - Training Epoch: 1/2, step 5516/7134 completed (loss: 0.05333607643842697, acc: 0.9887482523918152)
[2024-12-17 02:15:06,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:06,804][root][INFO] - Training Epoch: 1/2, step 5517/7134 completed (loss: 0.054547496140003204, acc: 0.9867021441459656)
[2024-12-17 02:15:06,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:07,158][root][INFO] - Training Epoch: 1/2, step 5518/7134 completed (loss: 0.06402542442083359, acc: 0.989130437374115)
[2024-12-17 02:15:07,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:07,509][root][INFO] - Training Epoch: 1/2, step 5519/7134 completed (loss: 0.039956457912921906, acc: 0.9875862002372742)
[2024-12-17 02:15:07,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:07,863][root][INFO] - Training Epoch: 1/2, step 5520/7134 completed (loss: 0.039205506443977356, acc: 0.9909399747848511)
[2024-12-17 02:15:07,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:08,218][root][INFO] - Training Epoch: 1/2, step 5521/7134 completed (loss: 0.07921435683965683, acc: 0.9849246144294739)
[2024-12-17 02:15:08,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:08,562][root][INFO] - Training Epoch: 1/2, step 5522/7134 completed (loss: 0.09074471890926361, acc: 0.9738562107086182)
[2024-12-17 02:15:08,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:08,868][root][INFO] - Training Epoch: 1/2, step 5523/7134 completed (loss: 0.07344674319028854, acc: 0.983146071434021)
[2024-12-17 02:15:08,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:09,194][root][INFO] - Training Epoch: 1/2, step 5524/7134 completed (loss: 0.07278545200824738, acc: 0.9814241528511047)
[2024-12-17 02:15:09,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:09,545][root][INFO] - Training Epoch: 1/2, step 5525/7134 completed (loss: 0.061860304325819016, acc: 0.9838945865631104)
[2024-12-17 02:15:09,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:09,877][root][INFO] - Training Epoch: 1/2, step 5526/7134 completed (loss: 0.0806431695818901, acc: 0.9808542132377625)
[2024-12-17 02:15:09,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:10,210][root][INFO] - Training Epoch: 1/2, step 5527/7134 completed (loss: 0.06974305212497711, acc: 0.9798319339752197)
[2024-12-17 02:15:10,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:10,563][root][INFO] - Training Epoch: 1/2, step 5528/7134 completed (loss: 0.05531967431306839, acc: 0.9846153855323792)
[2024-12-17 02:15:10,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:10,920][root][INFO] - Training Epoch: 1/2, step 5529/7134 completed (loss: 0.07491914927959442, acc: 0.9763593673706055)
[2024-12-17 02:15:11,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:11,269][root][INFO] - Training Epoch: 1/2, step 5530/7134 completed (loss: 0.06377866864204407, acc: 0.9850968718528748)
[2024-12-17 02:15:11,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:11,624][root][INFO] - Training Epoch: 1/2, step 5531/7134 completed (loss: 0.0698976218700409, acc: 0.9788293838500977)
[2024-12-17 02:15:11,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:11,994][root][INFO] - Training Epoch: 1/2, step 5532/7134 completed (loss: 0.09299543499946594, acc: 0.9752781391143799)
[2024-12-17 02:15:12,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:12,358][root][INFO] - Training Epoch: 1/2, step 5533/7134 completed (loss: 0.03475038334727287, acc: 0.9897959232330322)
[2024-12-17 02:15:12,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:12,727][root][INFO] - Training Epoch: 1/2, step 5534/7134 completed (loss: 0.08189332485198975, acc: 0.9766355156898499)
[2024-12-17 02:15:12,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:13,089][root][INFO] - Training Epoch: 1/2, step 5535/7134 completed (loss: 0.07509613782167435, acc: 0.9815016388893127)
[2024-12-17 02:15:13,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:13,430][root][INFO] - Training Epoch: 1/2, step 5536/7134 completed (loss: 0.0596206933259964, acc: 0.984883725643158)
[2024-12-17 02:15:13,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:13,772][root][INFO] - Training Epoch: 1/2, step 5537/7134 completed (loss: 0.06430331617593765, acc: 0.9871645569801331)
[2024-12-17 02:15:13,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:14,129][root][INFO] - Training Epoch: 1/2, step 5538/7134 completed (loss: 0.061360303312540054, acc: 0.9874857664108276)
[2024-12-17 02:15:14,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:14,496][root][INFO] - Training Epoch: 1/2, step 5539/7134 completed (loss: 0.07941048592329025, acc: 0.9740990996360779)
[2024-12-17 02:15:14,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:14,850][root][INFO] - Training Epoch: 1/2, step 5540/7134 completed (loss: 0.09638350456953049, acc: 0.9789473414421082)
[2024-12-17 02:15:14,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:15,206][root][INFO] - Training Epoch: 1/2, step 5541/7134 completed (loss: 0.07803221791982651, acc: 0.9813829660415649)
[2024-12-17 02:15:15,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:15,542][root][INFO] - Training Epoch: 1/2, step 5542/7134 completed (loss: 0.05082712322473526, acc: 0.984308123588562)
[2024-12-17 02:15:15,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:15,908][root][INFO] - Training Epoch: 1/2, step 5543/7134 completed (loss: 0.06205574795603752, acc: 0.9811530113220215)
[2024-12-17 02:15:16,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:16,268][root][INFO] - Training Epoch: 1/2, step 5544/7134 completed (loss: 0.03985944017767906, acc: 0.9870967864990234)
[2024-12-17 02:15:16,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:16,624][root][INFO] - Training Epoch: 1/2, step 5545/7134 completed (loss: 0.05843821167945862, acc: 0.985792338848114)
[2024-12-17 02:15:16,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:16,972][root][INFO] - Training Epoch: 1/2, step 5546/7134 completed (loss: 0.06666085124015808, acc: 0.9833887219429016)
[2024-12-17 02:15:17,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:17,336][root][INFO] - Training Epoch: 1/2, step 5547/7134 completed (loss: 0.0626385360956192, acc: 0.9861751198768616)
[2024-12-17 02:15:17,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:17,684][root][INFO] - Training Epoch: 1/2, step 5548/7134 completed (loss: 0.04371771588921547, acc: 0.9872093200683594)
[2024-12-17 02:15:17,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:18,014][root][INFO] - Training Epoch: 1/2, step 5549/7134 completed (loss: 0.04896647855639458, acc: 0.9842857122421265)
[2024-12-17 02:15:18,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:18,363][root][INFO] - Training Epoch: 1/2, step 5550/7134 completed (loss: 0.03561174497008324, acc: 0.9894242286682129)
[2024-12-17 02:15:18,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:18,680][root][INFO] - Training Epoch: 1/2, step 5551/7134 completed (loss: 0.09014376252889633, acc: 0.9797022938728333)
[2024-12-17 02:15:18,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:19,030][root][INFO] - Training Epoch: 1/2, step 5552/7134 completed (loss: 0.05966638773679733, acc: 0.9869203567504883)
[2024-12-17 02:15:19,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:19,371][root][INFO] - Training Epoch: 1/2, step 5553/7134 completed (loss: 0.06161241978406906, acc: 0.9876390695571899)
[2024-12-17 02:15:19,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:19,712][root][INFO] - Training Epoch: 1/2, step 5554/7134 completed (loss: 0.04040056839585304, acc: 0.9889975786209106)
[2024-12-17 02:15:19,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:20,053][root][INFO] - Training Epoch: 1/2, step 5555/7134 completed (loss: 0.06930553913116455, acc: 0.9732620120048523)
[2024-12-17 02:15:20,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:20,370][root][INFO] - Training Epoch: 1/2, step 5556/7134 completed (loss: 0.07218276709318161, acc: 0.9766536951065063)
[2024-12-17 02:15:20,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:20,725][root][INFO] - Training Epoch: 1/2, step 5557/7134 completed (loss: 0.0438075065612793, acc: 0.9887955188751221)
[2024-12-17 02:15:20,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:21,081][root][INFO] - Training Epoch: 1/2, step 5558/7134 completed (loss: 0.039166469126939774, acc: 0.9863353967666626)
[2024-12-17 02:15:21,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:21,425][root][INFO] - Training Epoch: 1/2, step 5559/7134 completed (loss: 0.0677439495921135, acc: 0.9863353967666626)
[2024-12-17 02:15:21,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:21,758][root][INFO] - Training Epoch: 1/2, step 5560/7134 completed (loss: 0.09131656587123871, acc: 0.9766839146614075)
[2024-12-17 02:15:21,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:22,055][root][INFO] - Training Epoch: 1/2, step 5561/7134 completed (loss: 0.07180721312761307, acc: 0.9867674708366394)
[2024-12-17 02:15:22,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:22,410][root][INFO] - Training Epoch: 1/2, step 5562/7134 completed (loss: 0.0475977323949337, acc: 0.9897611141204834)
[2024-12-17 02:15:22,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:22,755][root][INFO] - Training Epoch: 1/2, step 5563/7134 completed (loss: 0.08779744803905487, acc: 0.9759759902954102)
[2024-12-17 02:15:22,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:23,073][root][INFO] - Training Epoch: 1/2, step 5564/7134 completed (loss: 0.06008418649435043, acc: 0.991631805896759)
[2024-12-17 02:15:23,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:23,421][root][INFO] - Training Epoch: 1/2, step 5565/7134 completed (loss: 0.026638122275471687, acc: 0.9938555955886841)
[2024-12-17 02:15:23,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:23,783][root][INFO] - Training Epoch: 1/2, step 5566/7134 completed (loss: 0.04846283048391342, acc: 0.9873708486557007)
[2024-12-17 02:15:23,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:24,153][root][INFO] - Training Epoch: 1/2, step 5567/7134 completed (loss: 0.05310841649770737, acc: 0.9863013625144958)
[2024-12-17 02:15:24,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:24,473][root][INFO] - Training Epoch: 1/2, step 5568/7134 completed (loss: 0.05427945405244827, acc: 0.9871134161949158)
[2024-12-17 02:15:24,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:24,842][root][INFO] - Training Epoch: 1/2, step 5569/7134 completed (loss: 0.04161635413765907, acc: 0.990867555141449)
[2024-12-17 02:15:24,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:25,190][root][INFO] - Training Epoch: 1/2, step 5570/7134 completed (loss: 0.03482789918780327, acc: 0.9900621175765991)
[2024-12-17 02:15:25,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:25,510][root][INFO] - Training Epoch: 1/2, step 5571/7134 completed (loss: 0.055130209773778915, acc: 0.9866270422935486)
[2024-12-17 02:15:25,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:25,844][root][INFO] - Training Epoch: 1/2, step 5572/7134 completed (loss: 0.0671311542391777, acc: 0.9862637519836426)
[2024-12-17 02:15:25,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:26,210][root][INFO] - Training Epoch: 1/2, step 5573/7134 completed (loss: 0.053491413593292236, acc: 0.9868995547294617)
[2024-12-17 02:15:26,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:26,525][root][INFO] - Training Epoch: 1/2, step 5574/7134 completed (loss: 0.0328255295753479, acc: 0.9873015880584717)
[2024-12-17 02:15:26,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:26,872][root][INFO] - Training Epoch: 1/2, step 5575/7134 completed (loss: 0.0432492196559906, acc: 0.9824561476707458)
[2024-12-17 02:15:26,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:27,192][root][INFO] - Training Epoch: 1/2, step 5576/7134 completed (loss: 0.051551610231399536, acc: 0.9856733679771423)
[2024-12-17 02:15:27,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:27,529][root][INFO] - Training Epoch: 1/2, step 5577/7134 completed (loss: 0.06973279267549515, acc: 0.9790576100349426)
[2024-12-17 02:15:27,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:27,897][root][INFO] - Training Epoch: 1/2, step 5578/7134 completed (loss: 0.027376996353268623, acc: 0.9956958293914795)
[2024-12-17 02:15:28,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:28,252][root][INFO] - Training Epoch: 1/2, step 5579/7134 completed (loss: 0.04743010923266411, acc: 0.9861687421798706)
[2024-12-17 02:15:28,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:28,576][root][INFO] - Training Epoch: 1/2, step 5580/7134 completed (loss: 0.031916387379169464, acc: 0.9931787252426147)
[2024-12-17 02:15:28,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:28,926][root][INFO] - Training Epoch: 1/2, step 5581/7134 completed (loss: 0.053551122546195984, acc: 0.9853723645210266)
[2024-12-17 02:15:29,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:29,285][root][INFO] - Training Epoch: 1/2, step 5582/7134 completed (loss: 0.06218569725751877, acc: 0.9817470908164978)
[2024-12-17 02:15:29,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:29,641][root][INFO] - Training Epoch: 1/2, step 5583/7134 completed (loss: 0.06881874799728394, acc: 0.982367753982544)
[2024-12-17 02:15:29,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:29,973][root][INFO] - Training Epoch: 1/2, step 5584/7134 completed (loss: 0.051383696496486664, acc: 0.9852070808410645)
[2024-12-17 02:15:30,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:30,339][root][INFO] - Training Epoch: 1/2, step 5585/7134 completed (loss: 0.06082804501056671, acc: 0.9830303192138672)
[2024-12-17 02:15:30,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:30,646][root][INFO] - Training Epoch: 1/2, step 5586/7134 completed (loss: 0.07085968554019928, acc: 0.9822379946708679)
[2024-12-17 02:15:30,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:30,996][root][INFO] - Training Epoch: 1/2, step 5587/7134 completed (loss: 0.04364151135087013, acc: 0.9889042973518372)
[2024-12-17 02:15:31,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:31,352][root][INFO] - Training Epoch: 1/2, step 5588/7134 completed (loss: 0.0331215001642704, acc: 0.9909228682518005)
[2024-12-17 02:15:31,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:31,686][root][INFO] - Training Epoch: 1/2, step 5589/7134 completed (loss: 0.036043860018253326, acc: 0.9921135902404785)
[2024-12-17 02:15:31,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:32,010][root][INFO] - Training Epoch: 1/2, step 5590/7134 completed (loss: 0.04490919038653374, acc: 0.98591548204422)
[2024-12-17 02:15:32,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:32,331][root][INFO] - Training Epoch: 1/2, step 5591/7134 completed (loss: 0.03355807811021805, acc: 0.9921466112136841)
[2024-12-17 02:15:32,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:32,656][root][INFO] - Training Epoch: 1/2, step 5592/7134 completed (loss: 0.04220622405409813, acc: 0.9862825870513916)
[2024-12-17 02:15:32,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:33,005][root][INFO] - Training Epoch: 1/2, step 5593/7134 completed (loss: 0.06818947941064835, acc: 0.9805699586868286)
[2024-12-17 02:15:33,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:33,348][root][INFO] - Training Epoch: 1/2, step 5594/7134 completed (loss: 0.03528527542948723, acc: 0.9919137358665466)
[2024-12-17 02:15:33,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:33,685][root][INFO] - Training Epoch: 1/2, step 5595/7134 completed (loss: 0.07248885929584503, acc: 0.9825737476348877)
[2024-12-17 02:15:33,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:34,009][root][INFO] - Training Epoch: 1/2, step 5596/7134 completed (loss: 0.05321495607495308, acc: 0.977150559425354)
[2024-12-17 02:15:34,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:34,344][root][INFO] - Training Epoch: 1/2, step 5597/7134 completed (loss: 0.08940336108207703, acc: 0.9696969985961914)
[2024-12-17 02:15:34,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:34,677][root][INFO] - Training Epoch: 1/2, step 5598/7134 completed (loss: 0.05773567035794258, acc: 0.9818435907363892)
[2024-12-17 02:15:34,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:35,024][root][INFO] - Training Epoch: 1/2, step 5599/7134 completed (loss: 0.09097280353307724, acc: 0.9822404384613037)
[2024-12-17 02:15:35,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:35,380][root][INFO] - Training Epoch: 1/2, step 5600/7134 completed (loss: 0.04733797907829285, acc: 0.9871060252189636)
[2024-12-17 02:15:35,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:35,693][root][INFO] - Training Epoch: 1/2, step 5601/7134 completed (loss: 0.08537669479846954, acc: 0.9773913025856018)
[2024-12-17 02:15:35,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:36,023][root][INFO] - Training Epoch: 1/2, step 5602/7134 completed (loss: 0.07841359078884125, acc: 0.9758453965187073)
[2024-12-17 02:15:36,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:36,334][root][INFO] - Training Epoch: 1/2, step 5603/7134 completed (loss: 0.022645212709903717, acc: 0.9918166995048523)
[2024-12-17 02:15:36,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:36,641][root][INFO] - Training Epoch: 1/2, step 5604/7134 completed (loss: 0.11192310601472855, acc: 0.9646302461624146)
[2024-12-17 02:15:36,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:36,961][root][INFO] - Training Epoch: 1/2, step 5605/7134 completed (loss: 0.062067341059446335, acc: 0.9813242554664612)
[2024-12-17 02:15:37,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:37,283][root][INFO] - Training Epoch: 1/2, step 5606/7134 completed (loss: 0.0784250870347023, acc: 0.9764957427978516)
[2024-12-17 02:15:37,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:37,610][root][INFO] - Training Epoch: 1/2, step 5607/7134 completed (loss: 0.05012787505984306, acc: 0.9834586381912231)
[2024-12-17 02:15:37,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:37,934][root][INFO] - Training Epoch: 1/2, step 5608/7134 completed (loss: 0.06284894049167633, acc: 0.9819375872612)
[2024-12-17 02:15:38,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:38,250][root][INFO] - Training Epoch: 1/2, step 5609/7134 completed (loss: 0.0713551938533783, acc: 0.9756521582603455)
[2024-12-17 02:15:38,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:38,539][root][INFO] - Training Epoch: 1/2, step 5610/7134 completed (loss: 0.04552970454096794, acc: 0.9919517040252686)
[2024-12-17 02:15:38,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:38,905][root][INFO] - Training Epoch: 1/2, step 5611/7134 completed (loss: 0.0845879390835762, acc: 0.9715189933776855)
[2024-12-17 02:15:39,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:39,257][root][INFO] - Training Epoch: 1/2, step 5612/7134 completed (loss: 0.05911082774400711, acc: 0.9815950989723206)
[2024-12-17 02:15:39,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:39,580][root][INFO] - Training Epoch: 1/2, step 5613/7134 completed (loss: 0.07198145985603333, acc: 0.980322003364563)
[2024-12-17 02:15:39,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:39,908][root][INFO] - Training Epoch: 1/2, step 5614/7134 completed (loss: 0.0884162187576294, acc: 0.977142870426178)
[2024-12-17 02:15:40,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:40,251][root][INFO] - Training Epoch: 1/2, step 5615/7134 completed (loss: 0.08367781341075897, acc: 0.969348669052124)
[2024-12-17 02:15:40,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:40,576][root][INFO] - Training Epoch: 1/2, step 5616/7134 completed (loss: 0.06566064804792404, acc: 0.9762258529663086)
[2024-12-17 02:15:40,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:40,893][root][INFO] - Training Epoch: 1/2, step 5617/7134 completed (loss: 0.024356843903660774, acc: 0.9935064911842346)
[2024-12-17 02:15:41,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:41,228][root][INFO] - Training Epoch: 1/2, step 5618/7134 completed (loss: 0.09089682996273041, acc: 0.9707317352294922)
[2024-12-17 02:15:41,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:41,551][root][INFO] - Training Epoch: 1/2, step 5619/7134 completed (loss: 0.07730147242546082, acc: 0.9797160029411316)
[2024-12-17 02:15:41,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:41,896][root][INFO] - Training Epoch: 1/2, step 5620/7134 completed (loss: 0.0917138084769249, acc: 0.9738317728042603)
[2024-12-17 02:15:42,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:42,259][root][INFO] - Training Epoch: 1/2, step 5621/7134 completed (loss: 0.04580255225300789, acc: 0.9898348450660706)
[2024-12-17 02:15:42,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:42,600][root][INFO] - Training Epoch: 1/2, step 5622/7134 completed (loss: 0.08852359652519226, acc: 0.975476861000061)
[2024-12-17 02:15:42,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:42,904][root][INFO] - Training Epoch: 1/2, step 5623/7134 completed (loss: 0.06621547788381577, acc: 0.9808362126350403)
[2024-12-17 02:15:43,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:43,240][root][INFO] - Training Epoch: 1/2, step 5624/7134 completed (loss: 0.09039980918169022, acc: 0.978723406791687)
[2024-12-17 02:15:43,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:43,553][root][INFO] - Training Epoch: 1/2, step 5625/7134 completed (loss: 0.022204041481018066, acc: 0.9952940940856934)
[2024-12-17 02:15:43,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:43,878][root][INFO] - Training Epoch: 1/2, step 5626/7134 completed (loss: 0.04065558686852455, acc: 0.9915397763252258)
[2024-12-17 02:15:44,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:44,204][root][INFO] - Training Epoch: 1/2, step 5627/7134 completed (loss: 0.194907546043396, acc: 0.9591836929321289)
[2024-12-17 02:15:44,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:44,571][root][INFO] - Training Epoch: 1/2, step 5628/7134 completed (loss: 0.07984135299921036, acc: 0.9763205647468567)
[2024-12-17 02:15:44,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:44,919][root][INFO] - Training Epoch: 1/2, step 5629/7134 completed (loss: 0.1135321855545044, acc: 0.9753954410552979)
[2024-12-17 02:15:45,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:45,247][root][INFO] - Training Epoch: 1/2, step 5630/7134 completed (loss: 0.13057808578014374, acc: 0.9712525606155396)
[2024-12-17 02:15:45,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:45,570][root][INFO] - Training Epoch: 1/2, step 5631/7134 completed (loss: 0.14349423348903656, acc: 0.9502487778663635)
[2024-12-17 02:15:45,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:45,903][root][INFO] - Training Epoch: 1/2, step 5632/7134 completed (loss: 0.07882165163755417, acc: 0.9727767705917358)
[2024-12-17 02:15:46,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:46,225][root][INFO] - Training Epoch: 1/2, step 5633/7134 completed (loss: 0.11863185465335846, acc: 0.965798020362854)
[2024-12-17 02:15:46,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:46,552][root][INFO] - Training Epoch: 1/2, step 5634/7134 completed (loss: 0.08211961388587952, acc: 0.9842932224273682)
[2024-12-17 02:15:46,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:46,887][root][INFO] - Training Epoch: 1/2, step 5635/7134 completed (loss: 0.05687837302684784, acc: 0.9864864945411682)
[2024-12-17 02:15:46,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:47,222][root][INFO] - Training Epoch: 1/2, step 5636/7134 completed (loss: 0.0649053305387497, acc: 0.9760383367538452)
[2024-12-17 02:15:47,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:47,547][root][INFO] - Training Epoch: 1/2, step 5637/7134 completed (loss: 0.09678582847118378, acc: 0.9713321924209595)
[2024-12-17 02:15:47,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:47,836][root][INFO] - Training Epoch: 1/2, step 5638/7134 completed (loss: 0.0824005976319313, acc: 0.98046875)
[2024-12-17 02:15:47,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:48,177][root][INFO] - Training Epoch: 1/2, step 5639/7134 completed (loss: 0.07495465874671936, acc: 0.9772079586982727)
[2024-12-17 02:15:48,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:48,495][root][INFO] - Training Epoch: 1/2, step 5640/7134 completed (loss: 0.07360086590051651, acc: 0.9788618087768555)
[2024-12-17 02:15:48,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:48,775][root][INFO] - Training Epoch: 1/2, step 5641/7134 completed (loss: 0.1080094650387764, acc: 0.9823232293128967)
[2024-12-17 02:15:48,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:49,096][root][INFO] - Training Epoch: 1/2, step 5642/7134 completed (loss: 0.10139532387256622, acc: 0.9757575988769531)
[2024-12-17 02:15:49,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:49,434][root][INFO] - Training Epoch: 1/2, step 5643/7134 completed (loss: 0.08848093450069427, acc: 0.9756637215614319)
[2024-12-17 02:15:49,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:49,772][root][INFO] - Training Epoch: 1/2, step 5644/7134 completed (loss: 0.10315835475921631, acc: 0.9756097793579102)
[2024-12-17 02:15:49,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:50,093][root][INFO] - Training Epoch: 1/2, step 5645/7134 completed (loss: 0.07527767866849899, acc: 0.9779086709022522)
[2024-12-17 02:15:50,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:50,434][root][INFO] - Training Epoch: 1/2, step 5646/7134 completed (loss: 0.06339046359062195, acc: 0.9808917045593262)
[2024-12-17 02:15:50,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:50,770][root][INFO] - Training Epoch: 1/2, step 5647/7134 completed (loss: 0.06975020468235016, acc: 0.9860464930534363)
[2024-12-17 02:15:50,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:51,104][root][INFO] - Training Epoch: 1/2, step 5648/7134 completed (loss: 0.14391279220581055, acc: 0.9731343388557434)
[2024-12-17 02:15:51,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:51,417][root][INFO] - Training Epoch: 1/2, step 5649/7134 completed (loss: 0.09233146905899048, acc: 0.9785932898521423)
[2024-12-17 02:15:51,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:51,755][root][INFO] - Training Epoch: 1/2, step 5650/7134 completed (loss: 0.058173760771751404, acc: 0.9811320900917053)
[2024-12-17 02:15:51,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:52,094][root][INFO] - Training Epoch: 1/2, step 5651/7134 completed (loss: 0.03596877306699753, acc: 0.9926035404205322)
[2024-12-17 02:15:52,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:52,453][root][INFO] - Training Epoch: 1/2, step 5652/7134 completed (loss: 0.07079941034317017, acc: 0.9759615659713745)
[2024-12-17 02:15:52,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:52,714][root][INFO] - Training Epoch: 1/2, step 5653/7134 completed (loss: 0.13390636444091797, acc: 0.9557291865348816)
[2024-12-17 02:15:52,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:53,035][root][INFO] - Training Epoch: 1/2, step 5654/7134 completed (loss: 0.05093512684106827, acc: 0.9864864945411682)
[2024-12-17 02:15:53,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:53,367][root][INFO] - Training Epoch: 1/2, step 5655/7134 completed (loss: 0.06260395050048828, acc: 0.9829931855201721)
[2024-12-17 02:15:53,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:53,682][root][INFO] - Training Epoch: 1/2, step 5656/7134 completed (loss: 0.0526508167386055, acc: 0.9885714054107666)
[2024-12-17 02:15:53,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:54,004][root][INFO] - Training Epoch: 1/2, step 5657/7134 completed (loss: 0.06281178444623947, acc: 0.9912152290344238)
[2024-12-17 02:15:54,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:54,358][root][INFO] - Training Epoch: 1/2, step 5658/7134 completed (loss: 0.08464527875185013, acc: 0.9751381278038025)
[2024-12-17 02:15:54,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:54,687][root][INFO] - Training Epoch: 1/2, step 5659/7134 completed (loss: 0.07989452034235, acc: 0.9858155846595764)
[2024-12-17 02:15:54,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:55,013][root][INFO] - Training Epoch: 1/2, step 5660/7134 completed (loss: 0.05325603112578392, acc: 0.9851239919662476)
[2024-12-17 02:15:55,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:55,363][root][INFO] - Training Epoch: 1/2, step 5661/7134 completed (loss: 0.03803601488471031, acc: 0.989051103591919)
[2024-12-17 02:15:55,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:55,704][root][INFO] - Training Epoch: 1/2, step 5662/7134 completed (loss: 0.041319992393255234, acc: 0.9887820482254028)
[2024-12-17 02:15:55,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:56,031][root][INFO] - Training Epoch: 1/2, step 5663/7134 completed (loss: 0.03301386535167694, acc: 0.9922958612442017)
[2024-12-17 02:15:56,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:56,357][root][INFO] - Training Epoch: 1/2, step 5664/7134 completed (loss: 0.0910644680261612, acc: 0.9806835055351257)
[2024-12-17 02:15:56,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:56,694][root][INFO] - Training Epoch: 1/2, step 5665/7134 completed (loss: 0.041133079677820206, acc: 0.9871612191200256)
[2024-12-17 02:15:56,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:57,049][root][INFO] - Training Epoch: 1/2, step 5666/7134 completed (loss: 0.03536805137991905, acc: 0.9903448224067688)
[2024-12-17 02:15:57,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:57,392][root][INFO] - Training Epoch: 1/2, step 5667/7134 completed (loss: 0.0551174096763134, acc: 0.9927272796630859)
[2024-12-17 02:15:57,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:57,708][root][INFO] - Training Epoch: 1/2, step 5668/7134 completed (loss: 0.08356830477714539, acc: 0.9784052968025208)
[2024-12-17 02:15:57,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:58,036][root][INFO] - Training Epoch: 1/2, step 5669/7134 completed (loss: 0.0552913136780262, acc: 0.9868035316467285)
[2024-12-17 02:15:58,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:58,363][root][INFO] - Training Epoch: 1/2, step 5670/7134 completed (loss: 0.030828440561890602, acc: 0.9900000095367432)
[2024-12-17 02:15:58,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:58,729][root][INFO] - Training Epoch: 1/2, step 5671/7134 completed (loss: 0.01765311323106289, acc: 0.9963099360466003)
[2024-12-17 02:15:58,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:59,087][root][INFO] - Training Epoch: 1/2, step 5672/7134 completed (loss: 0.024616694077849388, acc: 0.9936908483505249)
[2024-12-17 02:15:59,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:59,391][root][INFO] - Training Epoch: 1/2, step 5673/7134 completed (loss: 0.02608518674969673, acc: 0.9940915703773499)
[2024-12-17 02:15:59,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:59,744][root][INFO] - Training Epoch: 1/2, step 5674/7134 completed (loss: 0.030900750309228897, acc: 0.9954128265380859)
[2024-12-17 02:15:59,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:00,064][root][INFO] - Training Epoch: 1/2, step 5675/7134 completed (loss: 0.06243599206209183, acc: 0.9800994992256165)
[2024-12-17 02:16:00,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:00,395][root][INFO] - Training Epoch: 1/2, step 5676/7134 completed (loss: 0.09868479520082474, acc: 0.9792899489402771)
[2024-12-17 02:16:00,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:00,732][root][INFO] - Training Epoch: 1/2, step 5677/7134 completed (loss: 0.06450235098600388, acc: 0.9857954382896423)
[2024-12-17 02:16:00,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:01,061][root][INFO] - Training Epoch: 1/2, step 5678/7134 completed (loss: 0.048615165054798126, acc: 0.9882352948188782)
[2024-12-17 02:16:01,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:01,419][root][INFO] - Training Epoch: 1/2, step 5679/7134 completed (loss: 0.11718396842479706, acc: 0.9692533016204834)
[2024-12-17 02:16:01,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:01,751][root][INFO] - Training Epoch: 1/2, step 5680/7134 completed (loss: 0.11582110822200775, acc: 0.9612518548965454)
[2024-12-17 02:16:01,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:02,092][root][INFO] - Training Epoch: 1/2, step 5681/7134 completed (loss: 0.10065121948719025, acc: 0.9743589758872986)
[2024-12-17 02:16:02,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:02,424][root][INFO] - Training Epoch: 1/2, step 5682/7134 completed (loss: 0.07306704670190811, acc: 0.9797979593276978)
[2024-12-17 02:16:02,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:02,764][root][INFO] - Training Epoch: 1/2, step 5683/7134 completed (loss: 0.10278859734535217, acc: 0.9648609161376953)
[2024-12-17 02:16:02,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:03,129][root][INFO] - Training Epoch: 1/2, step 5684/7134 completed (loss: 0.10764465481042862, acc: 0.9814502596855164)
[2024-12-17 02:16:03,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:03,453][root][INFO] - Training Epoch: 1/2, step 5685/7134 completed (loss: 0.1269828826189041, acc: 0.966911792755127)
[2024-12-17 02:16:03,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:03,791][root][INFO] - Training Epoch: 1/2, step 5686/7134 completed (loss: 0.1264151930809021, acc: 0.9695431590080261)
[2024-12-17 02:16:03,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:04,115][root][INFO] - Training Epoch: 1/2, step 5687/7134 completed (loss: 0.12064754217863083, acc: 0.970695972442627)
[2024-12-17 02:16:04,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:04,474][root][INFO] - Training Epoch: 1/2, step 5688/7134 completed (loss: 0.09140533208847046, acc: 0.9759679436683655)
[2024-12-17 02:16:04,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:04,818][root][INFO] - Training Epoch: 1/2, step 5689/7134 completed (loss: 0.12427593767642975, acc: 0.9726027250289917)
[2024-12-17 02:16:04,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:05,188][root][INFO] - Training Epoch: 1/2, step 5690/7134 completed (loss: 0.07300687581300735, acc: 0.9834905862808228)
[2024-12-17 02:16:05,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:05,514][root][INFO] - Training Epoch: 1/2, step 5691/7134 completed (loss: 0.09188196063041687, acc: 0.9739130139350891)
[2024-12-17 02:16:05,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:05,880][root][INFO] - Training Epoch: 1/2, step 5692/7134 completed (loss: 0.08569303900003433, acc: 0.9825737476348877)
[2024-12-17 02:16:05,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:06,208][root][INFO] - Training Epoch: 1/2, step 5693/7134 completed (loss: 0.05734901502728462, acc: 0.9820089936256409)
[2024-12-17 02:16:06,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:06,521][root][INFO] - Training Epoch: 1/2, step 5694/7134 completed (loss: 0.08128941059112549, acc: 0.9797394871711731)
[2024-12-17 02:16:06,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:06,871][root][INFO] - Training Epoch: 1/2, step 5695/7134 completed (loss: 0.05856979638338089, acc: 0.9856733679771423)
[2024-12-17 02:16:06,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:07,221][root][INFO] - Training Epoch: 1/2, step 5696/7134 completed (loss: 0.05845882371068001, acc: 0.9847058653831482)
[2024-12-17 02:16:07,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:07,568][root][INFO] - Training Epoch: 1/2, step 5697/7134 completed (loss: 0.09490804374217987, acc: 0.9746121168136597)
[2024-12-17 02:16:07,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:07,916][root][INFO] - Training Epoch: 1/2, step 5698/7134 completed (loss: 0.08403050899505615, acc: 0.9836734533309937)
[2024-12-17 02:16:08,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:08,276][root][INFO] - Training Epoch: 1/2, step 5699/7134 completed (loss: 0.08124334365129471, acc: 0.9821656346321106)
[2024-12-17 02:16:08,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:08,632][root][INFO] - Training Epoch: 1/2, step 5700/7134 completed (loss: 0.04850048944354057, acc: 0.9900709390640259)
[2024-12-17 02:16:08,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:09,015][root][INFO] - Training Epoch: 1/2, step 5701/7134 completed (loss: 0.07000145316123962, acc: 0.9899874925613403)
[2024-12-17 02:16:09,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:09,362][root][INFO] - Training Epoch: 1/2, step 5702/7134 completed (loss: 0.06407637149095535, acc: 0.9864681959152222)
[2024-12-17 02:16:09,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:09,724][root][INFO] - Training Epoch: 1/2, step 5703/7134 completed (loss: 0.032570671290159225, acc: 0.9887482523918152)
[2024-12-17 02:16:09,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:10,063][root][INFO] - Training Epoch: 1/2, step 5704/7134 completed (loss: 0.07272808253765106, acc: 0.984308123588562)
[2024-12-17 02:16:10,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:10,329][root][INFO] - Training Epoch: 1/2, step 5705/7134 completed (loss: 0.025151044130325317, acc: 0.9964285492897034)
[2024-12-17 02:16:10,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:10,705][root][INFO] - Training Epoch: 1/2, step 5706/7134 completed (loss: 0.04789987951517105, acc: 0.9854586124420166)
[2024-12-17 02:16:10,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:11,028][root][INFO] - Training Epoch: 1/2, step 5707/7134 completed (loss: 0.0954778864979744, acc: 0.9718309640884399)
[2024-12-17 02:16:11,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:11,357][root][INFO] - Training Epoch: 1/2, step 5708/7134 completed (loss: 0.03361080214381218, acc: 0.9881481528282166)
[2024-12-17 02:16:11,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:11,698][root][INFO] - Training Epoch: 1/2, step 5709/7134 completed (loss: 0.07180335372686386, acc: 0.9822161197662354)
[2024-12-17 02:16:11,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:12,047][root][INFO] - Training Epoch: 1/2, step 5710/7134 completed (loss: 0.06549196690320969, acc: 0.983460545539856)
[2024-12-17 02:16:12,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:12,374][root][INFO] - Training Epoch: 1/2, step 5711/7134 completed (loss: 0.08598558604717255, acc: 0.9790576100349426)
[2024-12-17 02:16:12,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:12,713][root][INFO] - Training Epoch: 1/2, step 5712/7134 completed (loss: 0.09013769775629044, acc: 0.9800000190734863)
[2024-12-17 02:16:12,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:13,083][root][INFO] - Training Epoch: 1/2, step 5713/7134 completed (loss: 0.03400516137480736, acc: 0.9923760890960693)
[2024-12-17 02:16:13,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:13,437][root][INFO] - Training Epoch: 1/2, step 5714/7134 completed (loss: 0.05267360433936119, acc: 0.9850560426712036)
[2024-12-17 02:16:13,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:13,761][root][INFO] - Training Epoch: 1/2, step 5715/7134 completed (loss: 0.10145758092403412, acc: 0.9851024150848389)
[2024-12-17 02:16:13,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:14,082][root][INFO] - Training Epoch: 1/2, step 5716/7134 completed (loss: 0.17439627647399902, acc: 0.9680284261703491)
[2024-12-17 02:16:14,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:14,400][root][INFO] - Training Epoch: 1/2, step 5717/7134 completed (loss: 0.1696455329656601, acc: 0.9688957929611206)
[2024-12-17 02:16:14,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:14,711][root][INFO] - Training Epoch: 1/2, step 5718/7134 completed (loss: 0.0816398486495018, acc: 0.9873816967010498)
[2024-12-17 02:16:14,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:15,035][root][INFO] - Training Epoch: 1/2, step 5719/7134 completed (loss: 0.06171960383653641, acc: 0.9865067601203918)
[2024-12-17 02:16:15,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:15,356][root][INFO] - Training Epoch: 1/2, step 5720/7134 completed (loss: 0.05651989206671715, acc: 0.984455943107605)
[2024-12-17 02:16:15,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:15,679][root][INFO] - Training Epoch: 1/2, step 5721/7134 completed (loss: 0.09379095584154129, acc: 0.9842105507850647)
[2024-12-17 02:16:15,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:15,954][root][INFO] - Training Epoch: 1/2, step 5722/7134 completed (loss: 0.07834574580192566, acc: 0.9844789505004883)
[2024-12-17 02:16:16,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:16,295][root][INFO] - Training Epoch: 1/2, step 5723/7134 completed (loss: 0.10575107485055923, acc: 0.9727685451507568)
[2024-12-17 02:16:16,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:16,613][root][INFO] - Training Epoch: 1/2, step 5724/7134 completed (loss: 0.06772222369909286, acc: 0.979200005531311)
[2024-12-17 02:16:16,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:16,963][root][INFO] - Training Epoch: 1/2, step 5725/7134 completed (loss: 0.06539230048656464, acc: 0.9828571677207947)
[2024-12-17 02:16:17,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:17,283][root][INFO] - Training Epoch: 1/2, step 5726/7134 completed (loss: 0.081016905605793, acc: 0.9801223278045654)
[2024-12-17 02:16:17,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:17,630][root][INFO] - Training Epoch: 1/2, step 5727/7134 completed (loss: 0.041795700788497925, acc: 0.990641713142395)
[2024-12-17 02:16:17,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:17,930][root][INFO] - Training Epoch: 1/2, step 5728/7134 completed (loss: 0.04030170664191246, acc: 0.9842105507850647)
[2024-12-17 02:16:18,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:18,252][root][INFO] - Training Epoch: 1/2, step 5729/7134 completed (loss: 0.04621254280209541, acc: 0.9850000143051147)
[2024-12-17 02:16:18,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:18,570][root][INFO] - Training Epoch: 1/2, step 5730/7134 completed (loss: 0.12016592919826508, acc: 0.9797979593276978)
[2024-12-17 02:16:18,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:18,923][root][INFO] - Training Epoch: 1/2, step 5731/7134 completed (loss: 0.09009163826704025, acc: 0.9717608094215393)
[2024-12-17 02:16:19,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:19,248][root][INFO] - Training Epoch: 1/2, step 5732/7134 completed (loss: 0.22058406472206116, acc: 0.9572815299034119)
[2024-12-17 02:16:19,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:19,573][root][INFO] - Training Epoch: 1/2, step 5733/7134 completed (loss: 0.06545750051736832, acc: 0.9781420826911926)
[2024-12-17 02:16:19,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:19,895][root][INFO] - Training Epoch: 1/2, step 5734/7134 completed (loss: 0.04360642656683922, acc: 0.9883333444595337)
[2024-12-17 02:16:20,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:20,213][root][INFO] - Training Epoch: 1/2, step 5735/7134 completed (loss: 0.10375986248254776, acc: 0.9713261723518372)
[2024-12-17 02:16:20,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:20,573][root][INFO] - Training Epoch: 1/2, step 5736/7134 completed (loss: 0.06549044698476791, acc: 0.9819548726081848)
[2024-12-17 02:16:20,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:20,904][root][INFO] - Training Epoch: 1/2, step 5737/7134 completed (loss: 0.07060394436120987, acc: 0.9803625345230103)
[2024-12-17 02:16:21,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:21,257][root][INFO] - Training Epoch: 1/2, step 5738/7134 completed (loss: 0.06056801974773407, acc: 0.9854897260665894)
[2024-12-17 02:16:21,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:21,595][root][INFO] - Training Epoch: 1/2, step 5739/7134 completed (loss: 0.1113562136888504, acc: 0.972631573677063)
[2024-12-17 02:16:21,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:21,924][root][INFO] - Training Epoch: 1/2, step 5740/7134 completed (loss: 0.06253938376903534, acc: 0.9795396327972412)
[2024-12-17 02:16:22,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:22,264][root][INFO] - Training Epoch: 1/2, step 5741/7134 completed (loss: 0.07581568509340286, acc: 0.9807445406913757)
[2024-12-17 02:16:22,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:22,607][root][INFO] - Training Epoch: 1/2, step 5742/7134 completed (loss: 0.04978134483098984, acc: 0.9855453372001648)
[2024-12-17 02:16:22,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:22,968][root][INFO] - Training Epoch: 1/2, step 5743/7134 completed (loss: 0.05729462951421738, acc: 0.9840686321258545)
[2024-12-17 02:16:23,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:23,258][root][INFO] - Training Epoch: 1/2, step 5744/7134 completed (loss: 0.05547938495874405, acc: 0.9811715483665466)
[2024-12-17 02:16:23,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:23,613][root][INFO] - Training Epoch: 1/2, step 5745/7134 completed (loss: 0.06750799715518951, acc: 0.984455943107605)
[2024-12-17 02:16:23,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:23,931][root][INFO] - Training Epoch: 1/2, step 5746/7134 completed (loss: 0.08953486382961273, acc: 0.9823529124259949)
[2024-12-17 02:16:24,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:24,264][root][INFO] - Training Epoch: 1/2, step 5747/7134 completed (loss: 0.03301071375608444, acc: 0.9916897416114807)
[2024-12-17 02:16:24,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:24,613][root][INFO] - Training Epoch: 1/2, step 5748/7134 completed (loss: 0.04606689512729645, acc: 0.9890310764312744)
[2024-12-17 02:16:24,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:24,973][root][INFO] - Training Epoch: 1/2, step 5749/7134 completed (loss: 0.062169838696718216, acc: 0.9842932224273682)
[2024-12-17 02:16:25,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:25,312][root][INFO] - Training Epoch: 1/2, step 5750/7134 completed (loss: 0.05980949476361275, acc: 0.9814356565475464)
[2024-12-17 02:16:25,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:25,652][root][INFO] - Training Epoch: 1/2, step 5751/7134 completed (loss: 0.07975725084543228, acc: 0.976893424987793)
[2024-12-17 02:16:25,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:25,992][root][INFO] - Training Epoch: 1/2, step 5752/7134 completed (loss: 0.1363966166973114, acc: 0.9651972055435181)
[2024-12-17 02:16:26,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:26,333][root][INFO] - Training Epoch: 1/2, step 5753/7134 completed (loss: 0.11490883678197861, acc: 0.973437488079071)
[2024-12-17 02:16:26,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:26,707][root][INFO] - Training Epoch: 1/2, step 5754/7134 completed (loss: 0.10395193845033646, acc: 0.9732484221458435)
[2024-12-17 02:16:26,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:27,043][root][INFO] - Training Epoch: 1/2, step 5755/7134 completed (loss: 0.06850872933864594, acc: 0.980966329574585)
[2024-12-17 02:16:27,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:27,367][root][INFO] - Training Epoch: 1/2, step 5756/7134 completed (loss: 0.07602312415838242, acc: 0.978723406791687)
[2024-12-17 02:16:27,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:27,714][root][INFO] - Training Epoch: 1/2, step 5757/7134 completed (loss: 0.06420540064573288, acc: 0.9782886505126953)
[2024-12-17 02:16:27,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:28,020][root][INFO] - Training Epoch: 1/2, step 5758/7134 completed (loss: 0.07011385262012482, acc: 0.9808823466300964)
[2024-12-17 02:16:28,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:28,311][root][INFO] - Training Epoch: 1/2, step 5759/7134 completed (loss: 0.11133097112178802, acc: 0.9703503847122192)
[2024-12-17 02:16:28,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:28,666][root][INFO] - Training Epoch: 1/2, step 5760/7134 completed (loss: 0.06138712167739868, acc: 0.9847328066825867)
[2024-12-17 02:16:28,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:29,023][root][INFO] - Training Epoch: 1/2, step 5761/7134 completed (loss: 0.07794655114412308, acc: 0.9835164546966553)
[2024-12-17 02:16:29,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:29,357][root][INFO] - Training Epoch: 1/2, step 5762/7134 completed (loss: 0.09906578063964844, acc: 0.9762773513793945)
[2024-12-17 02:16:29,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:29,717][root][INFO] - Training Epoch: 1/2, step 5763/7134 completed (loss: 0.07356498390436172, acc: 0.9836888313293457)
[2024-12-17 02:16:29,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:30,024][root][INFO] - Training Epoch: 1/2, step 5764/7134 completed (loss: 0.053592436015605927, acc: 0.988034188747406)
[2024-12-17 02:16:30,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:30,360][root][INFO] - Training Epoch: 1/2, step 5765/7134 completed (loss: 0.04657960683107376, acc: 0.9901960492134094)
[2024-12-17 02:16:30,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:30,690][root][INFO] - Training Epoch: 1/2, step 5766/7134 completed (loss: 0.04717038944363594, acc: 0.9910314083099365)
[2024-12-17 02:16:30,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:31,012][root][INFO] - Training Epoch: 1/2, step 5767/7134 completed (loss: 0.02806260623037815, acc: 0.9930459260940552)
[2024-12-17 02:16:31,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:31,353][root][INFO] - Training Epoch: 1/2, step 5768/7134 completed (loss: 0.039698276668787, acc: 0.9865269660949707)
[2024-12-17 02:16:31,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:31,706][root][INFO] - Training Epoch: 1/2, step 5769/7134 completed (loss: 0.036593422293663025, acc: 0.9885433912277222)
[2024-12-17 02:16:31,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:32,072][root][INFO] - Training Epoch: 1/2, step 5770/7134 completed (loss: 0.09093032032251358, acc: 0.977968156337738)
[2024-12-17 02:16:32,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:32,404][root][INFO] - Training Epoch: 1/2, step 5771/7134 completed (loss: 0.08143771439790726, acc: 0.9823369383811951)
[2024-12-17 02:16:32,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:32,750][root][INFO] - Training Epoch: 1/2, step 5772/7134 completed (loss: 0.03372969105839729, acc: 0.9930434823036194)
[2024-12-17 02:16:32,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:33,101][root][INFO] - Training Epoch: 1/2, step 5773/7134 completed (loss: 0.03918767720460892, acc: 0.9933110475540161)
[2024-12-17 02:16:33,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:33,434][root][INFO] - Training Epoch: 1/2, step 5774/7134 completed (loss: 0.056032028049230576, acc: 0.9792284965515137)
[2024-12-17 02:16:33,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:33,760][root][INFO] - Training Epoch: 1/2, step 5775/7134 completed (loss: 0.041852518916130066, acc: 0.9851729869842529)
[2024-12-17 02:16:33,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:34,098][root][INFO] - Training Epoch: 1/2, step 5776/7134 completed (loss: 0.09363922476768494, acc: 0.9705055952072144)
[2024-12-17 02:16:34,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:34,450][root][INFO] - Training Epoch: 1/2, step 5777/7134 completed (loss: 0.12541139125823975, acc: 0.9653465151786804)
[2024-12-17 02:16:34,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:34,801][root][INFO] - Training Epoch: 1/2, step 5778/7134 completed (loss: 0.17076729238033295, acc: 0.9599359035491943)
[2024-12-17 02:16:34,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:35,149][root][INFO] - Training Epoch: 1/2, step 5779/7134 completed (loss: 0.0792967826128006, acc: 0.9793672561645508)
[2024-12-17 02:16:35,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:35,517][root][INFO] - Training Epoch: 1/2, step 5780/7134 completed (loss: 0.055524636059999466, acc: 0.9856801629066467)
[2024-12-17 02:16:35,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:35,862][root][INFO] - Training Epoch: 1/2, step 5781/7134 completed (loss: 0.08244549483060837, acc: 0.9792817831039429)
[2024-12-17 02:16:35,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:36,217][root][INFO] - Training Epoch: 1/2, step 5782/7134 completed (loss: 0.047734275460243225, acc: 0.9857512712478638)
[2024-12-17 02:16:36,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:36,567][root][INFO] - Training Epoch: 1/2, step 5783/7134 completed (loss: 0.05747014284133911, acc: 0.9814077019691467)
[2024-12-17 02:16:36,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:36,898][root][INFO] - Training Epoch: 1/2, step 5784/7134 completed (loss: 0.06350760161876678, acc: 0.9865410327911377)
[2024-12-17 02:16:37,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:37,231][root][INFO] - Training Epoch: 1/2, step 5785/7134 completed (loss: 0.09685104340314865, acc: 0.9757412672042847)
[2024-12-17 02:16:37,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:37,548][root][INFO] - Training Epoch: 1/2, step 5786/7134 completed (loss: 0.08084841072559357, acc: 0.9795082211494446)
[2024-12-17 02:16:37,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:37,898][root][INFO] - Training Epoch: 1/2, step 5787/7134 completed (loss: 0.06436430662870407, acc: 0.9788557291030884)
[2024-12-17 02:16:38,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:38,212][root][INFO] - Training Epoch: 1/2, step 5788/7134 completed (loss: 0.03898351639509201, acc: 0.9861538410186768)
[2024-12-17 02:16:38,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:38,560][root][INFO] - Training Epoch: 1/2, step 5789/7134 completed (loss: 0.09694015979766846, acc: 0.9751861095428467)
[2024-12-17 02:16:38,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:38,901][root][INFO] - Training Epoch: 1/2, step 5790/7134 completed (loss: 0.06195404753088951, acc: 0.9766483306884766)
[2024-12-17 02:16:39,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:39,238][root][INFO] - Training Epoch: 1/2, step 5791/7134 completed (loss: 0.09200095385313034, acc: 0.9742268323898315)
[2024-12-17 02:16:39,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:39,579][root][INFO] - Training Epoch: 1/2, step 5792/7134 completed (loss: 0.09797749668359756, acc: 0.971137523651123)
[2024-12-17 02:16:39,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:39,912][root][INFO] - Training Epoch: 1/2, step 5793/7134 completed (loss: 0.10569706559181213, acc: 0.9764150977134705)
[2024-12-17 02:16:40,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:40,239][root][INFO] - Training Epoch: 1/2, step 5794/7134 completed (loss: 0.08004362136125565, acc: 0.9757575988769531)
[2024-12-17 02:16:40,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:40,571][root][INFO] - Training Epoch: 1/2, step 5795/7134 completed (loss: 0.15050756931304932, acc: 0.9642857313156128)
[2024-12-17 02:16:40,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:40,902][root][INFO] - Training Epoch: 1/2, step 5796/7134 completed (loss: 0.08315582573413849, acc: 0.9746192693710327)
[2024-12-17 02:16:41,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:41,227][root][INFO] - Training Epoch: 1/2, step 5797/7134 completed (loss: 0.05271126702427864, acc: 0.9807999730110168)
[2024-12-17 02:16:41,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:41,551][root][INFO] - Training Epoch: 1/2, step 5798/7134 completed (loss: 0.2031746357679367, acc: 0.9460869431495667)
[2024-12-17 02:16:41,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:41,872][root][INFO] - Training Epoch: 1/2, step 5799/7134 completed (loss: 0.11011365056037903, acc: 0.9684418439865112)
[2024-12-17 02:16:42,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:42,203][root][INFO] - Training Epoch: 1/2, step 5800/7134 completed (loss: 0.12094486504793167, acc: 0.96875)
[2024-12-17 02:16:42,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:42,544][root][INFO] - Training Epoch: 1/2, step 5801/7134 completed (loss: 0.09890785813331604, acc: 0.9679877758026123)
[2024-12-17 02:16:42,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:42,876][root][INFO] - Training Epoch: 1/2, step 5802/7134 completed (loss: 0.0723695158958435, acc: 0.975970447063446)
[2024-12-17 02:16:42,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:43,234][root][INFO] - Training Epoch: 1/2, step 5803/7134 completed (loss: 0.05878851190209389, acc: 0.9846938848495483)
[2024-12-17 02:16:43,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:43,569][root][INFO] - Training Epoch: 1/2, step 5804/7134 completed (loss: 0.11090446263551712, acc: 0.968876838684082)
[2024-12-17 02:16:43,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:43,902][root][INFO] - Training Epoch: 1/2, step 5805/7134 completed (loss: 0.07933744788169861, acc: 0.9798561334609985)
[2024-12-17 02:16:44,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:44,246][root][INFO] - Training Epoch: 1/2, step 5806/7134 completed (loss: 0.0818551629781723, acc: 0.9795082211494446)
[2024-12-17 02:16:44,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:44,582][root][INFO] - Training Epoch: 1/2, step 5807/7134 completed (loss: 0.11380089074373245, acc: 0.9727685451507568)
[2024-12-17 02:16:44,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:44,944][root][INFO] - Training Epoch: 1/2, step 5808/7134 completed (loss: 0.04127993807196617, acc: 0.9859353303909302)
[2024-12-17 02:16:45,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:45,264][root][INFO] - Training Epoch: 1/2, step 5809/7134 completed (loss: 0.09016551822423935, acc: 0.9780701994895935)
[2024-12-17 02:16:45,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:45,616][root][INFO] - Training Epoch: 1/2, step 5810/7134 completed (loss: 0.05426029488444328, acc: 0.9797160029411316)
[2024-12-17 02:16:45,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:45,886][root][INFO] - Training Epoch: 1/2, step 5811/7134 completed (loss: 0.08771376311779022, acc: 0.9710843563079834)
[2024-12-17 02:16:45,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:46,203][root][INFO] - Training Epoch: 1/2, step 5812/7134 completed (loss: 0.021533703431487083, acc: 0.9966996908187866)
[2024-12-17 02:16:46,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:46,520][root][INFO] - Training Epoch: 1/2, step 5813/7134 completed (loss: 0.038619622588157654, acc: 0.9886792302131653)
[2024-12-17 02:16:46,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:46,907][root][INFO] - Training Epoch: 1/2, step 5814/7134 completed (loss: 0.04942851886153221, acc: 0.9813874959945679)
[2024-12-17 02:16:47,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:47,238][root][INFO] - Training Epoch: 1/2, step 5815/7134 completed (loss: 0.0582021027803421, acc: 0.9849340915679932)
[2024-12-17 02:16:47,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:47,589][root][INFO] - Training Epoch: 1/2, step 5816/7134 completed (loss: 0.015168266370892525, acc: 0.9975062608718872)
[2024-12-17 02:16:47,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:47,914][root][INFO] - Training Epoch: 1/2, step 5817/7134 completed (loss: 0.0752883329987526, acc: 0.989924430847168)
[2024-12-17 02:16:48,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:48,245][root][INFO] - Training Epoch: 1/2, step 5818/7134 completed (loss: 0.06411702930927277, acc: 0.9851852059364319)
[2024-12-17 02:16:48,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:48,563][root][INFO] - Training Epoch: 1/2, step 5819/7134 completed (loss: 0.050442006438970566, acc: 0.9896551966667175)
[2024-12-17 02:16:48,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:48,886][root][INFO] - Training Epoch: 1/2, step 5820/7134 completed (loss: 0.07813481241464615, acc: 0.9814049601554871)
[2024-12-17 02:16:49,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:49,203][root][INFO] - Training Epoch: 1/2, step 5821/7134 completed (loss: 0.028985431417822838, acc: 0.9892141819000244)
[2024-12-17 02:16:49,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:49,529][root][INFO] - Training Epoch: 1/2, step 5822/7134 completed (loss: 0.0449519120156765, acc: 0.9854838848114014)
[2024-12-17 02:16:49,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:49,839][root][INFO] - Training Epoch: 1/2, step 5823/7134 completed (loss: 0.03918105736374855, acc: 0.9906687140464783)
[2024-12-17 02:16:49,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:50,197][root][INFO] - Training Epoch: 1/2, step 5824/7134 completed (loss: 0.0458604134619236, acc: 0.9906687140464783)
[2024-12-17 02:16:50,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:50,549][root][INFO] - Training Epoch: 1/2, step 5825/7134 completed (loss: 0.052141450345516205, acc: 0.9861591458320618)
[2024-12-17 02:16:50,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:50,880][root][INFO] - Training Epoch: 1/2, step 5826/7134 completed (loss: 0.0321788489818573, acc: 0.9929078221321106)
[2024-12-17 02:16:51,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:51,201][root][INFO] - Training Epoch: 1/2, step 5827/7134 completed (loss: 0.040510307997465134, acc: 0.9846153855323792)
[2024-12-17 02:16:51,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:51,530][root][INFO] - Training Epoch: 1/2, step 5828/7134 completed (loss: 0.058143649250268936, acc: 0.97919762134552)
[2024-12-17 02:16:51,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:51,868][root][INFO] - Training Epoch: 1/2, step 5829/7134 completed (loss: 0.047776881605386734, acc: 0.9868247509002686)
[2024-12-17 02:16:51,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:52,173][root][INFO] - Training Epoch: 1/2, step 5830/7134 completed (loss: 0.056727346032857895, acc: 0.9735350012779236)
[2024-12-17 02:16:52,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:52,487][root][INFO] - Training Epoch: 1/2, step 5831/7134 completed (loss: 0.02966492436826229, acc: 0.9906976819038391)
[2024-12-17 02:16:52,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:52,822][root][INFO] - Training Epoch: 1/2, step 5832/7134 completed (loss: 0.06663646548986435, acc: 0.9847972989082336)
[2024-12-17 02:16:52,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:53,132][root][INFO] - Training Epoch: 1/2, step 5833/7134 completed (loss: 0.05353640019893646, acc: 0.9856630563735962)
[2024-12-17 02:16:53,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:53,464][root][INFO] - Training Epoch: 1/2, step 5834/7134 completed (loss: 0.05087098106741905, acc: 0.9902777671813965)
[2024-12-17 02:16:53,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:53,796][root][INFO] - Training Epoch: 1/2, step 5835/7134 completed (loss: 0.023510204628109932, acc: 0.9971098303794861)
[2024-12-17 02:16:53,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:54,132][root][INFO] - Training Epoch: 1/2, step 5836/7134 completed (loss: 0.06653767824172974, acc: 0.9812679886817932)
[2024-12-17 02:16:54,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:54,456][root][INFO] - Training Epoch: 1/2, step 5837/7134 completed (loss: 0.07919323444366455, acc: 0.9864864945411682)
[2024-12-17 02:16:54,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:54,789][root][INFO] - Training Epoch: 1/2, step 5838/7134 completed (loss: 0.04923528432846069, acc: 0.9901153445243835)
[2024-12-17 02:16:54,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:55,114][root][INFO] - Training Epoch: 1/2, step 5839/7134 completed (loss: 0.045104313641786575, acc: 0.9892857074737549)
[2024-12-17 02:16:55,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:55,444][root][INFO] - Training Epoch: 1/2, step 5840/7134 completed (loss: 0.024465195834636688, acc: 0.995230495929718)
[2024-12-17 02:16:55,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:55,780][root][INFO] - Training Epoch: 1/2, step 5841/7134 completed (loss: 0.05910295993089676, acc: 0.9760765433311462)
[2024-12-17 02:16:55,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:56,100][root][INFO] - Training Epoch: 1/2, step 5842/7134 completed (loss: 0.051180560141801834, acc: 0.9855072498321533)
[2024-12-17 02:16:56,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:56,448][root][INFO] - Training Epoch: 1/2, step 5843/7134 completed (loss: 0.07346460968255997, acc: 0.9772422909736633)
[2024-12-17 02:16:56,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:56,784][root][INFO] - Training Epoch: 1/2, step 5844/7134 completed (loss: 0.03837034851312637, acc: 0.991465151309967)
[2024-12-17 02:16:56,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:57,118][root][INFO] - Training Epoch: 1/2, step 5845/7134 completed (loss: 0.06178523972630501, acc: 0.9857549667358398)
[2024-12-17 02:16:57,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:57,461][root][INFO] - Training Epoch: 1/2, step 5846/7134 completed (loss: 0.0896788239479065, acc: 0.9849520921707153)
[2024-12-17 02:16:57,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:57,804][root][INFO] - Training Epoch: 1/2, step 5847/7134 completed (loss: 0.03870180994272232, acc: 0.9931318759918213)
[2024-12-17 02:16:57,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:58,125][root][INFO] - Training Epoch: 1/2, step 5848/7134 completed (loss: 0.05848574638366699, acc: 0.980654776096344)
[2024-12-17 02:16:58,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:58,442][root][INFO] - Training Epoch: 1/2, step 5849/7134 completed (loss: 0.0693497583270073, acc: 0.9793510437011719)
[2024-12-17 02:16:58,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:58,766][root][INFO] - Training Epoch: 1/2, step 5850/7134 completed (loss: 0.04073287919163704, acc: 0.9877862334251404)
[2024-12-17 02:16:58,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:59,077][root][INFO] - Training Epoch: 1/2, step 5851/7134 completed (loss: 0.06645075976848602, acc: 0.9802631735801697)
[2024-12-17 02:16:59,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:59,403][root][INFO] - Training Epoch: 1/2, step 5852/7134 completed (loss: 0.03598597273230553, acc: 0.985401451587677)
[2024-12-17 02:16:59,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:59,739][root][INFO] - Training Epoch: 1/2, step 5853/7134 completed (loss: 0.0763099268078804, acc: 0.9783491492271423)
[2024-12-17 02:16:59,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:00,058][root][INFO] - Training Epoch: 1/2, step 5854/7134 completed (loss: 0.0648491308093071, acc: 0.9787610769271851)
[2024-12-17 02:17:00,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:00,367][root][INFO] - Training Epoch: 1/2, step 5855/7134 completed (loss: 0.06281837821006775, acc: 0.9879102110862732)
[2024-12-17 02:17:00,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:00,701][root][INFO] - Training Epoch: 1/2, step 5856/7134 completed (loss: 0.10379605740308762, acc: 0.9773414134979248)
[2024-12-17 02:17:00,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:01,062][root][INFO] - Training Epoch: 1/2, step 5857/7134 completed (loss: 0.047890424728393555, acc: 0.9873617887496948)
[2024-12-17 02:17:01,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:01,370][root][INFO] - Training Epoch: 1/2, step 5858/7134 completed (loss: 0.04592905566096306, acc: 0.9852125644683838)
[2024-12-17 02:17:01,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:01,699][root][INFO] - Training Epoch: 1/2, step 5859/7134 completed (loss: 0.06940419226884842, acc: 0.98046875)
[2024-12-17 02:17:01,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:02,017][root][INFO] - Training Epoch: 1/2, step 5860/7134 completed (loss: 0.08625797182321548, acc: 0.9752066135406494)
[2024-12-17 02:17:02,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:02,326][root][INFO] - Training Epoch: 1/2, step 5861/7134 completed (loss: 0.05568404495716095, acc: 0.9797160029411316)
[2024-12-17 02:17:02,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:02,659][root][INFO] - Training Epoch: 1/2, step 5862/7134 completed (loss: 0.06417729705572128, acc: 0.9828326106071472)
[2024-12-17 02:17:02,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:02,924][root][INFO] - Training Epoch: 1/2, step 5863/7134 completed (loss: 0.07378126680850983, acc: 0.9823232293128967)
[2024-12-17 02:17:03,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:03,256][root][INFO] - Training Epoch: 1/2, step 5864/7134 completed (loss: 0.08117395639419556, acc: 0.985029935836792)
[2024-12-17 02:17:03,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:03,577][root][INFO] - Training Epoch: 1/2, step 5865/7134 completed (loss: 0.08873300999403, acc: 0.9793650507926941)
[2024-12-17 02:17:03,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:03,938][root][INFO] - Training Epoch: 1/2, step 5866/7134 completed (loss: 0.06143023073673248, acc: 0.9867724776268005)
[2024-12-17 02:17:04,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:04,267][root][INFO] - Training Epoch: 1/2, step 5867/7134 completed (loss: 0.05596782639622688, acc: 0.9818181991577148)
[2024-12-17 02:17:04,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:04,613][root][INFO] - Training Epoch: 1/2, step 5868/7134 completed (loss: 0.07492978870868683, acc: 0.9741379022598267)
[2024-12-17 02:17:04,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:04,937][root][INFO] - Training Epoch: 1/2, step 5869/7134 completed (loss: 0.1391008347272873, acc: 0.9776119589805603)
[2024-12-17 02:17:05,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:05,264][root][INFO] - Training Epoch: 1/2, step 5870/7134 completed (loss: 0.09100314229726791, acc: 0.9728033542633057)
[2024-12-17 02:17:05,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:05,578][root][INFO] - Training Epoch: 1/2, step 5871/7134 completed (loss: 0.032569777220487595, acc: 0.9893842935562134)
[2024-12-17 02:17:05,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:05,901][root][INFO] - Training Epoch: 1/2, step 5872/7134 completed (loss: 0.09935924410820007, acc: 0.9756468534469604)
[2024-12-17 02:17:06,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:06,294][root][INFO] - Training Epoch: 1/2, step 5873/7134 completed (loss: 0.1198238730430603, acc: 0.9679999947547913)
[2024-12-17 02:17:06,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:06,570][root][INFO] - Training Epoch: 1/2, step 5874/7134 completed (loss: 0.03809937834739685, acc: 0.9859437942504883)
[2024-12-17 02:17:06,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:06,858][root][INFO] - Training Epoch: 1/2, step 5875/7134 completed (loss: 0.0713682696223259, acc: 0.9769911766052246)
[2024-12-17 02:17:06,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:07,200][root][INFO] - Training Epoch: 1/2, step 5876/7134 completed (loss: 0.03656848147511482, acc: 0.9902912378311157)
[2024-12-17 02:17:07,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:07,527][root][INFO] - Training Epoch: 1/2, step 5877/7134 completed (loss: 0.07356929033994675, acc: 0.9809644818305969)
[2024-12-17 02:17:07,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:07,863][root][INFO] - Training Epoch: 1/2, step 5878/7134 completed (loss: 0.06519699841737747, acc: 0.9824561476707458)
[2024-12-17 02:17:07,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:08,176][root][INFO] - Training Epoch: 1/2, step 5879/7134 completed (loss: 0.06101498007774353, acc: 0.9796954393386841)
[2024-12-17 02:17:08,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:08,441][root][INFO] - Training Epoch: 1/2, step 5880/7134 completed (loss: 0.04507490247488022, acc: 0.9866666793823242)
[2024-12-17 02:17:08,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:08,765][root][INFO] - Training Epoch: 1/2, step 5881/7134 completed (loss: 0.04301944747567177, acc: 0.984644889831543)
[2024-12-17 02:17:08,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:09,031][root][INFO] - Training Epoch: 1/2, step 5882/7134 completed (loss: 0.05551066994667053, acc: 0.9858823418617249)
[2024-12-17 02:17:09,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:09,301][root][INFO] - Training Epoch: 1/2, step 5883/7134 completed (loss: 0.08525411784648895, acc: 0.983146071434021)
[2024-12-17 02:17:09,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:09,628][root][INFO] - Training Epoch: 1/2, step 5884/7134 completed (loss: 0.1369732767343521, acc: 0.9689781069755554)
[2024-12-17 02:17:09,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:09,948][root][INFO] - Training Epoch: 1/2, step 5885/7134 completed (loss: 0.18888017535209656, acc: 0.95923912525177)
[2024-12-17 02:17:10,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:10,249][root][INFO] - Training Epoch: 1/2, step 5886/7134 completed (loss: 0.07253295183181763, acc: 0.9800000190734863)
[2024-12-17 02:17:10,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:10,589][root][INFO] - Training Epoch: 1/2, step 5887/7134 completed (loss: 0.08978457003831863, acc: 0.9766454100608826)
[2024-12-17 02:17:10,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:10,919][root][INFO] - Training Epoch: 1/2, step 5888/7134 completed (loss: 0.092972032725811, acc: 0.9780405163764954)
[2024-12-17 02:17:11,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:11,193][root][INFO] - Training Epoch: 1/2, step 5889/7134 completed (loss: 0.06004047021269798, acc: 0.9866071343421936)
[2024-12-17 02:17:11,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:11,546][root][INFO] - Training Epoch: 1/2, step 5890/7134 completed (loss: 0.0573471374809742, acc: 0.9807692170143127)
[2024-12-17 02:17:11,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:11,879][root][INFO] - Training Epoch: 1/2, step 5891/7134 completed (loss: 0.09176640957593918, acc: 0.9815837740898132)
[2024-12-17 02:17:11,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:12,236][root][INFO] - Training Epoch: 1/2, step 5892/7134 completed (loss: 0.10523517429828644, acc: 0.9737609624862671)
[2024-12-17 02:17:12,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:12,567][root][INFO] - Training Epoch: 1/2, step 5893/7134 completed (loss: 0.07951430231332779, acc: 0.9795275330543518)
[2024-12-17 02:17:12,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:12,856][root][INFO] - Training Epoch: 1/2, step 5894/7134 completed (loss: 0.053699467331171036, acc: 0.9868852496147156)
[2024-12-17 02:17:12,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:13,171][root][INFO] - Training Epoch: 1/2, step 5895/7134 completed (loss: 0.01995069347321987, acc: 1.0)
[2024-12-17 02:17:13,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:13,501][root][INFO] - Training Epoch: 1/2, step 5896/7134 completed (loss: 0.08284712582826614, acc: 0.9829931855201721)
[2024-12-17 02:17:13,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:13,854][root][INFO] - Training Epoch: 1/2, step 5897/7134 completed (loss: 0.05359209328889847, acc: 0.9848484992980957)
[2024-12-17 02:17:13,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:14,182][root][INFO] - Training Epoch: 1/2, step 5898/7134 completed (loss: 0.09981963038444519, acc: 0.9762930870056152)
[2024-12-17 02:17:14,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:14,465][root][INFO] - Training Epoch: 1/2, step 5899/7134 completed (loss: 0.04775894433259964, acc: 0.976190447807312)
[2024-12-17 02:17:14,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:14,763][root][INFO] - Training Epoch: 1/2, step 5900/7134 completed (loss: 0.0489804670214653, acc: 0.988095223903656)
[2024-12-17 02:17:14,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:15,055][root][INFO] - Training Epoch: 1/2, step 5901/7134 completed (loss: 0.10458272695541382, acc: 0.9725000262260437)
[2024-12-17 02:17:15,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:15,407][root][INFO] - Training Epoch: 1/2, step 5902/7134 completed (loss: 0.13055656850337982, acc: 0.9664948582649231)
[2024-12-17 02:17:15,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:15,745][root][INFO] - Training Epoch: 1/2, step 5903/7134 completed (loss: 0.07529372721910477, acc: 0.9817517995834351)
[2024-12-17 02:17:15,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:16,101][root][INFO] - Training Epoch: 1/2, step 5904/7134 completed (loss: 0.08663733303546906, acc: 0.9754098653793335)
[2024-12-17 02:17:16,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:16,414][root][INFO] - Training Epoch: 1/2, step 5905/7134 completed (loss: 0.08641822636127472, acc: 0.9791377186775208)
[2024-12-17 02:17:16,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:16,771][root][INFO] - Training Epoch: 1/2, step 5906/7134 completed (loss: 0.0985502302646637, acc: 0.9717444777488708)
[2024-12-17 02:17:16,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:17,148][root][INFO] - Training Epoch: 1/2, step 5907/7134 completed (loss: 0.10495053976774216, acc: 0.9689521193504333)
[2024-12-17 02:17:17,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:17,525][root][INFO] - Training Epoch: 1/2, step 5908/7134 completed (loss: 0.05618210509419441, acc: 0.9795396327972412)
[2024-12-17 02:17:17,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:17,999][root][INFO] - Training Epoch: 1/2, step 5909/7134 completed (loss: 0.06392884254455566, acc: 0.9855907559394836)
[2024-12-17 02:17:18,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:18,387][root][INFO] - Training Epoch: 1/2, step 5910/7134 completed (loss: 0.09121067821979523, acc: 0.9708737730979919)
[2024-12-17 02:17:18,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:18,721][root][INFO] - Training Epoch: 1/2, step 5911/7134 completed (loss: 0.08296641707420349, acc: 0.9818181991577148)
[2024-12-17 02:17:18,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:19,042][root][INFO] - Training Epoch: 1/2, step 5912/7134 completed (loss: 0.06424829363822937, acc: 0.9774965047836304)
[2024-12-17 02:17:19,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:19,407][root][INFO] - Training Epoch: 1/2, step 5913/7134 completed (loss: 0.14696118235588074, acc: 0.96875)
[2024-12-17 02:17:19,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:19,731][root][INFO] - Training Epoch: 1/2, step 5914/7134 completed (loss: 0.07181505858898163, acc: 0.9839486479759216)
[2024-12-17 02:17:19,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:20,096][root][INFO] - Training Epoch: 1/2, step 5915/7134 completed (loss: 0.11472588777542114, acc: 0.9751937985420227)
[2024-12-17 02:17:20,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:20,460][root][INFO] - Training Epoch: 1/2, step 5916/7134 completed (loss: 0.049560680985450745, acc: 0.9908257126808167)
[2024-12-17 02:17:20,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:20,762][root][INFO] - Training Epoch: 1/2, step 5917/7134 completed (loss: 0.0718466266989708, acc: 0.9792027473449707)
[2024-12-17 02:17:20,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:21,122][root][INFO] - Training Epoch: 1/2, step 5918/7134 completed (loss: 0.15760201215744019, acc: 0.9680696725845337)
[2024-12-17 02:17:21,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:21,453][root][INFO] - Training Epoch: 1/2, step 5919/7134 completed (loss: 0.05753509700298309, acc: 0.9817629456520081)
[2024-12-17 02:17:21,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:21,775][root][INFO] - Training Epoch: 1/2, step 5920/7134 completed (loss: 0.0839945524930954, acc: 0.9750415682792664)
[2024-12-17 02:17:21,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:22,101][root][INFO] - Training Epoch: 1/2, step 5921/7134 completed (loss: 0.10280685126781464, acc: 0.9749478101730347)
[2024-12-17 02:17:22,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:22,441][root][INFO] - Training Epoch: 1/2, step 5922/7134 completed (loss: 0.28785353899002075, acc: 0.9397163391113281)
[2024-12-17 02:17:22,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:22,799][root][INFO] - Training Epoch: 1/2, step 5923/7134 completed (loss: 0.16169482469558716, acc: 0.9590044021606445)
[2024-12-17 02:17:22,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:23,123][root][INFO] - Training Epoch: 1/2, step 5924/7134 completed (loss: 0.10436589270830154, acc: 0.9713603854179382)
[2024-12-17 02:17:23,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:23,389][root][INFO] - Training Epoch: 1/2, step 5925/7134 completed (loss: 0.27008482813835144, acc: 0.9354838728904724)
[2024-12-17 02:17:23,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:23,711][root][INFO] - Training Epoch: 1/2, step 5926/7134 completed (loss: 0.15146717429161072, acc: 0.9649999737739563)
[2024-12-17 02:17:23,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:24,030][root][INFO] - Training Epoch: 1/2, step 5927/7134 completed (loss: 0.13423362374305725, acc: 0.9710467457771301)
[2024-12-17 02:17:24,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:24,303][root][INFO] - Training Epoch: 1/2, step 5928/7134 completed (loss: 0.2992114722728729, acc: 0.931506872177124)
[2024-12-17 02:17:24,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:24,644][root][INFO] - Training Epoch: 1/2, step 5929/7134 completed (loss: 0.09371989220380783, acc: 0.9738805890083313)
[2024-12-17 02:17:24,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:24,944][root][INFO] - Training Epoch: 1/2, step 5930/7134 completed (loss: 0.15662981569766998, acc: 0.9665924310684204)
[2024-12-17 02:17:25,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:25,269][root][INFO] - Training Epoch: 1/2, step 5931/7134 completed (loss: 0.09882411360740662, acc: 0.9676026105880737)
[2024-12-17 02:17:25,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:25,591][root][INFO] - Training Epoch: 1/2, step 5932/7134 completed (loss: 0.12875746190547943, acc: 0.9629629850387573)
[2024-12-17 02:17:25,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:25,868][root][INFO] - Training Epoch: 1/2, step 5933/7134 completed (loss: 0.180426687002182, acc: 0.9580712914466858)
[2024-12-17 02:17:26,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:26,196][root][INFO] - Training Epoch: 1/2, step 5934/7134 completed (loss: 0.07909868657588959, acc: 0.9786856174468994)
[2024-12-17 02:17:26,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:26,524][root][INFO] - Training Epoch: 1/2, step 5935/7134 completed (loss: 0.05830717831850052, acc: 0.9864077568054199)
[2024-12-17 02:17:26,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:26,833][root][INFO] - Training Epoch: 1/2, step 5936/7134 completed (loss: 0.09316188097000122, acc: 0.9800918698310852)
[2024-12-17 02:17:26,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:27,164][root][INFO] - Training Epoch: 1/2, step 5937/7134 completed (loss: 0.03789505735039711, acc: 0.9920254945755005)
[2024-12-17 02:17:27,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:27,481][root][INFO] - Training Epoch: 1/2, step 5938/7134 completed (loss: 0.13974469900131226, acc: 0.961759090423584)
[2024-12-17 02:17:27,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:27,767][root][INFO] - Training Epoch: 1/2, step 5939/7134 completed (loss: 0.22134320437908173, acc: 0.9343891143798828)
[2024-12-17 02:17:27,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:28,132][root][INFO] - Training Epoch: 1/2, step 5940/7134 completed (loss: 0.118778295814991, acc: 0.9693877696990967)
[2024-12-17 02:17:28,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:28,418][root][INFO] - Training Epoch: 1/2, step 5941/7134 completed (loss: 0.10542415082454681, acc: 0.9781249761581421)
[2024-12-17 02:17:28,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:28,737][root][INFO] - Training Epoch: 1/2, step 5942/7134 completed (loss: 0.036028292030096054, acc: 0.990439772605896)
[2024-12-17 02:17:28,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:29,060][root][INFO] - Training Epoch: 1/2, step 5943/7134 completed (loss: 0.03839852288365364, acc: 0.9885550737380981)
[2024-12-17 02:17:29,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:29,419][root][INFO] - Training Epoch: 1/2, step 5944/7134 completed (loss: 0.08814186602830887, acc: 0.9685863852500916)
[2024-12-17 02:17:29,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:29,785][root][INFO] - Training Epoch: 1/2, step 5945/7134 completed (loss: 0.09101944416761398, acc: 0.9714714884757996)
[2024-12-17 02:17:29,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:30,104][root][INFO] - Training Epoch: 1/2, step 5946/7134 completed (loss: 0.07181879132986069, acc: 0.97826087474823)
[2024-12-17 02:17:30,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:30,452][root][INFO] - Training Epoch: 1/2, step 5947/7134 completed (loss: 0.06576041132211685, acc: 0.9801734685897827)
[2024-12-17 02:17:30,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:30,785][root][INFO] - Training Epoch: 1/2, step 5948/7134 completed (loss: 0.1183716207742691, acc: 0.9620000123977661)
[2024-12-17 02:17:30,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:31,131][root][INFO] - Training Epoch: 1/2, step 5949/7134 completed (loss: 0.04711810499429703, acc: 0.9899623394012451)
[2024-12-17 02:17:31,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:31,456][root][INFO] - Training Epoch: 1/2, step 5950/7134 completed (loss: 0.2235783487558365, acc: 0.9453681707382202)
[2024-12-17 02:17:31,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:31,786][root][INFO] - Training Epoch: 1/2, step 5951/7134 completed (loss: 0.10576984286308289, acc: 0.9684361815452576)
[2024-12-17 02:17:31,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:32,147][root][INFO] - Training Epoch: 1/2, step 5952/7134 completed (loss: 0.20784354209899902, acc: 0.956250011920929)
[2024-12-17 02:17:32,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:32,481][root][INFO] - Training Epoch: 1/2, step 5953/7134 completed (loss: 0.1062052920460701, acc: 0.9752066135406494)
[2024-12-17 02:17:32,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:32,806][root][INFO] - Training Epoch: 1/2, step 5954/7134 completed (loss: 0.06333785504102707, acc: 0.9873096346855164)
[2024-12-17 02:17:32,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:33,066][root][INFO] - Training Epoch: 1/2, step 5955/7134 completed (loss: 0.05713547393679619, acc: 0.9904761910438538)
[2024-12-17 02:17:33,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:33,379][root][INFO] - Training Epoch: 1/2, step 5956/7134 completed (loss: 0.14261893928050995, acc: 0.95686274766922)
[2024-12-17 02:17:33,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:33,686][root][INFO] - Training Epoch: 1/2, step 5957/7134 completed (loss: 0.09869643300771713, acc: 0.9745127558708191)
[2024-12-17 02:17:33,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:34,025][root][INFO] - Training Epoch: 1/2, step 5958/7134 completed (loss: 0.05120398476719856, acc: 0.9798657894134521)
[2024-12-17 02:17:34,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:34,372][root][INFO] - Training Epoch: 1/2, step 5959/7134 completed (loss: 0.0915297120809555, acc: 0.979973316192627)
[2024-12-17 02:17:34,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:34,721][root][INFO] - Training Epoch: 1/2, step 5960/7134 completed (loss: 0.030591238290071487, acc: 0.9943820238113403)
[2024-12-17 02:17:34,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:35,009][root][INFO] - Training Epoch: 1/2, step 5961/7134 completed (loss: 0.10722777992486954, acc: 0.9733606576919556)
[2024-12-17 02:17:35,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:35,342][root][INFO] - Training Epoch: 1/2, step 5962/7134 completed (loss: 0.06891321390867233, acc: 0.9821138381958008)
[2024-12-17 02:17:35,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:35,675][root][INFO] - Training Epoch: 1/2, step 5963/7134 completed (loss: 0.06072559580206871, acc: 0.9860334992408752)
[2024-12-17 02:17:35,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:35,997][root][INFO] - Training Epoch: 1/2, step 5964/7134 completed (loss: 0.04716317355632782, acc: 0.9907578825950623)
[2024-12-17 02:17:36,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:36,337][root][INFO] - Training Epoch: 1/2, step 5965/7134 completed (loss: 0.0684034451842308, acc: 0.9910045266151428)
[2024-12-17 02:17:36,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:36,684][root][INFO] - Training Epoch: 1/2, step 5966/7134 completed (loss: 0.09970339387655258, acc: 0.9750346541404724)
[2024-12-17 02:17:36,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:37,031][root][INFO] - Training Epoch: 1/2, step 5967/7134 completed (loss: 0.08646205812692642, acc: 0.9776119589805603)
[2024-12-17 02:17:37,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:37,357][root][INFO] - Training Epoch: 1/2, step 5968/7134 completed (loss: 0.08919581025838852, acc: 0.9794520735740662)
[2024-12-17 02:17:37,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:37,679][root][INFO] - Training Epoch: 1/2, step 5969/7134 completed (loss: 0.08126223087310791, acc: 0.9891641139984131)
[2024-12-17 02:17:37,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:38,007][root][INFO] - Training Epoch: 1/2, step 5970/7134 completed (loss: 0.08021309226751328, acc: 0.9815573692321777)
[2024-12-17 02:17:38,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:38,352][root][INFO] - Training Epoch: 1/2, step 5971/7134 completed (loss: 0.03953849896788597, acc: 0.9874686598777771)
[2024-12-17 02:17:38,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:38,696][root][INFO] - Training Epoch: 1/2, step 5972/7134 completed (loss: 0.10021236538887024, acc: 0.9735682606697083)
[2024-12-17 02:17:38,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:39,070][root][INFO] - Training Epoch: 1/2, step 5973/7134 completed (loss: 0.11319688707590103, acc: 0.9683453440666199)
[2024-12-17 02:17:39,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:39,438][root][INFO] - Training Epoch: 1/2, step 5974/7134 completed (loss: 0.04523301497101784, acc: 0.9896013736724854)
[2024-12-17 02:17:39,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:39,767][root][INFO] - Training Epoch: 1/2, step 5975/7134 completed (loss: 0.034125760197639465, acc: 0.99262535572052)
[2024-12-17 02:17:39,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:40,130][root][INFO] - Training Epoch: 1/2, step 5976/7134 completed (loss: 0.07120166718959808, acc: 0.9800613522529602)
[2024-12-17 02:17:40,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:40,493][root][INFO] - Training Epoch: 1/2, step 5977/7134 completed (loss: 0.030803173780441284, acc: 0.9938042163848877)
[2024-12-17 02:17:40,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:40,837][root][INFO] - Training Epoch: 1/2, step 5978/7134 completed (loss: 0.06700880825519562, acc: 0.9871794581413269)
[2024-12-17 02:17:40,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:41,137][root][INFO] - Training Epoch: 1/2, step 5979/7134 completed (loss: 0.0742592066526413, acc: 0.9876543283462524)
[2024-12-17 02:17:41,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:41,485][root][INFO] - Training Epoch: 1/2, step 5980/7134 completed (loss: 0.04996400699019432, acc: 0.9871959090232849)
[2024-12-17 02:17:41,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:41,848][root][INFO] - Training Epoch: 1/2, step 5981/7134 completed (loss: 0.07267192006111145, acc: 0.981502890586853)
[2024-12-17 02:17:41,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:42,160][root][INFO] - Training Epoch: 1/2, step 5982/7134 completed (loss: 0.04701131582260132, acc: 0.9880715608596802)
[2024-12-17 02:17:42,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:42,498][root][INFO] - Training Epoch: 1/2, step 5983/7134 completed (loss: 0.08908168971538544, acc: 0.9750000238418579)
[2024-12-17 02:17:42,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:42,846][root][INFO] - Training Epoch: 1/2, step 5984/7134 completed (loss: 0.05078179016709328, acc: 0.9858155846595764)
[2024-12-17 02:17:42,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:43,204][root][INFO] - Training Epoch: 1/2, step 5985/7134 completed (loss: 0.042232807725667953, acc: 0.9887359142303467)
[2024-12-17 02:17:43,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:43,572][root][INFO] - Training Epoch: 1/2, step 5986/7134 completed (loss: 0.09025953710079193, acc: 0.9783439636230469)
[2024-12-17 02:17:43,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:43,930][root][INFO] - Training Epoch: 1/2, step 5987/7134 completed (loss: 0.09832461178302765, acc: 0.9755244851112366)
[2024-12-17 02:17:44,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:44,272][root][INFO] - Training Epoch: 1/2, step 5988/7134 completed (loss: 0.030125150457024574, acc: 0.9946666955947876)
[2024-12-17 02:17:44,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:44,627][root][INFO] - Training Epoch: 1/2, step 5989/7134 completed (loss: 0.09365857392549515, acc: 0.9778597950935364)
[2024-12-17 02:17:44,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:45,001][root][INFO] - Training Epoch: 1/2, step 5990/7134 completed (loss: 0.07981692999601364, acc: 0.9767123460769653)
[2024-12-17 02:17:45,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:45,255][root][INFO] - Training Epoch: 1/2, step 5991/7134 completed (loss: 0.13073144853115082, acc: 0.9776536226272583)
[2024-12-17 02:17:45,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:45,639][root][INFO] - Training Epoch: 1/2, step 5992/7134 completed (loss: 0.06727217137813568, acc: 0.9802555441856384)
[2024-12-17 02:17:45,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:45,975][root][INFO] - Training Epoch: 1/2, step 5993/7134 completed (loss: 0.05452660098671913, acc: 0.9875173568725586)
[2024-12-17 02:17:46,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:46,290][root][INFO] - Training Epoch: 1/2, step 5994/7134 completed (loss: 0.03335123509168625, acc: 0.9942965507507324)
[2024-12-17 02:17:46,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:46,649][root][INFO] - Training Epoch: 1/2, step 5995/7134 completed (loss: 0.055098798125982285, acc: 0.9873239398002625)
[2024-12-17 02:17:46,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:46,999][root][INFO] - Training Epoch: 1/2, step 5996/7134 completed (loss: 0.13332141935825348, acc: 0.9655712246894836)
[2024-12-17 02:17:47,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:47,341][root][INFO] - Training Epoch: 1/2, step 5997/7134 completed (loss: 0.052624717354774475, acc: 0.979973316192627)
[2024-12-17 02:17:47,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:47,686][root][INFO] - Training Epoch: 1/2, step 5998/7134 completed (loss: 0.05767921730875969, acc: 0.9862843155860901)
[2024-12-17 02:17:47,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:48,018][root][INFO] - Training Epoch: 1/2, step 5999/7134 completed (loss: 0.04290877282619476, acc: 0.9888476133346558)
[2024-12-17 02:17:48,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:48,335][root][INFO] - Training Epoch: 1/2, step 6000/7134 completed (loss: 0.07036815583705902, acc: 0.981697142124176)
[2024-12-17 02:17:48,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:48,693][root][INFO] - Training Epoch: 1/2, step 6001/7134 completed (loss: 0.035633932799100876, acc: 0.9897698163986206)
[2024-12-17 02:17:48,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:49,026][root][INFO] - Training Epoch: 1/2, step 6002/7134 completed (loss: 0.07678550481796265, acc: 0.9746588468551636)
[2024-12-17 02:17:49,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:49,421][root][INFO] - Training Epoch: 1/2, step 6003/7134 completed (loss: 0.04716350510716438, acc: 0.9838472604751587)
[2024-12-17 02:17:49,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:49,757][root][INFO] - Training Epoch: 1/2, step 6004/7134 completed (loss: 0.05384112522006035, acc: 0.9819193482398987)
[2024-12-17 02:17:49,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:50,077][root][INFO] - Training Epoch: 1/2, step 6005/7134 completed (loss: 0.059570323675870895, acc: 0.9847792983055115)
[2024-12-17 02:17:50,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:50,409][root][INFO] - Training Epoch: 1/2, step 6006/7134 completed (loss: 0.08145665377378464, acc: 0.9806576371192932)
[2024-12-17 02:17:50,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:50,772][root][INFO] - Training Epoch: 1/2, step 6007/7134 completed (loss: 0.03714759275317192, acc: 0.9933221936225891)
[2024-12-17 02:17:50,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:51,122][root][INFO] - Training Epoch: 1/2, step 6008/7134 completed (loss: 0.07250047475099564, acc: 0.9762611389160156)
[2024-12-17 02:17:51,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:51,447][root][INFO] - Training Epoch: 1/2, step 6009/7134 completed (loss: 0.08972189575433731, acc: 0.9751552939414978)
[2024-12-17 02:17:51,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:51,794][root][INFO] - Training Epoch: 1/2, step 6010/7134 completed (loss: 0.13774137198925018, acc: 0.9539295434951782)
[2024-12-17 02:17:51,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:52,159][root][INFO] - Training Epoch: 1/2, step 6011/7134 completed (loss: 0.10282564163208008, acc: 0.9727979302406311)
[2024-12-17 02:17:52,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:52,492][root][INFO] - Training Epoch: 1/2, step 6012/7134 completed (loss: 0.07046866416931152, acc: 0.9805970191955566)
[2024-12-17 02:17:52,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:52,826][root][INFO] - Training Epoch: 1/2, step 6013/7134 completed (loss: 0.07894007861614227, acc: 0.9826202988624573)
[2024-12-17 02:17:52,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:53,138][root][INFO] - Training Epoch: 1/2, step 6014/7134 completed (loss: 0.047613102942705154, acc: 0.9836660623550415)
[2024-12-17 02:17:53,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:53,487][root][INFO] - Training Epoch: 1/2, step 6015/7134 completed (loss: 0.09723541140556335, acc: 0.9710744023323059)
[2024-12-17 02:17:53,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:53,811][root][INFO] - Training Epoch: 1/2, step 6016/7134 completed (loss: 0.041047822684049606, acc: 0.9928315281867981)
[2024-12-17 02:17:53,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:54,079][root][INFO] - Training Epoch: 1/2, step 6017/7134 completed (loss: 0.06865904480218887, acc: 0.9900990128517151)
[2024-12-17 02:17:54,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:54,356][root][INFO] - Training Epoch: 1/2, step 6018/7134 completed (loss: 0.02572539821267128, acc: 0.9894737005233765)
[2024-12-17 02:17:54,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:54,594][root][INFO] - Training Epoch: 1/2, step 6019/7134 completed (loss: 0.09507685154676437, acc: 0.9655172228813171)
[2024-12-17 02:17:54,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:54,862][root][INFO] - Training Epoch: 1/2, step 6020/7134 completed (loss: 0.018139278516173363, acc: 0.9962406158447266)
[2024-12-17 02:17:54,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:55,086][root][INFO] - Training Epoch: 1/2, step 6021/7134 completed (loss: 0.06105467677116394, acc: 0.9869281053543091)
[2024-12-17 02:17:55,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:55,349][root][INFO] - Training Epoch: 1/2, step 6022/7134 completed (loss: 0.06692435592412949, acc: 0.9741697311401367)
[2024-12-17 02:17:55,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:55,622][root][INFO] - Training Epoch: 1/2, step 6023/7134 completed (loss: 0.05246467888355255, acc: 0.9864498376846313)
[2024-12-17 02:17:55,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:55,876][root][INFO] - Training Epoch: 1/2, step 6024/7134 completed (loss: 0.016176756471395493, acc: 0.9953488111495972)
[2024-12-17 02:17:55,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:56,189][root][INFO] - Training Epoch: 1/2, step 6025/7134 completed (loss: 0.02030695416033268, acc: 0.991631805896759)
[2024-12-17 02:17:56,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:56,455][root][INFO] - Training Epoch: 1/2, step 6026/7134 completed (loss: 0.0646539181470871, acc: 0.9828571677207947)
[2024-12-17 02:17:56,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:56,730][root][INFO] - Training Epoch: 1/2, step 6027/7134 completed (loss: 0.05625681206583977, acc: 0.9871465563774109)
[2024-12-17 02:17:56,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:56,988][root][INFO] - Training Epoch: 1/2, step 6028/7134 completed (loss: 0.035495445132255554, acc: 0.9822221994400024)
[2024-12-17 02:17:57,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:57,246][root][INFO] - Training Epoch: 1/2, step 6029/7134 completed (loss: 0.08369991183280945, acc: 0.9747292399406433)
[2024-12-17 02:17:57,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:57,495][root][INFO] - Training Epoch: 1/2, step 6030/7134 completed (loss: 0.128801167011261, acc: 0.9731800556182861)
[2024-12-17 02:17:57,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:57,818][root][INFO] - Training Epoch: 1/2, step 6031/7134 completed (loss: 0.06430741399526596, acc: 0.9824561476707458)
[2024-12-17 02:17:57,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:58,097][root][INFO] - Training Epoch: 1/2, step 6032/7134 completed (loss: 0.0454106442630291, acc: 0.9949367046356201)
[2024-12-17 02:17:58,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:58,383][root][INFO] - Training Epoch: 1/2, step 6033/7134 completed (loss: 0.12472155690193176, acc: 0.9754098653793335)
[2024-12-17 02:17:58,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:58,619][root][INFO] - Training Epoch: 1/2, step 6034/7134 completed (loss: 0.07841160148382187, acc: 0.9713114500045776)
[2024-12-17 02:17:58,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:58,995][root][INFO] - Training Epoch: 1/2, step 6035/7134 completed (loss: 0.13994663953781128, acc: 0.9590643048286438)
[2024-12-17 02:17:59,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:59,369][root][INFO] - Training Epoch: 1/2, step 6036/7134 completed (loss: 0.09437637776136398, acc: 0.9748252034187317)
[2024-12-17 02:17:59,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:59,713][root][INFO] - Training Epoch: 1/2, step 6037/7134 completed (loss: 0.07757210731506348, acc: 0.9745762944221497)
[2024-12-17 02:17:59,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:00,076][root][INFO] - Training Epoch: 1/2, step 6038/7134 completed (loss: 0.07523172348737717, acc: 0.9821029305458069)
[2024-12-17 02:18:00,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:00,438][root][INFO] - Training Epoch: 1/2, step 6039/7134 completed (loss: 0.06319279223680496, acc: 0.9810201525688171)
[2024-12-17 02:18:00,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:00,799][root][INFO] - Training Epoch: 1/2, step 6040/7134 completed (loss: 0.08601707220077515, acc: 0.9781704545021057)
[2024-12-17 02:18:00,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:01,119][root][INFO] - Training Epoch: 1/2, step 6041/7134 completed (loss: 0.08036303520202637, acc: 0.9816513657569885)
[2024-12-17 02:18:01,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:01,468][root][INFO] - Training Epoch: 1/2, step 6042/7134 completed (loss: 0.057937104254961014, acc: 0.9860000014305115)
[2024-12-17 02:18:01,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:01,818][root][INFO] - Training Epoch: 1/2, step 6043/7134 completed (loss: 0.056953854858875275, acc: 0.986810564994812)
[2024-12-17 02:18:01,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:02,173][root][INFO] - Training Epoch: 1/2, step 6044/7134 completed (loss: 0.08564408868551254, acc: 0.9716049432754517)
[2024-12-17 02:18:02,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:02,505][root][INFO] - Training Epoch: 1/2, step 6045/7134 completed (loss: 0.06803681701421738, acc: 0.9810650944709778)
[2024-12-17 02:18:02,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:02,858][root][INFO] - Training Epoch: 1/2, step 6046/7134 completed (loss: 0.06763987243175507, acc: 0.9826689958572388)
[2024-12-17 02:18:02,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:03,218][root][INFO] - Training Epoch: 1/2, step 6047/7134 completed (loss: 0.17784136533737183, acc: 0.9561551213264465)
[2024-12-17 02:18:03,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:03,561][root][INFO] - Training Epoch: 1/2, step 6048/7134 completed (loss: 0.1253669112920761, acc: 0.9619238376617432)
[2024-12-17 02:18:03,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:03,872][root][INFO] - Training Epoch: 1/2, step 6049/7134 completed (loss: 0.03334363177418709, acc: 0.9897611141204834)
[2024-12-17 02:18:03,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:04,195][root][INFO] - Training Epoch: 1/2, step 6050/7134 completed (loss: 0.13814511895179749, acc: 0.9726402163505554)
[2024-12-17 02:18:04,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:04,565][root][INFO] - Training Epoch: 1/2, step 6051/7134 completed (loss: 0.18483753502368927, acc: 0.9453471302986145)
[2024-12-17 02:18:04,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:04,926][root][INFO] - Training Epoch: 1/2, step 6052/7134 completed (loss: 0.1265878677368164, acc: 0.9701727032661438)
[2024-12-17 02:18:05,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:05,289][root][INFO] - Training Epoch: 1/2, step 6053/7134 completed (loss: 0.10075780004262924, acc: 0.969298243522644)
[2024-12-17 02:18:05,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:05,633][root][INFO] - Training Epoch: 1/2, step 6054/7134 completed (loss: 0.0917309895157814, acc: 0.9722222089767456)
[2024-12-17 02:18:05,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:05,960][root][INFO] - Training Epoch: 1/2, step 6055/7134 completed (loss: 0.06087389215826988, acc: 0.9889415502548218)
[2024-12-17 02:18:06,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:06,266][root][INFO] - Training Epoch: 1/2, step 6056/7134 completed (loss: 0.10819610208272934, acc: 0.9677419066429138)
[2024-12-17 02:18:06,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:06,548][root][INFO] - Training Epoch: 1/2, step 6057/7134 completed (loss: 0.07573963701725006, acc: 0.9802631735801697)
[2024-12-17 02:18:06,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:06,837][root][INFO] - Training Epoch: 1/2, step 6058/7134 completed (loss: 0.02060081996023655, acc: 0.9954954981803894)
[2024-12-17 02:18:06,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:07,118][root][INFO] - Training Epoch: 1/2, step 6059/7134 completed (loss: 0.04498967528343201, acc: 0.9858657121658325)
[2024-12-17 02:18:07,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:07,468][root][INFO] - Training Epoch: 1/2, step 6060/7134 completed (loss: 0.07387404143810272, acc: 0.9744361042976379)
[2024-12-17 02:18:07,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:07,785][root][INFO] - Training Epoch: 1/2, step 6061/7134 completed (loss: 0.1359787881374359, acc: 0.9691833853721619)
[2024-12-17 02:18:07,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:08,127][root][INFO] - Training Epoch: 1/2, step 6062/7134 completed (loss: 0.11057239025831223, acc: 0.9651162624359131)
[2024-12-17 02:18:08,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:08,446][root][INFO] - Training Epoch: 1/2, step 6063/7134 completed (loss: 0.15956032276153564, acc: 0.9638336300849915)
[2024-12-17 02:18:08,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:08,796][root][INFO] - Training Epoch: 1/2, step 6064/7134 completed (loss: 0.09414821863174438, acc: 0.9768451452255249)
[2024-12-17 02:18:08,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:09,157][root][INFO] - Training Epoch: 1/2, step 6065/7134 completed (loss: 0.09892474114894867, acc: 0.9732685089111328)
[2024-12-17 02:18:09,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:09,478][root][INFO] - Training Epoch: 1/2, step 6066/7134 completed (loss: 0.1231786236166954, acc: 0.9703459739685059)
[2024-12-17 02:18:09,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:09,805][root][INFO] - Training Epoch: 1/2, step 6067/7134 completed (loss: 0.1221843883395195, acc: 0.9711399674415588)
[2024-12-17 02:18:09,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:10,215][root][INFO] - Training Epoch: 1/2, step 6068/7134 completed (loss: 0.16036708652973175, acc: 0.9536921381950378)
[2024-12-17 02:18:10,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:10,531][root][INFO] - Training Epoch: 1/2, step 6069/7134 completed (loss: 0.09738095849752426, acc: 0.9737226366996765)
[2024-12-17 02:18:10,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:10,898][root][INFO] - Training Epoch: 1/2, step 6070/7134 completed (loss: 0.11794960498809814, acc: 0.9653794765472412)
[2024-12-17 02:18:11,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:11,215][root][INFO] - Training Epoch: 1/2, step 6071/7134 completed (loss: 0.0999559760093689, acc: 0.9717361927032471)
[2024-12-17 02:18:11,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:11,485][root][INFO] - Training Epoch: 1/2, step 6072/7134 completed (loss: 0.14564338326454163, acc: 0.9684873819351196)
[2024-12-17 02:18:11,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:11,817][root][INFO] - Training Epoch: 1/2, step 6073/7134 completed (loss: 0.11589223891496658, acc: 0.9734265804290771)
[2024-12-17 02:18:11,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:12,141][root][INFO] - Training Epoch: 1/2, step 6074/7134 completed (loss: 0.11579015105962753, acc: 0.970588207244873)
[2024-12-17 02:18:12,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:12,495][root][INFO] - Training Epoch: 1/2, step 6075/7134 completed (loss: 0.09838796406984329, acc: 0.9784172773361206)
[2024-12-17 02:18:12,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:12,838][root][INFO] - Training Epoch: 1/2, step 6076/7134 completed (loss: 0.20155669748783112, acc: 0.9583333134651184)
[2024-12-17 02:18:12,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:13,171][root][INFO] - Training Epoch: 1/2, step 6077/7134 completed (loss: 0.1467646360397339, acc: 0.9568690061569214)
[2024-12-17 02:18:13,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:13,506][root][INFO] - Training Epoch: 1/2, step 6078/7134 completed (loss: 0.1286211758852005, acc: 0.9746478796005249)
[2024-12-17 02:18:13,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:13,864][root][INFO] - Training Epoch: 1/2, step 6079/7134 completed (loss: 0.07142952084541321, acc: 0.9762773513793945)
[2024-12-17 02:18:13,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:14,179][root][INFO] - Training Epoch: 1/2, step 6080/7134 completed (loss: 0.08864717930555344, acc: 0.9702970385551453)
[2024-12-17 02:18:14,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:14,516][root][INFO] - Training Epoch: 1/2, step 6081/7134 completed (loss: 0.07047908753156662, acc: 0.9786259531974792)
[2024-12-17 02:18:14,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:14,838][root][INFO] - Training Epoch: 1/2, step 6082/7134 completed (loss: 0.0814877599477768, acc: 0.9808917045593262)
[2024-12-17 02:18:14,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:15,199][root][INFO] - Training Epoch: 1/2, step 6083/7134 completed (loss: 0.04515290632843971, acc: 0.9864864945411682)
[2024-12-17 02:18:15,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:15,534][root][INFO] - Training Epoch: 1/2, step 6084/7134 completed (loss: 0.09253540635108948, acc: 0.9732704162597656)
[2024-12-17 02:18:15,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:15,890][root][INFO] - Training Epoch: 1/2, step 6085/7134 completed (loss: 0.06882069259881973, acc: 0.9856887459754944)
[2024-12-17 02:18:15,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:16,262][root][INFO] - Training Epoch: 1/2, step 6086/7134 completed (loss: 0.052591174840927124, acc: 0.9845505356788635)
[2024-12-17 02:18:16,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:16,623][root][INFO] - Training Epoch: 1/2, step 6087/7134 completed (loss: 0.11095090955495834, acc: 0.9710691571235657)
[2024-12-17 02:18:16,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:16,949][root][INFO] - Training Epoch: 1/2, step 6088/7134 completed (loss: 0.059903714805841446, acc: 0.9785522818565369)
[2024-12-17 02:18:17,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:17,317][root][INFO] - Training Epoch: 1/2, step 6089/7134 completed (loss: 0.07686067372560501, acc: 0.9793103337287903)
[2024-12-17 02:18:17,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:17,657][root][INFO] - Training Epoch: 1/2, step 6090/7134 completed (loss: 0.05984602868556976, acc: 0.9849108457565308)
[2024-12-17 02:18:17,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:17,979][root][INFO] - Training Epoch: 1/2, step 6091/7134 completed (loss: 0.07953974604606628, acc: 0.9792993664741516)
[2024-12-17 02:18:18,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:18,310][root][INFO] - Training Epoch: 1/2, step 6092/7134 completed (loss: 0.07252219319343567, acc: 0.9825396537780762)
[2024-12-17 02:18:18,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:18,639][root][INFO] - Training Epoch: 1/2, step 6093/7134 completed (loss: 0.11064338684082031, acc: 0.9684600830078125)
[2024-12-17 02:18:18,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:18,960][root][INFO] - Training Epoch: 1/2, step 6094/7134 completed (loss: 0.06167757511138916, acc: 0.9859943985939026)
[2024-12-17 02:18:19,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:19,261][root][INFO] - Training Epoch: 1/2, step 6095/7134 completed (loss: 0.044719304889440536, acc: 0.9928160905838013)
[2024-12-17 02:18:19,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:19,621][root][INFO] - Training Epoch: 1/2, step 6096/7134 completed (loss: 0.07769011706113815, acc: 0.9761336445808411)
[2024-12-17 02:18:19,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:19,959][root][INFO] - Training Epoch: 1/2, step 6097/7134 completed (loss: 0.09425240010023117, acc: 0.9750692248344421)
[2024-12-17 02:18:20,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:20,296][root][INFO] - Training Epoch: 1/2, step 6098/7134 completed (loss: 0.13664431869983673, acc: 0.9755469560623169)
[2024-12-17 02:18:20,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:20,645][root][INFO] - Training Epoch: 1/2, step 6099/7134 completed (loss: 0.10659056156873703, acc: 0.9709480404853821)
[2024-12-17 02:18:20,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:20,904][root][INFO] - Training Epoch: 1/2, step 6100/7134 completed (loss: 0.19286619126796722, acc: 0.957317054271698)
[2024-12-17 02:18:21,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:21,214][root][INFO] - Training Epoch: 1/2, step 6101/7134 completed (loss: 0.05891171842813492, acc: 0.9808306694030762)
[2024-12-17 02:18:21,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:21,544][root][INFO] - Training Epoch: 1/2, step 6102/7134 completed (loss: 0.09604471921920776, acc: 0.9806337952613831)
[2024-12-17 02:18:21,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:21,897][root][INFO] - Training Epoch: 1/2, step 6103/7134 completed (loss: 0.06975410878658295, acc: 0.9777777791023254)
[2024-12-17 02:18:21,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:22,224][root][INFO] - Training Epoch: 1/2, step 6104/7134 completed (loss: 0.1480388641357422, acc: 0.9540740847587585)
[2024-12-17 02:18:22,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:22,567][root][INFO] - Training Epoch: 1/2, step 6105/7134 completed (loss: 0.1273685246706009, acc: 0.9672619104385376)
[2024-12-17 02:18:22,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:22,845][root][INFO] - Training Epoch: 1/2, step 6106/7134 completed (loss: 0.11133318394422531, acc: 0.9731663465499878)
[2024-12-17 02:18:22,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:23,177][root][INFO] - Training Epoch: 1/2, step 6107/7134 completed (loss: 0.10120268166065216, acc: 0.9768907427787781)
[2024-12-17 02:18:23,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:23,489][root][INFO] - Training Epoch: 1/2, step 6108/7134 completed (loss: 0.10990747809410095, acc: 0.9763205647468567)
[2024-12-17 02:18:23,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:23,806][root][INFO] - Training Epoch: 1/2, step 6109/7134 completed (loss: 0.04507015645503998, acc: 0.9872881174087524)
[2024-12-17 02:18:23,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:24,134][root][INFO] - Training Epoch: 1/2, step 6110/7134 completed (loss: 0.14966833591461182, acc: 0.9594017267227173)
[2024-12-17 02:18:24,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:24,471][root][INFO] - Training Epoch: 1/2, step 6111/7134 completed (loss: 0.13974325358867645, acc: 0.9624664783477783)
[2024-12-17 02:18:24,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:24,807][root][INFO] - Training Epoch: 1/2, step 6112/7134 completed (loss: 0.08711950480937958, acc: 0.9732441306114197)
[2024-12-17 02:18:24,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:25,143][root][INFO] - Training Epoch: 1/2, step 6113/7134 completed (loss: 0.03755872696638107, acc: 0.9908952713012695)
[2024-12-17 02:18:25,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:25,477][root][INFO] - Training Epoch: 1/2, step 6114/7134 completed (loss: 0.12381435185670853, acc: 0.968595027923584)
[2024-12-17 02:18:25,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:25,775][root][INFO] - Training Epoch: 1/2, step 6115/7134 completed (loss: 0.08561477810144424, acc: 0.9885057210922241)
[2024-12-17 02:18:25,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:26,068][root][INFO] - Training Epoch: 1/2, step 6116/7134 completed (loss: 0.12310099601745605, acc: 0.9762845635414124)
[2024-12-17 02:18:26,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:26,418][root][INFO] - Training Epoch: 1/2, step 6117/7134 completed (loss: 0.13362707197666168, acc: 0.9672130942344666)
[2024-12-17 02:18:26,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:26,805][root][INFO] - Training Epoch: 1/2, step 6118/7134 completed (loss: 0.13938431441783905, acc: 0.966911792755127)
[2024-12-17 02:18:26,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:27,158][root][INFO] - Training Epoch: 1/2, step 6119/7134 completed (loss: 0.07810293883085251, acc: 0.9735894203186035)
[2024-12-17 02:18:27,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:27,495][root][INFO] - Training Epoch: 1/2, step 6120/7134 completed (loss: 0.08071411401033401, acc: 0.9785330891609192)
[2024-12-17 02:18:27,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:27,845][root][INFO] - Training Epoch: 1/2, step 6121/7134 completed (loss: 0.11096848547458649, acc: 0.9676259160041809)
[2024-12-17 02:18:27,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:28,190][root][INFO] - Training Epoch: 1/2, step 6122/7134 completed (loss: 0.06532485038042068, acc: 0.9754716753959656)
[2024-12-17 02:18:28,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:28,521][root][INFO] - Training Epoch: 1/2, step 6123/7134 completed (loss: 0.1407639980316162, acc: 0.9708939790725708)
[2024-12-17 02:18:28,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:28,842][root][INFO] - Training Epoch: 1/2, step 6124/7134 completed (loss: 0.057971011847257614, acc: 0.9846153855323792)
[2024-12-17 02:18:28,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:29,209][root][INFO] - Training Epoch: 1/2, step 6125/7134 completed (loss: 0.25888410210609436, acc: 0.9542168378829956)
[2024-12-17 02:18:29,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:29,534][root][INFO] - Training Epoch: 1/2, step 6126/7134 completed (loss: 0.13471117615699768, acc: 0.9702194333076477)
[2024-12-17 02:18:29,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:29,804][root][INFO] - Training Epoch: 1/2, step 6127/7134 completed (loss: 0.06851667165756226, acc: 0.976190447807312)
[2024-12-17 02:18:29,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:30,128][root][INFO] - Training Epoch: 1/2, step 6128/7134 completed (loss: 0.06978920102119446, acc: 0.9797570705413818)
[2024-12-17 02:18:30,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:30,465][root][INFO] - Training Epoch: 1/2, step 6129/7134 completed (loss: 0.08581409603357315, acc: 0.9803094267845154)
[2024-12-17 02:18:30,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:30,779][root][INFO] - Training Epoch: 1/2, step 6130/7134 completed (loss: 0.06587307155132294, acc: 0.9767025113105774)
[2024-12-17 02:18:30,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:31,132][root][INFO] - Training Epoch: 1/2, step 6131/7134 completed (loss: 0.1259821057319641, acc: 0.9640718698501587)
[2024-12-17 02:18:31,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:31,454][root][INFO] - Training Epoch: 1/2, step 6132/7134 completed (loss: 0.12116003036499023, acc: 0.9671875238418579)
[2024-12-17 02:18:31,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:31,823][root][INFO] - Training Epoch: 1/2, step 6133/7134 completed (loss: 0.0699961930513382, acc: 0.9830096960067749)
[2024-12-17 02:18:31,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:32,132][root][INFO] - Training Epoch: 1/2, step 6134/7134 completed (loss: 0.11043653637170792, acc: 0.9709035158157349)
[2024-12-17 02:18:32,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:32,452][root][INFO] - Training Epoch: 1/2, step 6135/7134 completed (loss: 0.04942832142114639, acc: 0.9825783967971802)
[2024-12-17 02:18:32,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:32,777][root][INFO] - Training Epoch: 1/2, step 6136/7134 completed (loss: 0.08581938594579697, acc: 0.981792688369751)
[2024-12-17 02:18:32,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:33,092][root][INFO] - Training Epoch: 1/2, step 6137/7134 completed (loss: 0.11015380173921585, acc: 0.9797191619873047)
[2024-12-17 02:18:33,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:33,415][root][INFO] - Training Epoch: 1/2, step 6138/7134 completed (loss: 0.10939186066389084, acc: 0.9738863110542297)
[2024-12-17 02:18:33,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:33,725][root][INFO] - Training Epoch: 1/2, step 6139/7134 completed (loss: 0.10853539407253265, acc: 0.9722222089767456)
[2024-12-17 02:18:33,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:34,091][root][INFO] - Training Epoch: 1/2, step 6140/7134 completed (loss: 0.06467565149068832, acc: 0.9893993139266968)
[2024-12-17 02:18:34,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:34,367][root][INFO] - Training Epoch: 1/2, step 6141/7134 completed (loss: 0.13088227808475494, acc: 0.9785932898521423)
[2024-12-17 02:18:34,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:34,700][root][INFO] - Training Epoch: 1/2, step 6142/7134 completed (loss: 0.06279744952917099, acc: 0.9798561334609985)
[2024-12-17 02:18:34,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:35,043][root][INFO] - Training Epoch: 1/2, step 6143/7134 completed (loss: 0.06328938901424408, acc: 0.9878378510475159)
[2024-12-17 02:18:35,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:35,356][root][INFO] - Training Epoch: 1/2, step 6144/7134 completed (loss: 0.054341837763786316, acc: 0.9848739504814148)
[2024-12-17 02:18:35,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:35,713][root][INFO] - Training Epoch: 1/2, step 6145/7134 completed (loss: 0.1338474154472351, acc: 0.9762219190597534)
[2024-12-17 02:18:35,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:36,035][root][INFO] - Training Epoch: 1/2, step 6146/7134 completed (loss: 0.10381803661584854, acc: 0.9743589758872986)
[2024-12-17 02:18:36,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:36,356][root][INFO] - Training Epoch: 1/2, step 6147/7134 completed (loss: 0.0921408087015152, acc: 0.97817462682724)
[2024-12-17 02:18:36,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:36,713][root][INFO] - Training Epoch: 1/2, step 6148/7134 completed (loss: 0.09999152272939682, acc: 0.9765493869781494)
[2024-12-17 02:18:36,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:37,041][root][INFO] - Training Epoch: 1/2, step 6149/7134 completed (loss: 0.10305050015449524, acc: 0.9694533944129944)
[2024-12-17 02:18:37,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:37,377][root][INFO] - Training Epoch: 1/2, step 6150/7134 completed (loss: 0.11628042161464691, acc: 0.9684210419654846)
[2024-12-17 02:18:37,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:37,682][root][INFO] - Training Epoch: 1/2, step 6151/7134 completed (loss: 0.038676876574754715, acc: 0.9905808568000793)
[2024-12-17 02:18:37,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:38,025][root][INFO] - Training Epoch: 1/2, step 6152/7134 completed (loss: 0.06641831994056702, acc: 0.9728506803512573)
[2024-12-17 02:18:38,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:38,380][root][INFO] - Training Epoch: 1/2, step 6153/7134 completed (loss: 0.053515393286943436, acc: 0.986975371837616)
[2024-12-17 02:18:38,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:38,744][root][INFO] - Training Epoch: 1/2, step 6154/7134 completed (loss: 0.06360087543725967, acc: 0.9832636117935181)
[2024-12-17 02:18:38,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:39,094][root][INFO] - Training Epoch: 1/2, step 6155/7134 completed (loss: 0.10665171593427658, acc: 0.9792284965515137)
[2024-12-17 02:18:39,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:39,403][root][INFO] - Training Epoch: 1/2, step 6156/7134 completed (loss: 0.0771743431687355, acc: 0.9793977737426758)
[2024-12-17 02:18:39,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:39,744][root][INFO] - Training Epoch: 1/2, step 6157/7134 completed (loss: 0.0609424002468586, acc: 0.9858934283256531)
[2024-12-17 02:18:39,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:40,080][root][INFO] - Training Epoch: 1/2, step 6158/7134 completed (loss: 0.11740405112504959, acc: 0.9819168448448181)
[2024-12-17 02:18:40,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:40,433][root][INFO] - Training Epoch: 1/2, step 6159/7134 completed (loss: 0.11489809304475784, acc: 0.9674306511878967)
[2024-12-17 02:18:40,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:40,768][root][INFO] - Training Epoch: 1/2, step 6160/7134 completed (loss: 0.13369624316692352, acc: 0.9681817889213562)
[2024-12-17 02:18:40,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:41,131][root][INFO] - Training Epoch: 1/2, step 6161/7134 completed (loss: 0.10696898400783539, acc: 0.9771528840065002)
[2024-12-17 02:18:41,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:41,484][root][INFO] - Training Epoch: 1/2, step 6162/7134 completed (loss: 0.09830516576766968, acc: 0.9770867228507996)
[2024-12-17 02:18:41,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:41,841][root][INFO] - Training Epoch: 1/2, step 6163/7134 completed (loss: 0.1409645825624466, acc: 0.9714285731315613)
[2024-12-17 02:18:41,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:42,198][root][INFO] - Training Epoch: 1/2, step 6164/7134 completed (loss: 0.1547866016626358, acc: 0.9617563486099243)
[2024-12-17 02:18:42,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:42,508][root][INFO] - Training Epoch: 1/2, step 6165/7134 completed (loss: 0.11048253625631332, acc: 0.9741697311401367)
[2024-12-17 02:18:42,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:42,826][root][INFO] - Training Epoch: 1/2, step 6166/7134 completed (loss: 0.060378458350896835, acc: 0.9859402179718018)
[2024-12-17 02:18:42,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:43,148][root][INFO] - Training Epoch: 1/2, step 6167/7134 completed (loss: 0.05208266153931618, acc: 0.985855758190155)
[2024-12-17 02:18:43,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:43,496][root][INFO] - Training Epoch: 1/2, step 6168/7134 completed (loss: 0.06654586642980576, acc: 0.9819819927215576)
[2024-12-17 02:18:43,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:43,811][root][INFO] - Training Epoch: 1/2, step 6169/7134 completed (loss: 0.09096761047840118, acc: 0.9825072884559631)
[2024-12-17 02:18:43,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:44,125][root][INFO] - Training Epoch: 1/2, step 6170/7134 completed (loss: 0.0530945286154747, acc: 0.9867674708366394)
[2024-12-17 02:18:44,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:44,462][root][INFO] - Training Epoch: 1/2, step 6171/7134 completed (loss: 0.037589602172374725, acc: 0.9855453372001648)
[2024-12-17 02:18:44,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:44,775][root][INFO] - Training Epoch: 1/2, step 6172/7134 completed (loss: 0.044517502188682556, acc: 0.9879759550094604)
[2024-12-17 02:18:44,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:45,092][root][INFO] - Training Epoch: 1/2, step 6173/7134 completed (loss: 0.04049638658761978, acc: 0.9896907210350037)
[2024-12-17 02:18:45,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:45,423][root][INFO] - Training Epoch: 1/2, step 6174/7134 completed (loss: 0.032763514667749405, acc: 0.9912023544311523)
[2024-12-17 02:18:45,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:45,773][root][INFO] - Training Epoch: 1/2, step 6175/7134 completed (loss: 0.07155212014913559, acc: 0.9822485446929932)
[2024-12-17 02:18:45,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:46,095][root][INFO] - Training Epoch: 1/2, step 6176/7134 completed (loss: 0.06089893728494644, acc: 0.9797394871711731)
[2024-12-17 02:18:46,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:46,431][root][INFO] - Training Epoch: 1/2, step 6177/7134 completed (loss: 0.032935336232185364, acc: 0.9897698163986206)
[2024-12-17 02:18:46,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:46,756][root][INFO] - Training Epoch: 1/2, step 6178/7134 completed (loss: 0.03767675161361694, acc: 0.9867256879806519)
[2024-12-17 02:18:46,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:47,084][root][INFO] - Training Epoch: 1/2, step 6179/7134 completed (loss: 0.06930231302976608, acc: 0.9798136353492737)
[2024-12-17 02:18:47,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:47,373][root][INFO] - Training Epoch: 1/2, step 6180/7134 completed (loss: 0.23582054674625397, acc: 0.9394904375076294)
[2024-12-17 02:18:47,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:47,685][root][INFO] - Training Epoch: 1/2, step 6181/7134 completed (loss: 0.3468891680240631, acc: 0.9090909361839294)
[2024-12-17 02:18:47,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:48,020][root][INFO] - Training Epoch: 1/2, step 6182/7134 completed (loss: 0.10172127932310104, acc: 0.9703153967857361)
[2024-12-17 02:18:48,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:48,352][root][INFO] - Training Epoch: 1/2, step 6183/7134 completed (loss: 0.08839786797761917, acc: 0.9709035158157349)
[2024-12-17 02:18:48,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:48,669][root][INFO] - Training Epoch: 1/2, step 6184/7134 completed (loss: 0.1773056983947754, acc: 0.9556451439857483)
[2024-12-17 02:18:48,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:48,999][root][INFO] - Training Epoch: 1/2, step 6185/7134 completed (loss: 0.07180576026439667, acc: 0.9797794222831726)
[2024-12-17 02:18:49,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:49,320][root][INFO] - Training Epoch: 1/2, step 6186/7134 completed (loss: 0.06335802376270294, acc: 0.9825174808502197)
[2024-12-17 02:18:49,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:49,677][root][INFO] - Training Epoch: 1/2, step 6187/7134 completed (loss: 0.05601293966174126, acc: 0.9841269850730896)
[2024-12-17 02:18:49,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:50,021][root][INFO] - Training Epoch: 1/2, step 6188/7134 completed (loss: 0.140074223279953, acc: 0.9703808426856995)
[2024-12-17 02:18:50,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:50,386][root][INFO] - Training Epoch: 1/2, step 6189/7134 completed (loss: 0.21167877316474915, acc: 0.9422799348831177)
[2024-12-17 02:18:50,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:50,712][root][INFO] - Training Epoch: 1/2, step 6190/7134 completed (loss: 0.24323001503944397, acc: 0.9385381937026978)
[2024-12-17 02:18:50,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:51,067][root][INFO] - Training Epoch: 1/2, step 6191/7134 completed (loss: 0.15014219284057617, acc: 0.9615384340286255)
[2024-12-17 02:18:51,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:51,436][root][INFO] - Training Epoch: 1/2, step 6192/7134 completed (loss: 0.08038410544395447, acc: 0.971061110496521)
[2024-12-17 02:18:51,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:51,783][root][INFO] - Training Epoch: 1/2, step 6193/7134 completed (loss: 0.16027237474918365, acc: 0.9583829045295715)
[2024-12-17 02:18:51,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:52,129][root][INFO] - Training Epoch: 1/2, step 6194/7134 completed (loss: 0.14511939883232117, acc: 0.951361894607544)
[2024-12-17 02:18:52,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:52,445][root][INFO] - Training Epoch: 1/2, step 6195/7134 completed (loss: 0.16434627771377563, acc: 0.9449760913848877)
[2024-12-17 02:18:52,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:52,788][root][INFO] - Training Epoch: 1/2, step 6196/7134 completed (loss: 0.13842488825321198, acc: 0.9545454382896423)
[2024-12-17 02:18:52,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:53,143][root][INFO] - Training Epoch: 1/2, step 6197/7134 completed (loss: 0.2509240508079529, acc: 0.9296551942825317)
[2024-12-17 02:18:53,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:53,471][root][INFO] - Training Epoch: 1/2, step 6198/7134 completed (loss: 0.10744380205869675, acc: 0.9668049812316895)
[2024-12-17 02:18:53,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:53,822][root][INFO] - Training Epoch: 1/2, step 6199/7134 completed (loss: 0.11060093343257904, acc: 0.9721577763557434)
[2024-12-17 02:18:53,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:54,172][root][INFO] - Training Epoch: 1/2, step 6200/7134 completed (loss: 0.09660360962152481, acc: 0.9682926535606384)
[2024-12-17 02:18:54,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:54,533][root][INFO] - Training Epoch: 1/2, step 6201/7134 completed (loss: 0.07786306738853455, acc: 0.9810479283332825)
[2024-12-17 02:18:54,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:54,845][root][INFO] - Training Epoch: 1/2, step 6202/7134 completed (loss: 0.07223894447088242, acc: 0.9848155975341797)
[2024-12-17 02:18:54,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:55,195][root][INFO] - Training Epoch: 1/2, step 6203/7134 completed (loss: 0.09421505033969879, acc: 0.9732142686843872)
[2024-12-17 02:18:55,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:55,530][root][INFO] - Training Epoch: 1/2, step 6204/7134 completed (loss: 0.10383386164903641, acc: 0.974459707736969)
[2024-12-17 02:18:55,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:55,862][root][INFO] - Training Epoch: 1/2, step 6205/7134 completed (loss: 0.10765479505062103, acc: 0.9692832827568054)
[2024-12-17 02:18:55,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:56,176][root][INFO] - Training Epoch: 1/2, step 6206/7134 completed (loss: 0.07254939526319504, acc: 0.9826338887214661)
[2024-12-17 02:18:56,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:56,530][root][INFO] - Training Epoch: 1/2, step 6207/7134 completed (loss: 0.24631646275520325, acc: 0.9412550330162048)
[2024-12-17 02:18:56,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:56,867][root][INFO] - Training Epoch: 1/2, step 6208/7134 completed (loss: 0.1210925430059433, acc: 0.9675925970077515)
[2024-12-17 02:18:56,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:57,227][root][INFO] - Training Epoch: 1/2, step 6209/7134 completed (loss: 0.12580299377441406, acc: 0.962483823299408)
[2024-12-17 02:18:57,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:57,609][root][INFO] - Training Epoch: 1/2, step 6210/7134 completed (loss: 0.13515524566173553, acc: 0.9615384340286255)
[2024-12-17 02:18:57,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:57,977][root][INFO] - Training Epoch: 1/2, step 6211/7134 completed (loss: 0.12430508434772491, acc: 0.9607577919960022)
[2024-12-17 02:18:58,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:58,295][root][INFO] - Training Epoch: 1/2, step 6212/7134 completed (loss: 0.09503787755966187, acc: 0.9701754450798035)
[2024-12-17 02:18:58,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:58,631][root][INFO] - Training Epoch: 1/2, step 6213/7134 completed (loss: 0.06486521661281586, acc: 0.9812889695167542)
[2024-12-17 02:18:58,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:58,973][root][INFO] - Training Epoch: 1/2, step 6214/7134 completed (loss: 0.10145456343889236, acc: 0.9743260741233826)
[2024-12-17 02:18:59,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:59,332][root][INFO] - Training Epoch: 1/2, step 6215/7134 completed (loss: 0.12934063374996185, acc: 0.9688940048217773)
[2024-12-17 02:18:59,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:59,592][root][INFO] - Training Epoch: 1/2, step 6216/7134 completed (loss: 0.12320855259895325, acc: 0.9680851101875305)
[2024-12-17 02:18:59,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:59,954][root][INFO] - Training Epoch: 1/2, step 6217/7134 completed (loss: 0.08903618901968002, acc: 0.9744966626167297)
[2024-12-17 02:19:00,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:00,313][root][INFO] - Training Epoch: 1/2, step 6218/7134 completed (loss: 0.0988793596625328, acc: 0.9786585569381714)
[2024-12-17 02:19:00,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:00,656][root][INFO] - Training Epoch: 1/2, step 6219/7134 completed (loss: 0.09377457201480865, acc: 0.9732770919799805)
[2024-12-17 02:19:00,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:00,959][root][INFO] - Training Epoch: 1/2, step 6220/7134 completed (loss: 0.14741547405719757, acc: 0.949999988079071)
[2024-12-17 02:19:01,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:01,293][root][INFO] - Training Epoch: 1/2, step 6221/7134 completed (loss: 0.05021211504936218, acc: 0.9877192974090576)
[2024-12-17 02:19:01,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:01,600][root][INFO] - Training Epoch: 1/2, step 6222/7134 completed (loss: 0.08292468637228012, acc: 0.9808743000030518)
[2024-12-17 02:19:01,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:01,948][root][INFO] - Training Epoch: 1/2, step 6223/7134 completed (loss: 0.08551132678985596, acc: 0.9768009781837463)
[2024-12-17 02:19:02,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:02,278][root][INFO] - Training Epoch: 1/2, step 6224/7134 completed (loss: 0.035821959376335144, acc: 0.9927431344985962)
[2024-12-17 02:19:02,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:02,634][root][INFO] - Training Epoch: 1/2, step 6225/7134 completed (loss: 0.0706450343132019, acc: 0.9783163070678711)
[2024-12-17 02:19:02,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:02,958][root][INFO] - Training Epoch: 1/2, step 6226/7134 completed (loss: 0.09683579206466675, acc: 0.9685451984405518)
[2024-12-17 02:19:03,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:03,318][root][INFO] - Training Epoch: 1/2, step 6227/7134 completed (loss: 0.053413473069667816, acc: 0.9852744340896606)
[2024-12-17 02:19:03,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:03,667][root][INFO] - Training Epoch: 1/2, step 6228/7134 completed (loss: 0.07928543537855148, acc: 0.9803439974784851)
[2024-12-17 02:19:03,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:04,019][root][INFO] - Training Epoch: 1/2, step 6229/7134 completed (loss: 0.11311214417219162, acc: 0.9733178615570068)
[2024-12-17 02:19:04,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:04,376][root][INFO] - Training Epoch: 1/2, step 6230/7134 completed (loss: 0.07016072422266006, acc: 0.9875311851501465)
[2024-12-17 02:19:04,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:04,695][root][INFO] - Training Epoch: 1/2, step 6231/7134 completed (loss: 0.04386488348245621, acc: 0.9793281555175781)
[2024-12-17 02:19:04,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:05,059][root][INFO] - Training Epoch: 1/2, step 6232/7134 completed (loss: 0.08057952672243118, acc: 0.9760100841522217)
[2024-12-17 02:19:05,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:05,421][root][INFO] - Training Epoch: 1/2, step 6233/7134 completed (loss: 0.038113027811050415, acc: 0.989276111125946)
[2024-12-17 02:19:05,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:05,781][root][INFO] - Training Epoch: 1/2, step 6234/7134 completed (loss: 0.08358009159564972, acc: 0.9759358167648315)
[2024-12-17 02:19:05,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:06,110][root][INFO] - Training Epoch: 1/2, step 6235/7134 completed (loss: 0.05692256987094879, acc: 0.9895697236061096)
[2024-12-17 02:19:06,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:06,477][root][INFO] - Training Epoch: 1/2, step 6236/7134 completed (loss: 0.06444042176008224, acc: 0.9795361757278442)
[2024-12-17 02:19:06,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:06,818][root][INFO] - Training Epoch: 1/2, step 6237/7134 completed (loss: 0.09606087952852249, acc: 0.9755351543426514)
[2024-12-17 02:19:06,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:07,127][root][INFO] - Training Epoch: 1/2, step 6238/7134 completed (loss: 0.04226132482290268, acc: 0.9903069734573364)
[2024-12-17 02:19:07,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:07,481][root][INFO] - Training Epoch: 1/2, step 6239/7134 completed (loss: 0.06225702539086342, acc: 0.9856630563735962)
[2024-12-17 02:19:07,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:07,822][root][INFO] - Training Epoch: 1/2, step 6240/7134 completed (loss: 0.015153621323406696, acc: 0.9985895752906799)
[2024-12-17 02:19:07,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:08,161][root][INFO] - Training Epoch: 1/2, step 6241/7134 completed (loss: 0.029732922092080116, acc: 0.9952531456947327)
[2024-12-17 02:19:08,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:08,506][root][INFO] - Training Epoch: 1/2, step 6242/7134 completed (loss: 0.035400088876485825, acc: 0.9897959232330322)
[2024-12-17 02:19:08,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:08,837][root][INFO] - Training Epoch: 1/2, step 6243/7134 completed (loss: 0.031714070588350296, acc: 0.9920381903648376)
[2024-12-17 02:19:08,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:09,174][root][INFO] - Training Epoch: 1/2, step 6244/7134 completed (loss: 0.03045920841395855, acc: 0.9931412935256958)
[2024-12-17 02:19:09,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:09,524][root][INFO] - Training Epoch: 1/2, step 6245/7134 completed (loss: 0.025919053703546524, acc: 0.99589604139328)
[2024-12-17 02:19:09,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:09,874][root][INFO] - Training Epoch: 1/2, step 6246/7134 completed (loss: 0.0447932705283165, acc: 0.9855072498321533)
[2024-12-17 02:19:09,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:10,234][root][INFO] - Training Epoch: 1/2, step 6247/7134 completed (loss: 0.07347682863473892, acc: 0.9795180559158325)
[2024-12-17 02:19:10,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:10,573][root][INFO] - Training Epoch: 1/2, step 6248/7134 completed (loss: 0.08063540607690811, acc: 0.9797507524490356)
[2024-12-17 02:19:10,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:10,890][root][INFO] - Training Epoch: 1/2, step 6249/7134 completed (loss: 0.018888115882873535, acc: 0.9937106966972351)
[2024-12-17 02:19:11,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:11,215][root][INFO] - Training Epoch: 1/2, step 6250/7134 completed (loss: 0.008727408945560455, acc: 0.9965986609458923)
[2024-12-17 02:19:11,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:11,549][root][INFO] - Training Epoch: 1/2, step 6251/7134 completed (loss: 0.02168065495789051, acc: 0.9923312664031982)
[2024-12-17 02:19:11,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:11,875][root][INFO] - Training Epoch: 1/2, step 6252/7134 completed (loss: 0.029670845717191696, acc: 0.9902912378311157)
[2024-12-17 02:19:11,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:12,201][root][INFO] - Training Epoch: 1/2, step 6253/7134 completed (loss: 0.04172161966562271, acc: 0.9896551966667175)
[2024-12-17 02:19:12,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:12,518][root][INFO] - Training Epoch: 1/2, step 6254/7134 completed (loss: 0.051202788949012756, acc: 0.9896193742752075)
[2024-12-17 02:19:12,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:12,849][root][INFO] - Training Epoch: 1/2, step 6255/7134 completed (loss: 0.057186953723430634, acc: 0.9878048896789551)
[2024-12-17 02:19:12,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:13,173][root][INFO] - Training Epoch: 1/2, step 6256/7134 completed (loss: 0.021886488422751427, acc: 0.9957447052001953)
[2024-12-17 02:19:13,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:13,506][root][INFO] - Training Epoch: 1/2, step 6257/7134 completed (loss: 0.052228134125471115, acc: 0.9856114983558655)
[2024-12-17 02:19:13,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:13,814][root][INFO] - Training Epoch: 1/2, step 6258/7134 completed (loss: 0.033773913979530334, acc: 0.9904000163078308)
[2024-12-17 02:19:13,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:14,148][root][INFO] - Training Epoch: 1/2, step 6259/7134 completed (loss: 0.03096606582403183, acc: 0.9894894957542419)
[2024-12-17 02:19:14,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:14,461][root][INFO] - Training Epoch: 1/2, step 6260/7134 completed (loss: 0.026586169376969337, acc: 0.9932885766029358)
[2024-12-17 02:19:14,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:14,811][root][INFO] - Training Epoch: 1/2, step 6261/7134 completed (loss: 0.03518687188625336, acc: 0.9908536672592163)
[2024-12-17 02:19:14,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:15,132][root][INFO] - Training Epoch: 1/2, step 6262/7134 completed (loss: 0.016255062073469162, acc: 0.9971305727958679)
[2024-12-17 02:19:15,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:15,453][root][INFO] - Training Epoch: 1/2, step 6263/7134 completed (loss: 0.02908303402364254, acc: 0.9926793575286865)
[2024-12-17 02:19:15,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:15,784][root][INFO] - Training Epoch: 1/2, step 6264/7134 completed (loss: 0.016026940196752548, acc: 0.9967159032821655)
[2024-12-17 02:19:15,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:16,131][root][INFO] - Training Epoch: 1/2, step 6265/7134 completed (loss: 0.03720247745513916, acc: 0.9896449446678162)
[2024-12-17 02:19:16,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:16,449][root][INFO] - Training Epoch: 1/2, step 6266/7134 completed (loss: 0.01164332590997219, acc: 0.996503472328186)
[2024-12-17 02:19:16,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:16,776][root][INFO] - Training Epoch: 1/2, step 6267/7134 completed (loss: 0.027261221781373024, acc: 0.990227997303009)
[2024-12-17 02:19:16,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:17,117][root][INFO] - Training Epoch: 1/2, step 6268/7134 completed (loss: 0.03081473521888256, acc: 0.9955357313156128)
[2024-12-17 02:19:17,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:17,451][root][INFO] - Training Epoch: 1/2, step 6269/7134 completed (loss: 0.02240563929080963, acc: 0.9978678226470947)
[2024-12-17 02:19:17,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:17,782][root][INFO] - Training Epoch: 1/2, step 6270/7134 completed (loss: 0.014060589484870434, acc: 0.9969325065612793)
[2024-12-17 02:19:17,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:18,118][root][INFO] - Training Epoch: 1/2, step 6271/7134 completed (loss: 0.03485892713069916, acc: 0.9946523904800415)
[2024-12-17 02:19:18,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:18,480][root][INFO] - Training Epoch: 1/2, step 6272/7134 completed (loss: 0.012512223795056343, acc: 0.997063159942627)
[2024-12-17 02:19:18,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:18,836][root][INFO] - Training Epoch: 1/2, step 6273/7134 completed (loss: 0.024580182507634163, acc: 0.9931600689888)
[2024-12-17 02:19:18,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:19,164][root][INFO] - Training Epoch: 1/2, step 6274/7134 completed (loss: 0.03266684338450432, acc: 0.9928673505783081)
[2024-12-17 02:19:19,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:19,494][root][INFO] - Training Epoch: 1/2, step 6275/7134 completed (loss: 0.05025753378868103, acc: 0.9893454909324646)
[2024-12-17 02:19:19,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:19,781][root][INFO] - Training Epoch: 1/2, step 6276/7134 completed (loss: 0.04579225555062294, acc: 0.9877408146858215)
[2024-12-17 02:19:19,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:20,078][root][INFO] - Training Epoch: 1/2, step 6277/7134 completed (loss: 0.1399061679840088, acc: 0.970588207244873)
[2024-12-17 02:19:20,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:20,399][root][INFO] - Training Epoch: 1/2, step 6278/7134 completed (loss: 0.027828991413116455, acc: 0.9934210777282715)
[2024-12-17 02:19:20,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:20,724][root][INFO] - Training Epoch: 1/2, step 6279/7134 completed (loss: 0.03586815297603607, acc: 0.9914383292198181)
[2024-12-17 02:19:20,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:21,046][root][INFO] - Training Epoch: 1/2, step 6280/7134 completed (loss: 0.04125388339161873, acc: 0.9895287752151489)
[2024-12-17 02:19:21,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:21,371][root][INFO] - Training Epoch: 1/2, step 6281/7134 completed (loss: 0.04828299209475517, acc: 0.9896013736724854)
[2024-12-17 02:19:21,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:21,706][root][INFO] - Training Epoch: 1/2, step 6282/7134 completed (loss: 0.03003525361418724, acc: 0.9952830076217651)
[2024-12-17 02:19:21,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:22,036][root][INFO] - Training Epoch: 1/2, step 6283/7134 completed (loss: 0.07551338523626328, acc: 0.9890829920768738)
[2024-12-17 02:19:22,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:22,354][root][INFO] - Training Epoch: 1/2, step 6284/7134 completed (loss: 0.0878608301281929, acc: 0.9781181812286377)
[2024-12-17 02:19:22,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:22,638][root][INFO] - Training Epoch: 1/2, step 6285/7134 completed (loss: 0.0365002378821373, acc: 0.9895012974739075)
[2024-12-17 02:19:22,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:22,953][root][INFO] - Training Epoch: 1/2, step 6286/7134 completed (loss: 0.03558383136987686, acc: 0.9917762875556946)
[2024-12-17 02:19:23,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:23,276][root][INFO] - Training Epoch: 1/2, step 6287/7134 completed (loss: 0.06635599583387375, acc: 0.9834558963775635)
[2024-12-17 02:19:23,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:23,597][root][INFO] - Training Epoch: 1/2, step 6288/7134 completed (loss: 0.011261215433478355, acc: 0.9967319965362549)
[2024-12-17 02:19:23,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:23,897][root][INFO] - Training Epoch: 1/2, step 6289/7134 completed (loss: 0.04677398502826691, acc: 0.9855855703353882)
[2024-12-17 02:19:24,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:24,232][root][INFO] - Training Epoch: 1/2, step 6290/7134 completed (loss: 0.03731997311115265, acc: 0.9904000163078308)
[2024-12-17 02:19:24,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:24,533][root][INFO] - Training Epoch: 1/2, step 6291/7134 completed (loss: 0.023149164393544197, acc: 0.9945454597473145)
[2024-12-17 02:19:24,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:24,825][root][INFO] - Training Epoch: 1/2, step 6292/7134 completed (loss: 0.06461060792207718, acc: 0.984054684638977)
[2024-12-17 02:19:24,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:25,183][root][INFO] - Training Epoch: 1/2, step 6293/7134 completed (loss: 0.09167332947254181, acc: 0.979522168636322)
[2024-12-17 02:19:25,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:25,536][root][INFO] - Training Epoch: 1/2, step 6294/7134 completed (loss: 0.044005539268255234, acc: 0.987034022808075)
[2024-12-17 02:19:25,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:25,862][root][INFO] - Training Epoch: 1/2, step 6295/7134 completed (loss: 0.0432913713157177, acc: 0.9873417615890503)
[2024-12-17 02:19:25,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:26,151][root][INFO] - Training Epoch: 1/2, step 6296/7134 completed (loss: 0.07072947919368744, acc: 0.9842519760131836)
[2024-12-17 02:19:26,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:26,478][root][INFO] - Training Epoch: 1/2, step 6297/7134 completed (loss: 0.035476475954055786, acc: 0.9868852496147156)
[2024-12-17 02:19:26,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:26,806][root][INFO] - Training Epoch: 1/2, step 6298/7134 completed (loss: 0.07605570554733276, acc: 0.975944995880127)
[2024-12-17 02:19:26,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:27,147][root][INFO] - Training Epoch: 1/2, step 6299/7134 completed (loss: 0.12740597128868103, acc: 0.9680511355400085)
[2024-12-17 02:19:27,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:27,480][root][INFO] - Training Epoch: 1/2, step 6300/7134 completed (loss: 0.0736219584941864, acc: 0.9849246144294739)
[2024-12-17 02:19:27,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:27,843][root][INFO] - Training Epoch: 1/2, step 6301/7134 completed (loss: 0.022601185366511345, acc: 0.9965517520904541)
[2024-12-17 02:19:27,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:28,185][root][INFO] - Training Epoch: 1/2, step 6302/7134 completed (loss: 0.03424907475709915, acc: 0.9903314709663391)
[2024-12-17 02:19:28,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:28,557][root][INFO] - Training Epoch: 1/2, step 6303/7134 completed (loss: 0.032890260219573975, acc: 0.99148029088974)
[2024-12-17 02:19:28,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:28,905][root][INFO] - Training Epoch: 1/2, step 6304/7134 completed (loss: 0.033019907772541046, acc: 0.9918919205665588)
[2024-12-17 02:19:29,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:29,243][root][INFO] - Training Epoch: 1/2, step 6305/7134 completed (loss: 0.03271135687828064, acc: 0.9934533834457397)
[2024-12-17 02:19:29,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:29,595][root][INFO] - Training Epoch: 1/2, step 6306/7134 completed (loss: 0.07956303656101227, acc: 0.9783913493156433)
[2024-12-17 02:19:29,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:29,939][root][INFO] - Training Epoch: 1/2, step 6307/7134 completed (loss: 0.10320407897233963, acc: 0.9823633432388306)
[2024-12-17 02:19:30,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:30,289][root][INFO] - Training Epoch: 1/2, step 6308/7134 completed (loss: 0.047726765275001526, acc: 0.9877150058746338)
[2024-12-17 02:19:30,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:30,615][root][INFO] - Training Epoch: 1/2, step 6309/7134 completed (loss: 0.05315260589122772, acc: 0.9855999946594238)
[2024-12-17 02:19:30,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:30,917][root][INFO] - Training Epoch: 1/2, step 6310/7134 completed (loss: 0.11758915334939957, acc: 0.9758241772651672)
[2024-12-17 02:19:31,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:31,262][root][INFO] - Training Epoch: 1/2, step 6311/7134 completed (loss: 0.06032487004995346, acc: 0.984009861946106)
[2024-12-17 02:19:31,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:31,582][root][INFO] - Training Epoch: 1/2, step 6312/7134 completed (loss: 0.093594491481781, acc: 0.9764150977134705)
[2024-12-17 02:19:31,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:31,928][root][INFO] - Training Epoch: 1/2, step 6313/7134 completed (loss: 0.028654402121901512, acc: 0.9901840686798096)
[2024-12-17 02:19:32,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:32,286][root][INFO] - Training Epoch: 1/2, step 6314/7134 completed (loss: 0.032796405255794525, acc: 0.996216893196106)
[2024-12-17 02:19:32,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:32,625][root][INFO] - Training Epoch: 1/2, step 6315/7134 completed (loss: 0.08151990175247192, acc: 0.9819672107696533)
[2024-12-17 02:19:32,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:32,972][root][INFO] - Training Epoch: 1/2, step 6316/7134 completed (loss: 0.04390065371990204, acc: 0.987034022808075)
[2024-12-17 02:19:33,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:33,319][root][INFO] - Training Epoch: 1/2, step 6317/7134 completed (loss: 0.024424368515610695, acc: 0.9903069734573364)
[2024-12-17 02:19:33,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:33,646][root][INFO] - Training Epoch: 1/2, step 6318/7134 completed (loss: 0.03722083941102028, acc: 0.9920508861541748)
[2024-12-17 02:19:33,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:34,010][root][INFO] - Training Epoch: 1/2, step 6319/7134 completed (loss: 0.02683480829000473, acc: 0.9897119402885437)
[2024-12-17 02:19:34,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:34,385][root][INFO] - Training Epoch: 1/2, step 6320/7134 completed (loss: 0.0839117094874382, acc: 0.9747235178947449)
[2024-12-17 02:19:34,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:34,736][root][INFO] - Training Epoch: 1/2, step 6321/7134 completed (loss: 0.03254948928952217, acc: 0.9866071343421936)
[2024-12-17 02:19:34,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:35,089][root][INFO] - Training Epoch: 1/2, step 6322/7134 completed (loss: 0.061553239822387695, acc: 0.9840116500854492)
[2024-12-17 02:19:35,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:35,450][root][INFO] - Training Epoch: 1/2, step 6323/7134 completed (loss: 0.05654042959213257, acc: 0.9879879951477051)
[2024-12-17 02:19:35,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:35,795][root][INFO] - Training Epoch: 1/2, step 6324/7134 completed (loss: 0.03482646122574806, acc: 0.9933422207832336)
[2024-12-17 02:19:35,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:36,107][root][INFO] - Training Epoch: 1/2, step 6325/7134 completed (loss: 0.06713712215423584, acc: 0.9886792302131653)
[2024-12-17 02:19:36,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:36,437][root][INFO] - Training Epoch: 1/2, step 6326/7134 completed (loss: 0.08876840025186539, acc: 0.9695023894309998)
[2024-12-17 02:19:36,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:36,761][root][INFO] - Training Epoch: 1/2, step 6327/7134 completed (loss: 0.034985870122909546, acc: 0.9947229623794556)
[2024-12-17 02:19:36,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:37,093][root][INFO] - Training Epoch: 1/2, step 6328/7134 completed (loss: 0.06096133962273598, acc: 0.9824561476707458)
[2024-12-17 02:19:37,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:37,421][root][INFO] - Training Epoch: 1/2, step 6329/7134 completed (loss: 0.07038002461194992, acc: 0.978787899017334)
[2024-12-17 02:19:37,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:37,751][root][INFO] - Training Epoch: 1/2, step 6330/7134 completed (loss: 0.059813037514686584, acc: 0.9900744557380676)
[2024-12-17 02:19:37,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:38,081][root][INFO] - Training Epoch: 1/2, step 6331/7134 completed (loss: 0.03196416422724724, acc: 0.9929328560829163)
[2024-12-17 02:19:38,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:38,426][root][INFO] - Training Epoch: 1/2, step 6332/7134 completed (loss: 0.11942488700151443, acc: 0.975836455821991)
[2024-12-17 02:19:38,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:38,751][root][INFO] - Training Epoch: 1/2, step 6333/7134 completed (loss: 0.1013396754860878, acc: 0.9730158448219299)
[2024-12-17 02:19:38,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:39,038][root][INFO] - Training Epoch: 1/2, step 6334/7134 completed (loss: 0.07143557071685791, acc: 0.9791666865348816)
[2024-12-17 02:19:39,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:39,363][root][INFO] - Training Epoch: 1/2, step 6335/7134 completed (loss: 0.07181879878044128, acc: 0.9848993420600891)
[2024-12-17 02:19:39,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:39,682][root][INFO] - Training Epoch: 1/2, step 6336/7134 completed (loss: 0.07214605063199997, acc: 0.9862385392189026)
[2024-12-17 02:19:39,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:40,024][root][INFO] - Training Epoch: 1/2, step 6337/7134 completed (loss: 0.029267892241477966, acc: 0.9945255517959595)
[2024-12-17 02:19:40,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:40,363][root][INFO] - Training Epoch: 1/2, step 6338/7134 completed (loss: 0.07615727931261063, acc: 0.9810426831245422)
[2024-12-17 02:19:40,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:40,702][root][INFO] - Training Epoch: 1/2, step 6339/7134 completed (loss: 0.07917029410600662, acc: 0.9740484356880188)
[2024-12-17 02:19:40,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:41,038][root][INFO] - Training Epoch: 1/2, step 6340/7134 completed (loss: 0.041672464460134506, acc: 0.9882698059082031)
[2024-12-17 02:19:41,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:41,358][root][INFO] - Training Epoch: 1/2, step 6341/7134 completed (loss: 0.04967469722032547, acc: 0.9810246825218201)
[2024-12-17 02:19:41,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:41,723][root][INFO] - Training Epoch: 1/2, step 6342/7134 completed (loss: 0.03941529244184494, acc: 0.9878869652748108)
[2024-12-17 02:19:41,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:42,069][root][INFO] - Training Epoch: 1/2, step 6343/7134 completed (loss: 0.08526282757520676, acc: 0.9827883243560791)
[2024-12-17 02:19:42,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:42,437][root][INFO] - Training Epoch: 1/2, step 6344/7134 completed (loss: 0.04179605096578598, acc: 0.9863201379776001)
[2024-12-17 02:19:42,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:42,783][root][INFO] - Training Epoch: 1/2, step 6345/7134 completed (loss: 0.05260036140680313, acc: 0.9863387942314148)
[2024-12-17 02:19:42,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:43,115][root][INFO] - Training Epoch: 1/2, step 6346/7134 completed (loss: 0.10858503729104996, acc: 0.9767801761627197)
[2024-12-17 02:19:43,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:43,392][root][INFO] - Training Epoch: 1/2, step 6347/7134 completed (loss: 0.09022857248783112, acc: 0.9783549904823303)
[2024-12-17 02:19:43,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:43,723][root][INFO] - Training Epoch: 1/2, step 6348/7134 completed (loss: 0.14798863232135773, acc: 0.9722222089767456)
[2024-12-17 02:19:43,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:44,053][root][INFO] - Training Epoch: 1/2, step 6349/7134 completed (loss: 0.09166184812784195, acc: 0.9763205647468567)
[2024-12-17 02:19:44,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:44,392][root][INFO] - Training Epoch: 1/2, step 6350/7134 completed (loss: 0.05954635888338089, acc: 0.9795918464660645)
[2024-12-17 02:19:44,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:44,744][root][INFO] - Training Epoch: 1/2, step 6351/7134 completed (loss: 0.08923493325710297, acc: 0.9761193990707397)
[2024-12-17 02:19:44,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:45,080][root][INFO] - Training Epoch: 1/2, step 6352/7134 completed (loss: 0.16492140293121338, acc: 0.9628528952598572)
[2024-12-17 02:19:45,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:45,451][root][INFO] - Training Epoch: 1/2, step 6353/7134 completed (loss: 0.053640495985746384, acc: 0.9868228435516357)
[2024-12-17 02:19:45,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:45,799][root][INFO] - Training Epoch: 1/2, step 6354/7134 completed (loss: 0.043920908123254776, acc: 0.990304708480835)
[2024-12-17 02:19:45,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:46,125][root][INFO] - Training Epoch: 1/2, step 6355/7134 completed (loss: 0.030656298622488976, acc: 0.991909384727478)
[2024-12-17 02:19:46,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:46,448][root][INFO] - Training Epoch: 1/2, step 6356/7134 completed (loss: 0.06049589440226555, acc: 0.988041877746582)
[2024-12-17 02:19:46,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:46,787][root][INFO] - Training Epoch: 1/2, step 6357/7134 completed (loss: 0.038245610892772675, acc: 0.9902777671813965)
[2024-12-17 02:19:46,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:47,149][root][INFO] - Training Epoch: 1/2, step 6358/7134 completed (loss: 0.06169063225388527, acc: 0.9845070242881775)
[2024-12-17 02:19:47,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:47,474][root][INFO] - Training Epoch: 1/2, step 6359/7134 completed (loss: 0.09261876344680786, acc: 0.976190447807312)
[2024-12-17 02:19:47,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:47,792][root][INFO] - Training Epoch: 1/2, step 6360/7134 completed (loss: 0.05132879316806793, acc: 0.9808917045593262)
[2024-12-17 02:19:47,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:48,120][root][INFO] - Training Epoch: 1/2, step 6361/7134 completed (loss: 0.07734145224094391, acc: 0.9799270033836365)
[2024-12-17 02:19:48,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:48,472][root][INFO] - Training Epoch: 1/2, step 6362/7134 completed (loss: 0.06160212680697441, acc: 0.9832317233085632)
[2024-12-17 02:19:48,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:48,808][root][INFO] - Training Epoch: 1/2, step 6363/7134 completed (loss: 0.08168044686317444, acc: 0.9824047088623047)
[2024-12-17 02:19:48,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:49,144][root][INFO] - Training Epoch: 1/2, step 6364/7134 completed (loss: 0.03452831879258156, acc: 0.9899857044219971)
[2024-12-17 02:19:49,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:49,470][root][INFO] - Training Epoch: 1/2, step 6365/7134 completed (loss: 0.07432395219802856, acc: 0.9817073345184326)
[2024-12-17 02:19:49,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:49,828][root][INFO] - Training Epoch: 1/2, step 6366/7134 completed (loss: 0.08602401614189148, acc: 0.9762219190597534)
[2024-12-17 02:19:49,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:50,148][root][INFO] - Training Epoch: 1/2, step 6367/7134 completed (loss: 0.07201170176267624, acc: 0.9792060256004333)
[2024-12-17 02:19:50,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:50,480][root][INFO] - Training Epoch: 1/2, step 6368/7134 completed (loss: 0.0658610388636589, acc: 0.9872881174087524)
[2024-12-17 02:19:50,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:50,833][root][INFO] - Training Epoch: 1/2, step 6369/7134 completed (loss: 0.0695701390504837, acc: 0.9816031455993652)
[2024-12-17 02:19:50,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:51,201][root][INFO] - Training Epoch: 1/2, step 6370/7134 completed (loss: 0.22531743347644806, acc: 0.9498680830001831)
[2024-12-17 02:19:51,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:51,536][root][INFO] - Training Epoch: 1/2, step 6371/7134 completed (loss: 0.07656159996986389, acc: 0.9695290923118591)
[2024-12-17 02:19:51,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:51,853][root][INFO] - Training Epoch: 1/2, step 6372/7134 completed (loss: 0.18041270971298218, acc: 0.9558541178703308)
[2024-12-17 02:19:51,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:52,155][root][INFO] - Training Epoch: 1/2, step 6373/7134 completed (loss: 0.10895997285842896, acc: 0.9708561301231384)
[2024-12-17 02:19:52,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:52,495][root][INFO] - Training Epoch: 1/2, step 6374/7134 completed (loss: 0.046659789979457855, acc: 0.9896265268325806)
[2024-12-17 02:19:52,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:52,848][root][INFO] - Training Epoch: 1/2, step 6375/7134 completed (loss: 0.07531171292066574, acc: 0.9794608354568481)
[2024-12-17 02:19:52,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:53,160][root][INFO] - Training Epoch: 1/2, step 6376/7134 completed (loss: 0.03592858090996742, acc: 0.9870848655700684)
[2024-12-17 02:19:53,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:53,463][root][INFO] - Training Epoch: 1/2, step 6377/7134 completed (loss: 0.040370017290115356, acc: 0.9890109896659851)
[2024-12-17 02:19:53,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:53,831][root][INFO] - Training Epoch: 1/2, step 6378/7134 completed (loss: 0.10569717735052109, acc: 0.9667738676071167)
[2024-12-17 02:19:53,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:54,149][root][INFO] - Training Epoch: 1/2, step 6379/7134 completed (loss: 0.08350244164466858, acc: 0.9809644818305969)
[2024-12-17 02:19:54,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:54,516][root][INFO] - Training Epoch: 1/2, step 6380/7134 completed (loss: 0.1036304235458374, acc: 0.9865269660949707)
[2024-12-17 02:19:54,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:54,852][root][INFO] - Training Epoch: 1/2, step 6381/7134 completed (loss: 0.045286741107702255, acc: 0.9877862334251404)
[2024-12-17 02:19:54,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:55,206][root][INFO] - Training Epoch: 1/2, step 6382/7134 completed (loss: 0.034854594618082047, acc: 0.9934297204017639)
[2024-12-17 02:19:55,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:55,552][root][INFO] - Training Epoch: 1/2, step 6383/7134 completed (loss: 0.09009406715631485, acc: 0.9837177991867065)
[2024-12-17 02:19:55,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:55,901][root][INFO] - Training Epoch: 1/2, step 6384/7134 completed (loss: 0.07293299585580826, acc: 0.9820627570152283)
[2024-12-17 02:19:56,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:56,243][root][INFO] - Training Epoch: 1/2, step 6385/7134 completed (loss: 0.1104181632399559, acc: 0.9832335114479065)
[2024-12-17 02:19:56,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:56,611][root][INFO] - Training Epoch: 1/2, step 6386/7134 completed (loss: 0.04461841285228729, acc: 0.9914529919624329)
[2024-12-17 02:19:56,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:56,959][root][INFO] - Training Epoch: 1/2, step 6387/7134 completed (loss: 0.09017454832792282, acc: 0.9741935729980469)
[2024-12-17 02:19:57,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:57,290][root][INFO] - Training Epoch: 1/2, step 6388/7134 completed (loss: 0.08104413002729416, acc: 0.9790419340133667)
[2024-12-17 02:19:57,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:57,655][root][INFO] - Training Epoch: 1/2, step 6389/7134 completed (loss: 0.08361656963825226, acc: 0.980463981628418)
[2024-12-17 02:19:57,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:58,038][root][INFO] - Training Epoch: 1/2, step 6390/7134 completed (loss: 0.07540573179721832, acc: 0.9838056564331055)
[2024-12-17 02:19:58,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:58,384][root][INFO] - Training Epoch: 1/2, step 6391/7134 completed (loss: 0.09214745461940765, acc: 0.9743918180465698)
[2024-12-17 02:19:58,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:58,739][root][INFO] - Training Epoch: 1/2, step 6392/7134 completed (loss: 0.09723589569330215, acc: 0.9784615635871887)
[2024-12-17 02:19:58,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:59,115][root][INFO] - Training Epoch: 1/2, step 6393/7134 completed (loss: 0.0798749253153801, acc: 0.9806598424911499)
[2024-12-17 02:19:59,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:59,480][root][INFO] - Training Epoch: 1/2, step 6394/7134 completed (loss: 0.13261286914348602, acc: 0.9666203260421753)
[2024-12-17 02:19:59,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:59,852][root][INFO] - Training Epoch: 1/2, step 6395/7134 completed (loss: 0.07987909764051437, acc: 0.9815497994422913)
[2024-12-17 02:19:59,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:00,204][root][INFO] - Training Epoch: 1/2, step 6396/7134 completed (loss: 0.10500937700271606, acc: 0.9793577790260315)
[2024-12-17 02:20:00,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:00,569][root][INFO] - Training Epoch: 1/2, step 6397/7134 completed (loss: 0.055760081857442856, acc: 0.9863523840904236)
[2024-12-17 02:20:00,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:00,921][root][INFO] - Training Epoch: 1/2, step 6398/7134 completed (loss: 0.03672150894999504, acc: 0.9873417615890503)
[2024-12-17 02:20:01,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:01,277][root][INFO] - Training Epoch: 1/2, step 6399/7134 completed (loss: 0.08200778812170029, acc: 0.9774436354637146)
[2024-12-17 02:20:01,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:01,620][root][INFO] - Training Epoch: 1/2, step 6400/7134 completed (loss: 0.04684290662407875, acc: 0.9900285005569458)
[2024-12-17 02:20:01,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:01,993][root][INFO] - Training Epoch: 1/2, step 6401/7134 completed (loss: 0.07485134899616241, acc: 0.9804560542106628)
[2024-12-17 02:20:02,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:02,344][root][INFO] - Training Epoch: 1/2, step 6402/7134 completed (loss: 0.07086291909217834, acc: 0.9841089844703674)
[2024-12-17 02:20:02,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:02,662][root][INFO] - Training Epoch: 1/2, step 6403/7134 completed (loss: 0.04818101227283478, acc: 0.9872449040412903)
[2024-12-17 02:20:02,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:03,005][root][INFO] - Training Epoch: 1/2, step 6404/7134 completed (loss: 0.0326167531311512, acc: 0.9916550517082214)
[2024-12-17 02:20:03,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:03,400][root][INFO] - Training Epoch: 1/2, step 6405/7134 completed (loss: 0.0484587587416172, acc: 0.9892473220825195)
[2024-12-17 02:20:03,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:03,769][root][INFO] - Training Epoch: 1/2, step 6406/7134 completed (loss: 0.06437134742736816, acc: 0.9840365052223206)
[2024-12-17 02:20:03,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:04,139][root][INFO] - Training Epoch: 1/2, step 6407/7134 completed (loss: 0.03281959891319275, acc: 0.9934297204017639)
[2024-12-17 02:20:04,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:04,474][root][INFO] - Training Epoch: 1/2, step 6408/7134 completed (loss: 0.11322854459285736, acc: 0.9748892188072205)
[2024-12-17 02:20:04,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:04,816][root][INFO] - Training Epoch: 1/2, step 6409/7134 completed (loss: 0.05455131083726883, acc: 0.9907894730567932)
[2024-12-17 02:20:04,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:05,145][root][INFO] - Training Epoch: 1/2, step 6410/7134 completed (loss: 0.051040541380643845, acc: 0.9871323704719543)
[2024-12-17 02:20:05,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:05,454][root][INFO] - Training Epoch: 1/2, step 6411/7134 completed (loss: 0.08024223148822784, acc: 0.9849246144294739)
[2024-12-17 02:20:05,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:05,778][root][INFO] - Training Epoch: 1/2, step 6412/7134 completed (loss: 0.029886817559599876, acc: 0.9893333315849304)
[2024-12-17 02:20:05,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:06,138][root][INFO] - Training Epoch: 1/2, step 6413/7134 completed (loss: 0.05610366538167, acc: 0.9897260069847107)
[2024-12-17 02:20:06,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:06,454][root][INFO] - Training Epoch: 1/2, step 6414/7134 completed (loss: 0.01870652474462986, acc: 0.9939576983451843)
[2024-12-17 02:20:06,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:06,790][root][INFO] - Training Epoch: 1/2, step 6415/7134 completed (loss: 0.04192044213414192, acc: 0.9871630072593689)
[2024-12-17 02:20:06,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:07,119][root][INFO] - Training Epoch: 1/2, step 6416/7134 completed (loss: 0.10805763304233551, acc: 0.9734345078468323)
[2024-12-17 02:20:07,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:07,448][root][INFO] - Training Epoch: 1/2, step 6417/7134 completed (loss: 0.1378900408744812, acc: 0.9771528840065002)
[2024-12-17 02:20:07,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:07,797][root][INFO] - Training Epoch: 1/2, step 6418/7134 completed (loss: 0.18632887303829193, acc: 0.966292142868042)
[2024-12-17 02:20:07,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:08,139][root][INFO] - Training Epoch: 1/2, step 6419/7134 completed (loss: 0.12933428585529327, acc: 0.980424165725708)
[2024-12-17 02:20:08,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:08,487][root][INFO] - Training Epoch: 1/2, step 6420/7134 completed (loss: 0.07541967928409576, acc: 0.9769452214241028)
[2024-12-17 02:20:08,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:08,815][root][INFO] - Training Epoch: 1/2, step 6421/7134 completed (loss: 0.05583341047167778, acc: 0.9881129264831543)
[2024-12-17 02:20:08,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:09,164][root][INFO] - Training Epoch: 1/2, step 6422/7134 completed (loss: 0.07004053145647049, acc: 0.9835841059684753)
[2024-12-17 02:20:09,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:09,501][root][INFO] - Training Epoch: 1/2, step 6423/7134 completed (loss: 0.10977346450090408, acc: 0.9794721603393555)
[2024-12-17 02:20:09,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:09,860][root][INFO] - Training Epoch: 1/2, step 6424/7134 completed (loss: 0.06637308746576309, acc: 0.9798234701156616)
[2024-12-17 02:20:09,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:10,222][root][INFO] - Training Epoch: 1/2, step 6425/7134 completed (loss: 0.07161638140678406, acc: 0.9765319228172302)
[2024-12-17 02:20:10,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:10,587][root][INFO] - Training Epoch: 1/2, step 6426/7134 completed (loss: 0.09334830939769745, acc: 0.9722955226898193)
[2024-12-17 02:20:10,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:10,926][root][INFO] - Training Epoch: 1/2, step 6427/7134 completed (loss: 0.07551495730876923, acc: 0.9758522510528564)
[2024-12-17 02:20:11,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:11,288][root][INFO] - Training Epoch: 1/2, step 6428/7134 completed (loss: 0.042865440249443054, acc: 0.9860334992408752)
[2024-12-17 02:20:11,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:11,618][root][INFO] - Training Epoch: 1/2, step 6429/7134 completed (loss: 0.028661638498306274, acc: 0.9909090995788574)
[2024-12-17 02:20:11,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:11,975][root][INFO] - Training Epoch: 1/2, step 6430/7134 completed (loss: 0.08230175077915192, acc: 0.9827337861061096)
[2024-12-17 02:20:12,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:12,302][root][INFO] - Training Epoch: 1/2, step 6431/7134 completed (loss: 0.08143260329961777, acc: 0.9828947186470032)
[2024-12-17 02:20:12,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:12,625][root][INFO] - Training Epoch: 1/2, step 6432/7134 completed (loss: 0.2749815881252289, acc: 0.936026930809021)
[2024-12-17 02:20:12,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:12,964][root][INFO] - Training Epoch: 1/2, step 6433/7134 completed (loss: 0.08798317611217499, acc: 0.9740437269210815)
[2024-12-17 02:20:13,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:13,281][root][INFO] - Training Epoch: 1/2, step 6434/7134 completed (loss: 0.032588496804237366, acc: 0.9906790852546692)
[2024-12-17 02:20:13,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:13,612][root][INFO] - Training Epoch: 1/2, step 6435/7134 completed (loss: 0.058954183012247086, acc: 0.984402060508728)
[2024-12-17 02:20:13,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:13,963][root][INFO] - Training Epoch: 1/2, step 6436/7134 completed (loss: 0.019129706546664238, acc: 0.9938176274299622)
[2024-12-17 02:20:14,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:14,310][root][INFO] - Training Epoch: 1/2, step 6437/7134 completed (loss: 0.05416914448142052, acc: 0.9900000095367432)
[2024-12-17 02:20:14,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:14,675][root][INFO] - Training Epoch: 1/2, step 6438/7134 completed (loss: 0.06375749409198761, acc: 0.9864029884338379)
[2024-12-17 02:20:14,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:15,006][root][INFO] - Training Epoch: 1/2, step 6439/7134 completed (loss: 0.08147428929805756, acc: 0.9763779640197754)
[2024-12-17 02:20:15,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:15,383][root][INFO] - Training Epoch: 1/2, step 6440/7134 completed (loss: 0.05317217484116554, acc: 0.9808841347694397)
[2024-12-17 02:20:15,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:15,718][root][INFO] - Training Epoch: 1/2, step 6441/7134 completed (loss: 0.030915413051843643, acc: 0.9926144480705261)
[2024-12-17 02:20:15,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:16,094][root][INFO] - Training Epoch: 1/2, step 6442/7134 completed (loss: 0.051341138780117035, acc: 0.9875141978263855)
[2024-12-17 02:20:16,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:16,446][root][INFO] - Training Epoch: 1/2, step 6443/7134 completed (loss: 0.036353494971990585, acc: 0.9913366436958313)
[2024-12-17 02:20:16,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:16,808][root][INFO] - Training Epoch: 1/2, step 6444/7134 completed (loss: 0.06537153571844101, acc: 0.9804469347000122)
[2024-12-17 02:20:16,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:17,159][root][INFO] - Training Epoch: 1/2, step 6445/7134 completed (loss: 0.06507154554128647, acc: 0.9827373623847961)
[2024-12-17 02:20:17,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:17,518][root][INFO] - Training Epoch: 1/2, step 6446/7134 completed (loss: 0.04222899302840233, acc: 0.989272952079773)
[2024-12-17 02:20:17,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:17,897][root][INFO] - Training Epoch: 1/2, step 6447/7134 completed (loss: 0.06799685209989548, acc: 0.9838895201683044)
[2024-12-17 02:20:17,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:18,241][root][INFO] - Training Epoch: 1/2, step 6448/7134 completed (loss: 0.135694220662117, acc: 0.9688473343849182)
[2024-12-17 02:20:18,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:18,592][root][INFO] - Training Epoch: 1/2, step 6449/7134 completed (loss: 0.05335262045264244, acc: 0.9855072498321533)
[2024-12-17 02:20:18,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:18,954][root][INFO] - Training Epoch: 1/2, step 6450/7134 completed (loss: 0.04017239063978195, acc: 0.9866071343421936)
[2024-12-17 02:20:19,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:19,372][root][INFO] - Training Epoch: 1/2, step 6451/7134 completed (loss: 0.06484320014715195, acc: 0.9833496809005737)
[2024-12-17 02:20:19,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:19,720][root][INFO] - Training Epoch: 1/2, step 6452/7134 completed (loss: 0.03074309043586254, acc: 0.9910813570022583)
[2024-12-17 02:20:19,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:20,066][root][INFO] - Training Epoch: 1/2, step 6453/7134 completed (loss: 0.048252325505018234, acc: 0.9852150678634644)
[2024-12-17 02:20:20,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:20,448][root][INFO] - Training Epoch: 1/2, step 6454/7134 completed (loss: 0.061421915888786316, acc: 0.982332170009613)
[2024-12-17 02:20:20,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:20,788][root][INFO] - Training Epoch: 1/2, step 6455/7134 completed (loss: 0.026804570108652115, acc: 0.9915110468864441)
[2024-12-17 02:20:20,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:21,151][root][INFO] - Training Epoch: 1/2, step 6456/7134 completed (loss: 0.05346092954277992, acc: 0.987730085849762)
[2024-12-17 02:20:21,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:21,497][root][INFO] - Training Epoch: 1/2, step 6457/7134 completed (loss: 0.030375631526112556, acc: 0.9933920502662659)
[2024-12-17 02:20:21,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:21,819][root][INFO] - Training Epoch: 1/2, step 6458/7134 completed (loss: 0.07076524198055267, acc: 0.9747899174690247)
[2024-12-17 02:20:21,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:22,164][root][INFO] - Training Epoch: 1/2, step 6459/7134 completed (loss: 0.01874983124434948, acc: 0.994490385055542)
[2024-12-17 02:20:22,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:22,534][root][INFO] - Training Epoch: 1/2, step 6460/7134 completed (loss: 0.02217799983918667, acc: 0.990554928779602)
[2024-12-17 02:20:22,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:22,873][root][INFO] - Training Epoch: 1/2, step 6461/7134 completed (loss: 0.03727008402347565, acc: 0.9868593811988831)
[2024-12-17 02:20:22,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:23,209][root][INFO] - Training Epoch: 1/2, step 6462/7134 completed (loss: 0.047788120806217194, acc: 0.9876998662948608)
[2024-12-17 02:20:23,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:23,585][root][INFO] - Training Epoch: 1/2, step 6463/7134 completed (loss: 0.0457620844244957, acc: 0.984054684638977)
[2024-12-17 02:20:23,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:23,924][root][INFO] - Training Epoch: 1/2, step 6464/7134 completed (loss: 0.044924378395080566, acc: 0.9830949306488037)
[2024-12-17 02:20:24,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:24,261][root][INFO] - Training Epoch: 1/2, step 6465/7134 completed (loss: 0.03643502667546272, acc: 0.9884318709373474)
[2024-12-17 02:20:24,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:24,591][root][INFO] - Training Epoch: 1/2, step 6466/7134 completed (loss: 0.04615451768040657, acc: 0.9894319772720337)
[2024-12-17 02:20:24,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:24,935][root][INFO] - Training Epoch: 1/2, step 6467/7134 completed (loss: 0.05488649383187294, acc: 0.9725190997123718)
[2024-12-17 02:20:25,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:25,279][root][INFO] - Training Epoch: 1/2, step 6468/7134 completed (loss: 0.11573360115289688, acc: 0.9756097793579102)
[2024-12-17 02:20:25,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:25,648][root][INFO] - Training Epoch: 1/2, step 6469/7134 completed (loss: 0.07819484174251556, acc: 0.9829476475715637)
[2024-12-17 02:20:25,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:25,958][root][INFO] - Training Epoch: 1/2, step 6470/7134 completed (loss: 0.07221739739179611, acc: 0.9828850626945496)
[2024-12-17 02:20:26,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:26,313][root][INFO] - Training Epoch: 1/2, step 6471/7134 completed (loss: 0.0496380478143692, acc: 0.9853420257568359)
[2024-12-17 02:20:26,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:26,686][root][INFO] - Training Epoch: 1/2, step 6472/7134 completed (loss: 0.08411223441362381, acc: 0.9846335649490356)
[2024-12-17 02:20:26,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:27,036][root][INFO] - Training Epoch: 1/2, step 6473/7134 completed (loss: 0.02121077850461006, acc: 0.9946380853652954)
[2024-12-17 02:20:27,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:27,370][root][INFO] - Training Epoch: 1/2, step 6474/7134 completed (loss: 0.0558260940015316, acc: 0.9784656763076782)
[2024-12-17 02:20:27,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:27,710][root][INFO] - Training Epoch: 1/2, step 6475/7134 completed (loss: 0.09370193630456924, acc: 0.9766666889190674)
[2024-12-17 02:20:27,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:27,988][root][INFO] - Training Epoch: 1/2, step 6476/7134 completed (loss: 0.09072752296924591, acc: 0.9768977165222168)
[2024-12-17 02:20:28,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:28,295][root][INFO] - Training Epoch: 1/2, step 6477/7134 completed (loss: 0.061552904546260834, acc: 0.9894067645072937)
[2024-12-17 02:20:28,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:28,624][root][INFO] - Training Epoch: 1/2, step 6478/7134 completed (loss: 0.029523037374019623, acc: 0.9870848655700684)
[2024-12-17 02:20:28,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:28,962][root][INFO] - Training Epoch: 1/2, step 6479/7134 completed (loss: 0.08354853093624115, acc: 0.981574535369873)
[2024-12-17 02:20:29,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:29,281][root][INFO] - Training Epoch: 1/2, step 6480/7134 completed (loss: 0.16413645446300507, acc: 0.9570446610450745)
[2024-12-17 02:20:29,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:29,617][root][INFO] - Training Epoch: 1/2, step 6481/7134 completed (loss: 0.04374172165989876, acc: 0.9846938848495483)
[2024-12-17 02:20:29,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:29,970][root][INFO] - Training Epoch: 1/2, step 6482/7134 completed (loss: 0.10155027359724045, acc: 0.9750000238418579)
[2024-12-17 02:20:30,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:30,302][root][INFO] - Training Epoch: 1/2, step 6483/7134 completed (loss: 0.13287724554538727, acc: 0.9747292399406433)
[2024-12-17 02:20:30,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:30,629][root][INFO] - Training Epoch: 1/2, step 6484/7134 completed (loss: 0.07067110389471054, acc: 0.9853372573852539)
[2024-12-17 02:20:30,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:30,999][root][INFO] - Training Epoch: 1/2, step 6485/7134 completed (loss: 0.06482992321252823, acc: 0.9841897487640381)
[2024-12-17 02:20:31,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:31,325][root][INFO] - Training Epoch: 1/2, step 6486/7134 completed (loss: 0.2025776356458664, acc: 0.9563636183738708)
[2024-12-17 02:20:31,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:31,589][root][INFO] - Training Epoch: 1/2, step 6487/7134 completed (loss: 0.2522282898426056, acc: 0.9433198571205139)
[2024-12-17 02:20:31,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:31,900][root][INFO] - Training Epoch: 1/2, step 6488/7134 completed (loss: 0.13340696692466736, acc: 0.9637826681137085)
[2024-12-17 02:20:32,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:32,221][root][INFO] - Training Epoch: 1/2, step 6489/7134 completed (loss: 0.1812475323677063, acc: 0.9626865386962891)
[2024-12-17 02:20:32,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:32,521][root][INFO] - Training Epoch: 1/2, step 6490/7134 completed (loss: 0.09854099154472351, acc: 0.9759863018989563)
[2024-12-17 02:20:32,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:32,872][root][INFO] - Training Epoch: 1/2, step 6491/7134 completed (loss: 0.15165981650352478, acc: 0.973009467124939)
[2024-12-17 02:20:32,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:33,202][root][INFO] - Training Epoch: 1/2, step 6492/7134 completed (loss: 0.06192357465624809, acc: 0.9818887710571289)
[2024-12-17 02:20:33,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:33,564][root][INFO] - Training Epoch: 1/2, step 6493/7134 completed (loss: 0.13416434824466705, acc: 0.9656488299369812)
[2024-12-17 02:20:33,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:33,873][root][INFO] - Training Epoch: 1/2, step 6494/7134 completed (loss: 0.0884898230433464, acc: 0.9704797267913818)
[2024-12-17 02:20:33,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:34,213][root][INFO] - Training Epoch: 1/2, step 6495/7134 completed (loss: 0.1236756294965744, acc: 0.9635343551635742)
[2024-12-17 02:20:34,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:34,573][root][INFO] - Training Epoch: 1/2, step 6496/7134 completed (loss: 0.07869084179401398, acc: 0.983627200126648)
[2024-12-17 02:20:34,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:34,906][root][INFO] - Training Epoch: 1/2, step 6497/7134 completed (loss: 0.18886315822601318, acc: 0.9517884850502014)
[2024-12-17 02:20:35,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:35,249][root][INFO] - Training Epoch: 1/2, step 6498/7134 completed (loss: 0.04768455773591995, acc: 0.9865853786468506)
[2024-12-17 02:20:35,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:35,595][root][INFO] - Training Epoch: 1/2, step 6499/7134 completed (loss: 0.07430994510650635, acc: 0.9850560426712036)
[2024-12-17 02:20:35,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:35,960][root][INFO] - Training Epoch: 1/2, step 6500/7134 completed (loss: 0.1447916477918625, acc: 0.9663865566253662)
[2024-12-17 02:20:36,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:36,302][root][INFO] - Training Epoch: 1/2, step 6501/7134 completed (loss: 0.1790405809879303, acc: 0.9578005075454712)
[2024-12-17 02:20:36,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:36,724][root][INFO] - Training Epoch: 1/2, step 6502/7134 completed (loss: 0.07083049416542053, acc: 0.980997622013092)
[2024-12-17 02:20:36,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:37,046][root][INFO] - Training Epoch: 1/2, step 6503/7134 completed (loss: 0.06318313628435135, acc: 0.9882698059082031)
[2024-12-17 02:20:37,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:37,355][root][INFO] - Training Epoch: 1/2, step 6504/7134 completed (loss: 0.12286583334207535, acc: 0.9668246507644653)
[2024-12-17 02:20:37,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:37,699][root][INFO] - Training Epoch: 1/2, step 6505/7134 completed (loss: 0.13575507700443268, acc: 0.969565212726593)
[2024-12-17 02:20:37,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:38,071][root][INFO] - Training Epoch: 1/2, step 6506/7134 completed (loss: 0.1406017541885376, acc: 0.9652551412582397)
[2024-12-17 02:20:38,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:38,422][root][INFO] - Training Epoch: 1/2, step 6507/7134 completed (loss: 0.17970111966133118, acc: 0.95158851146698)
[2024-12-17 02:20:38,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:38,783][root][INFO] - Training Epoch: 1/2, step 6508/7134 completed (loss: 0.08575154095888138, acc: 0.9765258431434631)
[2024-12-17 02:20:38,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:39,136][root][INFO] - Training Epoch: 1/2, step 6509/7134 completed (loss: 0.07357476651668549, acc: 0.9778516292572021)
[2024-12-17 02:20:39,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:39,523][root][INFO] - Training Epoch: 1/2, step 6510/7134 completed (loss: 0.07053766399621964, acc: 0.97991544008255)
[2024-12-17 02:20:39,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:39,863][root][INFO] - Training Epoch: 1/2, step 6511/7134 completed (loss: 0.09173572063446045, acc: 0.9789473414421082)
[2024-12-17 02:20:39,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:40,094][root][INFO] - Training Epoch: 1/2, step 6512/7134 completed (loss: 0.06139693781733513, acc: 0.9733840227127075)
[2024-12-17 02:20:40,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:40,440][root][INFO] - Training Epoch: 1/2, step 6513/7134 completed (loss: 0.09515925496816635, acc: 0.9768518805503845)
[2024-12-17 02:20:40,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:40,763][root][INFO] - Training Epoch: 1/2, step 6514/7134 completed (loss: 0.0839662030339241, acc: 0.9758522510528564)
[2024-12-17 02:20:40,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:41,134][root][INFO] - Training Epoch: 1/2, step 6515/7134 completed (loss: 0.08404159545898438, acc: 0.970812201499939)
[2024-12-17 02:20:41,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:41,495][root][INFO] - Training Epoch: 1/2, step 6516/7134 completed (loss: 0.12350590527057648, acc: 0.9668434858322144)
[2024-12-17 02:20:41,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:41,845][root][INFO] - Training Epoch: 1/2, step 6517/7134 completed (loss: 0.05440784618258476, acc: 0.9855263233184814)
[2024-12-17 02:20:41,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:42,195][root][INFO] - Training Epoch: 1/2, step 6518/7134 completed (loss: 0.045131221413612366, acc: 0.9917241334915161)
[2024-12-17 02:20:42,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:42,530][root][INFO] - Training Epoch: 1/2, step 6519/7134 completed (loss: 0.08345938473939896, acc: 0.9858155846595764)
[2024-12-17 02:20:42,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:42,852][root][INFO] - Training Epoch: 1/2, step 6520/7134 completed (loss: 0.06961707770824432, acc: 0.9828926920890808)
[2024-12-17 02:20:42,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:43,179][root][INFO] - Training Epoch: 1/2, step 6521/7134 completed (loss: 0.055440593510866165, acc: 0.9856770634651184)
[2024-12-17 02:20:43,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:43,511][root][INFO] - Training Epoch: 1/2, step 6522/7134 completed (loss: 0.06881729513406754, acc: 0.9794167876243591)
[2024-12-17 02:20:43,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:43,826][root][INFO] - Training Epoch: 1/2, step 6523/7134 completed (loss: 0.12871018052101135, acc: 0.9582577347755432)
[2024-12-17 02:20:43,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:44,176][root][INFO] - Training Epoch: 1/2, step 6524/7134 completed (loss: 0.10448979586362839, acc: 0.9768637418746948)
[2024-12-17 02:20:44,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:44,519][root][INFO] - Training Epoch: 1/2, step 6525/7134 completed (loss: 0.02802315726876259, acc: 0.9919678568840027)
[2024-12-17 02:20:44,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:44,914][root][INFO] - Training Epoch: 1/2, step 6526/7134 completed (loss: 0.10363748669624329, acc: 0.9679897427558899)
[2024-12-17 02:20:45,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:45,241][root][INFO] - Training Epoch: 1/2, step 6527/7134 completed (loss: 0.06886163353919983, acc: 0.9836795330047607)
[2024-12-17 02:20:45,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:45,554][root][INFO] - Training Epoch: 1/2, step 6528/7134 completed (loss: 0.10928818583488464, acc: 0.9783393740653992)
[2024-12-17 02:20:45,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:45,864][root][INFO] - Training Epoch: 1/2, step 6529/7134 completed (loss: 0.12510479986667633, acc: 0.9793233275413513)
[2024-12-17 02:20:45,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:46,206][root][INFO] - Training Epoch: 1/2, step 6530/7134 completed (loss: 0.05619780346751213, acc: 0.9828816056251526)
[2024-12-17 02:20:46,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:46,548][root][INFO] - Training Epoch: 1/2, step 6531/7134 completed (loss: 0.05686280503869057, acc: 0.9826589822769165)
[2024-12-17 02:20:46,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:46,900][root][INFO] - Training Epoch: 1/2, step 6532/7134 completed (loss: 0.07259781658649445, acc: 0.9799749851226807)
[2024-12-17 02:20:47,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:47,237][root][INFO] - Training Epoch: 1/2, step 6533/7134 completed (loss: 0.03934018313884735, acc: 0.9910447597503662)
[2024-12-17 02:20:47,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:47,556][root][INFO] - Training Epoch: 1/2, step 6534/7134 completed (loss: 0.096625916659832, acc: 0.9798927903175354)
[2024-12-17 02:20:47,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:47,869][root][INFO] - Training Epoch: 1/2, step 6535/7134 completed (loss: 0.03285996988415718, acc: 0.9906322956085205)
[2024-12-17 02:20:47,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:48,190][root][INFO] - Training Epoch: 1/2, step 6536/7134 completed (loss: 0.0751153901219368, acc: 0.9841269850730896)
[2024-12-17 02:20:48,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:48,496][root][INFO] - Training Epoch: 1/2, step 6537/7134 completed (loss: 0.09549594670534134, acc: 0.9734513163566589)
[2024-12-17 02:20:48,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:48,822][root][INFO] - Training Epoch: 1/2, step 6538/7134 completed (loss: 0.09786485135555267, acc: 0.9733570218086243)
[2024-12-17 02:20:48,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:49,069][root][INFO] - Training Epoch: 1/2, step 6539/7134 completed (loss: 0.01933380402624607, acc: 0.9939758777618408)
[2024-12-17 02:20:49,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:49,401][root][INFO] - Training Epoch: 1/2, step 6540/7134 completed (loss: 0.3561561107635498, acc: 0.9289617538452148)
[2024-12-17 02:20:49,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:49,772][root][INFO] - Training Epoch: 1/2, step 6541/7134 completed (loss: 0.10659633576869965, acc: 0.9779411554336548)
[2024-12-17 02:20:49,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:50,134][root][INFO] - Training Epoch: 1/2, step 6542/7134 completed (loss: 0.09829039126634598, acc: 0.9762712121009827)
[2024-12-17 02:20:50,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:50,491][root][INFO] - Training Epoch: 1/2, step 6543/7134 completed (loss: 0.048771295696496964, acc: 0.9874213933944702)
[2024-12-17 02:20:50,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:50,835][root][INFO] - Training Epoch: 1/2, step 6544/7134 completed (loss: 0.06907987594604492, acc: 0.9880715608596802)
[2024-12-17 02:20:50,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:51,158][root][INFO] - Training Epoch: 1/2, step 6545/7134 completed (loss: 0.06954583525657654, acc: 0.9869888424873352)
[2024-12-17 02:20:51,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:51,461][root][INFO] - Training Epoch: 1/2, step 6546/7134 completed (loss: 0.06900892406702042, acc: 0.9837133288383484)
[2024-12-17 02:20:51,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:51,784][root][INFO] - Training Epoch: 1/2, step 6547/7134 completed (loss: 0.15083055198192596, acc: 0.9659284353256226)
[2024-12-17 02:20:51,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:52,061][root][INFO] - Training Epoch: 1/2, step 6548/7134 completed (loss: 0.05417298898100853, acc: 0.976190447807312)
[2024-12-17 02:20:52,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:52,389][root][INFO] - Training Epoch: 1/2, step 6549/7134 completed (loss: 0.1047179326415062, acc: 0.9766990542411804)
[2024-12-17 02:20:52,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:52,710][root][INFO] - Training Epoch: 1/2, step 6550/7134 completed (loss: 0.10717516392469406, acc: 0.9723076820373535)
[2024-12-17 02:20:52,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:53,065][root][INFO] - Training Epoch: 1/2, step 6551/7134 completed (loss: 0.045472290366888046, acc: 0.9908883571624756)
[2024-12-17 02:20:53,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:53,430][root][INFO] - Training Epoch: 1/2, step 6552/7134 completed (loss: 0.06873877346515656, acc: 0.987051784992218)
[2024-12-17 02:20:53,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:53,792][root][INFO] - Training Epoch: 1/2, step 6553/7134 completed (loss: 0.0902041494846344, acc: 0.9770992398262024)
[2024-12-17 02:20:53,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:54,170][root][INFO] - Training Epoch: 1/2, step 6554/7134 completed (loss: 0.062151867896318436, acc: 0.9870270490646362)
[2024-12-17 02:20:54,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:54,551][root][INFO] - Training Epoch: 1/2, step 6555/7134 completed (loss: 0.12043021619319916, acc: 0.9678068161010742)
[2024-12-17 02:20:54,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:54,892][root][INFO] - Training Epoch: 1/2, step 6556/7134 completed (loss: 0.08092735707759857, acc: 0.9821052551269531)
[2024-12-17 02:20:55,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:55,264][root][INFO] - Training Epoch: 1/2, step 6557/7134 completed (loss: 0.07357458025217056, acc: 0.9788306355476379)
[2024-12-17 02:20:55,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:55,643][root][INFO] - Training Epoch: 1/2, step 6558/7134 completed (loss: 0.099373959004879, acc: 0.9717391133308411)
[2024-12-17 02:20:55,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:55,992][root][INFO] - Training Epoch: 1/2, step 6559/7134 completed (loss: 0.05819390341639519, acc: 0.9861303567886353)
[2024-12-17 02:20:56,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:56,423][root][INFO] - Training Epoch: 1/2, step 6560/7134 completed (loss: 0.06839391589164734, acc: 0.9797859787940979)
[2024-12-17 02:20:56,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:56,762][root][INFO] - Training Epoch: 1/2, step 6561/7134 completed (loss: 0.060915395617485046, acc: 0.984795331954956)
[2024-12-17 02:20:56,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:57,102][root][INFO] - Training Epoch: 1/2, step 6562/7134 completed (loss: 0.06871912628412247, acc: 0.980567991733551)
[2024-12-17 02:20:57,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:57,468][root][INFO] - Training Epoch: 1/2, step 6563/7134 completed (loss: 0.07908987998962402, acc: 0.9837020039558411)
[2024-12-17 02:20:57,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:57,821][root][INFO] - Training Epoch: 1/2, step 6564/7134 completed (loss: 0.08403956145048141, acc: 0.9797570705413818)
[2024-12-17 02:20:57,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:58,190][root][INFO] - Training Epoch: 1/2, step 6565/7134 completed (loss: 0.07051018625497818, acc: 0.9788583517074585)
[2024-12-17 02:20:58,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:58,578][root][INFO] - Training Epoch: 1/2, step 6566/7134 completed (loss: 0.07119400799274445, acc: 0.9810066223144531)
[2024-12-17 02:20:58,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:58,963][root][INFO] - Training Epoch: 1/2, step 6567/7134 completed (loss: 0.05860299617052078, acc: 0.9827761054039001)
[2024-12-17 02:20:59,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:59,327][root][INFO] - Training Epoch: 1/2, step 6568/7134 completed (loss: 0.05482236295938492, acc: 0.9823455214500427)
[2024-12-17 02:20:59,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:59,674][root][INFO] - Training Epoch: 1/2, step 6569/7134 completed (loss: 0.038584478199481964, acc: 0.9912087917327881)
[2024-12-17 02:20:59,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:00,028][root][INFO] - Training Epoch: 1/2, step 6570/7134 completed (loss: 0.03942257910966873, acc: 0.9895470142364502)
[2024-12-17 02:21:00,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:00,349][root][INFO] - Training Epoch: 1/2, step 6571/7134 completed (loss: 0.04782449081540108, acc: 0.9869109988212585)
[2024-12-17 02:21:00,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:00,702][root][INFO] - Training Epoch: 1/2, step 6572/7134 completed (loss: 0.06842581182718277, acc: 0.9822616577148438)
[2024-12-17 02:21:00,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:01,063][root][INFO] - Training Epoch: 1/2, step 6573/7134 completed (loss: 0.037475697696208954, acc: 0.98758465051651)
[2024-12-17 02:21:01,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:01,432][root][INFO] - Training Epoch: 1/2, step 6574/7134 completed (loss: 0.03148595988750458, acc: 0.9897750616073608)
[2024-12-17 02:21:01,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:01,822][root][INFO] - Training Epoch: 1/2, step 6575/7134 completed (loss: 0.08094362914562225, acc: 0.9756906032562256)
[2024-12-17 02:21:01,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:02,179][root][INFO] - Training Epoch: 1/2, step 6576/7134 completed (loss: 0.0373305082321167, acc: 0.993697464466095)
[2024-12-17 02:21:02,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:02,536][root][INFO] - Training Epoch: 1/2, step 6577/7134 completed (loss: 0.08676489442586899, acc: 0.981792688369751)
[2024-12-17 02:21:02,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:03,052][root][INFO] - Training Epoch: 1/2, step 6578/7134 completed (loss: 0.06057460978627205, acc: 0.9839857816696167)
[2024-12-17 02:21:03,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:03,355][root][INFO] - Training Epoch: 1/2, step 6579/7134 completed (loss: 0.05579598620533943, acc: 0.9854809641838074)
[2024-12-17 02:21:03,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:03,716][root][INFO] - Training Epoch: 1/2, step 6580/7134 completed (loss: 0.051214247941970825, acc: 0.9858823418617249)
[2024-12-17 02:21:03,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:04,061][root][INFO] - Training Epoch: 1/2, step 6581/7134 completed (loss: 0.05313439667224884, acc: 0.984009861946106)
[2024-12-17 02:21:04,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:04,367][root][INFO] - Training Epoch: 1/2, step 6582/7134 completed (loss: 0.08065713196992874, acc: 0.9769784212112427)
[2024-12-17 02:21:04,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:04,729][root][INFO] - Training Epoch: 1/2, step 6583/7134 completed (loss: 0.03208288922905922, acc: 0.9885583519935608)
[2024-12-17 02:21:04,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:05,086][root][INFO] - Training Epoch: 1/2, step 6584/7134 completed (loss: 0.0714886337518692, acc: 0.9804161787033081)
[2024-12-17 02:21:05,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:05,434][root][INFO] - Training Epoch: 1/2, step 6585/7134 completed (loss: 0.07480575889348984, acc: 0.9851973652839661)
[2024-12-17 02:21:05,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:05,777][root][INFO] - Training Epoch: 1/2, step 6586/7134 completed (loss: 0.059212327003479004, acc: 0.9896373152732849)
[2024-12-17 02:21:05,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:06,130][root][INFO] - Training Epoch: 1/2, step 6587/7134 completed (loss: 0.10221024602651596, acc: 0.974056601524353)
[2024-12-17 02:21:06,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:06,456][root][INFO] - Training Epoch: 1/2, step 6588/7134 completed (loss: 0.07163889706134796, acc: 0.9874213933944702)
[2024-12-17 02:21:06,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:06,798][root][INFO] - Training Epoch: 1/2, step 6589/7134 completed (loss: 0.07198337465524673, acc: 0.9792531132698059)
[2024-12-17 02:21:06,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:07,165][root][INFO] - Training Epoch: 1/2, step 6590/7134 completed (loss: 0.08906576782464981, acc: 0.9790453910827637)
[2024-12-17 02:21:07,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:07,531][root][INFO] - Training Epoch: 1/2, step 6591/7134 completed (loss: 0.06124589592218399, acc: 0.9826517701148987)
[2024-12-17 02:21:07,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:07,893][root][INFO] - Training Epoch: 1/2, step 6592/7134 completed (loss: 0.10703404247760773, acc: 0.975028395652771)
[2024-12-17 02:21:08,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:08,223][root][INFO] - Training Epoch: 1/2, step 6593/7134 completed (loss: 0.06474438309669495, acc: 0.9832572340965271)
[2024-12-17 02:21:08,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:08,574][root][INFO] - Training Epoch: 1/2, step 6594/7134 completed (loss: 0.04626628756523132, acc: 0.9882628917694092)
[2024-12-17 02:21:08,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:08,916][root][INFO] - Training Epoch: 1/2, step 6595/7134 completed (loss: 0.07304199784994125, acc: 0.9807121753692627)
[2024-12-17 02:21:09,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:09,231][root][INFO] - Training Epoch: 1/2, step 6596/7134 completed (loss: 0.05773107334971428, acc: 0.987860381603241)
[2024-12-17 02:21:09,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:09,589][root][INFO] - Training Epoch: 1/2, step 6597/7134 completed (loss: 0.06144634634256363, acc: 0.9858490824699402)
[2024-12-17 02:21:09,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:09,937][root][INFO] - Training Epoch: 1/2, step 6598/7134 completed (loss: 0.05979728326201439, acc: 0.9852349162101746)
[2024-12-17 02:21:10,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:10,325][root][INFO] - Training Epoch: 1/2, step 6599/7134 completed (loss: 0.0836528018116951, acc: 0.9734299778938293)
[2024-12-17 02:21:10,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:10,648][root][INFO] - Training Epoch: 1/2, step 6600/7134 completed (loss: 0.0816195160150528, acc: 0.9730586409568787)
[2024-12-17 02:21:10,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:11,009][root][INFO] - Training Epoch: 1/2, step 6601/7134 completed (loss: 0.09579736739397049, acc: 0.9730046987533569)
[2024-12-17 02:21:11,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:11,365][root][INFO] - Training Epoch: 1/2, step 6602/7134 completed (loss: 0.05828440561890602, acc: 0.9891696572303772)
[2024-12-17 02:21:11,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:11,722][root][INFO] - Training Epoch: 1/2, step 6603/7134 completed (loss: 0.053605806082487106, acc: 0.9817671775817871)
[2024-12-17 02:21:11,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:12,018][root][INFO] - Training Epoch: 1/2, step 6604/7134 completed (loss: 0.11077671498060226, acc: 0.9741379022598267)
[2024-12-17 02:21:12,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:12,351][root][INFO] - Training Epoch: 1/2, step 6605/7134 completed (loss: 0.12597578763961792, acc: 0.9681881070137024)
[2024-12-17 02:21:12,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:12,709][root][INFO] - Training Epoch: 1/2, step 6606/7134 completed (loss: 0.05896356701850891, acc: 0.9848484992980957)
[2024-12-17 02:21:12,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:13,067][root][INFO] - Training Epoch: 1/2, step 6607/7134 completed (loss: 0.1179688423871994, acc: 0.9813829660415649)
[2024-12-17 02:21:13,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:13,428][root][INFO] - Training Epoch: 1/2, step 6608/7134 completed (loss: 0.041725967079401016, acc: 0.9893758296966553)
[2024-12-17 02:21:13,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:13,778][root][INFO] - Training Epoch: 1/2, step 6609/7134 completed (loss: 0.10507767647504807, acc: 0.9718826413154602)
[2024-12-17 02:21:13,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:14,106][root][INFO] - Training Epoch: 1/2, step 6610/7134 completed (loss: 0.10507185012102127, acc: 0.9716981053352356)
[2024-12-17 02:21:14,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:14,422][root][INFO] - Training Epoch: 1/2, step 6611/7134 completed (loss: 0.14361892640590668, acc: 0.9599999785423279)
[2024-12-17 02:21:14,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:14,795][root][INFO] - Training Epoch: 1/2, step 6612/7134 completed (loss: 0.11220245808362961, acc: 0.9743290543556213)
[2024-12-17 02:21:14,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:15,171][root][INFO] - Training Epoch: 1/2, step 6613/7134 completed (loss: 0.06406276673078537, acc: 0.9821428656578064)
[2024-12-17 02:21:15,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:15,515][root][INFO] - Training Epoch: 1/2, step 6614/7134 completed (loss: 0.10443319380283356, acc: 0.9768977165222168)
[2024-12-17 02:21:15,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:15,858][root][INFO] - Training Epoch: 1/2, step 6615/7134 completed (loss: 0.09698373079299927, acc: 0.9787836074829102)
[2024-12-17 02:21:15,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:16,223][root][INFO] - Training Epoch: 1/2, step 6616/7134 completed (loss: 0.05232992023229599, acc: 0.9882628917694092)
[2024-12-17 02:21:16,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:16,583][root][INFO] - Training Epoch: 1/2, step 6617/7134 completed (loss: 0.05483339726924896, acc: 0.9812679886817932)
[2024-12-17 02:21:16,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:16,923][root][INFO] - Training Epoch: 1/2, step 6618/7134 completed (loss: 0.06580163538455963, acc: 0.9821693897247314)
[2024-12-17 02:21:17,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:17,296][root][INFO] - Training Epoch: 1/2, step 6619/7134 completed (loss: 0.05810356140136719, acc: 0.9831838607788086)
[2024-12-17 02:21:17,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:17,684][root][INFO] - Training Epoch: 1/2, step 6620/7134 completed (loss: 0.07797698676586151, acc: 0.9724896550178528)
[2024-12-17 02:21:17,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:18,027][root][INFO] - Training Epoch: 1/2, step 6621/7134 completed (loss: 0.06707028299570084, acc: 0.9838150143623352)
[2024-12-17 02:21:18,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:18,379][root][INFO] - Training Epoch: 1/2, step 6622/7134 completed (loss: 0.08540483564138412, acc: 0.9767759442329407)
[2024-12-17 02:21:18,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:18,723][root][INFO] - Training Epoch: 1/2, step 6623/7134 completed (loss: 0.03925429657101631, acc: 0.9886792302131653)
[2024-12-17 02:21:18,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:19,070][root][INFO] - Training Epoch: 1/2, step 6624/7134 completed (loss: 0.058056339621543884, acc: 0.9830729365348816)
[2024-12-17 02:21:19,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:19,411][root][INFO] - Training Epoch: 1/2, step 6625/7134 completed (loss: 0.03923851251602173, acc: 0.9862448573112488)
[2024-12-17 02:21:19,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:19,770][root][INFO] - Training Epoch: 1/2, step 6626/7134 completed (loss: 0.04281247779726982, acc: 0.9854545593261719)
[2024-12-17 02:21:19,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:20,141][root][INFO] - Training Epoch: 1/2, step 6627/7134 completed (loss: 0.05422792211174965, acc: 0.9848648905754089)
[2024-12-17 02:21:20,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:20,503][root][INFO] - Training Epoch: 1/2, step 6628/7134 completed (loss: 0.07854960858821869, acc: 0.9822485446929932)
[2024-12-17 02:21:20,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:20,822][root][INFO] - Training Epoch: 1/2, step 6629/7134 completed (loss: 0.10099649429321289, acc: 0.9743260741233826)
[2024-12-17 02:21:20,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:21,215][root][INFO] - Training Epoch: 1/2, step 6630/7134 completed (loss: 0.08404804766178131, acc: 0.9810479283332825)
[2024-12-17 02:21:21,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:21,568][root][INFO] - Training Epoch: 1/2, step 6631/7134 completed (loss: 0.07301346957683563, acc: 0.9829620122909546)
[2024-12-17 02:21:21,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:21,974][root][INFO] - Training Epoch: 1/2, step 6632/7134 completed (loss: 0.03863239288330078, acc: 0.9921259880065918)
[2024-12-17 02:21:22,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:22,314][root][INFO] - Training Epoch: 1/2, step 6633/7134 completed (loss: 0.06783746182918549, acc: 0.9865853786468506)
[2024-12-17 02:21:22,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:22,647][root][INFO] - Training Epoch: 1/2, step 6634/7134 completed (loss: 0.06640923768281937, acc: 0.9838998317718506)
[2024-12-17 02:21:22,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:22,978][root][INFO] - Training Epoch: 1/2, step 6635/7134 completed (loss: 0.14499348402023315, acc: 0.9680306911468506)
[2024-12-17 02:21:23,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:23,343][root][INFO] - Training Epoch: 1/2, step 6636/7134 completed (loss: 0.10302477329969406, acc: 0.9691780805587769)
[2024-12-17 02:21:23,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:23,685][root][INFO] - Training Epoch: 1/2, step 6637/7134 completed (loss: 0.06319016963243484, acc: 0.9854439496994019)
[2024-12-17 02:21:23,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:24,038][root][INFO] - Training Epoch: 1/2, step 6638/7134 completed (loss: 0.03609912097454071, acc: 0.9923760890960693)
[2024-12-17 02:21:24,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:24,395][root][INFO] - Training Epoch: 1/2, step 6639/7134 completed (loss: 0.08016025274991989, acc: 0.9776452779769897)
[2024-12-17 02:21:24,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:24,750][root][INFO] - Training Epoch: 1/2, step 6640/7134 completed (loss: 0.06274183094501495, acc: 0.9739663004875183)
[2024-12-17 02:21:24,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:25,107][root][INFO] - Training Epoch: 1/2, step 6641/7134 completed (loss: 0.14169520139694214, acc: 0.9706916809082031)
[2024-12-17 02:21:25,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:25,459][root][INFO] - Training Epoch: 1/2, step 6642/7134 completed (loss: 0.0588613860309124, acc: 0.9864457845687866)
[2024-12-17 02:21:25,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:25,830][root][INFO] - Training Epoch: 1/2, step 6643/7134 completed (loss: 0.08298519253730774, acc: 0.9801849126815796)
[2024-12-17 02:21:25,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:26,194][root][INFO] - Training Epoch: 1/2, step 6644/7134 completed (loss: 0.13264703750610352, acc: 0.9715157747268677)
[2024-12-17 02:21:26,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:26,541][root][INFO] - Training Epoch: 1/2, step 6645/7134 completed (loss: 0.06679357588291168, acc: 0.9815725088119507)
[2024-12-17 02:21:26,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:26,915][root][INFO] - Training Epoch: 1/2, step 6646/7134 completed (loss: 0.06955781579017639, acc: 0.9834801554679871)
[2024-12-17 02:21:27,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:27,261][root][INFO] - Training Epoch: 1/2, step 6647/7134 completed (loss: 0.04344983771443367, acc: 0.989130437374115)
[2024-12-17 02:21:27,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:27,624][root][INFO] - Training Epoch: 1/2, step 6648/7134 completed (loss: 0.14557182788848877, acc: 0.9696000218391418)
[2024-12-17 02:21:27,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:28,002][root][INFO] - Training Epoch: 1/2, step 6649/7134 completed (loss: 0.07913091033697128, acc: 0.9740259647369385)
[2024-12-17 02:21:28,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:28,395][root][INFO] - Training Epoch: 1/2, step 6650/7134 completed (loss: 0.04823987931013107, acc: 0.9888392686843872)
[2024-12-17 02:21:28,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:28,776][root][INFO] - Training Epoch: 1/2, step 6651/7134 completed (loss: 0.06695260852575302, acc: 0.9863574504852295)
[2024-12-17 02:21:28,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:29,131][root][INFO] - Training Epoch: 1/2, step 6652/7134 completed (loss: 0.08398175984621048, acc: 0.9758453965187073)
[2024-12-17 02:21:29,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:29,494][root][INFO] - Training Epoch: 1/2, step 6653/7134 completed (loss: 0.0891743153333664, acc: 0.9715224504470825)
[2024-12-17 02:21:29,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:29,835][root][INFO] - Training Epoch: 1/2, step 6654/7134 completed (loss: 0.09322793781757355, acc: 0.9751937985420227)
[2024-12-17 02:21:29,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:30,177][root][INFO] - Training Epoch: 1/2, step 6655/7134 completed (loss: 0.09983986616134644, acc: 0.9751861095428467)
[2024-12-17 02:21:30,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:30,510][root][INFO] - Training Epoch: 1/2, step 6656/7134 completed (loss: 0.069370336830616, acc: 0.9847328066825867)
[2024-12-17 02:21:30,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:30,858][root][INFO] - Training Epoch: 1/2, step 6657/7134 completed (loss: 0.1057058721780777, acc: 0.9688346982002258)
[2024-12-17 02:21:30,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:31,223][root][INFO] - Training Epoch: 1/2, step 6658/7134 completed (loss: 0.04379143938422203, acc: 0.9870967864990234)
[2024-12-17 02:21:31,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:31,606][root][INFO] - Training Epoch: 1/2, step 6659/7134 completed (loss: 0.05203264579176903, acc: 0.984375)
[2024-12-17 02:21:31,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:31,964][root][INFO] - Training Epoch: 1/2, step 6660/7134 completed (loss: 0.07960674166679382, acc: 0.9801587462425232)
[2024-12-17 02:21:32,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:32,341][root][INFO] - Training Epoch: 1/2, step 6661/7134 completed (loss: 0.054196733981370926, acc: 0.9851484894752502)
[2024-12-17 02:21:32,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:32,671][root][INFO] - Training Epoch: 1/2, step 6662/7134 completed (loss: 0.12994860112667084, acc: 0.9656652212142944)
[2024-12-17 02:21:32,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:33,029][root][INFO] - Training Epoch: 1/2, step 6663/7134 completed (loss: 0.06930861622095108, acc: 0.985792338848114)
[2024-12-17 02:21:33,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:33,345][root][INFO] - Training Epoch: 1/2, step 6664/7134 completed (loss: 0.13989266753196716, acc: 0.955719530582428)
[2024-12-17 02:21:33,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:33,671][root][INFO] - Training Epoch: 1/2, step 6665/7134 completed (loss: 0.12015434354543686, acc: 0.9577922224998474)
[2024-12-17 02:21:33,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:34,037][root][INFO] - Training Epoch: 1/2, step 6666/7134 completed (loss: 0.0446988120675087, acc: 0.9873096346855164)
[2024-12-17 02:21:34,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:34,371][root][INFO] - Training Epoch: 1/2, step 6667/7134 completed (loss: 0.06054268777370453, acc: 0.982332170009613)
[2024-12-17 02:21:34,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:34,693][root][INFO] - Training Epoch: 1/2, step 6668/7134 completed (loss: 0.05047692358493805, acc: 0.9826689958572388)
[2024-12-17 02:21:34,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:35,021][root][INFO] - Training Epoch: 1/2, step 6669/7134 completed (loss: 0.057137660682201385, acc: 0.9848993420600891)
[2024-12-17 02:21:35,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:35,330][root][INFO] - Training Epoch: 1/2, step 6670/7134 completed (loss: 0.03994950279593468, acc: 0.9916387796401978)
[2024-12-17 02:21:35,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:35,681][root][INFO] - Training Epoch: 1/2, step 6671/7134 completed (loss: 0.041388895362615585, acc: 0.9853372573852539)
[2024-12-17 02:21:35,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:36,016][root][INFO] - Training Epoch: 1/2, step 6672/7134 completed (loss: 0.03935056924819946, acc: 0.9849905967712402)
[2024-12-17 02:21:36,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:36,362][root][INFO] - Training Epoch: 1/2, step 6673/7134 completed (loss: 0.050326019525527954, acc: 0.98531574010849)
[2024-12-17 02:21:36,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:36,679][root][INFO] - Training Epoch: 1/2, step 6674/7134 completed (loss: 0.04325905069708824, acc: 0.988394558429718)
[2024-12-17 02:21:36,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:37,005][root][INFO] - Training Epoch: 1/2, step 6675/7134 completed (loss: 0.025898486375808716, acc: 0.9925925731658936)
[2024-12-17 02:21:37,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:37,345][root][INFO] - Training Epoch: 1/2, step 6676/7134 completed (loss: 0.04246906936168671, acc: 0.9880668520927429)
[2024-12-17 02:21:37,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:37,644][root][INFO] - Training Epoch: 1/2, step 6677/7134 completed (loss: 0.11016283929347992, acc: 0.9790076613426208)
[2024-12-17 02:21:37,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:37,969][root][INFO] - Training Epoch: 1/2, step 6678/7134 completed (loss: 0.031134970486164093, acc: 0.987500011920929)
[2024-12-17 02:21:38,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:38,257][root][INFO] - Training Epoch: 1/2, step 6679/7134 completed (loss: 0.04897835850715637, acc: 0.9847161769866943)
[2024-12-17 02:21:38,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:38,543][root][INFO] - Training Epoch: 1/2, step 6680/7134 completed (loss: 0.023809535428881645, acc: 0.9945945739746094)
[2024-12-17 02:21:38,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:38,874][root][INFO] - Training Epoch: 1/2, step 6681/7134 completed (loss: 0.037020422518253326, acc: 0.987525999546051)
[2024-12-17 02:21:38,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:39,194][root][INFO] - Training Epoch: 1/2, step 6682/7134 completed (loss: 0.10658465325832367, acc: 0.9813084006309509)
[2024-12-17 02:21:39,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:39,477][root][INFO] - Training Epoch: 1/2, step 6683/7134 completed (loss: 0.035289216786623, acc: 0.9862637519836426)
[2024-12-17 02:21:39,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:39,801][root][INFO] - Training Epoch: 1/2, step 6684/7134 completed (loss: 0.06862558424472809, acc: 0.987500011920929)
[2024-12-17 02:21:39,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:40,124][root][INFO] - Training Epoch: 1/2, step 6685/7134 completed (loss: 0.05259466916322708, acc: 0.9866412281990051)
[2024-12-17 02:21:40,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:40,458][root][INFO] - Training Epoch: 1/2, step 6686/7134 completed (loss: 0.10774247348308563, acc: 0.9772727489471436)
[2024-12-17 02:21:40,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:40,747][root][INFO] - Training Epoch: 1/2, step 6687/7134 completed (loss: 0.1216469258069992, acc: 0.9629629850387573)
[2024-12-17 02:21:40,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:41,111][root][INFO] - Training Epoch: 1/2, step 6688/7134 completed (loss: 0.15357500314712524, acc: 0.9639175534248352)
[2024-12-17 02:21:41,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:41,444][root][INFO] - Training Epoch: 1/2, step 6689/7134 completed (loss: 0.13290676474571228, acc: 0.9603960514068604)
[2024-12-17 02:21:41,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:41,753][root][INFO] - Training Epoch: 1/2, step 6690/7134 completed (loss: 0.24278436601161957, acc: 0.9370459914207458)
[2024-12-17 02:21:41,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:42,082][root][INFO] - Training Epoch: 1/2, step 6691/7134 completed (loss: 0.10152081400156021, acc: 0.9819967150688171)
[2024-12-17 02:21:42,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:42,378][root][INFO] - Training Epoch: 1/2, step 6692/7134 completed (loss: 0.06386737525463104, acc: 0.9788135886192322)
[2024-12-17 02:21:42,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:42,698][root][INFO] - Training Epoch: 1/2, step 6693/7134 completed (loss: 0.06280823051929474, acc: 0.9801980257034302)
[2024-12-17 02:21:42,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:43,034][root][INFO] - Training Epoch: 1/2, step 6694/7134 completed (loss: 0.15679489076137543, acc: 0.961773693561554)
[2024-12-17 02:21:43,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:43,368][root][INFO] - Training Epoch: 1/2, step 6695/7134 completed (loss: 0.10038195550441742, acc: 0.9753761887550354)
[2024-12-17 02:21:43,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:43,703][root][INFO] - Training Epoch: 1/2, step 6696/7134 completed (loss: 0.08554024994373322, acc: 0.9814241528511047)
[2024-12-17 02:21:43,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:44,026][root][INFO] - Training Epoch: 1/2, step 6697/7134 completed (loss: 0.12625955045223236, acc: 0.9704918265342712)
[2024-12-17 02:21:44,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:44,346][root][INFO] - Training Epoch: 1/2, step 6698/7134 completed (loss: 0.05760941654443741, acc: 0.9851632118225098)
[2024-12-17 02:21:44,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:44,677][root][INFO] - Training Epoch: 1/2, step 6699/7134 completed (loss: 0.06681624054908752, acc: 0.9794988632202148)
[2024-12-17 02:21:44,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:45,014][root][INFO] - Training Epoch: 1/2, step 6700/7134 completed (loss: 0.12547022104263306, acc: 0.9742646813392639)
[2024-12-17 02:21:45,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:45,329][root][INFO] - Training Epoch: 1/2, step 6701/7134 completed (loss: 0.17939859628677368, acc: 0.9523809552192688)
[2024-12-17 02:21:45,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:45,642][root][INFO] - Training Epoch: 1/2, step 6702/7134 completed (loss: 0.0847550481557846, acc: 0.9724950790405273)
[2024-12-17 02:21:45,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:45,967][root][INFO] - Training Epoch: 1/2, step 6703/7134 completed (loss: 0.1540265530347824, acc: 0.9473684430122375)
[2024-12-17 02:21:46,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:46,307][root][INFO] - Training Epoch: 1/2, step 6704/7134 completed (loss: 0.1461254358291626, acc: 0.9573091864585876)
[2024-12-17 02:21:46,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:46,646][root][INFO] - Training Epoch: 1/2, step 6705/7134 completed (loss: 0.11152364313602448, acc: 0.9700910449028015)
[2024-12-17 02:21:46,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:46,942][root][INFO] - Training Epoch: 1/2, step 6706/7134 completed (loss: 0.09243520349264145, acc: 0.9731404781341553)
[2024-12-17 02:21:47,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:47,270][root][INFO] - Training Epoch: 1/2, step 6707/7134 completed (loss: 0.11483069509267807, acc: 0.9644970297813416)
[2024-12-17 02:21:47,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:47,622][root][INFO] - Training Epoch: 1/2, step 6708/7134 completed (loss: 0.10393848270177841, acc: 0.9752475023269653)
[2024-12-17 02:21:47,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:47,956][root][INFO] - Training Epoch: 1/2, step 6709/7134 completed (loss: 0.0856221467256546, acc: 0.976047933101654)
[2024-12-17 02:21:48,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:48,282][root][INFO] - Training Epoch: 1/2, step 6710/7134 completed (loss: 0.17970193922519684, acc: 0.9634369015693665)
[2024-12-17 02:21:48,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:48,638][root][INFO] - Training Epoch: 1/2, step 6711/7134 completed (loss: 0.06426334381103516, acc: 0.9825396537780762)
[2024-12-17 02:21:48,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:48,965][root][INFO] - Training Epoch: 1/2, step 6712/7134 completed (loss: 0.08030745387077332, acc: 0.9818456768989563)
[2024-12-17 02:21:49,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:49,404][root][INFO] - Training Epoch: 1/2, step 6713/7134 completed (loss: 0.07497645914554596, acc: 0.9811866879463196)
[2024-12-17 02:21:49,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:49,745][root][INFO] - Training Epoch: 1/2, step 6714/7134 completed (loss: 0.06465503573417664, acc: 0.9762258529663086)
[2024-12-17 02:21:49,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:50,077][root][INFO] - Training Epoch: 1/2, step 6715/7134 completed (loss: 0.09917861223220825, acc: 0.9686028361320496)
[2024-12-17 02:21:50,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:50,417][root][INFO] - Training Epoch: 1/2, step 6716/7134 completed (loss: 0.054401978850364685, acc: 0.985029935836792)
[2024-12-17 02:21:50,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:50,744][root][INFO] - Training Epoch: 1/2, step 6717/7134 completed (loss: 0.06678612530231476, acc: 0.979066014289856)
[2024-12-17 02:21:50,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:51,069][root][INFO] - Training Epoch: 1/2, step 6718/7134 completed (loss: 0.11994975805282593, acc: 0.9742424488067627)
[2024-12-17 02:21:51,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:51,393][root][INFO] - Training Epoch: 1/2, step 6719/7134 completed (loss: 0.06426359713077545, acc: 0.9803921580314636)
[2024-12-17 02:21:51,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:51,726][root][INFO] - Training Epoch: 1/2, step 6720/7134 completed (loss: 0.10696455836296082, acc: 0.9804469347000122)
[2024-12-17 02:21:51,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:52,036][root][INFO] - Training Epoch: 1/2, step 6721/7134 completed (loss: 0.10593654960393906, acc: 0.9797191619873047)
[2024-12-17 02:21:52,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:52,317][root][INFO] - Training Epoch: 1/2, step 6722/7134 completed (loss: 0.147816002368927, acc: 0.9701230525970459)
[2024-12-17 02:21:52,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:52,651][root][INFO] - Training Epoch: 1/2, step 6723/7134 completed (loss: 0.05229777842760086, acc: 0.9833333492279053)
[2024-12-17 02:21:52,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:52,973][root][INFO] - Training Epoch: 1/2, step 6724/7134 completed (loss: 0.08117266744375229, acc: 0.9795022010803223)
[2024-12-17 02:21:53,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:53,272][root][INFO] - Training Epoch: 1/2, step 6725/7134 completed (loss: 0.07220900058746338, acc: 0.9778156876564026)
[2024-12-17 02:21:53,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:53,579][root][INFO] - Training Epoch: 1/2, step 6726/7134 completed (loss: 0.13942746818065643, acc: 0.9658634662628174)
[2024-12-17 02:21:53,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:53,897][root][INFO] - Training Epoch: 1/2, step 6727/7134 completed (loss: 0.1272045224905014, acc: 0.9683098793029785)
[2024-12-17 02:21:54,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:54,239][root][INFO] - Training Epoch: 1/2, step 6728/7134 completed (loss: 0.10514899343252182, acc: 0.9800307154655457)
[2024-12-17 02:21:54,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:54,589][root][INFO] - Training Epoch: 1/2, step 6729/7134 completed (loss: 0.05117505416274071, acc: 0.9864130616188049)
[2024-12-17 02:21:54,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:54,946][root][INFO] - Training Epoch: 1/2, step 6730/7134 completed (loss: 0.12508951127529144, acc: 0.9701727032661438)
[2024-12-17 02:21:55,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:55,295][root][INFO] - Training Epoch: 1/2, step 6731/7134 completed (loss: 0.06331738084554672, acc: 0.9819004535675049)
[2024-12-17 02:21:55,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:55,617][root][INFO] - Training Epoch: 1/2, step 6732/7134 completed (loss: 0.08325039595365524, acc: 0.9779874086380005)
[2024-12-17 02:21:55,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:55,933][root][INFO] - Training Epoch: 1/2, step 6733/7134 completed (loss: 0.07865465432405472, acc: 0.9753320813179016)
[2024-12-17 02:21:56,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:56,244][root][INFO] - Training Epoch: 1/2, step 6734/7134 completed (loss: 0.09807837009429932, acc: 0.977570116519928)
[2024-12-17 02:21:56,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:56,564][root][INFO] - Training Epoch: 1/2, step 6735/7134 completed (loss: 0.08797189593315125, acc: 0.9769585132598877)
[2024-12-17 02:21:56,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:56,927][root][INFO] - Training Epoch: 1/2, step 6736/7134 completed (loss: 0.10065243393182755, acc: 0.976323127746582)
[2024-12-17 02:21:57,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:57,273][root][INFO] - Training Epoch: 1/2, step 6737/7134 completed (loss: 0.0985269695520401, acc: 0.9789302945137024)
[2024-12-17 02:21:57,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:57,592][root][INFO] - Training Epoch: 1/2, step 6738/7134 completed (loss: 0.09746978431940079, acc: 0.9850746393203735)
[2024-12-17 02:21:57,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:57,861][root][INFO] - Training Epoch: 1/2, step 6739/7134 completed (loss: 0.0600101538002491, acc: 0.9889705777168274)
[2024-12-17 02:21:57,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:58,193][root][INFO] - Training Epoch: 1/2, step 6740/7134 completed (loss: 0.08046822249889374, acc: 0.9830220937728882)
[2024-12-17 02:21:58,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:58,515][root][INFO] - Training Epoch: 1/2, step 6741/7134 completed (loss: 0.05605589225888252, acc: 0.9825834631919861)
[2024-12-17 02:21:58,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:58,812][root][INFO] - Training Epoch: 1/2, step 6742/7134 completed (loss: 0.03516087681055069, acc: 0.9927849769592285)
[2024-12-17 02:21:58,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:59,176][root][INFO] - Training Epoch: 1/2, step 6743/7134 completed (loss: 0.042631927877664566, acc: 0.9891008138656616)
[2024-12-17 02:21:59,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:59,499][root][INFO] - Training Epoch: 1/2, step 6744/7134 completed (loss: 0.04491827264428139, acc: 0.9903846383094788)
[2024-12-17 02:21:59,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:59,820][root][INFO] - Training Epoch: 1/2, step 6745/7134 completed (loss: 0.03361925855278969, acc: 0.9876203536987305)
[2024-12-17 02:21:59,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:00,128][root][INFO] - Training Epoch: 1/2, step 6746/7134 completed (loss: 0.03950507566332817, acc: 0.9911816716194153)
[2024-12-17 02:22:00,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:00,459][root][INFO] - Training Epoch: 1/2, step 6747/7134 completed (loss: 0.06192898377776146, acc: 0.9875776171684265)
[2024-12-17 02:22:00,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:00,842][root][INFO] - Training Epoch: 1/2, step 6748/7134 completed (loss: 0.038472358137369156, acc: 0.9921082258224487)
[2024-12-17 02:22:00,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:01,219][root][INFO] - Training Epoch: 1/2, step 6749/7134 completed (loss: 0.041494328528642654, acc: 0.9880174398422241)
[2024-12-17 02:22:01,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:01,585][root][INFO] - Training Epoch: 1/2, step 6750/7134 completed (loss: 0.037122923880815506, acc: 0.9884659647941589)
[2024-12-17 02:22:01,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:01,958][root][INFO] - Training Epoch: 1/2, step 6751/7134 completed (loss: 0.025096261873841286, acc: 0.9931507110595703)
[2024-12-17 02:22:02,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:02,319][root][INFO] - Training Epoch: 1/2, step 6752/7134 completed (loss: 0.015456395223736763, acc: 0.9970972537994385)
[2024-12-17 02:22:02,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:02,689][root][INFO] - Training Epoch: 1/2, step 6753/7134 completed (loss: 0.027898160740733147, acc: 0.9954128265380859)
[2024-12-17 02:22:02,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:03,024][root][INFO] - Training Epoch: 1/2, step 6754/7134 completed (loss: 0.02394750900566578, acc: 0.9951807260513306)
[2024-12-17 02:22:03,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:03,379][root][INFO] - Training Epoch: 1/2, step 6755/7134 completed (loss: 0.03156633302569389, acc: 0.9901477694511414)
[2024-12-17 02:22:03,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:03,722][root][INFO] - Training Epoch: 1/2, step 6756/7134 completed (loss: 0.009913410991430283, acc: 0.9986594915390015)
[2024-12-17 02:22:03,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:04,044][root][INFO] - Training Epoch: 1/2, step 6757/7134 completed (loss: 0.07042861729860306, acc: 0.9862805008888245)
[2024-12-17 02:22:04,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:04,390][root][INFO] - Training Epoch: 1/2, step 6758/7134 completed (loss: 0.03179255872964859, acc: 0.9909443855285645)
[2024-12-17 02:22:04,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:04,757][root][INFO] - Training Epoch: 1/2, step 6759/7134 completed (loss: 0.04461117833852768, acc: 0.9865771532058716)
[2024-12-17 02:22:04,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:05,110][root][INFO] - Training Epoch: 1/2, step 6760/7134 completed (loss: 0.05240697041153908, acc: 0.9868766665458679)
[2024-12-17 02:22:05,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:05,455][root][INFO] - Training Epoch: 1/2, step 6761/7134 completed (loss: 0.06107962131500244, acc: 0.9879518151283264)
[2024-12-17 02:22:05,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:05,808][root][INFO] - Training Epoch: 1/2, step 6762/7134 completed (loss: 0.06323374807834625, acc: 0.9828431606292725)
[2024-12-17 02:22:05,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:06,166][root][INFO] - Training Epoch: 1/2, step 6763/7134 completed (loss: 0.02060309424996376, acc: 0.9924717545509338)
[2024-12-17 02:22:06,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:06,488][root][INFO] - Training Epoch: 1/2, step 6764/7134 completed (loss: 0.024445872753858566, acc: 0.9928160905838013)
[2024-12-17 02:22:06,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:06,864][root][INFO] - Training Epoch: 1/2, step 6765/7134 completed (loss: 0.029576696455478668, acc: 0.9920106530189514)
[2024-12-17 02:22:06,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:07,188][root][INFO] - Training Epoch: 1/2, step 6766/7134 completed (loss: 0.03207011893391609, acc: 0.9944827556610107)
[2024-12-17 02:22:07,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:07,450][root][INFO] - Training Epoch: 1/2, step 6767/7134 completed (loss: 0.04034416005015373, acc: 0.9887387156486511)
[2024-12-17 02:22:07,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:07,799][root][INFO] - Training Epoch: 1/2, step 6768/7134 completed (loss: 0.02435586228966713, acc: 0.9923954606056213)
[2024-12-17 02:22:07,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:08,124][root][INFO] - Training Epoch: 1/2, step 6769/7134 completed (loss: 0.032229408621788025, acc: 0.9891975522041321)
[2024-12-17 02:22:08,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:08,469][root][INFO] - Training Epoch: 1/2, step 6770/7134 completed (loss: 0.09659357368946075, acc: 0.9758388996124268)
[2024-12-17 02:22:08,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:08,823][root][INFO] - Training Epoch: 1/2, step 6771/7134 completed (loss: 0.05432066321372986, acc: 0.9842271208763123)
[2024-12-17 02:22:08,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:09,169][root][INFO] - Training Epoch: 1/2, step 6772/7134 completed (loss: 0.14701667428016663, acc: 0.9732620120048523)
[2024-12-17 02:22:09,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:09,496][root][INFO] - Training Epoch: 1/2, step 6773/7134 completed (loss: 0.05842570960521698, acc: 0.9762658476829529)
[2024-12-17 02:22:09,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:09,835][root][INFO] - Training Epoch: 1/2, step 6774/7134 completed (loss: 0.09405769407749176, acc: 0.9761146306991577)
[2024-12-17 02:22:09,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:10,160][root][INFO] - Training Epoch: 1/2, step 6775/7134 completed (loss: 0.05041961744427681, acc: 0.9867674708366394)
[2024-12-17 02:22:10,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:10,491][root][INFO] - Training Epoch: 1/2, step 6776/7134 completed (loss: 0.07875961810350418, acc: 0.9765957593917847)
[2024-12-17 02:22:10,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:10,822][root][INFO] - Training Epoch: 1/2, step 6777/7134 completed (loss: 0.06170874834060669, acc: 0.9812080264091492)
[2024-12-17 02:22:10,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:11,174][root][INFO] - Training Epoch: 1/2, step 6778/7134 completed (loss: 0.08941937983036041, acc: 0.9762258529663086)
[2024-12-17 02:22:11,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:11,513][root][INFO] - Training Epoch: 1/2, step 6779/7134 completed (loss: 0.05676886811852455, acc: 0.9820895791053772)
[2024-12-17 02:22:11,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:11,851][root][INFO] - Training Epoch: 1/2, step 6780/7134 completed (loss: 0.03724915534257889, acc: 0.9895366430282593)
[2024-12-17 02:22:11,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:12,199][root][INFO] - Training Epoch: 1/2, step 6781/7134 completed (loss: 0.07029270380735397, acc: 0.977544903755188)
[2024-12-17 02:22:12,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:12,523][root][INFO] - Training Epoch: 1/2, step 6782/7134 completed (loss: 0.11768332123756409, acc: 0.9722222089767456)
[2024-12-17 02:22:12,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:12,815][root][INFO] - Training Epoch: 1/2, step 6783/7134 completed (loss: 0.09259461611509323, acc: 0.9750480055809021)
[2024-12-17 02:22:12,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:13,153][root][INFO] - Training Epoch: 1/2, step 6784/7134 completed (loss: 0.06514682620763779, acc: 0.9833610653877258)
[2024-12-17 02:22:13,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:13,494][root][INFO] - Training Epoch: 1/2, step 6785/7134 completed (loss: 0.04185746982693672, acc: 0.9874213933944702)
[2024-12-17 02:22:13,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:13,855][root][INFO] - Training Epoch: 1/2, step 6786/7134 completed (loss: 0.03607688099145889, acc: 0.9884892106056213)
[2024-12-17 02:22:13,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:14,208][root][INFO] - Training Epoch: 1/2, step 6787/7134 completed (loss: 0.0793001800775528, acc: 0.9802631735801697)
[2024-12-17 02:22:14,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:14,535][root][INFO] - Training Epoch: 1/2, step 6788/7134 completed (loss: 0.11689499020576477, acc: 0.9748201370239258)
[2024-12-17 02:22:14,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:14,849][root][INFO] - Training Epoch: 1/2, step 6789/7134 completed (loss: 0.053211066871881485, acc: 0.9844357967376709)
[2024-12-17 02:22:14,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:15,196][root][INFO] - Training Epoch: 1/2, step 6790/7134 completed (loss: 0.1063322052359581, acc: 0.9755747318267822)
[2024-12-17 02:22:15,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:15,524][root][INFO] - Training Epoch: 1/2, step 6791/7134 completed (loss: 0.045484695583581924, acc: 0.9863713979721069)
[2024-12-17 02:22:15,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:15,863][root][INFO] - Training Epoch: 1/2, step 6792/7134 completed (loss: 0.06311028450727463, acc: 0.9816513657569885)
[2024-12-17 02:22:15,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:16,212][root][INFO] - Training Epoch: 1/2, step 6793/7134 completed (loss: 0.04472631588578224, acc: 0.9894514679908752)
[2024-12-17 02:22:16,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:16,546][root][INFO] - Training Epoch: 1/2, step 6794/7134 completed (loss: 0.06878911703824997, acc: 0.9868637323379517)
[2024-12-17 02:22:16,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:16,893][root][INFO] - Training Epoch: 1/2, step 6795/7134 completed (loss: 0.03802339732646942, acc: 0.9883117079734802)
[2024-12-17 02:22:17,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:17,224][root][INFO] - Training Epoch: 1/2, step 6796/7134 completed (loss: 0.03736565262079239, acc: 0.9897360801696777)
[2024-12-17 02:22:17,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:17,558][root][INFO] - Training Epoch: 1/2, step 6797/7134 completed (loss: 0.06750775128602982, acc: 0.9854439496994019)
[2024-12-17 02:22:17,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:17,886][root][INFO] - Training Epoch: 1/2, step 6798/7134 completed (loss: 0.06112440675497055, acc: 0.9820936918258667)
[2024-12-17 02:22:17,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:18,223][root][INFO] - Training Epoch: 1/2, step 6799/7134 completed (loss: 0.036233726888895035, acc: 0.9904240965843201)
[2024-12-17 02:22:18,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:18,547][root][INFO] - Training Epoch: 1/2, step 6800/7134 completed (loss: 0.07346046715974808, acc: 0.9820442199707031)
[2024-12-17 02:22:18,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:18,909][root][INFO] - Training Epoch: 1/2, step 6801/7134 completed (loss: 0.046203311532735825, acc: 0.9842519760131836)
[2024-12-17 02:22:19,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:19,240][root][INFO] - Training Epoch: 1/2, step 6802/7134 completed (loss: 0.03805432841181755, acc: 0.9941434860229492)
[2024-12-17 02:22:19,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:19,587][root][INFO] - Training Epoch: 1/2, step 6803/7134 completed (loss: 0.04022038355469704, acc: 0.9886792302131653)
[2024-12-17 02:22:19,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:19,913][root][INFO] - Training Epoch: 1/2, step 6804/7134 completed (loss: 0.09138932824134827, acc: 0.984375)
[2024-12-17 02:22:20,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:20,266][root][INFO] - Training Epoch: 1/2, step 6805/7134 completed (loss: 0.08634469658136368, acc: 0.9743589758872986)
[2024-12-17 02:22:20,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:20,612][root][INFO] - Training Epoch: 1/2, step 6806/7134 completed (loss: 0.06279730051755905, acc: 0.9873417615890503)
[2024-12-17 02:22:20,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:20,982][root][INFO] - Training Epoch: 1/2, step 6807/7134 completed (loss: 0.041223060339689255, acc: 0.9841954112052917)
[2024-12-17 02:22:21,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:21,317][root][INFO] - Training Epoch: 1/2, step 6808/7134 completed (loss: 0.091502346098423, acc: 0.9776714444160461)
[2024-12-17 02:22:21,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:21,670][root][INFO] - Training Epoch: 1/2, step 6809/7134 completed (loss: 0.0882294625043869, acc: 0.9810298085212708)
[2024-12-17 02:22:21,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:21,993][root][INFO] - Training Epoch: 1/2, step 6810/7134 completed (loss: 0.0202928613871336, acc: 0.9947368502616882)
[2024-12-17 02:22:22,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:22,354][root][INFO] - Training Epoch: 1/2, step 6811/7134 completed (loss: 0.09165216982364655, acc: 0.9777195453643799)
[2024-12-17 02:22:22,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:22,686][root][INFO] - Training Epoch: 1/2, step 6812/7134 completed (loss: 0.07098495960235596, acc: 0.9837925434112549)
[2024-12-17 02:22:22,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:23,019][root][INFO] - Training Epoch: 1/2, step 6813/7134 completed (loss: 0.03381909430027008, acc: 0.9901408553123474)
[2024-12-17 02:22:23,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:23,360][root][INFO] - Training Epoch: 1/2, step 6814/7134 completed (loss: 0.03446521237492561, acc: 0.9919354915618896)
[2024-12-17 02:22:23,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:23,703][root][INFO] - Training Epoch: 1/2, step 6815/7134 completed (loss: 0.04238814488053322, acc: 0.9881734848022461)
[2024-12-17 02:22:23,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:24,038][root][INFO] - Training Epoch: 1/2, step 6816/7134 completed (loss: 0.05666489899158478, acc: 0.9899665713310242)
[2024-12-17 02:22:24,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:24,393][root][INFO] - Training Epoch: 1/2, step 6817/7134 completed (loss: 0.08758541941642761, acc: 0.9811965823173523)
[2024-12-17 02:22:24,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:24,732][root][INFO] - Training Epoch: 1/2, step 6818/7134 completed (loss: 0.034725721925497055, acc: 0.9895052313804626)
[2024-12-17 02:22:24,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:25,073][root][INFO] - Training Epoch: 1/2, step 6819/7134 completed (loss: 0.08077491819858551, acc: 0.9766187071800232)
[2024-12-17 02:22:25,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:25,401][root][INFO] - Training Epoch: 1/2, step 6820/7134 completed (loss: 0.06776121258735657, acc: 0.9855855703353882)
[2024-12-17 02:22:25,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:25,675][root][INFO] - Training Epoch: 1/2, step 6821/7134 completed (loss: 0.05244786664843559, acc: 0.9818181991577148)
[2024-12-17 02:22:25,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:26,011][root][INFO] - Training Epoch: 1/2, step 6822/7134 completed (loss: 0.0771588534116745, acc: 0.9773123860359192)
[2024-12-17 02:22:26,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:26,347][root][INFO] - Training Epoch: 1/2, step 6823/7134 completed (loss: 0.06802952289581299, acc: 0.9756795167922974)
[2024-12-17 02:22:26,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:26,643][root][INFO] - Training Epoch: 1/2, step 6824/7134 completed (loss: 0.11971016973257065, acc: 0.9637096524238586)
[2024-12-17 02:22:26,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:26,958][root][INFO] - Training Epoch: 1/2, step 6825/7134 completed (loss: 0.04406682401895523, acc: 0.9902439117431641)
[2024-12-17 02:22:27,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:27,273][root][INFO] - Training Epoch: 1/2, step 6826/7134 completed (loss: 0.06967675685882568, acc: 0.9898989796638489)
[2024-12-17 02:22:27,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:27,612][root][INFO] - Training Epoch: 1/2, step 6827/7134 completed (loss: 0.17141789197921753, acc: 0.9548969268798828)
[2024-12-17 02:22:27,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:27,952][root][INFO] - Training Epoch: 1/2, step 6828/7134 completed (loss: 0.09355974197387695, acc: 0.970802903175354)
[2024-12-17 02:22:28,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:28,296][root][INFO] - Training Epoch: 1/2, step 6829/7134 completed (loss: 0.07232485711574554, acc: 0.9807121753692627)
[2024-12-17 02:22:28,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:28,620][root][INFO] - Training Epoch: 1/2, step 6830/7134 completed (loss: 0.050116416066884995, acc: 0.9868203997612)
[2024-12-17 02:22:28,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:28,958][root][INFO] - Training Epoch: 1/2, step 6831/7134 completed (loss: 0.06455673277378082, acc: 0.9852150678634644)
[2024-12-17 02:22:29,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:29,284][root][INFO] - Training Epoch: 1/2, step 6832/7134 completed (loss: 0.0764046385884285, acc: 0.975970447063446)
[2024-12-17 02:22:29,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:29,609][root][INFO] - Training Epoch: 1/2, step 6833/7134 completed (loss: 0.07586556673049927, acc: 0.9807074069976807)
[2024-12-17 02:22:29,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:29,894][root][INFO] - Training Epoch: 1/2, step 6834/7134 completed (loss: 0.09826908260583878, acc: 0.9744463562965393)
[2024-12-17 02:22:30,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:30,215][root][INFO] - Training Epoch: 1/2, step 6835/7134 completed (loss: 0.056104790419340134, acc: 0.9821428656578064)
[2024-12-17 02:22:30,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:30,539][root][INFO] - Training Epoch: 1/2, step 6836/7134 completed (loss: 0.09786684066057205, acc: 0.9761306643486023)
[2024-12-17 02:22:30,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:30,897][root][INFO] - Training Epoch: 1/2, step 6837/7134 completed (loss: 0.05808936804533005, acc: 0.9865030646324158)
[2024-12-17 02:22:31,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:31,220][root][INFO] - Training Epoch: 1/2, step 6838/7134 completed (loss: 0.13955505192279816, acc: 0.9658119678497314)
[2024-12-17 02:22:31,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:31,531][root][INFO] - Training Epoch: 1/2, step 6839/7134 completed (loss: 0.16455179452896118, acc: 0.9636963605880737)
[2024-12-17 02:22:31,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:31,856][root][INFO] - Training Epoch: 1/2, step 6840/7134 completed (loss: 0.11847883462905884, acc: 0.9713466763496399)
[2024-12-17 02:22:31,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:32,182][root][INFO] - Training Epoch: 1/2, step 6841/7134 completed (loss: 0.1095077246427536, acc: 0.9639249444007874)
[2024-12-17 02:22:32,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:32,542][root][INFO] - Training Epoch: 1/2, step 6842/7134 completed (loss: 0.06347403675317764, acc: 0.976190447807312)
[2024-12-17 02:22:32,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:32,901][root][INFO] - Training Epoch: 1/2, step 6843/7134 completed (loss: 0.09006324410438538, acc: 0.9753391146659851)
[2024-12-17 02:22:33,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:33,231][root][INFO] - Training Epoch: 1/2, step 6844/7134 completed (loss: 0.062214404344558716, acc: 0.984455943107605)
[2024-12-17 02:22:33,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:33,588][root][INFO] - Training Epoch: 1/2, step 6845/7134 completed (loss: 0.04660429432988167, acc: 0.9829931855201721)
[2024-12-17 02:22:33,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:33,913][root][INFO] - Training Epoch: 1/2, step 6846/7134 completed (loss: 0.08633848279714584, acc: 0.9770773649215698)
[2024-12-17 02:22:34,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:34,257][root][INFO] - Training Epoch: 1/2, step 6847/7134 completed (loss: 0.08234009891748428, acc: 0.9757575988769531)
[2024-12-17 02:22:34,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:34,587][root][INFO] - Training Epoch: 1/2, step 6848/7134 completed (loss: 0.07668492943048477, acc: 0.9756757020950317)
[2024-12-17 02:22:34,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:34,923][root][INFO] - Training Epoch: 1/2, step 6849/7134 completed (loss: 0.0795588344335556, acc: 0.9828178882598877)
[2024-12-17 02:22:35,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:35,240][root][INFO] - Training Epoch: 1/2, step 6850/7134 completed (loss: 0.13319119811058044, acc: 0.9633867144584656)
[2024-12-17 02:22:35,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:35,582][root][INFO] - Training Epoch: 1/2, step 6851/7134 completed (loss: 0.1074981689453125, acc: 0.9732016921043396)
[2024-12-17 02:22:35,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:35,924][root][INFO] - Training Epoch: 1/2, step 6852/7134 completed (loss: 0.03448827937245369, acc: 0.9930070042610168)
[2024-12-17 02:22:36,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:36,298][root][INFO] - Training Epoch: 1/2, step 6853/7134 completed (loss: 0.07468265295028687, acc: 0.9847856163978577)
[2024-12-17 02:22:36,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:36,573][root][INFO] - Training Epoch: 1/2, step 6854/7134 completed (loss: 0.0795758068561554, acc: 0.9848155975341797)
[2024-12-17 02:22:36,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:36,891][root][INFO] - Training Epoch: 1/2, step 6855/7134 completed (loss: 0.04448452964425087, acc: 0.9882075190544128)
[2024-12-17 02:22:37,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:37,242][root][INFO] - Training Epoch: 1/2, step 6856/7134 completed (loss: 0.023112691938877106, acc: 0.9928469061851501)
[2024-12-17 02:22:37,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:37,594][root][INFO] - Training Epoch: 1/2, step 6857/7134 completed (loss: 0.05818374454975128, acc: 0.9868035316467285)
[2024-12-17 02:22:37,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:37,823][root][INFO] - Training Epoch: 1/2, step 6858/7134 completed (loss: 0.02052895538508892, acc: 0.9926199316978455)
[2024-12-17 02:22:37,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:38,180][root][INFO] - Training Epoch: 1/2, step 6859/7134 completed (loss: 0.02897353656589985, acc: 0.994878351688385)
[2024-12-17 02:22:38,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:38,514][root][INFO] - Training Epoch: 1/2, step 6860/7134 completed (loss: 0.03304684907197952, acc: 0.9929078221321106)
[2024-12-17 02:22:38,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:38,831][root][INFO] - Training Epoch: 1/2, step 6861/7134 completed (loss: 0.026725586503744125, acc: 0.9948096871376038)
[2024-12-17 02:22:38,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:39,187][root][INFO] - Training Epoch: 1/2, step 6862/7134 completed (loss: 0.05610296502709389, acc: 0.9847618937492371)
[2024-12-17 02:22:39,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:39,520][root][INFO] - Training Epoch: 1/2, step 6863/7134 completed (loss: 0.048865556716918945, acc: 0.9887005686759949)
[2024-12-17 02:22:39,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:39,874][root][INFO] - Training Epoch: 1/2, step 6864/7134 completed (loss: 0.03919360786676407, acc: 0.9850249290466309)
[2024-12-17 02:22:39,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:40,207][root][INFO] - Training Epoch: 1/2, step 6865/7134 completed (loss: 0.07369856536388397, acc: 0.985567033290863)
[2024-12-17 02:22:40,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:40,531][root][INFO] - Training Epoch: 1/2, step 6866/7134 completed (loss: 0.011895943433046341, acc: 0.9954407215118408)
[2024-12-17 02:22:40,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:40,865][root][INFO] - Training Epoch: 1/2, step 6867/7134 completed (loss: 0.023525632917881012, acc: 0.9925925731658936)
[2024-12-17 02:22:40,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:41,133][root][INFO] - Training Epoch: 1/2, step 6868/7134 completed (loss: 0.013705825433135033, acc: 0.9944598078727722)
[2024-12-17 02:22:41,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:41,416][root][INFO] - Training Epoch: 1/2, step 6869/7134 completed (loss: 0.05258651077747345, acc: 0.9871520400047302)
[2024-12-17 02:22:41,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:41,767][root][INFO] - Training Epoch: 1/2, step 6870/7134 completed (loss: 0.034434013068675995, acc: 0.9934853315353394)
[2024-12-17 02:22:41,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:42,119][root][INFO] - Training Epoch: 1/2, step 6871/7134 completed (loss: 0.013330196030437946, acc: 0.9943820238113403)
[2024-12-17 02:22:42,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:42,445][root][INFO] - Training Epoch: 1/2, step 6872/7134 completed (loss: 0.030932506546378136, acc: 0.9889196753501892)
[2024-12-17 02:22:42,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:42,792][root][INFO] - Training Epoch: 1/2, step 6873/7134 completed (loss: 0.021386992186307907, acc: 0.9929971694946289)
[2024-12-17 02:22:42,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:43,117][root][INFO] - Training Epoch: 1/2, step 6874/7134 completed (loss: 0.02946275658905506, acc: 0.98758864402771)
[2024-12-17 02:22:43,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:43,451][root][INFO] - Training Epoch: 1/2, step 6875/7134 completed (loss: 0.03867054730653763, acc: 0.9876352548599243)
[2024-12-17 02:22:43,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:43,776][root][INFO] - Training Epoch: 1/2, step 6876/7134 completed (loss: 0.041122548282146454, acc: 0.9915397763252258)
[2024-12-17 02:22:43,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:44,135][root][INFO] - Training Epoch: 1/2, step 6877/7134 completed (loss: 0.03563489392399788, acc: 0.9915730357170105)
[2024-12-17 02:22:44,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:44,474][root][INFO] - Training Epoch: 1/2, step 6878/7134 completed (loss: 0.03134090453386307, acc: 0.9910045266151428)
[2024-12-17 02:22:44,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:44,747][root][INFO] - Training Epoch: 1/2, step 6879/7134 completed (loss: 0.03809141740202904, acc: 0.9832636117935181)
[2024-12-17 02:22:44,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:45,116][root][INFO] - Training Epoch: 1/2, step 6880/7134 completed (loss: 0.01659114472568035, acc: 0.9965075850486755)
[2024-12-17 02:22:45,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:45,473][root][INFO] - Training Epoch: 1/2, step 6881/7134 completed (loss: 0.07065338641405106, acc: 0.9878493547439575)
[2024-12-17 02:22:45,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:45,787][root][INFO] - Training Epoch: 1/2, step 6882/7134 completed (loss: 0.0838361531496048, acc: 0.9755638837814331)
[2024-12-17 02:22:45,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:46,114][root][INFO] - Training Epoch: 1/2, step 6883/7134 completed (loss: 0.04667087271809578, acc: 0.9851484894752502)
[2024-12-17 02:22:46,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:46,459][root][INFO] - Training Epoch: 1/2, step 6884/7134 completed (loss: 0.135672464966774, acc: 0.9785894155502319)
[2024-12-17 02:22:46,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:46,762][root][INFO] - Training Epoch: 1/2, step 6885/7134 completed (loss: 0.08987387269735336, acc: 0.9821428656578064)
[2024-12-17 02:22:46,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:47,091][root][INFO] - Training Epoch: 1/2, step 6886/7134 completed (loss: 0.049081217497587204, acc: 0.9841521382331848)
[2024-12-17 02:22:47,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:47,406][root][INFO] - Training Epoch: 1/2, step 6887/7134 completed (loss: 0.0641620010137558, acc: 0.9794661402702332)
[2024-12-17 02:22:47,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:47,754][root][INFO] - Training Epoch: 1/2, step 6888/7134 completed (loss: 0.04591153934597969, acc: 0.9883720874786377)
[2024-12-17 02:22:47,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:48,099][root][INFO] - Training Epoch: 1/2, step 6889/7134 completed (loss: 0.02511799894273281, acc: 0.9954057931900024)
[2024-12-17 02:22:48,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:48,449][root][INFO] - Training Epoch: 1/2, step 6890/7134 completed (loss: 0.03580208867788315, acc: 0.9933949708938599)
[2024-12-17 02:22:48,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:48,777][root][INFO] - Training Epoch: 1/2, step 6891/7134 completed (loss: 0.0469014048576355, acc: 0.9881481528282166)
[2024-12-17 02:22:48,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:49,135][root][INFO] - Training Epoch: 1/2, step 6892/7134 completed (loss: 0.04113810136914253, acc: 0.9908854365348816)
[2024-12-17 02:22:49,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:49,479][root][INFO] - Training Epoch: 1/2, step 6893/7134 completed (loss: 0.07344087958335876, acc: 0.9766355156898499)
[2024-12-17 02:22:49,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:49,828][root][INFO] - Training Epoch: 1/2, step 6894/7134 completed (loss: 0.07058122009038925, acc: 0.9842105507850647)
[2024-12-17 02:22:49,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:50,182][root][INFO] - Training Epoch: 1/2, step 6895/7134 completed (loss: 0.07986491173505783, acc: 0.9820144176483154)
[2024-12-17 02:22:50,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:50,491][root][INFO] - Training Epoch: 1/2, step 6896/7134 completed (loss: 0.04535650089383125, acc: 0.9884058237075806)
[2024-12-17 02:22:50,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:50,837][root][INFO] - Training Epoch: 1/2, step 6897/7134 completed (loss: 0.02754477597773075, acc: 0.9938650131225586)
[2024-12-17 02:22:50,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:51,157][root][INFO] - Training Epoch: 1/2, step 6898/7134 completed (loss: 0.024507220834493637, acc: 0.9917582273483276)
[2024-12-17 02:22:51,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:51,519][root][INFO] - Training Epoch: 1/2, step 6899/7134 completed (loss: 0.037431903183460236, acc: 0.9886934757232666)
[2024-12-17 02:22:51,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:51,870][root][INFO] - Training Epoch: 1/2, step 6900/7134 completed (loss: 0.059200674295425415, acc: 0.9801980257034302)
[2024-12-17 02:22:51,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:52,223][root][INFO] - Training Epoch: 1/2, step 6901/7134 completed (loss: 0.05588262528181076, acc: 0.9854689836502075)
[2024-12-17 02:22:52,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:52,591][root][INFO] - Training Epoch: 1/2, step 6902/7134 completed (loss: 0.060552842915058136, acc: 0.9861303567886353)
[2024-12-17 02:22:52,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:52,939][root][INFO] - Training Epoch: 1/2, step 6903/7134 completed (loss: 0.05521354079246521, acc: 0.9885931611061096)
[2024-12-17 02:22:53,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:53,294][root][INFO] - Training Epoch: 1/2, step 6904/7134 completed (loss: 0.032110512256622314, acc: 0.9912935495376587)
[2024-12-17 02:22:53,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:53,653][root][INFO] - Training Epoch: 1/2, step 6905/7134 completed (loss: 0.04301145672798157, acc: 0.9872123003005981)
[2024-12-17 02:22:53,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:54,022][root][INFO] - Training Epoch: 1/2, step 6906/7134 completed (loss: 0.04775533452630043, acc: 0.9856287240982056)
[2024-12-17 02:22:54,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:54,378][root][INFO] - Training Epoch: 1/2, step 6907/7134 completed (loss: 0.08100029081106186, acc: 0.9826302528381348)
[2024-12-17 02:22:54,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:54,727][root][INFO] - Training Epoch: 1/2, step 6908/7134 completed (loss: 0.06531333923339844, acc: 0.9805699586868286)
[2024-12-17 02:22:54,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:55,077][root][INFO] - Training Epoch: 1/2, step 6909/7134 completed (loss: 0.030307944864034653, acc: 0.99210524559021)
[2024-12-17 02:22:55,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:55,423][root][INFO] - Training Epoch: 1/2, step 6910/7134 completed (loss: 0.035953328013420105, acc: 0.9898089170455933)
[2024-12-17 02:22:55,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:55,729][root][INFO] - Training Epoch: 1/2, step 6911/7134 completed (loss: 0.0808316171169281, acc: 0.9825581312179565)
[2024-12-17 02:22:55,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:56,081][root][INFO] - Training Epoch: 1/2, step 6912/7134 completed (loss: 0.04649171978235245, acc: 0.9925093650817871)
[2024-12-17 02:22:56,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:56,484][root][INFO] - Training Epoch: 1/2, step 6913/7134 completed (loss: 0.0591932013630867, acc: 0.9853836894035339)
[2024-12-17 02:22:56,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:56,802][root][INFO] - Training Epoch: 1/2, step 6914/7134 completed (loss: 0.11961119621992111, acc: 0.9747474789619446)
[2024-12-17 02:22:56,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:57,154][root][INFO] - Training Epoch: 1/2, step 6915/7134 completed (loss: 0.037883151322603226, acc: 0.9870466589927673)
[2024-12-17 02:22:57,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:57,516][root][INFO] - Training Epoch: 1/2, step 6916/7134 completed (loss: 0.07272117584943771, acc: 0.982822060585022)
[2024-12-17 02:22:57,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:57,889][root][INFO] - Training Epoch: 1/2, step 6917/7134 completed (loss: 0.09230972081422806, acc: 0.9772727489471436)
[2024-12-17 02:22:58,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:58,225][root][INFO] - Training Epoch: 1/2, step 6918/7134 completed (loss: 0.048561785370111465, acc: 0.9906322956085205)
[2024-12-17 02:22:58,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:58,580][root][INFO] - Training Epoch: 1/2, step 6919/7134 completed (loss: 0.08386789262294769, acc: 0.9815455675125122)
[2024-12-17 02:22:58,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:58,901][root][INFO] - Training Epoch: 1/2, step 6920/7134 completed (loss: 0.060028430074453354, acc: 0.9800570011138916)
[2024-12-17 02:22:58,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:59,260][root][INFO] - Training Epoch: 1/2, step 6921/7134 completed (loss: 0.09950783103704453, acc: 0.980369508266449)
[2024-12-17 02:22:59,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:59,563][root][INFO] - Training Epoch: 1/2, step 6922/7134 completed (loss: 0.08746735006570816, acc: 0.975039005279541)
[2024-12-17 02:22:59,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:59,917][root][INFO] - Training Epoch: 1/2, step 6923/7134 completed (loss: 0.08307710289955139, acc: 0.9805447459220886)
[2024-12-17 02:23:00,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:00,267][root][INFO] - Training Epoch: 1/2, step 6924/7134 completed (loss: 0.04643494635820389, acc: 0.9904631972312927)
[2024-12-17 02:23:00,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:00,610][root][INFO] - Training Epoch: 1/2, step 6925/7134 completed (loss: 0.05177024006843567, acc: 0.9895833134651184)
[2024-12-17 02:23:00,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:00,942][root][INFO] - Training Epoch: 1/2, step 6926/7134 completed (loss: 0.06924236565828323, acc: 0.9819168448448181)
[2024-12-17 02:23:01,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:01,303][root][INFO] - Training Epoch: 1/2, step 6927/7134 completed (loss: 0.09795854240655899, acc: 0.9724220633506775)
[2024-12-17 02:23:01,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:01,613][root][INFO] - Training Epoch: 1/2, step 6928/7134 completed (loss: 0.11240638792514801, acc: 0.9706457853317261)
[2024-12-17 02:23:01,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:02,004][root][INFO] - Training Epoch: 1/2, step 6929/7134 completed (loss: 0.08460906147956848, acc: 0.9844632744789124)
[2024-12-17 02:23:02,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:02,370][root][INFO] - Training Epoch: 1/2, step 6930/7134 completed (loss: 0.09877154231071472, acc: 0.9751861095428467)
[2024-12-17 02:23:02,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:02,741][root][INFO] - Training Epoch: 1/2, step 6931/7134 completed (loss: 0.05038871616125107, acc: 0.9865853786468506)
[2024-12-17 02:23:02,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:03,038][root][INFO] - Training Epoch: 1/2, step 6932/7134 completed (loss: 0.07278149574995041, acc: 0.9779411554336548)
[2024-12-17 02:23:03,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:03,375][root][INFO] - Training Epoch: 1/2, step 6933/7134 completed (loss: 0.11313290894031525, acc: 0.9767140746116638)
[2024-12-17 02:23:03,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:03,681][root][INFO] - Training Epoch: 1/2, step 6934/7134 completed (loss: 0.14734603464603424, acc: 0.9695023894309998)
[2024-12-17 02:23:03,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:04,047][root][INFO] - Training Epoch: 1/2, step 6935/7134 completed (loss: 0.1227705180644989, acc: 0.9751309156417847)
[2024-12-17 02:23:04,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:04,407][root][INFO] - Training Epoch: 1/2, step 6936/7134 completed (loss: 0.07198794186115265, acc: 0.9826666712760925)
[2024-12-17 02:23:04,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:04,735][root][INFO] - Training Epoch: 1/2, step 6937/7134 completed (loss: 0.17538069188594818, acc: 0.9562171697616577)
[2024-12-17 02:23:04,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:05,090][root][INFO] - Training Epoch: 1/2, step 6938/7134 completed (loss: 0.15427188575267792, acc: 0.965624988079071)
[2024-12-17 02:23:05,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:05,459][root][INFO] - Training Epoch: 1/2, step 6939/7134 completed (loss: 0.10156361758708954, acc: 0.9819193482398987)
[2024-12-17 02:23:05,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:05,777][root][INFO] - Training Epoch: 1/2, step 6940/7134 completed (loss: 0.12759286165237427, acc: 0.9743150472640991)
[2024-12-17 02:23:05,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:06,084][root][INFO] - Training Epoch: 1/2, step 6941/7134 completed (loss: 0.05413117632269859, acc: 0.9913194179534912)
[2024-12-17 02:23:06,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:06,410][root][INFO] - Training Epoch: 1/2, step 6942/7134 completed (loss: 0.09520366042852402, acc: 0.9698629975318909)
[2024-12-17 02:23:06,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:06,716][root][INFO] - Training Epoch: 1/2, step 6943/7134 completed (loss: 0.07303718477487564, acc: 0.9811715483665466)
[2024-12-17 02:23:06,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:07,071][root][INFO] - Training Epoch: 1/2, step 6944/7134 completed (loss: 0.08066127449274063, acc: 0.9840764403343201)
[2024-12-17 02:23:07,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:07,362][root][INFO] - Training Epoch: 1/2, step 6945/7134 completed (loss: 0.12374742329120636, acc: 0.9720767736434937)
[2024-12-17 02:23:07,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:07,659][root][INFO] - Training Epoch: 1/2, step 6946/7134 completed (loss: 0.08252285420894623, acc: 0.9713466763496399)
[2024-12-17 02:23:07,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:07,979][root][INFO] - Training Epoch: 1/2, step 6947/7134 completed (loss: 0.0760471373796463, acc: 0.97826087474823)
[2024-12-17 02:23:08,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:08,321][root][INFO] - Training Epoch: 1/2, step 6948/7134 completed (loss: 0.11660445481538773, acc: 0.9698492288589478)
[2024-12-17 02:23:08,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:08,639][root][INFO] - Training Epoch: 1/2, step 6949/7134 completed (loss: 0.10116563737392426, acc: 0.9722222089767456)
[2024-12-17 02:23:08,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:08,913][root][INFO] - Training Epoch: 1/2, step 6950/7134 completed (loss: 0.04627500846982002, acc: 0.9897959232330322)
[2024-12-17 02:23:09,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:09,252][root][INFO] - Training Epoch: 1/2, step 6951/7134 completed (loss: 0.05363631248474121, acc: 0.9830508232116699)
[2024-12-17 02:23:09,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:09,542][root][INFO] - Training Epoch: 1/2, step 6952/7134 completed (loss: 0.04705077409744263, acc: 0.9836448431015015)
[2024-12-17 02:23:09,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:09,866][root][INFO] - Training Epoch: 1/2, step 6953/7134 completed (loss: 0.037766821682453156, acc: 0.9868852496147156)
[2024-12-17 02:23:10,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:10,192][root][INFO] - Training Epoch: 1/2, step 6954/7134 completed (loss: 0.10265892744064331, acc: 0.9765458703041077)
[2024-12-17 02:23:10,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:10,501][root][INFO] - Training Epoch: 1/2, step 6955/7134 completed (loss: 0.04547202214598656, acc: 0.9817073345184326)
[2024-12-17 02:23:10,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:10,833][root][INFO] - Training Epoch: 1/2, step 6956/7134 completed (loss: 0.06106134504079819, acc: 0.980461835861206)
[2024-12-17 02:23:10,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:11,154][root][INFO] - Training Epoch: 1/2, step 6957/7134 completed (loss: 0.02770899049937725, acc: 0.9941291809082031)
[2024-12-17 02:23:11,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:11,488][root][INFO] - Training Epoch: 1/2, step 6958/7134 completed (loss: 0.08233179152011871, acc: 0.9766082167625427)
[2024-12-17 02:23:11,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:11,808][root][INFO] - Training Epoch: 1/2, step 6959/7134 completed (loss: 0.048734959214925766, acc: 0.9800443649291992)
[2024-12-17 02:23:11,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:12,140][root][INFO] - Training Epoch: 1/2, step 6960/7134 completed (loss: 0.06198885664343834, acc: 0.9821138381958008)
[2024-12-17 02:23:12,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:12,459][root][INFO] - Training Epoch: 1/2, step 6961/7134 completed (loss: 0.051423944532871246, acc: 0.991919219493866)
[2024-12-17 02:23:12,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:12,782][root][INFO] - Training Epoch: 1/2, step 6962/7134 completed (loss: 0.051393840461969376, acc: 0.9895651936531067)
[2024-12-17 02:23:12,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:13,112][root][INFO] - Training Epoch: 1/2, step 6963/7134 completed (loss: 0.03231961652636528, acc: 0.9898989796638489)
[2024-12-17 02:23:13,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:13,440][root][INFO] - Training Epoch: 1/2, step 6964/7134 completed (loss: 0.036458369344472885, acc: 0.9909747242927551)
[2024-12-17 02:23:13,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:13,772][root][INFO] - Training Epoch: 1/2, step 6965/7134 completed (loss: 0.03375919163227081, acc: 0.9890109896659851)
[2024-12-17 02:23:13,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:14,062][root][INFO] - Training Epoch: 1/2, step 6966/7134 completed (loss: 0.07762408256530762, acc: 0.9725685715675354)
[2024-12-17 02:23:14,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:14,389][root][INFO] - Training Epoch: 1/2, step 6967/7134 completed (loss: 0.033872220665216446, acc: 0.9909502267837524)
[2024-12-17 02:23:14,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:14,709][root][INFO] - Training Epoch: 1/2, step 6968/7134 completed (loss: 0.04327986016869545, acc: 0.9879310131072998)
[2024-12-17 02:23:14,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:15,035][root][INFO] - Training Epoch: 1/2, step 6969/7134 completed (loss: 0.1129174754023552, acc: 0.9729729890823364)
[2024-12-17 02:23:15,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:15,359][root][INFO] - Training Epoch: 1/2, step 6970/7134 completed (loss: 0.125712051987648, acc: 0.9684210419654846)
[2024-12-17 02:23:15,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:15,701][root][INFO] - Training Epoch: 1/2, step 6971/7134 completed (loss: 0.07606212049722672, acc: 0.9758203625679016)
[2024-12-17 02:23:15,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:16,034][root][INFO] - Training Epoch: 1/2, step 6972/7134 completed (loss: 0.041730307042598724, acc: 0.9857397675514221)
[2024-12-17 02:23:16,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:16,349][root][INFO] - Training Epoch: 1/2, step 6973/7134 completed (loss: 0.05147998780012131, acc: 0.984581470489502)
[2024-12-17 02:23:16,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:16,674][root][INFO] - Training Epoch: 1/2, step 6974/7134 completed (loss: 0.054792340844869614, acc: 0.9844827651977539)
[2024-12-17 02:23:16,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:16,990][root][INFO] - Training Epoch: 1/2, step 6975/7134 completed (loss: 0.07293595373630524, acc: 0.9869847893714905)
[2024-12-17 02:23:17,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:17,310][root][INFO] - Training Epoch: 1/2, step 6976/7134 completed (loss: 0.07844748347997665, acc: 0.9826689958572388)
[2024-12-17 02:23:17,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:17,631][root][INFO] - Training Epoch: 1/2, step 6977/7134 completed (loss: 0.0619012787938118, acc: 0.981203019618988)
[2024-12-17 02:23:17,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:17,965][root][INFO] - Training Epoch: 1/2, step 6978/7134 completed (loss: 0.06002464145421982, acc: 0.9853658676147461)
[2024-12-17 02:23:18,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:18,319][root][INFO] - Training Epoch: 1/2, step 6979/7134 completed (loss: 0.10013508051633835, acc: 0.9710366129875183)
[2024-12-17 02:23:18,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:18,675][root][INFO] - Training Epoch: 1/2, step 6980/7134 completed (loss: 0.16715118288993835, acc: 0.9547169804573059)
[2024-12-17 02:23:18,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:19,040][root][INFO] - Training Epoch: 1/2, step 6981/7134 completed (loss: 0.15953651070594788, acc: 0.9565772414207458)
[2024-12-17 02:23:19,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:19,409][root][INFO] - Training Epoch: 1/2, step 6982/7134 completed (loss: 0.17233899235725403, acc: 0.9549329876899719)
[2024-12-17 02:23:19,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:19,765][root][INFO] - Training Epoch: 1/2, step 6983/7134 completed (loss: 0.17484162747859955, acc: 0.9614243507385254)
[2024-12-17 02:23:19,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:20,126][root][INFO] - Training Epoch: 1/2, step 6984/7134 completed (loss: 0.060088302940130234, acc: 0.9828510284423828)
[2024-12-17 02:23:20,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:20,507][root][INFO] - Training Epoch: 1/2, step 6985/7134 completed (loss: 0.1953529268503189, acc: 0.9651281833648682)
[2024-12-17 02:23:20,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:20,850][root][INFO] - Training Epoch: 1/2, step 6986/7134 completed (loss: 0.07776490598917007, acc: 0.9747399687767029)
[2024-12-17 02:23:20,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:21,232][root][INFO] - Training Epoch: 1/2, step 6987/7134 completed (loss: 0.13891544938087463, acc: 0.9585858583450317)
[2024-12-17 02:23:21,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:21,470][root][INFO] - Training Epoch: 1/2, step 6988/7134 completed (loss: 0.08000603318214417, acc: 0.9821073412895203)
[2024-12-17 02:23:21,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:21,761][root][INFO] - Training Epoch: 1/2, step 6989/7134 completed (loss: 0.257327675819397, acc: 0.9418181777000427)
[2024-12-17 02:23:21,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:22,076][root][INFO] - Training Epoch: 1/2, step 6990/7134 completed (loss: 0.09376221895217896, acc: 0.9776785969734192)
[2024-12-17 02:23:22,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:22,370][root][INFO] - Training Epoch: 1/2, step 6991/7134 completed (loss: 0.11234019696712494, acc: 0.9674185514450073)
[2024-12-17 02:23:22,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:22,696][root][INFO] - Training Epoch: 1/2, step 6992/7134 completed (loss: 0.1154153048992157, acc: 0.9663158059120178)
[2024-12-17 02:23:22,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:23,037][root][INFO] - Training Epoch: 1/2, step 6993/7134 completed (loss: 0.1920233517885208, acc: 0.953242838382721)
[2024-12-17 02:23:23,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:23,410][root][INFO] - Training Epoch: 1/2, step 6994/7134 completed (loss: 0.20021362602710724, acc: 0.9550561904907227)
[2024-12-17 02:23:23,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:23,758][root][INFO] - Training Epoch: 1/2, step 6995/7134 completed (loss: 0.06742101907730103, acc: 0.9869109988212585)
[2024-12-17 02:23:23,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:24,085][root][INFO] - Training Epoch: 1/2, step 6996/7134 completed (loss: 0.09559406340122223, acc: 0.9772727489471436)
[2024-12-17 02:23:24,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:24,409][root][INFO] - Training Epoch: 1/2, step 6997/7134 completed (loss: 0.11823033541440964, acc: 0.9688473343849182)
[2024-12-17 02:23:24,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:24,684][root][INFO] - Training Epoch: 1/2, step 6998/7134 completed (loss: 0.22105826437473297, acc: 0.936274528503418)
[2024-12-17 02:23:24,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:25,058][root][INFO] - Training Epoch: 1/2, step 6999/7134 completed (loss: 0.09532731026411057, acc: 0.9764705896377563)
[2024-12-17 02:23:25,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:25,317][root][INFO] - Training Epoch: 1/2, step 7000/7134 completed (loss: 0.08015257120132446, acc: 0.9809321761131287)
[2024-12-17 02:23:25,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:25,664][root][INFO] - Training Epoch: 1/2, step 7001/7134 completed (loss: 0.15323124825954437, acc: 0.9668674468994141)
[2024-12-17 02:23:25,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:26,018][root][INFO] - Training Epoch: 1/2, step 7002/7134 completed (loss: 0.06880206614732742, acc: 0.9797160029411316)
[2024-12-17 02:23:26,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:26,376][root][INFO] - Training Epoch: 1/2, step 7003/7134 completed (loss: 0.06500518321990967, acc: 0.9791894555091858)
[2024-12-17 02:23:26,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:26,742][root][INFO] - Training Epoch: 1/2, step 7004/7134 completed (loss: 0.15903078019618988, acc: 0.9619422554969788)
[2024-12-17 02:23:26,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:27,108][root][INFO] - Training Epoch: 1/2, step 7005/7134 completed (loss: 0.1128668561577797, acc: 0.9635627269744873)
[2024-12-17 02:23:27,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:27,471][root][INFO] - Training Epoch: 1/2, step 7006/7134 completed (loss: 0.10241155326366425, acc: 0.9740082025527954)
[2024-12-17 02:23:27,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:27,825][root][INFO] - Training Epoch: 1/2, step 7007/7134 completed (loss: 0.07700726389884949, acc: 0.9805389046669006)
[2024-12-17 02:23:27,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:28,163][root][INFO] - Training Epoch: 1/2, step 7008/7134 completed (loss: 0.08492808789014816, acc: 0.9790382385253906)
[2024-12-17 02:23:28,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:28,523][root][INFO] - Training Epoch: 1/2, step 7009/7134 completed (loss: 0.08397693186998367, acc: 0.9733796119689941)
[2024-12-17 02:23:28,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:28,849][root][INFO] - Training Epoch: 1/2, step 7010/7134 completed (loss: 0.07999041676521301, acc: 0.9799692034721375)
[2024-12-17 02:23:28,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:29,205][root][INFO] - Training Epoch: 1/2, step 7011/7134 completed (loss: 0.07241202145814896, acc: 0.9771634340286255)
[2024-12-17 02:23:29,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:29,520][root][INFO] - Training Epoch: 1/2, step 7012/7134 completed (loss: 0.1278030425310135, acc: 0.9766764044761658)
[2024-12-17 02:23:29,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:29,874][root][INFO] - Training Epoch: 1/2, step 7013/7134 completed (loss: 0.04162260517477989, acc: 0.9884726405143738)
[2024-12-17 02:23:30,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:30,206][root][INFO] - Training Epoch: 1/2, step 7014/7134 completed (loss: 0.04737091064453125, acc: 0.9871175289154053)
[2024-12-17 02:23:30,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:30,523][root][INFO] - Training Epoch: 1/2, step 7015/7134 completed (loss: 0.07720959931612015, acc: 0.971377432346344)
[2024-12-17 02:23:30,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:30,888][root][INFO] - Training Epoch: 1/2, step 7016/7134 completed (loss: 0.09396752715110779, acc: 0.97398841381073)
[2024-12-17 02:23:31,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:31,169][root][INFO] - Training Epoch: 1/2, step 7017/7134 completed (loss: 0.08977488428354263, acc: 0.9792531132698059)
[2024-12-17 02:23:31,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:31,505][root][INFO] - Training Epoch: 1/2, step 7018/7134 completed (loss: 0.09180732071399689, acc: 0.9782945513725281)
[2024-12-17 02:23:31,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:31,818][root][INFO] - Training Epoch: 1/2, step 7019/7134 completed (loss: 0.15190275013446808, acc: 0.957602322101593)
[2024-12-17 02:23:31,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:32,156][root][INFO] - Training Epoch: 1/2, step 7020/7134 completed (loss: 0.04008534923195839, acc: 0.994358241558075)
[2024-12-17 02:23:32,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:32,541][root][INFO] - Training Epoch: 1/2, step 7021/7134 completed (loss: 0.05210890620946884, acc: 0.9846677780151367)
[2024-12-17 02:23:32,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:32,829][root][INFO] - Training Epoch: 1/2, step 7022/7134 completed (loss: 0.17088572680950165, acc: 0.9567901492118835)
[2024-12-17 02:23:32,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:33,134][root][INFO] - Training Epoch: 1/2, step 7023/7134 completed (loss: 0.11070255935192108, acc: 0.9713603854179382)
[2024-12-17 02:23:33,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:33,398][root][INFO] - Training Epoch: 1/2, step 7024/7134 completed (loss: 0.08203525841236115, acc: 0.9808917045593262)
[2024-12-17 02:23:33,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:33,702][root][INFO] - Training Epoch: 1/2, step 7025/7134 completed (loss: 0.18048560619354248, acc: 0.951724112033844)
[2024-12-17 02:23:33,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:33,983][root][INFO] - Training Epoch: 1/2, step 7026/7134 completed (loss: 0.23150396347045898, acc: 0.9459459185600281)
[2024-12-17 02:23:34,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:34,261][root][INFO] - Training Epoch: 1/2, step 7027/7134 completed (loss: 0.05929356813430786, acc: 0.9847561120986938)
[2024-12-17 02:23:34,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:34,564][root][INFO] - Training Epoch: 1/2, step 7028/7134 completed (loss: 0.03445388004183769, acc: 0.9927361011505127)
[2024-12-17 02:23:34,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:34,848][root][INFO] - Training Epoch: 1/2, step 7029/7134 completed (loss: 0.07340861856937408, acc: 0.9814385175704956)
[2024-12-17 02:23:34,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:35,127][root][INFO] - Training Epoch: 1/2, step 7030/7134 completed (loss: 0.17302998900413513, acc: 0.9478672742843628)
[2024-12-17 02:23:35,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:35,432][root][INFO] - Training Epoch: 1/2, step 7031/7134 completed (loss: 0.13714253902435303, acc: 0.9593908786773682)
[2024-12-17 02:23:35,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:35,703][root][INFO] - Training Epoch: 1/2, step 7032/7134 completed (loss: 0.10563638806343079, acc: 0.9674796462059021)
[2024-12-17 02:23:35,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:35,968][root][INFO] - Training Epoch: 1/2, step 7033/7134 completed (loss: 0.10086829215288162, acc: 0.9677419066429138)
[2024-12-17 02:23:36,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:36,249][root][INFO] - Training Epoch: 1/2, step 7034/7134 completed (loss: 0.1358601152896881, acc: 0.9646643400192261)
[2024-12-17 02:23:36,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:36,540][root][INFO] - Training Epoch: 1/2, step 7035/7134 completed (loss: 0.14884260296821594, acc: 0.9603174328804016)
[2024-12-17 02:23:36,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:36,774][root][INFO] - Training Epoch: 1/2, step 7036/7134 completed (loss: 0.14115974307060242, acc: 0.9547325372695923)
[2024-12-17 02:23:36,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:37,010][root][INFO] - Training Epoch: 1/2, step 7037/7134 completed (loss: 0.05539821460843086, acc: 0.98046875)
[2024-12-17 02:23:37,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:37,294][root][INFO] - Training Epoch: 1/2, step 7038/7134 completed (loss: 0.13329362869262695, acc: 0.960422158241272)
[2024-12-17 02:23:37,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:37,585][root][INFO] - Training Epoch: 1/2, step 7039/7134 completed (loss: 0.09094258397817612, acc: 0.9710144996643066)
[2024-12-17 02:23:37,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:37,876][root][INFO] - Training Epoch: 1/2, step 7040/7134 completed (loss: 0.21314141154289246, acc: 0.9425287246704102)
[2024-12-17 02:23:37,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:38,148][root][INFO] - Training Epoch: 1/2, step 7041/7134 completed (loss: 0.19390137493610382, acc: 0.9496855139732361)
[2024-12-17 02:23:38,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:38,429][root][INFO] - Training Epoch: 1/2, step 7042/7134 completed (loss: 0.1398918330669403, acc: 0.9692307710647583)
[2024-12-17 02:23:38,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:38,701][root][INFO] - Training Epoch: 1/2, step 7043/7134 completed (loss: 0.1590735912322998, acc: 0.9546666741371155)
[2024-12-17 02:23:38,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:38,969][root][INFO] - Training Epoch: 1/2, step 7044/7134 completed (loss: 0.1319291889667511, acc: 0.9510703086853027)
[2024-12-17 02:23:39,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:39,289][root][INFO] - Training Epoch: 1/2, step 7045/7134 completed (loss: 0.0704314336180687, acc: 0.9812925457954407)
[2024-12-17 02:23:39,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:39,649][root][INFO] - Training Epoch: 1/2, step 7046/7134 completed (loss: 0.13501392304897308, acc: 0.9726775884628296)
[2024-12-17 02:23:39,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:40,017][root][INFO] - Training Epoch: 1/2, step 7047/7134 completed (loss: 0.12647128105163574, acc: 0.9690476059913635)
[2024-12-17 02:23:40,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:40,366][root][INFO] - Training Epoch: 1/2, step 7048/7134 completed (loss: 0.027566593140363693, acc: 0.9941245317459106)
[2024-12-17 02:23:40,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:40,688][root][INFO] - Training Epoch: 1/2, step 7049/7134 completed (loss: 0.06482937932014465, acc: 0.9826202988624573)
[2024-12-17 02:23:40,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:41,018][root][INFO] - Training Epoch: 1/2, step 7050/7134 completed (loss: 0.05122360214591026, acc: 0.9831606149673462)
[2024-12-17 02:23:41,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:41,369][root][INFO] - Training Epoch: 1/2, step 7051/7134 completed (loss: 0.08910511434078217, acc: 0.9785082340240479)
[2024-12-17 02:23:41,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:41,728][root][INFO] - Training Epoch: 1/2, step 7052/7134 completed (loss: 0.09780562669038773, acc: 0.9733688235282898)
[2024-12-17 02:23:41,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:42,090][root][INFO] - Training Epoch: 1/2, step 7053/7134 completed (loss: 0.02607409842312336, acc: 0.9914737939834595)
[2024-12-17 02:23:42,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:42,444][root][INFO] - Training Epoch: 1/2, step 7054/7134 completed (loss: 0.08321619778871536, acc: 0.982594907283783)
[2024-12-17 02:23:42,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:42,781][root][INFO] - Training Epoch: 1/2, step 7055/7134 completed (loss: 0.06345216184854507, acc: 0.9795918464660645)
[2024-12-17 02:23:42,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:43,158][root][INFO] - Training Epoch: 1/2, step 7056/7134 completed (loss: 0.08200758695602417, acc: 0.9843937754631042)
[2024-12-17 02:23:43,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:43,526][root][INFO] - Training Epoch: 1/2, step 7057/7134 completed (loss: 0.1989951729774475, acc: 0.9589040875434875)
[2024-12-17 02:23:43,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:43,868][root][INFO] - Training Epoch: 1/2, step 7058/7134 completed (loss: 0.10045062005519867, acc: 0.9685039520263672)
[2024-12-17 02:23:43,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:44,210][root][INFO] - Training Epoch: 1/2, step 7059/7134 completed (loss: 0.03198758512735367, acc: 0.99301677942276)
[2024-12-17 02:23:44,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:44,532][root][INFO] - Training Epoch: 1/2, step 7060/7134 completed (loss: 0.09665808826684952, acc: 0.977419376373291)
[2024-12-17 02:23:44,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:44,875][root][INFO] - Training Epoch: 1/2, step 7061/7134 completed (loss: 0.0895569920539856, acc: 0.9765625)
[2024-12-17 02:23:44,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:45,201][root][INFO] - Training Epoch: 1/2, step 7062/7134 completed (loss: 0.1639254093170166, acc: 0.9555555582046509)
[2024-12-17 02:23:45,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:45,549][root][INFO] - Training Epoch: 1/2, step 7063/7134 completed (loss: 0.09260989725589752, acc: 0.9816993474960327)
[2024-12-17 02:23:45,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:45,919][root][INFO] - Training Epoch: 1/2, step 7064/7134 completed (loss: 0.05670427531003952, acc: 0.9836795330047607)
[2024-12-17 02:23:46,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:46,274][root][INFO] - Training Epoch: 1/2, step 7065/7134 completed (loss: 0.056071870028972626, acc: 0.9907299876213074)
[2024-12-17 02:23:46,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:46,634][root][INFO] - Training Epoch: 1/2, step 7066/7134 completed (loss: 0.05461613088846207, acc: 0.9916765689849854)
[2024-12-17 02:23:46,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:46,979][root][INFO] - Training Epoch: 1/2, step 7067/7134 completed (loss: 0.05821679159998894, acc: 0.9847133755683899)
[2024-12-17 02:23:47,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:47,341][root][INFO] - Training Epoch: 1/2, step 7068/7134 completed (loss: 0.03848925977945328, acc: 0.9891435503959656)
[2024-12-17 02:23:47,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:47,720][root][INFO] - Training Epoch: 1/2, step 7069/7134 completed (loss: 0.05333656072616577, acc: 0.983234703540802)
[2024-12-17 02:23:47,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:48,064][root][INFO] - Training Epoch: 1/2, step 7070/7134 completed (loss: 0.05515130236744881, acc: 0.9890260696411133)
[2024-12-17 02:23:48,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:48,398][root][INFO] - Training Epoch: 1/2, step 7071/7134 completed (loss: 0.08206605911254883, acc: 0.9849624037742615)
[2024-12-17 02:23:48,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:48,746][root][INFO] - Training Epoch: 1/2, step 7072/7134 completed (loss: 0.053565457463264465, acc: 0.9818181991577148)
[2024-12-17 02:23:48,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:49,126][root][INFO] - Training Epoch: 1/2, step 7073/7134 completed (loss: 0.06429672241210938, acc: 0.9840728044509888)
[2024-12-17 02:23:49,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:49,440][root][INFO] - Training Epoch: 1/2, step 7074/7134 completed (loss: 0.06291013956069946, acc: 0.980879545211792)
[2024-12-17 02:23:49,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:49,783][root][INFO] - Training Epoch: 1/2, step 7075/7134 completed (loss: 0.07238632440567017, acc: 0.9835575222969055)
[2024-12-17 02:23:49,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:50,100][root][INFO] - Training Epoch: 1/2, step 7076/7134 completed (loss: 0.06659665703773499, acc: 0.9829059839248657)
[2024-12-17 02:23:50,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:50,410][root][INFO] - Training Epoch: 1/2, step 7077/7134 completed (loss: 0.06610767543315887, acc: 0.980327844619751)
[2024-12-17 02:23:50,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:50,741][root][INFO] - Training Epoch: 1/2, step 7078/7134 completed (loss: 0.05775931105017662, acc: 0.9839743375778198)
[2024-12-17 02:23:50,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:51,065][root][INFO] - Training Epoch: 1/2, step 7079/7134 completed (loss: 0.07289379090070724, acc: 0.9852216839790344)
[2024-12-17 02:23:51,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:51,381][root][INFO] - Training Epoch: 1/2, step 7080/7134 completed (loss: 0.07585787028074265, acc: 0.9767441749572754)
[2024-12-17 02:23:51,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:51,728][root][INFO] - Training Epoch: 1/2, step 7081/7134 completed (loss: 0.06230079010128975, acc: 0.9817671775817871)
[2024-12-17 02:23:51,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:52,055][root][INFO] - Training Epoch: 1/2, step 7082/7134 completed (loss: 0.061530716717243195, acc: 0.9789983630180359)
[2024-12-17 02:23:52,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:52,381][root][INFO] - Training Epoch: 1/2, step 7083/7134 completed (loss: 0.060121357440948486, acc: 0.9849498271942139)
[2024-12-17 02:23:52,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:52,714][root][INFO] - Training Epoch: 1/2, step 7084/7134 completed (loss: 0.0690067782998085, acc: 0.9840348362922668)
[2024-12-17 02:23:52,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:53,034][root][INFO] - Training Epoch: 1/2, step 7085/7134 completed (loss: 0.07486243546009064, acc: 0.9814814925193787)
[2024-12-17 02:23:53,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:53,385][root][INFO] - Training Epoch: 1/2, step 7086/7134 completed (loss: 0.049960698932409286, acc: 0.9863201379776001)
[2024-12-17 02:23:53,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:53,726][root][INFO] - Training Epoch: 1/2, step 7087/7134 completed (loss: 0.05215331166982651, acc: 0.9907578825950623)
[2024-12-17 02:23:53,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:54,061][root][INFO] - Training Epoch: 1/2, step 7088/7134 completed (loss: 0.09418699145317078, acc: 0.9801324605941772)
[2024-12-17 02:23:54,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:54,384][root][INFO] - Training Epoch: 1/2, step 7089/7134 completed (loss: 0.12519267201423645, acc: 0.9745222926139832)
[2024-12-17 02:23:54,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:54,729][root][INFO] - Training Epoch: 1/2, step 7090/7134 completed (loss: 0.06817899644374847, acc: 0.9837398529052734)
[2024-12-17 02:23:54,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:55,056][root][INFO] - Training Epoch: 1/2, step 7091/7134 completed (loss: 0.018954802304506302, acc: 0.9958217144012451)
[2024-12-17 02:23:55,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:55,397][root][INFO] - Training Epoch: 1/2, step 7092/7134 completed (loss: 0.06065485253930092, acc: 0.9828473329544067)
[2024-12-17 02:23:55,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:55,695][root][INFO] - Training Epoch: 1/2, step 7093/7134 completed (loss: 0.08011563867330551, acc: 0.97817462682724)
[2024-12-17 02:23:55,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:56,008][root][INFO] - Training Epoch: 1/2, step 7094/7134 completed (loss: 0.04250418767333031, acc: 0.9884792566299438)
[2024-12-17 02:23:56,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:56,334][root][INFO] - Training Epoch: 1/2, step 7095/7134 completed (loss: 0.06587552279233932, acc: 0.9896694421768188)
[2024-12-17 02:23:56,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:56,648][root][INFO] - Training Epoch: 1/2, step 7096/7134 completed (loss: 0.07955551892518997, acc: 0.9764705896377563)
[2024-12-17 02:23:56,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:56,980][root][INFO] - Training Epoch: 1/2, step 7097/7134 completed (loss: 0.13459406793117523, acc: 0.9769452214241028)
[2024-12-17 02:23:57,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:57,304][root][INFO] - Training Epoch: 1/2, step 7098/7134 completed (loss: 0.06063463166356087, acc: 0.9823434948921204)
[2024-12-17 02:23:57,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:57,597][root][INFO] - Training Epoch: 1/2, step 7099/7134 completed (loss: 0.07519621402025223, acc: 0.9794871807098389)
[2024-12-17 02:23:57,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:57,929][root][INFO] - Training Epoch: 1/2, step 7100/7134 completed (loss: 0.13058331608772278, acc: 0.9674418568611145)
[2024-12-17 02:23:58,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:58,204][root][INFO] - Training Epoch: 1/2, step 7101/7134 completed (loss: 0.12691932916641235, acc: 0.9821109175682068)
[2024-12-17 02:23:58,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:58,542][root][INFO] - Training Epoch: 1/2, step 7102/7134 completed (loss: 0.032201431691646576, acc: 0.9903100728988647)
[2024-12-17 02:23:58,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:58,824][root][INFO] - Training Epoch: 1/2, step 7103/7134 completed (loss: 0.05388478562235832, acc: 0.9838709831237793)
[2024-12-17 02:23:58,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:59,148][root][INFO] - Training Epoch: 1/2, step 7104/7134 completed (loss: 0.035526227205991745, acc: 0.9876543283462524)
[2024-12-17 02:23:59,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:59,473][root][INFO] - Training Epoch: 1/2, step 7105/7134 completed (loss: 0.061433594673871994, acc: 0.9850000143051147)
[2024-12-17 02:23:59,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:59,785][root][INFO] - Training Epoch: 1/2, step 7106/7134 completed (loss: 0.02941814251244068, acc: 0.9933221936225891)
[2024-12-17 02:23:59,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:00,112][root][INFO] - Training Epoch: 1/2, step 7107/7134 completed (loss: 0.033882711082696915, acc: 0.9906832575798035)
[2024-12-17 02:24:00,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:00,436][root][INFO] - Training Epoch: 1/2, step 7108/7134 completed (loss: 0.0448685921728611, acc: 0.9866666793823242)
[2024-12-17 02:24:00,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:00,733][root][INFO] - Training Epoch: 1/2, step 7109/7134 completed (loss: 0.10695315897464752, acc: 0.9643527269363403)
[2024-12-17 02:24:00,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:01,061][root][INFO] - Training Epoch: 1/2, step 7110/7134 completed (loss: 0.05133228749036789, acc: 0.9864406585693359)
[2024-12-17 02:24:01,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:01,343][root][INFO] - Training Epoch: 1/2, step 7111/7134 completed (loss: 0.10357830673456192, acc: 0.9711751937866211)
[2024-12-17 02:24:01,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:01,672][root][INFO] - Training Epoch: 1/2, step 7112/7134 completed (loss: 0.07610111683607101, acc: 0.9814814925193787)
[2024-12-17 02:24:01,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:02,025][root][INFO] - Training Epoch: 1/2, step 7113/7134 completed (loss: 0.1343912035226822, acc: 0.9637224078178406)
[2024-12-17 02:24:02,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:02,344][root][INFO] - Training Epoch: 1/2, step 7114/7134 completed (loss: 0.03794052451848984, acc: 0.9923518300056458)
[2024-12-17 02:24:02,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:02,661][root][INFO] - Training Epoch: 1/2, step 7115/7134 completed (loss: 0.04840625077486038, acc: 0.9858906269073486)
[2024-12-17 02:24:02,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:02,989][root][INFO] - Training Epoch: 1/2, step 7116/7134 completed (loss: 0.06252660602331161, acc: 0.9859402179718018)
[2024-12-17 02:24:03,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:03,318][root][INFO] - Training Epoch: 1/2, step 7117/7134 completed (loss: 0.053239721804857254, acc: 0.9883333444595337)
[2024-12-17 02:24:03,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:03,655][root][INFO] - Training Epoch: 1/2, step 7118/7134 completed (loss: 0.07120557129383087, acc: 0.979651153087616)
[2024-12-17 02:24:03,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:03,993][root][INFO] - Training Epoch: 1/2, step 7119/7134 completed (loss: 0.033044151961803436, acc: 0.9918166995048523)
[2024-12-17 02:24:04,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:04,298][root][INFO] - Training Epoch: 1/2, step 7120/7134 completed (loss: 0.05446118488907814, acc: 0.9883177280426025)
[2024-12-17 02:24:04,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:04,618][root][INFO] - Training Epoch: 1/2, step 7121/7134 completed (loss: 0.0423608124256134, acc: 0.9876760840415955)
[2024-12-17 02:24:04,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:04,895][root][INFO] - Training Epoch: 1/2, step 7122/7134 completed (loss: 0.04875374212861061, acc: 0.9866310358047485)
[2024-12-17 02:24:05,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:05,169][root][INFO] - Training Epoch: 1/2, step 7123/7134 completed (loss: 0.0748276561498642, acc: 0.9829268455505371)
[2024-12-17 02:24:05,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:05,529][root][INFO] - Training Epoch: 1/2, step 7124/7134 completed (loss: 0.03619515523314476, acc: 0.9812382459640503)
[2024-12-17 02:24:05,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:05,830][root][INFO] - Training Epoch: 1/2, step 7125/7134 completed (loss: 0.04518750682473183, acc: 0.9850746393203735)
[2024-12-17 02:24:05,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:06,160][root][INFO] - Training Epoch: 1/2, step 7126/7134 completed (loss: 0.14765970408916473, acc: 0.9645868539810181)
[2024-12-17 02:24:06,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:06,466][root][INFO] - Training Epoch: 1/2, step 7127/7134 completed (loss: 0.07245227694511414, acc: 0.9808917045593262)
[2024-12-17 02:24:06,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:06,783][root][INFO] - Training Epoch: 1/2, step 7128/7134 completed (loss: 0.06986202299594879, acc: 0.9723577499389648)
[2024-12-17 02:24:06,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:07,109][root][INFO] - Training Epoch: 1/2, step 7129/7134 completed (loss: 0.1070818305015564, acc: 0.9709172248840332)
[2024-12-17 02:24:07,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:07,450][root][INFO] - Training Epoch: 1/2, step 7130/7134 completed (loss: 0.16533048450946808, acc: 0.9482142925262451)
[2024-12-17 02:24:07,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:07,770][root][INFO] - Training Epoch: 1/2, step 7131/7134 completed (loss: 0.03009788691997528, acc: 0.9907192587852478)
[2024-12-17 02:24:08,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:08,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:09,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:09,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:09,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:09,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:10,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:10,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:10,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:10,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:11,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:11,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:11,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:11,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:12,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:12,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:12,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:12,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:13,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:13,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:13,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:13,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:14,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:14,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:14,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:14,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:15,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:15,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:15,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:15,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:16,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:16,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:17,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:17,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:17,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:17,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:18,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:18,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:18,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:18,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:18,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:19,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:19,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:19,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:20,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:20,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:20,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:21,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:21,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:21,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:22,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:22,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:22,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:22,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:23,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:23,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:23,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:24,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:24,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:24,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:24,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:25,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:25,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:25,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:25,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:26,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:26,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:26,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:27,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:27,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:27,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:27,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:28,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:28,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:28,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:28,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:29,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:29,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:29,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:30,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:30,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:30,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:31,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:31,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:31,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:31,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:32,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:32,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:32,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:33,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:33,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:33,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:34,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:34,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:34,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:34,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:35,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:35,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:35,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:35,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:36,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:36,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:36,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:37,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:37,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:37,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:37,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:38,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:38,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:38,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:38,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:39,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:39,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:39,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:39,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:40,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:40,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:40,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:40,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:41,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:41,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:41,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:42,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:42,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:42,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:42,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:43,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:43,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:43,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:43,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:44,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:44,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:44,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:45,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:45,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:45,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:45,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:46,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:46,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:46,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:47,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:47,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:47,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:47,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:48,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:48,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:48,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:49,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:49,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:49,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:49,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:50,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:50,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:50,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:51,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:51,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:51,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:51,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:52,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:52,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:52,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:53,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:53,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:53,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:53,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:54,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:54,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:54,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:55,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:55,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:55,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:55,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:56,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:56,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:56,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:57,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:57,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:57,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:57,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:58,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:58,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:58,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:58,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:59,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:59,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:59,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:00,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:00,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:00,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:00,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:01,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:01,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:01,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:02,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:02,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:02,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:02,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:03,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:03,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:03,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:04,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:04,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:04,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:04,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:05,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:05,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:05,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:05,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:06,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:06,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:06,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:06,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:07,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:07,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:07,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:07,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:08,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:08,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:08,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:08,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:09,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:09,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:09,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:10,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:10,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:10,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:10,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:11,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:11,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:11,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:12,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:12,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:12,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:12,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:13,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:13,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:13,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:13,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:14,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:14,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:14,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:15,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:15,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:15,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:16,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:16,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:16,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:17,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:17,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:18,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:18,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:18,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:18,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:19,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:19,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:19,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:19,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:20,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:20,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:20,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:21,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:21,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:21,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:21,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:22,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:22,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:22,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:23,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:23,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:23,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:23,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:24,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:24,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:25,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:25,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:25,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:25,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:26,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:26,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:26,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:27,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:27,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:28,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:28,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:28,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:28,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:29,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:29,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:30,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:30,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:30,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:31,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:31,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:31,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:32,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:32,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:32,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:33,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:33,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:33,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:34,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:34,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:34,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:34,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:35,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:35,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:35,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:35,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:36,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:36,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:36,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:36,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:37,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:37,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:37,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:38,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:38,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:38,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:38,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:39,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:39,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:40,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:40,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:40,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:40,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:41,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:41,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:42,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:42,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:42,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:43,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:43,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:43,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:43,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:44,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:44,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:44,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:45,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:45,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:45,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:46,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:46,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:47,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:47,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:47,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:48,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:48,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:48,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:49,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:49,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:49,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:49,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:50,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:50,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:50,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:50,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:51,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:51,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:51,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:52,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:52,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:53,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:53,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:54,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:54,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:55,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:55,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:55,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:55,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:56,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:56,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:56,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:57,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:57,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:57,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:57,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:58,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:58,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:58,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:59,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:59,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:59,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:00,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:00,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:00,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:00,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:01,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:01,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:01,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:02,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:02,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:02,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:02,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:03,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:03,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:03,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:03,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:04,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:04,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:04,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:04,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:04,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:05,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:05,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:05,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:05,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:06,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:06,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:06,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:06,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:06,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:07,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:07,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:07,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:07,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:08,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:08,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:08,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:09,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:09,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:09,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:09,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:10,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:10,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:10,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:11,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:11,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:11,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:11,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:12,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:12,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:12,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:12,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:13,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:13,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:13,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:13,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:14,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:14,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:14,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:15,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:15,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:15,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:15,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:16,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:16,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:16,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:17,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:17,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:17,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:17,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:18,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:18,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:18,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:18,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:19,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:19,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:19,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:20,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:20,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:20,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:20,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:21,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:21,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:21,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:22,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:22,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:22,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:22,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:23,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:23,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:23,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:23,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:24,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:24,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:24,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:25,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:25,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:25,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:26,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:26,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:26,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:27,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:27,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:27,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:28,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:28,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:28,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:28,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:29,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:29,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:29,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:30,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:30,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:30,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:31,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:31,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:31,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:31,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:32,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:32,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:32,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:33,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:33,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:34,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:34,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:34,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:34,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:35,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:35,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:35,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:36,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:36,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:36,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:36,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:37,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:37,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:37,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:37,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:38,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:38,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:38,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:39,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:39,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:39,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:39,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:40,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:40,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:40,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:40,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:41,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:41,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:41,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:41,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:42,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:42,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:43,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:43,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:43,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:43,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:44,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:44,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:44,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:44,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:45,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:45,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:45,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:45,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:46,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:46,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:46,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:47,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:47,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:47,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:48,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:48,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:48,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:48,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:49,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:49,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:49,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:49,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:49,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:50,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:50,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:50,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:51,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:51,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:51,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:52,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:52,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:52,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:52,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:53,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:53,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:53,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:54,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:54,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:54,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:55,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:55,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:55,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:56,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:56,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:56,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:57,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:57,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:57,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:58,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:58,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:58,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:58,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:59,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:59,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:59,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:00,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:00,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:00,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:00,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:01,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:01,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:01,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:01,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:02,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:02,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:02,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:03,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:03,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:03,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:03,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:04,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:04,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:04,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:05,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:05,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:05,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:05,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:06,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:06,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:06,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:07,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:07,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:07,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:07,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:08,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:08,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:09,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:10,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:10,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:10,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:11,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:11,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:11,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:12,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:12,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:12,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:13,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:13,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:13,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:14,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:14,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:14,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:14,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:15,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:15,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:15,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:16,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:16,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:16,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:17,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:17,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:17,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:17,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:18,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:18,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:18,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:19,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:19,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:19,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:19,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:20,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:20,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:20,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:20,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:21,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:21,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:21,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:22,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:22,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:22,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:23,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:23,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:23,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:23,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:24,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:25,070][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.0865, device='cuda:0') eval_epoch_loss=tensor(0.0830, device='cuda:0') eval_epoch_acc=tensor(0.9782, device='cuda:0')
[2024-12-17 02:27:25,072][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-12-17 02:27:25,073][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 02:27:25,329][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_1_step_7132_loss_0.08298046886920929/model.pt
[2024-12-17 02:27:25,338][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 0.08298046886920929
[2024-12-17 02:27:25,339][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.9781712889671326
[2024-12-17 02:27:25,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:25,643][root][INFO] - Training Epoch: 1/2, step 7132/7134 completed (loss: 0.04671201854944229, acc: 0.9865319728851318)
[2024-12-17 02:27:25,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:25,937][root][INFO] - Training Epoch: 1/2, step 7133/7134 completed (loss: 0.017127925530076027, acc: 0.9944547414779663)
[2024-12-17 02:27:26,626][slam_llm.utils.train_utils][INFO] - Epoch 1: train_perplexity=1.4818, train_epoch_loss=0.3933, epoch time 3221.937053885311s
[2024-12-17 02:27:26,626][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 12 GB
[2024-12-17 02:27:26,626][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 30 GB
[2024-12-17 02:27:26,626][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 12 GB
[2024-12-17 02:27:26,626][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 5
[2024-12-17 02:27:26,626][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 7 GB
[2024-12-17 02:27:27,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:27,677][root][INFO] - Training Epoch: 2/2, step 0/7134 completed (loss: 0.04043697938323021, acc: 0.98959881067276)
[2024-12-17 02:27:27,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:28,029][root][INFO] - Training Epoch: 2/2, step 1/7134 completed (loss: 0.054395370185375214, acc: 0.9832636117935181)
[2024-12-17 02:27:28,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:28,408][root][INFO] - Training Epoch: 2/2, step 2/7134 completed (loss: 0.047151077538728714, acc: 0.9852744340896606)
[2024-12-17 02:27:28,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:28,747][root][INFO] - Training Epoch: 2/2, step 3/7134 completed (loss: 0.016581857576966286, acc: 0.994878351688385)
[2024-12-17 02:27:28,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:29,084][root][INFO] - Training Epoch: 2/2, step 4/7134 completed (loss: 0.03912493214011192, acc: 0.9890859723091125)
[2024-12-17 02:27:29,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:29,425][root][INFO] - Training Epoch: 2/2, step 5/7134 completed (loss: 0.042409006506204605, acc: 0.989847719669342)
[2024-12-17 02:27:29,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:29,759][root][INFO] - Training Epoch: 2/2, step 6/7134 completed (loss: 0.016488540917634964, acc: 0.9967897534370422)
[2024-12-17 02:27:29,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:30,097][root][INFO] - Training Epoch: 2/2, step 7/7134 completed (loss: 0.06728379428386688, acc: 0.9800747036933899)
[2024-12-17 02:27:30,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:30,458][root][INFO] - Training Epoch: 2/2, step 8/7134 completed (loss: 0.08487897366285324, acc: 0.9793672561645508)
[2024-12-17 02:27:30,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:30,785][root][INFO] - Training Epoch: 2/2, step 9/7134 completed (loss: 0.017594527453184128, acc: 0.9922480583190918)
[2024-12-17 02:27:30,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:31,204][root][INFO] - Training Epoch: 2/2, step 10/7134 completed (loss: 0.055836308747529984, acc: 0.9843527674674988)
[2024-12-17 02:27:31,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:31,551][root][INFO] - Training Epoch: 2/2, step 11/7134 completed (loss: 0.01497932430356741, acc: 0.9943714737892151)
[2024-12-17 02:27:31,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:31,911][root][INFO] - Training Epoch: 2/2, step 12/7134 completed (loss: 0.021842725574970245, acc: 0.9919246435165405)
[2024-12-17 02:27:32,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:32,239][root][INFO] - Training Epoch: 2/2, step 13/7134 completed (loss: 0.05440433695912361, acc: 0.9862448573112488)
[2024-12-17 02:27:32,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:32,564][root][INFO] - Training Epoch: 2/2, step 14/7134 completed (loss: 0.015192094258964062, acc: 0.9983193278312683)
[2024-12-17 02:27:32,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:32,882][root][INFO] - Training Epoch: 2/2, step 15/7134 completed (loss: 0.03763941302895546, acc: 0.9896729588508606)
[2024-12-17 02:27:32,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:33,206][root][INFO] - Training Epoch: 2/2, step 16/7134 completed (loss: 0.02182026393711567, acc: 0.9939024448394775)
[2024-12-17 02:27:33,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:33,499][root][INFO] - Training Epoch: 2/2, step 17/7134 completed (loss: 0.09426676481962204, acc: 0.9756757020950317)
[2024-12-17 02:27:33,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:33,836][root][INFO] - Training Epoch: 2/2, step 18/7134 completed (loss: 0.03303145244717598, acc: 0.9886363744735718)
[2024-12-17 02:27:33,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:34,192][root][INFO] - Training Epoch: 2/2, step 19/7134 completed (loss: 0.057124797254800797, acc: 0.9862068891525269)
[2024-12-17 02:27:34,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:34,513][root][INFO] - Training Epoch: 2/2, step 20/7134 completed (loss: 0.021382080391049385, acc: 0.99210524559021)
[2024-12-17 02:27:34,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:34,886][root][INFO] - Training Epoch: 2/2, step 21/7134 completed (loss: 0.02079465240240097, acc: 0.9935566782951355)
[2024-12-17 02:27:35,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:35,245][root][INFO] - Training Epoch: 2/2, step 22/7134 completed (loss: 0.007469015195965767, acc: 0.9985590577125549)
[2024-12-17 02:27:35,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:35,577][root][INFO] - Training Epoch: 2/2, step 23/7134 completed (loss: 0.02318495512008667, acc: 0.9945651888847351)
[2024-12-17 02:27:35,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:35,908][root][INFO] - Training Epoch: 2/2, step 24/7134 completed (loss: 0.02253459393978119, acc: 0.9916434288024902)
[2024-12-17 02:27:36,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:36,267][root][INFO] - Training Epoch: 2/2, step 25/7134 completed (loss: 0.03091207891702652, acc: 0.9886363744735718)
[2024-12-17 02:27:36,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:36,604][root][INFO] - Training Epoch: 2/2, step 26/7134 completed (loss: 0.03993040695786476, acc: 0.98525071144104)
[2024-12-17 02:27:36,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:36,931][root][INFO] - Training Epoch: 2/2, step 27/7134 completed (loss: 0.024617543444037437, acc: 0.9955686926841736)
[2024-12-17 02:27:37,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:37,293][root][INFO] - Training Epoch: 2/2, step 28/7134 completed (loss: 0.10247862339019775, acc: 0.9710843563079834)
[2024-12-17 02:27:37,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:37,661][root][INFO] - Training Epoch: 2/2, step 29/7134 completed (loss: 0.09713085740804672, acc: 0.9702549576759338)
[2024-12-17 02:27:37,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:38,027][root][INFO] - Training Epoch: 2/2, step 30/7134 completed (loss: 0.04835224151611328, acc: 0.9887005686759949)
[2024-12-17 02:27:38,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:38,380][root][INFO] - Training Epoch: 2/2, step 31/7134 completed (loss: 0.0852941945195198, acc: 0.9819915294647217)
[2024-12-17 02:27:38,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:38,736][root][INFO] - Training Epoch: 2/2, step 32/7134 completed (loss: 0.07910843938589096, acc: 0.9830949306488037)
[2024-12-17 02:27:38,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:39,035][root][INFO] - Training Epoch: 2/2, step 33/7134 completed (loss: 0.14355799555778503, acc: 0.9681274890899658)
[2024-12-17 02:27:39,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:39,382][root][INFO] - Training Epoch: 2/2, step 34/7134 completed (loss: 0.10577373206615448, acc: 0.9765533208847046)
[2024-12-17 02:27:39,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:39,772][root][INFO] - Training Epoch: 2/2, step 35/7134 completed (loss: 0.1114693209528923, acc: 0.9698397517204285)
[2024-12-17 02:27:39,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:40,141][root][INFO] - Training Epoch: 2/2, step 36/7134 completed (loss: 0.06554531306028366, acc: 0.988056480884552)
[2024-12-17 02:27:40,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:40,496][root][INFO] - Training Epoch: 2/2, step 37/7134 completed (loss: 0.05379253253340721, acc: 0.9887359142303467)
[2024-12-17 02:27:40,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:40,816][root][INFO] - Training Epoch: 2/2, step 38/7134 completed (loss: 0.03860902413725853, acc: 0.9895833134651184)
[2024-12-17 02:27:40,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:41,170][root][INFO] - Training Epoch: 2/2, step 39/7134 completed (loss: 0.029691603034734726, acc: 0.9932340979576111)
[2024-12-17 02:27:41,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:41,480][root][INFO] - Training Epoch: 2/2, step 40/7134 completed (loss: 0.02859213948249817, acc: 0.9932735562324524)
[2024-12-17 02:27:41,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:41,801][root][INFO] - Training Epoch: 2/2, step 41/7134 completed (loss: 0.054202452301979065, acc: 0.9875173568725586)
[2024-12-17 02:27:41,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:42,131][root][INFO] - Training Epoch: 2/2, step 42/7134 completed (loss: 0.06475293636322021, acc: 0.9873772859573364)
[2024-12-17 02:27:42,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:42,441][root][INFO] - Training Epoch: 2/2, step 43/7134 completed (loss: 0.01718171313405037, acc: 0.9922580718994141)
[2024-12-17 02:27:42,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:42,775][root][INFO] - Training Epoch: 2/2, step 44/7134 completed (loss: 0.06898987293243408, acc: 0.9847133755683899)
[2024-12-17 02:27:42,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:43,146][root][INFO] - Training Epoch: 2/2, step 45/7134 completed (loss: 0.07167309522628784, acc: 0.9848320484161377)
[2024-12-17 02:27:43,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:43,482][root][INFO] - Training Epoch: 2/2, step 46/7134 completed (loss: 0.05814797431230545, acc: 0.9853333234786987)
[2024-12-17 02:27:43,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:43,844][root][INFO] - Training Epoch: 2/2, step 47/7134 completed (loss: 0.07964020222425461, acc: 0.9711399674415588)
[2024-12-17 02:27:43,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:44,221][root][INFO] - Training Epoch: 2/2, step 48/7134 completed (loss: 0.05086442455649376, acc: 0.9865168333053589)
[2024-12-17 02:27:44,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:44,573][root][INFO] - Training Epoch: 2/2, step 49/7134 completed (loss: 0.029107531532645226, acc: 0.9931412935256958)
[2024-12-17 02:27:44,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:44,956][root][INFO] - Training Epoch: 2/2, step 50/7134 completed (loss: 0.029235580936074257, acc: 0.9942330121994019)
[2024-12-17 02:27:45,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:45,283][root][INFO] - Training Epoch: 2/2, step 51/7134 completed (loss: 0.036496181041002274, acc: 0.9911167621612549)
[2024-12-17 02:27:45,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:45,597][root][INFO] - Training Epoch: 2/2, step 52/7134 completed (loss: 0.022517824545502663, acc: 0.9934959411621094)
[2024-12-17 02:27:45,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:45,915][root][INFO] - Training Epoch: 2/2, step 53/7134 completed (loss: 0.031425297260284424, acc: 0.9921259880065918)
[2024-12-17 02:27:46,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:46,271][root][INFO] - Training Epoch: 2/2, step 54/7134 completed (loss: 0.01905992440879345, acc: 0.9930955171585083)
[2024-12-17 02:27:46,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:46,603][root][INFO] - Training Epoch: 2/2, step 55/7134 completed (loss: 0.034103747457265854, acc: 0.9949238300323486)
[2024-12-17 02:27:46,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:46,950][root][INFO] - Training Epoch: 2/2, step 56/7134 completed (loss: 0.05210280790925026, acc: 0.9857142567634583)
[2024-12-17 02:27:47,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:47,298][root][INFO] - Training Epoch: 2/2, step 57/7134 completed (loss: 0.06557224690914154, acc: 0.9875776171684265)
[2024-12-17 02:27:47,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:47,663][root][INFO] - Training Epoch: 2/2, step 58/7134 completed (loss: 0.06432057917118073, acc: 0.984635055065155)
[2024-12-17 02:27:47,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:48,028][root][INFO] - Training Epoch: 2/2, step 59/7134 completed (loss: 0.029501715674996376, acc: 0.9940898418426514)
[2024-12-17 02:27:48,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:48,400][root][INFO] - Training Epoch: 2/2, step 60/7134 completed (loss: 0.06377869099378586, acc: 0.9829545617103577)
[2024-12-17 02:27:48,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:48,744][root][INFO] - Training Epoch: 2/2, step 61/7134 completed (loss: 0.0648730993270874, acc: 0.9853121042251587)
[2024-12-17 02:27:48,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:49,084][root][INFO] - Training Epoch: 2/2, step 62/7134 completed (loss: 0.0333826057612896, acc: 0.987293541431427)
[2024-12-17 02:27:49,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:49,434][root][INFO] - Training Epoch: 2/2, step 63/7134 completed (loss: 0.08519437909126282, acc: 0.9763387441635132)
[2024-12-17 02:27:49,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:49,796][root][INFO] - Training Epoch: 2/2, step 64/7134 completed (loss: 0.03348981961607933, acc: 0.9879032373428345)
[2024-12-17 02:27:49,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:50,169][root][INFO] - Training Epoch: 2/2, step 65/7134 completed (loss: 0.09572990983724594, acc: 0.9692874550819397)
[2024-12-17 02:27:50,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:50,509][root][INFO] - Training Epoch: 2/2, step 66/7134 completed (loss: 0.10252698510885239, acc: 0.9749103784561157)
[2024-12-17 02:27:50,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:50,872][root][INFO] - Training Epoch: 2/2, step 67/7134 completed (loss: 0.06345780938863754, acc: 0.9777777791023254)
[2024-12-17 02:27:50,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:51,213][root][INFO] - Training Epoch: 2/2, step 68/7134 completed (loss: 0.10951216518878937, acc: 0.9690322875976562)
[2024-12-17 02:27:51,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:51,568][root][INFO] - Training Epoch: 2/2, step 69/7134 completed (loss: 0.08116179704666138, acc: 0.9788029789924622)
[2024-12-17 02:27:51,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:51,907][root][INFO] - Training Epoch: 2/2, step 70/7134 completed (loss: 0.0836944654583931, acc: 0.9789473414421082)
[2024-12-17 02:27:52,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:52,249][root][INFO] - Training Epoch: 2/2, step 71/7134 completed (loss: 0.0433146096765995, acc: 0.9887955188751221)
[2024-12-17 02:27:52,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:52,608][root][INFO] - Training Epoch: 2/2, step 72/7134 completed (loss: 0.06308723241090775, acc: 0.9820972084999084)
[2024-12-17 02:27:52,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:52,943][root][INFO] - Training Epoch: 2/2, step 73/7134 completed (loss: 0.0770505741238594, acc: 0.976902186870575)
[2024-12-17 02:27:53,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:53,279][root][INFO] - Training Epoch: 2/2, step 74/7134 completed (loss: 0.06495346873998642, acc: 0.9818941354751587)
[2024-12-17 02:27:53,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:53,649][root][INFO] - Training Epoch: 2/2, step 75/7134 completed (loss: 0.14432765543460846, acc: 0.9686098694801331)
[2024-12-17 02:27:53,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:53,997][root][INFO] - Training Epoch: 2/2, step 76/7134 completed (loss: 0.033831823617219925, acc: 0.989924430847168)
[2024-12-17 02:27:54,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:54,339][root][INFO] - Training Epoch: 2/2, step 77/7134 completed (loss: 0.04660661518573761, acc: 0.9862155318260193)
[2024-12-17 02:27:54,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:54,687][root][INFO] - Training Epoch: 2/2, step 78/7134 completed (loss: 0.09097259491682053, acc: 0.9748427867889404)
[2024-12-17 02:27:54,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:55,018][root][INFO] - Training Epoch: 2/2, step 79/7134 completed (loss: 0.0877259373664856, acc: 0.9737654328346252)
[2024-12-17 02:27:55,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:55,369][root][INFO] - Training Epoch: 2/2, step 80/7134 completed (loss: 0.0523490309715271, acc: 0.98828125)
[2024-12-17 02:27:55,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:55,726][root][INFO] - Training Epoch: 2/2, step 81/7134 completed (loss: 0.060019608587026596, acc: 0.9842932224273682)
[2024-12-17 02:27:55,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:56,100][root][INFO] - Training Epoch: 2/2, step 82/7134 completed (loss: 0.05889853090047836, acc: 0.9844412803649902)
[2024-12-17 02:27:56,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:56,458][root][INFO] - Training Epoch: 2/2, step 83/7134 completed (loss: 0.0445886105298996, acc: 0.9845758080482483)
[2024-12-17 02:27:56,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:56,801][root][INFO] - Training Epoch: 2/2, step 84/7134 completed (loss: 0.08126724511384964, acc: 0.9810017347335815)
[2024-12-17 02:27:56,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:57,114][root][INFO] - Training Epoch: 2/2, step 85/7134 completed (loss: 0.08069835603237152, acc: 0.9785202741622925)
[2024-12-17 02:27:57,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:57,435][root][INFO] - Training Epoch: 2/2, step 86/7134 completed (loss: 0.05704018101096153, acc: 0.9816513657569885)
[2024-12-17 02:27:57,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:57,794][root][INFO] - Training Epoch: 2/2, step 87/7134 completed (loss: 0.15091465413570404, acc: 0.9662261605262756)
[2024-12-17 02:27:57,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:58,159][root][INFO] - Training Epoch: 2/2, step 88/7134 completed (loss: 0.1546759158372879, acc: 0.9654218554496765)
[2024-12-17 02:27:58,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:58,515][root][INFO] - Training Epoch: 2/2, step 89/7134 completed (loss: 0.0804130956530571, acc: 0.9794608354568481)
[2024-12-17 02:27:58,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:58,847][root][INFO] - Training Epoch: 2/2, step 90/7134 completed (loss: 0.1052752360701561, acc: 0.9667832255363464)
[2024-12-17 02:27:58,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:59,170][root][INFO] - Training Epoch: 2/2, step 91/7134 completed (loss: 0.06886013597249985, acc: 0.981632649898529)
[2024-12-17 02:27:59,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:59,529][root][INFO] - Training Epoch: 2/2, step 92/7134 completed (loss: 0.07573376595973969, acc: 0.9747545719146729)
[2024-12-17 02:27:59,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:59,877][root][INFO] - Training Epoch: 2/2, step 93/7134 completed (loss: 0.07605428993701935, acc: 0.9820936918258667)
[2024-12-17 02:27:59,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:00,149][root][INFO] - Training Epoch: 2/2, step 94/7134 completed (loss: 0.10815554112195969, acc: 0.9651972055435181)
[2024-12-17 02:28:00,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:00,499][root][INFO] - Training Epoch: 2/2, step 95/7134 completed (loss: 0.06750921159982681, acc: 0.9824120402336121)
[2024-12-17 02:28:00,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:00,824][root][INFO] - Training Epoch: 2/2, step 96/7134 completed (loss: 0.07032210379838943, acc: 0.9869646430015564)
[2024-12-17 02:28:00,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:01,078][root][INFO] - Training Epoch: 2/2, step 97/7134 completed (loss: 0.2897135317325592, acc: 0.9337349534034729)
[2024-12-17 02:28:01,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:01,440][root][INFO] - Training Epoch: 2/2, step 98/7134 completed (loss: 0.13306067883968353, acc: 0.96278315782547)
[2024-12-17 02:28:01,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:01,766][root][INFO] - Training Epoch: 2/2, step 99/7134 completed (loss: 0.0901326835155487, acc: 0.9743119478225708)
[2024-12-17 02:28:01,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:02,138][root][INFO] - Training Epoch: 2/2, step 100/7134 completed (loss: 0.060145534574985504, acc: 0.9820512533187866)
[2024-12-17 02:28:02,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:02,456][root][INFO] - Training Epoch: 2/2, step 101/7134 completed (loss: 0.08062515407800674, acc: 0.9819079041481018)
[2024-12-17 02:28:02,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:02,805][root][INFO] - Training Epoch: 2/2, step 102/7134 completed (loss: 0.0515422523021698, acc: 0.9865689873695374)
[2024-12-17 02:28:02,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:03,111][root][INFO] - Training Epoch: 2/2, step 103/7134 completed (loss: 0.06502541154623032, acc: 0.9766666889190674)
[2024-12-17 02:28:03,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:03,464][root][INFO] - Training Epoch: 2/2, step 104/7134 completed (loss: 0.048216406255960464, acc: 0.9894259572029114)
[2024-12-17 02:28:03,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:03,815][root][INFO] - Training Epoch: 2/2, step 105/7134 completed (loss: 0.058677319437265396, acc: 0.9820554852485657)
[2024-12-17 02:28:03,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:04,169][root][INFO] - Training Epoch: 2/2, step 106/7134 completed (loss: 0.09741470217704773, acc: 0.9749059081077576)
[2024-12-17 02:28:04,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:04,502][root][INFO] - Training Epoch: 2/2, step 107/7134 completed (loss: 0.22059449553489685, acc: 0.9469913840293884)
[2024-12-17 02:28:04,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:04,865][root][INFO] - Training Epoch: 2/2, step 108/7134 completed (loss: 0.08511296659708023, acc: 0.9760192036628723)
[2024-12-17 02:28:04,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:05,175][root][INFO] - Training Epoch: 2/2, step 109/7134 completed (loss: 0.05528590828180313, acc: 0.9797794222831726)
[2024-12-17 02:28:05,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:05,546][root][INFO] - Training Epoch: 2/2, step 110/7134 completed (loss: 0.070804163813591, acc: 0.9800235033035278)
[2024-12-17 02:28:05,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:05,867][root][INFO] - Training Epoch: 2/2, step 111/7134 completed (loss: 0.06742620468139648, acc: 0.9790940880775452)
[2024-12-17 02:28:05,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:06,174][root][INFO] - Training Epoch: 2/2, step 112/7134 completed (loss: 0.039765987545251846, acc: 0.9892141819000244)
[2024-12-17 02:28:06,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:06,521][root][INFO] - Training Epoch: 2/2, step 113/7134 completed (loss: 0.04821964353322983, acc: 0.9860759377479553)
[2024-12-17 02:28:06,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:06,863][root][INFO] - Training Epoch: 2/2, step 114/7134 completed (loss: 0.05794121325016022, acc: 0.9854111671447754)
[2024-12-17 02:28:06,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:07,124][root][INFO] - Training Epoch: 2/2, step 115/7134 completed (loss: 0.1518326699733734, acc: 0.9580052495002747)
[2024-12-17 02:28:07,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:07,502][root][INFO] - Training Epoch: 2/2, step 116/7134 completed (loss: 0.06913132220506668, acc: 0.9776207208633423)
[2024-12-17 02:28:07,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:07,831][root][INFO] - Training Epoch: 2/2, step 117/7134 completed (loss: 0.07802934944629669, acc: 0.9778393507003784)
[2024-12-17 02:28:07,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:08,218][root][INFO] - Training Epoch: 2/2, step 118/7134 completed (loss: 0.05019776523113251, acc: 0.9795918464660645)
[2024-12-17 02:28:08,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:08,573][root][INFO] - Training Epoch: 2/2, step 119/7134 completed (loss: 0.05412875488400459, acc: 0.9842615127563477)
[2024-12-17 02:28:08,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:08,909][root][INFO] - Training Epoch: 2/2, step 120/7134 completed (loss: 0.019721975550055504, acc: 0.993446946144104)
[2024-12-17 02:28:09,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:09,235][root][INFO] - Training Epoch: 2/2, step 121/7134 completed (loss: 0.057471632957458496, acc: 0.9881109595298767)
[2024-12-17 02:28:09,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:09,574][root][INFO] - Training Epoch: 2/2, step 122/7134 completed (loss: 0.03685109317302704, acc: 0.9867549538612366)
[2024-12-17 02:28:09,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:09,903][root][INFO] - Training Epoch: 2/2, step 123/7134 completed (loss: 0.026625363156199455, acc: 0.9909909963607788)
[2024-12-17 02:28:10,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:10,210][root][INFO] - Training Epoch: 2/2, step 124/7134 completed (loss: 0.048787813633680344, acc: 0.9862068891525269)
[2024-12-17 02:28:10,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:10,574][root][INFO] - Training Epoch: 2/2, step 125/7134 completed (loss: 0.06528286635875702, acc: 0.9834070801734924)
[2024-12-17 02:28:10,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:10,906][root][INFO] - Training Epoch: 2/2, step 126/7134 completed (loss: 0.029377736151218414, acc: 0.9933333396911621)
[2024-12-17 02:28:11,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:11,259][root][INFO] - Training Epoch: 2/2, step 127/7134 completed (loss: 0.02795896679162979, acc: 0.9913580417633057)
[2024-12-17 02:28:11,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:11,611][root][INFO] - Training Epoch: 2/2, step 128/7134 completed (loss: 0.06285367906093597, acc: 0.9815455675125122)
[2024-12-17 02:28:11,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:11,976][root][INFO] - Training Epoch: 2/2, step 129/7134 completed (loss: 0.04901585355401039, acc: 0.9840686321258545)
[2024-12-17 02:28:12,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:12,322][root][INFO] - Training Epoch: 2/2, step 130/7134 completed (loss: 0.038521409034729004, acc: 0.9842105507850647)
[2024-12-17 02:28:12,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:12,671][root][INFO] - Training Epoch: 2/2, step 131/7134 completed (loss: 0.03891482204198837, acc: 0.9881578683853149)
[2024-12-17 02:28:12,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:13,004][root][INFO] - Training Epoch: 2/2, step 132/7134 completed (loss: 0.04782585799694061, acc: 0.9854862093925476)
[2024-12-17 02:28:13,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:13,334][root][INFO] - Training Epoch: 2/2, step 133/7134 completed (loss: 0.019504250958561897, acc: 0.9916805028915405)
[2024-12-17 02:28:13,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:13,685][root][INFO] - Training Epoch: 2/2, step 134/7134 completed (loss: 0.04307786002755165, acc: 0.9876106381416321)
[2024-12-17 02:28:13,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:14,046][root][INFO] - Training Epoch: 2/2, step 135/7134 completed (loss: 0.04043624922633171, acc: 0.992222249507904)
[2024-12-17 02:28:14,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:14,404][root][INFO] - Training Epoch: 2/2, step 136/7134 completed (loss: 0.029546348378062248, acc: 0.9916368126869202)
[2024-12-17 02:28:14,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:14,768][root][INFO] - Training Epoch: 2/2, step 137/7134 completed (loss: 0.0553356409072876, acc: 0.9889298677444458)
[2024-12-17 02:28:14,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:15,129][root][INFO] - Training Epoch: 2/2, step 138/7134 completed (loss: 0.06054788455367088, acc: 0.982300877571106)
[2024-12-17 02:28:15,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:15,498][root][INFO] - Training Epoch: 2/2, step 139/7134 completed (loss: 0.08340664207935333, acc: 0.9833759665489197)
[2024-12-17 02:28:15,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:15,842][root][INFO] - Training Epoch: 2/2, step 140/7134 completed (loss: 0.033240366727113724, acc: 0.9895522594451904)
[2024-12-17 02:28:15,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:16,169][root][INFO] - Training Epoch: 2/2, step 141/7134 completed (loss: 0.03749474883079529, acc: 0.9846698045730591)
[2024-12-17 02:28:16,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:16,528][root][INFO] - Training Epoch: 2/2, step 142/7134 completed (loss: 0.09682559967041016, acc: 0.9791377186775208)
[2024-12-17 02:28:16,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:16,875][root][INFO] - Training Epoch: 2/2, step 143/7134 completed (loss: 0.025211943313479424, acc: 0.9895697236061096)
[2024-12-17 02:28:16,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:17,224][root][INFO] - Training Epoch: 2/2, step 144/7134 completed (loss: 0.11527912318706512, acc: 0.9766277074813843)
[2024-12-17 02:28:17,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:17,560][root][INFO] - Training Epoch: 2/2, step 145/7134 completed (loss: 0.15320077538490295, acc: 0.9591549038887024)
[2024-12-17 02:28:17,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:17,917][root][INFO] - Training Epoch: 2/2, step 146/7134 completed (loss: 0.09813199937343597, acc: 0.9743589758872986)
[2024-12-17 02:28:18,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:18,247][root][INFO] - Training Epoch: 2/2, step 147/7134 completed (loss: 0.12203826010227203, acc: 0.9670710563659668)
[2024-12-17 02:28:18,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:18,564][root][INFO] - Training Epoch: 2/2, step 148/7134 completed (loss: 0.19462791085243225, acc: 0.9466357231140137)
[2024-12-17 02:28:18,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:18,903][root][INFO] - Training Epoch: 2/2, step 149/7134 completed (loss: 0.1574748307466507, acc: 0.9690322875976562)
[2024-12-17 02:28:19,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:19,262][root][INFO] - Training Epoch: 2/2, step 150/7134 completed (loss: 0.08736936748027802, acc: 0.9759358167648315)
[2024-12-17 02:28:19,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:19,622][root][INFO] - Training Epoch: 2/2, step 151/7134 completed (loss: 0.1048664003610611, acc: 0.9689737558364868)
[2024-12-17 02:28:19,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:19,972][root][INFO] - Training Epoch: 2/2, step 152/7134 completed (loss: 0.09869499504566193, acc: 0.9794988632202148)
[2024-12-17 02:28:20,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:20,311][root][INFO] - Training Epoch: 2/2, step 153/7134 completed (loss: 0.12859132885932922, acc: 0.9720670580863953)
[2024-12-17 02:28:20,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:20,631][root][INFO] - Training Epoch: 2/2, step 154/7134 completed (loss: 0.08446153253316879, acc: 0.9848024249076843)
[2024-12-17 02:28:20,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:20,994][root][INFO] - Training Epoch: 2/2, step 155/7134 completed (loss: 0.13104724884033203, acc: 0.9649350643157959)
[2024-12-17 02:28:21,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:21,361][root][INFO] - Training Epoch: 2/2, step 156/7134 completed (loss: 0.09452012926340103, acc: 0.9684947729110718)
[2024-12-17 02:28:21,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:21,732][root][INFO] - Training Epoch: 2/2, step 157/7134 completed (loss: 0.11796357482671738, acc: 0.9734939932823181)
[2024-12-17 02:28:21,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:22,094][root][INFO] - Training Epoch: 2/2, step 158/7134 completed (loss: 0.04769079014658928, acc: 0.9894319772720337)
[2024-12-17 02:28:22,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:22,452][root][INFO] - Training Epoch: 2/2, step 159/7134 completed (loss: 0.09456166625022888, acc: 0.9769119620323181)
[2024-12-17 02:28:22,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:22,766][root][INFO] - Training Epoch: 2/2, step 160/7134 completed (loss: 0.10341046750545502, acc: 0.9676113128662109)
[2024-12-17 02:28:22,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:23,022][root][INFO] - Training Epoch: 2/2, step 161/7134 completed (loss: 0.06570827960968018, acc: 0.9709302186965942)
[2024-12-17 02:28:23,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:23,343][root][INFO] - Training Epoch: 2/2, step 162/7134 completed (loss: 0.08415084332227707, acc: 0.9693094491958618)
[2024-12-17 02:28:23,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:23,707][root][INFO] - Training Epoch: 2/2, step 163/7134 completed (loss: 0.10246505588293076, acc: 0.9763663411140442)
[2024-12-17 02:28:23,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:24,007][root][INFO] - Training Epoch: 2/2, step 164/7134 completed (loss: 0.07868532836437225, acc: 0.9808510541915894)
[2024-12-17 02:28:24,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:24,311][root][INFO] - Training Epoch: 2/2, step 165/7134 completed (loss: 0.10768463462591171, acc: 0.9641148447990417)
[2024-12-17 02:28:24,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:24,534][root][INFO] - Training Epoch: 2/2, step 166/7134 completed (loss: 0.06115809828042984, acc: 0.9820895791053772)
[2024-12-17 02:28:24,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:24,883][root][INFO] - Training Epoch: 2/2, step 167/7134 completed (loss: 0.5412037968635559, acc: 0.8787878751754761)
[2024-12-17 02:28:25,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:25,183][root][INFO] - Training Epoch: 2/2, step 168/7134 completed (loss: 1.7373881340026855, acc: 0.6235294342041016)
[2024-12-17 02:28:25,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:25,450][root][INFO] - Training Epoch: 2/2, step 169/7134 completed (loss: 1.0558494329452515, acc: 0.7507002949714661)
[2024-12-17 02:28:25,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:25,747][root][INFO] - Training Epoch: 2/2, step 170/7134 completed (loss: 0.5123042464256287, acc: 0.8747628331184387)
[2024-12-17 02:28:25,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:26,031][root][INFO] - Training Epoch: 2/2, step 171/7134 completed (loss: 0.6550427079200745, acc: 0.8344155550003052)
[2024-12-17 02:28:26,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:26,350][root][INFO] - Training Epoch: 2/2, step 172/7134 completed (loss: 0.36214131116867065, acc: 0.90220046043396)
[2024-12-17 02:28:26,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:26,648][root][INFO] - Training Epoch: 2/2, step 173/7134 completed (loss: 0.2765587568283081, acc: 0.9269911646842957)
[2024-12-17 02:28:26,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:26,941][root][INFO] - Training Epoch: 2/2, step 174/7134 completed (loss: 0.2038964033126831, acc: 0.9683098793029785)
[2024-12-17 02:28:27,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:27,285][root][INFO] - Training Epoch: 2/2, step 175/7134 completed (loss: 0.198499396443367, acc: 0.9563636183738708)
[2024-12-17 02:28:27,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:27,654][root][INFO] - Training Epoch: 2/2, step 176/7134 completed (loss: 0.22923366725444794, acc: 0.939130425453186)
[2024-12-17 02:28:27,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:27,981][root][INFO] - Training Epoch: 2/2, step 177/7134 completed (loss: 0.22772659361362457, acc: 0.9444444179534912)
[2024-12-17 02:28:28,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:28,228][root][INFO] - Training Epoch: 2/2, step 178/7134 completed (loss: 0.21854057908058167, acc: 0.9263566136360168)
[2024-12-17 02:28:28,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:28,561][root][INFO] - Training Epoch: 2/2, step 179/7134 completed (loss: 0.12049298733472824, acc: 0.9690521955490112)
[2024-12-17 02:28:28,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:28,917][root][INFO] - Training Epoch: 2/2, step 180/7134 completed (loss: 0.12310855835676193, acc: 0.9691516757011414)
[2024-12-17 02:28:29,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:29,243][root][INFO] - Training Epoch: 2/2, step 181/7134 completed (loss: 0.08359885215759277, acc: 0.9749670624732971)
[2024-12-17 02:28:29,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:29,614][root][INFO] - Training Epoch: 2/2, step 182/7134 completed (loss: 0.08992847800254822, acc: 0.9792429804801941)
[2024-12-17 02:28:29,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:29,962][root][INFO] - Training Epoch: 2/2, step 183/7134 completed (loss: 0.08311066031455994, acc: 0.9809264540672302)
[2024-12-17 02:28:30,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:30,287][root][INFO] - Training Epoch: 2/2, step 184/7134 completed (loss: 0.06678146123886108, acc: 0.9846389889717102)
[2024-12-17 02:28:30,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:30,626][root][INFO] - Training Epoch: 2/2, step 185/7134 completed (loss: 0.06203867122530937, acc: 0.9856938719749451)
[2024-12-17 02:28:30,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:30,977][root][INFO] - Training Epoch: 2/2, step 186/7134 completed (loss: 0.13920658826828003, acc: 0.9567307829856873)
[2024-12-17 02:28:31,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:31,301][root][INFO] - Training Epoch: 2/2, step 187/7134 completed (loss: 0.11867047846317291, acc: 0.9692737460136414)
[2024-12-17 02:28:31,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:31,648][root][INFO] - Training Epoch: 2/2, step 188/7134 completed (loss: 0.15000203251838684, acc: 0.9638888835906982)
[2024-12-17 02:28:31,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:31,931][root][INFO] - Training Epoch: 2/2, step 189/7134 completed (loss: 0.09204733371734619, acc: 0.9807692170143127)
[2024-12-17 02:28:32,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:32,304][root][INFO] - Training Epoch: 2/2, step 190/7134 completed (loss: 0.18951253592967987, acc: 0.9594383835792542)
[2024-12-17 02:28:32,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:32,636][root][INFO] - Training Epoch: 2/2, step 191/7134 completed (loss: 0.10016477853059769, acc: 0.9807692170143127)
[2024-12-17 02:28:32,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:33,011][root][INFO] - Training Epoch: 2/2, step 192/7134 completed (loss: 0.02336050197482109, acc: 0.9942726492881775)
[2024-12-17 02:28:33,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:33,339][root][INFO] - Training Epoch: 2/2, step 193/7134 completed (loss: 0.08986790478229523, acc: 0.9785234928131104)
[2024-12-17 02:28:33,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:33,687][root][INFO] - Training Epoch: 2/2, step 194/7134 completed (loss: 0.10214963555335999, acc: 0.9698708653450012)
[2024-12-17 02:28:33,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:34,025][root][INFO] - Training Epoch: 2/2, step 195/7134 completed (loss: 0.09054107964038849, acc: 0.9714285731315613)
[2024-12-17 02:28:34,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:34,378][root][INFO] - Training Epoch: 2/2, step 196/7134 completed (loss: 0.08937065303325653, acc: 0.9786096215248108)
[2024-12-17 02:28:34,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:34,730][root][INFO] - Training Epoch: 2/2, step 197/7134 completed (loss: 0.051540885120630264, acc: 0.9886040091514587)
[2024-12-17 02:28:34,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:35,086][root][INFO] - Training Epoch: 2/2, step 198/7134 completed (loss: 0.05907421186566353, acc: 0.9833546876907349)
[2024-12-17 02:28:35,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:35,422][root][INFO] - Training Epoch: 2/2, step 199/7134 completed (loss: 0.08977197110652924, acc: 0.9786535501480103)
[2024-12-17 02:28:35,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:35,806][root][INFO] - Training Epoch: 2/2, step 200/7134 completed (loss: 0.04205487668514252, acc: 0.9865771532058716)
[2024-12-17 02:28:35,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:36,145][root][INFO] - Training Epoch: 2/2, step 201/7134 completed (loss: 0.06682123988866806, acc: 0.9789325594902039)
[2024-12-17 02:28:36,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:36,475][root][INFO] - Training Epoch: 2/2, step 202/7134 completed (loss: 0.0802246555685997, acc: 0.9765517115592957)
[2024-12-17 02:28:36,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:36,812][root][INFO] - Training Epoch: 2/2, step 203/7134 completed (loss: 0.10586374253034592, acc: 0.9710744023323059)
[2024-12-17 02:28:36,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:37,161][root][INFO] - Training Epoch: 2/2, step 204/7134 completed (loss: 0.08706585317850113, acc: 0.9772036671638489)
[2024-12-17 02:28:37,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:37,514][root][INFO] - Training Epoch: 2/2, step 205/7134 completed (loss: 0.09030406922101974, acc: 0.9689521193504333)
[2024-12-17 02:28:37,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:37,868][root][INFO] - Training Epoch: 2/2, step 206/7134 completed (loss: 0.10704843699932098, acc: 0.9727126955986023)
[2024-12-17 02:28:37,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:38,209][root][INFO] - Training Epoch: 2/2, step 207/7134 completed (loss: 0.08466612547636032, acc: 0.979522168636322)
[2024-12-17 02:28:38,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:38,545][root][INFO] - Training Epoch: 2/2, step 208/7134 completed (loss: 0.18360468745231628, acc: 0.9509803652763367)
[2024-12-17 02:28:38,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:38,894][root][INFO] - Training Epoch: 2/2, step 209/7134 completed (loss: 0.17031745612621307, acc: 0.9650259017944336)
[2024-12-17 02:28:39,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:39,261][root][INFO] - Training Epoch: 2/2, step 210/7134 completed (loss: 0.16419190168380737, acc: 0.9543817639350891)
[2024-12-17 02:28:39,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:39,520][root][INFO] - Training Epoch: 2/2, step 211/7134 completed (loss: 0.20930583775043488, acc: 0.9509803652763367)
[2024-12-17 02:28:39,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:39,852][root][INFO] - Training Epoch: 2/2, step 212/7134 completed (loss: 0.22798465192317963, acc: 0.9545454382896423)
[2024-12-17 02:28:39,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:40,180][root][INFO] - Training Epoch: 2/2, step 213/7134 completed (loss: 0.1018565446138382, acc: 0.9724919199943542)
[2024-12-17 02:28:40,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:40,479][root][INFO] - Training Epoch: 2/2, step 214/7134 completed (loss: 0.10388748347759247, acc: 0.9743589758872986)
[2024-12-17 02:28:40,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:40,815][root][INFO] - Training Epoch: 2/2, step 215/7134 completed (loss: 0.08080888539552689, acc: 0.9809027910232544)
[2024-12-17 02:28:40,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:41,143][root][INFO] - Training Epoch: 2/2, step 216/7134 completed (loss: 0.08059508353471756, acc: 0.9777777791023254)
[2024-12-17 02:28:41,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:41,508][root][INFO] - Training Epoch: 2/2, step 217/7134 completed (loss: 0.08648074418306351, acc: 0.9818181991577148)
[2024-12-17 02:28:41,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:41,855][root][INFO] - Training Epoch: 2/2, step 218/7134 completed (loss: 0.04829917848110199, acc: 0.9872773289680481)
[2024-12-17 02:28:41,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:42,183][root][INFO] - Training Epoch: 2/2, step 219/7134 completed (loss: 0.07182061672210693, acc: 0.9922027587890625)
[2024-12-17 02:28:42,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:42,540][root][INFO] - Training Epoch: 2/2, step 220/7134 completed (loss: 0.0501011498272419, acc: 0.9895397424697876)
[2024-12-17 02:28:42,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:42,886][root][INFO] - Training Epoch: 2/2, step 221/7134 completed (loss: 0.06782398372888565, acc: 0.983582079410553)
[2024-12-17 02:28:42,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:43,249][root][INFO] - Training Epoch: 2/2, step 222/7134 completed (loss: 0.06876526027917862, acc: 0.981675386428833)
[2024-12-17 02:28:43,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:43,586][root][INFO] - Training Epoch: 2/2, step 223/7134 completed (loss: 0.10472603142261505, acc: 0.9717586636543274)
[2024-12-17 02:28:43,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:43,925][root][INFO] - Training Epoch: 2/2, step 224/7134 completed (loss: 0.1447375863790512, acc: 0.966277539730072)
[2024-12-17 02:28:44,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:44,264][root][INFO] - Training Epoch: 2/2, step 225/7134 completed (loss: 0.13587121665477753, acc: 0.9640564918518066)
[2024-12-17 02:28:44,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:44,619][root][INFO] - Training Epoch: 2/2, step 226/7134 completed (loss: 0.08658202737569809, acc: 0.9816625714302063)
[2024-12-17 02:28:44,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:44,986][root][INFO] - Training Epoch: 2/2, step 227/7134 completed (loss: 0.18268580734729767, acc: 0.9516128897666931)
[2024-12-17 02:28:45,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:45,350][root][INFO] - Training Epoch: 2/2, step 228/7134 completed (loss: 0.11860907077789307, acc: 0.9753979444503784)
[2024-12-17 02:28:45,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:45,712][root][INFO] - Training Epoch: 2/2, step 229/7134 completed (loss: 0.1575188785791397, acc: 0.9683544039726257)
[2024-12-17 02:28:45,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:46,069][root][INFO] - Training Epoch: 2/2, step 230/7134 completed (loss: 0.06252917647361755, acc: 0.9766584634780884)
[2024-12-17 02:28:46,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:46,406][root][INFO] - Training Epoch: 2/2, step 231/7134 completed (loss: 0.06092747673392296, acc: 0.9811676144599915)
[2024-12-17 02:28:46,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:46,739][root][INFO] - Training Epoch: 2/2, step 232/7134 completed (loss: 0.06674353778362274, acc: 0.9835255146026611)
[2024-12-17 02:28:46,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:47,080][root][INFO] - Training Epoch: 2/2, step 233/7134 completed (loss: 0.08253025263547897, acc: 0.9778130054473877)
[2024-12-17 02:28:47,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:47,415][root][INFO] - Training Epoch: 2/2, step 234/7134 completed (loss: 0.10134264826774597, acc: 0.9712837934494019)
[2024-12-17 02:28:47,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:47,780][root][INFO] - Training Epoch: 2/2, step 235/7134 completed (loss: 0.11518648266792297, acc: 0.9772079586982727)
[2024-12-17 02:28:47,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:48,122][root][INFO] - Training Epoch: 2/2, step 236/7134 completed (loss: 0.03671446442604065, acc: 0.9859374761581421)
[2024-12-17 02:28:48,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:48,461][root][INFO] - Training Epoch: 2/2, step 237/7134 completed (loss: 0.10630955547094345, acc: 0.9716840386390686)
[2024-12-17 02:28:48,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:48,751][root][INFO] - Training Epoch: 2/2, step 238/7134 completed (loss: 0.12586607038974762, acc: 0.983208954334259)
[2024-12-17 02:28:48,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:49,059][root][INFO] - Training Epoch: 2/2, step 239/7134 completed (loss: 0.030236486345529556, acc: 0.9894958138465881)
[2024-12-17 02:28:49,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:49,397][root][INFO] - Training Epoch: 2/2, step 240/7134 completed (loss: 0.08350201696157455, acc: 0.9872881174087524)
[2024-12-17 02:28:49,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:49,791][root][INFO] - Training Epoch: 2/2, step 241/7134 completed (loss: 0.12890742719173431, acc: 0.966183602809906)
[2024-12-17 02:28:49,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:50,104][root][INFO] - Training Epoch: 2/2, step 242/7134 completed (loss: 0.13522638380527496, acc: 0.9584055542945862)
[2024-12-17 02:28:50,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:50,419][root][INFO] - Training Epoch: 2/2, step 243/7134 completed (loss: 0.1667899638414383, acc: 0.954081654548645)
[2024-12-17 02:28:50,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:50,751][root][INFO] - Training Epoch: 2/2, step 244/7134 completed (loss: 0.04850105196237564, acc: 0.9864253401756287)
[2024-12-17 02:28:50,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:51,090][root][INFO] - Training Epoch: 2/2, step 245/7134 completed (loss: 0.13048768043518066, acc: 0.9719789624214172)
[2024-12-17 02:28:51,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:51,420][root][INFO] - Training Epoch: 2/2, step 246/7134 completed (loss: 0.06753432005643845, acc: 0.9810725450515747)
[2024-12-17 02:28:51,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:51,754][root][INFO] - Training Epoch: 2/2, step 247/7134 completed (loss: 0.09943543374538422, acc: 0.9745916724205017)
[2024-12-17 02:28:51,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:52,109][root][INFO] - Training Epoch: 2/2, step 248/7134 completed (loss: 0.052364856004714966, acc: 0.9806201457977295)
[2024-12-17 02:28:52,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:52,401][root][INFO] - Training Epoch: 2/2, step 249/7134 completed (loss: 0.06620170921087265, acc: 0.9812332391738892)
[2024-12-17 02:28:52,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:52,735][root][INFO] - Training Epoch: 2/2, step 250/7134 completed (loss: 0.0757378488779068, acc: 0.9715189933776855)
[2024-12-17 02:28:52,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:53,067][root][INFO] - Training Epoch: 2/2, step 251/7134 completed (loss: 0.09029268473386765, acc: 0.9777777791023254)
[2024-12-17 02:28:53,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:53,395][root][INFO] - Training Epoch: 2/2, step 252/7134 completed (loss: 0.03224167972803116, acc: 0.9918032884597778)
[2024-12-17 02:28:53,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:53,741][root][INFO] - Training Epoch: 2/2, step 253/7134 completed (loss: 0.0444919727742672, acc: 0.9857397675514221)
[2024-12-17 02:28:53,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:54,071][root][INFO] - Training Epoch: 2/2, step 254/7134 completed (loss: 0.06545019894838333, acc: 0.9857142567634583)
[2024-12-17 02:28:54,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:54,400][root][INFO] - Training Epoch: 2/2, step 255/7134 completed (loss: 0.07364405691623688, acc: 0.9766082167625427)
[2024-12-17 02:28:54,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:54,688][root][INFO] - Training Epoch: 2/2, step 256/7134 completed (loss: 0.09855537116527557, acc: 0.970588207244873)
[2024-12-17 02:28:54,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:55,052][root][INFO] - Training Epoch: 2/2, step 257/7134 completed (loss: 0.12130831182003021, acc: 0.9754601120948792)
[2024-12-17 02:28:55,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:55,383][root][INFO] - Training Epoch: 2/2, step 258/7134 completed (loss: 0.06182720884680748, acc: 0.9818181991577148)
[2024-12-17 02:28:55,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:55,717][root][INFO] - Training Epoch: 2/2, step 259/7134 completed (loss: 0.0624675489962101, acc: 0.9821717739105225)
[2024-12-17 02:28:55,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:56,068][root][INFO] - Training Epoch: 2/2, step 260/7134 completed (loss: 0.05890605226159096, acc: 0.9830795526504517)
[2024-12-17 02:28:56,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:56,377][root][INFO] - Training Epoch: 2/2, step 261/7134 completed (loss: 0.06279390305280685, acc: 0.9815950989723206)
[2024-12-17 02:28:56,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:56,654][root][INFO] - Training Epoch: 2/2, step 262/7134 completed (loss: 0.04108463600277901, acc: 0.9866888523101807)
[2024-12-17 02:28:56,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:56,981][root][INFO] - Training Epoch: 2/2, step 263/7134 completed (loss: 0.05766255781054497, acc: 0.9821200370788574)
[2024-12-17 02:28:57,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:57,348][root][INFO] - Training Epoch: 2/2, step 264/7134 completed (loss: 0.06577984988689423, acc: 0.9766355156898499)
[2024-12-17 02:28:57,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:57,701][root][INFO] - Training Epoch: 2/2, step 265/7134 completed (loss: 0.08088617026805878, acc: 0.9819587469100952)
[2024-12-17 02:28:57,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:58,049][root][INFO] - Training Epoch: 2/2, step 266/7134 completed (loss: 0.049276821315288544, acc: 0.982798159122467)
[2024-12-17 02:28:58,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:58,424][root][INFO] - Training Epoch: 2/2, step 267/7134 completed (loss: 0.08933459967374802, acc: 0.9747126698493958)
[2024-12-17 02:28:58,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:58,795][root][INFO] - Training Epoch: 2/2, step 268/7134 completed (loss: 0.0933510959148407, acc: 0.9753566980361938)
[2024-12-17 02:28:58,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:59,150][root][INFO] - Training Epoch: 2/2, step 269/7134 completed (loss: 0.10529942065477371, acc: 0.9721835851669312)
[2024-12-17 02:28:59,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:59,476][root][INFO] - Training Epoch: 2/2, step 270/7134 completed (loss: 0.0493781752884388, acc: 0.983582079410553)
[2024-12-17 02:28:59,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:59,834][root][INFO] - Training Epoch: 2/2, step 271/7134 completed (loss: 0.07514028996229172, acc: 0.9823455214500427)
[2024-12-17 02:28:59,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:00,189][root][INFO] - Training Epoch: 2/2, step 272/7134 completed (loss: 0.05234292149543762, acc: 0.983460545539856)
[2024-12-17 02:29:00,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:00,538][root][INFO] - Training Epoch: 2/2, step 273/7134 completed (loss: 0.05301731452345848, acc: 0.9844311475753784)
[2024-12-17 02:29:00,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:00,864][root][INFO] - Training Epoch: 2/2, step 274/7134 completed (loss: 0.0453529879450798, acc: 0.993122398853302)
[2024-12-17 02:29:00,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:01,228][root][INFO] - Training Epoch: 2/2, step 275/7134 completed (loss: 0.06435319781303406, acc: 0.9814385175704956)
[2024-12-17 02:29:01,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:01,610][root][INFO] - Training Epoch: 2/2, step 276/7134 completed (loss: 0.05029347538948059, acc: 0.986601710319519)
[2024-12-17 02:29:01,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:01,963][root][INFO] - Training Epoch: 2/2, step 277/7134 completed (loss: 0.0816890299320221, acc: 0.9755469560623169)
[2024-12-17 02:29:02,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:02,305][root][INFO] - Training Epoch: 2/2, step 278/7134 completed (loss: 0.04145254194736481, acc: 0.9859514832496643)
[2024-12-17 02:29:02,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:02,656][root][INFO] - Training Epoch: 2/2, step 279/7134 completed (loss: 0.051187146455049515, acc: 0.9816272854804993)
[2024-12-17 02:29:02,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:02,976][root][INFO] - Training Epoch: 2/2, step 280/7134 completed (loss: 0.075111024081707, acc: 0.9749103784561157)
[2024-12-17 02:29:03,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:03,304][root][INFO] - Training Epoch: 2/2, step 281/7134 completed (loss: 0.0856873020529747, acc: 0.9779999852180481)
[2024-12-17 02:29:03,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:03,642][root][INFO] - Training Epoch: 2/2, step 282/7134 completed (loss: 0.11554040014743805, acc: 0.9679389595985413)
[2024-12-17 02:29:03,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:03,975][root][INFO] - Training Epoch: 2/2, step 283/7134 completed (loss: 0.08356785774230957, acc: 0.9745330810546875)
[2024-12-17 02:29:04,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:04,298][root][INFO] - Training Epoch: 2/2, step 284/7134 completed (loss: 0.0522860512137413, acc: 0.9848993420600891)
[2024-12-17 02:29:04,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:04,623][root][INFO] - Training Epoch: 2/2, step 285/7134 completed (loss: 0.05863546207547188, acc: 0.9805996417999268)
[2024-12-17 02:29:04,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:04,941][root][INFO] - Training Epoch: 2/2, step 286/7134 completed (loss: 0.0659831315279007, acc: 0.982300877571106)
[2024-12-17 02:29:05,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:05,278][root][INFO] - Training Epoch: 2/2, step 287/7134 completed (loss: 0.07079939544200897, acc: 0.9791332483291626)
[2024-12-17 02:29:05,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:05,619][root][INFO] - Training Epoch: 2/2, step 288/7134 completed (loss: 0.08223763853311539, acc: 0.968692421913147)
[2024-12-17 02:29:05,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:05,974][root][INFO] - Training Epoch: 2/2, step 289/7134 completed (loss: 0.05291503667831421, acc: 0.9837251305580139)
[2024-12-17 02:29:06,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:06,289][root][INFO] - Training Epoch: 2/2, step 290/7134 completed (loss: 0.06775220483541489, acc: 0.9863221645355225)
[2024-12-17 02:29:06,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:06,631][root][INFO] - Training Epoch: 2/2, step 291/7134 completed (loss: 0.07954249531030655, acc: 0.9851973652839661)
[2024-12-17 02:29:06,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:06,972][root][INFO] - Training Epoch: 2/2, step 292/7134 completed (loss: 0.0673234835267067, acc: 0.9846625924110413)
[2024-12-17 02:29:07,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:07,297][root][INFO] - Training Epoch: 2/2, step 293/7134 completed (loss: 0.05523094907402992, acc: 0.9839357137680054)
[2024-12-17 02:29:07,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:07,639][root][INFO] - Training Epoch: 2/2, step 294/7134 completed (loss: 0.07077420502901077, acc: 0.9785575270652771)
[2024-12-17 02:29:07,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:08,003][root][INFO] - Training Epoch: 2/2, step 295/7134 completed (loss: 0.09103656560182571, acc: 0.9761092066764832)
[2024-12-17 02:29:08,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:08,347][root][INFO] - Training Epoch: 2/2, step 296/7134 completed (loss: 0.05305086448788643, acc: 0.9813953638076782)
[2024-12-17 02:29:08,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:08,701][root][INFO] - Training Epoch: 2/2, step 297/7134 completed (loss: 0.0382327102124691, acc: 0.9893428087234497)
[2024-12-17 02:29:08,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:09,041][root][INFO] - Training Epoch: 2/2, step 298/7134 completed (loss: 0.04067213460803032, acc: 0.9887999892234802)
[2024-12-17 02:29:09,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:09,365][root][INFO] - Training Epoch: 2/2, step 299/7134 completed (loss: 0.0624760277569294, acc: 0.9789473414421082)
[2024-12-17 02:29:09,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:09,700][root][INFO] - Training Epoch: 2/2, step 300/7134 completed (loss: 0.04957505688071251, acc: 0.9886731505393982)
[2024-12-17 02:29:09,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:10,047][root][INFO] - Training Epoch: 2/2, step 301/7134 completed (loss: 0.037973687052726746, acc: 0.9816124439239502)
[2024-12-17 02:29:10,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:10,388][root][INFO] - Training Epoch: 2/2, step 302/7134 completed (loss: 0.07097402960062027, acc: 0.9863547682762146)
[2024-12-17 02:29:10,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:10,676][root][INFO] - Training Epoch: 2/2, step 303/7134 completed (loss: 0.047197647392749786, acc: 0.9864077568054199)
[2024-12-17 02:29:10,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:10,997][root][INFO] - Training Epoch: 2/2, step 304/7134 completed (loss: 0.02443196065723896, acc: 0.9944444298744202)
[2024-12-17 02:29:11,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:11,332][root][INFO] - Training Epoch: 2/2, step 305/7134 completed (loss: 0.0648621991276741, acc: 0.9872813820838928)
[2024-12-17 02:29:11,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:11,647][root][INFO] - Training Epoch: 2/2, step 306/7134 completed (loss: 0.014727250672876835, acc: 0.9963768124580383)
[2024-12-17 02:29:11,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:11,990][root][INFO] - Training Epoch: 2/2, step 307/7134 completed (loss: 0.06644624471664429, acc: 0.9804270267486572)
[2024-12-17 02:29:12,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:12,325][root][INFO] - Training Epoch: 2/2, step 308/7134 completed (loss: 0.020358284935355186, acc: 0.9950658082962036)
[2024-12-17 02:29:12,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:12,668][root][INFO] - Training Epoch: 2/2, step 309/7134 completed (loss: 0.04082602262496948, acc: 0.9862068891525269)
[2024-12-17 02:29:12,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:13,034][root][INFO] - Training Epoch: 2/2, step 310/7134 completed (loss: 0.03379473090171814, acc: 0.9912280440330505)
[2024-12-17 02:29:13,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:13,371][root][INFO] - Training Epoch: 2/2, step 311/7134 completed (loss: 0.02803722955286503, acc: 0.9906687140464783)
[2024-12-17 02:29:13,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:13,708][root][INFO] - Training Epoch: 2/2, step 312/7134 completed (loss: 0.031643278896808624, acc: 0.9878683090209961)
[2024-12-17 02:29:13,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:14,045][root][INFO] - Training Epoch: 2/2, step 313/7134 completed (loss: 0.03020729124546051, acc: 0.9878261089324951)
[2024-12-17 02:29:14,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:14,373][root][INFO] - Training Epoch: 2/2, step 314/7134 completed (loss: 0.0423179529607296, acc: 0.987500011920929)
[2024-12-17 02:29:14,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:14,711][root][INFO] - Training Epoch: 2/2, step 315/7134 completed (loss: 0.047980550676584244, acc: 0.9868852496147156)
[2024-12-17 02:29:14,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:15,057][root][INFO] - Training Epoch: 2/2, step 316/7134 completed (loss: 0.07461864501237869, acc: 0.9819494485855103)
[2024-12-17 02:29:15,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:15,403][root][INFO] - Training Epoch: 2/2, step 317/7134 completed (loss: 0.009210535325109959, acc: 1.0)
[2024-12-17 02:29:15,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:15,766][root][INFO] - Training Epoch: 2/2, step 318/7134 completed (loss: 0.09243983030319214, acc: 0.9816849827766418)
[2024-12-17 02:29:15,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:16,093][root][INFO] - Training Epoch: 2/2, step 319/7134 completed (loss: 0.0733109563589096, acc: 0.9831697344779968)
[2024-12-17 02:29:16,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:16,473][root][INFO] - Training Epoch: 2/2, step 320/7134 completed (loss: 0.04106985032558441, acc: 0.9885877370834351)
[2024-12-17 02:29:16,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:16,851][root][INFO] - Training Epoch: 2/2, step 321/7134 completed (loss: 0.11700961738824844, acc: 0.9719029664993286)
[2024-12-17 02:29:16,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:17,217][root][INFO] - Training Epoch: 2/2, step 322/7134 completed (loss: 0.06387894600629807, acc: 0.9819819927215576)
[2024-12-17 02:29:17,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:17,561][root][INFO] - Training Epoch: 2/2, step 323/7134 completed (loss: 0.06923777610063553, acc: 0.9820282459259033)
[2024-12-17 02:29:17,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:17,935][root][INFO] - Training Epoch: 2/2, step 324/7134 completed (loss: 0.07375501841306686, acc: 0.9815880060195923)
[2024-12-17 02:29:18,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:18,288][root][INFO] - Training Epoch: 2/2, step 325/7134 completed (loss: 0.029958117753267288, acc: 0.9884318709373474)
[2024-12-17 02:29:18,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:18,627][root][INFO] - Training Epoch: 2/2, step 326/7134 completed (loss: 0.04570462182164192, acc: 0.9890377521514893)
[2024-12-17 02:29:18,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:18,995][root][INFO] - Training Epoch: 2/2, step 327/7134 completed (loss: 0.07945776730775833, acc: 0.9831081032752991)
[2024-12-17 02:29:19,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:19,369][root][INFO] - Training Epoch: 2/2, step 328/7134 completed (loss: 0.05047706142067909, acc: 0.9896296262741089)
[2024-12-17 02:29:19,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:19,742][root][INFO] - Training Epoch: 2/2, step 329/7134 completed (loss: 0.028562091290950775, acc: 0.9917743802070618)
[2024-12-17 02:29:19,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:20,121][root][INFO] - Training Epoch: 2/2, step 330/7134 completed (loss: 0.05899864807724953, acc: 0.981873095035553)
[2024-12-17 02:29:20,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:20,474][root][INFO] - Training Epoch: 2/2, step 331/7134 completed (loss: 0.0453079454600811, acc: 0.9874572157859802)
[2024-12-17 02:29:20,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:20,823][root][INFO] - Training Epoch: 2/2, step 332/7134 completed (loss: 0.02862384170293808, acc: 0.9929161667823792)
[2024-12-17 02:29:20,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:21,152][root][INFO] - Training Epoch: 2/2, step 333/7134 completed (loss: 0.0675385594367981, acc: 0.9817517995834351)
[2024-12-17 02:29:21,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:21,502][root][INFO] - Training Epoch: 2/2, step 334/7134 completed (loss: 0.03181177005171776, acc: 0.9911280274391174)
[2024-12-17 02:29:21,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:21,863][root][INFO] - Training Epoch: 2/2, step 335/7134 completed (loss: 0.03184685483574867, acc: 0.9927219748497009)
[2024-12-17 02:29:21,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:22,218][root][INFO] - Training Epoch: 2/2, step 336/7134 completed (loss: 0.052272699773311615, acc: 0.9880239367485046)
[2024-12-17 02:29:22,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:22,560][root][INFO] - Training Epoch: 2/2, step 337/7134 completed (loss: 0.04146992415189743, acc: 0.987730085849762)
[2024-12-17 02:29:22,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:22,903][root][INFO] - Training Epoch: 2/2, step 338/7134 completed (loss: 0.08957751095294952, acc: 0.9748110771179199)
[2024-12-17 02:29:23,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:23,250][root][INFO] - Training Epoch: 2/2, step 339/7134 completed (loss: 0.03932543471455574, acc: 0.9900000095367432)
[2024-12-17 02:29:23,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:23,576][root][INFO] - Training Epoch: 2/2, step 340/7134 completed (loss: 0.06365059316158295, acc: 0.9821882843971252)
[2024-12-17 02:29:23,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:23,933][root][INFO] - Training Epoch: 2/2, step 341/7134 completed (loss: 0.028683368116617203, acc: 0.9911727905273438)
[2024-12-17 02:29:24,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:24,284][root][INFO] - Training Epoch: 2/2, step 342/7134 completed (loss: 0.02253013662993908, acc: 0.9924242496490479)
[2024-12-17 02:29:24,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:24,621][root][INFO] - Training Epoch: 2/2, step 343/7134 completed (loss: 0.03946717083454132, acc: 0.9886578321456909)
[2024-12-17 02:29:24,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:24,943][root][INFO] - Training Epoch: 2/2, step 344/7134 completed (loss: 0.01848985068500042, acc: 0.9963503479957581)
[2024-12-17 02:29:25,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:25,284][root][INFO] - Training Epoch: 2/2, step 345/7134 completed (loss: 0.034334879368543625, acc: 0.9892857074737549)
[2024-12-17 02:29:25,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:25,648][root][INFO] - Training Epoch: 2/2, step 346/7134 completed (loss: 0.04546405002474785, acc: 0.9872813820838928)
[2024-12-17 02:29:25,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:26,004][root][INFO] - Training Epoch: 2/2, step 347/7134 completed (loss: 0.04539579153060913, acc: 0.9901823401451111)
[2024-12-17 02:29:26,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:26,368][root][INFO] - Training Epoch: 2/2, step 348/7134 completed (loss: 0.023353133350610733, acc: 0.9932157397270203)
[2024-12-17 02:29:26,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:26,700][root][INFO] - Training Epoch: 2/2, step 349/7134 completed (loss: 0.04814329370856285, acc: 0.9865771532058716)
[2024-12-17 02:29:26,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:27,126][root][INFO] - Training Epoch: 2/2, step 350/7134 completed (loss: 0.05804399400949478, acc: 0.9891696572303772)
[2024-12-17 02:29:27,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:27,495][root][INFO] - Training Epoch: 2/2, step 351/7134 completed (loss: 0.053631603717803955, acc: 0.9809160232543945)
[2024-12-17 02:29:27,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:27,827][root][INFO] - Training Epoch: 2/2, step 352/7134 completed (loss: 0.03263320028781891, acc: 0.99048912525177)
[2024-12-17 02:29:27,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:28,188][root][INFO] - Training Epoch: 2/2, step 353/7134 completed (loss: 0.03634355217218399, acc: 0.9893617033958435)
[2024-12-17 02:29:28,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:28,542][root][INFO] - Training Epoch: 2/2, step 354/7134 completed (loss: 0.02659418433904648, acc: 0.9941792488098145)
[2024-12-17 02:29:28,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:28,874][root][INFO] - Training Epoch: 2/2, step 355/7134 completed (loss: 0.06732083857059479, acc: 0.9888268113136292)
[2024-12-17 02:29:28,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:29,237][root][INFO] - Training Epoch: 2/2, step 356/7134 completed (loss: 0.03144468739628792, acc: 0.9907407164573669)
[2024-12-17 02:29:29,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:29,624][root][INFO] - Training Epoch: 2/2, step 357/7134 completed (loss: 0.0306699201464653, acc: 0.9923664331436157)
[2024-12-17 02:29:29,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:29,963][root][INFO] - Training Epoch: 2/2, step 358/7134 completed (loss: 0.05501387640833855, acc: 0.9863574504852295)
[2024-12-17 02:29:30,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:30,322][root][INFO] - Training Epoch: 2/2, step 359/7134 completed (loss: 0.02350078709423542, acc: 0.9905405640602112)
[2024-12-17 02:29:30,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:30,655][root][INFO] - Training Epoch: 2/2, step 360/7134 completed (loss: 0.027137162163853645, acc: 0.9924699068069458)
[2024-12-17 02:29:30,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:30,993][root][INFO] - Training Epoch: 2/2, step 361/7134 completed (loss: 0.04520178958773613, acc: 0.9897210001945496)
[2024-12-17 02:29:31,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:31,316][root][INFO] - Training Epoch: 2/2, step 362/7134 completed (loss: 0.045322418212890625, acc: 0.9910179376602173)
[2024-12-17 02:29:31,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:31,680][root][INFO] - Training Epoch: 2/2, step 363/7134 completed (loss: 0.06912285834550858, acc: 0.9830729365348816)
[2024-12-17 02:29:31,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:31,986][root][INFO] - Training Epoch: 2/2, step 364/7134 completed (loss: 0.044516608119010925, acc: 0.985981285572052)
[2024-12-17 02:29:32,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:32,347][root][INFO] - Training Epoch: 2/2, step 365/7134 completed (loss: 0.05346635729074478, acc: 0.9889807105064392)
[2024-12-17 02:29:32,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:32,689][root][INFO] - Training Epoch: 2/2, step 366/7134 completed (loss: 0.05827039107680321, acc: 0.9796238541603088)
[2024-12-17 02:29:32,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:33,055][root][INFO] - Training Epoch: 2/2, step 367/7134 completed (loss: 0.03455860912799835, acc: 0.9862499833106995)
[2024-12-17 02:29:33,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:33,401][root][INFO] - Training Epoch: 2/2, step 368/7134 completed (loss: 0.02883944660425186, acc: 0.9925705790519714)
[2024-12-17 02:29:33,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:33,724][root][INFO] - Training Epoch: 2/2, step 369/7134 completed (loss: 0.03614244982600212, acc: 0.9877488613128662)
[2024-12-17 02:29:33,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:34,068][root][INFO] - Training Epoch: 2/2, step 370/7134 completed (loss: 0.09467524290084839, acc: 0.9781659245491028)
[2024-12-17 02:29:34,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:34,405][root][INFO] - Training Epoch: 2/2, step 371/7134 completed (loss: 0.04404278099536896, acc: 0.9894737005233765)
[2024-12-17 02:29:34,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:34,741][root][INFO] - Training Epoch: 2/2, step 372/7134 completed (loss: 0.039368752390146255, acc: 0.9910846948623657)
[2024-12-17 02:29:34,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:35,080][root][INFO] - Training Epoch: 2/2, step 373/7134 completed (loss: 0.01991763710975647, acc: 0.994020938873291)
[2024-12-17 02:29:35,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:35,437][root][INFO] - Training Epoch: 2/2, step 374/7134 completed (loss: 0.04864773899316788, acc: 0.9839228391647339)
[2024-12-17 02:29:35,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:35,755][root][INFO] - Training Epoch: 2/2, step 375/7134 completed (loss: 0.06801553070545197, acc: 0.9879518151283264)
[2024-12-17 02:29:35,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:36,110][root][INFO] - Training Epoch: 2/2, step 376/7134 completed (loss: 0.06585785746574402, acc: 0.9834482669830322)
[2024-12-17 02:29:36,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:36,467][root][INFO] - Training Epoch: 2/2, step 377/7134 completed (loss: 0.046748340129852295, acc: 0.9889958500862122)
[2024-12-17 02:29:36,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:36,794][root][INFO] - Training Epoch: 2/2, step 378/7134 completed (loss: 0.046529971063137054, acc: 0.9836512207984924)
[2024-12-17 02:29:36,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:37,146][root][INFO] - Training Epoch: 2/2, step 379/7134 completed (loss: 0.03770357370376587, acc: 0.9899497628211975)
[2024-12-17 02:29:37,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:37,483][root][INFO] - Training Epoch: 2/2, step 380/7134 completed (loss: 0.08182501792907715, acc: 0.9750328660011292)
[2024-12-17 02:29:37,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:37,837][root][INFO] - Training Epoch: 2/2, step 381/7134 completed (loss: 0.061301589012145996, acc: 0.9883720874786377)
[2024-12-17 02:29:37,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:38,180][root][INFO] - Training Epoch: 2/2, step 382/7134 completed (loss: 0.053940702229738235, acc: 0.9807445406913757)
[2024-12-17 02:29:38,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:38,508][root][INFO] - Training Epoch: 2/2, step 383/7134 completed (loss: 0.05527419224381447, acc: 0.9848771095275879)
[2024-12-17 02:29:38,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:38,820][root][INFO] - Training Epoch: 2/2, step 384/7134 completed (loss: 0.05030592158436775, acc: 0.9893190860748291)
[2024-12-17 02:29:38,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:39,142][root][INFO] - Training Epoch: 2/2, step 385/7134 completed (loss: 0.03712281212210655, acc: 0.9952903985977173)
[2024-12-17 02:29:39,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:39,420][root][INFO] - Training Epoch: 2/2, step 386/7134 completed (loss: 0.030145037919282913, acc: 0.9918200373649597)
[2024-12-17 02:29:39,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:39,776][root][INFO] - Training Epoch: 2/2, step 387/7134 completed (loss: 0.06096740812063217, acc: 0.9810495376586914)
[2024-12-17 02:29:39,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:40,129][root][INFO] - Training Epoch: 2/2, step 388/7134 completed (loss: 0.027402209118008614, acc: 0.9917840361595154)
[2024-12-17 02:29:40,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:40,492][root][INFO] - Training Epoch: 2/2, step 389/7134 completed (loss: 0.08274199068546295, acc: 0.9807162284851074)
[2024-12-17 02:29:40,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:40,802][root][INFO] - Training Epoch: 2/2, step 390/7134 completed (loss: 0.05892660468816757, acc: 0.9854369163513184)
[2024-12-17 02:29:40,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:41,124][root][INFO] - Training Epoch: 2/2, step 391/7134 completed (loss: 0.047151852399110794, acc: 0.9846938848495483)
[2024-12-17 02:29:41,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:41,474][root][INFO] - Training Epoch: 2/2, step 392/7134 completed (loss: 0.05350339412689209, acc: 0.9807407259941101)
[2024-12-17 02:29:41,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:41,794][root][INFO] - Training Epoch: 2/2, step 393/7134 completed (loss: 0.06090809404850006, acc: 0.9819444417953491)
[2024-12-17 02:29:41,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:42,109][root][INFO] - Training Epoch: 2/2, step 394/7134 completed (loss: 0.08171579241752625, acc: 0.9766536951065063)
[2024-12-17 02:29:42,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:42,433][root][INFO] - Training Epoch: 2/2, step 395/7134 completed (loss: 0.11057410389184952, acc: 0.973936915397644)
[2024-12-17 02:29:42,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:42,758][root][INFO] - Training Epoch: 2/2, step 396/7134 completed (loss: 0.05000290274620056, acc: 0.9849462509155273)
[2024-12-17 02:29:42,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:43,120][root][INFO] - Training Epoch: 2/2, step 397/7134 completed (loss: 0.07327446341514587, acc: 0.9828042387962341)
[2024-12-17 02:29:43,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:43,472][root][INFO] - Training Epoch: 2/2, step 398/7134 completed (loss: 0.046509113162755966, acc: 0.9871134161949158)
[2024-12-17 02:29:43,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:43,800][root][INFO] - Training Epoch: 2/2, step 399/7134 completed (loss: 0.074496328830719, acc: 0.9825673699378967)
[2024-12-17 02:29:43,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:44,158][root][INFO] - Training Epoch: 2/2, step 400/7134 completed (loss: 0.15326747298240662, acc: 0.9641790986061096)
[2024-12-17 02:29:44,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:44,523][root][INFO] - Training Epoch: 2/2, step 401/7134 completed (loss: 0.06052302196621895, acc: 0.9865196347236633)
[2024-12-17 02:29:44,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:44,878][root][INFO] - Training Epoch: 2/2, step 402/7134 completed (loss: 0.037548452615737915, acc: 0.9936628937721252)
[2024-12-17 02:29:44,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:45,256][root][INFO] - Training Epoch: 2/2, step 403/7134 completed (loss: 0.04946683719754219, acc: 0.9913606643676758)
[2024-12-17 02:29:45,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:45,584][root][INFO] - Training Epoch: 2/2, step 404/7134 completed (loss: 0.07222963869571686, acc: 0.985897421836853)
[2024-12-17 02:29:45,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:45,937][root][INFO] - Training Epoch: 2/2, step 405/7134 completed (loss: 0.12778940796852112, acc: 0.9672897458076477)
[2024-12-17 02:29:46,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:46,288][root][INFO] - Training Epoch: 2/2, step 406/7134 completed (loss: 0.08973138779401779, acc: 0.9841269850730896)
[2024-12-17 02:29:46,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:46,591][root][INFO] - Training Epoch: 2/2, step 407/7134 completed (loss: 0.17874209582805634, acc: 0.9610169529914856)
[2024-12-17 02:29:46,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:46,915][root][INFO] - Training Epoch: 2/2, step 408/7134 completed (loss: 0.1058870404958725, acc: 0.9753086566925049)
[2024-12-17 02:29:47,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:47,267][root][INFO] - Training Epoch: 2/2, step 409/7134 completed (loss: 0.0731620341539383, acc: 0.9811320900917053)
[2024-12-17 02:29:47,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:47,643][root][INFO] - Training Epoch: 2/2, step 410/7134 completed (loss: 0.08323326706886292, acc: 0.9777448177337646)
[2024-12-17 02:29:47,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:48,011][root][INFO] - Training Epoch: 2/2, step 411/7134 completed (loss: 0.05938880145549774, acc: 0.9873417615890503)
[2024-12-17 02:29:48,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:48,371][root][INFO] - Training Epoch: 2/2, step 412/7134 completed (loss: 0.0543258897960186, acc: 0.9828375577926636)
[2024-12-17 02:29:48,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:48,704][root][INFO] - Training Epoch: 2/2, step 413/7134 completed (loss: 0.043742403388023376, acc: 0.9866488575935364)
[2024-12-17 02:29:48,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:49,036][root][INFO] - Training Epoch: 2/2, step 414/7134 completed (loss: 0.04786622151732445, acc: 0.9851632118225098)
[2024-12-17 02:29:49,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:49,391][root][INFO] - Training Epoch: 2/2, step 415/7134 completed (loss: 0.06958549469709396, acc: 0.9861111044883728)
[2024-12-17 02:29:49,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:49,768][root][INFO] - Training Epoch: 2/2, step 416/7134 completed (loss: 0.045558761805295944, acc: 0.9881936311721802)
[2024-12-17 02:29:49,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:50,125][root][INFO] - Training Epoch: 2/2, step 417/7134 completed (loss: 0.10048448294401169, acc: 0.98097825050354)
[2024-12-17 02:29:50,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:50,497][root][INFO] - Training Epoch: 2/2, step 418/7134 completed (loss: 0.05101669579744339, acc: 0.9827784299850464)
[2024-12-17 02:29:50,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:50,859][root][INFO] - Training Epoch: 2/2, step 419/7134 completed (loss: 0.06321227550506592, acc: 0.9826302528381348)
[2024-12-17 02:29:50,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:51,183][root][INFO] - Training Epoch: 2/2, step 420/7134 completed (loss: 0.03071880154311657, acc: 0.9932318329811096)
[2024-12-17 02:29:51,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:51,525][root][INFO] - Training Epoch: 2/2, step 421/7134 completed (loss: 0.021173980087041855, acc: 0.9952229261398315)
[2024-12-17 02:29:51,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:51,868][root][INFO] - Training Epoch: 2/2, step 422/7134 completed (loss: 0.04165426269173622, acc: 0.9911764860153198)
[2024-12-17 02:29:52,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:52,232][root][INFO] - Training Epoch: 2/2, step 423/7134 completed (loss: 0.021996675059199333, acc: 0.9928571581840515)
[2024-12-17 02:29:52,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:52,561][root][INFO] - Training Epoch: 2/2, step 424/7134 completed (loss: 0.04269755631685257, acc: 0.9857594966888428)
[2024-12-17 02:29:52,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:52,896][root][INFO] - Training Epoch: 2/2, step 425/7134 completed (loss: 0.016196459531784058, acc: 0.9956395626068115)
[2024-12-17 02:29:53,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:53,243][root][INFO] - Training Epoch: 2/2, step 426/7134 completed (loss: 0.020324833691120148, acc: 0.9958217144012451)
[2024-12-17 02:29:53,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:53,570][root][INFO] - Training Epoch: 2/2, step 427/7134 completed (loss: 0.02568107098340988, acc: 0.9954476356506348)
[2024-12-17 02:29:53,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:53,915][root][INFO] - Training Epoch: 2/2, step 428/7134 completed (loss: 0.030566109344363213, acc: 0.9939758777618408)
[2024-12-17 02:29:54,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:54,248][root][INFO] - Training Epoch: 2/2, step 429/7134 completed (loss: 0.045269716531038284, acc: 0.9825119376182556)
[2024-12-17 02:29:54,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:54,585][root][INFO] - Training Epoch: 2/2, step 430/7134 completed (loss: 0.039380673319101334, acc: 0.9870874881744385)
[2024-12-17 02:29:54,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:54,906][root][INFO] - Training Epoch: 2/2, step 431/7134 completed (loss: 0.046015236526727676, acc: 0.9884726405143738)
[2024-12-17 02:29:55,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:55,222][root][INFO] - Training Epoch: 2/2, step 432/7134 completed (loss: 0.03305608034133911, acc: 0.9853747487068176)
[2024-12-17 02:29:55,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:55,592][root][INFO] - Training Epoch: 2/2, step 433/7134 completed (loss: 0.0335024818778038, acc: 0.9864130616188049)
[2024-12-17 02:29:55,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:55,931][root][INFO] - Training Epoch: 2/2, step 434/7134 completed (loss: 0.04301529750227928, acc: 0.9868228435516357)
[2024-12-17 02:29:56,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:56,282][root][INFO] - Training Epoch: 2/2, step 435/7134 completed (loss: 0.037087760865688324, acc: 0.9900709390640259)
[2024-12-17 02:29:56,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:56,603][root][INFO] - Training Epoch: 2/2, step 436/7134 completed (loss: 0.04626086354255676, acc: 0.9940944910049438)
[2024-12-17 02:29:56,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:56,925][root][INFO] - Training Epoch: 2/2, step 437/7134 completed (loss: 0.04427460581064224, acc: 0.9893993139266968)
[2024-12-17 02:29:57,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:57,240][root][INFO] - Training Epoch: 2/2, step 438/7134 completed (loss: 0.04836881160736084, acc: 0.9865384697914124)
[2024-12-17 02:29:57,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:57,600][root][INFO] - Training Epoch: 2/2, step 439/7134 completed (loss: 0.04223053529858589, acc: 0.9908376932144165)
[2024-12-17 02:29:57,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:57,915][root][INFO] - Training Epoch: 2/2, step 440/7134 completed (loss: 0.05514388531446457, acc: 0.9809358716011047)
[2024-12-17 02:29:58,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:58,249][root][INFO] - Training Epoch: 2/2, step 441/7134 completed (loss: 0.0235675610601902, acc: 0.995502233505249)
[2024-12-17 02:29:58,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:58,579][root][INFO] - Training Epoch: 2/2, step 442/7134 completed (loss: 0.013734789565205574, acc: 0.996268630027771)
[2024-12-17 02:29:58,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:58,937][root][INFO] - Training Epoch: 2/2, step 443/7134 completed (loss: 0.0141032999381423, acc: 0.9984496235847473)
[2024-12-17 02:29:59,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:59,252][root][INFO] - Training Epoch: 2/2, step 444/7134 completed (loss: 0.018442189320921898, acc: 0.9950000047683716)
[2024-12-17 02:29:59,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:59,593][root][INFO] - Training Epoch: 2/2, step 445/7134 completed (loss: 0.05553911253809929, acc: 0.9839650392532349)
[2024-12-17 02:29:59,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:59,943][root][INFO] - Training Epoch: 2/2, step 446/7134 completed (loss: 0.016822300851345062, acc: 0.9944289922714233)
[2024-12-17 02:30:00,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:00,268][root][INFO] - Training Epoch: 2/2, step 447/7134 completed (loss: 0.018038589507341385, acc: 0.9958391189575195)
[2024-12-17 02:30:00,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:00,632][root][INFO] - Training Epoch: 2/2, step 448/7134 completed (loss: 0.08163565397262573, acc: 0.9769821166992188)
[2024-12-17 02:30:00,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:00,993][root][INFO] - Training Epoch: 2/2, step 449/7134 completed (loss: 0.11271931976079941, acc: 0.9646596908569336)
[2024-12-17 02:30:01,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:01,363][root][INFO] - Training Epoch: 2/2, step 450/7134 completed (loss: 0.09002994745969772, acc: 0.9766454100608826)
[2024-12-17 02:30:01,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:01,735][root][INFO] - Training Epoch: 2/2, step 451/7134 completed (loss: 0.16141889989376068, acc: 0.9583829045295715)
[2024-12-17 02:30:01,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:02,099][root][INFO] - Training Epoch: 2/2, step 452/7134 completed (loss: 0.12264993786811829, acc: 0.9602739810943604)
[2024-12-17 02:30:02,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:02,414][root][INFO] - Training Epoch: 2/2, step 453/7134 completed (loss: 0.05415911599993706, acc: 0.9853211045265198)
[2024-12-17 02:30:02,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:02,777][root][INFO] - Training Epoch: 2/2, step 454/7134 completed (loss: 0.11504419147968292, acc: 0.9698600769042969)
[2024-12-17 02:30:02,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:03,139][root][INFO] - Training Epoch: 2/2, step 455/7134 completed (loss: 0.13645023107528687, acc: 0.9699346423149109)
[2024-12-17 02:30:03,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:03,490][root][INFO] - Training Epoch: 2/2, step 456/7134 completed (loss: 0.04115862026810646, acc: 0.9858356714248657)
[2024-12-17 02:30:03,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:03,845][root][INFO] - Training Epoch: 2/2, step 457/7134 completed (loss: 0.08069703727960587, acc: 0.9748322367668152)
[2024-12-17 02:30:03,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:04,161][root][INFO] - Training Epoch: 2/2, step 458/7134 completed (loss: 0.04257705435156822, acc: 0.9900596141815186)
[2024-12-17 02:30:04,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:04,481][root][INFO] - Training Epoch: 2/2, step 459/7134 completed (loss: 0.11128440499305725, acc: 0.9733333587646484)
[2024-12-17 02:30:04,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:04,802][root][INFO] - Training Epoch: 2/2, step 460/7134 completed (loss: 0.07630105316638947, acc: 0.9811023473739624)
[2024-12-17 02:30:04,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:05,165][root][INFO] - Training Epoch: 2/2, step 461/7134 completed (loss: 0.07023042440414429, acc: 0.9831697344779968)
[2024-12-17 02:30:05,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:05,565][root][INFO] - Training Epoch: 2/2, step 462/7134 completed (loss: 0.13235679268836975, acc: 0.9602803587913513)
[2024-12-17 02:30:05,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:05,940][root][INFO] - Training Epoch: 2/2, step 463/7134 completed (loss: 0.08709926158189774, acc: 0.9749059081077576)
[2024-12-17 02:30:06,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:06,320][root][INFO] - Training Epoch: 2/2, step 464/7134 completed (loss: 0.08953744173049927, acc: 0.9702549576759338)
[2024-12-17 02:30:06,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:06,648][root][INFO] - Training Epoch: 2/2, step 465/7134 completed (loss: 0.1246921718120575, acc: 0.9751958250999451)
[2024-12-17 02:30:06,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:07,012][root][INFO] - Training Epoch: 2/2, step 466/7134 completed (loss: 0.13100877404212952, acc: 0.9678249955177307)
[2024-12-17 02:30:07,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:07,366][root][INFO] - Training Epoch: 2/2, step 467/7134 completed (loss: 0.13522526621818542, acc: 0.9671574234962463)
[2024-12-17 02:30:07,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:07,679][root][INFO] - Training Epoch: 2/2, step 468/7134 completed (loss: 0.18842455744743347, acc: 0.9573590159416199)
[2024-12-17 02:30:07,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:08,028][root][INFO] - Training Epoch: 2/2, step 469/7134 completed (loss: 0.09638825058937073, acc: 0.9769452214241028)
[2024-12-17 02:30:08,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:08,362][root][INFO] - Training Epoch: 2/2, step 470/7134 completed (loss: 0.09855692088603973, acc: 0.9755101799964905)
[2024-12-17 02:30:08,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:08,709][root][INFO] - Training Epoch: 2/2, step 471/7134 completed (loss: 0.0964830294251442, acc: 0.9727810621261597)
[2024-12-17 02:30:08,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:09,042][root][INFO] - Training Epoch: 2/2, step 472/7134 completed (loss: 0.12136494368314743, acc: 0.9721407890319824)
[2024-12-17 02:30:09,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:09,378][root][INFO] - Training Epoch: 2/2, step 473/7134 completed (loss: 0.07701226323843002, acc: 0.9675925970077515)
[2024-12-17 02:30:09,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:09,728][root][INFO] - Training Epoch: 2/2, step 474/7134 completed (loss: 0.09853719919919968, acc: 0.9723320007324219)
[2024-12-17 02:30:09,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:10,054][root][INFO] - Training Epoch: 2/2, step 475/7134 completed (loss: 0.1605636179447174, acc: 0.9632353186607361)
[2024-12-17 02:30:10,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:10,391][root][INFO] - Training Epoch: 2/2, step 476/7134 completed (loss: 0.13441574573516846, acc: 0.9541547298431396)
[2024-12-17 02:30:10,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:10,768][root][INFO] - Training Epoch: 2/2, step 477/7134 completed (loss: 0.08863863348960876, acc: 0.9706601500511169)
[2024-12-17 02:30:10,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:11,102][root][INFO] - Training Epoch: 2/2, step 478/7134 completed (loss: 0.16552478075027466, acc: 0.9640591740608215)
[2024-12-17 02:30:11,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:11,416][root][INFO] - Training Epoch: 2/2, step 479/7134 completed (loss: 0.05503338575363159, acc: 0.9827833771705627)
[2024-12-17 02:30:11,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:11,739][root][INFO] - Training Epoch: 2/2, step 480/7134 completed (loss: 0.03558017313480377, acc: 0.9927007555961609)
[2024-12-17 02:30:11,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:12,092][root][INFO] - Training Epoch: 2/2, step 481/7134 completed (loss: 0.05200928449630737, acc: 0.98828125)
[2024-12-17 02:30:12,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:12,427][root][INFO] - Training Epoch: 2/2, step 482/7134 completed (loss: 0.026065636426210403, acc: 0.9957143068313599)
[2024-12-17 02:30:12,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:12,802][root][INFO] - Training Epoch: 2/2, step 483/7134 completed (loss: 0.02175953984260559, acc: 0.9938575029373169)
[2024-12-17 02:30:12,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:13,146][root][INFO] - Training Epoch: 2/2, step 484/7134 completed (loss: 0.08786281943321228, acc: 0.9759358167648315)
[2024-12-17 02:30:13,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:13,477][root][INFO] - Training Epoch: 2/2, step 485/7134 completed (loss: 0.10689305514097214, acc: 0.9788199663162231)
[2024-12-17 02:30:13,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:13,819][root][INFO] - Training Epoch: 2/2, step 486/7134 completed (loss: 0.09143316745758057, acc: 0.9736841917037964)
[2024-12-17 02:30:13,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:14,150][root][INFO] - Training Epoch: 2/2, step 487/7134 completed (loss: 0.05507257208228111, acc: 0.9867841601371765)
[2024-12-17 02:30:14,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:14,460][root][INFO] - Training Epoch: 2/2, step 488/7134 completed (loss: 0.13099423050880432, acc: 0.9692028760910034)
[2024-12-17 02:30:14,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:14,783][root][INFO] - Training Epoch: 2/2, step 489/7134 completed (loss: 0.10849537700414658, acc: 0.9747899174690247)
[2024-12-17 02:30:14,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:15,117][root][INFO] - Training Epoch: 2/2, step 490/7134 completed (loss: 0.06985065340995789, acc: 0.9863945841789246)
[2024-12-17 02:30:15,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:15,432][root][INFO] - Training Epoch: 2/2, step 491/7134 completed (loss: 0.05405651777982712, acc: 0.9868420958518982)
[2024-12-17 02:30:15,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:15,752][root][INFO] - Training Epoch: 2/2, step 492/7134 completed (loss: 0.02089504338800907, acc: 0.998487114906311)
[2024-12-17 02:30:15,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:16,100][root][INFO] - Training Epoch: 2/2, step 493/7134 completed (loss: 0.0735727846622467, acc: 0.982807993888855)
[2024-12-17 02:30:16,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:16,424][root][INFO] - Training Epoch: 2/2, step 494/7134 completed (loss: 0.03525253385305405, acc: 0.9921875)
[2024-12-17 02:30:16,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:16,739][root][INFO] - Training Epoch: 2/2, step 495/7134 completed (loss: 0.03647059202194214, acc: 0.9921568632125854)
[2024-12-17 02:30:16,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:16,994][root][INFO] - Training Epoch: 2/2, step 496/7134 completed (loss: 0.05372237786650658, acc: 0.989159882068634)
[2024-12-17 02:30:17,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:17,311][root][INFO] - Training Epoch: 2/2, step 497/7134 completed (loss: 0.08047128468751907, acc: 0.9767441749572754)
[2024-12-17 02:30:17,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:17,639][root][INFO] - Training Epoch: 2/2, step 498/7134 completed (loss: 0.03685307130217552, acc: 0.995192289352417)
[2024-12-17 02:30:17,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:18,007][root][INFO] - Training Epoch: 2/2, step 499/7134 completed (loss: 0.02780621126294136, acc: 0.9944367408752441)
[2024-12-17 02:30:18,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:18,342][root][INFO] - Training Epoch: 2/2, step 500/7134 completed (loss: 0.030572082847356796, acc: 0.9919999837875366)
[2024-12-17 02:30:18,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:18,705][root][INFO] - Training Epoch: 2/2, step 501/7134 completed (loss: 0.025974804535508156, acc: 0.9958449006080627)
[2024-12-17 02:30:18,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:19,007][root][INFO] - Training Epoch: 2/2, step 502/7134 completed (loss: 0.029266171157360077, acc: 0.9954128265380859)
[2024-12-17 02:30:19,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:19,317][root][INFO] - Training Epoch: 2/2, step 503/7134 completed (loss: 0.04142707213759422, acc: 0.9852349162101746)
[2024-12-17 02:30:19,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:19,667][root][INFO] - Training Epoch: 2/2, step 504/7134 completed (loss: 0.027515821158885956, acc: 0.9916201233863831)
[2024-12-17 02:30:19,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:19,989][root][INFO] - Training Epoch: 2/2, step 505/7134 completed (loss: 0.023164456710219383, acc: 0.9947643876075745)
[2024-12-17 02:30:20,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:20,351][root][INFO] - Training Epoch: 2/2, step 506/7134 completed (loss: 0.04846279323101044, acc: 0.9888059496879578)
[2024-12-17 02:30:20,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:20,711][root][INFO] - Training Epoch: 2/2, step 507/7134 completed (loss: 0.0576571524143219, acc: 0.99210524559021)
[2024-12-17 02:30:20,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:21,057][root][INFO] - Training Epoch: 2/2, step 508/7134 completed (loss: 0.04926280304789543, acc: 0.9860334992408752)
[2024-12-17 02:30:21,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:21,424][root][INFO] - Training Epoch: 2/2, step 509/7134 completed (loss: 0.06171022728085518, acc: 0.9829984307289124)
[2024-12-17 02:30:21,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:21,735][root][INFO] - Training Epoch: 2/2, step 510/7134 completed (loss: 0.1532394289970398, acc: 0.9729729890823364)
[2024-12-17 02:30:21,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:22,047][root][INFO] - Training Epoch: 2/2, step 511/7134 completed (loss: 0.09160803258419037, acc: 0.980440080165863)
[2024-12-17 02:30:22,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:22,373][root][INFO] - Training Epoch: 2/2, step 512/7134 completed (loss: 0.12551696598529816, acc: 0.9739478826522827)
[2024-12-17 02:30:22,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:22,695][root][INFO] - Training Epoch: 2/2, step 513/7134 completed (loss: 0.11129923909902573, acc: 0.9638554453849792)
[2024-12-17 02:30:22,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:22,939][root][INFO] - Training Epoch: 2/2, step 514/7134 completed (loss: 0.14194031059741974, acc: 0.9572864174842834)
[2024-12-17 02:30:23,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:23,310][root][INFO] - Training Epoch: 2/2, step 515/7134 completed (loss: 0.05055283382534981, acc: 0.9929278492927551)
[2024-12-17 02:30:23,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:23,569][root][INFO] - Training Epoch: 2/2, step 516/7134 completed (loss: 0.051550593227148056, acc: 0.986270010471344)
[2024-12-17 02:30:23,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:23,899][root][INFO] - Training Epoch: 2/2, step 517/7134 completed (loss: 0.12808102369308472, acc: 0.9767025113105774)
[2024-12-17 02:30:24,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:24,253][root][INFO] - Training Epoch: 2/2, step 518/7134 completed (loss: 0.05926813185214996, acc: 0.9895052313804626)
[2024-12-17 02:30:24,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:24,580][root][INFO] - Training Epoch: 2/2, step 519/7134 completed (loss: 0.039392467588186264, acc: 0.9876288771629333)
[2024-12-17 02:30:24,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:24,909][root][INFO] - Training Epoch: 2/2, step 520/7134 completed (loss: 0.02816164121031761, acc: 0.9936708807945251)
[2024-12-17 02:30:25,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:25,260][root][INFO] - Training Epoch: 2/2, step 521/7134 completed (loss: 0.0842057466506958, acc: 0.9826435446739197)
[2024-12-17 02:30:25,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:25,601][root][INFO] - Training Epoch: 2/2, step 522/7134 completed (loss: 0.038433365523815155, acc: 0.9906166195869446)
[2024-12-17 02:30:25,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:25,963][root][INFO] - Training Epoch: 2/2, step 523/7134 completed (loss: 0.054866861552000046, acc: 0.9853801131248474)
[2024-12-17 02:30:26,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:26,313][root][INFO] - Training Epoch: 2/2, step 524/7134 completed (loss: 0.05549946054816246, acc: 0.9852150678634644)
[2024-12-17 02:30:26,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:26,638][root][INFO] - Training Epoch: 2/2, step 525/7134 completed (loss: 0.10958147794008255, acc: 0.9768160581588745)
[2024-12-17 02:30:26,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:26,988][root][INFO] - Training Epoch: 2/2, step 526/7134 completed (loss: 0.05677580088376999, acc: 0.9849315285682678)
[2024-12-17 02:30:27,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:27,311][root][INFO] - Training Epoch: 2/2, step 527/7134 completed (loss: 0.0510014072060585, acc: 0.9906716346740723)
[2024-12-17 02:30:27,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:27,666][root][INFO] - Training Epoch: 2/2, step 528/7134 completed (loss: 0.018084201961755753, acc: 0.9959758520126343)
[2024-12-17 02:30:27,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:28,026][root][INFO] - Training Epoch: 2/2, step 529/7134 completed (loss: 0.09899738430976868, acc: 0.9746031761169434)
[2024-12-17 02:30:28,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:28,351][root][INFO] - Training Epoch: 2/2, step 530/7134 completed (loss: 0.040534861385822296, acc: 0.9914236664772034)
[2024-12-17 02:30:28,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:28,625][root][INFO] - Training Epoch: 2/2, step 531/7134 completed (loss: 0.10068368166685104, acc: 0.9794871807098389)
[2024-12-17 02:30:28,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:28,951][root][INFO] - Training Epoch: 2/2, step 532/7134 completed (loss: 0.025172650814056396, acc: 0.9979209899902344)
[2024-12-17 02:30:29,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:29,279][root][INFO] - Training Epoch: 2/2, step 533/7134 completed (loss: 0.08483224362134933, acc: 0.9828178882598877)
[2024-12-17 02:30:29,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:29,633][root][INFO] - Training Epoch: 2/2, step 534/7134 completed (loss: 0.026607539504766464, acc: 0.9958791136741638)
[2024-12-17 02:30:29,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:30,000][root][INFO] - Training Epoch: 2/2, step 535/7134 completed (loss: 0.06906702369451523, acc: 0.9841827750205994)
[2024-12-17 02:30:30,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:30,359][root][INFO] - Training Epoch: 2/2, step 536/7134 completed (loss: 0.048630278557538986, acc: 0.985401451587677)
[2024-12-17 02:30:30,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:30,690][root][INFO] - Training Epoch: 2/2, step 537/7134 completed (loss: 0.05869245529174805, acc: 0.9823269248008728)
[2024-12-17 02:30:30,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:31,031][root][INFO] - Training Epoch: 2/2, step 538/7134 completed (loss: 0.057662952691316605, acc: 0.9792284965515137)
[2024-12-17 02:30:31,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:31,365][root][INFO] - Training Epoch: 2/2, step 539/7134 completed (loss: 0.0492456890642643, acc: 0.9844290614128113)
[2024-12-17 02:30:31,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:31,681][root][INFO] - Training Epoch: 2/2, step 540/7134 completed (loss: 0.05384859815239906, acc: 0.9878787994384766)
[2024-12-17 02:30:31,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:32,032][root][INFO] - Training Epoch: 2/2, step 541/7134 completed (loss: 0.08833908289670944, acc: 0.978723406791687)
[2024-12-17 02:30:32,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:32,342][root][INFO] - Training Epoch: 2/2, step 542/7134 completed (loss: 0.1296510249376297, acc: 0.9577465057373047)
[2024-12-17 02:30:32,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:32,672][root][INFO] - Training Epoch: 2/2, step 543/7134 completed (loss: 0.1002475917339325, acc: 0.9638336300849915)
[2024-12-17 02:30:32,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:33,117][root][INFO] - Training Epoch: 2/2, step 544/7134 completed (loss: 0.08036958426237106, acc: 0.9810725450515747)
[2024-12-17 02:30:33,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:33,481][root][INFO] - Training Epoch: 2/2, step 545/7134 completed (loss: 0.07935940474271774, acc: 0.9806763529777527)
[2024-12-17 02:30:33,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:33,819][root][INFO] - Training Epoch: 2/2, step 546/7134 completed (loss: 0.13090646266937256, acc: 0.957446813583374)
[2024-12-17 02:30:33,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:34,175][root][INFO] - Training Epoch: 2/2, step 547/7134 completed (loss: 0.06189143657684326, acc: 0.9869375824928284)
[2024-12-17 02:30:34,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:34,517][root][INFO] - Training Epoch: 2/2, step 548/7134 completed (loss: 0.05201821029186249, acc: 0.9882659912109375)
[2024-12-17 02:30:34,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:34,853][root][INFO] - Training Epoch: 2/2, step 549/7134 completed (loss: 0.11754058301448822, acc: 0.9627329111099243)
[2024-12-17 02:30:34,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:35,189][root][INFO] - Training Epoch: 2/2, step 550/7134 completed (loss: 0.06130006164312363, acc: 0.9812286496162415)
[2024-12-17 02:30:35,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:35,470][root][INFO] - Training Epoch: 2/2, step 551/7134 completed (loss: 0.06420578807592392, acc: 0.9779005646705627)
[2024-12-17 02:30:35,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:35,796][root][INFO] - Training Epoch: 2/2, step 552/7134 completed (loss: 0.05474139004945755, acc: 0.9814814925193787)
[2024-12-17 02:30:35,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:36,087][root][INFO] - Training Epoch: 2/2, step 553/7134 completed (loss: 0.05566338449716568, acc: 0.9824561476707458)
[2024-12-17 02:30:36,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:36,445][root][INFO] - Training Epoch: 2/2, step 554/7134 completed (loss: 0.0728440135717392, acc: 0.9814550876617432)
[2024-12-17 02:30:36,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:36,781][root][INFO] - Training Epoch: 2/2, step 555/7134 completed (loss: 0.07899335771799088, acc: 0.9810426831245422)
[2024-12-17 02:30:36,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:37,114][root][INFO] - Training Epoch: 2/2, step 556/7134 completed (loss: 0.044512324035167694, acc: 0.987270176410675)
[2024-12-17 02:30:37,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:37,453][root][INFO] - Training Epoch: 2/2, step 557/7134 completed (loss: 0.07860706001520157, acc: 0.9763113260269165)
[2024-12-17 02:30:37,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:37,804][root][INFO] - Training Epoch: 2/2, step 558/7134 completed (loss: 0.03484529256820679, acc: 0.9886524677276611)
[2024-12-17 02:30:37,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:38,157][root][INFO] - Training Epoch: 2/2, step 559/7134 completed (loss: 0.10064931958913803, acc: 0.9729344844818115)
[2024-12-17 02:30:38,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:38,479][root][INFO] - Training Epoch: 2/2, step 560/7134 completed (loss: 0.07467944920063019, acc: 0.9789103865623474)
[2024-12-17 02:30:38,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:38,841][root][INFO] - Training Epoch: 2/2, step 561/7134 completed (loss: 0.10272254049777985, acc: 0.977011501789093)
[2024-12-17 02:30:38,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:39,167][root][INFO] - Training Epoch: 2/2, step 562/7134 completed (loss: 0.04633724316954613, acc: 0.9867549538612366)
[2024-12-17 02:30:39,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:39,490][root][INFO] - Training Epoch: 2/2, step 563/7134 completed (loss: 0.11394426971673965, acc: 0.969936728477478)
[2024-12-17 02:30:39,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:39,844][root][INFO] - Training Epoch: 2/2, step 564/7134 completed (loss: 0.07577215135097504, acc: 0.977750301361084)
[2024-12-17 02:30:39,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:40,151][root][INFO] - Training Epoch: 2/2, step 565/7134 completed (loss: 0.06935679167509079, acc: 0.9765493869781494)
[2024-12-17 02:30:40,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:40,472][root][INFO] - Training Epoch: 2/2, step 566/7134 completed (loss: 0.12850183248519897, acc: 0.9605568647384644)
[2024-12-17 02:30:40,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:40,804][root][INFO] - Training Epoch: 2/2, step 567/7134 completed (loss: 0.07127664238214493, acc: 0.9859747290611267)
[2024-12-17 02:30:40,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:41,141][root][INFO] - Training Epoch: 2/2, step 568/7134 completed (loss: 0.06916335225105286, acc: 0.9816993474960327)
[2024-12-17 02:30:41,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:41,464][root][INFO] - Training Epoch: 2/2, step 569/7134 completed (loss: 0.04539238288998604, acc: 0.9913580417633057)
[2024-12-17 02:30:41,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:41,834][root][INFO] - Training Epoch: 2/2, step 570/7134 completed (loss: 0.04966314136981964, acc: 0.9811986088752747)
[2024-12-17 02:30:41,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:42,189][root][INFO] - Training Epoch: 2/2, step 571/7134 completed (loss: 0.03640225902199745, acc: 0.991183876991272)
[2024-12-17 02:30:42,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:42,528][root][INFO] - Training Epoch: 2/2, step 572/7134 completed (loss: 0.044024571776390076, acc: 0.9884169697761536)
[2024-12-17 02:30:42,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:42,874][root][INFO] - Training Epoch: 2/2, step 573/7134 completed (loss: 0.02425054833292961, acc: 0.9948849081993103)
[2024-12-17 02:30:42,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:43,193][root][INFO] - Training Epoch: 2/2, step 574/7134 completed (loss: 0.022563962265849113, acc: 0.9934123754501343)
[2024-12-17 02:30:43,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:43,568][root][INFO] - Training Epoch: 2/2, step 575/7134 completed (loss: 0.04340174421668053, acc: 0.9922879338264465)
[2024-12-17 02:30:43,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:43,909][root][INFO] - Training Epoch: 2/2, step 576/7134 completed (loss: 0.03182161599397659, acc: 0.9900990128517151)
[2024-12-17 02:30:43,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:44,255][root][INFO] - Training Epoch: 2/2, step 577/7134 completed (loss: 0.05094866454601288, acc: 0.9868247509002686)
[2024-12-17 02:30:44,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:44,624][root][INFO] - Training Epoch: 2/2, step 578/7134 completed (loss: 0.06620031595230103, acc: 0.9837586879730225)
[2024-12-17 02:30:44,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:44,951][root][INFO] - Training Epoch: 2/2, step 579/7134 completed (loss: 0.12174031138420105, acc: 0.9704749584197998)
[2024-12-17 02:30:45,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:45,296][root][INFO] - Training Epoch: 2/2, step 580/7134 completed (loss: 0.0714137852191925, acc: 0.9752925634384155)
[2024-12-17 02:30:45,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:45,612][root][INFO] - Training Epoch: 2/2, step 581/7134 completed (loss: 0.03984862193465233, acc: 0.9902371168136597)
[2024-12-17 02:30:45,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:45,968][root][INFO] - Training Epoch: 2/2, step 582/7134 completed (loss: 0.0459909625351429, acc: 0.9868263602256775)
[2024-12-17 02:30:46,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:46,326][root][INFO] - Training Epoch: 2/2, step 583/7134 completed (loss: 0.04401162266731262, acc: 0.9870129823684692)
[2024-12-17 02:30:46,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:46,678][root][INFO] - Training Epoch: 2/2, step 584/7134 completed (loss: 0.021129842847585678, acc: 0.9976076483726501)
[2024-12-17 02:30:46,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:47,017][root][INFO] - Training Epoch: 2/2, step 585/7134 completed (loss: 0.052454233169555664, acc: 0.987922728061676)
[2024-12-17 02:30:47,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:47,342][root][INFO] - Training Epoch: 2/2, step 586/7134 completed (loss: 0.05155922472476959, acc: 0.9882659912109375)
[2024-12-17 02:30:47,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:47,677][root][INFO] - Training Epoch: 2/2, step 587/7134 completed (loss: 0.04971243813633919, acc: 0.9834815859794617)
[2024-12-17 02:30:47,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:48,035][root][INFO] - Training Epoch: 2/2, step 588/7134 completed (loss: 0.04331212118268013, acc: 0.9905808568000793)
[2024-12-17 02:30:48,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:48,375][root][INFO] - Training Epoch: 2/2, step 589/7134 completed (loss: 0.05037109553813934, acc: 0.9823788404464722)
[2024-12-17 02:30:48,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:48,714][root][INFO] - Training Epoch: 2/2, step 590/7134 completed (loss: 0.0412033386528492, acc: 0.9924812316894531)
[2024-12-17 02:30:48,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:49,062][root][INFO] - Training Epoch: 2/2, step 591/7134 completed (loss: 0.044882241636514664, acc: 0.991525411605835)
[2024-12-17 02:30:49,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:49,394][root][INFO] - Training Epoch: 2/2, step 592/7134 completed (loss: 0.05514070391654968, acc: 0.9873096346855164)
[2024-12-17 02:30:49,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:49,724][root][INFO] - Training Epoch: 2/2, step 593/7134 completed (loss: 0.050886254757642746, acc: 0.9855642914772034)
[2024-12-17 02:30:49,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:50,075][root][INFO] - Training Epoch: 2/2, step 594/7134 completed (loss: 0.06933386623859406, acc: 0.9836478233337402)
[2024-12-17 02:30:50,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:50,452][root][INFO] - Training Epoch: 2/2, step 595/7134 completed (loss: 0.08477528393268585, acc: 0.9785082340240479)
[2024-12-17 02:30:50,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:50,810][root][INFO] - Training Epoch: 2/2, step 596/7134 completed (loss: 0.028965311124920845, acc: 0.9909793734550476)
[2024-12-17 02:30:50,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:51,185][root][INFO] - Training Epoch: 2/2, step 597/7134 completed (loss: 0.16014361381530762, acc: 0.9657443761825562)
[2024-12-17 02:30:51,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:51,534][root][INFO] - Training Epoch: 2/2, step 598/7134 completed (loss: 0.07370635867118835, acc: 0.9729363918304443)
[2024-12-17 02:30:51,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:51,874][root][INFO] - Training Epoch: 2/2, step 599/7134 completed (loss: 0.03754972293972969, acc: 0.9912280440330505)
[2024-12-17 02:30:52,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:52,233][root][INFO] - Training Epoch: 2/2, step 600/7134 completed (loss: 0.049768365919589996, acc: 0.9903730154037476)
[2024-12-17 02:30:52,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:52,598][root][INFO] - Training Epoch: 2/2, step 601/7134 completed (loss: 0.07748492062091827, acc: 0.977869987487793)
[2024-12-17 02:30:52,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:52,969][root][INFO] - Training Epoch: 2/2, step 602/7134 completed (loss: 0.05338263139128685, acc: 0.9872390031814575)
[2024-12-17 02:30:53,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:53,319][root][INFO] - Training Epoch: 2/2, step 603/7134 completed (loss: 0.05882162228226662, acc: 0.9871465563774109)
[2024-12-17 02:30:53,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:53,621][root][INFO] - Training Epoch: 2/2, step 604/7134 completed (loss: 0.060963258147239685, acc: 0.9824304580688477)
[2024-12-17 02:30:53,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:53,962][root][INFO] - Training Epoch: 2/2, step 605/7134 completed (loss: 0.04816276580095291, acc: 0.9870466589927673)
[2024-12-17 02:30:54,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:54,312][root][INFO] - Training Epoch: 2/2, step 606/7134 completed (loss: 0.1507587730884552, acc: 0.9690976738929749)
[2024-12-17 02:30:54,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:54,663][root][INFO] - Training Epoch: 2/2, step 607/7134 completed (loss: 0.05643324553966522, acc: 0.9853137731552124)
[2024-12-17 02:30:54,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:55,023][root][INFO] - Training Epoch: 2/2, step 608/7134 completed (loss: 0.04637064039707184, acc: 0.9909326434135437)
[2024-12-17 02:30:55,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:55,378][root][INFO] - Training Epoch: 2/2, step 609/7134 completed (loss: 0.06206804886460304, acc: 0.9824355840682983)
[2024-12-17 02:30:55,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:55,733][root][INFO] - Training Epoch: 2/2, step 610/7134 completed (loss: 0.06782299280166626, acc: 0.982300877571106)
[2024-12-17 02:30:55,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:56,093][root][INFO] - Training Epoch: 2/2, step 611/7134 completed (loss: 0.043516967445611954, acc: 0.9890244007110596)
[2024-12-17 02:30:56,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:56,420][root][INFO] - Training Epoch: 2/2, step 612/7134 completed (loss: 0.05849564075469971, acc: 0.9722955226898193)
[2024-12-17 02:30:56,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:56,782][root][INFO] - Training Epoch: 2/2, step 613/7134 completed (loss: 0.05293163284659386, acc: 0.9835873246192932)
[2024-12-17 02:30:56,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:57,130][root][INFO] - Training Epoch: 2/2, step 614/7134 completed (loss: 0.042337436228990555, acc: 0.9864099621772766)
[2024-12-17 02:30:57,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:57,477][root][INFO] - Training Epoch: 2/2, step 615/7134 completed (loss: 0.026756662875413895, acc: 0.9901840686798096)
[2024-12-17 02:30:57,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:57,838][root][INFO] - Training Epoch: 2/2, step 616/7134 completed (loss: 0.0396537259221077, acc: 0.9863636493682861)
[2024-12-17 02:30:57,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:58,195][root][INFO] - Training Epoch: 2/2, step 617/7134 completed (loss: 0.03732021898031235, acc: 0.9908883571624756)
[2024-12-17 02:30:58,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:58,536][root][INFO] - Training Epoch: 2/2, step 618/7134 completed (loss: 0.05964692682027817, acc: 0.9786096215248108)
[2024-12-17 02:30:58,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:58,812][root][INFO] - Training Epoch: 2/2, step 619/7134 completed (loss: 0.0984831228852272, acc: 0.9817813634872437)
[2024-12-17 02:30:58,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:59,167][root][INFO] - Training Epoch: 2/2, step 620/7134 completed (loss: 0.0891772136092186, acc: 0.9808917045593262)
[2024-12-17 02:30:59,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:59,507][root][INFO] - Training Epoch: 2/2, step 621/7134 completed (loss: 0.07246661186218262, acc: 0.9832572340965271)
[2024-12-17 02:30:59,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:59,841][root][INFO] - Training Epoch: 2/2, step 622/7134 completed (loss: 0.041723448783159256, acc: 0.9885222315788269)
[2024-12-17 02:30:59,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:00,144][root][INFO] - Training Epoch: 2/2, step 623/7134 completed (loss: 0.11952252686023712, acc: 0.9781340956687927)
[2024-12-17 02:31:00,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:00,495][root][INFO] - Training Epoch: 2/2, step 624/7134 completed (loss: 0.036868710070848465, acc: 0.9932432174682617)
[2024-12-17 02:31:00,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:00,845][root][INFO] - Training Epoch: 2/2, step 625/7134 completed (loss: 0.06640937924385071, acc: 0.9788918495178223)
[2024-12-17 02:31:00,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:01,165][root][INFO] - Training Epoch: 2/2, step 626/7134 completed (loss: 0.11266198754310608, acc: 0.9793814420700073)
[2024-12-17 02:31:01,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:01,496][root][INFO] - Training Epoch: 2/2, step 627/7134 completed (loss: 0.06415042281150818, acc: 0.982300877571106)
[2024-12-17 02:31:01,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:01,836][root][INFO] - Training Epoch: 2/2, step 628/7134 completed (loss: 0.048262037336826324, acc: 0.9889042973518372)
[2024-12-17 02:31:01,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:02,155][root][INFO] - Training Epoch: 2/2, step 629/7134 completed (loss: 0.07292146980762482, acc: 0.9842632412910461)
[2024-12-17 02:31:02,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:02,498][root][INFO] - Training Epoch: 2/2, step 630/7134 completed (loss: 0.056265559047460556, acc: 0.9792746305465698)
[2024-12-17 02:31:02,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:02,816][root][INFO] - Training Epoch: 2/2, step 631/7134 completed (loss: 0.04216139018535614, acc: 0.9828947186470032)
[2024-12-17 02:31:02,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:03,161][root][INFO] - Training Epoch: 2/2, step 632/7134 completed (loss: 0.04787338897585869, acc: 0.9886731505393982)
[2024-12-17 02:31:03,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:03,487][root][INFO] - Training Epoch: 2/2, step 633/7134 completed (loss: 0.06445009261369705, acc: 0.9811320900917053)
[2024-12-17 02:31:03,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:03,814][root][INFO] - Training Epoch: 2/2, step 634/7134 completed (loss: 0.03178198263049126, acc: 0.9936708807945251)
[2024-12-17 02:31:03,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:04,155][root][INFO] - Training Epoch: 2/2, step 635/7134 completed (loss: 0.05734546482563019, acc: 0.9862595200538635)
[2024-12-17 02:31:04,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:04,505][root][INFO] - Training Epoch: 2/2, step 636/7134 completed (loss: 0.10070426017045975, acc: 0.977931022644043)
[2024-12-17 02:31:04,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:04,826][root][INFO] - Training Epoch: 2/2, step 637/7134 completed (loss: 0.05234547331929207, acc: 0.9906890392303467)
[2024-12-17 02:31:04,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:05,145][root][INFO] - Training Epoch: 2/2, step 638/7134 completed (loss: 0.07324347645044327, acc: 0.9765990376472473)
[2024-12-17 02:31:05,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:05,467][root][INFO] - Training Epoch: 2/2, step 639/7134 completed (loss: 0.04804326966404915, acc: 0.9866666793823242)
[2024-12-17 02:31:05,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:05,781][root][INFO] - Training Epoch: 2/2, step 640/7134 completed (loss: 0.07733215391635895, acc: 0.9791304469108582)
[2024-12-17 02:31:05,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:06,097][root][INFO] - Training Epoch: 2/2, step 641/7134 completed (loss: 0.04901747778058052, acc: 0.9852700233459473)
[2024-12-17 02:31:06,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:06,428][root][INFO] - Training Epoch: 2/2, step 642/7134 completed (loss: 0.04076182469725609, acc: 0.9897959232330322)
[2024-12-17 02:31:06,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:06,765][root][INFO] - Training Epoch: 2/2, step 643/7134 completed (loss: 0.030417906120419502, acc: 0.9897304177284241)
[2024-12-17 02:31:06,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:07,095][root][INFO] - Training Epoch: 2/2, step 644/7134 completed (loss: 0.04605282098054886, acc: 0.9845559597015381)
[2024-12-17 02:31:07,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:07,417][root][INFO] - Training Epoch: 2/2, step 645/7134 completed (loss: 0.04749863222241402, acc: 0.9915825128555298)
[2024-12-17 02:31:07,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:07,745][root][INFO] - Training Epoch: 2/2, step 646/7134 completed (loss: 0.0831841453909874, acc: 0.9785932898521423)
[2024-12-17 02:31:07,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:08,069][root][INFO] - Training Epoch: 2/2, step 647/7134 completed (loss: 0.027495024725794792, acc: 0.9932318329811096)
[2024-12-17 02:31:08,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:08,398][root][INFO] - Training Epoch: 2/2, step 648/7134 completed (loss: 0.11838944256305695, acc: 0.9720767736434937)
[2024-12-17 02:31:08,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:08,742][root][INFO] - Training Epoch: 2/2, step 649/7134 completed (loss: 0.05350770801305771, acc: 0.9846153855323792)
[2024-12-17 02:31:08,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:09,074][root][INFO] - Training Epoch: 2/2, step 650/7134 completed (loss: 0.11574656516313553, acc: 0.9670329689979553)
[2024-12-17 02:31:09,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:09,422][root][INFO] - Training Epoch: 2/2, step 651/7134 completed (loss: 0.15788134932518005, acc: 0.9480122327804565)
[2024-12-17 02:31:09,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:09,763][root][INFO] - Training Epoch: 2/2, step 652/7134 completed (loss: 0.04901778697967529, acc: 0.9862542748451233)
[2024-12-17 02:31:09,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:10,101][root][INFO] - Training Epoch: 2/2, step 653/7134 completed (loss: 0.04930741712450981, acc: 0.9872340559959412)
[2024-12-17 02:31:10,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:10,415][root][INFO] - Training Epoch: 2/2, step 654/7134 completed (loss: 0.18372727930545807, acc: 0.9568034410476685)
[2024-12-17 02:31:10,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:10,767][root][INFO] - Training Epoch: 2/2, step 655/7134 completed (loss: 0.08412604033946991, acc: 0.9717742204666138)
[2024-12-17 02:31:10,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:11,095][root][INFO] - Training Epoch: 2/2, step 656/7134 completed (loss: 0.09377475827932358, acc: 0.9762532711029053)
[2024-12-17 02:31:11,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:11,465][root][INFO] - Training Epoch: 2/2, step 657/7134 completed (loss: 0.06193210557103157, acc: 0.9807383418083191)
[2024-12-17 02:31:11,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:11,806][root][INFO] - Training Epoch: 2/2, step 658/7134 completed (loss: 0.06687373667955399, acc: 0.9815546870231628)
[2024-12-17 02:31:11,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:12,160][root][INFO] - Training Epoch: 2/2, step 659/7134 completed (loss: 0.05287465825676918, acc: 0.9809384346008301)
[2024-12-17 02:31:12,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:12,521][root][INFO] - Training Epoch: 2/2, step 660/7134 completed (loss: 0.09019319713115692, acc: 0.9780701994895935)
[2024-12-17 02:31:12,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:12,891][root][INFO] - Training Epoch: 2/2, step 661/7134 completed (loss: 0.1320091336965561, acc: 0.9728033542633057)
[2024-12-17 02:31:12,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:13,256][root][INFO] - Training Epoch: 2/2, step 662/7134 completed (loss: 0.06799516081809998, acc: 0.9798927903175354)
[2024-12-17 02:31:13,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:13,635][root][INFO] - Training Epoch: 2/2, step 663/7134 completed (loss: 0.075041763484478, acc: 0.9775533080101013)
[2024-12-17 02:31:13,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:13,962][root][INFO] - Training Epoch: 2/2, step 664/7134 completed (loss: 0.06778735667467117, acc: 0.9833333492279053)
[2024-12-17 02:31:14,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:14,296][root][INFO] - Training Epoch: 2/2, step 665/7134 completed (loss: 0.06786657124757767, acc: 0.9771198034286499)
[2024-12-17 02:31:14,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:14,666][root][INFO] - Training Epoch: 2/2, step 666/7134 completed (loss: 0.10023953020572662, acc: 0.9780219793319702)
[2024-12-17 02:31:14,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:15,013][root][INFO] - Training Epoch: 2/2, step 667/7134 completed (loss: 0.07271145284175873, acc: 0.9852724671363831)
[2024-12-17 02:31:15,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:15,359][root][INFO] - Training Epoch: 2/2, step 668/7134 completed (loss: 0.07188982516527176, acc: 0.9860582947731018)
[2024-12-17 02:31:15,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:15,735][root][INFO] - Training Epoch: 2/2, step 669/7134 completed (loss: 0.0488971546292305, acc: 0.9863574504852295)
[2024-12-17 02:31:15,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:16,128][root][INFO] - Training Epoch: 2/2, step 670/7134 completed (loss: 0.08188991993665695, acc: 0.9794661402702332)
[2024-12-17 02:31:16,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:16,504][root][INFO] - Training Epoch: 2/2, step 671/7134 completed (loss: 0.06630554050207138, acc: 0.9807074069976807)
[2024-12-17 02:31:16,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:16,817][root][INFO] - Training Epoch: 2/2, step 672/7134 completed (loss: 0.0705767273902893, acc: 0.9836065769195557)
[2024-12-17 02:31:16,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:17,163][root][INFO] - Training Epoch: 2/2, step 673/7134 completed (loss: 0.0760979875922203, acc: 0.9828009605407715)
[2024-12-17 02:31:17,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:17,515][root][INFO] - Training Epoch: 2/2, step 674/7134 completed (loss: 0.11243331432342529, acc: 0.9728506803512573)
[2024-12-17 02:31:17,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:17,872][root][INFO] - Training Epoch: 2/2, step 675/7134 completed (loss: 0.10827726125717163, acc: 0.979139506816864)
[2024-12-17 02:31:17,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:18,219][root][INFO] - Training Epoch: 2/2, step 676/7134 completed (loss: 0.08002965152263641, acc: 0.9905325174331665)
[2024-12-17 02:31:18,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:18,585][root][INFO] - Training Epoch: 2/2, step 677/7134 completed (loss: 0.042850833386182785, acc: 0.9889025688171387)
[2024-12-17 02:31:18,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:18,945][root][INFO] - Training Epoch: 2/2, step 678/7134 completed (loss: 0.05696040764451027, acc: 0.9798115491867065)
[2024-12-17 02:31:19,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:19,273][root][INFO] - Training Epoch: 2/2, step 679/7134 completed (loss: 0.020126763731241226, acc: 0.996219277381897)
[2024-12-17 02:31:19,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:19,638][root][INFO] - Training Epoch: 2/2, step 680/7134 completed (loss: 0.1302339881658554, acc: 0.9703503847122192)
[2024-12-17 02:31:19,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:20,007][root][INFO] - Training Epoch: 2/2, step 681/7134 completed (loss: 0.07417688518762589, acc: 0.9852761030197144)
[2024-12-17 02:31:20,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:20,328][root][INFO] - Training Epoch: 2/2, step 682/7134 completed (loss: 0.04331154748797417, acc: 0.9884726405143738)
[2024-12-17 02:31:20,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:20,692][root][INFO] - Training Epoch: 2/2, step 683/7134 completed (loss: 0.08638438582420349, acc: 0.9849108457565308)
[2024-12-17 02:31:20,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:21,052][root][INFO] - Training Epoch: 2/2, step 684/7134 completed (loss: 0.07724788039922714, acc: 0.9819944500923157)
[2024-12-17 02:31:21,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:21,400][root][INFO] - Training Epoch: 2/2, step 685/7134 completed (loss: 0.053474389016628265, acc: 0.9850373864173889)
[2024-12-17 02:31:21,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:21,752][root][INFO] - Training Epoch: 2/2, step 686/7134 completed (loss: 0.03680386021733284, acc: 0.9907529950141907)
[2024-12-17 02:31:21,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:22,105][root][INFO] - Training Epoch: 2/2, step 687/7134 completed (loss: 0.05006176233291626, acc: 0.9864603281021118)
[2024-12-17 02:31:22,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:22,458][root][INFO] - Training Epoch: 2/2, step 688/7134 completed (loss: 0.014889175072312355, acc: 0.9970414042472839)
[2024-12-17 02:31:22,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:22,776][root][INFO] - Training Epoch: 2/2, step 689/7134 completed (loss: 0.03159356862306595, acc: 0.9897435903549194)
[2024-12-17 02:31:22,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:23,095][root][INFO] - Training Epoch: 2/2, step 690/7134 completed (loss: 0.048059508204460144, acc: 0.9809221029281616)
[2024-12-17 02:31:23,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:23,423][root][INFO] - Training Epoch: 2/2, step 691/7134 completed (loss: 0.08016569912433624, acc: 0.9798850417137146)
[2024-12-17 02:31:23,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:23,774][root][INFO] - Training Epoch: 2/2, step 692/7134 completed (loss: 0.08613137155771255, acc: 0.972000002861023)
[2024-12-17 02:31:23,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:24,095][root][INFO] - Training Epoch: 2/2, step 693/7134 completed (loss: 0.05676651746034622, acc: 0.9886914491653442)
[2024-12-17 02:31:24,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:24,425][root][INFO] - Training Epoch: 2/2, step 694/7134 completed (loss: 0.08227267116308212, acc: 0.9781022071838379)
[2024-12-17 02:31:24,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:24,776][root][INFO] - Training Epoch: 2/2, step 695/7134 completed (loss: 0.11888676881790161, acc: 0.9741824269294739)
[2024-12-17 02:31:24,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:25,104][root][INFO] - Training Epoch: 2/2, step 696/7134 completed (loss: 0.1023237332701683, acc: 0.9741100072860718)
[2024-12-17 02:31:25,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:25,463][root][INFO] - Training Epoch: 2/2, step 697/7134 completed (loss: 0.033222753554582596, acc: 0.9925558567047119)
[2024-12-17 02:31:25,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:25,785][root][INFO] - Training Epoch: 2/2, step 698/7134 completed (loss: 0.045861195772886276, acc: 0.9869706630706787)
[2024-12-17 02:31:25,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:26,160][root][INFO] - Training Epoch: 2/2, step 699/7134 completed (loss: 0.03931540623307228, acc: 0.9906542301177979)
[2024-12-17 02:31:26,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:26,494][root][INFO] - Training Epoch: 2/2, step 700/7134 completed (loss: 0.0619187131524086, acc: 0.9776119589805603)
[2024-12-17 02:31:26,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:26,810][root][INFO] - Training Epoch: 2/2, step 701/7134 completed (loss: 0.06520821899175644, acc: 0.978723406791687)
[2024-12-17 02:31:26,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:27,160][root][INFO] - Training Epoch: 2/2, step 702/7134 completed (loss: 0.06245707720518112, acc: 0.9788960814476013)
[2024-12-17 02:31:27,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:27,487][root][INFO] - Training Epoch: 2/2, step 703/7134 completed (loss: 0.04642472043633461, acc: 0.9919224381446838)
[2024-12-17 02:31:27,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:27,848][root][INFO] - Training Epoch: 2/2, step 704/7134 completed (loss: 0.07563704252243042, acc: 0.9772036671638489)
[2024-12-17 02:31:27,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:28,228][root][INFO] - Training Epoch: 2/2, step 705/7134 completed (loss: 0.09156543761491776, acc: 0.97318434715271)
[2024-12-17 02:31:28,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:28,597][root][INFO] - Training Epoch: 2/2, step 706/7134 completed (loss: 0.04068555682897568, acc: 0.9846827387809753)
[2024-12-17 02:31:28,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:28,947][root][INFO] - Training Epoch: 2/2, step 707/7134 completed (loss: 0.04601829871535301, acc: 0.9904076457023621)
[2024-12-17 02:31:29,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:29,315][root][INFO] - Training Epoch: 2/2, step 708/7134 completed (loss: 0.03295084089040756, acc: 0.9876084327697754)
[2024-12-17 02:31:29,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:29,683][root][INFO] - Training Epoch: 2/2, step 709/7134 completed (loss: 0.05035356059670448, acc: 0.9892601370811462)
[2024-12-17 02:31:29,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:30,049][root][INFO] - Training Epoch: 2/2, step 710/7134 completed (loss: 0.04602304473519325, acc: 0.9866828322410583)
[2024-12-17 02:31:30,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:30,382][root][INFO] - Training Epoch: 2/2, step 711/7134 completed (loss: 0.05408189445734024, acc: 0.9858323335647583)
[2024-12-17 02:31:30,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:30,726][root][INFO] - Training Epoch: 2/2, step 712/7134 completed (loss: 0.04598814994096756, acc: 0.9914529919624329)
[2024-12-17 02:31:30,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:31,090][root][INFO] - Training Epoch: 2/2, step 713/7134 completed (loss: 0.02491275779902935, acc: 0.9953863620758057)
[2024-12-17 02:31:31,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:31,364][root][INFO] - Training Epoch: 2/2, step 714/7134 completed (loss: 0.042322125285863876, acc: 0.9806763529777527)
[2024-12-17 02:31:31,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:31,730][root][INFO] - Training Epoch: 2/2, step 715/7134 completed (loss: 0.030257226899266243, acc: 0.9900568127632141)
[2024-12-17 02:31:31,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:32,082][root][INFO] - Training Epoch: 2/2, step 716/7134 completed (loss: 0.028580227866768837, acc: 0.9943116903305054)
[2024-12-17 02:31:32,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:32,425][root][INFO] - Training Epoch: 2/2, step 717/7134 completed (loss: 0.04902917519211769, acc: 0.9873577952384949)
[2024-12-17 02:31:32,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:32,792][root][INFO] - Training Epoch: 2/2, step 718/7134 completed (loss: 0.025309793651103973, acc: 0.9937343597412109)
[2024-12-17 02:31:32,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:33,084][root][INFO] - Training Epoch: 2/2, step 719/7134 completed (loss: 0.03240824490785599, acc: 0.9896551966667175)
[2024-12-17 02:31:33,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:33,446][root][INFO] - Training Epoch: 2/2, step 720/7134 completed (loss: 0.04787305369973183, acc: 0.9874686598777771)
[2024-12-17 02:31:33,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:33,810][root][INFO] - Training Epoch: 2/2, step 721/7134 completed (loss: 0.06578648835420609, acc: 0.97567218542099)
[2024-12-17 02:31:33,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:34,206][root][INFO] - Training Epoch: 2/2, step 722/7134 completed (loss: 0.027891308069229126, acc: 0.9918319582939148)
[2024-12-17 02:31:34,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:34,571][root][INFO] - Training Epoch: 2/2, step 723/7134 completed (loss: 0.025169603526592255, acc: 0.9939467310905457)
[2024-12-17 02:31:34,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:34,928][root][INFO] - Training Epoch: 2/2, step 724/7134 completed (loss: 0.04140142723917961, acc: 0.9885550737380981)
[2024-12-17 02:31:35,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:35,285][root][INFO] - Training Epoch: 2/2, step 725/7134 completed (loss: 0.032224640250205994, acc: 0.9898697733879089)
[2024-12-17 02:31:35,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:35,638][root][INFO] - Training Epoch: 2/2, step 726/7134 completed (loss: 0.03542746976017952, acc: 0.9888424277305603)
[2024-12-17 02:31:35,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:35,981][root][INFO] - Training Epoch: 2/2, step 727/7134 completed (loss: 0.025630531832575798, acc: 0.9913420081138611)
[2024-12-17 02:31:36,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:36,322][root][INFO] - Training Epoch: 2/2, step 728/7134 completed (loss: 0.022386057302355766, acc: 0.9931129217147827)
[2024-12-17 02:31:36,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:36,671][root][INFO] - Training Epoch: 2/2, step 729/7134 completed (loss: 0.01951812393963337, acc: 0.9916550517082214)
[2024-12-17 02:31:36,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:37,026][root][INFO] - Training Epoch: 2/2, step 730/7134 completed (loss: 0.031751230359077454, acc: 0.990920901298523)
[2024-12-17 02:31:37,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:37,380][root][INFO] - Training Epoch: 2/2, step 731/7134 completed (loss: 0.03059195540845394, acc: 0.9919999837875366)
[2024-12-17 02:31:37,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:37,726][root][INFO] - Training Epoch: 2/2, step 732/7134 completed (loss: 0.08429329842329025, acc: 0.9773585200309753)
[2024-12-17 02:31:37,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:38,016][root][INFO] - Training Epoch: 2/2, step 733/7134 completed (loss: 0.06480372697114944, acc: 0.9822379946708679)
[2024-12-17 02:31:38,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:38,341][root][INFO] - Training Epoch: 2/2, step 734/7134 completed (loss: 0.030011026188731194, acc: 0.9938555955886841)
[2024-12-17 02:31:38,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:38,673][root][INFO] - Training Epoch: 2/2, step 735/7134 completed (loss: 0.026553016155958176, acc: 0.9887459874153137)
[2024-12-17 02:31:38,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:38,997][root][INFO] - Training Epoch: 2/2, step 736/7134 completed (loss: 0.06348022073507309, acc: 0.9758241772651672)
[2024-12-17 02:31:39,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:39,332][root][INFO] - Training Epoch: 2/2, step 737/7134 completed (loss: 0.1335086226463318, acc: 0.9695740342140198)
[2024-12-17 02:31:39,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:39,658][root][INFO] - Training Epoch: 2/2, step 738/7134 completed (loss: 0.011953615583479404, acc: 0.9980769157409668)
[2024-12-17 02:31:39,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:39,993][root][INFO] - Training Epoch: 2/2, step 739/7134 completed (loss: 0.0398918017745018, acc: 0.9834862351417542)
[2024-12-17 02:31:40,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:40,319][root][INFO] - Training Epoch: 2/2, step 740/7134 completed (loss: 0.011057947762310505, acc: 0.9984126687049866)
[2024-12-17 02:31:40,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:40,654][root][INFO] - Training Epoch: 2/2, step 741/7134 completed (loss: 0.04627939313650131, acc: 0.9858044385910034)
[2024-12-17 02:31:40,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:40,939][root][INFO] - Training Epoch: 2/2, step 742/7134 completed (loss: 0.03690740838646889, acc: 0.9874213933944702)
[2024-12-17 02:31:41,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:41,296][root][INFO] - Training Epoch: 2/2, step 743/7134 completed (loss: 0.07076596468687057, acc: 0.9789156913757324)
[2024-12-17 02:31:41,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:41,632][root][INFO] - Training Epoch: 2/2, step 744/7134 completed (loss: 0.06489884108304977, acc: 0.9841269850730896)
[2024-12-17 02:31:41,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:41,996][root][INFO] - Training Epoch: 2/2, step 745/7134 completed (loss: 0.052298158407211304, acc: 0.9909365773200989)
[2024-12-17 02:31:42,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:42,338][root][INFO] - Training Epoch: 2/2, step 746/7134 completed (loss: 0.0668821856379509, acc: 0.9835796356201172)
[2024-12-17 02:31:42,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:42,629][root][INFO] - Training Epoch: 2/2, step 747/7134 completed (loss: 0.11898248642683029, acc: 0.97508305311203)
[2024-12-17 02:31:42,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:42,992][root][INFO] - Training Epoch: 2/2, step 748/7134 completed (loss: 0.050310589373111725, acc: 0.9849624037742615)
[2024-12-17 02:31:43,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:43,336][root][INFO] - Training Epoch: 2/2, step 749/7134 completed (loss: 0.03568284586071968, acc: 0.9899135231971741)
[2024-12-17 02:31:43,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:43,741][root][INFO] - Training Epoch: 2/2, step 750/7134 completed (loss: 0.05852927640080452, acc: 0.9891892075538635)
[2024-12-17 02:31:43,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:44,079][root][INFO] - Training Epoch: 2/2, step 751/7134 completed (loss: 0.10150520503520966, acc: 0.9795570969581604)
[2024-12-17 02:31:44,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:44,365][root][INFO] - Training Epoch: 2/2, step 752/7134 completed (loss: 0.05650483816862106, acc: 0.9879879951477051)
[2024-12-17 02:31:44,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:44,689][root][INFO] - Training Epoch: 2/2, step 753/7134 completed (loss: 0.04458801448345184, acc: 0.9814189076423645)
[2024-12-17 02:31:44,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:45,018][root][INFO] - Training Epoch: 2/2, step 754/7134 completed (loss: 0.031273651868104935, acc: 0.993966817855835)
[2024-12-17 02:31:45,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:45,381][root][INFO] - Training Epoch: 2/2, step 755/7134 completed (loss: 0.07775228470563889, acc: 0.9735973477363586)
[2024-12-17 02:31:45,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:45,723][root][INFO] - Training Epoch: 2/2, step 756/7134 completed (loss: 0.05615095794200897, acc: 0.9813084006309509)
[2024-12-17 02:31:45,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:46,053][root][INFO] - Training Epoch: 2/2, step 757/7134 completed (loss: 0.031589288264513016, acc: 0.9885057210922241)
[2024-12-17 02:31:46,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:46,390][root][INFO] - Training Epoch: 2/2, step 758/7134 completed (loss: 0.09245709329843521, acc: 0.9827883243560791)
[2024-12-17 02:31:46,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:46,681][root][INFO] - Training Epoch: 2/2, step 759/7134 completed (loss: 0.05786149576306343, acc: 0.9786821603775024)
[2024-12-17 02:31:46,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:46,999][root][INFO] - Training Epoch: 2/2, step 760/7134 completed (loss: 0.02101212367415428, acc: 0.9948006868362427)
[2024-12-17 02:31:47,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:47,324][root][INFO] - Training Epoch: 2/2, step 761/7134 completed (loss: 0.02805686555802822, acc: 0.9906103014945984)
[2024-12-17 02:31:47,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:47,649][root][INFO] - Training Epoch: 2/2, step 762/7134 completed (loss: 0.024210242554545403, acc: 0.9946236610412598)
[2024-12-17 02:31:47,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:47,978][root][INFO] - Training Epoch: 2/2, step 763/7134 completed (loss: 0.07363492995500565, acc: 0.9771987199783325)
[2024-12-17 02:31:48,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:48,315][root][INFO] - Training Epoch: 2/2, step 764/7134 completed (loss: 0.02195478416979313, acc: 0.991391658782959)
[2024-12-17 02:31:48,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:48,683][root][INFO] - Training Epoch: 2/2, step 765/7134 completed (loss: 0.02452036365866661, acc: 0.9941434860229492)
[2024-12-17 02:31:48,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:49,044][root][INFO] - Training Epoch: 2/2, step 766/7134 completed (loss: 0.013946172781288624, acc: 0.997032642364502)
[2024-12-17 02:31:49,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:49,382][root][INFO] - Training Epoch: 2/2, step 767/7134 completed (loss: 0.028620673343539238, acc: 0.9926793575286865)
[2024-12-17 02:31:49,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:49,718][root][INFO] - Training Epoch: 2/2, step 768/7134 completed (loss: 0.045660004019737244, acc: 0.9915013909339905)
[2024-12-17 02:31:49,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:50,054][root][INFO] - Training Epoch: 2/2, step 769/7134 completed (loss: 0.015560553409159184, acc: 0.9957020282745361)
[2024-12-17 02:31:50,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:50,370][root][INFO] - Training Epoch: 2/2, step 770/7134 completed (loss: 0.03722384199500084, acc: 0.9877488613128662)
[2024-12-17 02:31:50,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:50,670][root][INFO] - Training Epoch: 2/2, step 771/7134 completed (loss: 0.040206193923950195, acc: 0.986138641834259)
[2024-12-17 02:31:50,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:50,998][root][INFO] - Training Epoch: 2/2, step 772/7134 completed (loss: 0.03784588724374771, acc: 0.9899497628211975)
[2024-12-17 02:31:51,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:51,359][root][INFO] - Training Epoch: 2/2, step 773/7134 completed (loss: 0.05896168574690819, acc: 0.9858611822128296)
[2024-12-17 02:31:51,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:51,684][root][INFO] - Training Epoch: 2/2, step 774/7134 completed (loss: 0.02244994416832924, acc: 0.9933554530143738)
[2024-12-17 02:31:51,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:52,045][root][INFO] - Training Epoch: 2/2, step 775/7134 completed (loss: 0.020892485976219177, acc: 0.9960052967071533)
[2024-12-17 02:31:52,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:52,382][root][INFO] - Training Epoch: 2/2, step 776/7134 completed (loss: 0.015395071357488632, acc: 0.9940828680992126)
[2024-12-17 02:31:52,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:52,698][root][INFO] - Training Epoch: 2/2, step 777/7134 completed (loss: 0.042999789118766785, acc: 0.995184600353241)
[2024-12-17 02:31:52,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:53,048][root][INFO] - Training Epoch: 2/2, step 778/7134 completed (loss: 0.06633520871400833, acc: 0.9871794581413269)
[2024-12-17 02:31:53,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:53,400][root][INFO] - Training Epoch: 2/2, step 779/7134 completed (loss: 0.05314129963517189, acc: 0.9839416146278381)
[2024-12-17 02:31:53,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:53,744][root][INFO] - Training Epoch: 2/2, step 780/7134 completed (loss: 0.05954965949058533, acc: 0.9847908616065979)
[2024-12-17 02:31:53,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:54,117][root][INFO] - Training Epoch: 2/2, step 781/7134 completed (loss: 0.06882081925868988, acc: 0.9780219793319702)
[2024-12-17 02:31:54,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:54,424][root][INFO] - Training Epoch: 2/2, step 782/7134 completed (loss: 0.06612582504749298, acc: 0.9810126423835754)
[2024-12-17 02:31:54,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:54,785][root][INFO] - Training Epoch: 2/2, step 783/7134 completed (loss: 0.05272942781448364, acc: 0.9885350465774536)
[2024-12-17 02:31:54,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:55,122][root][INFO] - Training Epoch: 2/2, step 784/7134 completed (loss: 0.059075165539979935, acc: 0.9805115461349487)
[2024-12-17 02:31:55,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:55,468][root][INFO] - Training Epoch: 2/2, step 785/7134 completed (loss: 0.03651154786348343, acc: 0.9899665713310242)
[2024-12-17 02:31:55,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:55,785][root][INFO] - Training Epoch: 2/2, step 786/7134 completed (loss: 0.10917007923126221, acc: 0.9795538783073425)
[2024-12-17 02:31:55,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:56,101][root][INFO] - Training Epoch: 2/2, step 787/7134 completed (loss: 0.02262466587126255, acc: 0.9963503479957581)
[2024-12-17 02:31:56,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:56,455][root][INFO] - Training Epoch: 2/2, step 788/7134 completed (loss: 0.11363640427589417, acc: 0.9720998406410217)
[2024-12-17 02:31:56,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:56,776][root][INFO] - Training Epoch: 2/2, step 789/7134 completed (loss: 0.04577386751770973, acc: 0.989313006401062)
[2024-12-17 02:31:56,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:57,100][root][INFO] - Training Epoch: 2/2, step 790/7134 completed (loss: 0.0992194190621376, acc: 0.9748520851135254)
[2024-12-17 02:31:57,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:57,417][root][INFO] - Training Epoch: 2/2, step 791/7134 completed (loss: 0.10407806932926178, acc: 0.9743083119392395)
[2024-12-17 02:31:57,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:57,743][root][INFO] - Training Epoch: 2/2, step 792/7134 completed (loss: 0.053748153150081635, acc: 0.984544038772583)
[2024-12-17 02:31:57,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:58,074][root][INFO] - Training Epoch: 2/2, step 793/7134 completed (loss: 0.03140228986740112, acc: 0.9926035404205322)
[2024-12-17 02:31:58,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:58,401][root][INFO] - Training Epoch: 2/2, step 794/7134 completed (loss: 0.04932072013616562, acc: 0.9906759858131409)
[2024-12-17 02:31:58,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:58,671][root][INFO] - Training Epoch: 2/2, step 795/7134 completed (loss: 0.07271070033311844, acc: 0.9813084006309509)
[2024-12-17 02:31:58,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:59,002][root][INFO] - Training Epoch: 2/2, step 796/7134 completed (loss: 0.08176209032535553, acc: 0.9772727489471436)
[2024-12-17 02:31:59,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:59,286][root][INFO] - Training Epoch: 2/2, step 797/7134 completed (loss: 0.05853154882788658, acc: 0.9839357137680054)
[2024-12-17 02:31:59,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:59,571][root][INFO] - Training Epoch: 2/2, step 798/7134 completed (loss: 0.04157488793134689, acc: 0.9841269850730896)
[2024-12-17 02:31:59,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:59,851][root][INFO] - Training Epoch: 2/2, step 799/7134 completed (loss: 0.04043266922235489, acc: 0.9849462509155273)
[2024-12-17 02:31:59,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:00,166][root][INFO] - Training Epoch: 2/2, step 800/7134 completed (loss: 0.0592961460351944, acc: 0.9869646430015564)
[2024-12-17 02:32:00,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:00,511][root][INFO] - Training Epoch: 2/2, step 801/7134 completed (loss: 0.07135340571403503, acc: 0.9760000109672546)
[2024-12-17 02:32:00,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:00,867][root][INFO] - Training Epoch: 2/2, step 802/7134 completed (loss: 0.06197319179773331, acc: 0.9919484853744507)
[2024-12-17 02:32:00,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:01,162][root][INFO] - Training Epoch: 2/2, step 803/7134 completed (loss: 0.04225447028875351, acc: 0.9839285612106323)
[2024-12-17 02:32:01,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:01,480][root][INFO] - Training Epoch: 2/2, step 804/7134 completed (loss: 0.04425150901079178, acc: 0.9898167252540588)
[2024-12-17 02:32:01,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:01,808][root][INFO] - Training Epoch: 2/2, step 805/7134 completed (loss: 0.08120608329772949, acc: 0.9812734127044678)
[2024-12-17 02:32:01,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:02,141][root][INFO] - Training Epoch: 2/2, step 806/7134 completed (loss: 0.02631199359893799, acc: 0.99301677942276)
[2024-12-17 02:32:02,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:02,500][root][INFO] - Training Epoch: 2/2, step 807/7134 completed (loss: 0.07158239930868149, acc: 0.9829683899879456)
[2024-12-17 02:32:02,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:02,851][root][INFO] - Training Epoch: 2/2, step 808/7134 completed (loss: 0.02040759287774563, acc: 0.9928143620491028)
[2024-12-17 02:32:02,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:03,197][root][INFO] - Training Epoch: 2/2, step 809/7134 completed (loss: 0.024031680077314377, acc: 0.9970282316207886)
[2024-12-17 02:32:03,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:03,529][root][INFO] - Training Epoch: 2/2, step 810/7134 completed (loss: 0.08266209065914154, acc: 0.9838056564331055)
[2024-12-17 02:32:03,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:03,830][root][INFO] - Training Epoch: 2/2, step 811/7134 completed (loss: 0.10270487517118454, acc: 0.9753954410552979)
[2024-12-17 02:32:03,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:04,170][root][INFO] - Training Epoch: 2/2, step 812/7134 completed (loss: 0.052951302379369736, acc: 0.9823455214500427)
[2024-12-17 02:32:04,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:04,497][root][INFO] - Training Epoch: 2/2, step 813/7134 completed (loss: 0.03211553394794464, acc: 0.9883889555931091)
[2024-12-17 02:32:04,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:04,851][root][INFO] - Training Epoch: 2/2, step 814/7134 completed (loss: 0.07488255947828293, acc: 0.9806451797485352)
[2024-12-17 02:32:04,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:05,206][root][INFO] - Training Epoch: 2/2, step 815/7134 completed (loss: 0.07169332355260849, acc: 0.9799072742462158)
[2024-12-17 02:32:05,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:05,580][root][INFO] - Training Epoch: 2/2, step 816/7134 completed (loss: 0.06213676184415817, acc: 0.9847457408905029)
[2024-12-17 02:32:05,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:05,922][root][INFO] - Training Epoch: 2/2, step 817/7134 completed (loss: 0.09790240973234177, acc: 0.9817184805870056)
[2024-12-17 02:32:06,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:06,253][root][INFO] - Training Epoch: 2/2, step 818/7134 completed (loss: 0.07037584483623505, acc: 0.975944995880127)
[2024-12-17 02:32:06,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:06,580][root][INFO] - Training Epoch: 2/2, step 819/7134 completed (loss: 0.06327689439058304, acc: 0.9887999892234802)
[2024-12-17 02:32:06,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:06,939][root][INFO] - Training Epoch: 2/2, step 820/7134 completed (loss: 0.04236821085214615, acc: 0.9876352548599243)
[2024-12-17 02:32:07,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:07,305][root][INFO] - Training Epoch: 2/2, step 821/7134 completed (loss: 0.040328774601221085, acc: 0.9946380853652954)
[2024-12-17 02:32:07,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:07,626][root][INFO] - Training Epoch: 2/2, step 822/7134 completed (loss: 0.04529471695423126, acc: 0.9874411225318909)
[2024-12-17 02:32:07,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:07,965][root][INFO] - Training Epoch: 2/2, step 823/7134 completed (loss: 0.019180260598659515, acc: 0.9962476491928101)
[2024-12-17 02:32:08,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:08,293][root][INFO] - Training Epoch: 2/2, step 824/7134 completed (loss: 0.07736906409263611, acc: 0.9787985682487488)
[2024-12-17 02:32:08,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:08,653][root][INFO] - Training Epoch: 2/2, step 825/7134 completed (loss: 0.06016936153173447, acc: 0.9802371263504028)
[2024-12-17 02:32:08,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:09,010][root][INFO] - Training Epoch: 2/2, step 826/7134 completed (loss: 0.03930440545082092, acc: 0.9904631972312927)
[2024-12-17 02:32:09,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:09,346][root][INFO] - Training Epoch: 2/2, step 827/7134 completed (loss: 0.030015036463737488, acc: 0.9921259880065918)
[2024-12-17 02:32:09,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:09,660][root][INFO] - Training Epoch: 2/2, step 828/7134 completed (loss: 0.038459960371255875, acc: 0.9906687140464783)
[2024-12-17 02:32:09,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:09,988][root][INFO] - Training Epoch: 2/2, step 829/7134 completed (loss: 0.04333314299583435, acc: 0.987864077091217)
[2024-12-17 02:32:10,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:10,347][root][INFO] - Training Epoch: 2/2, step 830/7134 completed (loss: 0.04616416618227959, acc: 0.9867109656333923)
[2024-12-17 02:32:10,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:10,688][root][INFO] - Training Epoch: 2/2, step 831/7134 completed (loss: 0.025982031598687172, acc: 0.9945205450057983)
[2024-12-17 02:32:10,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:11,019][root][INFO] - Training Epoch: 2/2, step 832/7134 completed (loss: 0.10772628337144852, acc: 0.9778156876564026)
[2024-12-17 02:32:11,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:11,377][root][INFO] - Training Epoch: 2/2, step 833/7134 completed (loss: 0.03501247987151146, acc: 0.9887955188751221)
[2024-12-17 02:32:11,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:11,718][root][INFO] - Training Epoch: 2/2, step 834/7134 completed (loss: 0.022393058985471725, acc: 0.9944055676460266)
[2024-12-17 02:32:11,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:12,060][root][INFO] - Training Epoch: 2/2, step 835/7134 completed (loss: 0.06816601753234863, acc: 0.9860140085220337)
[2024-12-17 02:32:12,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:12,422][root][INFO] - Training Epoch: 2/2, step 836/7134 completed (loss: 0.05866914242506027, acc: 0.982598602771759)
[2024-12-17 02:32:12,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:12,751][root][INFO] - Training Epoch: 2/2, step 837/7134 completed (loss: 0.06134970858693123, acc: 0.9863760471343994)
[2024-12-17 02:32:12,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:13,087][root][INFO] - Training Epoch: 2/2, step 838/7134 completed (loss: 0.030037932097911835, acc: 0.9936407208442688)
[2024-12-17 02:32:13,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:13,441][root][INFO] - Training Epoch: 2/2, step 839/7134 completed (loss: 0.02779894322156906, acc: 0.9904305934906006)
[2024-12-17 02:32:13,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:13,768][root][INFO] - Training Epoch: 2/2, step 840/7134 completed (loss: 0.03635114058852196, acc: 0.9902371168136597)
[2024-12-17 02:32:13,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:14,104][root][INFO] - Training Epoch: 2/2, step 841/7134 completed (loss: 0.06150539964437485, acc: 0.9834024906158447)
[2024-12-17 02:32:14,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:14,473][root][INFO] - Training Epoch: 2/2, step 842/7134 completed (loss: 0.050284963101148605, acc: 0.986522912979126)
[2024-12-17 02:32:14,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:14,824][root][INFO] - Training Epoch: 2/2, step 843/7134 completed (loss: 0.03976564109325409, acc: 0.9902642369270325)
[2024-12-17 02:32:14,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:15,145][root][INFO] - Training Epoch: 2/2, step 844/7134 completed (loss: 0.0475887656211853, acc: 0.9873617887496948)
[2024-12-17 02:32:15,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:15,466][root][INFO] - Training Epoch: 2/2, step 845/7134 completed (loss: 0.07266119122505188, acc: 0.982300877571106)
[2024-12-17 02:32:15,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:15,813][root][INFO] - Training Epoch: 2/2, step 846/7134 completed (loss: 0.03099977597594261, acc: 0.9925816059112549)
[2024-12-17 02:32:15,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:16,161][root][INFO] - Training Epoch: 2/2, step 847/7134 completed (loss: 0.03467933461070061, acc: 0.98975670337677)
[2024-12-17 02:32:16,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:16,495][root][INFO] - Training Epoch: 2/2, step 848/7134 completed (loss: 0.069420225918293, acc: 0.9814586043357849)
[2024-12-17 02:32:16,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:16,853][root][INFO] - Training Epoch: 2/2, step 849/7134 completed (loss: 0.04534482955932617, acc: 0.987908124923706)
[2024-12-17 02:32:17,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:17,230][root][INFO] - Training Epoch: 2/2, step 850/7134 completed (loss: 0.031648050993680954, acc: 0.991946280002594)
[2024-12-17 02:32:17,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:17,581][root][INFO] - Training Epoch: 2/2, step 851/7134 completed (loss: 0.05720939114689827, acc: 0.9868593811988831)
[2024-12-17 02:32:17,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:17,932][root][INFO] - Training Epoch: 2/2, step 852/7134 completed (loss: 0.026348616927862167, acc: 0.9951159954071045)
[2024-12-17 02:32:18,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:18,302][root][INFO] - Training Epoch: 2/2, step 853/7134 completed (loss: 0.031233051791787148, acc: 0.9889867901802063)
[2024-12-17 02:32:18,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:18,640][root][INFO] - Training Epoch: 2/2, step 854/7134 completed (loss: 0.05809063836932182, acc: 0.9825870394706726)
[2024-12-17 02:32:18,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:19,013][root][INFO] - Training Epoch: 2/2, step 855/7134 completed (loss: 0.06535189598798752, acc: 0.976580798625946)
[2024-12-17 02:32:19,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:19,361][root][INFO] - Training Epoch: 2/2, step 856/7134 completed (loss: 0.025577181950211525, acc: 0.9927361011505127)
[2024-12-17 02:32:19,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:19,689][root][INFO] - Training Epoch: 2/2, step 857/7134 completed (loss: 0.05587615445256233, acc: 0.98531574010849)
[2024-12-17 02:32:19,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:20,032][root][INFO] - Training Epoch: 2/2, step 858/7134 completed (loss: 0.04802853614091873, acc: 0.9838308691978455)
[2024-12-17 02:32:20,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:20,384][root][INFO] - Training Epoch: 2/2, step 859/7134 completed (loss: 0.07281625270843506, acc: 0.9774881601333618)
[2024-12-17 02:32:20,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:20,731][root][INFO] - Training Epoch: 2/2, step 860/7134 completed (loss: 0.05653657764196396, acc: 0.9772440195083618)
[2024-12-17 02:32:20,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:21,091][root][INFO] - Training Epoch: 2/2, step 861/7134 completed (loss: 0.11743178218603134, acc: 0.9696641564369202)
[2024-12-17 02:32:21,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:21,424][root][INFO] - Training Epoch: 2/2, step 862/7134 completed (loss: 0.052037645131349564, acc: 0.9855595827102661)
[2024-12-17 02:32:21,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:21,778][root][INFO] - Training Epoch: 2/2, step 863/7134 completed (loss: 0.08538787066936493, acc: 0.9767171144485474)
[2024-12-17 02:32:21,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:22,124][root][INFO] - Training Epoch: 2/2, step 864/7134 completed (loss: 0.10282742232084274, acc: 0.9681416153907776)
[2024-12-17 02:32:22,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:22,477][root][INFO] - Training Epoch: 2/2, step 865/7134 completed (loss: 0.0768788680434227, acc: 0.9781022071838379)
[2024-12-17 02:32:22,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:22,828][root][INFO] - Training Epoch: 2/2, step 866/7134 completed (loss: 0.12714238464832306, acc: 0.965925931930542)
[2024-12-17 02:32:22,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:23,151][root][INFO] - Training Epoch: 2/2, step 867/7134 completed (loss: 0.07308390736579895, acc: 0.9762202501296997)
[2024-12-17 02:32:23,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:23,508][root][INFO] - Training Epoch: 2/2, step 868/7134 completed (loss: 0.11200358718633652, acc: 0.977748692035675)
[2024-12-17 02:32:23,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:23,768][root][INFO] - Training Epoch: 2/2, step 869/7134 completed (loss: 0.08174128830432892, acc: 0.9681528806686401)
[2024-12-17 02:32:23,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:24,110][root][INFO] - Training Epoch: 2/2, step 870/7134 completed (loss: 0.04761138930916786, acc: 0.9838274717330933)
[2024-12-17 02:32:24,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:24,435][root][INFO] - Training Epoch: 2/2, step 871/7134 completed (loss: 0.1055288016796112, acc: 0.9837133288383484)
[2024-12-17 02:32:24,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:24,764][root][INFO] - Training Epoch: 2/2, step 872/7134 completed (loss: 0.0500958077609539, acc: 0.9811617136001587)
[2024-12-17 02:32:24,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:25,108][root][INFO] - Training Epoch: 2/2, step 873/7134 completed (loss: 0.09155183285474777, acc: 0.9802817106246948)
[2024-12-17 02:32:25,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:25,462][root][INFO] - Training Epoch: 2/2, step 874/7134 completed (loss: 0.06118439510464668, acc: 0.9845916628837585)
[2024-12-17 02:32:25,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:25,793][root][INFO] - Training Epoch: 2/2, step 875/7134 completed (loss: 0.06733114272356033, acc: 0.9795022010803223)
[2024-12-17 02:32:25,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:26,136][root][INFO] - Training Epoch: 2/2, step 876/7134 completed (loss: 0.048986539244651794, acc: 0.9853801131248474)
[2024-12-17 02:32:26,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:26,503][root][INFO] - Training Epoch: 2/2, step 877/7134 completed (loss: 0.11886398494243622, acc: 0.9682119488716125)
[2024-12-17 02:32:26,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:26,838][root][INFO] - Training Epoch: 2/2, step 878/7134 completed (loss: 0.08133868873119354, acc: 0.9734748005867004)
[2024-12-17 02:32:26,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:27,170][root][INFO] - Training Epoch: 2/2, step 879/7134 completed (loss: 0.07011570781469345, acc: 0.9825327396392822)
[2024-12-17 02:32:27,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:27,493][root][INFO] - Training Epoch: 2/2, step 880/7134 completed (loss: 0.020258860662579536, acc: 0.9912663698196411)
[2024-12-17 02:32:27,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:27,816][root][INFO] - Training Epoch: 2/2, step 881/7134 completed (loss: 0.030998729169368744, acc: 0.9939879775047302)
[2024-12-17 02:32:27,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:28,147][root][INFO] - Training Epoch: 2/2, step 882/7134 completed (loss: 0.05378268286585808, acc: 0.9838129281997681)
[2024-12-17 02:32:28,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:28,463][root][INFO] - Training Epoch: 2/2, step 883/7134 completed (loss: 0.08457398414611816, acc: 0.9785932898521423)
[2024-12-17 02:32:28,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:28,793][root][INFO] - Training Epoch: 2/2, step 884/7134 completed (loss: 0.0631670132279396, acc: 0.9825737476348877)
[2024-12-17 02:32:28,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:29,126][root][INFO] - Training Epoch: 2/2, step 885/7134 completed (loss: 0.029962504282593727, acc: 0.9957864880561829)
[2024-12-17 02:32:29,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:29,473][root][INFO] - Training Epoch: 2/2, step 886/7134 completed (loss: 0.10022936016321182, acc: 0.9785575270652771)
[2024-12-17 02:32:29,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:29,758][root][INFO] - Training Epoch: 2/2, step 887/7134 completed (loss: 0.04955895617604256, acc: 0.991150438785553)
[2024-12-17 02:32:29,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:30,090][root][INFO] - Training Epoch: 2/2, step 888/7134 completed (loss: 0.08342812955379486, acc: 0.9833080172538757)
[2024-12-17 02:32:30,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:30,391][root][INFO] - Training Epoch: 2/2, step 889/7134 completed (loss: 0.034594617784023285, acc: 0.9933333396911621)
[2024-12-17 02:32:30,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:30,719][root][INFO] - Training Epoch: 2/2, step 890/7134 completed (loss: 0.07619819790124893, acc: 0.9847198724746704)
[2024-12-17 02:32:30,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:31,070][root][INFO] - Training Epoch: 2/2, step 891/7134 completed (loss: 0.07290833443403244, acc: 0.9888734221458435)
[2024-12-17 02:32:31,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:31,400][root][INFO] - Training Epoch: 2/2, step 892/7134 completed (loss: 0.06104443967342377, acc: 0.9869186282157898)
[2024-12-17 02:32:31,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:31,710][root][INFO] - Training Epoch: 2/2, step 893/7134 completed (loss: 0.0440969243645668, acc: 0.9891641139984131)
[2024-12-17 02:32:31,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:32,052][root][INFO] - Training Epoch: 2/2, step 894/7134 completed (loss: 0.044995613396167755, acc: 0.9916201233863831)
[2024-12-17 02:32:32,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:32,390][root][INFO] - Training Epoch: 2/2, step 895/7134 completed (loss: 0.030106712132692337, acc: 0.988034188747406)
[2024-12-17 02:32:32,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:32,701][root][INFO] - Training Epoch: 2/2, step 896/7134 completed (loss: 0.039068832993507385, acc: 0.9919999837875366)
[2024-12-17 02:32:32,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:33,059][root][INFO] - Training Epoch: 2/2, step 897/7134 completed (loss: 0.033491022884845734, acc: 0.9916434288024902)
[2024-12-17 02:32:33,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:33,422][root][INFO] - Training Epoch: 2/2, step 898/7134 completed (loss: 0.017130248248577118, acc: 0.9975093603134155)
[2024-12-17 02:32:33,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:33,766][root][INFO] - Training Epoch: 2/2, step 899/7134 completed (loss: 0.01863654889166355, acc: 0.9987562298774719)
[2024-12-17 02:32:33,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:34,090][root][INFO] - Training Epoch: 2/2, step 900/7134 completed (loss: 0.0161850918084383, acc: 0.9957805871963501)
[2024-12-17 02:32:34,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:34,440][root][INFO] - Training Epoch: 2/2, step 901/7134 completed (loss: 0.04204028472304344, acc: 0.9866666793823242)
[2024-12-17 02:32:34,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:34,755][root][INFO] - Training Epoch: 2/2, step 902/7134 completed (loss: 0.023549100384116173, acc: 0.9928264021873474)
[2024-12-17 02:32:34,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:35,117][root][INFO] - Training Epoch: 2/2, step 903/7134 completed (loss: 0.007660360541194677, acc: 0.998678982257843)
[2024-12-17 02:32:35,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:35,483][root][INFO] - Training Epoch: 2/2, step 904/7134 completed (loss: 0.02614556811749935, acc: 0.9895833134651184)
[2024-12-17 02:32:35,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:35,849][root][INFO] - Training Epoch: 2/2, step 905/7134 completed (loss: 0.019904285669326782, acc: 0.9946091771125793)
[2024-12-17 02:32:36,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:36,223][root][INFO] - Training Epoch: 2/2, step 906/7134 completed (loss: 0.033894509077072144, acc: 0.9839141964912415)
[2024-12-17 02:32:36,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:36,580][root][INFO] - Training Epoch: 2/2, step 907/7134 completed (loss: 0.02458224818110466, acc: 0.99210524559021)
[2024-12-17 02:32:36,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:36,922][root][INFO] - Training Epoch: 2/2, step 908/7134 completed (loss: 0.02795201539993286, acc: 0.9882965087890625)
[2024-12-17 02:32:37,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:37,265][root][INFO] - Training Epoch: 2/2, step 909/7134 completed (loss: 0.052388910204172134, acc: 0.9864864945411682)
[2024-12-17 02:32:37,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:37,629][root][INFO] - Training Epoch: 2/2, step 910/7134 completed (loss: 0.04180144891142845, acc: 0.9853137731552124)
[2024-12-17 02:32:37,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:37,982][root][INFO] - Training Epoch: 2/2, step 911/7134 completed (loss: 0.023395240306854248, acc: 0.9930070042610168)
[2024-12-17 02:32:38,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:38,340][root][INFO] - Training Epoch: 2/2, step 912/7134 completed (loss: 0.049874890595674515, acc: 0.9911727905273438)
[2024-12-17 02:32:38,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:38,699][root][INFO] - Training Epoch: 2/2, step 913/7134 completed (loss: 0.034505631774663925, acc: 0.9912060499191284)
[2024-12-17 02:32:38,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:39,042][root][INFO] - Training Epoch: 2/2, step 914/7134 completed (loss: 0.03179549053311348, acc: 0.9897959232330322)
[2024-12-17 02:32:39,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:39,367][root][INFO] - Training Epoch: 2/2, step 915/7134 completed (loss: 0.07732288539409637, acc: 0.9854369163513184)
[2024-12-17 02:32:39,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:39,684][root][INFO] - Training Epoch: 2/2, step 916/7134 completed (loss: 0.024922894313931465, acc: 0.9930192232131958)
[2024-12-17 02:32:39,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:40,009][root][INFO] - Training Epoch: 2/2, step 917/7134 completed (loss: 0.05486965551972389, acc: 0.9849170446395874)
[2024-12-17 02:32:40,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:40,341][root][INFO] - Training Epoch: 2/2, step 918/7134 completed (loss: 0.012749327346682549, acc: 0.9954057931900024)
[2024-12-17 02:32:40,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:40,662][root][INFO] - Training Epoch: 2/2, step 919/7134 completed (loss: 0.018490631133317947, acc: 0.9956709742546082)
[2024-12-17 02:32:40,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:40,988][root][INFO] - Training Epoch: 2/2, step 920/7134 completed (loss: 0.034993357956409454, acc: 0.9901960492134094)
[2024-12-17 02:32:41,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:41,306][root][INFO] - Training Epoch: 2/2, step 921/7134 completed (loss: 0.02702736295759678, acc: 0.9905149340629578)
[2024-12-17 02:32:41,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:41,626][root][INFO] - Training Epoch: 2/2, step 922/7134 completed (loss: 0.05920141190290451, acc: 0.980327844619751)
[2024-12-17 02:32:41,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:41,957][root][INFO] - Training Epoch: 2/2, step 923/7134 completed (loss: 0.045238882303237915, acc: 0.9841269850730896)
[2024-12-17 02:32:42,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:42,346][root][INFO] - Training Epoch: 2/2, step 924/7134 completed (loss: 0.025072447955608368, acc: 0.990338146686554)
[2024-12-17 02:32:42,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:42,715][root][INFO] - Training Epoch: 2/2, step 925/7134 completed (loss: 0.042045123875141144, acc: 0.9926578402519226)
[2024-12-17 02:32:42,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:43,074][root][INFO] - Training Epoch: 2/2, step 926/7134 completed (loss: 0.05021069943904877, acc: 0.9887640476226807)
[2024-12-17 02:32:43,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:43,426][root][INFO] - Training Epoch: 2/2, step 927/7134 completed (loss: 0.0743594691157341, acc: 0.983660101890564)
[2024-12-17 02:32:43,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:43,779][root][INFO] - Training Epoch: 2/2, step 928/7134 completed (loss: 0.04622695595026016, acc: 0.9842209219932556)
[2024-12-17 02:32:43,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:44,129][root][INFO] - Training Epoch: 2/2, step 929/7134 completed (loss: 0.025799598544836044, acc: 0.9952606558799744)
[2024-12-17 02:32:44,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:44,434][root][INFO] - Training Epoch: 2/2, step 930/7134 completed (loss: 0.039339784532785416, acc: 0.9879032373428345)
[2024-12-17 02:32:44,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:44,756][root][INFO] - Training Epoch: 2/2, step 931/7134 completed (loss: 0.06135168299078941, acc: 0.9894179701805115)
[2024-12-17 02:32:44,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:45,075][root][INFO] - Training Epoch: 2/2, step 932/7134 completed (loss: 0.04646534472703934, acc: 0.982807993888855)
[2024-12-17 02:32:45,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:45,404][root][INFO] - Training Epoch: 2/2, step 933/7134 completed (loss: 0.050078071653842926, acc: 0.9901269674301147)
[2024-12-17 02:32:45,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:45,737][root][INFO] - Training Epoch: 2/2, step 934/7134 completed (loss: 0.02765054814517498, acc: 0.9908376932144165)
[2024-12-17 02:32:45,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:46,068][root][INFO] - Training Epoch: 2/2, step 935/7134 completed (loss: 0.03208702802658081, acc: 0.989983320236206)
[2024-12-17 02:32:46,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:46,414][root][INFO] - Training Epoch: 2/2, step 936/7134 completed (loss: 0.0598042756319046, acc: 0.982425332069397)
[2024-12-17 02:32:46,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:46,754][root][INFO] - Training Epoch: 2/2, step 937/7134 completed (loss: 0.035305701196193695, acc: 0.9929577708244324)
[2024-12-17 02:32:46,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:47,097][root][INFO] - Training Epoch: 2/2, step 938/7134 completed (loss: 0.04800292104482651, acc: 0.9813753366470337)
[2024-12-17 02:32:47,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:47,418][root][INFO] - Training Epoch: 2/2, step 939/7134 completed (loss: 0.05000128597021103, acc: 0.985981285572052)
[2024-12-17 02:32:47,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:47,783][root][INFO] - Training Epoch: 2/2, step 940/7134 completed (loss: 0.046449799090623856, acc: 0.9856938719749451)
[2024-12-17 02:32:47,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:48,144][root][INFO] - Training Epoch: 2/2, step 941/7134 completed (loss: 0.02580561861395836, acc: 0.9889655113220215)
[2024-12-17 02:32:48,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:48,479][root][INFO] - Training Epoch: 2/2, step 942/7134 completed (loss: 0.05688370764255524, acc: 0.9898403286933899)
[2024-12-17 02:32:48,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:48,817][root][INFO] - Training Epoch: 2/2, step 943/7134 completed (loss: 0.02332339808344841, acc: 0.9939117431640625)
[2024-12-17 02:32:48,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:49,117][root][INFO] - Training Epoch: 2/2, step 944/7134 completed (loss: 0.04080917686223984, acc: 0.9850075244903564)
[2024-12-17 02:32:49,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:49,440][root][INFO] - Training Epoch: 2/2, step 945/7134 completed (loss: 0.04431910440325737, acc: 0.9902098178863525)
[2024-12-17 02:32:49,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:49,769][root][INFO] - Training Epoch: 2/2, step 946/7134 completed (loss: 0.017762117087841034, acc: 0.9935759902000427)
[2024-12-17 02:32:49,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:50,099][root][INFO] - Training Epoch: 2/2, step 947/7134 completed (loss: 0.04185807704925537, acc: 0.9845094680786133)
[2024-12-17 02:32:50,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:50,446][root][INFO] - Training Epoch: 2/2, step 948/7134 completed (loss: 0.043833594769239426, acc: 0.9874826073646545)
[2024-12-17 02:32:50,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:50,822][root][INFO] - Training Epoch: 2/2, step 949/7134 completed (loss: 0.026368549093604088, acc: 0.991584837436676)
[2024-12-17 02:32:50,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:51,159][root][INFO] - Training Epoch: 2/2, step 950/7134 completed (loss: 0.045470643788576126, acc: 0.9876543283462524)
[2024-12-17 02:32:51,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:51,476][root][INFO] - Training Epoch: 2/2, step 951/7134 completed (loss: 0.03058202750980854, acc: 0.9894366264343262)
[2024-12-17 02:32:51,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:51,788][root][INFO] - Training Epoch: 2/2, step 952/7134 completed (loss: 0.08546724170446396, acc: 0.9783693552017212)
[2024-12-17 02:32:51,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:52,152][root][INFO] - Training Epoch: 2/2, step 953/7134 completed (loss: 0.10808748006820679, acc: 0.9705521464347839)
[2024-12-17 02:32:52,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:52,498][root][INFO] - Training Epoch: 2/2, step 954/7134 completed (loss: 0.07417026907205582, acc: 0.9867841601371765)
[2024-12-17 02:32:52,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:52,858][root][INFO] - Training Epoch: 2/2, step 955/7134 completed (loss: 0.044153690338134766, acc: 0.9879518151283264)
[2024-12-17 02:32:52,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:53,203][root][INFO] - Training Epoch: 2/2, step 956/7134 completed (loss: 0.03365122526884079, acc: 0.9890244007110596)
[2024-12-17 02:32:53,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:53,567][root][INFO] - Training Epoch: 2/2, step 957/7134 completed (loss: 0.034187156707048416, acc: 0.9920364022254944)
[2024-12-17 02:32:53,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:53,877][root][INFO] - Training Epoch: 2/2, step 958/7134 completed (loss: 0.05550091341137886, acc: 0.9871323704719543)
[2024-12-17 02:32:54,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:54,215][root][INFO] - Training Epoch: 2/2, step 959/7134 completed (loss: 0.11800424009561539, acc: 0.9679144620895386)
[2024-12-17 02:32:54,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:54,546][root][INFO] - Training Epoch: 2/2, step 960/7134 completed (loss: 0.08286356180906296, acc: 0.9716446399688721)
[2024-12-17 02:32:54,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:54,884][root][INFO] - Training Epoch: 2/2, step 961/7134 completed (loss: 0.09730105847120285, acc: 0.9757412672042847)
[2024-12-17 02:32:54,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:55,230][root][INFO] - Training Epoch: 2/2, step 962/7134 completed (loss: 0.15967753529548645, acc: 0.9586206674575806)
[2024-12-17 02:32:55,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:55,552][root][INFO] - Training Epoch: 2/2, step 963/7134 completed (loss: 0.10268710553646088, acc: 0.9725610017776489)
[2024-12-17 02:32:55,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:55,888][root][INFO] - Training Epoch: 2/2, step 964/7134 completed (loss: 0.15038609504699707, acc: 0.9580209851264954)
[2024-12-17 02:32:56,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:56,226][root][INFO] - Training Epoch: 2/2, step 965/7134 completed (loss: 0.0902273878455162, acc: 0.9698708653450012)
[2024-12-17 02:32:56,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:56,549][root][INFO] - Training Epoch: 2/2, step 966/7134 completed (loss: 0.0678747370839119, acc: 0.9836065769195557)
[2024-12-17 02:32:56,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:56,904][root][INFO] - Training Epoch: 2/2, step 967/7134 completed (loss: 0.05689167231321335, acc: 0.9849931597709656)
[2024-12-17 02:32:57,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:57,218][root][INFO] - Training Epoch: 2/2, step 968/7134 completed (loss: 0.1197124645113945, acc: 0.9721670150756836)
[2024-12-17 02:32:57,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:57,540][root][INFO] - Training Epoch: 2/2, step 969/7134 completed (loss: 0.06517685204744339, acc: 0.9819004535675049)
[2024-12-17 02:32:57,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:57,850][root][INFO] - Training Epoch: 2/2, step 970/7134 completed (loss: 0.07397966086864471, acc: 0.9790076613426208)
[2024-12-17 02:32:57,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:58,197][root][INFO] - Training Epoch: 2/2, step 971/7134 completed (loss: 0.0623914897441864, acc: 0.979141116142273)
[2024-12-17 02:32:58,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:58,566][root][INFO] - Training Epoch: 2/2, step 972/7134 completed (loss: 0.05872643366456032, acc: 0.9775840640068054)
[2024-12-17 02:32:58,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:58,904][root][INFO] - Training Epoch: 2/2, step 973/7134 completed (loss: 0.1166670024394989, acc: 0.978205144405365)
[2024-12-17 02:32:59,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:59,273][root][INFO] - Training Epoch: 2/2, step 974/7134 completed (loss: 0.0862695500254631, acc: 0.9771949648857117)
[2024-12-17 02:32:59,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:59,612][root][INFO] - Training Epoch: 2/2, step 975/7134 completed (loss: 0.1033821776509285, acc: 0.9784688949584961)
[2024-12-17 02:32:59,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:59,969][root][INFO] - Training Epoch: 2/2, step 976/7134 completed (loss: 0.06052648276090622, acc: 0.9844236969947815)
[2024-12-17 02:33:00,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:00,317][root][INFO] - Training Epoch: 2/2, step 977/7134 completed (loss: 0.10003539174795151, acc: 0.9724025726318359)
[2024-12-17 02:33:00,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:00,654][root][INFO] - Training Epoch: 2/2, step 978/7134 completed (loss: 0.042060352861881256, acc: 0.9843562245368958)
[2024-12-17 02:33:00,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:01,003][root][INFO] - Training Epoch: 2/2, step 979/7134 completed (loss: 0.07195933163166046, acc: 0.9786096215248108)
[2024-12-17 02:33:01,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:01,339][root][INFO] - Training Epoch: 2/2, step 980/7134 completed (loss: 0.07131631672382355, acc: 0.981249988079071)
[2024-12-17 02:33:01,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:01,651][root][INFO] - Training Epoch: 2/2, step 981/7134 completed (loss: 0.13888181746006012, acc: 0.9742765426635742)
[2024-12-17 02:33:01,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:02,001][root][INFO] - Training Epoch: 2/2, step 982/7134 completed (loss: 0.060934506356716156, acc: 0.9845505356788635)
[2024-12-17 02:33:02,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:02,332][root][INFO] - Training Epoch: 2/2, step 983/7134 completed (loss: 0.06858157366514206, acc: 0.9794520735740662)
[2024-12-17 02:33:02,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:02,662][root][INFO] - Training Epoch: 2/2, step 984/7134 completed (loss: 0.061384208500385284, acc: 0.9852941036224365)
[2024-12-17 02:33:02,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:03,014][root][INFO] - Training Epoch: 2/2, step 985/7134 completed (loss: 0.06954004615545273, acc: 0.9783163070678711)
[2024-12-17 02:33:03,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:03,351][root][INFO] - Training Epoch: 2/2, step 986/7134 completed (loss: 0.04785594344139099, acc: 0.9815863966941833)
[2024-12-17 02:33:03,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:03,673][root][INFO] - Training Epoch: 2/2, step 987/7134 completed (loss: 0.04368353262543678, acc: 0.9855305552482605)
[2024-12-17 02:33:03,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:03,999][root][INFO] - Training Epoch: 2/2, step 988/7134 completed (loss: 0.11624213308095932, acc: 0.9764216542243958)
[2024-12-17 02:33:04,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:04,336][root][INFO] - Training Epoch: 2/2, step 989/7134 completed (loss: 0.06738433241844177, acc: 0.9791377186775208)
[2024-12-17 02:33:04,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:04,676][root][INFO] - Training Epoch: 2/2, step 990/7134 completed (loss: 0.07351166009902954, acc: 0.9721871018409729)
[2024-12-17 02:33:04,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:05,006][root][INFO] - Training Epoch: 2/2, step 991/7134 completed (loss: 0.08904161304235458, acc: 0.9765258431434631)
[2024-12-17 02:33:05,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:05,359][root][INFO] - Training Epoch: 2/2, step 992/7134 completed (loss: 0.08820407092571259, acc: 0.9736841917037964)
[2024-12-17 02:33:05,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:05,692][root][INFO] - Training Epoch: 2/2, step 993/7134 completed (loss: 0.054376911371946335, acc: 0.9836333990097046)
[2024-12-17 02:33:05,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:06,066][root][INFO] - Training Epoch: 2/2, step 994/7134 completed (loss: 0.06578182429075241, acc: 0.9842342138290405)
[2024-12-17 02:33:06,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:06,407][root][INFO] - Training Epoch: 2/2, step 995/7134 completed (loss: 0.0652771145105362, acc: 0.9768518805503845)
[2024-12-17 02:33:06,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:06,736][root][INFO] - Training Epoch: 2/2, step 996/7134 completed (loss: 0.0640367791056633, acc: 0.9804469347000122)
[2024-12-17 02:33:06,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:07,073][root][INFO] - Training Epoch: 2/2, step 997/7134 completed (loss: 0.07487362623214722, acc: 0.982807993888855)
[2024-12-17 02:33:07,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:07,407][root][INFO] - Training Epoch: 2/2, step 998/7134 completed (loss: 0.059902384877204895, acc: 0.98591548204422)
[2024-12-17 02:33:07,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:07,742][root][INFO] - Training Epoch: 2/2, step 999/7134 completed (loss: 0.033991146832704544, acc: 0.9910394549369812)
[2024-12-17 02:33:07,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:08,072][root][INFO] - Training Epoch: 2/2, step 1000/7134 completed (loss: 0.04859118163585663, acc: 0.9863013625144958)
[2024-12-17 02:33:08,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:08,394][root][INFO] - Training Epoch: 2/2, step 1001/7134 completed (loss: 0.06269124150276184, acc: 0.9838383793830872)
[2024-12-17 02:33:08,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:08,743][root][INFO] - Training Epoch: 2/2, step 1002/7134 completed (loss: 0.06587023288011551, acc: 0.984308123588562)
[2024-12-17 02:33:08,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:09,086][root][INFO] - Training Epoch: 2/2, step 1003/7134 completed (loss: 0.05948282778263092, acc: 0.9851411581039429)
[2024-12-17 02:33:09,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:09,409][root][INFO] - Training Epoch: 2/2, step 1004/7134 completed (loss: 0.08385322242975235, acc: 0.9752577543258667)
[2024-12-17 02:33:09,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:09,743][root][INFO] - Training Epoch: 2/2, step 1005/7134 completed (loss: 0.12237562984228134, acc: 0.9768211841583252)
[2024-12-17 02:33:09,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:10,070][root][INFO] - Training Epoch: 2/2, step 1006/7134 completed (loss: 0.06422669440507889, acc: 0.9832869172096252)
[2024-12-17 02:33:10,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:10,396][root][INFO] - Training Epoch: 2/2, step 1007/7134 completed (loss: 0.12150288373231888, acc: 0.9654631018638611)
[2024-12-17 02:33:10,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:10,734][root][INFO] - Training Epoch: 2/2, step 1008/7134 completed (loss: 0.07480030506849289, acc: 0.9758865237236023)
[2024-12-17 02:33:10,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:11,066][root][INFO] - Training Epoch: 2/2, step 1009/7134 completed (loss: 0.04805852845311165, acc: 0.9911190271377563)
[2024-12-17 02:33:11,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:11,387][root][INFO] - Training Epoch: 2/2, step 1010/7134 completed (loss: 0.06277073919773102, acc: 0.9743083119392395)
[2024-12-17 02:33:11,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:11,724][root][INFO] - Training Epoch: 2/2, step 1011/7134 completed (loss: 0.05364438518881798, acc: 0.9847856163978577)
[2024-12-17 02:33:11,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:12,058][root][INFO] - Training Epoch: 2/2, step 1012/7134 completed (loss: 0.05171278119087219, acc: 0.9858356714248657)
[2024-12-17 02:33:12,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:12,396][root][INFO] - Training Epoch: 2/2, step 1013/7134 completed (loss: 0.09538651257753372, acc: 0.972779393196106)
[2024-12-17 02:33:12,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:12,726][root][INFO] - Training Epoch: 2/2, step 1014/7134 completed (loss: 0.05431671813130379, acc: 0.9835796356201172)
[2024-12-17 02:33:12,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:13,061][root][INFO] - Training Epoch: 2/2, step 1015/7134 completed (loss: 0.05920586362481117, acc: 0.9849397540092468)
[2024-12-17 02:33:13,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:13,378][root][INFO] - Training Epoch: 2/2, step 1016/7134 completed (loss: 0.06719107925891876, acc: 0.9885277152061462)
[2024-12-17 02:33:13,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:13,737][root][INFO] - Training Epoch: 2/2, step 1017/7134 completed (loss: 0.022138286381959915, acc: 0.9946308732032776)
[2024-12-17 02:33:13,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:14,070][root][INFO] - Training Epoch: 2/2, step 1018/7134 completed (loss: 0.0810060203075409, acc: 0.980966329574585)
[2024-12-17 02:33:14,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:14,398][root][INFO] - Training Epoch: 2/2, step 1019/7134 completed (loss: 0.0540630929172039, acc: 0.9839743375778198)
[2024-12-17 02:33:14,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:14,712][root][INFO] - Training Epoch: 2/2, step 1020/7134 completed (loss: 0.030959339812397957, acc: 0.9895522594451904)
[2024-12-17 02:33:14,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:15,045][root][INFO] - Training Epoch: 2/2, step 1021/7134 completed (loss: 0.03006153739988804, acc: 0.9904458522796631)
[2024-12-17 02:33:15,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:15,395][root][INFO] - Training Epoch: 2/2, step 1022/7134 completed (loss: 0.03158368915319443, acc: 0.9894598126411438)
[2024-12-17 02:33:15,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:15,733][root][INFO] - Training Epoch: 2/2, step 1023/7134 completed (loss: 0.05334687605500221, acc: 0.9884169697761536)
[2024-12-17 02:33:15,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:16,051][root][INFO] - Training Epoch: 2/2, step 1024/7134 completed (loss: 0.07608228921890259, acc: 0.9820466637611389)
[2024-12-17 02:33:16,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:16,376][root][INFO] - Training Epoch: 2/2, step 1025/7134 completed (loss: 0.061279430985450745, acc: 0.9875444769859314)
[2024-12-17 02:33:16,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:16,711][root][INFO] - Training Epoch: 2/2, step 1026/7134 completed (loss: 0.10523498058319092, acc: 0.9747368693351746)
[2024-12-17 02:33:16,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:17,041][root][INFO] - Training Epoch: 2/2, step 1027/7134 completed (loss: 0.017458437010645866, acc: 0.9932340979576111)
[2024-12-17 02:33:17,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:17,378][root][INFO] - Training Epoch: 2/2, step 1028/7134 completed (loss: 0.028813432902097702, acc: 0.994020938873291)
[2024-12-17 02:33:17,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:17,727][root][INFO] - Training Epoch: 2/2, step 1029/7134 completed (loss: 0.025515174493193626, acc: 0.9955423474311829)
[2024-12-17 02:33:17,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:18,063][root][INFO] - Training Epoch: 2/2, step 1030/7134 completed (loss: 0.012381300330162048, acc: 0.9986522793769836)
[2024-12-17 02:33:18,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:18,403][root][INFO] - Training Epoch: 2/2, step 1031/7134 completed (loss: 0.04560643807053566, acc: 0.9878048896789551)
[2024-12-17 02:33:18,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:18,758][root][INFO] - Training Epoch: 2/2, step 1032/7134 completed (loss: 0.05081743374466896, acc: 0.9907833933830261)
[2024-12-17 02:33:18,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:19,116][root][INFO] - Training Epoch: 2/2, step 1033/7134 completed (loss: 0.029683152213692665, acc: 0.991391658782959)
[2024-12-17 02:33:19,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:19,466][root][INFO] - Training Epoch: 2/2, step 1034/7134 completed (loss: 0.05918433517217636, acc: 0.987034022808075)
[2024-12-17 02:33:19,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:19,769][root][INFO] - Training Epoch: 2/2, step 1035/7134 completed (loss: 0.18830783665180206, acc: 0.9508771896362305)
[2024-12-17 02:33:19,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:20,056][root][INFO] - Training Epoch: 2/2, step 1036/7134 completed (loss: 0.1573968529701233, acc: 0.9644444584846497)
[2024-12-17 02:33:20,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:20,407][root][INFO] - Training Epoch: 2/2, step 1037/7134 completed (loss: 0.022162558510899544, acc: 0.9940476417541504)
[2024-12-17 02:33:20,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:20,765][root][INFO] - Training Epoch: 2/2, step 1038/7134 completed (loss: 0.02983909659087658, acc: 0.9882550239562988)
[2024-12-17 02:33:20,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:21,075][root][INFO] - Training Epoch: 2/2, step 1039/7134 completed (loss: 0.03288383409380913, acc: 0.9896480441093445)
[2024-12-17 02:33:21,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:21,440][root][INFO] - Training Epoch: 2/2, step 1040/7134 completed (loss: 0.016494574025273323, acc: 0.9965753555297852)
[2024-12-17 02:33:21,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:21,775][root][INFO] - Training Epoch: 2/2, step 1041/7134 completed (loss: 0.03851304575800896, acc: 0.9906542301177979)
[2024-12-17 02:33:21,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:22,126][root][INFO] - Training Epoch: 2/2, step 1042/7134 completed (loss: 0.035855259746313095, acc: 0.9910256266593933)
[2024-12-17 02:33:22,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:22,481][root][INFO] - Training Epoch: 2/2, step 1043/7134 completed (loss: 0.037557851523160934, acc: 0.9927797913551331)
[2024-12-17 02:33:22,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:22,819][root][INFO] - Training Epoch: 2/2, step 1044/7134 completed (loss: 0.05306379869580269, acc: 0.9876712560653687)
[2024-12-17 02:33:22,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:23,124][root][INFO] - Training Epoch: 2/2, step 1045/7134 completed (loss: 0.10536815971136093, acc: 0.9773828983306885)
[2024-12-17 02:33:23,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:23,446][root][INFO] - Training Epoch: 2/2, step 1046/7134 completed (loss: 0.05049311742186546, acc: 0.9884169697761536)
[2024-12-17 02:33:23,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:23,788][root][INFO] - Training Epoch: 2/2, step 1047/7134 completed (loss: 0.07563738524913788, acc: 0.9822221994400024)
[2024-12-17 02:33:23,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:24,197][root][INFO] - Training Epoch: 2/2, step 1048/7134 completed (loss: 0.02622956410050392, acc: 0.992668628692627)
[2024-12-17 02:33:24,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:24,536][root][INFO] - Training Epoch: 2/2, step 1049/7134 completed (loss: 0.05404822155833244, acc: 0.9795022010803223)
[2024-12-17 02:33:24,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:24,880][root][INFO] - Training Epoch: 2/2, step 1050/7134 completed (loss: 0.04400734230875969, acc: 0.9849726557731628)
[2024-12-17 02:33:25,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:25,233][root][INFO] - Training Epoch: 2/2, step 1051/7134 completed (loss: 0.03561539202928543, acc: 0.9917808175086975)
[2024-12-17 02:33:25,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:25,557][root][INFO] - Training Epoch: 2/2, step 1052/7134 completed (loss: 0.08262237906455994, acc: 0.9757673740386963)
[2024-12-17 02:33:25,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:25,888][root][INFO] - Training Epoch: 2/2, step 1053/7134 completed (loss: 0.04179222881793976, acc: 0.9901408553123474)
[2024-12-17 02:33:26,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:26,227][root][INFO] - Training Epoch: 2/2, step 1054/7134 completed (loss: 0.03190237283706665, acc: 0.9867549538612366)
[2024-12-17 02:33:26,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:26,554][root][INFO] - Training Epoch: 2/2, step 1055/7134 completed (loss: 0.1053714007139206, acc: 0.9667405486106873)
[2024-12-17 02:33:26,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:26,886][root][INFO] - Training Epoch: 2/2, step 1056/7134 completed (loss: 0.09457884728908539, acc: 0.9664991497993469)
[2024-12-17 02:33:26,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:27,220][root][INFO] - Training Epoch: 2/2, step 1057/7134 completed (loss: 0.0847640186548233, acc: 0.9754335284233093)
[2024-12-17 02:33:27,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:27,579][root][INFO] - Training Epoch: 2/2, step 1058/7134 completed (loss: 0.038438353687524796, acc: 0.9898550510406494)
[2024-12-17 02:33:27,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:27,934][root][INFO] - Training Epoch: 2/2, step 1059/7134 completed (loss: 0.07386229187250137, acc: 0.9793548583984375)
[2024-12-17 02:33:28,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:28,267][root][INFO] - Training Epoch: 2/2, step 1060/7134 completed (loss: 0.04598582535982132, acc: 0.9858044385910034)
[2024-12-17 02:33:28,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:28,625][root][INFO] - Training Epoch: 2/2, step 1061/7134 completed (loss: 0.05547972768545151, acc: 0.9840116500854492)
[2024-12-17 02:33:28,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:28,944][root][INFO] - Training Epoch: 2/2, step 1062/7134 completed (loss: 0.046910252422094345, acc: 0.9864406585693359)
[2024-12-17 02:33:29,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:29,278][root][INFO] - Training Epoch: 2/2, step 1063/7134 completed (loss: 0.03805786743760109, acc: 0.987034022808075)
[2024-12-17 02:33:29,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:29,637][root][INFO] - Training Epoch: 2/2, step 1064/7134 completed (loss: 0.054562073200941086, acc: 0.9830247163772583)
[2024-12-17 02:33:29,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:29,976][root][INFO] - Training Epoch: 2/2, step 1065/7134 completed (loss: 0.028681475669145584, acc: 0.989159882068634)
[2024-12-17 02:33:30,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:30,304][root][INFO] - Training Epoch: 2/2, step 1066/7134 completed (loss: 0.051205217838287354, acc: 0.9865771532058716)
[2024-12-17 02:33:30,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:30,628][root][INFO] - Training Epoch: 2/2, step 1067/7134 completed (loss: 0.0387103334069252, acc: 0.9876733422279358)
[2024-12-17 02:33:30,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:30,952][root][INFO] - Training Epoch: 2/2, step 1068/7134 completed (loss: 0.03806716576218605, acc: 0.9868667721748352)
[2024-12-17 02:33:31,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:31,287][root][INFO] - Training Epoch: 2/2, step 1069/7134 completed (loss: 0.07136394083499908, acc: 0.9849749803543091)
[2024-12-17 02:33:31,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:31,603][root][INFO] - Training Epoch: 2/2, step 1070/7134 completed (loss: 0.0270544346421957, acc: 0.9885057210922241)
[2024-12-17 02:33:31,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:31,959][root][INFO] - Training Epoch: 2/2, step 1071/7134 completed (loss: 0.031117241829633713, acc: 0.9906291961669922)
[2024-12-17 02:33:32,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:32,302][root][INFO] - Training Epoch: 2/2, step 1072/7134 completed (loss: 0.01025449950248003, acc: 0.9959404468536377)
[2024-12-17 02:33:32,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:32,631][root][INFO] - Training Epoch: 2/2, step 1073/7134 completed (loss: 0.011700589209794998, acc: 0.9942362904548645)
[2024-12-17 02:33:32,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:32,941][root][INFO] - Training Epoch: 2/2, step 1074/7134 completed (loss: 0.09236367791891098, acc: 0.9758203625679016)
[2024-12-17 02:33:33,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:33,283][root][INFO] - Training Epoch: 2/2, step 1075/7134 completed (loss: 0.12993867695331573, acc: 0.970534086227417)
[2024-12-17 02:33:33,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:33,634][root][INFO] - Training Epoch: 2/2, step 1076/7134 completed (loss: 0.13051123917102814, acc: 0.9680851101875305)
[2024-12-17 02:33:33,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:33,953][root][INFO] - Training Epoch: 2/2, step 1077/7134 completed (loss: 0.1539667844772339, acc: 0.9504504799842834)
[2024-12-17 02:33:34,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:34,303][root][INFO] - Training Epoch: 2/2, step 1078/7134 completed (loss: 0.14133520424365997, acc: 0.9660742878913879)
[2024-12-17 02:33:34,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:34,651][root][INFO] - Training Epoch: 2/2, step 1079/7134 completed (loss: 0.0479106605052948, acc: 0.9861591458320618)
[2024-12-17 02:33:34,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:34,965][root][INFO] - Training Epoch: 2/2, step 1080/7134 completed (loss: 0.06367046386003494, acc: 0.9868420958518982)
[2024-12-17 02:33:35,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:35,305][root][INFO] - Training Epoch: 2/2, step 1081/7134 completed (loss: 0.060678981244564056, acc: 0.9789621233940125)
[2024-12-17 02:33:35,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:35,688][root][INFO] - Training Epoch: 2/2, step 1082/7134 completed (loss: 0.03179739788174629, acc: 0.9876670241355896)
[2024-12-17 02:33:35,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:36,046][root][INFO] - Training Epoch: 2/2, step 1083/7134 completed (loss: 0.043001171201467514, acc: 0.9830508232116699)
[2024-12-17 02:33:36,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:36,402][root][INFO] - Training Epoch: 2/2, step 1084/7134 completed (loss: 0.062311746180057526, acc: 0.9776951670646667)
[2024-12-17 02:33:36,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:36,741][root][INFO] - Training Epoch: 2/2, step 1085/7134 completed (loss: 0.03915614262223244, acc: 0.9852744340896606)
[2024-12-17 02:33:36,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:37,061][root][INFO] - Training Epoch: 2/2, step 1086/7134 completed (loss: 0.07968634366989136, acc: 0.9754253029823303)
[2024-12-17 02:33:37,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:37,419][root][INFO] - Training Epoch: 2/2, step 1087/7134 completed (loss: 0.051078978925943375, acc: 0.9829268455505371)
[2024-12-17 02:33:37,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:37,749][root][INFO] - Training Epoch: 2/2, step 1088/7134 completed (loss: 0.027960876002907753, acc: 0.99301677942276)
[2024-12-17 02:33:37,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:38,076][root][INFO] - Training Epoch: 2/2, step 1089/7134 completed (loss: 0.06769105046987534, acc: 0.9821162223815918)
[2024-12-17 02:33:38,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:38,415][root][INFO] - Training Epoch: 2/2, step 1090/7134 completed (loss: 0.05291690304875374, acc: 0.9781591296195984)
[2024-12-17 02:33:38,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:38,740][root][INFO] - Training Epoch: 2/2, step 1091/7134 completed (loss: 0.03805866464972496, acc: 0.9939117431640625)
[2024-12-17 02:33:38,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:39,092][root][INFO] - Training Epoch: 2/2, step 1092/7134 completed (loss: 0.025152888149023056, acc: 0.9927745461463928)
[2024-12-17 02:33:39,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:39,424][root][INFO] - Training Epoch: 2/2, step 1093/7134 completed (loss: 0.09187143296003342, acc: 0.9733542203903198)
[2024-12-17 02:33:39,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:39,758][root][INFO] - Training Epoch: 2/2, step 1094/7134 completed (loss: 0.08376272022724152, acc: 0.975836455821991)
[2024-12-17 02:33:39,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:40,132][root][INFO] - Training Epoch: 2/2, step 1095/7134 completed (loss: 0.057208988815546036, acc: 0.9853836894035339)
[2024-12-17 02:33:40,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:40,499][root][INFO] - Training Epoch: 2/2, step 1096/7134 completed (loss: 0.05258297920227051, acc: 0.9848101139068604)
[2024-12-17 02:33:40,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:40,853][root][INFO] - Training Epoch: 2/2, step 1097/7134 completed (loss: 0.08905773609876633, acc: 0.9733145833015442)
[2024-12-17 02:33:40,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:41,190][root][INFO] - Training Epoch: 2/2, step 1098/7134 completed (loss: 0.04138144478201866, acc: 0.9851668477058411)
[2024-12-17 02:33:41,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:41,540][root][INFO] - Training Epoch: 2/2, step 1099/7134 completed (loss: 0.043861277401447296, acc: 0.9897435903549194)
[2024-12-17 02:33:41,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:41,899][root][INFO] - Training Epoch: 2/2, step 1100/7134 completed (loss: 0.06598705798387527, acc: 0.98777174949646)
[2024-12-17 02:33:42,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:42,251][root][INFO] - Training Epoch: 2/2, step 1101/7134 completed (loss: 0.04148755595088005, acc: 0.9922077655792236)
[2024-12-17 02:33:42,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:42,582][root][INFO] - Training Epoch: 2/2, step 1102/7134 completed (loss: 0.061951179057359695, acc: 0.980430543422699)
[2024-12-17 02:33:42,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:42,946][root][INFO] - Training Epoch: 2/2, step 1103/7134 completed (loss: 0.10577021539211273, acc: 0.9746666550636292)
[2024-12-17 02:33:43,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:43,271][root][INFO] - Training Epoch: 2/2, step 1104/7134 completed (loss: 0.04991218447685242, acc: 0.9855907559394836)
[2024-12-17 02:33:43,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:43,612][root][INFO] - Training Epoch: 2/2, step 1105/7134 completed (loss: 0.048657000064849854, acc: 0.9892183542251587)
[2024-12-17 02:33:43,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:43,935][root][INFO] - Training Epoch: 2/2, step 1106/7134 completed (loss: 0.06073557212948799, acc: 0.9834710955619812)
[2024-12-17 02:33:44,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:44,310][root][INFO] - Training Epoch: 2/2, step 1107/7134 completed (loss: 0.04129547253251076, acc: 0.9906213283538818)
[2024-12-17 02:33:44,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:44,656][root][INFO] - Training Epoch: 2/2, step 1108/7134 completed (loss: 0.019750233739614487, acc: 0.9961340427398682)
[2024-12-17 02:33:44,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:45,013][root][INFO] - Training Epoch: 2/2, step 1109/7134 completed (loss: 0.06297702342271805, acc: 0.9804469347000122)
[2024-12-17 02:33:45,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:45,344][root][INFO] - Training Epoch: 2/2, step 1110/7134 completed (loss: 0.09754842519760132, acc: 0.9777195453643799)
[2024-12-17 02:33:45,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:45,676][root][INFO] - Training Epoch: 2/2, step 1111/7134 completed (loss: 0.0495455339550972, acc: 0.9861878156661987)
[2024-12-17 02:33:45,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:45,983][root][INFO] - Training Epoch: 2/2, step 1112/7134 completed (loss: 0.0725395455956459, acc: 0.9750000238418579)
[2024-12-17 02:33:46,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:46,320][root][INFO] - Training Epoch: 2/2, step 1113/7134 completed (loss: 0.0461563803255558, acc: 0.9897040128707886)
[2024-12-17 02:33:46,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:46,667][root][INFO] - Training Epoch: 2/2, step 1114/7134 completed (loss: 0.03922717645764351, acc: 0.9878493547439575)
[2024-12-17 02:33:46,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:47,002][root][INFO] - Training Epoch: 2/2, step 1115/7134 completed (loss: 0.05755378305912018, acc: 0.9811320900917053)
[2024-12-17 02:33:47,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:47,315][root][INFO] - Training Epoch: 2/2, step 1116/7134 completed (loss: 0.028659777715802193, acc: 0.9925373196601868)
[2024-12-17 02:33:47,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:47,639][root][INFO] - Training Epoch: 2/2, step 1117/7134 completed (loss: 0.03865775465965271, acc: 0.9923312664031982)
[2024-12-17 02:33:47,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:47,952][root][INFO] - Training Epoch: 2/2, step 1118/7134 completed (loss: 0.03407495841383934, acc: 0.9896551966667175)
[2024-12-17 02:33:48,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:48,269][root][INFO] - Training Epoch: 2/2, step 1119/7134 completed (loss: 0.05011459067463875, acc: 0.9873617887496948)
[2024-12-17 02:33:48,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:48,605][root][INFO] - Training Epoch: 2/2, step 1120/7134 completed (loss: 0.06283358484506607, acc: 0.9842767119407654)
[2024-12-17 02:33:48,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:48,935][root][INFO] - Training Epoch: 2/2, step 1121/7134 completed (loss: 0.07649997621774673, acc: 0.9837518334388733)
[2024-12-17 02:33:49,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:49,229][root][INFO] - Training Epoch: 2/2, step 1122/7134 completed (loss: 0.04478667676448822, acc: 0.9902912378311157)
[2024-12-17 02:33:49,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:49,562][root][INFO] - Training Epoch: 2/2, step 1123/7134 completed (loss: 0.04745086282491684, acc: 0.9855538010597229)
[2024-12-17 02:33:49,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:49,905][root][INFO] - Training Epoch: 2/2, step 1124/7134 completed (loss: 0.046578548848629, acc: 0.9860681295394897)
[2024-12-17 02:33:50,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:50,242][root][INFO] - Training Epoch: 2/2, step 1125/7134 completed (loss: 0.028230728581547737, acc: 0.9918808937072754)
[2024-12-17 02:33:50,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:50,578][root][INFO] - Training Epoch: 2/2, step 1126/7134 completed (loss: 0.0605931431055069, acc: 0.9834254384040833)
[2024-12-17 02:33:50,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:50,913][root][INFO] - Training Epoch: 2/2, step 1127/7134 completed (loss: 0.03118116222321987, acc: 0.9904000163078308)
[2024-12-17 02:33:51,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:51,245][root][INFO] - Training Epoch: 2/2, step 1128/7134 completed (loss: 0.03248276188969612, acc: 0.9895833134651184)
[2024-12-17 02:33:51,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:51,543][root][INFO] - Training Epoch: 2/2, step 1129/7134 completed (loss: 0.055512163788080215, acc: 0.9820627570152283)
[2024-12-17 02:33:51,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:51,890][root][INFO] - Training Epoch: 2/2, step 1130/7134 completed (loss: 0.0412343367934227, acc: 0.9886914491653442)
[2024-12-17 02:33:52,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:52,259][root][INFO] - Training Epoch: 2/2, step 1131/7134 completed (loss: 0.08437629789113998, acc: 0.9764150977134705)
[2024-12-17 02:33:52,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:52,585][root][INFO] - Training Epoch: 2/2, step 1132/7134 completed (loss: 0.13101468980312347, acc: 0.9678407311439514)
[2024-12-17 02:33:52,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:52,943][root][INFO] - Training Epoch: 2/2, step 1133/7134 completed (loss: 0.12849611043930054, acc: 0.9728958606719971)
[2024-12-17 02:33:53,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:53,283][root][INFO] - Training Epoch: 2/2, step 1134/7134 completed (loss: 0.07715320587158203, acc: 0.9788029789924622)
[2024-12-17 02:33:53,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:53,612][root][INFO] - Training Epoch: 2/2, step 1135/7134 completed (loss: 0.07998067140579224, acc: 0.974399983882904)
[2024-12-17 02:33:53,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:53,968][root][INFO] - Training Epoch: 2/2, step 1136/7134 completed (loss: 0.10585571080446243, acc: 0.9673469662666321)
[2024-12-17 02:33:54,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:54,267][root][INFO] - Training Epoch: 2/2, step 1137/7134 completed (loss: 0.06942444294691086, acc: 0.9795454740524292)
[2024-12-17 02:33:54,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:54,633][root][INFO] - Training Epoch: 2/2, step 1138/7134 completed (loss: 0.08603594452142715, acc: 0.9726775884628296)
[2024-12-17 02:33:54,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:54,952][root][INFO] - Training Epoch: 2/2, step 1139/7134 completed (loss: 0.10713807493448257, acc: 0.9713321924209595)
[2024-12-17 02:33:55,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:55,275][root][INFO] - Training Epoch: 2/2, step 1140/7134 completed (loss: 0.04428093880414963, acc: 0.9774436354637146)
[2024-12-17 02:33:55,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:55,604][root][INFO] - Training Epoch: 2/2, step 1141/7134 completed (loss: 0.04250848665833473, acc: 0.9953161478042603)
[2024-12-17 02:33:55,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:55,947][root][INFO] - Training Epoch: 2/2, step 1142/7134 completed (loss: 0.06533169001340866, acc: 0.98828125)
[2024-12-17 02:33:56,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:56,267][root][INFO] - Training Epoch: 2/2, step 1143/7134 completed (loss: 0.10257895290851593, acc: 0.9749652147293091)
[2024-12-17 02:33:56,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:56,610][root][INFO] - Training Epoch: 2/2, step 1144/7134 completed (loss: 0.0901155173778534, acc: 0.981249988079071)
[2024-12-17 02:33:56,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:56,957][root][INFO] - Training Epoch: 2/2, step 1145/7134 completed (loss: 0.04690344259142876, acc: 0.9904076457023621)
[2024-12-17 02:33:57,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:57,297][root][INFO] - Training Epoch: 2/2, step 1146/7134 completed (loss: 0.03646886348724365, acc: 0.9927536249160767)
[2024-12-17 02:33:57,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:57,626][root][INFO] - Training Epoch: 2/2, step 1147/7134 completed (loss: 0.03936067596077919, acc: 0.9900249242782593)
[2024-12-17 02:33:57,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:57,954][root][INFO] - Training Epoch: 2/2, step 1148/7134 completed (loss: 0.05937756597995758, acc: 0.988054633140564)
[2024-12-17 02:33:58,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:58,270][root][INFO] - Training Epoch: 2/2, step 1149/7134 completed (loss: 0.11765158176422119, acc: 0.9604395627975464)
[2024-12-17 02:33:58,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:58,618][root][INFO] - Training Epoch: 2/2, step 1150/7134 completed (loss: 0.04137510806322098, acc: 0.9860464930534363)
[2024-12-17 02:33:58,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:58,941][root][INFO] - Training Epoch: 2/2, step 1151/7134 completed (loss: 0.017519015818834305, acc: 0.9959431886672974)
[2024-12-17 02:33:59,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:59,271][root][INFO] - Training Epoch: 2/2, step 1152/7134 completed (loss: 0.030078930780291557, acc: 0.9931623935699463)
[2024-12-17 02:33:59,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:59,618][root][INFO] - Training Epoch: 2/2, step 1153/7134 completed (loss: 0.09435848146677017, acc: 0.9768392443656921)
[2024-12-17 02:33:59,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:59,951][root][INFO] - Training Epoch: 2/2, step 1154/7134 completed (loss: 0.05690063163638115, acc: 0.9858406782150269)
[2024-12-17 02:34:00,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:00,305][root][INFO] - Training Epoch: 2/2, step 1155/7134 completed (loss: 0.07723333686590195, acc: 0.969298243522644)
[2024-12-17 02:34:00,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:00,657][root][INFO] - Training Epoch: 2/2, step 1156/7134 completed (loss: 0.02282337099313736, acc: 0.9938555955886841)
[2024-12-17 02:34:00,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:00,992][root][INFO] - Training Epoch: 2/2, step 1157/7134 completed (loss: 0.0892326682806015, acc: 0.9762309193611145)
[2024-12-17 02:34:01,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:01,318][root][INFO] - Training Epoch: 2/2, step 1158/7134 completed (loss: 0.07554885745048523, acc: 0.9822485446929932)
[2024-12-17 02:34:01,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:01,664][root][INFO] - Training Epoch: 2/2, step 1159/7134 completed (loss: 0.07688641548156738, acc: 0.980141818523407)
[2024-12-17 02:34:01,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:02,015][root][INFO] - Training Epoch: 2/2, step 1160/7134 completed (loss: 0.039999257773160934, acc: 0.9895833134651184)
[2024-12-17 02:34:02,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:02,346][root][INFO] - Training Epoch: 2/2, step 1161/7134 completed (loss: 0.10998277366161346, acc: 0.9771615266799927)
[2024-12-17 02:34:02,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:02,665][root][INFO] - Training Epoch: 2/2, step 1162/7134 completed (loss: 0.0507468655705452, acc: 0.9818181991577148)
[2024-12-17 02:34:02,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:02,997][root][INFO] - Training Epoch: 2/2, step 1163/7134 completed (loss: 0.05080029368400574, acc: 0.9897611141204834)
[2024-12-17 02:34:03,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:03,325][root][INFO] - Training Epoch: 2/2, step 1164/7134 completed (loss: 0.07357463985681534, acc: 0.9847009778022766)
[2024-12-17 02:34:03,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:03,691][root][INFO] - Training Epoch: 2/2, step 1165/7134 completed (loss: 0.02928963303565979, acc: 0.9932157397270203)
[2024-12-17 02:34:03,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:04,025][root][INFO] - Training Epoch: 2/2, step 1166/7134 completed (loss: 0.038143664598464966, acc: 0.9890260696411133)
[2024-12-17 02:34:04,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:04,357][root][INFO] - Training Epoch: 2/2, step 1167/7134 completed (loss: 0.014563659206032753, acc: 0.9980353713035583)
[2024-12-17 02:34:04,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:04,724][root][INFO] - Training Epoch: 2/2, step 1168/7134 completed (loss: 0.02229156903922558, acc: 0.9907894730567932)
[2024-12-17 02:34:04,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:05,063][root][INFO] - Training Epoch: 2/2, step 1169/7134 completed (loss: 0.0667695477604866, acc: 0.9851351380348206)
[2024-12-17 02:34:05,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:05,410][root][INFO] - Training Epoch: 2/2, step 1170/7134 completed (loss: 0.04166519269347191, acc: 0.9901685118675232)
[2024-12-17 02:34:05,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:05,685][root][INFO] - Training Epoch: 2/2, step 1171/7134 completed (loss: 0.03489821404218674, acc: 0.9916527271270752)
[2024-12-17 02:34:05,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:06,008][root][INFO] - Training Epoch: 2/2, step 1172/7134 completed (loss: 0.059823669493198395, acc: 0.9848713874816895)
[2024-12-17 02:34:06,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:06,337][root][INFO] - Training Epoch: 2/2, step 1173/7134 completed (loss: 0.06944525241851807, acc: 0.9826086759567261)
[2024-12-17 02:34:06,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:06,657][root][INFO] - Training Epoch: 2/2, step 1174/7134 completed (loss: 0.027658279985189438, acc: 0.9924924969673157)
[2024-12-17 02:34:06,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:06,997][root][INFO] - Training Epoch: 2/2, step 1175/7134 completed (loss: 0.032494381070137024, acc: 0.991304337978363)
[2024-12-17 02:34:07,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:07,323][root][INFO] - Training Epoch: 2/2, step 1176/7134 completed (loss: 0.011735866777598858, acc: 0.9982876777648926)
[2024-12-17 02:34:07,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:07,636][root][INFO] - Training Epoch: 2/2, step 1177/7134 completed (loss: 0.016560878604650497, acc: 0.9941176176071167)
[2024-12-17 02:34:07,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:07,909][root][INFO] - Training Epoch: 2/2, step 1178/7134 completed (loss: 0.030199551954865456, acc: 0.9906542301177979)
[2024-12-17 02:34:07,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:08,238][root][INFO] - Training Epoch: 2/2, step 1179/7134 completed (loss: 0.0418192557990551, acc: 0.990439772605896)
[2024-12-17 02:34:08,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:08,596][root][INFO] - Training Epoch: 2/2, step 1180/7134 completed (loss: 0.01983577013015747, acc: 0.9945255517959595)
[2024-12-17 02:34:08,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:08,937][root][INFO] - Training Epoch: 2/2, step 1181/7134 completed (loss: 0.04139326885342598, acc: 0.9884892106056213)
[2024-12-17 02:34:09,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:09,263][root][INFO] - Training Epoch: 2/2, step 1182/7134 completed (loss: 0.01800672709941864, acc: 0.9965811967849731)
[2024-12-17 02:34:09,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:09,613][root][INFO] - Training Epoch: 2/2, step 1183/7134 completed (loss: 0.0178767628967762, acc: 0.9955947399139404)
[2024-12-17 02:34:09,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:09,947][root][INFO] - Training Epoch: 2/2, step 1184/7134 completed (loss: 0.06930641084909439, acc: 0.9871244430541992)
[2024-12-17 02:34:10,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:10,280][root][INFO] - Training Epoch: 2/2, step 1185/7134 completed (loss: 0.02437448687851429, acc: 0.9924812316894531)
[2024-12-17 02:34:10,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:10,616][root][INFO] - Training Epoch: 2/2, step 1186/7134 completed (loss: 0.0324980691075325, acc: 0.9961089491844177)
[2024-12-17 02:34:10,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:10,952][root][INFO] - Training Epoch: 2/2, step 1187/7134 completed (loss: 0.033756598830223083, acc: 0.9930747747421265)
[2024-12-17 02:34:11,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:11,307][root][INFO] - Training Epoch: 2/2, step 1188/7134 completed (loss: 0.02872871235013008, acc: 0.9934036731719971)
[2024-12-17 02:34:11,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:11,642][root][INFO] - Training Epoch: 2/2, step 1189/7134 completed (loss: 0.018341490998864174, acc: 0.9971098303794861)
[2024-12-17 02:34:11,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:11,965][root][INFO] - Training Epoch: 2/2, step 1190/7134 completed (loss: 0.022216562181711197, acc: 0.9923664331436157)
[2024-12-17 02:34:12,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:12,308][root][INFO] - Training Epoch: 2/2, step 1191/7134 completed (loss: 0.06337834149599075, acc: 0.9837518334388733)
[2024-12-17 02:34:12,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:12,654][root][INFO] - Training Epoch: 2/2, step 1192/7134 completed (loss: 0.029434548690915108, acc: 0.9921362996101379)
[2024-12-17 02:34:12,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:12,991][root][INFO] - Training Epoch: 2/2, step 1193/7134 completed (loss: 0.057223957031965256, acc: 0.9920254945755005)
[2024-12-17 02:34:13,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:13,322][root][INFO] - Training Epoch: 2/2, step 1194/7134 completed (loss: 0.05303044244647026, acc: 0.9876373410224915)
[2024-12-17 02:34:13,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:13,658][root][INFO] - Training Epoch: 2/2, step 1195/7134 completed (loss: 0.05579207465052605, acc: 0.9852941036224365)
[2024-12-17 02:34:13,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:14,006][root][INFO] - Training Epoch: 2/2, step 1196/7134 completed (loss: 0.07557515054941177, acc: 0.9819672107696533)
[2024-12-17 02:34:14,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:14,326][root][INFO] - Training Epoch: 2/2, step 1197/7134 completed (loss: 0.04947017878293991, acc: 0.9838709831237793)
[2024-12-17 02:34:14,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:14,656][root][INFO] - Training Epoch: 2/2, step 1198/7134 completed (loss: 0.05052380636334419, acc: 0.9870503544807434)
[2024-12-17 02:34:14,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:15,022][root][INFO] - Training Epoch: 2/2, step 1199/7134 completed (loss: 0.023345189169049263, acc: 0.9926362037658691)
[2024-12-17 02:34:15,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:15,352][root][INFO] - Training Epoch: 2/2, step 1200/7134 completed (loss: 0.03230955824255943, acc: 0.9917864203453064)
[2024-12-17 02:34:15,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:15,704][root][INFO] - Training Epoch: 2/2, step 1201/7134 completed (loss: 0.04663965106010437, acc: 0.9882179498672485)
[2024-12-17 02:34:15,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:16,064][root][INFO] - Training Epoch: 2/2, step 1202/7134 completed (loss: 0.061890263110399246, acc: 0.982503354549408)
[2024-12-17 02:34:16,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:16,377][root][INFO] - Training Epoch: 2/2, step 1203/7134 completed (loss: 0.014061836525797844, acc: 0.9969651103019714)
[2024-12-17 02:34:16,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:16,692][root][INFO] - Training Epoch: 2/2, step 1204/7134 completed (loss: 0.048716455698013306, acc: 0.9850746393203735)
[2024-12-17 02:34:16,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:17,035][root][INFO] - Training Epoch: 2/2, step 1205/7134 completed (loss: 0.08432813733816147, acc: 0.9816901683807373)
[2024-12-17 02:34:17,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:17,390][root][INFO] - Training Epoch: 2/2, step 1206/7134 completed (loss: 0.03771524876356125, acc: 0.9925558567047119)
[2024-12-17 02:34:17,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:17,744][root][INFO] - Training Epoch: 2/2, step 1207/7134 completed (loss: 0.07134761661291122, acc: 0.9886934757232666)
[2024-12-17 02:34:17,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:18,076][root][INFO] - Training Epoch: 2/2, step 1208/7134 completed (loss: 0.0548255518078804, acc: 0.983208954334259)
[2024-12-17 02:34:18,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:18,405][root][INFO] - Training Epoch: 2/2, step 1209/7134 completed (loss: 0.11322954297065735, acc: 0.9652650952339172)
[2024-12-17 02:34:18,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:18,736][root][INFO] - Training Epoch: 2/2, step 1210/7134 completed (loss: 0.07618298381567001, acc: 0.9824561476707458)
[2024-12-17 02:34:18,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:19,065][root][INFO] - Training Epoch: 2/2, step 1211/7134 completed (loss: 0.16517578065395355, acc: 0.9537572264671326)
[2024-12-17 02:34:19,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:19,389][root][INFO] - Training Epoch: 2/2, step 1212/7134 completed (loss: 0.08095789700746536, acc: 0.9786585569381714)
[2024-12-17 02:34:19,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:19,735][root][INFO] - Training Epoch: 2/2, step 1213/7134 completed (loss: 0.03645232319831848, acc: 0.9915134310722351)
[2024-12-17 02:34:19,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:20,057][root][INFO] - Training Epoch: 2/2, step 1214/7134 completed (loss: 0.08766996115446091, acc: 0.9707692265510559)
[2024-12-17 02:34:20,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:20,402][root][INFO] - Training Epoch: 2/2, step 1215/7134 completed (loss: 0.08572721481323242, acc: 0.9765517115592957)
[2024-12-17 02:34:20,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:20,742][root][INFO] - Training Epoch: 2/2, step 1216/7134 completed (loss: 0.0474298857152462, acc: 0.9897810220718384)
[2024-12-17 02:34:20,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:21,097][root][INFO] - Training Epoch: 2/2, step 1217/7134 completed (loss: 0.07034066319465637, acc: 0.9853895902633667)
[2024-12-17 02:34:21,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:21,458][root][INFO] - Training Epoch: 2/2, step 1218/7134 completed (loss: 0.12128011137247086, acc: 0.9746268391609192)
[2024-12-17 02:34:21,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:21,818][root][INFO] - Training Epoch: 2/2, step 1219/7134 completed (loss: 0.1256106197834015, acc: 0.9753954410552979)
[2024-12-17 02:34:21,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:22,176][root][INFO] - Training Epoch: 2/2, step 1220/7134 completed (loss: 0.11509181559085846, acc: 0.9695431590080261)
[2024-12-17 02:34:22,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:22,556][root][INFO] - Training Epoch: 2/2, step 1221/7134 completed (loss: 0.12524469196796417, acc: 0.9649122953414917)
[2024-12-17 02:34:22,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:22,906][root][INFO] - Training Epoch: 2/2, step 1222/7134 completed (loss: 0.08763483911752701, acc: 0.9761620759963989)
[2024-12-17 02:34:22,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:23,255][root][INFO] - Training Epoch: 2/2, step 1223/7134 completed (loss: 0.2136915922164917, acc: 0.9492455124855042)
[2024-12-17 02:34:23,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:23,616][root][INFO] - Training Epoch: 2/2, step 1224/7134 completed (loss: 0.09629376232624054, acc: 0.9779249429702759)
[2024-12-17 02:34:23,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:23,976][root][INFO] - Training Epoch: 2/2, step 1225/7134 completed (loss: 0.087957464158535, acc: 0.9727582335472107)
[2024-12-17 02:34:24,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:24,320][root][INFO] - Training Epoch: 2/2, step 1226/7134 completed (loss: 0.14308933913707733, acc: 0.9617705941200256)
[2024-12-17 02:34:24,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:24,667][root][INFO] - Training Epoch: 2/2, step 1227/7134 completed (loss: 0.16654662787914276, acc: 0.9517426490783691)
[2024-12-17 02:34:24,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:25,011][root][INFO] - Training Epoch: 2/2, step 1228/7134 completed (loss: 0.13518653810024261, acc: 0.9728183150291443)
[2024-12-17 02:34:25,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:25,360][root][INFO] - Training Epoch: 2/2, step 1229/7134 completed (loss: 0.07431492954492569, acc: 0.981992781162262)
[2024-12-17 02:34:25,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:25,730][root][INFO] - Training Epoch: 2/2, step 1230/7134 completed (loss: 0.11008473485708237, acc: 0.9728813767433167)
[2024-12-17 02:34:25,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:26,121][root][INFO] - Training Epoch: 2/2, step 1231/7134 completed (loss: 0.0918908417224884, acc: 0.9803516268730164)
[2024-12-17 02:34:26,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:26,501][root][INFO] - Training Epoch: 2/2, step 1232/7134 completed (loss: 0.09980487823486328, acc: 0.9765708446502686)
[2024-12-17 02:34:26,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:26,865][root][INFO] - Training Epoch: 2/2, step 1233/7134 completed (loss: 0.15834662318229675, acc: 0.9641618728637695)
[2024-12-17 02:34:26,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:27,224][root][INFO] - Training Epoch: 2/2, step 1234/7134 completed (loss: 0.047775447368621826, acc: 0.9922360181808472)
[2024-12-17 02:34:27,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:27,589][root][INFO] - Training Epoch: 2/2, step 1235/7134 completed (loss: 0.09374602138996124, acc: 0.9796162843704224)
[2024-12-17 02:34:27,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:27,952][root][INFO] - Training Epoch: 2/2, step 1236/7134 completed (loss: 0.18690966069698334, acc: 0.9590044021606445)
[2024-12-17 02:34:28,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:28,306][root][INFO] - Training Epoch: 2/2, step 1237/7134 completed (loss: 0.10033117234706879, acc: 0.9689440727233887)
[2024-12-17 02:34:28,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:28,657][root][INFO] - Training Epoch: 2/2, step 1238/7134 completed (loss: 0.1574130654335022, acc: 0.9519650936126709)
[2024-12-17 02:34:28,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:29,055][root][INFO] - Training Epoch: 2/2, step 1239/7134 completed (loss: 0.12253351509571075, acc: 0.9613733887672424)
[2024-12-17 02:34:29,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:29,416][root][INFO] - Training Epoch: 2/2, step 1240/7134 completed (loss: 0.10404378175735474, acc: 0.9656084775924683)
[2024-12-17 02:34:29,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:29,685][root][INFO] - Training Epoch: 2/2, step 1241/7134 completed (loss: 0.13182227313518524, acc: 0.9678714871406555)
[2024-12-17 02:34:29,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:30,047][root][INFO] - Training Epoch: 2/2, step 1242/7134 completed (loss: 0.0829467624425888, acc: 0.9783653616905212)
[2024-12-17 02:34:30,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:30,417][root][INFO] - Training Epoch: 2/2, step 1243/7134 completed (loss: 0.0913189947605133, acc: 0.98221755027771)
[2024-12-17 02:34:30,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:30,765][root][INFO] - Training Epoch: 2/2, step 1244/7134 completed (loss: 0.11679846048355103, acc: 0.9784768223762512)
[2024-12-17 02:34:30,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:31,133][root][INFO] - Training Epoch: 2/2, step 1245/7134 completed (loss: 0.10633868724107742, acc: 0.9722921848297119)
[2024-12-17 02:34:31,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:31,473][root][INFO] - Training Epoch: 2/2, step 1246/7134 completed (loss: 0.13479049503803253, acc: 0.9679075479507446)
[2024-12-17 02:34:31,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:31,822][root][INFO] - Training Epoch: 2/2, step 1247/7134 completed (loss: 0.058923717588186264, acc: 0.9826338887214661)
[2024-12-17 02:34:31,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:32,155][root][INFO] - Training Epoch: 2/2, step 1248/7134 completed (loss: 0.09270484000444412, acc: 0.9771167039871216)
[2024-12-17 02:34:32,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:32,483][root][INFO] - Training Epoch: 2/2, step 1249/7134 completed (loss: 0.03702911362051964, acc: 0.9875444769859314)
[2024-12-17 02:34:32,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:32,808][root][INFO] - Training Epoch: 2/2, step 1250/7134 completed (loss: 0.032690759748220444, acc: 0.9900850057601929)
[2024-12-17 02:34:32,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:33,142][root][INFO] - Training Epoch: 2/2, step 1251/7134 completed (loss: 0.028482887893915176, acc: 0.9931412935256958)
[2024-12-17 02:34:33,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:33,475][root][INFO] - Training Epoch: 2/2, step 1252/7134 completed (loss: 0.039222389459609985, acc: 0.9922839403152466)
[2024-12-17 02:34:33,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:33,808][root][INFO] - Training Epoch: 2/2, step 1253/7134 completed (loss: 0.0630049780011177, acc: 0.9864864945411682)
[2024-12-17 02:34:33,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:34,145][root][INFO] - Training Epoch: 2/2, step 1254/7134 completed (loss: 0.08622008562088013, acc: 0.9772727489471436)
[2024-12-17 02:34:34,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:34,470][root][INFO] - Training Epoch: 2/2, step 1255/7134 completed (loss: 0.05743620544672012, acc: 0.9868804812431335)
[2024-12-17 02:34:34,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:34,780][root][INFO] - Training Epoch: 2/2, step 1256/7134 completed (loss: 0.04412606731057167, acc: 0.9871382713317871)
[2024-12-17 02:34:34,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:35,113][root][INFO] - Training Epoch: 2/2, step 1257/7134 completed (loss: 0.02592405118048191, acc: 0.993537962436676)
[2024-12-17 02:34:35,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:35,448][root][INFO] - Training Epoch: 2/2, step 1258/7134 completed (loss: 0.08637735247612, acc: 0.9751098155975342)
[2024-12-17 02:34:35,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:35,760][root][INFO] - Training Epoch: 2/2, step 1259/7134 completed (loss: 0.07938947528600693, acc: 0.9892703890800476)
[2024-12-17 02:34:35,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:36,096][root][INFO] - Training Epoch: 2/2, step 1260/7134 completed (loss: 0.028528569266200066, acc: 0.9913294911384583)
[2024-12-17 02:34:36,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:36,443][root][INFO] - Training Epoch: 2/2, step 1261/7134 completed (loss: 0.043852467089891434, acc: 0.9866468906402588)
[2024-12-17 02:34:36,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:36,737][root][INFO] - Training Epoch: 2/2, step 1262/7134 completed (loss: 0.006705156061798334, acc: 0.9981684684753418)
[2024-12-17 02:34:36,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:37,055][root][INFO] - Training Epoch: 2/2, step 1263/7134 completed (loss: 0.03493686765432358, acc: 0.9942857027053833)
[2024-12-17 02:34:37,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:37,392][root][INFO] - Training Epoch: 2/2, step 1264/7134 completed (loss: 0.043466418981552124, acc: 0.9875389337539673)
[2024-12-17 02:34:37,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:37,754][root][INFO] - Training Epoch: 2/2, step 1265/7134 completed (loss: 0.03365325555205345, acc: 0.9937343597412109)
[2024-12-17 02:34:37,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:38,089][root][INFO] - Training Epoch: 2/2, step 1266/7134 completed (loss: 0.03643837943673134, acc: 0.9931153059005737)
[2024-12-17 02:34:38,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:38,412][root][INFO] - Training Epoch: 2/2, step 1267/7134 completed (loss: 0.04067368432879448, acc: 0.9889655113220215)
[2024-12-17 02:34:38,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:38,759][root][INFO] - Training Epoch: 2/2, step 1268/7134 completed (loss: 0.04451404884457588, acc: 0.9911373853683472)
[2024-12-17 02:34:38,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:39,098][root][INFO] - Training Epoch: 2/2, step 1269/7134 completed (loss: 0.07552660256624222, acc: 0.9810344576835632)
[2024-12-17 02:34:39,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:39,436][root][INFO] - Training Epoch: 2/2, step 1270/7134 completed (loss: 0.04043678194284439, acc: 0.9888424277305603)
[2024-12-17 02:34:39,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:39,712][root][INFO] - Training Epoch: 2/2, step 1271/7134 completed (loss: 0.0845671221613884, acc: 0.9814814925193787)
[2024-12-17 02:34:39,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:40,068][root][INFO] - Training Epoch: 2/2, step 1272/7134 completed (loss: 0.03414548560976982, acc: 0.9933949708938599)
[2024-12-17 02:34:40,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:40,395][root][INFO] - Training Epoch: 2/2, step 1273/7134 completed (loss: 0.0294918492436409, acc: 0.9919354915618896)
[2024-12-17 02:34:40,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:40,722][root][INFO] - Training Epoch: 2/2, step 1274/7134 completed (loss: 0.03744658827781677, acc: 0.9881756901741028)
[2024-12-17 02:34:40,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:41,051][root][INFO] - Training Epoch: 2/2, step 1275/7134 completed (loss: 0.0366249717772007, acc: 0.9892280101776123)
[2024-12-17 02:34:41,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:41,367][root][INFO] - Training Epoch: 2/2, step 1276/7134 completed (loss: 0.025723909959197044, acc: 0.9903225898742676)
[2024-12-17 02:34:41,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:41,678][root][INFO] - Training Epoch: 2/2, step 1277/7134 completed (loss: 0.05620381608605385, acc: 0.9854604005813599)
[2024-12-17 02:34:41,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:42,025][root][INFO] - Training Epoch: 2/2, step 1278/7134 completed (loss: 0.051709551364183426, acc: 0.9860031008720398)
[2024-12-17 02:34:42,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:42,356][root][INFO] - Training Epoch: 2/2, step 1279/7134 completed (loss: 0.0567239373922348, acc: 0.9888337254524231)
[2024-12-17 02:34:42,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:42,684][root][INFO] - Training Epoch: 2/2, step 1280/7134 completed (loss: 0.05150632932782173, acc: 0.9868593811988831)
[2024-12-17 02:34:42,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:43,005][root][INFO] - Training Epoch: 2/2, step 1281/7134 completed (loss: 0.08099261671304703, acc: 0.977624773979187)
[2024-12-17 02:34:43,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:43,356][root][INFO] - Training Epoch: 2/2, step 1282/7134 completed (loss: 0.1327221542596817, acc: 0.9759358167648315)
[2024-12-17 02:34:43,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:43,715][root][INFO] - Training Epoch: 2/2, step 1283/7134 completed (loss: 0.11198597401380539, acc: 0.9771126508712769)
[2024-12-17 02:34:43,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:44,056][root][INFO] - Training Epoch: 2/2, step 1284/7134 completed (loss: 0.06599398702383041, acc: 0.9877384305000305)
[2024-12-17 02:34:44,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:44,370][root][INFO] - Training Epoch: 2/2, step 1285/7134 completed (loss: 0.09070811420679092, acc: 0.9826839566230774)
[2024-12-17 02:34:44,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:44,722][root][INFO] - Training Epoch: 2/2, step 1286/7134 completed (loss: 0.08240342885255814, acc: 0.9799714088439941)
[2024-12-17 02:34:44,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:45,028][root][INFO] - Training Epoch: 2/2, step 1287/7134 completed (loss: 0.11756126582622528, acc: 0.97508305311203)
[2024-12-17 02:34:45,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:45,349][root][INFO] - Training Epoch: 2/2, step 1288/7134 completed (loss: 0.05658078193664551, acc: 0.9873096346855164)
[2024-12-17 02:34:45,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:45,669][root][INFO] - Training Epoch: 2/2, step 1289/7134 completed (loss: 0.052850499749183655, acc: 0.9849246144294739)
[2024-12-17 02:34:45,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:46,006][root][INFO] - Training Epoch: 2/2, step 1290/7134 completed (loss: 0.07512607425451279, acc: 0.9802817106246948)
[2024-12-17 02:34:46,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:46,379][root][INFO] - Training Epoch: 2/2, step 1291/7134 completed (loss: 0.03752070292830467, acc: 0.9874476790428162)
[2024-12-17 02:34:46,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:46,716][root][INFO] - Training Epoch: 2/2, step 1292/7134 completed (loss: 0.05016562342643738, acc: 0.9870129823684692)
[2024-12-17 02:34:46,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:47,069][root][INFO] - Training Epoch: 2/2, step 1293/7134 completed (loss: 0.04170529916882515, acc: 0.99068683385849)
[2024-12-17 02:34:47,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:47,403][root][INFO] - Training Epoch: 2/2, step 1294/7134 completed (loss: 0.05324895679950714, acc: 0.9895969033241272)
[2024-12-17 02:34:47,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:47,754][root][INFO] - Training Epoch: 2/2, step 1295/7134 completed (loss: 0.05874664708971977, acc: 0.9847198724746704)
[2024-12-17 02:34:47,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:48,096][root][INFO] - Training Epoch: 2/2, step 1296/7134 completed (loss: 0.020965708419680595, acc: 0.9933628439903259)
[2024-12-17 02:34:48,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:48,382][root][INFO] - Training Epoch: 2/2, step 1297/7134 completed (loss: 0.06062687560915947, acc: 0.9833679795265198)
[2024-12-17 02:34:48,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:48,709][root][INFO] - Training Epoch: 2/2, step 1298/7134 completed (loss: 0.09441320598125458, acc: 0.9784172773361206)
[2024-12-17 02:34:48,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:48,965][root][INFO] - Training Epoch: 2/2, step 1299/7134 completed (loss: 0.04473155736923218, acc: 0.9869791865348816)
[2024-12-17 02:34:49,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:49,321][root][INFO] - Training Epoch: 2/2, step 1300/7134 completed (loss: 0.04519391804933548, acc: 0.9878197312355042)
[2024-12-17 02:34:49,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:49,646][root][INFO] - Training Epoch: 2/2, step 1301/7134 completed (loss: 0.02677987329661846, acc: 0.9881305694580078)
[2024-12-17 02:34:49,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:50,001][root][INFO] - Training Epoch: 2/2, step 1302/7134 completed (loss: 0.07526957988739014, acc: 0.984375)
[2024-12-17 02:34:50,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:50,359][root][INFO] - Training Epoch: 2/2, step 1303/7134 completed (loss: 0.0692451149225235, acc: 0.9855769276618958)
[2024-12-17 02:34:50,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:50,691][root][INFO] - Training Epoch: 2/2, step 1304/7134 completed (loss: 0.1176261380314827, acc: 0.9749670624732971)
[2024-12-17 02:34:50,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:51,047][root][INFO] - Training Epoch: 2/2, step 1305/7134 completed (loss: 0.05324827507138252, acc: 0.9873096346855164)
[2024-12-17 02:34:51,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:51,416][root][INFO] - Training Epoch: 2/2, step 1306/7134 completed (loss: 0.11758164316415787, acc: 0.9757207632064819)
[2024-12-17 02:34:51,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:51,740][root][INFO] - Training Epoch: 2/2, step 1307/7134 completed (loss: 0.04240426793694496, acc: 0.9889415502548218)
[2024-12-17 02:34:51,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:52,081][root][INFO] - Training Epoch: 2/2, step 1308/7134 completed (loss: 0.035984717309474945, acc: 0.9849624037742615)
[2024-12-17 02:34:52,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:52,439][root][INFO] - Training Epoch: 2/2, step 1309/7134 completed (loss: 0.06549438834190369, acc: 0.9856459498405457)
[2024-12-17 02:34:52,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:52,801][root][INFO] - Training Epoch: 2/2, step 1310/7134 completed (loss: 0.06654252111911774, acc: 0.9809523820877075)
[2024-12-17 02:34:52,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:53,141][root][INFO] - Training Epoch: 2/2, step 1311/7134 completed (loss: 0.06953511387109756, acc: 0.9819004535675049)
[2024-12-17 02:34:53,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:53,496][root][INFO] - Training Epoch: 2/2, step 1312/7134 completed (loss: 0.10553927719593048, acc: 0.9811320900917053)
[2024-12-17 02:34:53,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:53,851][root][INFO] - Training Epoch: 2/2, step 1313/7134 completed (loss: 0.0869869813323021, acc: 0.9787535667419434)
[2024-12-17 02:34:53,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:54,175][root][INFO] - Training Epoch: 2/2, step 1314/7134 completed (loss: 0.050030022859573364, acc: 0.9842105507850647)
[2024-12-17 02:34:54,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:54,514][root][INFO] - Training Epoch: 2/2, step 1315/7134 completed (loss: 0.19090722501277924, acc: 0.9613333344459534)
[2024-12-17 02:34:54,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:54,866][root][INFO] - Training Epoch: 2/2, step 1316/7134 completed (loss: 0.04497939720749855, acc: 0.9849340915679932)
[2024-12-17 02:34:54,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:55,124][root][INFO] - Training Epoch: 2/2, step 1317/7134 completed (loss: 0.13548950850963593, acc: 0.9593495726585388)
[2024-12-17 02:34:55,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:55,458][root][INFO] - Training Epoch: 2/2, step 1318/7134 completed (loss: 0.06798999756574631, acc: 0.9836512207984924)
[2024-12-17 02:34:55,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:55,739][root][INFO] - Training Epoch: 2/2, step 1319/7134 completed (loss: 0.11519502848386765, acc: 0.9748283624649048)
[2024-12-17 02:34:55,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:56,057][root][INFO] - Training Epoch: 2/2, step 1320/7134 completed (loss: 0.11881069839000702, acc: 0.9723126888275146)
[2024-12-17 02:34:56,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:56,436][root][INFO] - Training Epoch: 2/2, step 1321/7134 completed (loss: 0.06053144484758377, acc: 0.9816176295280457)
[2024-12-17 02:34:56,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:56,775][root][INFO] - Training Epoch: 2/2, step 1322/7134 completed (loss: 0.07654077559709549, acc: 0.9754500985145569)
[2024-12-17 02:34:56,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:57,115][root][INFO] - Training Epoch: 2/2, step 1323/7134 completed (loss: 0.09993728250265121, acc: 0.9696428775787354)
[2024-12-17 02:34:57,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:57,452][root][INFO] - Training Epoch: 2/2, step 1324/7134 completed (loss: 0.050948839634656906, acc: 0.9851973652839661)
[2024-12-17 02:34:57,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:57,727][root][INFO] - Training Epoch: 2/2, step 1325/7134 completed (loss: 0.06556577980518341, acc: 0.9818593859672546)
[2024-12-17 02:34:57,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:58,088][root][INFO] - Training Epoch: 2/2, step 1326/7134 completed (loss: 0.10395181179046631, acc: 0.9758507013320923)
[2024-12-17 02:34:58,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:58,435][root][INFO] - Training Epoch: 2/2, step 1327/7134 completed (loss: 0.07530185580253601, acc: 0.9745127558708191)
[2024-12-17 02:34:58,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:58,788][root][INFO] - Training Epoch: 2/2, step 1328/7134 completed (loss: 0.091107577085495, acc: 0.9790697693824768)
[2024-12-17 02:34:58,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:59,130][root][INFO] - Training Epoch: 2/2, step 1329/7134 completed (loss: 0.09060660749673843, acc: 0.9779005646705627)
[2024-12-17 02:34:59,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:59,421][root][INFO] - Training Epoch: 2/2, step 1330/7134 completed (loss: 0.05408928915858269, acc: 0.9862778782844543)
[2024-12-17 02:34:59,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:59,774][root][INFO] - Training Epoch: 2/2, step 1331/7134 completed (loss: 0.017142977565526962, acc: 0.9934853315353394)
[2024-12-17 02:34:59,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:00,014][root][INFO] - Training Epoch: 2/2, step 1332/7134 completed (loss: 0.027758188545703888, acc: 0.9912663698196411)
[2024-12-17 02:35:00,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:00,372][root][INFO] - Training Epoch: 2/2, step 1333/7134 completed (loss: 0.04836947098374367, acc: 0.9846938848495483)
[2024-12-17 02:35:00,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:00,728][root][INFO] - Training Epoch: 2/2, step 1334/7134 completed (loss: 0.12611013650894165, acc: 0.9751552939414978)
[2024-12-17 02:35:00,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:01,046][root][INFO] - Training Epoch: 2/2, step 1335/7134 completed (loss: 0.13331922888755798, acc: 0.9760319590568542)
[2024-12-17 02:35:01,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:01,401][root][INFO] - Training Epoch: 2/2, step 1336/7134 completed (loss: 0.038292281329631805, acc: 0.9905277490615845)
[2024-12-17 02:35:01,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:01,763][root][INFO] - Training Epoch: 2/2, step 1337/7134 completed (loss: 0.054383788257837296, acc: 0.9892638325691223)
[2024-12-17 02:35:01,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:01,999][root][INFO] - Training Epoch: 2/2, step 1338/7134 completed (loss: 0.09549640864133835, acc: 0.9638554453849792)
[2024-12-17 02:35:02,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:02,288][root][INFO] - Training Epoch: 2/2, step 1339/7134 completed (loss: 0.09094086289405823, acc: 0.9719101190567017)
[2024-12-17 02:35:02,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:02,607][root][INFO] - Training Epoch: 2/2, step 1340/7134 completed (loss: 0.09047527611255646, acc: 0.9731743931770325)
[2024-12-17 02:35:02,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:02,870][root][INFO] - Training Epoch: 2/2, step 1341/7134 completed (loss: 0.10101810842752457, acc: 0.9802259802818298)
[2024-12-17 02:35:02,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:03,191][root][INFO] - Training Epoch: 2/2, step 1342/7134 completed (loss: 0.0318179577589035, acc: 0.9919484853744507)
[2024-12-17 02:35:03,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:03,544][root][INFO] - Training Epoch: 2/2, step 1343/7134 completed (loss: 0.10477810353040695, acc: 0.980322003364563)
[2024-12-17 02:35:03,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:03,842][root][INFO] - Training Epoch: 2/2, step 1344/7134 completed (loss: 0.04039962962269783, acc: 0.9909502267837524)
[2024-12-17 02:35:03,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:04,056][root][INFO] - Training Epoch: 2/2, step 1345/7134 completed (loss: 0.04053138568997383, acc: 0.9840849041938782)
[2024-12-17 02:35:04,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:04,421][root][INFO] - Training Epoch: 2/2, step 1346/7134 completed (loss: 0.07857160270214081, acc: 0.9839786291122437)
[2024-12-17 02:35:04,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:04,744][root][INFO] - Training Epoch: 2/2, step 1347/7134 completed (loss: 0.0936906561255455, acc: 0.9808362126350403)
[2024-12-17 02:35:04,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:05,083][root][INFO] - Training Epoch: 2/2, step 1348/7134 completed (loss: 0.03709371015429497, acc: 0.9921362996101379)
[2024-12-17 02:35:05,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:05,426][root][INFO] - Training Epoch: 2/2, step 1349/7134 completed (loss: 0.04288666322827339, acc: 0.9931623935699463)
[2024-12-17 02:35:05,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:05,765][root][INFO] - Training Epoch: 2/2, step 1350/7134 completed (loss: 0.054254788905382156, acc: 0.9884225726127625)
[2024-12-17 02:35:05,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:06,075][root][INFO] - Training Epoch: 2/2, step 1351/7134 completed (loss: 0.03165366128087044, acc: 0.9921414256095886)
[2024-12-17 02:35:06,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:06,391][root][INFO] - Training Epoch: 2/2, step 1352/7134 completed (loss: 0.05019911006093025, acc: 0.9895833134651184)
[2024-12-17 02:35:06,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:06,699][root][INFO] - Training Epoch: 2/2, step 1353/7134 completed (loss: 0.08259110152721405, acc: 0.984674334526062)
[2024-12-17 02:35:06,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:07,035][root][INFO] - Training Epoch: 2/2, step 1354/7134 completed (loss: 0.01864573545753956, acc: 0.9935170412063599)
[2024-12-17 02:35:07,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:07,349][root][INFO] - Training Epoch: 2/2, step 1355/7134 completed (loss: 0.01886865496635437, acc: 0.9953271150588989)
[2024-12-17 02:35:07,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:07,714][root][INFO] - Training Epoch: 2/2, step 1356/7134 completed (loss: 0.027615780010819435, acc: 0.9947368502616882)
[2024-12-17 02:35:07,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:08,056][root][INFO] - Training Epoch: 2/2, step 1357/7134 completed (loss: 0.010010017082095146, acc: 0.9974779486656189)
[2024-12-17 02:35:08,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:08,428][root][INFO] - Training Epoch: 2/2, step 1358/7134 completed (loss: 0.03765737637877464, acc: 0.9896103739738464)
[2024-12-17 02:35:08,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:08,755][root][INFO] - Training Epoch: 2/2, step 1359/7134 completed (loss: 0.02204509824514389, acc: 0.9939271211624146)
[2024-12-17 02:35:08,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:09,083][root][INFO] - Training Epoch: 2/2, step 1360/7134 completed (loss: 0.012927771545946598, acc: 0.9959677457809448)
[2024-12-17 02:35:09,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:09,439][root][INFO] - Training Epoch: 2/2, step 1361/7134 completed (loss: 0.028112336993217468, acc: 0.9927007555961609)
[2024-12-17 02:35:09,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:09,773][root][INFO] - Training Epoch: 2/2, step 1362/7134 completed (loss: 0.027216697111725807, acc: 0.9904371500015259)
[2024-12-17 02:35:09,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:10,116][root][INFO] - Training Epoch: 2/2, step 1363/7134 completed (loss: 0.032972197979688644, acc: 0.9932975769042969)
[2024-12-17 02:35:10,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:10,457][root][INFO] - Training Epoch: 2/2, step 1364/7134 completed (loss: 0.015930945053696632, acc: 0.9957143068313599)
[2024-12-17 02:35:10,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:10,776][root][INFO] - Training Epoch: 2/2, step 1365/7134 completed (loss: 0.009282189421355724, acc: 1.0)
[2024-12-17 02:35:10,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:11,123][root][INFO] - Training Epoch: 2/2, step 1366/7134 completed (loss: 0.00822377484291792, acc: 0.9982143044471741)
[2024-12-17 02:35:11,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:11,448][root][INFO] - Training Epoch: 2/2, step 1367/7134 completed (loss: 0.016472384333610535, acc: 0.9948275685310364)
[2024-12-17 02:35:11,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:11,801][root][INFO] - Training Epoch: 2/2, step 1368/7134 completed (loss: 0.0365775004029274, acc: 0.9893292784690857)
[2024-12-17 02:35:11,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:12,127][root][INFO] - Training Epoch: 2/2, step 1369/7134 completed (loss: 0.050061240792274475, acc: 0.9912434220314026)
[2024-12-17 02:35:12,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:12,462][root][INFO] - Training Epoch: 2/2, step 1370/7134 completed (loss: 0.05921861156821251, acc: 0.991150438785553)
[2024-12-17 02:35:12,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:12,813][root][INFO] - Training Epoch: 2/2, step 1371/7134 completed (loss: 0.039482489228248596, acc: 0.9898107647895813)
[2024-12-17 02:35:12,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:13,141][root][INFO] - Training Epoch: 2/2, step 1372/7134 completed (loss: 0.10544037073850632, acc: 0.9756554365158081)
[2024-12-17 02:35:13,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:13,489][root][INFO] - Training Epoch: 2/2, step 1373/7134 completed (loss: 0.038509950041770935, acc: 0.9881889820098877)
[2024-12-17 02:35:13,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:13,830][root][INFO] - Training Epoch: 2/2, step 1374/7134 completed (loss: 0.03519127145409584, acc: 0.9881188273429871)
[2024-12-17 02:35:13,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:14,125][root][INFO] - Training Epoch: 2/2, step 1375/7134 completed (loss: 0.04863743484020233, acc: 0.9807692170143127)
[2024-12-17 02:35:14,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:14,450][root][INFO] - Training Epoch: 2/2, step 1376/7134 completed (loss: 0.06690647453069687, acc: 0.9707724452018738)
[2024-12-17 02:35:14,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:14,788][root][INFO] - Training Epoch: 2/2, step 1377/7134 completed (loss: 0.02923537604510784, acc: 0.9929412007331848)
[2024-12-17 02:35:14,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:15,070][root][INFO] - Training Epoch: 2/2, step 1378/7134 completed (loss: 0.07472346723079681, acc: 0.9785575270652771)
[2024-12-17 02:35:15,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:15,356][root][INFO] - Training Epoch: 2/2, step 1379/7134 completed (loss: 0.06406703591346741, acc: 0.9827957153320312)
[2024-12-17 02:35:15,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:15,691][root][INFO] - Training Epoch: 2/2, step 1380/7134 completed (loss: 0.05231507495045662, acc: 0.9813084006309509)
[2024-12-17 02:35:15,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:16,024][root][INFO] - Training Epoch: 2/2, step 1381/7134 completed (loss: 0.05643397197127342, acc: 0.9850746393203735)
[2024-12-17 02:35:16,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:16,352][root][INFO] - Training Epoch: 2/2, step 1382/7134 completed (loss: 0.061224136501550674, acc: 0.976190447807312)
[2024-12-17 02:35:16,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:16,698][root][INFO] - Training Epoch: 2/2, step 1383/7134 completed (loss: 0.03444449231028557, acc: 0.9896729588508606)
[2024-12-17 02:35:16,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:17,026][root][INFO] - Training Epoch: 2/2, step 1384/7134 completed (loss: 0.11444048583507538, acc: 0.960066556930542)
[2024-12-17 02:35:17,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:17,360][root][INFO] - Training Epoch: 2/2, step 1385/7134 completed (loss: 0.09727746993303299, acc: 0.9724770784378052)
[2024-12-17 02:35:17,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:17,698][root][INFO] - Training Epoch: 2/2, step 1386/7134 completed (loss: 0.038989730179309845, acc: 0.9896755218505859)
[2024-12-17 02:35:17,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:18,033][root][INFO] - Training Epoch: 2/2, step 1387/7134 completed (loss: 0.06908900290727615, acc: 0.9813753366470337)
[2024-12-17 02:35:18,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:18,358][root][INFO] - Training Epoch: 2/2, step 1388/7134 completed (loss: 0.05839873105287552, acc: 0.9795570969581604)
[2024-12-17 02:35:18,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:18,688][root][INFO] - Training Epoch: 2/2, step 1389/7134 completed (loss: 0.05272205173969269, acc: 0.9854133129119873)
[2024-12-17 02:35:18,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:19,021][root][INFO] - Training Epoch: 2/2, step 1390/7134 completed (loss: 0.05669371038675308, acc: 0.9828392863273621)
[2024-12-17 02:35:19,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:19,341][root][INFO] - Training Epoch: 2/2, step 1391/7134 completed (loss: 0.09975770860910416, acc: 0.9753954410552979)
[2024-12-17 02:35:19,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:19,676][root][INFO] - Training Epoch: 2/2, step 1392/7134 completed (loss: 0.051653116941452026, acc: 0.9844290614128113)
[2024-12-17 02:35:19,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:19,999][root][INFO] - Training Epoch: 2/2, step 1393/7134 completed (loss: 0.03587818518280983, acc: 0.9884792566299438)
[2024-12-17 02:35:20,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:20,320][root][INFO] - Training Epoch: 2/2, step 1394/7134 completed (loss: 0.03708714619278908, acc: 0.988095223903656)
[2024-12-17 02:35:20,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:20,616][root][INFO] - Training Epoch: 2/2, step 1395/7134 completed (loss: 0.06660134345293045, acc: 0.9842209219932556)
[2024-12-17 02:35:20,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:20,936][root][INFO] - Training Epoch: 2/2, step 1396/7134 completed (loss: 0.04981273412704468, acc: 0.9847972989082336)
[2024-12-17 02:35:21,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:21,260][root][INFO] - Training Epoch: 2/2, step 1397/7134 completed (loss: 0.08505352586507797, acc: 0.9679595232009888)
[2024-12-17 02:35:21,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:21,572][root][INFO] - Training Epoch: 2/2, step 1398/7134 completed (loss: 0.06353884935379028, acc: 0.9878296256065369)
[2024-12-17 02:35:21,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:21,903][root][INFO] - Training Epoch: 2/2, step 1399/7134 completed (loss: 0.09664253890514374, acc: 0.9746376872062683)
[2024-12-17 02:35:22,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:22,243][root][INFO] - Training Epoch: 2/2, step 1400/7134 completed (loss: 0.04382128641009331, acc: 0.9842932224273682)
[2024-12-17 02:35:22,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:22,582][root][INFO] - Training Epoch: 2/2, step 1401/7134 completed (loss: 0.06188519299030304, acc: 0.9785832166671753)
[2024-12-17 02:35:22,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:22,933][root][INFO] - Training Epoch: 2/2, step 1402/7134 completed (loss: 0.025809798389673233, acc: 0.9948186278343201)
[2024-12-17 02:35:23,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:23,283][root][INFO] - Training Epoch: 2/2, step 1403/7134 completed (loss: 0.04063821956515312, acc: 0.9866130948066711)
[2024-12-17 02:35:23,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:23,654][root][INFO] - Training Epoch: 2/2, step 1404/7134 completed (loss: 0.022013714537024498, acc: 0.9960212111473083)
[2024-12-17 02:35:23,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:23,984][root][INFO] - Training Epoch: 2/2, step 1405/7134 completed (loss: 0.03056858479976654, acc: 0.9886040091514587)
[2024-12-17 02:35:24,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:24,334][root][INFO] - Training Epoch: 2/2, step 1406/7134 completed (loss: 0.015210531651973724, acc: 0.9956896305084229)
[2024-12-17 02:35:24,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:24,661][root][INFO] - Training Epoch: 2/2, step 1407/7134 completed (loss: 0.02664947509765625, acc: 0.9934810996055603)
[2024-12-17 02:35:24,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:25,005][root][INFO] - Training Epoch: 2/2, step 1408/7134 completed (loss: 0.04059880971908569, acc: 0.9887820482254028)
[2024-12-17 02:35:25,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:25,347][root][INFO] - Training Epoch: 2/2, step 1409/7134 completed (loss: 0.02126718871295452, acc: 0.9940387606620789)
[2024-12-17 02:35:25,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:25,700][root][INFO] - Training Epoch: 2/2, step 1410/7134 completed (loss: 0.04221271350979805, acc: 0.9895833134651184)
[2024-12-17 02:35:25,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:26,041][root][INFO] - Training Epoch: 2/2, step 1411/7134 completed (loss: 0.015035009011626244, acc: 0.9960106611251831)
[2024-12-17 02:35:26,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:26,406][root][INFO] - Training Epoch: 2/2, step 1412/7134 completed (loss: 0.012482424266636372, acc: 0.9964370727539062)
[2024-12-17 02:35:26,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:26,758][root][INFO] - Training Epoch: 2/2, step 1413/7134 completed (loss: 0.028262754902243614, acc: 0.9928057789802551)
[2024-12-17 02:35:26,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:27,100][root][INFO] - Training Epoch: 2/2, step 1414/7134 completed (loss: 0.01733839511871338, acc: 0.9953271150588989)
[2024-12-17 02:35:27,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:27,435][root][INFO] - Training Epoch: 2/2, step 1415/7134 completed (loss: 0.04194749891757965, acc: 0.9884105920791626)
[2024-12-17 02:35:27,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:27,801][root][INFO] - Training Epoch: 2/2, step 1416/7134 completed (loss: 0.018873639404773712, acc: 0.9957864880561829)
[2024-12-17 02:35:27,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:28,123][root][INFO] - Training Epoch: 2/2, step 1417/7134 completed (loss: 0.014467370696365833, acc: 0.9982993006706238)
[2024-12-17 02:35:28,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:28,425][root][INFO] - Training Epoch: 2/2, step 1418/7134 completed (loss: 0.01828766241669655, acc: 0.9961832165718079)
[2024-12-17 02:35:28,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:28,787][root][INFO] - Training Epoch: 2/2, step 1419/7134 completed (loss: 0.053690534085035324, acc: 0.9919028282165527)
[2024-12-17 02:35:28,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:29,128][root][INFO] - Training Epoch: 2/2, step 1420/7134 completed (loss: 0.026832539588212967, acc: 0.993261456489563)
[2024-12-17 02:35:29,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:29,469][root][INFO] - Training Epoch: 2/2, step 1421/7134 completed (loss: 0.029685603454709053, acc: 0.9919871687889099)
[2024-12-17 02:35:29,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:29,795][root][INFO] - Training Epoch: 2/2, step 1422/7134 completed (loss: 0.06458806991577148, acc: 0.9814814925193787)
[2024-12-17 02:35:29,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:30,109][root][INFO] - Training Epoch: 2/2, step 1423/7134 completed (loss: 0.058718107640743256, acc: 0.9857142567634583)
[2024-12-17 02:35:30,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:30,438][root][INFO] - Training Epoch: 2/2, step 1424/7134 completed (loss: 0.07030780613422394, acc: 0.9695817232131958)
[2024-12-17 02:35:30,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:30,779][root][INFO] - Training Epoch: 2/2, step 1425/7134 completed (loss: 0.03661751002073288, acc: 0.9850968718528748)
[2024-12-17 02:35:30,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:31,139][root][INFO] - Training Epoch: 2/2, step 1426/7134 completed (loss: 0.04716355353593826, acc: 0.9845758080482483)
[2024-12-17 02:35:31,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:31,499][root][INFO] - Training Epoch: 2/2, step 1427/7134 completed (loss: 0.06697404384613037, acc: 0.9821200370788574)
[2024-12-17 02:35:31,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:31,814][root][INFO] - Training Epoch: 2/2, step 1428/7134 completed (loss: 0.3257715702056885, acc: 0.9123867154121399)
[2024-12-17 02:35:31,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:32,165][root][INFO] - Training Epoch: 2/2, step 1429/7134 completed (loss: 0.040460407733917236, acc: 0.9896050095558167)
[2024-12-17 02:35:32,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:32,525][root][INFO] - Training Epoch: 2/2, step 1430/7134 completed (loss: 0.06434623152017593, acc: 0.9797047972679138)
[2024-12-17 02:35:32,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:32,856][root][INFO] - Training Epoch: 2/2, step 1431/7134 completed (loss: 0.027003901079297066, acc: 0.9905020594596863)
[2024-12-17 02:35:32,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:33,207][root][INFO] - Training Epoch: 2/2, step 1432/7134 completed (loss: 0.022064201533794403, acc: 0.9961389899253845)
[2024-12-17 02:35:33,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:33,553][root][INFO] - Training Epoch: 2/2, step 1433/7134 completed (loss: 0.05016515031456947, acc: 0.985602080821991)
[2024-12-17 02:35:33,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:33,885][root][INFO] - Training Epoch: 2/2, step 1434/7134 completed (loss: 0.0723135694861412, acc: 0.9799196720123291)
[2024-12-17 02:35:33,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:34,241][root][INFO] - Training Epoch: 2/2, step 1435/7134 completed (loss: 0.08245024085044861, acc: 0.973607063293457)
[2024-12-17 02:35:34,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:34,586][root][INFO] - Training Epoch: 2/2, step 1436/7134 completed (loss: 0.1181216835975647, acc: 0.9619289636611938)
[2024-12-17 02:35:34,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:34,910][root][INFO] - Training Epoch: 2/2, step 1437/7134 completed (loss: 0.053198158740997314, acc: 0.9805014133453369)
[2024-12-17 02:35:35,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:35,263][root][INFO] - Training Epoch: 2/2, step 1438/7134 completed (loss: 0.05617885664105415, acc: 0.9897810220718384)
[2024-12-17 02:35:35,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:35,613][root][INFO] - Training Epoch: 2/2, step 1439/7134 completed (loss: 0.04271825775504112, acc: 0.9833024144172668)
[2024-12-17 02:35:35,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:35,930][root][INFO] - Training Epoch: 2/2, step 1440/7134 completed (loss: 0.09234499931335449, acc: 0.9672977328300476)
[2024-12-17 02:35:36,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:36,300][root][INFO] - Training Epoch: 2/2, step 1441/7134 completed (loss: 0.042843688279390335, acc: 0.9853372573852539)
[2024-12-17 02:35:36,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:36,566][root][INFO] - Training Epoch: 2/2, step 1442/7134 completed (loss: 0.04868149757385254, acc: 0.9856459498405457)
[2024-12-17 02:35:36,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:36,899][root][INFO] - Training Epoch: 2/2, step 1443/7134 completed (loss: 0.09906995296478271, acc: 0.9771528840065002)
[2024-12-17 02:35:36,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:37,231][root][INFO] - Training Epoch: 2/2, step 1444/7134 completed (loss: 0.05201215669512749, acc: 0.9824903011322021)
[2024-12-17 02:35:37,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:37,587][root][INFO] - Training Epoch: 2/2, step 1445/7134 completed (loss: 0.08533523976802826, acc: 0.9833610653877258)
[2024-12-17 02:35:37,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:37,917][root][INFO] - Training Epoch: 2/2, step 1446/7134 completed (loss: 0.03874101862311363, acc: 0.9871976971626282)
[2024-12-17 02:35:38,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:38,248][root][INFO] - Training Epoch: 2/2, step 1447/7134 completed (loss: 0.0646013543009758, acc: 0.980141818523407)
[2024-12-17 02:35:38,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:38,543][root][INFO] - Training Epoch: 2/2, step 1448/7134 completed (loss: 0.07891705632209778, acc: 0.9766949415206909)
[2024-12-17 02:35:38,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:38,884][root][INFO] - Training Epoch: 2/2, step 1449/7134 completed (loss: 0.11237242817878723, acc: 0.9620786309242249)
[2024-12-17 02:35:38,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:39,196][root][INFO] - Training Epoch: 2/2, step 1450/7134 completed (loss: 0.03931866213679314, acc: 0.9854862093925476)
[2024-12-17 02:35:39,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:39,512][root][INFO] - Training Epoch: 2/2, step 1451/7134 completed (loss: 0.03326599672436714, acc: 0.9868228435516357)
[2024-12-17 02:35:39,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:39,839][root][INFO] - Training Epoch: 2/2, step 1452/7134 completed (loss: 0.0802038162946701, acc: 0.9878472089767456)
[2024-12-17 02:35:39,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:40,152][root][INFO] - Training Epoch: 2/2, step 1453/7134 completed (loss: 0.06694428622722626, acc: 0.9857369065284729)
[2024-12-17 02:35:40,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:40,505][root][INFO] - Training Epoch: 2/2, step 1454/7134 completed (loss: 0.11269498616456985, acc: 0.9717361927032471)
[2024-12-17 02:35:40,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:40,821][root][INFO] - Training Epoch: 2/2, step 1455/7134 completed (loss: 0.10419175028800964, acc: 0.9834862351417542)
[2024-12-17 02:35:40,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:41,128][root][INFO] - Training Epoch: 2/2, step 1456/7134 completed (loss: 0.027668781578540802, acc: 0.9934498071670532)
[2024-12-17 02:35:41,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:41,447][root][INFO] - Training Epoch: 2/2, step 1457/7134 completed (loss: 0.054310962557792664, acc: 0.9829457402229309)
[2024-12-17 02:35:41,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:41,772][root][INFO] - Training Epoch: 2/2, step 1458/7134 completed (loss: 0.0164193082600832, acc: 0.9970545172691345)
[2024-12-17 02:35:41,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:42,096][root][INFO] - Training Epoch: 2/2, step 1459/7134 completed (loss: 0.04256743937730789, acc: 0.9875665903091431)
[2024-12-17 02:35:42,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:42,439][root][INFO] - Training Epoch: 2/2, step 1460/7134 completed (loss: 0.08268287032842636, acc: 0.9776315689086914)
[2024-12-17 02:35:42,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:42,757][root][INFO] - Training Epoch: 2/2, step 1461/7134 completed (loss: 0.03996745124459267, acc: 0.9856459498405457)
[2024-12-17 02:35:42,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:43,094][root][INFO] - Training Epoch: 2/2, step 1462/7134 completed (loss: 0.11718616634607315, acc: 0.97817462682724)
[2024-12-17 02:35:43,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:43,425][root][INFO] - Training Epoch: 2/2, step 1463/7134 completed (loss: 0.1058957651257515, acc: 0.9721059799194336)
[2024-12-17 02:35:43,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:43,764][root][INFO] - Training Epoch: 2/2, step 1464/7134 completed (loss: 0.16022461652755737, acc: 0.9609609842300415)
[2024-12-17 02:35:43,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:44,101][root][INFO] - Training Epoch: 2/2, step 1465/7134 completed (loss: 0.07251761108636856, acc: 0.982758641242981)
[2024-12-17 02:35:44,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:44,447][root][INFO] - Training Epoch: 2/2, step 1466/7134 completed (loss: 0.03273214399814606, acc: 0.9957507252693176)
[2024-12-17 02:35:44,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:44,787][root][INFO] - Training Epoch: 2/2, step 1467/7134 completed (loss: 0.02013404294848442, acc: 0.9956772327423096)
[2024-12-17 02:35:44,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:45,136][root][INFO] - Training Epoch: 2/2, step 1468/7134 completed (loss: 0.03799166530370712, acc: 0.9894319772720337)
[2024-12-17 02:35:45,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:45,474][root][INFO] - Training Epoch: 2/2, step 1469/7134 completed (loss: 0.018987147137522697, acc: 0.9959623217582703)
[2024-12-17 02:35:45,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:45,792][root][INFO] - Training Epoch: 2/2, step 1470/7134 completed (loss: 0.057865094393491745, acc: 0.9855491518974304)
[2024-12-17 02:35:45,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:46,114][root][INFO] - Training Epoch: 2/2, step 1471/7134 completed (loss: 0.04524184390902519, acc: 0.9893428087234497)
[2024-12-17 02:35:46,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:46,462][root][INFO] - Training Epoch: 2/2, step 1472/7134 completed (loss: 0.03502998501062393, acc: 0.9849056601524353)
[2024-12-17 02:35:46,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:46,792][root][INFO] - Training Epoch: 2/2, step 1473/7134 completed (loss: 0.06517331302165985, acc: 0.9777448177337646)
[2024-12-17 02:35:46,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:47,108][root][INFO] - Training Epoch: 2/2, step 1474/7134 completed (loss: 0.09168704599142075, acc: 0.9815436005592346)
[2024-12-17 02:35:47,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:47,453][root][INFO] - Training Epoch: 2/2, step 1475/7134 completed (loss: 0.07057352364063263, acc: 0.9881266355514526)
[2024-12-17 02:35:47,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:47,783][root][INFO] - Training Epoch: 2/2, step 1476/7134 completed (loss: 0.04963822290301323, acc: 0.9813664555549622)
[2024-12-17 02:35:47,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:48,086][root][INFO] - Training Epoch: 2/2, step 1477/7134 completed (loss: 0.05275052413344383, acc: 0.9842932224273682)
[2024-12-17 02:35:48,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:48,431][root][INFO] - Training Epoch: 2/2, step 1478/7134 completed (loss: 0.03256448358297348, acc: 0.9883211851119995)
[2024-12-17 02:35:48,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:48,772][root][INFO] - Training Epoch: 2/2, step 1479/7134 completed (loss: 0.0465528778731823, acc: 0.9870689511299133)
[2024-12-17 02:35:48,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:49,116][root][INFO] - Training Epoch: 2/2, step 1480/7134 completed (loss: 0.02720145508646965, acc: 0.9896103739738464)
[2024-12-17 02:35:49,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:49,479][root][INFO] - Training Epoch: 2/2, step 1481/7134 completed (loss: 0.04447595030069351, acc: 0.99210524559021)
[2024-12-17 02:35:49,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:49,830][root][INFO] - Training Epoch: 2/2, step 1482/7134 completed (loss: 0.0651952251791954, acc: 0.9815340638160706)
[2024-12-17 02:35:49,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:50,161][root][INFO] - Training Epoch: 2/2, step 1483/7134 completed (loss: 0.028492456302046776, acc: 0.9921011328697205)
[2024-12-17 02:35:50,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:50,512][root][INFO] - Training Epoch: 2/2, step 1484/7134 completed (loss: 0.08310987800359726, acc: 0.9812138676643372)
[2024-12-17 02:35:50,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:50,854][root][INFO] - Training Epoch: 2/2, step 1485/7134 completed (loss: 0.036583565175533295, acc: 0.9873577952384949)
[2024-12-17 02:35:50,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:51,181][root][INFO] - Training Epoch: 2/2, step 1486/7134 completed (loss: 0.03945569694042206, acc: 0.9918808937072754)
[2024-12-17 02:35:51,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:51,524][root][INFO] - Training Epoch: 2/2, step 1487/7134 completed (loss: 0.03333564102649689, acc: 0.9882352948188782)
[2024-12-17 02:35:51,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:51,900][root][INFO] - Training Epoch: 2/2, step 1488/7134 completed (loss: 0.049273718148469925, acc: 0.9893048405647278)
[2024-12-17 02:35:51,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:52,237][root][INFO] - Training Epoch: 2/2, step 1489/7134 completed (loss: 0.050953857600688934, acc: 0.9883177280426025)
[2024-12-17 02:35:52,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:52,604][root][INFO] - Training Epoch: 2/2, step 1490/7134 completed (loss: 0.030887214466929436, acc: 0.9904761910438538)
[2024-12-17 02:35:52,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:52,949][root][INFO] - Training Epoch: 2/2, step 1491/7134 completed (loss: 0.030976934358477592, acc: 0.9919540286064148)
[2024-12-17 02:35:53,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:53,296][root][INFO] - Training Epoch: 2/2, step 1492/7134 completed (loss: 0.05600171163678169, acc: 0.988399088382721)
[2024-12-17 02:35:53,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:53,641][root][INFO] - Training Epoch: 2/2, step 1493/7134 completed (loss: 0.043550457805395126, acc: 0.9919354915618896)
[2024-12-17 02:35:53,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:53,997][root][INFO] - Training Epoch: 2/2, step 1494/7134 completed (loss: 0.04390381649136543, acc: 0.9914841651916504)
[2024-12-17 02:35:54,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:54,344][root][INFO] - Training Epoch: 2/2, step 1495/7134 completed (loss: 0.025098703801631927, acc: 0.9940119981765747)
[2024-12-17 02:35:54,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:54,693][root][INFO] - Training Epoch: 2/2, step 1496/7134 completed (loss: 0.0621754415333271, acc: 0.9814814925193787)
[2024-12-17 02:35:54,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:55,050][root][INFO] - Training Epoch: 2/2, step 1497/7134 completed (loss: 0.029858257621526718, acc: 0.9920814633369446)
[2024-12-17 02:35:55,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:55,391][root][INFO] - Training Epoch: 2/2, step 1498/7134 completed (loss: 0.02504529431462288, acc: 0.9947299361228943)
[2024-12-17 02:35:55,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:55,761][root][INFO] - Training Epoch: 2/2, step 1499/7134 completed (loss: 0.031874533742666245, acc: 0.991696298122406)
[2024-12-17 02:35:55,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:56,074][root][INFO] - Training Epoch: 2/2, step 1500/7134 completed (loss: 0.03413955122232437, acc: 0.9917218685150146)
[2024-12-17 02:35:56,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:56,431][root][INFO] - Training Epoch: 2/2, step 1501/7134 completed (loss: 0.04459255561232567, acc: 0.9896755218505859)
[2024-12-17 02:35:56,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:56,783][root][INFO] - Training Epoch: 2/2, step 1502/7134 completed (loss: 0.06047559902071953, acc: 0.9864712357521057)
[2024-12-17 02:35:56,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:57,104][root][INFO] - Training Epoch: 2/2, step 1503/7134 completed (loss: 0.07240389287471771, acc: 0.9815340638160706)
[2024-12-17 02:35:57,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:57,431][root][INFO] - Training Epoch: 2/2, step 1504/7134 completed (loss: 0.023482033982872963, acc: 0.99245285987854)
[2024-12-17 02:35:57,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:57,755][root][INFO] - Training Epoch: 2/2, step 1505/7134 completed (loss: 0.0468839593231678, acc: 0.9906542301177979)
[2024-12-17 02:35:57,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:58,103][root][INFO] - Training Epoch: 2/2, step 1506/7134 completed (loss: 0.06406058371067047, acc: 0.9772036671638489)
[2024-12-17 02:35:58,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:58,428][root][INFO] - Training Epoch: 2/2, step 1507/7134 completed (loss: 0.028379611670970917, acc: 0.9947643876075745)
[2024-12-17 02:35:58,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:58,790][root][INFO] - Training Epoch: 2/2, step 1508/7134 completed (loss: 0.02963566966354847, acc: 0.9879649877548218)
[2024-12-17 02:35:58,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:59,137][root][INFO] - Training Epoch: 2/2, step 1509/7134 completed (loss: 0.018625011667609215, acc: 0.9957982897758484)
[2024-12-17 02:35:59,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:59,492][root][INFO] - Training Epoch: 2/2, step 1510/7134 completed (loss: 0.15303610265254974, acc: 0.9633333086967468)
[2024-12-17 02:35:59,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:59,837][root][INFO] - Training Epoch: 2/2, step 1511/7134 completed (loss: 0.08390738815069199, acc: 0.9843971729278564)
[2024-12-17 02:35:59,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:00,183][root][INFO] - Training Epoch: 2/2, step 1512/7134 completed (loss: 0.0335705541074276, acc: 0.990867555141449)
[2024-12-17 02:36:00,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:00,510][root][INFO] - Training Epoch: 2/2, step 1513/7134 completed (loss: 0.023695630952715874, acc: 0.9920634627342224)
[2024-12-17 02:36:00,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:00,862][root][INFO] - Training Epoch: 2/2, step 1514/7134 completed (loss: 0.06043330579996109, acc: 0.9888198971748352)
[2024-12-17 02:36:00,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:01,209][root][INFO] - Training Epoch: 2/2, step 1515/7134 completed (loss: 0.04915290325880051, acc: 0.985981285572052)
[2024-12-17 02:36:01,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:01,450][root][INFO] - Training Epoch: 2/2, step 1516/7134 completed (loss: 0.060009974986314774, acc: 0.9800570011138916)
[2024-12-17 02:36:01,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:01,744][root][INFO] - Training Epoch: 2/2, step 1517/7134 completed (loss: 0.07828889042139053, acc: 0.9747899174690247)
[2024-12-17 02:36:01,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:02,015][root][INFO] - Training Epoch: 2/2, step 1518/7134 completed (loss: 0.06249566003680229, acc: 0.9855421781539917)
[2024-12-17 02:36:02,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:02,350][root][INFO] - Training Epoch: 2/2, step 1519/7134 completed (loss: 0.037087999284267426, acc: 0.9861751198768616)
[2024-12-17 02:36:02,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:02,703][root][INFO] - Training Epoch: 2/2, step 1520/7134 completed (loss: 0.055736999958753586, acc: 0.9797191619873047)
[2024-12-17 02:36:02,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:03,173][root][INFO] - Training Epoch: 2/2, step 1521/7134 completed (loss: 0.15339058637619019, acc: 0.947858452796936)
[2024-12-17 02:36:03,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:03,514][root][INFO] - Training Epoch: 2/2, step 1522/7134 completed (loss: 0.14093412458896637, acc: 0.963391125202179)
[2024-12-17 02:36:03,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:03,839][root][INFO] - Training Epoch: 2/2, step 1523/7134 completed (loss: 0.16319264471530914, acc: 0.9625187516212463)
[2024-12-17 02:36:03,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:04,084][root][INFO] - Training Epoch: 2/2, step 1524/7134 completed (loss: 0.0527181513607502, acc: 0.9932885766029358)
[2024-12-17 02:36:04,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:04,425][root][INFO] - Training Epoch: 2/2, step 1525/7134 completed (loss: 0.055565427988767624, acc: 0.9841628670692444)
[2024-12-17 02:36:04,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:04,799][root][INFO] - Training Epoch: 2/2, step 1526/7134 completed (loss: 0.10865174978971481, acc: 0.9753265380859375)
[2024-12-17 02:36:04,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:05,177][root][INFO] - Training Epoch: 2/2, step 1527/7134 completed (loss: 0.13371479511260986, acc: 0.9616026878356934)
[2024-12-17 02:36:05,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:05,561][root][INFO] - Training Epoch: 2/2, step 1528/7134 completed (loss: 0.09175294637680054, acc: 0.967793881893158)
[2024-12-17 02:36:05,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:05,920][root][INFO] - Training Epoch: 2/2, step 1529/7134 completed (loss: 0.0795404389500618, acc: 0.9738406538963318)
[2024-12-17 02:36:06,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:06,241][root][INFO] - Training Epoch: 2/2, step 1530/7134 completed (loss: 0.0795588493347168, acc: 0.980879545211792)
[2024-12-17 02:36:06,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:06,560][root][INFO] - Training Epoch: 2/2, step 1531/7134 completed (loss: 0.18689674139022827, acc: 0.9503546357154846)
[2024-12-17 02:36:06,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:06,931][root][INFO] - Training Epoch: 2/2, step 1532/7134 completed (loss: 0.050512224435806274, acc: 0.9861271381378174)
[2024-12-17 02:36:07,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:07,269][root][INFO] - Training Epoch: 2/2, step 1533/7134 completed (loss: 0.04215257987380028, acc: 0.9875518679618835)
[2024-12-17 02:36:07,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:07,621][root][INFO] - Training Epoch: 2/2, step 1534/7134 completed (loss: 0.0575491264462471, acc: 0.9847645163536072)
[2024-12-17 02:36:07,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:08,006][root][INFO] - Training Epoch: 2/2, step 1535/7134 completed (loss: 0.05226759612560272, acc: 0.9868263602256775)
[2024-12-17 02:36:08,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:08,354][root][INFO] - Training Epoch: 2/2, step 1536/7134 completed (loss: 0.03858768939971924, acc: 0.993678867816925)
[2024-12-17 02:36:08,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:08,674][root][INFO] - Training Epoch: 2/2, step 1537/7134 completed (loss: 0.06821447610855103, acc: 0.985602080821991)
[2024-12-17 02:36:08,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:09,012][root][INFO] - Training Epoch: 2/2, step 1538/7134 completed (loss: 0.0752091109752655, acc: 0.9820742607116699)
[2024-12-17 02:36:09,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:09,365][root][INFO] - Training Epoch: 2/2, step 1539/7134 completed (loss: 0.05923456326127052, acc: 0.9855072498321533)
[2024-12-17 02:36:09,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:09,714][root][INFO] - Training Epoch: 2/2, step 1540/7134 completed (loss: 0.05562300235033035, acc: 0.9798927903175354)
[2024-12-17 02:36:09,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:10,058][root][INFO] - Training Epoch: 2/2, step 1541/7134 completed (loss: 0.08393530547618866, acc: 0.9761006236076355)
[2024-12-17 02:36:10,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:10,434][root][INFO] - Training Epoch: 2/2, step 1542/7134 completed (loss: 0.07923421263694763, acc: 0.979784369468689)
[2024-12-17 02:36:10,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:10,784][root][INFO] - Training Epoch: 2/2, step 1543/7134 completed (loss: 0.037262968719005585, acc: 0.9923497438430786)
[2024-12-17 02:36:10,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:11,142][root][INFO] - Training Epoch: 2/2, step 1544/7134 completed (loss: 0.023327816277742386, acc: 0.9951456189155579)
[2024-12-17 02:36:11,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:11,462][root][INFO] - Training Epoch: 2/2, step 1545/7134 completed (loss: 0.0461723729968071, acc: 0.9870874881744385)
[2024-12-17 02:36:11,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:11,828][root][INFO] - Training Epoch: 2/2, step 1546/7134 completed (loss: 0.09474911540746689, acc: 0.9747545719146729)
[2024-12-17 02:36:11,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:12,167][root][INFO] - Training Epoch: 2/2, step 1547/7134 completed (loss: 0.059139184653759, acc: 0.9850746393203735)
[2024-12-17 02:36:12,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:12,526][root][INFO] - Training Epoch: 2/2, step 1548/7134 completed (loss: 0.04281260445713997, acc: 0.9863481521606445)
[2024-12-17 02:36:12,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:12,886][root][INFO] - Training Epoch: 2/2, step 1549/7134 completed (loss: 0.03668772801756859, acc: 0.9889258146286011)
[2024-12-17 02:36:12,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:13,238][root][INFO] - Training Epoch: 2/2, step 1550/7134 completed (loss: 0.03355425223708153, acc: 0.9923954606056213)
[2024-12-17 02:36:13,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:13,567][root][INFO] - Training Epoch: 2/2, step 1551/7134 completed (loss: 0.042365822941064835, acc: 0.9857142567634583)
[2024-12-17 02:36:13,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:13,933][root][INFO] - Training Epoch: 2/2, step 1552/7134 completed (loss: 0.05819267779588699, acc: 0.9838362336158752)
[2024-12-17 02:36:14,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:14,253][root][INFO] - Training Epoch: 2/2, step 1553/7134 completed (loss: 0.06421470642089844, acc: 0.9778933525085449)
[2024-12-17 02:36:14,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:14,618][root][INFO] - Training Epoch: 2/2, step 1554/7134 completed (loss: 0.0395064614713192, acc: 0.988726019859314)
[2024-12-17 02:36:14,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:14,962][root][INFO] - Training Epoch: 2/2, step 1555/7134 completed (loss: 0.035096898674964905, acc: 0.9899216294288635)
[2024-12-17 02:36:15,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:15,315][root][INFO] - Training Epoch: 2/2, step 1556/7134 completed (loss: 0.04085027426481247, acc: 0.9905992746353149)
[2024-12-17 02:36:15,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:15,677][root][INFO] - Training Epoch: 2/2, step 1557/7134 completed (loss: 0.037007030099630356, acc: 0.9854586124420166)
[2024-12-17 02:36:15,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:16,013][root][INFO] - Training Epoch: 2/2, step 1558/7134 completed (loss: 0.05998781695961952, acc: 0.9845288395881653)
[2024-12-17 02:36:16,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:16,348][root][INFO] - Training Epoch: 2/2, step 1559/7134 completed (loss: 0.028739435598254204, acc: 0.9906291961669922)
[2024-12-17 02:36:16,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:16,695][root][INFO] - Training Epoch: 2/2, step 1560/7134 completed (loss: 0.06926651298999786, acc: 0.9796696305274963)
[2024-12-17 02:36:16,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:17,049][root][INFO] - Training Epoch: 2/2, step 1561/7134 completed (loss: 0.14737549424171448, acc: 0.9696641564369202)
[2024-12-17 02:36:17,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:17,373][root][INFO] - Training Epoch: 2/2, step 1562/7134 completed (loss: 0.06192990019917488, acc: 0.9848713874816895)
[2024-12-17 02:36:17,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:17,715][root][INFO] - Training Epoch: 2/2, step 1563/7134 completed (loss: 0.06567338854074478, acc: 0.9851428866386414)
[2024-12-17 02:36:17,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:18,061][root][INFO] - Training Epoch: 2/2, step 1564/7134 completed (loss: 0.09429663419723511, acc: 0.978960394859314)
[2024-12-17 02:36:18,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:18,369][root][INFO] - Training Epoch: 2/2, step 1565/7134 completed (loss: 0.07426103204488754, acc: 0.978151261806488)
[2024-12-17 02:36:18,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:18,701][root][INFO] - Training Epoch: 2/2, step 1566/7134 completed (loss: 0.07194624096155167, acc: 0.9794801473617554)
[2024-12-17 02:36:18,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:19,089][root][INFO] - Training Epoch: 2/2, step 1567/7134 completed (loss: 0.06652159243822098, acc: 0.9837905168533325)
[2024-12-17 02:36:19,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:19,429][root][INFO] - Training Epoch: 2/2, step 1568/7134 completed (loss: 0.07947175204753876, acc: 0.9775148034095764)
[2024-12-17 02:36:19,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:19,774][root][INFO] - Training Epoch: 2/2, step 1569/7134 completed (loss: 0.07284802198410034, acc: 0.9780701994895935)
[2024-12-17 02:36:19,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:20,140][root][INFO] - Training Epoch: 2/2, step 1570/7134 completed (loss: 0.10605519264936447, acc: 0.9757441878318787)
[2024-12-17 02:36:20,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:20,474][root][INFO] - Training Epoch: 2/2, step 1571/7134 completed (loss: 0.07156819850206375, acc: 0.9857650995254517)
[2024-12-17 02:36:20,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:20,840][root][INFO] - Training Epoch: 2/2, step 1572/7134 completed (loss: 0.07738687098026276, acc: 0.9776207208633423)
[2024-12-17 02:36:20,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:21,159][root][INFO] - Training Epoch: 2/2, step 1573/7134 completed (loss: 0.029609110206365585, acc: 0.9956458806991577)
[2024-12-17 02:36:21,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:21,520][root][INFO] - Training Epoch: 2/2, step 1574/7134 completed (loss: 0.07110625505447388, acc: 0.9835886359214783)
[2024-12-17 02:36:21,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:21,858][root][INFO] - Training Epoch: 2/2, step 1575/7134 completed (loss: 0.08205027878284454, acc: 0.978935718536377)
[2024-12-17 02:36:21,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:22,201][root][INFO] - Training Epoch: 2/2, step 1576/7134 completed (loss: 0.09389722347259521, acc: 0.9789719581604004)
[2024-12-17 02:36:22,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:22,544][root][INFO] - Training Epoch: 2/2, step 1577/7134 completed (loss: 0.06245439872145653, acc: 0.9835100173950195)
[2024-12-17 02:36:22,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:22,891][root][INFO] - Training Epoch: 2/2, step 1578/7134 completed (loss: 0.05140920728445053, acc: 0.9878214001655579)
[2024-12-17 02:36:22,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:23,264][root][INFO] - Training Epoch: 2/2, step 1579/7134 completed (loss: 0.047644466161727905, acc: 0.985023021697998)
[2024-12-17 02:36:23,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:23,630][root][INFO] - Training Epoch: 2/2, step 1580/7134 completed (loss: 0.1150425374507904, acc: 0.9735682606697083)
[2024-12-17 02:36:23,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:23,893][root][INFO] - Training Epoch: 2/2, step 1581/7134 completed (loss: 0.12163186073303223, acc: 0.970678985118866)
[2024-12-17 02:36:24,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:24,243][root][INFO] - Training Epoch: 2/2, step 1582/7134 completed (loss: 0.07105065882205963, acc: 0.9827855825424194)
[2024-12-17 02:36:24,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:24,571][root][INFO] - Training Epoch: 2/2, step 1583/7134 completed (loss: 0.05570599064230919, acc: 0.9856733679771423)
[2024-12-17 02:36:24,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:24,946][root][INFO] - Training Epoch: 2/2, step 1584/7134 completed (loss: 0.036182768642902374, acc: 0.9903640151023865)
[2024-12-17 02:36:25,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:25,290][root][INFO] - Training Epoch: 2/2, step 1585/7134 completed (loss: 0.05546053871512413, acc: 0.982332170009613)
[2024-12-17 02:36:25,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:25,616][root][INFO] - Training Epoch: 2/2, step 1586/7134 completed (loss: 0.07752551883459091, acc: 0.9798099994659424)
[2024-12-17 02:36:25,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:25,957][root][INFO] - Training Epoch: 2/2, step 1587/7134 completed (loss: 0.0475088432431221, acc: 0.9890109896659851)
[2024-12-17 02:36:26,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:26,304][root][INFO] - Training Epoch: 2/2, step 1588/7134 completed (loss: 0.0812329351902008, acc: 0.9840213060379028)
[2024-12-17 02:36:26,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:26,640][root][INFO] - Training Epoch: 2/2, step 1589/7134 completed (loss: 0.05104325711727142, acc: 0.988664984703064)
[2024-12-17 02:36:26,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:26,957][root][INFO] - Training Epoch: 2/2, step 1590/7134 completed (loss: 0.05298951640725136, acc: 0.981873095035553)
[2024-12-17 02:36:27,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:27,281][root][INFO] - Training Epoch: 2/2, step 1591/7134 completed (loss: 0.032549455761909485, acc: 0.9915397763252258)
[2024-12-17 02:36:27,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:27,636][root][INFO] - Training Epoch: 2/2, step 1592/7134 completed (loss: 0.04138975217938423, acc: 0.9857346415519714)
[2024-12-17 02:36:27,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:28,002][root][INFO] - Training Epoch: 2/2, step 1593/7134 completed (loss: 0.056940946727991104, acc: 0.9873563051223755)
[2024-12-17 02:36:28,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:28,338][root][INFO] - Training Epoch: 2/2, step 1594/7134 completed (loss: 0.03253348544239998, acc: 0.9884297251701355)
[2024-12-17 02:36:28,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:28,674][root][INFO] - Training Epoch: 2/2, step 1595/7134 completed (loss: 0.040279656648635864, acc: 0.9910394549369812)
[2024-12-17 02:36:28,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:29,005][root][INFO] - Training Epoch: 2/2, step 1596/7134 completed (loss: 0.10502023994922638, acc: 0.9811023473739624)
[2024-12-17 02:36:29,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:29,334][root][INFO] - Training Epoch: 2/2, step 1597/7134 completed (loss: 0.020437560975551605, acc: 0.9928366541862488)
[2024-12-17 02:36:29,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:29,659][root][INFO] - Training Epoch: 2/2, step 1598/7134 completed (loss: 0.1160353347659111, acc: 0.9640718698501587)
[2024-12-17 02:36:29,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:30,002][root][INFO] - Training Epoch: 2/2, step 1599/7134 completed (loss: 0.13945651054382324, acc: 0.9719008207321167)
[2024-12-17 02:36:30,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:30,372][root][INFO] - Training Epoch: 2/2, step 1600/7134 completed (loss: 0.06869084388017654, acc: 0.9872978925704956)
[2024-12-17 02:36:30,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:30,705][root][INFO] - Training Epoch: 2/2, step 1601/7134 completed (loss: 0.04620058089494705, acc: 0.9876203536987305)
[2024-12-17 02:36:30,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:31,062][root][INFO] - Training Epoch: 2/2, step 1602/7134 completed (loss: 0.0730627104640007, acc: 0.9894419312477112)
[2024-12-17 02:36:31,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:31,345][root][INFO] - Training Epoch: 2/2, step 1603/7134 completed (loss: 0.06698495149612427, acc: 0.9846547245979309)
[2024-12-17 02:36:31,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:31,701][root][INFO] - Training Epoch: 2/2, step 1604/7134 completed (loss: 0.029609892517328262, acc: 0.9933686852455139)
[2024-12-17 02:36:31,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:32,036][root][INFO] - Training Epoch: 2/2, step 1605/7134 completed (loss: 0.05714578554034233, acc: 0.9856584072113037)
[2024-12-17 02:36:32,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:32,360][root][INFO] - Training Epoch: 2/2, step 1606/7134 completed (loss: 0.025556933134794235, acc: 0.9954057931900024)
[2024-12-17 02:36:32,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:32,634][root][INFO] - Training Epoch: 2/2, step 1607/7134 completed (loss: 0.014840178191661835, acc: 0.9938900470733643)
[2024-12-17 02:36:32,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:32,946][root][INFO] - Training Epoch: 2/2, step 1608/7134 completed (loss: 0.027105875313282013, acc: 0.9925650358200073)
[2024-12-17 02:36:33,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:33,291][root][INFO] - Training Epoch: 2/2, step 1609/7134 completed (loss: 0.04954797029495239, acc: 0.9890965819358826)
[2024-12-17 02:36:33,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:33,620][root][INFO] - Training Epoch: 2/2, step 1610/7134 completed (loss: 0.0579710379242897, acc: 0.9883138537406921)
[2024-12-17 02:36:33,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:33,948][root][INFO] - Training Epoch: 2/2, step 1611/7134 completed (loss: 0.08139970153570175, acc: 0.9854497313499451)
[2024-12-17 02:36:34,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:34,273][root][INFO] - Training Epoch: 2/2, step 1612/7134 completed (loss: 0.08055701106786728, acc: 0.9809160232543945)
[2024-12-17 02:36:34,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:34,603][root][INFO] - Training Epoch: 2/2, step 1613/7134 completed (loss: 0.05895800516009331, acc: 0.9868247509002686)
[2024-12-17 02:36:34,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:34,936][root][INFO] - Training Epoch: 2/2, step 1614/7134 completed (loss: 0.07208964973688126, acc: 0.9855832457542419)
[2024-12-17 02:36:35,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:35,311][root][INFO] - Training Epoch: 2/2, step 1615/7134 completed (loss: 0.055976007133722305, acc: 0.9865771532058716)
[2024-12-17 02:36:35,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:35,649][root][INFO] - Training Epoch: 2/2, step 1616/7134 completed (loss: 0.020505353808403015, acc: 0.9956709742546082)
[2024-12-17 02:36:35,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:35,976][root][INFO] - Training Epoch: 2/2, step 1617/7134 completed (loss: 0.04486438259482384, acc: 0.9906396269798279)
[2024-12-17 02:36:36,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:36,303][root][INFO] - Training Epoch: 2/2, step 1618/7134 completed (loss: 0.08269034326076508, acc: 0.9771929979324341)
[2024-12-17 02:36:36,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:36,637][root][INFO] - Training Epoch: 2/2, step 1619/7134 completed (loss: 0.05339277908205986, acc: 0.9863760471343994)
[2024-12-17 02:36:36,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:36,972][root][INFO] - Training Epoch: 2/2, step 1620/7134 completed (loss: 0.08690210431814194, acc: 0.9712556600570679)
[2024-12-17 02:36:37,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:37,324][root][INFO] - Training Epoch: 2/2, step 1621/7134 completed (loss: 0.0844038799405098, acc: 0.9824324250221252)
[2024-12-17 02:36:37,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:37,656][root][INFO] - Training Epoch: 2/2, step 1622/7134 completed (loss: 0.0625191330909729, acc: 0.9874652028083801)
[2024-12-17 02:36:37,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:38,010][root][INFO] - Training Epoch: 2/2, step 1623/7134 completed (loss: 0.06338753551244736, acc: 0.9873595237731934)
[2024-12-17 02:36:38,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:38,355][root][INFO] - Training Epoch: 2/2, step 1624/7134 completed (loss: 0.06906212866306305, acc: 0.9867841601371765)
[2024-12-17 02:36:38,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:38,694][root][INFO] - Training Epoch: 2/2, step 1625/7134 completed (loss: 0.03410186618566513, acc: 0.9886040091514587)
[2024-12-17 02:36:38,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:39,024][root][INFO] - Training Epoch: 2/2, step 1626/7134 completed (loss: 0.09264269471168518, acc: 0.9745370149612427)
[2024-12-17 02:36:39,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:39,342][root][INFO] - Training Epoch: 2/2, step 1627/7134 completed (loss: 0.03820610046386719, acc: 0.9872262477874756)
[2024-12-17 02:36:39,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:39,675][root][INFO] - Training Epoch: 2/2, step 1628/7134 completed (loss: 0.016339071094989777, acc: 0.9956268072128296)
[2024-12-17 02:36:39,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:39,991][root][INFO] - Training Epoch: 2/2, step 1629/7134 completed (loss: 0.04046496003866196, acc: 0.9836363792419434)
[2024-12-17 02:36:40,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:40,316][root][INFO] - Training Epoch: 2/2, step 1630/7134 completed (loss: 0.05464113503694534, acc: 0.9866666793823242)
[2024-12-17 02:36:40,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:40,650][root][INFO] - Training Epoch: 2/2, step 1631/7134 completed (loss: 0.07102182507514954, acc: 0.9839228391647339)
[2024-12-17 02:36:40,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:40,965][root][INFO] - Training Epoch: 2/2, step 1632/7134 completed (loss: 0.02930702269077301, acc: 0.9900497794151306)
[2024-12-17 02:36:41,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:41,290][root][INFO] - Training Epoch: 2/2, step 1633/7134 completed (loss: 0.031220775097608566, acc: 0.9905808568000793)
[2024-12-17 02:36:41,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:41,618][root][INFO] - Training Epoch: 2/2, step 1634/7134 completed (loss: 0.032865092158317566, acc: 0.9938744306564331)
[2024-12-17 02:36:41,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:41,929][root][INFO] - Training Epoch: 2/2, step 1635/7134 completed (loss: 0.04086890444159508, acc: 0.9837067127227783)
[2024-12-17 02:36:42,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:42,252][root][INFO] - Training Epoch: 2/2, step 1636/7134 completed (loss: 0.055013854056596756, acc: 0.977142870426178)
[2024-12-17 02:36:42,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:42,582][root][INFO] - Training Epoch: 2/2, step 1637/7134 completed (loss: 0.02357889898121357, acc: 0.991525411605835)
[2024-12-17 02:36:42,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:42,914][root][INFO] - Training Epoch: 2/2, step 1638/7134 completed (loss: 0.06965948641300201, acc: 0.9813242554664612)
[2024-12-17 02:36:43,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:43,253][root][INFO] - Training Epoch: 2/2, step 1639/7134 completed (loss: 0.1411011815071106, acc: 0.9719350337982178)
[2024-12-17 02:36:43,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:43,603][root][INFO] - Training Epoch: 2/2, step 1640/7134 completed (loss: 0.06456216424703598, acc: 0.9771341681480408)
[2024-12-17 02:36:43,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:43,928][root][INFO] - Training Epoch: 2/2, step 1641/7134 completed (loss: 0.0286966934800148, acc: 0.9913793206214905)
[2024-12-17 02:36:44,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:44,273][root][INFO] - Training Epoch: 2/2, step 1642/7134 completed (loss: 0.07909298688173294, acc: 0.9776315689086914)
[2024-12-17 02:36:44,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:44,594][root][INFO] - Training Epoch: 2/2, step 1643/7134 completed (loss: 0.11623981595039368, acc: 0.9705372452735901)
[2024-12-17 02:36:44,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:44,950][root][INFO] - Training Epoch: 2/2, step 1644/7134 completed (loss: 0.07393383979797363, acc: 0.9830508232116699)
[2024-12-17 02:36:45,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:45,285][root][INFO] - Training Epoch: 2/2, step 1645/7134 completed (loss: 0.06942665576934814, acc: 0.9870689511299133)
[2024-12-17 02:36:45,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:45,648][root][INFO] - Training Epoch: 2/2, step 1646/7134 completed (loss: 0.0970330685377121, acc: 0.9824281334877014)
[2024-12-17 02:36:45,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:45,992][root][INFO] - Training Epoch: 2/2, step 1647/7134 completed (loss: 0.03559580072760582, acc: 0.9876819849014282)
[2024-12-17 02:36:46,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:46,339][root][INFO] - Training Epoch: 2/2, step 1648/7134 completed (loss: 0.06963828951120377, acc: 0.9813829660415649)
[2024-12-17 02:36:46,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:46,693][root][INFO] - Training Epoch: 2/2, step 1649/7134 completed (loss: 0.058863457292318344, acc: 0.985571563243866)
[2024-12-17 02:36:46,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:47,057][root][INFO] - Training Epoch: 2/2, step 1650/7134 completed (loss: 0.0641416683793068, acc: 0.9845361113548279)
[2024-12-17 02:36:47,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:47,414][root][INFO] - Training Epoch: 2/2, step 1651/7134 completed (loss: 0.09037789702415466, acc: 0.9811946749687195)
[2024-12-17 02:36:47,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:47,789][root][INFO] - Training Epoch: 2/2, step 1652/7134 completed (loss: 0.03623677417635918, acc: 0.9934569001197815)
[2024-12-17 02:36:47,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:48,145][root][INFO] - Training Epoch: 2/2, step 1653/7134 completed (loss: 0.0541987307369709, acc: 0.9850560426712036)
[2024-12-17 02:36:48,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:48,537][root][INFO] - Training Epoch: 2/2, step 1654/7134 completed (loss: 0.07375473529100418, acc: 0.9816513657569885)
[2024-12-17 02:36:48,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:48,903][root][INFO] - Training Epoch: 2/2, step 1655/7134 completed (loss: 0.08253530412912369, acc: 0.9801734685897827)
[2024-12-17 02:36:48,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:49,251][root][INFO] - Training Epoch: 2/2, step 1656/7134 completed (loss: 0.07403597235679626, acc: 0.9808558821678162)
[2024-12-17 02:36:49,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:49,637][root][INFO] - Training Epoch: 2/2, step 1657/7134 completed (loss: 0.05015062913298607, acc: 0.983561635017395)
[2024-12-17 02:36:49,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:50,005][root][INFO] - Training Epoch: 2/2, step 1658/7134 completed (loss: 0.02790890447795391, acc: 0.9918367266654968)
[2024-12-17 02:36:50,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:50,362][root][INFO] - Training Epoch: 2/2, step 1659/7134 completed (loss: 0.06583082675933838, acc: 0.9848341345787048)
[2024-12-17 02:36:50,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:50,732][root][INFO] - Training Epoch: 2/2, step 1660/7134 completed (loss: 0.04631217569112778, acc: 0.990338146686554)
[2024-12-17 02:36:50,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:51,094][root][INFO] - Training Epoch: 2/2, step 1661/7134 completed (loss: 0.06573081016540527, acc: 0.97921222448349)
[2024-12-17 02:36:51,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:51,446][root][INFO] - Training Epoch: 2/2, step 1662/7134 completed (loss: 0.058133870363235474, acc: 0.9893955588340759)
[2024-12-17 02:36:51,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:51,820][root][INFO] - Training Epoch: 2/2, step 1663/7134 completed (loss: 0.06787474453449249, acc: 0.9835560321807861)
[2024-12-17 02:36:51,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:52,162][root][INFO] - Training Epoch: 2/2, step 1664/7134 completed (loss: 0.029071897268295288, acc: 0.9880810379981995)
[2024-12-17 02:36:52,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:52,517][root][INFO] - Training Epoch: 2/2, step 1665/7134 completed (loss: 0.06082556024193764, acc: 0.9827337861061096)
[2024-12-17 02:36:52,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:52,919][root][INFO] - Training Epoch: 2/2, step 1666/7134 completed (loss: 0.05702236294746399, acc: 0.9880239367485046)
[2024-12-17 02:36:53,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:53,300][root][INFO] - Training Epoch: 2/2, step 1667/7134 completed (loss: 0.07325419038534164, acc: 0.9798099994659424)
[2024-12-17 02:36:53,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:53,662][root][INFO] - Training Epoch: 2/2, step 1668/7134 completed (loss: 0.037236835807561874, acc: 0.993697464466095)
[2024-12-17 02:36:53,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:54,070][root][INFO] - Training Epoch: 2/2, step 1669/7134 completed (loss: 0.0613849014043808, acc: 0.9849340915679932)
[2024-12-17 02:36:54,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:54,468][root][INFO] - Training Epoch: 2/2, step 1670/7134 completed (loss: 0.06641370803117752, acc: 0.9780534505844116)
[2024-12-17 02:36:54,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:54,839][root][INFO] - Training Epoch: 2/2, step 1671/7134 completed (loss: 0.07011502236127853, acc: 0.9844683408737183)
[2024-12-17 02:36:54,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:55,187][root][INFO] - Training Epoch: 2/2, step 1672/7134 completed (loss: 0.05734175443649292, acc: 0.9880478382110596)
[2024-12-17 02:36:55,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:55,541][root][INFO] - Training Epoch: 2/2, step 1673/7134 completed (loss: 0.06593354046344757, acc: 0.9852150678634644)
[2024-12-17 02:36:55,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:55,857][root][INFO] - Training Epoch: 2/2, step 1674/7134 completed (loss: 0.06354234367609024, acc: 0.9860334992408752)
[2024-12-17 02:36:55,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:56,209][root][INFO] - Training Epoch: 2/2, step 1675/7134 completed (loss: 0.12122321873903275, acc: 0.9714285731315613)
[2024-12-17 02:36:56,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:56,545][root][INFO] - Training Epoch: 2/2, step 1676/7134 completed (loss: 0.034334443509578705, acc: 0.9903314709663391)
[2024-12-17 02:36:56,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:56,872][root][INFO] - Training Epoch: 2/2, step 1677/7134 completed (loss: 0.1037425622344017, acc: 0.9738134145736694)
[2024-12-17 02:36:56,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:57,233][root][INFO] - Training Epoch: 2/2, step 1678/7134 completed (loss: 0.0339994914829731, acc: 0.9945205450057983)
[2024-12-17 02:36:57,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:57,570][root][INFO] - Training Epoch: 2/2, step 1679/7134 completed (loss: 0.06533310562372208, acc: 0.9838945865631104)
[2024-12-17 02:36:57,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:57,935][root][INFO] - Training Epoch: 2/2, step 1680/7134 completed (loss: 0.057649239897727966, acc: 0.9879356622695923)
[2024-12-17 02:36:58,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:58,271][root][INFO] - Training Epoch: 2/2, step 1681/7134 completed (loss: 0.0490693598985672, acc: 0.9857954382896423)
[2024-12-17 02:36:58,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:58,622][root][INFO] - Training Epoch: 2/2, step 1682/7134 completed (loss: 0.1123841181397438, acc: 0.9711815714836121)
[2024-12-17 02:36:58,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:58,949][root][INFO] - Training Epoch: 2/2, step 1683/7134 completed (loss: 0.04545506089925766, acc: 0.983818769454956)
[2024-12-17 02:36:59,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:59,288][root][INFO] - Training Epoch: 2/2, step 1684/7134 completed (loss: 0.04741285741329193, acc: 0.9845890402793884)
[2024-12-17 02:36:59,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:59,630][root][INFO] - Training Epoch: 2/2, step 1685/7134 completed (loss: 0.06681273132562637, acc: 0.9833101630210876)
[2024-12-17 02:36:59,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:59,956][root][INFO] - Training Epoch: 2/2, step 1686/7134 completed (loss: 0.04287806525826454, acc: 0.9881756901741028)
[2024-12-17 02:37:00,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:00,291][root][INFO] - Training Epoch: 2/2, step 1687/7134 completed (loss: 0.03800376504659653, acc: 0.9847908616065979)
[2024-12-17 02:37:00,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:00,603][root][INFO] - Training Epoch: 2/2, step 1688/7134 completed (loss: 0.04561404138803482, acc: 0.9907264113426208)
[2024-12-17 02:37:00,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:00,920][root][INFO] - Training Epoch: 2/2, step 1689/7134 completed (loss: 0.030718639492988586, acc: 0.9927849769592285)
[2024-12-17 02:37:01,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:01,232][root][INFO] - Training Epoch: 2/2, step 1690/7134 completed (loss: 0.03174744173884392, acc: 0.9898374080657959)
[2024-12-17 02:37:01,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:01,551][root][INFO] - Training Epoch: 2/2, step 1691/7134 completed (loss: 0.013728166930377483, acc: 0.9933775067329407)
[2024-12-17 02:37:01,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:01,878][root][INFO] - Training Epoch: 2/2, step 1692/7134 completed (loss: 0.06937240809202194, acc: 0.9814502596855164)
[2024-12-17 02:37:01,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:02,211][root][INFO] - Training Epoch: 2/2, step 1693/7134 completed (loss: 0.03744477033615112, acc: 0.992514967918396)
[2024-12-17 02:37:02,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:02,547][root][INFO] - Training Epoch: 2/2, step 1694/7134 completed (loss: 0.04029502347111702, acc: 0.9874804615974426)
[2024-12-17 02:37:02,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:02,889][root][INFO] - Training Epoch: 2/2, step 1695/7134 completed (loss: 0.02813507802784443, acc: 0.9909909963607788)
[2024-12-17 02:37:02,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:03,200][root][INFO] - Training Epoch: 2/2, step 1696/7134 completed (loss: 0.05864611268043518, acc: 0.981574535369873)
[2024-12-17 02:37:03,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:03,513][root][INFO] - Training Epoch: 2/2, step 1697/7134 completed (loss: 0.06086549907922745, acc: 0.9906103014945984)
[2024-12-17 02:37:03,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:03,845][root][INFO] - Training Epoch: 2/2, step 1698/7134 completed (loss: 0.03346935287117958, acc: 0.9905956387519836)
[2024-12-17 02:37:03,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:04,190][root][INFO] - Training Epoch: 2/2, step 1699/7134 completed (loss: 0.05171556770801544, acc: 0.9861591458320618)
[2024-12-17 02:37:04,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:04,548][root][INFO] - Training Epoch: 2/2, step 1700/7134 completed (loss: 0.07216043025255203, acc: 0.980322003364563)
[2024-12-17 02:37:04,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:04,878][root][INFO] - Training Epoch: 2/2, step 1701/7134 completed (loss: 0.060933563858270645, acc: 0.977746844291687)
[2024-12-17 02:37:04,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:05,217][root][INFO] - Training Epoch: 2/2, step 1702/7134 completed (loss: 0.06866395473480225, acc: 0.9776397347450256)
[2024-12-17 02:37:05,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:05,548][root][INFO] - Training Epoch: 2/2, step 1703/7134 completed (loss: 0.07804633677005768, acc: 0.9779005646705627)
[2024-12-17 02:37:05,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:05,892][root][INFO] - Training Epoch: 2/2, step 1704/7134 completed (loss: 0.11016186326742172, acc: 0.970108687877655)
[2024-12-17 02:37:05,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:06,240][root][INFO] - Training Epoch: 2/2, step 1705/7134 completed (loss: 0.06982534378767014, acc: 0.9802761077880859)
[2024-12-17 02:37:06,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:06,456][root][INFO] - Training Epoch: 2/2, step 1706/7134 completed (loss: 0.04995274171233177, acc: 0.9886363744735718)
[2024-12-17 02:37:06,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:06,815][root][INFO] - Training Epoch: 2/2, step 1707/7134 completed (loss: 0.052778925746679306, acc: 0.9894291758537292)
[2024-12-17 02:37:06,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:07,146][root][INFO] - Training Epoch: 2/2, step 1708/7134 completed (loss: 0.06369942426681519, acc: 0.9788618087768555)
[2024-12-17 02:37:07,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:07,476][root][INFO] - Training Epoch: 2/2, step 1709/7134 completed (loss: 0.054439958184957504, acc: 0.9810344576835632)
[2024-12-17 02:37:07,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:07,834][root][INFO] - Training Epoch: 2/2, step 1710/7134 completed (loss: 0.06354017555713654, acc: 0.9813218116760254)
[2024-12-17 02:37:07,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:08,139][root][INFO] - Training Epoch: 2/2, step 1711/7134 completed (loss: 0.06773524731397629, acc: 0.9861830472946167)
[2024-12-17 02:37:08,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:08,448][root][INFO] - Training Epoch: 2/2, step 1712/7134 completed (loss: 0.09970369935035706, acc: 0.9719298481941223)
[2024-12-17 02:37:08,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:08,756][root][INFO] - Training Epoch: 2/2, step 1713/7134 completed (loss: 0.05283660441637039, acc: 0.9840319156646729)
[2024-12-17 02:37:08,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:09,096][root][INFO] - Training Epoch: 2/2, step 1714/7134 completed (loss: 0.08739230036735535, acc: 0.96875)
[2024-12-17 02:37:09,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:09,438][root][INFO] - Training Epoch: 2/2, step 1715/7134 completed (loss: 0.05857948586344719, acc: 0.9776875972747803)
[2024-12-17 02:37:09,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:09,750][root][INFO] - Training Epoch: 2/2, step 1716/7134 completed (loss: 0.10924123227596283, acc: 0.9649999737739563)
[2024-12-17 02:37:09,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:10,053][root][INFO] - Training Epoch: 2/2, step 1717/7134 completed (loss: 0.057886652648448944, acc: 0.9766536951065063)
[2024-12-17 02:37:10,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:10,363][root][INFO] - Training Epoch: 2/2, step 1718/7134 completed (loss: 0.07413074374198914, acc: 0.9799554347991943)
[2024-12-17 02:37:10,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:10,708][root][INFO] - Training Epoch: 2/2, step 1719/7134 completed (loss: 0.09688598662614822, acc: 0.9849315285682678)
[2024-12-17 02:37:10,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:11,004][root][INFO] - Training Epoch: 2/2, step 1720/7134 completed (loss: 0.11761025339365005, acc: 0.9585921168327332)
[2024-12-17 02:37:11,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:11,283][root][INFO] - Training Epoch: 2/2, step 1721/7134 completed (loss: 0.06187894567847252, acc: 0.9763912558555603)
[2024-12-17 02:37:11,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:11,577][root][INFO] - Training Epoch: 2/2, step 1722/7134 completed (loss: 0.03008166141808033, acc: 0.9868420958518982)
[2024-12-17 02:37:11,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:11,900][root][INFO] - Training Epoch: 2/2, step 1723/7134 completed (loss: 0.1122724786400795, acc: 0.9716840386390686)
[2024-12-17 02:37:12,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:12,234][root][INFO] - Training Epoch: 2/2, step 1724/7134 completed (loss: 0.11626550555229187, acc: 0.9670329689979553)
[2024-12-17 02:37:12,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:12,525][root][INFO] - Training Epoch: 2/2, step 1725/7134 completed (loss: 0.035939764231443405, acc: 0.9903537034988403)
[2024-12-17 02:37:12,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:12,796][root][INFO] - Training Epoch: 2/2, step 1726/7134 completed (loss: 0.08608812093734741, acc: 0.9775784611701965)
[2024-12-17 02:37:12,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:13,117][root][INFO] - Training Epoch: 2/2, step 1727/7134 completed (loss: 0.04968986287713051, acc: 0.9908758997917175)
[2024-12-17 02:37:13,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:13,455][root][INFO] - Training Epoch: 2/2, step 1728/7134 completed (loss: 0.04717817157506943, acc: 0.9884105920791626)
[2024-12-17 02:37:13,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:13,769][root][INFO] - Training Epoch: 2/2, step 1729/7134 completed (loss: 0.08632068336009979, acc: 0.9755600690841675)
[2024-12-17 02:37:13,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:14,111][root][INFO] - Training Epoch: 2/2, step 1730/7134 completed (loss: 0.04323819652199745, acc: 0.9850106835365295)
[2024-12-17 02:37:14,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:14,355][root][INFO] - Training Epoch: 2/2, step 1731/7134 completed (loss: 0.06356345117092133, acc: 0.9855491518974304)
[2024-12-17 02:37:14,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:14,655][root][INFO] - Training Epoch: 2/2, step 1732/7134 completed (loss: 0.057744741439819336, acc: 0.9835729002952576)
[2024-12-17 02:37:14,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:14,959][root][INFO] - Training Epoch: 2/2, step 1733/7134 completed (loss: 0.05186614766716957, acc: 0.9876543283462524)
[2024-12-17 02:37:15,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:15,324][root][INFO] - Training Epoch: 2/2, step 1734/7134 completed (loss: 0.07142994552850723, acc: 0.977886974811554)
[2024-12-17 02:37:15,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:15,666][root][INFO] - Training Epoch: 2/2, step 1735/7134 completed (loss: 0.031860508024692535, acc: 0.991584837436676)
[2024-12-17 02:37:15,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:16,017][root][INFO] - Training Epoch: 2/2, step 1736/7134 completed (loss: 0.04801473394036293, acc: 0.9890909194946289)
[2024-12-17 02:37:16,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:16,364][root][INFO] - Training Epoch: 2/2, step 1737/7134 completed (loss: 0.04765861853957176, acc: 0.9859550595283508)
[2024-12-17 02:37:16,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:16,715][root][INFO] - Training Epoch: 2/2, step 1738/7134 completed (loss: 0.021975921466946602, acc: 0.9963811635971069)
[2024-12-17 02:37:16,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:17,071][root][INFO] - Training Epoch: 2/2, step 1739/7134 completed (loss: 0.0631527379155159, acc: 0.9805389046669006)
[2024-12-17 02:37:17,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:17,422][root][INFO] - Training Epoch: 2/2, step 1740/7134 completed (loss: 0.02170378901064396, acc: 0.9970760345458984)
[2024-12-17 02:37:17,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:17,786][root][INFO] - Training Epoch: 2/2, step 1741/7134 completed (loss: 0.05938784405589104, acc: 0.9854497313499451)
[2024-12-17 02:37:17,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:18,120][root][INFO] - Training Epoch: 2/2, step 1742/7134 completed (loss: 0.037278126925230026, acc: 0.9886524677276611)
[2024-12-17 02:37:18,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:18,473][root][INFO] - Training Epoch: 2/2, step 1743/7134 completed (loss: 0.058048564940690994, acc: 0.9831932783126831)
[2024-12-17 02:37:18,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:18,805][root][INFO] - Training Epoch: 2/2, step 1744/7134 completed (loss: 0.05506251007318497, acc: 0.990227997303009)
[2024-12-17 02:37:18,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:19,159][root][INFO] - Training Epoch: 2/2, step 1745/7134 completed (loss: 0.04991581663489342, acc: 0.9837092757225037)
[2024-12-17 02:37:19,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:19,508][root][INFO] - Training Epoch: 2/2, step 1746/7134 completed (loss: 0.025628574192523956, acc: 0.9912790656089783)
[2024-12-17 02:37:19,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:19,873][root][INFO] - Training Epoch: 2/2, step 1747/7134 completed (loss: 0.046669814735651016, acc: 0.9862328171730042)
[2024-12-17 02:37:19,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:20,232][root][INFO] - Training Epoch: 2/2, step 1748/7134 completed (loss: 0.04872453957796097, acc: 0.9838709831237793)
[2024-12-17 02:37:20,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:20,594][root][INFO] - Training Epoch: 2/2, step 1749/7134 completed (loss: 0.04508451372385025, acc: 0.9886492490768433)
[2024-12-17 02:37:20,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:20,958][root][INFO] - Training Epoch: 2/2, step 1750/7134 completed (loss: 0.05564342811703682, acc: 0.9856114983558655)
[2024-12-17 02:37:21,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:21,306][root][INFO] - Training Epoch: 2/2, step 1751/7134 completed (loss: 0.06066139042377472, acc: 0.9806060791015625)
[2024-12-17 02:37:21,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:21,654][root][INFO] - Training Epoch: 2/2, step 1752/7134 completed (loss: 0.09153680503368378, acc: 0.9793814420700073)
[2024-12-17 02:37:21,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:21,985][root][INFO] - Training Epoch: 2/2, step 1753/7134 completed (loss: 0.08132468909025192, acc: 0.981794536113739)
[2024-12-17 02:37:22,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:22,313][root][INFO] - Training Epoch: 2/2, step 1754/7134 completed (loss: 0.05116298422217369, acc: 0.9855907559394836)
[2024-12-17 02:37:22,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:22,647][root][INFO] - Training Epoch: 2/2, step 1755/7134 completed (loss: 0.029492080211639404, acc: 0.9947090148925781)
[2024-12-17 02:37:22,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:22,988][root][INFO] - Training Epoch: 2/2, step 1756/7134 completed (loss: 0.06311935186386108, acc: 0.9791937470436096)
[2024-12-17 02:37:23,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:23,313][root][INFO] - Training Epoch: 2/2, step 1757/7134 completed (loss: 0.07298048585653305, acc: 0.980033278465271)
[2024-12-17 02:37:23,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:23,674][root][INFO] - Training Epoch: 2/2, step 1758/7134 completed (loss: 0.03300793096423149, acc: 0.9924242496490479)
[2024-12-17 02:37:23,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:24,016][root][INFO] - Training Epoch: 2/2, step 1759/7134 completed (loss: 0.0558650940656662, acc: 0.9847009778022766)
[2024-12-17 02:37:24,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:24,340][root][INFO] - Training Epoch: 2/2, step 1760/7134 completed (loss: 0.04292208328843117, acc: 0.9882352948188782)
[2024-12-17 02:37:24,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:24,658][root][INFO] - Training Epoch: 2/2, step 1761/7134 completed (loss: 0.042621199041604996, acc: 0.9900568127632141)
[2024-12-17 02:37:24,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:24,983][root][INFO] - Training Epoch: 2/2, step 1762/7134 completed (loss: 0.026603376492857933, acc: 0.9938144087791443)
[2024-12-17 02:37:25,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:25,295][root][INFO] - Training Epoch: 2/2, step 1763/7134 completed (loss: 0.054517000913619995, acc: 0.9839743375778198)
[2024-12-17 02:37:25,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:25,616][root][INFO] - Training Epoch: 2/2, step 1764/7134 completed (loss: 0.04414971545338631, acc: 0.9851301312446594)
[2024-12-17 02:37:25,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:25,953][root][INFO] - Training Epoch: 2/2, step 1765/7134 completed (loss: 0.02795693278312683, acc: 0.9938271641731262)
[2024-12-17 02:37:26,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:26,277][root][INFO] - Training Epoch: 2/2, step 1766/7134 completed (loss: 0.04717246815562248, acc: 0.9809384346008301)
[2024-12-17 02:37:26,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:26,614][root][INFO] - Training Epoch: 2/2, step 1767/7134 completed (loss: 0.07687931507825851, acc: 0.9759547114372253)
[2024-12-17 02:37:26,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:26,940][root][INFO] - Training Epoch: 2/2, step 1768/7134 completed (loss: 0.060376137495040894, acc: 0.9826589822769165)
[2024-12-17 02:37:27,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:27,276][root][INFO] - Training Epoch: 2/2, step 1769/7134 completed (loss: 0.035042185336351395, acc: 0.9911764860153198)
[2024-12-17 02:37:27,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:27,593][root][INFO] - Training Epoch: 2/2, step 1770/7134 completed (loss: 0.0427386537194252, acc: 0.9893778562545776)
[2024-12-17 02:37:27,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:27,948][root][INFO] - Training Epoch: 2/2, step 1771/7134 completed (loss: 0.02455890364944935, acc: 0.9972066879272461)
[2024-12-17 02:37:28,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:28,256][root][INFO] - Training Epoch: 2/2, step 1772/7134 completed (loss: 0.026233240962028503, acc: 0.9865996837615967)
[2024-12-17 02:37:28,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:28,590][root][INFO] - Training Epoch: 2/2, step 1773/7134 completed (loss: 0.020653584972023964, acc: 0.9956395626068115)
[2024-12-17 02:37:28,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:28,897][root][INFO] - Training Epoch: 2/2, step 1774/7134 completed (loss: 0.03073556162416935, acc: 0.9916943311691284)
[2024-12-17 02:37:28,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:29,203][root][INFO] - Training Epoch: 2/2, step 1775/7134 completed (loss: 0.01580471359193325, acc: 0.9984375238418579)
[2024-12-17 02:37:29,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:29,519][root][INFO] - Training Epoch: 2/2, step 1776/7134 completed (loss: 0.029882071539759636, acc: 0.9895209670066833)
[2024-12-17 02:37:29,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:29,837][root][INFO] - Training Epoch: 2/2, step 1777/7134 completed (loss: 0.024654574692249298, acc: 0.9911242723464966)
[2024-12-17 02:37:29,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:30,159][root][INFO] - Training Epoch: 2/2, step 1778/7134 completed (loss: 0.07250819355249405, acc: 0.9881656765937805)
[2024-12-17 02:37:30,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:30,474][root][INFO] - Training Epoch: 2/2, step 1779/7134 completed (loss: 0.03398101031780243, acc: 0.9898989796638489)
[2024-12-17 02:37:30,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:30,844][root][INFO] - Training Epoch: 2/2, step 1780/7134 completed (loss: 0.03154068812727928, acc: 0.9929278492927551)
[2024-12-17 02:37:31,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:31,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:32,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:32,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:32,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:32,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:33,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:33,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:33,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:34,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:34,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:34,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:34,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:35,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:35,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:35,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:35,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:36,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:36,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:36,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:37,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:37,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:37,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:37,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:38,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:38,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:38,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:39,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:39,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:39,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:40,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:40,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:40,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:41,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:41,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:41,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:41,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:42,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:42,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:42,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:43,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:43,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:43,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:43,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:44,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:44,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:44,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:45,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:45,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:45,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:46,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:46,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:46,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:46,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:47,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:47,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:47,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:47,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:48,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:48,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:48,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:48,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:49,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:49,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:49,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:50,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:50,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:50,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:50,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:51,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:51,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:51,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:51,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:52,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:52,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:52,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:53,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:53,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:53,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:53,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:54,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:54,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:54,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:54,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:55,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:55,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:55,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:56,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:56,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:56,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:56,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:57,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:57,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:57,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:57,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:58,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:58,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:58,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:58,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:59,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:59,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:59,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:59,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:00,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:00,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:00,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:00,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:01,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:01,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:01,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:01,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:02,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:02,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:02,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:03,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:03,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:03,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:03,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:04,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:04,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:04,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:04,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:05,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:05,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:05,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:05,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:06,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:06,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:06,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:07,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:07,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:07,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:07,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:08,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:08,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:08,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:09,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:09,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:09,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:09,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:10,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:10,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:10,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:11,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:11,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:11,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:11,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:12,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:12,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:12,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:12,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:13,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:13,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:13,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:13,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:14,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:14,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:14,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:14,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:15,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:15,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:15,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:15,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:16,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:16,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:16,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:17,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:17,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:17,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:17,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:18,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:18,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:18,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:19,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:19,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:19,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:19,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:20,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:20,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:20,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:21,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:21,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:21,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:21,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:22,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:22,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:22,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:23,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:23,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:23,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:24,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:24,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:24,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:24,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:25,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:25,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:25,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:25,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:26,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:26,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:26,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:27,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:27,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:27,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:27,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:28,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:28,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:28,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:28,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:29,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:29,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:29,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:29,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:30,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:30,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:30,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:30,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:31,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:31,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:31,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:32,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:32,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:32,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:33,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:33,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:33,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:33,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:34,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:34,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:34,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:35,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:35,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:35,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:35,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:36,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:36,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:36,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:37,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:37,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:37,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:37,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:38,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:38,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:38,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:39,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:39,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:39,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:40,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:40,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:40,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:41,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:41,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:41,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:42,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:42,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:42,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:43,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:43,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:43,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:43,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:44,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:44,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:44,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:45,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:45,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:45,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:45,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:46,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:46,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:46,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:47,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:47,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:47,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:48,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:48,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:48,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:49,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:49,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:49,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:50,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:50,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:50,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:51,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:51,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:51,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:52,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:52,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:52,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:53,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:53,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:53,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:54,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:54,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:54,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:55,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:55,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:56,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:56,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:56,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:56,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:57,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:57,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:57,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:58,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:58,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:58,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:59,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:59,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:59,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:59,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:00,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:00,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:00,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:01,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:01,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:01,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:01,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:02,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:02,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:02,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:03,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:03,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:03,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:03,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:04,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:04,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:04,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:05,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:05,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:05,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:06,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:06,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:06,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:06,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:07,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:07,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:07,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:08,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:08,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:08,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:08,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:09,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:09,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:10,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:10,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:10,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:11,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:11,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:11,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:12,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:12,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:12,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:13,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:13,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:13,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:13,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:14,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:14,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:14,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:15,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:15,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:16,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:16,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:17,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:17,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:18,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:18,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:18,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:19,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:19,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:19,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:20,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:20,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:20,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:20,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:20,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:21,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:21,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:21,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:21,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:22,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:22,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:22,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:22,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:23,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:23,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:23,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:24,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:24,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:24,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:24,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:25,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:25,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:25,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:26,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:26,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:26,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:26,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:27,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:27,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:27,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:27,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:28,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:28,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:28,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:28,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:29,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:29,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:29,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:29,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:30,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:30,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:30,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:30,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:31,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:31,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:31,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:31,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:32,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:32,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:32,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:32,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:33,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:33,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:33,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:34,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:34,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:34,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:34,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:35,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:35,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:35,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:35,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:36,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:36,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:36,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:37,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:37,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:37,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:37,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:38,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:38,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:38,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:39,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:39,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:39,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:39,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:40,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:40,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:40,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:40,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:41,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:41,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:41,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:41,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:42,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:42,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:42,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:42,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:43,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:43,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:43,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:43,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:44,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:44,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:44,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:44,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:45,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:45,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:45,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:45,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:46,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:46,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:46,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:46,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:47,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:47,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:47,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:47,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:48,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:48,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:48,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:49,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:49,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:49,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:50,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:50,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:50,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:51,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:51,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:51,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:52,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:52,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:52,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:52,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:53,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:53,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:53,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:53,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:54,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:54,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:54,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:55,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:55,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:55,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:56,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:56,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:56,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:56,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:57,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:57,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:57,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:58,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:58,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:58,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:58,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:59,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:59,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:59,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:59,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:00,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:00,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:00,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:00,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:01,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:01,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:01,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:02,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:02,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:02,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:02,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:03,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:03,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:03,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:04,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:04,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:04,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:04,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:05,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:05,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:05,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:05,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:06,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:06,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:06,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:06,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:07,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:07,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:07,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:08,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:08,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:08,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:08,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:09,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:09,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:09,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:10,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:10,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:10,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:10,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:11,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:11,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:11,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:12,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:12,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:12,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:12,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:13,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:13,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:13,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:13,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:14,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:14,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:14,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:14,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:15,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:15,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:15,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:16,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:16,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:16,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:17,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:17,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:18,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:18,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:18,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:19,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:19,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:19,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:19,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:20,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:20,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:20,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:21,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:21,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:21,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:22,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:22,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:22,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:22,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:22,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:23,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:23,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:23,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:24,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:24,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:24,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:24,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:25,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:25,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:25,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:25,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:26,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:26,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:26,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:26,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:27,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:27,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:27,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:27,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:28,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:28,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:28,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:29,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:29,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:29,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:30,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:31,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:31,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:31,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:32,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:32,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:32,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:33,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:33,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:33,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:34,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:34,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:34,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:35,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:35,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:35,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:35,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:36,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:36,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:36,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:36,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:37,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:37,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:37,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:38,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:38,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:38,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:38,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:39,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:39,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:39,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:40,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:40,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:40,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:40,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:40,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:41,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:41,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:41,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:42,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:42,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:42,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:42,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:43,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:43,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:43,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:44,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:44,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:44,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:45,336][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.0800, device='cuda:0') eval_epoch_loss=tensor(0.0769, device='cuda:0') eval_epoch_acc=tensor(0.9804, device='cuda:0')
[2024-12-17 02:40:45,338][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-12-17 02:40:45,338][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 02:40:45,537][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_2_step_1781_loss_0.07691870629787445/model.pt
[2024-12-17 02:40:45,544][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 0.07691870629787445
[2024-12-17 02:40:45,545][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.9804474711418152
[2024-12-17 02:40:45,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:45,894][root][INFO] - Training Epoch: 2/2, step 1781/7134 completed (loss: 0.03224208950996399, acc: 0.9877862334251404)
[2024-12-17 02:40:45,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:46,212][root][INFO] - Training Epoch: 2/2, step 1782/7134 completed (loss: 0.051098376512527466, acc: 0.9878234267234802)
[2024-12-17 02:40:46,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:46,554][root][INFO] - Training Epoch: 2/2, step 1783/7134 completed (loss: 0.0728619322180748, acc: 0.9810810685157776)
[2024-12-17 02:40:46,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:46,906][root][INFO] - Training Epoch: 2/2, step 1784/7134 completed (loss: 0.02881591208279133, acc: 0.992668628692627)
[2024-12-17 02:40:47,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:47,262][root][INFO] - Training Epoch: 2/2, step 1785/7134 completed (loss: 0.037254080176353455, acc: 0.9889958500862122)
[2024-12-17 02:40:47,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:47,582][root][INFO] - Training Epoch: 2/2, step 1786/7134 completed (loss: 0.0281001515686512, acc: 0.9921996593475342)
[2024-12-17 02:40:47,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:47,919][root][INFO] - Training Epoch: 2/2, step 1787/7134 completed (loss: 0.028833579272031784, acc: 0.9910714030265808)
[2024-12-17 02:40:48,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:48,234][root][INFO] - Training Epoch: 2/2, step 1788/7134 completed (loss: 0.0448933020234108, acc: 0.9836333990097046)
[2024-12-17 02:40:48,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:48,566][root][INFO] - Training Epoch: 2/2, step 1789/7134 completed (loss: 0.0276050828397274, acc: 0.9923195242881775)
[2024-12-17 02:40:48,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:48,909][root][INFO] - Training Epoch: 2/2, step 1790/7134 completed (loss: 0.16139377653598785, acc: 0.9726247787475586)
[2024-12-17 02:40:49,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:49,236][root][INFO] - Training Epoch: 2/2, step 1791/7134 completed (loss: 0.17475514113903046, acc: 0.968616247177124)
[2024-12-17 02:40:49,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:49,592][root][INFO] - Training Epoch: 2/2, step 1792/7134 completed (loss: 0.18449653685092926, acc: 0.9647696614265442)
[2024-12-17 02:40:49,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:49,949][root][INFO] - Training Epoch: 2/2, step 1793/7134 completed (loss: 0.17497088015079498, acc: 0.9648648500442505)
[2024-12-17 02:40:50,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:50,314][root][INFO] - Training Epoch: 2/2, step 1794/7134 completed (loss: 0.12095345556735992, acc: 0.9638364911079407)
[2024-12-17 02:40:50,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:50,649][root][INFO] - Training Epoch: 2/2, step 1795/7134 completed (loss: 0.1746683269739151, acc: 0.9609929323196411)
[2024-12-17 02:40:50,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:50,986][root][INFO] - Training Epoch: 2/2, step 1796/7134 completed (loss: 0.14536525309085846, acc: 0.9655172228813171)
[2024-12-17 02:40:51,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:51,323][root][INFO] - Training Epoch: 2/2, step 1797/7134 completed (loss: 0.0899144858121872, acc: 0.976190447807312)
[2024-12-17 02:40:51,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:51,681][root][INFO] - Training Epoch: 2/2, step 1798/7134 completed (loss: 0.14101827144622803, acc: 0.9498069286346436)
[2024-12-17 02:40:51,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:52,036][root][INFO] - Training Epoch: 2/2, step 1799/7134 completed (loss: 0.13471226394176483, acc: 0.9685929417610168)
[2024-12-17 02:40:52,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:52,388][root][INFO] - Training Epoch: 2/2, step 1800/7134 completed (loss: 0.15730632841587067, acc: 0.9649532437324524)
[2024-12-17 02:40:52,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:52,741][root][INFO] - Training Epoch: 2/2, step 1801/7134 completed (loss: 0.11714278906583786, acc: 0.9724576473236084)
[2024-12-17 02:40:52,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:53,088][root][INFO] - Training Epoch: 2/2, step 1802/7134 completed (loss: 0.08894612640142441, acc: 0.9774718284606934)
[2024-12-17 02:40:53,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:53,428][root][INFO] - Training Epoch: 2/2, step 1803/7134 completed (loss: 0.08366735279560089, acc: 0.9784283638000488)
[2024-12-17 02:40:53,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:53,772][root][INFO] - Training Epoch: 2/2, step 1804/7134 completed (loss: 0.03437431529164314, acc: 0.9914004802703857)
[2024-12-17 02:40:53,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:54,105][root][INFO] - Training Epoch: 2/2, step 1805/7134 completed (loss: 0.08786739408969879, acc: 0.9855700135231018)
[2024-12-17 02:40:54,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:54,430][root][INFO] - Training Epoch: 2/2, step 1806/7134 completed (loss: 0.0657428726553917, acc: 0.9828947186470032)
[2024-12-17 02:40:54,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:54,757][root][INFO] - Training Epoch: 2/2, step 1807/7134 completed (loss: 0.06200307980179787, acc: 0.987270176410675)
[2024-12-17 02:40:54,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:55,077][root][INFO] - Training Epoch: 2/2, step 1808/7134 completed (loss: 0.04033219814300537, acc: 0.9882965087890625)
[2024-12-17 02:40:55,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:55,434][root][INFO] - Training Epoch: 2/2, step 1809/7134 completed (loss: 0.0571947917342186, acc: 0.9878378510475159)
[2024-12-17 02:40:55,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:55,791][root][INFO] - Training Epoch: 2/2, step 1810/7134 completed (loss: 0.021851982921361923, acc: 0.9974226951599121)
[2024-12-17 02:40:55,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:56,131][root][INFO] - Training Epoch: 2/2, step 1811/7134 completed (loss: 0.09573544561862946, acc: 0.9715061187744141)
[2024-12-17 02:40:56,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:56,482][root][INFO] - Training Epoch: 2/2, step 1812/7134 completed (loss: 0.04453026503324509, acc: 0.9872449040412903)
[2024-12-17 02:40:56,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:56,842][root][INFO] - Training Epoch: 2/2, step 1813/7134 completed (loss: 0.0658864974975586, acc: 0.9868263602256775)
[2024-12-17 02:40:56,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:57,201][root][INFO] - Training Epoch: 2/2, step 1814/7134 completed (loss: 0.03165844827890396, acc: 0.9906759858131409)
[2024-12-17 02:40:57,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:57,540][root][INFO] - Training Epoch: 2/2, step 1815/7134 completed (loss: 0.03841090202331543, acc: 0.9928160905838013)
[2024-12-17 02:40:57,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:57,874][root][INFO] - Training Epoch: 2/2, step 1816/7134 completed (loss: 0.07656533271074295, acc: 0.9796556830406189)
[2024-12-17 02:40:58,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:58,232][root][INFO] - Training Epoch: 2/2, step 1817/7134 completed (loss: 0.06132941693067551, acc: 0.9880668520927429)
[2024-12-17 02:40:58,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:58,596][root][INFO] - Training Epoch: 2/2, step 1818/7134 completed (loss: 0.06711830198764801, acc: 0.983890950679779)
[2024-12-17 02:40:58,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:58,950][root][INFO] - Training Epoch: 2/2, step 1819/7134 completed (loss: 0.021386295557022095, acc: 0.9925187230110168)
[2024-12-17 02:40:59,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:59,359][root][INFO] - Training Epoch: 2/2, step 1820/7134 completed (loss: 0.04291869327425957, acc: 0.9890829920768738)
[2024-12-17 02:40:59,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:59,704][root][INFO] - Training Epoch: 2/2, step 1821/7134 completed (loss: 0.0488995760679245, acc: 0.9868708848953247)
[2024-12-17 02:40:59,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:00,024][root][INFO] - Training Epoch: 2/2, step 1822/7134 completed (loss: 0.01422471646219492, acc: 0.9941520690917969)
[2024-12-17 02:41:00,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:00,368][root][INFO] - Training Epoch: 2/2, step 1823/7134 completed (loss: 0.035386379808187485, acc: 0.9904502034187317)
[2024-12-17 02:41:00,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:00,717][root][INFO] - Training Epoch: 2/2, step 1824/7134 completed (loss: 0.023153729736804962, acc: 0.9913473129272461)
[2024-12-17 02:41:00,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:01,077][root][INFO] - Training Epoch: 2/2, step 1825/7134 completed (loss: 0.022112639620900154, acc: 0.9932735562324524)
[2024-12-17 02:41:01,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:01,430][root][INFO] - Training Epoch: 2/2, step 1826/7134 completed (loss: 0.0344739630818367, acc: 0.9878869652748108)
[2024-12-17 02:41:01,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:01,778][root][INFO] - Training Epoch: 2/2, step 1827/7134 completed (loss: 0.06896515935659409, acc: 0.981256902217865)
[2024-12-17 02:41:01,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:02,125][root][INFO] - Training Epoch: 2/2, step 1828/7134 completed (loss: 0.011384373530745506, acc: 0.9987130165100098)
[2024-12-17 02:41:02,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:02,474][root][INFO] - Training Epoch: 2/2, step 1829/7134 completed (loss: 0.03800530359148979, acc: 0.9875776171684265)
[2024-12-17 02:41:02,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:02,829][root][INFO] - Training Epoch: 2/2, step 1830/7134 completed (loss: 0.04204452037811279, acc: 0.990314781665802)
[2024-12-17 02:41:02,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:03,160][root][INFO] - Training Epoch: 2/2, step 1831/7134 completed (loss: 0.04115162044763565, acc: 0.984375)
[2024-12-17 02:41:03,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:03,486][root][INFO] - Training Epoch: 2/2, step 1832/7134 completed (loss: 0.09630036354064941, acc: 0.9805653691291809)
[2024-12-17 02:41:03,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:03,835][root][INFO] - Training Epoch: 2/2, step 1833/7134 completed (loss: 0.2376033216714859, acc: 0.9619450569152832)
[2024-12-17 02:41:03,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:04,192][root][INFO] - Training Epoch: 2/2, step 1834/7134 completed (loss: 0.08687392622232437, acc: 0.9816901683807373)
[2024-12-17 02:41:04,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:04,530][root][INFO] - Training Epoch: 2/2, step 1835/7134 completed (loss: 0.09558843076229095, acc: 0.9767441749572754)
[2024-12-17 02:41:04,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:04,878][root][INFO] - Training Epoch: 2/2, step 1836/7134 completed (loss: 0.05081980675458908, acc: 0.986997663974762)
[2024-12-17 02:41:04,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:05,225][root][INFO] - Training Epoch: 2/2, step 1837/7134 completed (loss: 0.03440679609775543, acc: 0.9877150058746338)
[2024-12-17 02:41:05,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:05,493][root][INFO] - Training Epoch: 2/2, step 1838/7134 completed (loss: 0.04580572247505188, acc: 0.9897959232330322)
[2024-12-17 02:41:05,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:05,851][root][INFO] - Training Epoch: 2/2, step 1839/7134 completed (loss: 0.035576336085796356, acc: 0.9896373152732849)
[2024-12-17 02:41:05,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:06,211][root][INFO] - Training Epoch: 2/2, step 1840/7134 completed (loss: 0.05686614289879799, acc: 0.9846583008766174)
[2024-12-17 02:41:06,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:06,557][root][INFO] - Training Epoch: 2/2, step 1841/7134 completed (loss: 0.05407135561108589, acc: 0.9808510541915894)
[2024-12-17 02:41:06,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:06,914][root][INFO] - Training Epoch: 2/2, step 1842/7134 completed (loss: 0.060412950813770294, acc: 0.9850339889526367)
[2024-12-17 02:41:07,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:07,247][root][INFO] - Training Epoch: 2/2, step 1843/7134 completed (loss: 0.09087749570608139, acc: 0.9775000214576721)
[2024-12-17 02:41:07,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:07,604][root][INFO] - Training Epoch: 2/2, step 1844/7134 completed (loss: 0.0507412888109684, acc: 0.9837398529052734)
[2024-12-17 02:41:07,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:07,967][root][INFO] - Training Epoch: 2/2, step 1845/7134 completed (loss: 0.07905902713537216, acc: 0.9832985401153564)
[2024-12-17 02:41:08,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:08,301][root][INFO] - Training Epoch: 2/2, step 1846/7134 completed (loss: 0.03962426260113716, acc: 0.9900285005569458)
[2024-12-17 02:41:08,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:08,666][root][INFO] - Training Epoch: 2/2, step 1847/7134 completed (loss: 0.042331937700510025, acc: 0.9877111911773682)
[2024-12-17 02:41:08,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:09,027][root][INFO] - Training Epoch: 2/2, step 1848/7134 completed (loss: 0.07538968324661255, acc: 0.9802259802818298)
[2024-12-17 02:41:09,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:09,370][root][INFO] - Training Epoch: 2/2, step 1849/7134 completed (loss: 0.07884104549884796, acc: 0.9841827750205994)
[2024-12-17 02:41:09,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:09,738][root][INFO] - Training Epoch: 2/2, step 1850/7134 completed (loss: 0.038614362478256226, acc: 0.9938875436782837)
[2024-12-17 02:41:09,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:10,108][root][INFO] - Training Epoch: 2/2, step 1851/7134 completed (loss: 0.04741905629634857, acc: 0.9865689873695374)
[2024-12-17 02:41:10,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:10,440][root][INFO] - Training Epoch: 2/2, step 1852/7134 completed (loss: 0.038660384714603424, acc: 0.989130437374115)
[2024-12-17 02:41:10,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:10,788][root][INFO] - Training Epoch: 2/2, step 1853/7134 completed (loss: 0.051926981657743454, acc: 0.9928229451179504)
[2024-12-17 02:41:10,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:11,136][root][INFO] - Training Epoch: 2/2, step 1854/7134 completed (loss: 0.08085166662931442, acc: 0.9762187600135803)
[2024-12-17 02:41:11,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:11,492][root][INFO] - Training Epoch: 2/2, step 1855/7134 completed (loss: 0.06304119527339935, acc: 0.9849711060523987)
[2024-12-17 02:41:11,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:11,832][root][INFO] - Training Epoch: 2/2, step 1856/7134 completed (loss: 0.049092020839452744, acc: 0.9864698648452759)
[2024-12-17 02:41:11,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:12,206][root][INFO] - Training Epoch: 2/2, step 1857/7134 completed (loss: 0.08093390613794327, acc: 0.9839901328086853)
[2024-12-17 02:41:12,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:12,565][root][INFO] - Training Epoch: 2/2, step 1858/7134 completed (loss: 0.029511617496609688, acc: 0.9928229451179504)
[2024-12-17 02:41:12,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:12,938][root][INFO] - Training Epoch: 2/2, step 1859/7134 completed (loss: 0.017499534413218498, acc: 0.9965870380401611)
[2024-12-17 02:41:13,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:13,299][root][INFO] - Training Epoch: 2/2, step 1860/7134 completed (loss: 0.026422766968607903, acc: 0.9911392331123352)
[2024-12-17 02:41:13,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:13,646][root][INFO] - Training Epoch: 2/2, step 1861/7134 completed (loss: 0.0580633245408535, acc: 0.9870800971984863)
[2024-12-17 02:41:13,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:13,995][root][INFO] - Training Epoch: 2/2, step 1862/7134 completed (loss: 0.0288617592304945, acc: 0.9932157397270203)
[2024-12-17 02:41:14,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:14,355][root][INFO] - Training Epoch: 2/2, step 1863/7134 completed (loss: 0.04374052956700325, acc: 0.9904076457023621)
[2024-12-17 02:41:14,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:14,689][root][INFO] - Training Epoch: 2/2, step 1864/7134 completed (loss: 0.1686839759349823, acc: 0.960544228553772)
[2024-12-17 02:41:14,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:15,005][root][INFO] - Training Epoch: 2/2, step 1865/7134 completed (loss: 0.04550500959157944, acc: 0.9847715497016907)
[2024-12-17 02:41:15,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:15,347][root][INFO] - Training Epoch: 2/2, step 1866/7134 completed (loss: 0.02528439089655876, acc: 0.9929971694946289)
[2024-12-17 02:41:15,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:15,714][root][INFO] - Training Epoch: 2/2, step 1867/7134 completed (loss: 0.033952534198760986, acc: 0.9899117350578308)
[2024-12-17 02:41:15,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:16,080][root][INFO] - Training Epoch: 2/2, step 1868/7134 completed (loss: 0.104485422372818, acc: 0.9735973477363586)
[2024-12-17 02:41:16,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:16,424][root][INFO] - Training Epoch: 2/2, step 1869/7134 completed (loss: 0.06193305924534798, acc: 0.9787928462028503)
[2024-12-17 02:41:16,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:16,751][root][INFO] - Training Epoch: 2/2, step 1870/7134 completed (loss: 0.026921771466732025, acc: 0.9908854365348816)
[2024-12-17 02:41:16,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:17,112][root][INFO] - Training Epoch: 2/2, step 1871/7134 completed (loss: 0.0728209912776947, acc: 0.9820554852485657)
[2024-12-17 02:41:17,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:17,370][root][INFO] - Training Epoch: 2/2, step 1872/7134 completed (loss: 0.5108538866043091, acc: 0.90055251121521)
[2024-12-17 02:41:17,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:17,701][root][INFO] - Training Epoch: 2/2, step 1873/7134 completed (loss: 0.19466811418533325, acc: 0.9548693299293518)
[2024-12-17 02:41:17,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:18,056][root][INFO] - Training Epoch: 2/2, step 1874/7134 completed (loss: 0.06531517207622528, acc: 0.9855832457542419)
[2024-12-17 02:41:18,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:18,375][root][INFO] - Training Epoch: 2/2, step 1875/7134 completed (loss: 0.04542561247944832, acc: 0.9890829920768738)
[2024-12-17 02:41:18,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:18,708][root][INFO] - Training Epoch: 2/2, step 1876/7134 completed (loss: 0.1535986065864563, acc: 0.9643463492393494)
[2024-12-17 02:41:18,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:19,061][root][INFO] - Training Epoch: 2/2, step 1877/7134 completed (loss: 0.07046198099851608, acc: 0.982367753982544)
[2024-12-17 02:41:19,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:19,408][root][INFO] - Training Epoch: 2/2, step 1878/7134 completed (loss: 0.08709609508514404, acc: 0.973805844783783)
[2024-12-17 02:41:19,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:19,735][root][INFO] - Training Epoch: 2/2, step 1879/7134 completed (loss: 0.09068189561367035, acc: 0.9722675085067749)
[2024-12-17 02:41:19,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:20,031][root][INFO] - Training Epoch: 2/2, step 1880/7134 completed (loss: 0.10175133496522903, acc: 0.9778671860694885)
[2024-12-17 02:41:20,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:20,368][root][INFO] - Training Epoch: 2/2, step 1881/7134 completed (loss: 0.1016559973359108, acc: 0.9738562107086182)
[2024-12-17 02:41:20,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:20,639][root][INFO] - Training Epoch: 2/2, step 1882/7134 completed (loss: 0.07201751321554184, acc: 0.9802955389022827)
[2024-12-17 02:41:20,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:20,975][root][INFO] - Training Epoch: 2/2, step 1883/7134 completed (loss: 0.07080511003732681, acc: 0.9842519760131836)
[2024-12-17 02:41:21,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:21,301][root][INFO] - Training Epoch: 2/2, step 1884/7134 completed (loss: 0.11084600538015366, acc: 0.9684044122695923)
[2024-12-17 02:41:21,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:21,627][root][INFO] - Training Epoch: 2/2, step 1885/7134 completed (loss: 0.0774284228682518, acc: 0.9737336039543152)
[2024-12-17 02:41:21,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:21,959][root][INFO] - Training Epoch: 2/2, step 1886/7134 completed (loss: 0.08817557245492935, acc: 0.9728600978851318)
[2024-12-17 02:41:22,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:22,282][root][INFO] - Training Epoch: 2/2, step 1887/7134 completed (loss: 0.08213773369789124, acc: 0.9791271090507507)
[2024-12-17 02:41:22,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:22,625][root][INFO] - Training Epoch: 2/2, step 1888/7134 completed (loss: 0.0972101241350174, acc: 0.9769673943519592)
[2024-12-17 02:41:22,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:22,984][root][INFO] - Training Epoch: 2/2, step 1889/7134 completed (loss: 0.06538685411214828, acc: 0.9768785834312439)
[2024-12-17 02:41:23,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:23,324][root][INFO] - Training Epoch: 2/2, step 1890/7134 completed (loss: 0.030493952333927155, acc: 0.9891641139984131)
[2024-12-17 02:41:23,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:23,656][root][INFO] - Training Epoch: 2/2, step 1891/7134 completed (loss: 0.09432105720043182, acc: 0.9740259647369385)
[2024-12-17 02:41:23,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:23,990][root][INFO] - Training Epoch: 2/2, step 1892/7134 completed (loss: 0.08212950080633163, acc: 0.9814528822898865)
[2024-12-17 02:41:24,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:24,308][root][INFO] - Training Epoch: 2/2, step 1893/7134 completed (loss: 0.03847084566950798, acc: 0.9875195026397705)
[2024-12-17 02:41:24,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:24,638][root][INFO] - Training Epoch: 2/2, step 1894/7134 completed (loss: 0.11186912655830383, acc: 0.9739583134651184)
[2024-12-17 02:41:24,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:24,945][root][INFO] - Training Epoch: 2/2, step 1895/7134 completed (loss: 0.29391220211982727, acc: 0.9313725233078003)
[2024-12-17 02:41:25,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:25,278][root][INFO] - Training Epoch: 2/2, step 1896/7134 completed (loss: 0.09366156905889511, acc: 0.981176495552063)
[2024-12-17 02:41:25,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:25,617][root][INFO] - Training Epoch: 2/2, step 1897/7134 completed (loss: 0.037735797464847565, acc: 0.9907407164573669)
[2024-12-17 02:41:25,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:25,947][root][INFO] - Training Epoch: 2/2, step 1898/7134 completed (loss: 0.06096772477030754, acc: 0.9834162592887878)
[2024-12-17 02:41:26,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:26,234][root][INFO] - Training Epoch: 2/2, step 1899/7134 completed (loss: 0.08094220608472824, acc: 0.9819168448448181)
[2024-12-17 02:41:26,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:26,564][root][INFO] - Training Epoch: 2/2, step 1900/7134 completed (loss: 0.03699299693107605, acc: 0.9886731505393982)
[2024-12-17 02:41:26,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:26,894][root][INFO] - Training Epoch: 2/2, step 1901/7134 completed (loss: 0.07822350412607193, acc: 0.9835466146469116)
[2024-12-17 02:41:26,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:27,212][root][INFO] - Training Epoch: 2/2, step 1902/7134 completed (loss: 0.03951495885848999, acc: 0.9894551634788513)
[2024-12-17 02:41:27,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:27,545][root][INFO] - Training Epoch: 2/2, step 1903/7134 completed (loss: 0.04658757150173187, acc: 0.9861111044883728)
[2024-12-17 02:41:27,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:27,861][root][INFO] - Training Epoch: 2/2, step 1904/7134 completed (loss: 0.048555269837379456, acc: 0.9872881174087524)
[2024-12-17 02:41:27,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:28,178][root][INFO] - Training Epoch: 2/2, step 1905/7134 completed (loss: 0.07123306393623352, acc: 0.9754601120948792)
[2024-12-17 02:41:28,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:28,493][root][INFO] - Training Epoch: 2/2, step 1906/7134 completed (loss: 0.060788728296756744, acc: 0.9824561476707458)
[2024-12-17 02:41:28,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:28,814][root][INFO] - Training Epoch: 2/2, step 1907/7134 completed (loss: 0.05941423773765564, acc: 0.9815126061439514)
[2024-12-17 02:41:28,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:29,156][root][INFO] - Training Epoch: 2/2, step 1908/7134 completed (loss: 0.04593517258763313, acc: 0.9903329610824585)
[2024-12-17 02:41:29,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:29,484][root][INFO] - Training Epoch: 2/2, step 1909/7134 completed (loss: 0.050879061222076416, acc: 0.9867549538612366)
[2024-12-17 02:41:29,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:29,836][root][INFO] - Training Epoch: 2/2, step 1910/7134 completed (loss: 0.06504492461681366, acc: 0.9868420958518982)
[2024-12-17 02:41:29,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:30,183][root][INFO] - Training Epoch: 2/2, step 1911/7134 completed (loss: 0.044218748807907104, acc: 0.987864077091217)
[2024-12-17 02:41:30,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:30,530][root][INFO] - Training Epoch: 2/2, step 1912/7134 completed (loss: 0.01531143393367529, acc: 0.9946737885475159)
[2024-12-17 02:41:30,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:30,829][root][INFO] - Training Epoch: 2/2, step 1913/7134 completed (loss: 0.09575778990983963, acc: 0.9870129823684692)
[2024-12-17 02:41:30,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:31,180][root][INFO] - Training Epoch: 2/2, step 1914/7134 completed (loss: 0.06513843685388565, acc: 0.9824086427688599)
[2024-12-17 02:41:31,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:31,514][root][INFO] - Training Epoch: 2/2, step 1915/7134 completed (loss: 0.056585103273391724, acc: 0.9836868047714233)
[2024-12-17 02:41:31,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:31,861][root][INFO] - Training Epoch: 2/2, step 1916/7134 completed (loss: 0.05055494233965874, acc: 0.9817296266555786)
[2024-12-17 02:41:31,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:32,214][root][INFO] - Training Epoch: 2/2, step 1917/7134 completed (loss: 0.046555906534194946, acc: 0.9887955188751221)
[2024-12-17 02:41:32,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:32,546][root][INFO] - Training Epoch: 2/2, step 1918/7134 completed (loss: 0.0682981014251709, acc: 0.9890282154083252)
[2024-12-17 02:41:32,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:32,908][root][INFO] - Training Epoch: 2/2, step 1919/7134 completed (loss: 0.04978920519351959, acc: 0.9885222315788269)
[2024-12-17 02:41:33,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:33,250][root][INFO] - Training Epoch: 2/2, step 1920/7134 completed (loss: 0.03229297697544098, acc: 0.9891975522041321)
[2024-12-17 02:41:33,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:33,583][root][INFO] - Training Epoch: 2/2, step 1921/7134 completed (loss: 0.060313839465379715, acc: 0.9806094169616699)
[2024-12-17 02:41:33,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:33,954][root][INFO] - Training Epoch: 2/2, step 1922/7134 completed (loss: 0.036323182284832, acc: 0.9920477271080017)
[2024-12-17 02:41:34,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:34,289][root][INFO] - Training Epoch: 2/2, step 1923/7134 completed (loss: 0.04126637428998947, acc: 0.9882746934890747)
[2024-12-17 02:41:34,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:34,634][root][INFO] - Training Epoch: 2/2, step 1924/7134 completed (loss: 0.057987064123153687, acc: 0.9871244430541992)
[2024-12-17 02:41:34,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:35,003][root][INFO] - Training Epoch: 2/2, step 1925/7134 completed (loss: 0.08362817019224167, acc: 0.9777777791023254)
[2024-12-17 02:41:35,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:35,365][root][INFO] - Training Epoch: 2/2, step 1926/7134 completed (loss: 0.022608991712331772, acc: 0.9959142208099365)
[2024-12-17 02:41:35,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:35,730][root][INFO] - Training Epoch: 2/2, step 1927/7134 completed (loss: 0.05867818742990494, acc: 0.99005526304245)
[2024-12-17 02:41:35,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:36,100][root][INFO] - Training Epoch: 2/2, step 1928/7134 completed (loss: 0.04472756013274193, acc: 0.9908814430236816)
[2024-12-17 02:41:36,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:36,424][root][INFO] - Training Epoch: 2/2, step 1929/7134 completed (loss: 0.029268711805343628, acc: 0.994350254535675)
[2024-12-17 02:41:36,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:36,790][root][INFO] - Training Epoch: 2/2, step 1930/7134 completed (loss: 0.0853978842496872, acc: 0.9790025949478149)
[2024-12-17 02:41:36,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:37,156][root][INFO] - Training Epoch: 2/2, step 1931/7134 completed (loss: 0.1333712786436081, acc: 0.975979745388031)
[2024-12-17 02:41:37,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:37,465][root][INFO] - Training Epoch: 2/2, step 1932/7134 completed (loss: 0.12834832072257996, acc: 0.9716417789459229)
[2024-12-17 02:41:37,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:37,813][root][INFO] - Training Epoch: 2/2, step 1933/7134 completed (loss: 0.17280592024326324, acc: 0.9691876769065857)
[2024-12-17 02:41:37,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:38,137][root][INFO] - Training Epoch: 2/2, step 1934/7134 completed (loss: 0.03558496758341789, acc: 0.9929378628730774)
[2024-12-17 02:41:38,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:38,495][root][INFO] - Training Epoch: 2/2, step 1935/7134 completed (loss: 0.14251962304115295, acc: 0.9665210843086243)
[2024-12-17 02:41:38,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:38,848][root][INFO] - Training Epoch: 2/2, step 1936/7134 completed (loss: 0.03836634382605553, acc: 0.9905213117599487)
[2024-12-17 02:41:38,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:39,166][root][INFO] - Training Epoch: 2/2, step 1937/7134 completed (loss: 0.07840777188539505, acc: 0.9805194735527039)
[2024-12-17 02:41:39,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:39,517][root][INFO] - Training Epoch: 2/2, step 1938/7134 completed (loss: 0.1269472986459732, acc: 0.9786324501037598)
[2024-12-17 02:41:39,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:39,864][root][INFO] - Training Epoch: 2/2, step 1939/7134 completed (loss: 0.06846265494823456, acc: 0.9830508232116699)
[2024-12-17 02:41:39,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:40,211][root][INFO] - Training Epoch: 2/2, step 1940/7134 completed (loss: 0.08970864117145538, acc: 0.9768707752227783)
[2024-12-17 02:41:40,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:40,565][root][INFO] - Training Epoch: 2/2, step 1941/7134 completed (loss: 0.10332372039556503, acc: 0.970588207244873)
[2024-12-17 02:41:40,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:40,868][root][INFO] - Training Epoch: 2/2, step 1942/7134 completed (loss: 0.06756956875324249, acc: 0.9837398529052734)
[2024-12-17 02:41:40,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:41,233][root][INFO] - Training Epoch: 2/2, step 1943/7134 completed (loss: 0.09699402004480362, acc: 0.9719512462615967)
[2024-12-17 02:41:41,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:41,581][root][INFO] - Training Epoch: 2/2, step 1944/7134 completed (loss: 0.07590680569410324, acc: 0.974405825138092)
[2024-12-17 02:41:41,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:41,928][root][INFO] - Training Epoch: 2/2, step 1945/7134 completed (loss: 0.07261810451745987, acc: 0.9803149700164795)
[2024-12-17 02:41:42,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:42,272][root][INFO] - Training Epoch: 2/2, step 1946/7134 completed (loss: 0.06480630487203598, acc: 0.9745330810546875)
[2024-12-17 02:41:42,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:42,615][root][INFO] - Training Epoch: 2/2, step 1947/7134 completed (loss: 0.08960701525211334, acc: 0.9697368144989014)
[2024-12-17 02:41:42,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:42,939][root][INFO] - Training Epoch: 2/2, step 1948/7134 completed (loss: 0.12336514890193939, acc: 0.9639468789100647)
[2024-12-17 02:41:43,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:43,221][root][INFO] - Training Epoch: 2/2, step 1949/7134 completed (loss: 0.06584995239973068, acc: 0.9832776188850403)
[2024-12-17 02:41:43,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:43,571][root][INFO] - Training Epoch: 2/2, step 1950/7134 completed (loss: 0.08371694386005402, acc: 0.9817517995834351)
[2024-12-17 02:41:43,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:43,973][root][INFO] - Training Epoch: 2/2, step 1951/7134 completed (loss: 0.07272425293922424, acc: 0.9799330830574036)
[2024-12-17 02:41:44,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:44,311][root][INFO] - Training Epoch: 2/2, step 1952/7134 completed (loss: 0.11898971349000931, acc: 0.9700499176979065)
[2024-12-17 02:41:44,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:44,651][root][INFO] - Training Epoch: 2/2, step 1953/7134 completed (loss: 0.05217175558209419, acc: 0.9829721450805664)
[2024-12-17 02:41:44,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:44,940][root][INFO] - Training Epoch: 2/2, step 1954/7134 completed (loss: 0.056404344737529755, acc: 0.9804878234863281)
[2024-12-17 02:41:45,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:45,264][root][INFO] - Training Epoch: 2/2, step 1955/7134 completed (loss: 0.0518110916018486, acc: 0.9894551634788513)
[2024-12-17 02:41:45,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:45,525][root][INFO] - Training Epoch: 2/2, step 1956/7134 completed (loss: 0.02669753134250641, acc: 0.9946236610412598)
[2024-12-17 02:41:45,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:45,842][root][INFO] - Training Epoch: 2/2, step 1957/7134 completed (loss: 0.06224362552165985, acc: 0.9814814925193787)
[2024-12-17 02:41:45,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:46,076][root][INFO] - Training Epoch: 2/2, step 1958/7134 completed (loss: 0.07363396137952805, acc: 0.9713466763496399)
[2024-12-17 02:41:46,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:46,385][root][INFO] - Training Epoch: 2/2, step 1959/7134 completed (loss: 0.04926444962620735, acc: 0.9893389940261841)
[2024-12-17 02:41:46,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:46,720][root][INFO] - Training Epoch: 2/2, step 1960/7134 completed (loss: 0.03621715307235718, acc: 0.9906014800071716)
[2024-12-17 02:41:46,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:47,013][root][INFO] - Training Epoch: 2/2, step 1961/7134 completed (loss: 0.055035945028066635, acc: 0.9832776188850403)
[2024-12-17 02:41:47,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:47,380][root][INFO] - Training Epoch: 2/2, step 1962/7134 completed (loss: 0.06510672718286514, acc: 0.9832402467727661)
[2024-12-17 02:41:47,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:47,708][root][INFO] - Training Epoch: 2/2, step 1963/7134 completed (loss: 0.05796017497777939, acc: 0.9810017347335815)
[2024-12-17 02:41:47,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:48,052][root][INFO] - Training Epoch: 2/2, step 1964/7134 completed (loss: 0.06090031936764717, acc: 0.9829059839248657)
[2024-12-17 02:41:48,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:48,386][root][INFO] - Training Epoch: 2/2, step 1965/7134 completed (loss: 0.03580566123127937, acc: 0.9888424277305603)
[2024-12-17 02:41:48,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:48,715][root][INFO] - Training Epoch: 2/2, step 1966/7134 completed (loss: 0.058020882308483124, acc: 0.9847095012664795)
[2024-12-17 02:41:48,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:49,073][root][INFO] - Training Epoch: 2/2, step 1967/7134 completed (loss: 0.0782812312245369, acc: 0.9770700931549072)
[2024-12-17 02:41:49,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:49,428][root][INFO] - Training Epoch: 2/2, step 1968/7134 completed (loss: 0.04086316376924515, acc: 0.9888888597488403)
[2024-12-17 02:41:49,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:49,760][root][INFO] - Training Epoch: 2/2, step 1969/7134 completed (loss: 0.07084077596664429, acc: 0.9826666712760925)
[2024-12-17 02:41:49,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:50,119][root][INFO] - Training Epoch: 2/2, step 1970/7134 completed (loss: 0.045800596475601196, acc: 0.9861963391304016)
[2024-12-17 02:41:50,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:50,444][root][INFO] - Training Epoch: 2/2, step 1971/7134 completed (loss: 0.06950227916240692, acc: 0.982758641242981)
[2024-12-17 02:41:50,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:50,749][root][INFO] - Training Epoch: 2/2, step 1972/7134 completed (loss: 0.24790966510772705, acc: 0.9434889554977417)
[2024-12-17 02:41:50,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:51,068][root][INFO] - Training Epoch: 2/2, step 1973/7134 completed (loss: 0.1352488249540329, acc: 0.9599999785423279)
[2024-12-17 02:41:51,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:51,428][root][INFO] - Training Epoch: 2/2, step 1974/7134 completed (loss: 0.042326781898736954, acc: 0.9899497628211975)
[2024-12-17 02:41:51,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:51,765][root][INFO] - Training Epoch: 2/2, step 1975/7134 completed (loss: 0.029239870607852936, acc: 0.9924242496490479)
[2024-12-17 02:41:51,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:52,125][root][INFO] - Training Epoch: 2/2, step 1976/7134 completed (loss: 0.05595938861370087, acc: 0.9841449856758118)
[2024-12-17 02:41:52,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:52,475][root][INFO] - Training Epoch: 2/2, step 1977/7134 completed (loss: 0.06287333369255066, acc: 0.9840579628944397)
[2024-12-17 02:41:52,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:52,813][root][INFO] - Training Epoch: 2/2, step 1978/7134 completed (loss: 0.026453817263245583, acc: 0.991946280002594)
[2024-12-17 02:41:52,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:53,177][root][INFO] - Training Epoch: 2/2, step 1979/7134 completed (loss: 0.030586689710617065, acc: 0.9947916865348816)
[2024-12-17 02:41:53,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:53,547][root][INFO] - Training Epoch: 2/2, step 1980/7134 completed (loss: 0.1319860816001892, acc: 0.9726206064224243)
[2024-12-17 02:41:53,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:53,903][root][INFO] - Training Epoch: 2/2, step 1981/7134 completed (loss: 0.0526253879070282, acc: 0.9874125719070435)
[2024-12-17 02:41:54,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:54,235][root][INFO] - Training Epoch: 2/2, step 1982/7134 completed (loss: 0.03960079699754715, acc: 0.9909909963607788)
[2024-12-17 02:41:54,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:54,566][root][INFO] - Training Epoch: 2/2, step 1983/7134 completed (loss: 0.032756488770246506, acc: 0.9923664331436157)
[2024-12-17 02:41:54,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:54,908][root][INFO] - Training Epoch: 2/2, step 1984/7134 completed (loss: 0.0247553288936615, acc: 0.9919246435165405)
[2024-12-17 02:41:55,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:55,244][root][INFO] - Training Epoch: 2/2, step 1985/7134 completed (loss: 0.05056692659854889, acc: 0.9860724210739136)
[2024-12-17 02:41:55,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:55,598][root][INFO] - Training Epoch: 2/2, step 1986/7134 completed (loss: 0.06925078481435776, acc: 0.9897040128707886)
[2024-12-17 02:41:55,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:55,949][root][INFO] - Training Epoch: 2/2, step 1987/7134 completed (loss: 0.0505201630294323, acc: 0.9872521162033081)
[2024-12-17 02:41:56,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:56,299][root][INFO] - Training Epoch: 2/2, step 1988/7134 completed (loss: 0.0599711537361145, acc: 0.9828816056251526)
[2024-12-17 02:41:56,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:56,618][root][INFO] - Training Epoch: 2/2, step 1989/7134 completed (loss: 0.0786176398396492, acc: 0.980861246585846)
[2024-12-17 02:41:56,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:56,976][root][INFO] - Training Epoch: 2/2, step 1990/7134 completed (loss: 0.054281603544950485, acc: 0.9866504669189453)
[2024-12-17 02:41:57,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:57,329][root][INFO] - Training Epoch: 2/2, step 1991/7134 completed (loss: 0.03438980132341385, acc: 0.9883720874786377)
[2024-12-17 02:41:57,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:57,669][root][INFO] - Training Epoch: 2/2, step 1992/7134 completed (loss: 0.04880490526556969, acc: 0.987596869468689)
[2024-12-17 02:41:57,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:57,996][root][INFO] - Training Epoch: 2/2, step 1993/7134 completed (loss: 0.01807006634771824, acc: 0.9964850544929504)
[2024-12-17 02:41:58,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:58,326][root][INFO] - Training Epoch: 2/2, step 1994/7134 completed (loss: 0.01561584509909153, acc: 0.9965517520904541)
[2024-12-17 02:41:58,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:58,656][root][INFO] - Training Epoch: 2/2, step 1995/7134 completed (loss: 0.02936582826077938, acc: 0.9953632354736328)
[2024-12-17 02:41:58,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:58,987][root][INFO] - Training Epoch: 2/2, step 1996/7134 completed (loss: 0.040612779557704926, acc: 0.9900826215744019)
[2024-12-17 02:41:59,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:59,318][root][INFO] - Training Epoch: 2/2, step 1997/7134 completed (loss: 0.03869796171784401, acc: 0.9927219748497009)
[2024-12-17 02:41:59,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:59,644][root][INFO] - Training Epoch: 2/2, step 1998/7134 completed (loss: 0.028978707268834114, acc: 0.9921507239341736)
[2024-12-17 02:41:59,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:59,977][root][INFO] - Training Epoch: 2/2, step 1999/7134 completed (loss: 0.038290441036224365, acc: 0.9864176511764526)
[2024-12-17 02:42:00,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:00,304][root][INFO] - Training Epoch: 2/2, step 2000/7134 completed (loss: 0.04607584699988365, acc: 0.988959014415741)
[2024-12-17 02:42:00,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:00,617][root][INFO] - Training Epoch: 2/2, step 2001/7134 completed (loss: 0.03144175186753273, acc: 0.9909090995788574)
[2024-12-17 02:42:00,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:00,957][root][INFO] - Training Epoch: 2/2, step 2002/7134 completed (loss: 0.046606630086898804, acc: 0.9930434823036194)
[2024-12-17 02:42:01,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:01,233][root][INFO] - Training Epoch: 2/2, step 2003/7134 completed (loss: 0.0321725457906723, acc: 0.987500011920929)
[2024-12-17 02:42:01,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:01,523][root][INFO] - Training Epoch: 2/2, step 2004/7134 completed (loss: 0.17978379130363464, acc: 0.9599156379699707)
[2024-12-17 02:42:01,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:01,919][root][INFO] - Training Epoch: 2/2, step 2005/7134 completed (loss: 0.1445249319076538, acc: 0.9726027250289917)
[2024-12-17 02:42:02,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:02,212][root][INFO] - Training Epoch: 2/2, step 2006/7134 completed (loss: 0.04021308943629265, acc: 0.9884726405143738)
[2024-12-17 02:42:02,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:02,537][root][INFO] - Training Epoch: 2/2, step 2007/7134 completed (loss: 0.0739218071103096, acc: 0.9899598360061646)
[2024-12-17 02:42:02,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:02,858][root][INFO] - Training Epoch: 2/2, step 2008/7134 completed (loss: 0.07574617862701416, acc: 0.9804270267486572)
[2024-12-17 02:42:02,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:03,157][root][INFO] - Training Epoch: 2/2, step 2009/7134 completed (loss: 0.05312811955809593, acc: 0.9855595827102661)
[2024-12-17 02:42:03,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:03,477][root][INFO] - Training Epoch: 2/2, step 2010/7134 completed (loss: 0.03300519660115242, acc: 0.9914236664772034)
[2024-12-17 02:42:03,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:03,786][root][INFO] - Training Epoch: 2/2, step 2011/7134 completed (loss: 0.025568144395947456, acc: 0.9921721816062927)
[2024-12-17 02:42:03,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:04,104][root][INFO] - Training Epoch: 2/2, step 2012/7134 completed (loss: 0.04485761374235153, acc: 0.9873149991035461)
[2024-12-17 02:42:04,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:04,444][root][INFO] - Training Epoch: 2/2, step 2013/7134 completed (loss: 0.03143340349197388, acc: 0.9940000176429749)
[2024-12-17 02:42:04,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:04,786][root][INFO] - Training Epoch: 2/2, step 2014/7134 completed (loss: 0.03264353424310684, acc: 0.9889763593673706)
[2024-12-17 02:42:04,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:05,121][root][INFO] - Training Epoch: 2/2, step 2015/7134 completed (loss: 0.04080250859260559, acc: 0.9901315569877625)
[2024-12-17 02:42:05,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:05,467][root][INFO] - Training Epoch: 2/2, step 2016/7134 completed (loss: 0.0970430001616478, acc: 0.9753845930099487)
[2024-12-17 02:42:05,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:05,801][root][INFO] - Training Epoch: 2/2, step 2017/7134 completed (loss: 0.08978384733200073, acc: 0.9756757020950317)
[2024-12-17 02:42:05,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:06,131][root][INFO] - Training Epoch: 2/2, step 2018/7134 completed (loss: 0.027146318927407265, acc: 0.9910256266593933)
[2024-12-17 02:42:06,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:06,455][root][INFO] - Training Epoch: 2/2, step 2019/7134 completed (loss: 0.04880298301577568, acc: 0.9889655113220215)
[2024-12-17 02:42:06,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:06,793][root][INFO] - Training Epoch: 2/2, step 2020/7134 completed (loss: 0.02983235940337181, acc: 0.9881556630134583)
[2024-12-17 02:42:06,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:07,133][root][INFO] - Training Epoch: 2/2, step 2021/7134 completed (loss: 0.055556219071149826, acc: 0.9857142567634583)
[2024-12-17 02:42:07,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:07,449][root][INFO] - Training Epoch: 2/2, step 2022/7134 completed (loss: 0.08569187670946121, acc: 0.9792027473449707)
[2024-12-17 02:42:07,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:07,784][root][INFO] - Training Epoch: 2/2, step 2023/7134 completed (loss: 0.044856008142232895, acc: 0.985401451587677)
[2024-12-17 02:42:07,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:08,132][root][INFO] - Training Epoch: 2/2, step 2024/7134 completed (loss: 0.054417286068201065, acc: 0.9861111044883728)
[2024-12-17 02:42:08,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:08,479][root][INFO] - Training Epoch: 2/2, step 2025/7134 completed (loss: 0.03684509918093681, acc: 0.9919999837875366)
[2024-12-17 02:42:08,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:08,817][root][INFO] - Training Epoch: 2/2, step 2026/7134 completed (loss: 0.06775902211666107, acc: 0.9804216623306274)
[2024-12-17 02:42:08,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:09,165][root][INFO] - Training Epoch: 2/2, step 2027/7134 completed (loss: 0.04421976953744888, acc: 0.985049843788147)
[2024-12-17 02:42:09,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:09,505][root][INFO] - Training Epoch: 2/2, step 2028/7134 completed (loss: 0.05494358763098717, acc: 0.9853801131248474)
[2024-12-17 02:42:09,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:09,850][root][INFO] - Training Epoch: 2/2, step 2029/7134 completed (loss: 0.05458483472466469, acc: 0.9829545617103577)
[2024-12-17 02:42:09,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:10,166][root][INFO] - Training Epoch: 2/2, step 2030/7134 completed (loss: 0.06790345907211304, acc: 0.9739263653755188)
[2024-12-17 02:42:10,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:10,524][root][INFO] - Training Epoch: 2/2, step 2031/7134 completed (loss: 0.05460742115974426, acc: 0.9889570474624634)
[2024-12-17 02:42:10,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:10,861][root][INFO] - Training Epoch: 2/2, step 2032/7134 completed (loss: 0.06909459084272385, acc: 0.9865591526031494)
[2024-12-17 02:42:10,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:11,211][root][INFO] - Training Epoch: 2/2, step 2033/7134 completed (loss: 0.05119318142533302, acc: 0.9879931211471558)
[2024-12-17 02:42:11,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:11,531][root][INFO] - Training Epoch: 2/2, step 2034/7134 completed (loss: 0.06751471757888794, acc: 0.9831546545028687)
[2024-12-17 02:42:11,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:11,885][root][INFO] - Training Epoch: 2/2, step 2035/7134 completed (loss: 0.032318320125341415, acc: 0.9925280213356018)
[2024-12-17 02:42:11,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:12,191][root][INFO] - Training Epoch: 2/2, step 2036/7134 completed (loss: 0.044397983700037, acc: 0.991349458694458)
[2024-12-17 02:42:12,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:12,542][root][INFO] - Training Epoch: 2/2, step 2037/7134 completed (loss: 0.02932577393949032, acc: 0.9955489635467529)
[2024-12-17 02:42:12,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:12,898][root][INFO] - Training Epoch: 2/2, step 2038/7134 completed (loss: 0.030300753191113472, acc: 0.9929078221321106)
[2024-12-17 02:42:13,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:13,231][root][INFO] - Training Epoch: 2/2, step 2039/7134 completed (loss: 0.021855173632502556, acc: 0.9981982111930847)
[2024-12-17 02:42:13,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:13,531][root][INFO] - Training Epoch: 2/2, step 2040/7134 completed (loss: 0.046754833310842514, acc: 0.9938271641731262)
[2024-12-17 02:42:13,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:13,873][root][INFO] - Training Epoch: 2/2, step 2041/7134 completed (loss: 0.026270754635334015, acc: 0.9917582273483276)
[2024-12-17 02:42:14,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:14,198][root][INFO] - Training Epoch: 2/2, step 2042/7134 completed (loss: 0.0454351045191288, acc: 0.9858871102333069)
[2024-12-17 02:42:14,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:14,524][root][INFO] - Training Epoch: 2/2, step 2043/7134 completed (loss: 0.0569877028465271, acc: 0.989062488079071)
[2024-12-17 02:42:14,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:14,868][root][INFO] - Training Epoch: 2/2, step 2044/7134 completed (loss: 0.03437066078186035, acc: 0.991055428981781)
[2024-12-17 02:42:15,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:15,193][root][INFO] - Training Epoch: 2/2, step 2045/7134 completed (loss: 0.022935528308153152, acc: 0.9963833689689636)
[2024-12-17 02:42:15,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:15,485][root][INFO] - Training Epoch: 2/2, step 2046/7134 completed (loss: 0.03124896064400673, acc: 0.9898374080657959)
[2024-12-17 02:42:15,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:15,824][root][INFO] - Training Epoch: 2/2, step 2047/7134 completed (loss: 0.04092792049050331, acc: 0.9833055138587952)
[2024-12-17 02:42:15,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:16,159][root][INFO] - Training Epoch: 2/2, step 2048/7134 completed (loss: 0.07073966413736343, acc: 0.9835575222969055)
[2024-12-17 02:42:16,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:16,490][root][INFO] - Training Epoch: 2/2, step 2049/7134 completed (loss: 0.09811709076166153, acc: 0.974117636680603)
[2024-12-17 02:42:16,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:16,805][root][INFO] - Training Epoch: 2/2, step 2050/7134 completed (loss: 0.0965181365609169, acc: 0.9829059839248657)
[2024-12-17 02:42:16,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:17,130][root][INFO] - Training Epoch: 2/2, step 2051/7134 completed (loss: 0.049567271023988724, acc: 0.986328125)
[2024-12-17 02:42:17,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:17,465][root][INFO] - Training Epoch: 2/2, step 2052/7134 completed (loss: 0.11574593186378479, acc: 0.9744027256965637)
[2024-12-17 02:42:17,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:17,793][root][INFO] - Training Epoch: 2/2, step 2053/7134 completed (loss: 0.04835111275315285, acc: 0.9900000095367432)
[2024-12-17 02:42:17,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:18,137][root][INFO] - Training Epoch: 2/2, step 2054/7134 completed (loss: 0.13627099990844727, acc: 0.9601910710334778)
[2024-12-17 02:42:18,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:18,479][root][INFO] - Training Epoch: 2/2, step 2055/7134 completed (loss: 0.10135999321937561, acc: 0.9795275330543518)
[2024-12-17 02:42:18,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:18,843][root][INFO] - Training Epoch: 2/2, step 2056/7134 completed (loss: 0.06304264813661575, acc: 0.9831387996673584)
[2024-12-17 02:42:18,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:19,179][root][INFO] - Training Epoch: 2/2, step 2057/7134 completed (loss: 0.07222016900777817, acc: 0.975576639175415)
[2024-12-17 02:42:19,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:19,535][root][INFO] - Training Epoch: 2/2, step 2058/7134 completed (loss: 0.12269585579633713, acc: 0.9698708653450012)
[2024-12-17 02:42:19,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:19,874][root][INFO] - Training Epoch: 2/2, step 2059/7134 completed (loss: 0.14180561900138855, acc: 0.9688041806221008)
[2024-12-17 02:42:19,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:20,221][root][INFO] - Training Epoch: 2/2, step 2060/7134 completed (loss: 0.06839162856340408, acc: 0.9828326106071472)
[2024-12-17 02:42:20,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:20,565][root][INFO] - Training Epoch: 2/2, step 2061/7134 completed (loss: 0.08717496693134308, acc: 0.9787535667419434)
[2024-12-17 02:42:20,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:20,890][root][INFO] - Training Epoch: 2/2, step 2062/7134 completed (loss: 0.0990629494190216, acc: 0.9696394801139832)
[2024-12-17 02:42:21,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:21,204][root][INFO] - Training Epoch: 2/2, step 2063/7134 completed (loss: 0.11781375110149384, acc: 0.97947758436203)
[2024-12-17 02:42:21,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:21,540][root][INFO] - Training Epoch: 2/2, step 2064/7134 completed (loss: 0.027618730440735817, acc: 0.989062488079071)
[2024-12-17 02:42:21,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:21,864][root][INFO] - Training Epoch: 2/2, step 2065/7134 completed (loss: 0.1000571995973587, acc: 0.9748031497001648)
[2024-12-17 02:42:21,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:22,152][root][INFO] - Training Epoch: 2/2, step 2066/7134 completed (loss: 0.04706184193491936, acc: 0.9899799823760986)
[2024-12-17 02:42:22,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:22,475][root][INFO] - Training Epoch: 2/2, step 2067/7134 completed (loss: 0.04272175580263138, acc: 0.9867172837257385)
[2024-12-17 02:42:22,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:22,801][root][INFO] - Training Epoch: 2/2, step 2068/7134 completed (loss: 0.06682524085044861, acc: 0.976580798625946)
[2024-12-17 02:42:22,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:23,148][root][INFO] - Training Epoch: 2/2, step 2069/7134 completed (loss: 0.03604597598314285, acc: 0.989230751991272)
[2024-12-17 02:42:23,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:23,469][root][INFO] - Training Epoch: 2/2, step 2070/7134 completed (loss: 0.054200418293476105, acc: 0.9847908616065979)
[2024-12-17 02:42:23,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:23,794][root][INFO] - Training Epoch: 2/2, step 2071/7134 completed (loss: 0.03488299623131752, acc: 0.9929742217063904)
[2024-12-17 02:42:23,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:24,111][root][INFO] - Training Epoch: 2/2, step 2072/7134 completed (loss: 0.038233015686273575, acc: 0.9925742745399475)
[2024-12-17 02:42:24,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:24,426][root][INFO] - Training Epoch: 2/2, step 2073/7134 completed (loss: 0.046501025557518005, acc: 0.9807692170143127)
[2024-12-17 02:42:24,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:24,790][root][INFO] - Training Epoch: 2/2, step 2074/7134 completed (loss: 0.05999971181154251, acc: 0.98591548204422)
[2024-12-17 02:42:24,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:25,154][root][INFO] - Training Epoch: 2/2, step 2075/7134 completed (loss: 0.0854673683643341, acc: 0.9699499011039734)
[2024-12-17 02:42:25,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:25,505][root][INFO] - Training Epoch: 2/2, step 2076/7134 completed (loss: 0.04970727860927582, acc: 0.9861538410186768)
[2024-12-17 02:42:25,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:25,849][root][INFO] - Training Epoch: 2/2, step 2077/7134 completed (loss: 0.04871831834316254, acc: 0.9853917956352234)
[2024-12-17 02:42:25,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:26,212][root][INFO] - Training Epoch: 2/2, step 2078/7134 completed (loss: 0.0462535098195076, acc: 0.9872093200683594)
[2024-12-17 02:42:26,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:26,561][root][INFO] - Training Epoch: 2/2, step 2079/7134 completed (loss: 0.03142887353897095, acc: 0.988095223903656)
[2024-12-17 02:42:26,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:26,889][root][INFO] - Training Epoch: 2/2, step 2080/7134 completed (loss: 0.03687259554862976, acc: 0.9911764860153198)
[2024-12-17 02:42:26,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:27,225][root][INFO] - Training Epoch: 2/2, step 2081/7134 completed (loss: 0.03467706963419914, acc: 0.9883889555931091)
[2024-12-17 02:42:27,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:27,592][root][INFO] - Training Epoch: 2/2, step 2082/7134 completed (loss: 0.12417416274547577, acc: 0.9685534834861755)
[2024-12-17 02:42:27,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:27,894][root][INFO] - Training Epoch: 2/2, step 2083/7134 completed (loss: 0.06426261365413666, acc: 0.9888888597488403)
[2024-12-17 02:42:27,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:28,217][root][INFO] - Training Epoch: 2/2, step 2084/7134 completed (loss: 0.044008903205394745, acc: 0.989130437374115)
[2024-12-17 02:42:28,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:28,552][root][INFO] - Training Epoch: 2/2, step 2085/7134 completed (loss: 0.01913757063448429, acc: 0.996303141117096)
[2024-12-17 02:42:28,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:28,837][root][INFO] - Training Epoch: 2/2, step 2086/7134 completed (loss: 0.019610516726970673, acc: 0.9954338073730469)
[2024-12-17 02:42:28,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:29,182][root][INFO] - Training Epoch: 2/2, step 2087/7134 completed (loss: 0.015088614076375961, acc: 0.9971550703048706)
[2024-12-17 02:42:29,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:29,522][root][INFO] - Training Epoch: 2/2, step 2088/7134 completed (loss: 0.056435421109199524, acc: 0.9855907559394836)
[2024-12-17 02:42:29,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:29,867][root][INFO] - Training Epoch: 2/2, step 2089/7134 completed (loss: 0.029325343668460846, acc: 0.9905362725257874)
[2024-12-17 02:42:29,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:30,180][root][INFO] - Training Epoch: 2/2, step 2090/7134 completed (loss: 0.02161768451333046, acc: 0.9936808943748474)
[2024-12-17 02:42:30,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:30,498][root][INFO] - Training Epoch: 2/2, step 2091/7134 completed (loss: 0.03851670026779175, acc: 0.9898648858070374)
[2024-12-17 02:42:30,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:30,853][root][INFO] - Training Epoch: 2/2, step 2092/7134 completed (loss: 0.023231370374560356, acc: 0.9952681660652161)
[2024-12-17 02:42:30,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:31,213][root][INFO] - Training Epoch: 2/2, step 2093/7134 completed (loss: 0.028424564749002457, acc: 0.9932157397270203)
[2024-12-17 02:42:31,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:31,499][root][INFO] - Training Epoch: 2/2, step 2094/7134 completed (loss: 0.09445566684007645, acc: 0.9756592512130737)
[2024-12-17 02:42:31,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:31,847][root][INFO] - Training Epoch: 2/2, step 2095/7134 completed (loss: 0.048504021018743515, acc: 0.9894459247589111)
[2024-12-17 02:42:31,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:32,158][root][INFO] - Training Epoch: 2/2, step 2096/7134 completed (loss: 0.03520143777132034, acc: 0.9948275685310364)
[2024-12-17 02:42:32,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:32,482][root][INFO] - Training Epoch: 2/2, step 2097/7134 completed (loss: 0.03063712641596794, acc: 0.9901823401451111)
[2024-12-17 02:42:32,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:32,804][root][INFO] - Training Epoch: 2/2, step 2098/7134 completed (loss: 0.03091772273182869, acc: 0.9919614195823669)
[2024-12-17 02:42:32,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:33,116][root][INFO] - Training Epoch: 2/2, step 2099/7134 completed (loss: 0.03199521824717522, acc: 0.9926605224609375)
[2024-12-17 02:42:33,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:33,461][root][INFO] - Training Epoch: 2/2, step 2100/7134 completed (loss: 0.017870694398880005, acc: 0.9946879148483276)
[2024-12-17 02:42:33,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:33,794][root][INFO] - Training Epoch: 2/2, step 2101/7134 completed (loss: 0.03860970959067345, acc: 0.992443323135376)
[2024-12-17 02:42:33,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:34,106][root][INFO] - Training Epoch: 2/2, step 2102/7134 completed (loss: 0.04971066117286682, acc: 0.980867326259613)
[2024-12-17 02:42:34,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:34,430][root][INFO] - Training Epoch: 2/2, step 2103/7134 completed (loss: 0.05816735327243805, acc: 0.9831288456916809)
[2024-12-17 02:42:34,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:34,781][root][INFO] - Training Epoch: 2/2, step 2104/7134 completed (loss: 0.029333222657442093, acc: 0.9922680258750916)
[2024-12-17 02:42:34,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:35,100][root][INFO] - Training Epoch: 2/2, step 2105/7134 completed (loss: 0.09692066162824631, acc: 0.9718309640884399)
[2024-12-17 02:42:35,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:35,423][root][INFO] - Training Epoch: 2/2, step 2106/7134 completed (loss: 0.07446856796741486, acc: 0.9841954112052917)
[2024-12-17 02:42:35,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:35,777][root][INFO] - Training Epoch: 2/2, step 2107/7134 completed (loss: 0.05016098916530609, acc: 0.9865047335624695)
[2024-12-17 02:42:35,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:36,127][root][INFO] - Training Epoch: 2/2, step 2108/7134 completed (loss: 0.04797374829649925, acc: 0.9865471124649048)
[2024-12-17 02:42:36,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:36,442][root][INFO] - Training Epoch: 2/2, step 2109/7134 completed (loss: 0.09300518780946732, acc: 0.9788359999656677)
[2024-12-17 02:42:36,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:36,807][root][INFO] - Training Epoch: 2/2, step 2110/7134 completed (loss: 0.08255879580974579, acc: 0.979651153087616)
[2024-12-17 02:42:36,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:37,136][root][INFO] - Training Epoch: 2/2, step 2111/7134 completed (loss: 0.07266220450401306, acc: 0.9818417429924011)
[2024-12-17 02:42:37,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:37,431][root][INFO] - Training Epoch: 2/2, step 2112/7134 completed (loss: 0.1399092674255371, acc: 0.9649681448936462)
[2024-12-17 02:42:37,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:37,756][root][INFO] - Training Epoch: 2/2, step 2113/7134 completed (loss: 0.03216433525085449, acc: 0.9865871667861938)
[2024-12-17 02:42:37,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:38,089][root][INFO] - Training Epoch: 2/2, step 2114/7134 completed (loss: 0.03699959069490433, acc: 0.9895424842834473)
[2024-12-17 02:42:38,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:38,441][root][INFO] - Training Epoch: 2/2, step 2115/7134 completed (loss: 0.04128352925181389, acc: 0.9887359142303467)
[2024-12-17 02:42:38,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:38,767][root][INFO] - Training Epoch: 2/2, step 2116/7134 completed (loss: 0.04716038703918457, acc: 0.9892638325691223)
[2024-12-17 02:42:38,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:39,103][root][INFO] - Training Epoch: 2/2, step 2117/7134 completed (loss: 0.047760531306266785, acc: 0.9875621795654297)
[2024-12-17 02:42:39,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:39,429][root][INFO] - Training Epoch: 2/2, step 2118/7134 completed (loss: 0.04780364781618118, acc: 0.9918144345283508)
[2024-12-17 02:42:39,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:39,756][root][INFO] - Training Epoch: 2/2, step 2119/7134 completed (loss: 0.04838988184928894, acc: 0.9855642914772034)
[2024-12-17 02:42:39,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:40,084][root][INFO] - Training Epoch: 2/2, step 2120/7134 completed (loss: 0.05843004211783409, acc: 0.9817351698875427)
[2024-12-17 02:42:40,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:40,383][root][INFO] - Training Epoch: 2/2, step 2121/7134 completed (loss: 0.05735621228814125, acc: 0.9793650507926941)
[2024-12-17 02:42:40,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:40,720][root][INFO] - Training Epoch: 2/2, step 2122/7134 completed (loss: 0.036127205938100815, acc: 0.98828125)
[2024-12-17 02:42:40,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:41,040][root][INFO] - Training Epoch: 2/2, step 2123/7134 completed (loss: 0.038430105894804, acc: 0.9905660152435303)
[2024-12-17 02:42:41,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:41,355][root][INFO] - Training Epoch: 2/2, step 2124/7134 completed (loss: 0.017355848103761673, acc: 0.9984423518180847)
[2024-12-17 02:42:41,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:41,703][root][INFO] - Training Epoch: 2/2, step 2125/7134 completed (loss: 0.021435104310512543, acc: 0.9939393997192383)
[2024-12-17 02:42:41,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:42,046][root][INFO] - Training Epoch: 2/2, step 2126/7134 completed (loss: 0.02926914393901825, acc: 0.9949579834938049)
[2024-12-17 02:42:42,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:42,361][root][INFO] - Training Epoch: 2/2, step 2127/7134 completed (loss: 0.03252207487821579, acc: 0.99262535572052)
[2024-12-17 02:42:42,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:42,707][root][INFO] - Training Epoch: 2/2, step 2128/7134 completed (loss: 0.03431982547044754, acc: 0.9895012974739075)
[2024-12-17 02:42:42,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:43,038][root][INFO] - Training Epoch: 2/2, step 2129/7134 completed (loss: 0.05639614537358284, acc: 0.9834087491035461)
[2024-12-17 02:42:43,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:43,351][root][INFO] - Training Epoch: 2/2, step 2130/7134 completed (loss: 0.04285184293985367, acc: 0.9900990128517151)
[2024-12-17 02:42:43,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:43,650][root][INFO] - Training Epoch: 2/2, step 2131/7134 completed (loss: 0.022003499791026115, acc: 0.9922600388526917)
[2024-12-17 02:42:43,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:43,972][root][INFO] - Training Epoch: 2/2, step 2132/7134 completed (loss: 0.027069883421063423, acc: 0.9919137358665466)
[2024-12-17 02:42:44,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:44,302][root][INFO] - Training Epoch: 2/2, step 2133/7134 completed (loss: 0.03643602877855301, acc: 0.9881109595298767)
[2024-12-17 02:42:44,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:44,634][root][INFO] - Training Epoch: 2/2, step 2134/7134 completed (loss: 0.02555101364850998, acc: 0.9919678568840027)
[2024-12-17 02:42:44,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:44,948][root][INFO] - Training Epoch: 2/2, step 2135/7134 completed (loss: 0.03631248697638512, acc: 0.9879518151283264)
[2024-12-17 02:42:45,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:45,283][root][INFO] - Training Epoch: 2/2, step 2136/7134 completed (loss: 0.02940654382109642, acc: 0.9919893145561218)
[2024-12-17 02:42:45,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:45,640][root][INFO] - Training Epoch: 2/2, step 2137/7134 completed (loss: 0.021725742146372795, acc: 0.9883871078491211)
[2024-12-17 02:42:45,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:45,954][root][INFO] - Training Epoch: 2/2, step 2138/7134 completed (loss: 0.02406703494489193, acc: 0.9939024448394775)
[2024-12-17 02:42:46,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:46,285][root][INFO] - Training Epoch: 2/2, step 2139/7134 completed (loss: 0.01572430320084095, acc: 0.9958391189575195)
[2024-12-17 02:42:46,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:46,657][root][INFO] - Training Epoch: 2/2, step 2140/7134 completed (loss: 0.05888662487268448, acc: 0.9876033067703247)
[2024-12-17 02:42:46,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:46,894][root][INFO] - Training Epoch: 2/2, step 2141/7134 completed (loss: 0.0368044339120388, acc: 0.9853801131248474)
[2024-12-17 02:42:46,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:47,249][root][INFO] - Training Epoch: 2/2, step 2142/7134 completed (loss: 0.03810707479715347, acc: 0.9886685609817505)
[2024-12-17 02:42:47,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:47,600][root][INFO] - Training Epoch: 2/2, step 2143/7134 completed (loss: 0.025647982954978943, acc: 0.9894737005233765)
[2024-12-17 02:42:47,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:47,960][root][INFO] - Training Epoch: 2/2, step 2144/7134 completed (loss: 0.01111617498099804, acc: 0.9986720085144043)
[2024-12-17 02:42:48,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:48,313][root][INFO] - Training Epoch: 2/2, step 2145/7134 completed (loss: 0.04985760897397995, acc: 0.9856938719749451)
[2024-12-17 02:42:48,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:48,629][root][INFO] - Training Epoch: 2/2, step 2146/7134 completed (loss: 0.03721326217055321, acc: 0.9894366264343262)
[2024-12-17 02:42:48,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:48,998][root][INFO] - Training Epoch: 2/2, step 2147/7134 completed (loss: 0.04977598041296005, acc: 0.9875311851501465)
[2024-12-17 02:42:49,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:49,324][root][INFO] - Training Epoch: 2/2, step 2148/7134 completed (loss: 0.0630410686135292, acc: 0.9854439496994019)
[2024-12-17 02:42:49,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:49,663][root][INFO] - Training Epoch: 2/2, step 2149/7134 completed (loss: 0.028951363638043404, acc: 0.9887323975563049)
[2024-12-17 02:42:49,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:49,984][root][INFO] - Training Epoch: 2/2, step 2150/7134 completed (loss: 0.05766041949391365, acc: 0.9866666793823242)
[2024-12-17 02:42:50,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:50,314][root][INFO] - Training Epoch: 2/2, step 2151/7134 completed (loss: 0.039966557174921036, acc: 0.991428554058075)
[2024-12-17 02:42:50,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:50,653][root][INFO] - Training Epoch: 2/2, step 2152/7134 completed (loss: 0.17310094833374023, acc: 0.9595588445663452)
[2024-12-17 02:42:50,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:51,133][root][INFO] - Training Epoch: 2/2, step 2153/7134 completed (loss: 0.07382722944021225, acc: 0.9833518266677856)
[2024-12-17 02:42:51,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:51,524][root][INFO] - Training Epoch: 2/2, step 2154/7134 completed (loss: 0.07594644278287888, acc: 0.9810366630554199)
[2024-12-17 02:42:51,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:51,855][root][INFO] - Training Epoch: 2/2, step 2155/7134 completed (loss: 0.08753040432929993, acc: 0.9835164546966553)
[2024-12-17 02:42:51,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:52,171][root][INFO] - Training Epoch: 2/2, step 2156/7134 completed (loss: 0.026427412405610085, acc: 0.9930555820465088)
[2024-12-17 02:42:52,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:52,533][root][INFO] - Training Epoch: 2/2, step 2157/7134 completed (loss: 0.033520448952913284, acc: 0.9932960867881775)
[2024-12-17 02:42:52,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:52,899][root][INFO] - Training Epoch: 2/2, step 2158/7134 completed (loss: 0.07950112223625183, acc: 0.9841269850730896)
[2024-12-17 02:42:52,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:53,248][root][INFO] - Training Epoch: 2/2, step 2159/7134 completed (loss: 0.04129105806350708, acc: 0.9936143159866333)
[2024-12-17 02:42:53,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:53,602][root][INFO] - Training Epoch: 2/2, step 2160/7134 completed (loss: 0.0646984800696373, acc: 0.9793672561645508)
[2024-12-17 02:42:53,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:53,953][root][INFO] - Training Epoch: 2/2, step 2161/7134 completed (loss: 0.0771617442369461, acc: 0.984635055065155)
[2024-12-17 02:42:54,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:54,294][root][INFO] - Training Epoch: 2/2, step 2162/7134 completed (loss: 0.07923650741577148, acc: 0.9833585619926453)
[2024-12-17 02:42:54,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:54,657][root][INFO] - Training Epoch: 2/2, step 2163/7134 completed (loss: 0.05066107213497162, acc: 0.9889763593673706)
[2024-12-17 02:42:54,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:54,971][root][INFO] - Training Epoch: 2/2, step 2164/7134 completed (loss: 0.03901863470673561, acc: 0.989708423614502)
[2024-12-17 02:42:55,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:55,332][root][INFO] - Training Epoch: 2/2, step 2165/7134 completed (loss: 0.04352015256881714, acc: 0.9885222315788269)
[2024-12-17 02:42:55,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:55,671][root][INFO] - Training Epoch: 2/2, step 2166/7134 completed (loss: 0.052386924624443054, acc: 0.984375)
[2024-12-17 02:42:55,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:55,997][root][INFO] - Training Epoch: 2/2, step 2167/7134 completed (loss: 0.05855628103017807, acc: 0.9799554347991943)
[2024-12-17 02:42:56,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:56,324][root][INFO] - Training Epoch: 2/2, step 2168/7134 completed (loss: 0.0504036508500576, acc: 0.9873015880584717)
[2024-12-17 02:42:56,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:56,675][root][INFO] - Training Epoch: 2/2, step 2169/7134 completed (loss: 0.05322837457060814, acc: 0.9895591735839844)
[2024-12-17 02:42:56,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:57,012][root][INFO] - Training Epoch: 2/2, step 2170/7134 completed (loss: 0.05088881775736809, acc: 0.9883551597595215)
[2024-12-17 02:42:57,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:57,374][root][INFO] - Training Epoch: 2/2, step 2171/7134 completed (loss: 0.058834996074438095, acc: 0.9886749982833862)
[2024-12-17 02:42:57,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:57,739][root][INFO] - Training Epoch: 2/2, step 2172/7134 completed (loss: 0.034274086356163025, acc: 0.9927685856819153)
[2024-12-17 02:42:57,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:58,079][root][INFO] - Training Epoch: 2/2, step 2173/7134 completed (loss: 0.07477937638759613, acc: 0.9848942756652832)
[2024-12-17 02:42:58,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:58,415][root][INFO] - Training Epoch: 2/2, step 2174/7134 completed (loss: 0.03326428309082985, acc: 0.9929078221321106)
[2024-12-17 02:42:58,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:58,754][root][INFO] - Training Epoch: 2/2, step 2175/7134 completed (loss: 0.0950751081109047, acc: 0.9806094169616699)
[2024-12-17 02:42:58,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:59,140][root][INFO] - Training Epoch: 2/2, step 2176/7134 completed (loss: 0.046596311032772064, acc: 0.9845971465110779)
[2024-12-17 02:42:59,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:59,538][root][INFO] - Training Epoch: 2/2, step 2177/7134 completed (loss: 0.04297022148966789, acc: 0.9870129823684692)
[2024-12-17 02:42:59,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:59,879][root][INFO] - Training Epoch: 2/2, step 2178/7134 completed (loss: 0.02914860099554062, acc: 0.9911699891090393)
[2024-12-17 02:42:59,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:00,233][root][INFO] - Training Epoch: 2/2, step 2179/7134 completed (loss: 0.04754673317074776, acc: 0.9936708807945251)
[2024-12-17 02:43:00,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:00,593][root][INFO] - Training Epoch: 2/2, step 2180/7134 completed (loss: 0.04346510395407677, acc: 0.9881796836853027)
[2024-12-17 02:43:00,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:00,969][root][INFO] - Training Epoch: 2/2, step 2181/7134 completed (loss: 0.02269088663160801, acc: 0.9942775368690491)
[2024-12-17 02:43:01,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:01,317][root][INFO] - Training Epoch: 2/2, step 2182/7134 completed (loss: 0.06918511539697647, acc: 0.9815455675125122)
[2024-12-17 02:43:01,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:01,697][root][INFO] - Training Epoch: 2/2, step 2183/7134 completed (loss: 0.04237132892012596, acc: 0.9895226955413818)
[2024-12-17 02:43:01,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:02,058][root][INFO] - Training Epoch: 2/2, step 2184/7134 completed (loss: 0.04827376455068588, acc: 0.9872204661369324)
[2024-12-17 02:43:02,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:02,403][root][INFO] - Training Epoch: 2/2, step 2185/7134 completed (loss: 0.07217514514923096, acc: 0.980169951915741)
[2024-12-17 02:43:02,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:02,760][root][INFO] - Training Epoch: 2/2, step 2186/7134 completed (loss: 0.0720706582069397, acc: 0.9821717739105225)
[2024-12-17 02:43:02,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:03,103][root][INFO] - Training Epoch: 2/2, step 2187/7134 completed (loss: 0.13398830592632294, acc: 0.9728000164031982)
[2024-12-17 02:43:03,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:03,460][root][INFO] - Training Epoch: 2/2, step 2188/7134 completed (loss: 0.02398875169456005, acc: 0.9931600689888)
[2024-12-17 02:43:03,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:03,785][root][INFO] - Training Epoch: 2/2, step 2189/7134 completed (loss: 0.07151000946760178, acc: 0.9831804037094116)
[2024-12-17 02:43:03,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:04,140][root][INFO] - Training Epoch: 2/2, step 2190/7134 completed (loss: 0.041206300258636475, acc: 0.9881266355514526)
[2024-12-17 02:43:04,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:04,428][root][INFO] - Training Epoch: 2/2, step 2191/7134 completed (loss: 0.0813625231385231, acc: 0.9756097793579102)
[2024-12-17 02:43:04,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:04,743][root][INFO] - Training Epoch: 2/2, step 2192/7134 completed (loss: 0.022718731313943863, acc: 0.994350254535675)
[2024-12-17 02:43:04,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:05,084][root][INFO] - Training Epoch: 2/2, step 2193/7134 completed (loss: 0.04193699732422829, acc: 0.9906914830207825)
[2024-12-17 02:43:05,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:05,414][root][INFO] - Training Epoch: 2/2, step 2194/7134 completed (loss: 0.06452636420726776, acc: 0.9782244563102722)
[2024-12-17 02:43:05,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:05,758][root][INFO] - Training Epoch: 2/2, step 2195/7134 completed (loss: 0.02167120948433876, acc: 0.9919999837875366)
[2024-12-17 02:43:05,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:06,120][root][INFO] - Training Epoch: 2/2, step 2196/7134 completed (loss: 0.053838007152080536, acc: 0.9792746305465698)
[2024-12-17 02:43:06,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:06,431][root][INFO] - Training Epoch: 2/2, step 2197/7134 completed (loss: 0.04080222174525261, acc: 0.9890710115432739)
[2024-12-17 02:43:06,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:06,771][root][INFO] - Training Epoch: 2/2, step 2198/7134 completed (loss: 0.058126963675022125, acc: 0.9834087491035461)
[2024-12-17 02:43:06,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:07,102][root][INFO] - Training Epoch: 2/2, step 2199/7134 completed (loss: 0.021994100883603096, acc: 0.9939576983451843)
[2024-12-17 02:43:07,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:07,444][root][INFO] - Training Epoch: 2/2, step 2200/7134 completed (loss: 0.05967288836836815, acc: 0.9837251305580139)
[2024-12-17 02:43:07,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:07,783][root][INFO] - Training Epoch: 2/2, step 2201/7134 completed (loss: 0.01975245028734207, acc: 0.9924242496490479)
[2024-12-17 02:43:07,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:08,115][root][INFO] - Training Epoch: 2/2, step 2202/7134 completed (loss: 0.040835294872522354, acc: 0.989983320236206)
[2024-12-17 02:43:08,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:08,476][root][INFO] - Training Epoch: 2/2, step 2203/7134 completed (loss: 0.018584975972771645, acc: 0.9931507110595703)
[2024-12-17 02:43:08,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:08,809][root][INFO] - Training Epoch: 2/2, step 2204/7134 completed (loss: 0.030659781768918037, acc: 0.9926900863647461)
[2024-12-17 02:43:08,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:09,156][root][INFO] - Training Epoch: 2/2, step 2205/7134 completed (loss: 0.031546615064144135, acc: 0.9859648942947388)
[2024-12-17 02:43:09,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:09,479][root][INFO] - Training Epoch: 2/2, step 2206/7134 completed (loss: 0.08824820071458817, acc: 0.982425332069397)
[2024-12-17 02:43:09,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:09,805][root][INFO] - Training Epoch: 2/2, step 2207/7134 completed (loss: 0.029964875429868698, acc: 0.9967690110206604)
[2024-12-17 02:43:09,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:10,130][root][INFO] - Training Epoch: 2/2, step 2208/7134 completed (loss: 0.04792806878685951, acc: 0.9884297251701355)
[2024-12-17 02:43:10,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:10,459][root][INFO] - Training Epoch: 2/2, step 2209/7134 completed (loss: 0.04240474849939346, acc: 0.987270176410675)
[2024-12-17 02:43:10,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:10,785][root][INFO] - Training Epoch: 2/2, step 2210/7134 completed (loss: 0.05680541694164276, acc: 0.9817906022071838)
[2024-12-17 02:43:10,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:11,122][root][INFO] - Training Epoch: 2/2, step 2211/7134 completed (loss: 0.03904809430241585, acc: 0.9889196753501892)
[2024-12-17 02:43:11,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:11,461][root][INFO] - Training Epoch: 2/2, step 2212/7134 completed (loss: 0.019034598022699356, acc: 0.9944444298744202)
[2024-12-17 02:43:11,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:11,793][root][INFO] - Training Epoch: 2/2, step 2213/7134 completed (loss: 0.030567478388547897, acc: 0.9901130199432373)
[2024-12-17 02:43:11,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:12,118][root][INFO] - Training Epoch: 2/2, step 2214/7134 completed (loss: 0.04245220124721527, acc: 0.9865671396255493)
[2024-12-17 02:43:12,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:12,443][root][INFO] - Training Epoch: 2/2, step 2215/7134 completed (loss: 0.02573758363723755, acc: 0.9887640476226807)
[2024-12-17 02:43:12,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:12,775][root][INFO] - Training Epoch: 2/2, step 2216/7134 completed (loss: 0.02042742818593979, acc: 0.9946595430374146)
[2024-12-17 02:43:12,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:13,114][root][INFO] - Training Epoch: 2/2, step 2217/7134 completed (loss: 0.03661378473043442, acc: 0.9900373816490173)
[2024-12-17 02:43:13,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:13,440][root][INFO] - Training Epoch: 2/2, step 2218/7134 completed (loss: 0.05040743201971054, acc: 0.9885057210922241)
[2024-12-17 02:43:13,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:13,762][root][INFO] - Training Epoch: 2/2, step 2219/7134 completed (loss: 0.031196534633636475, acc: 0.9938176274299622)
[2024-12-17 02:43:13,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:14,084][root][INFO] - Training Epoch: 2/2, step 2220/7134 completed (loss: 0.027346059679985046, acc: 0.9905660152435303)
[2024-12-17 02:43:14,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:14,431][root][INFO] - Training Epoch: 2/2, step 2221/7134 completed (loss: 0.043229468166828156, acc: 0.9896103739738464)
[2024-12-17 02:43:14,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:14,778][root][INFO] - Training Epoch: 2/2, step 2222/7134 completed (loss: 0.03412916511297226, acc: 0.9913294911384583)
[2024-12-17 02:43:14,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:15,106][root][INFO] - Training Epoch: 2/2, step 2223/7134 completed (loss: 0.033209607005119324, acc: 0.9930264949798584)
[2024-12-17 02:43:15,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:15,453][root][INFO] - Training Epoch: 2/2, step 2224/7134 completed (loss: 0.05056262016296387, acc: 0.9862825870513916)
[2024-12-17 02:43:15,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:15,787][root][INFO] - Training Epoch: 2/2, step 2225/7134 completed (loss: 0.02885781228542328, acc: 0.9913169145584106)
[2024-12-17 02:43:15,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:16,123][root][INFO] - Training Epoch: 2/2, step 2226/7134 completed (loss: 0.035037316381931305, acc: 0.9939117431640625)
[2024-12-17 02:43:16,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:16,454][root][INFO] - Training Epoch: 2/2, step 2227/7134 completed (loss: 0.02329719066619873, acc: 0.9926793575286865)
[2024-12-17 02:43:16,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:16,790][root][INFO] - Training Epoch: 2/2, step 2228/7134 completed (loss: 0.021381637081503868, acc: 0.9918699264526367)
[2024-12-17 02:43:16,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:17,121][root][INFO] - Training Epoch: 2/2, step 2229/7134 completed (loss: 0.03691031411290169, acc: 0.9940000176429749)
[2024-12-17 02:43:17,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:17,443][root][INFO] - Training Epoch: 2/2, step 2230/7134 completed (loss: 0.023094234988093376, acc: 0.9935275316238403)
[2024-12-17 02:43:17,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:17,757][root][INFO] - Training Epoch: 2/2, step 2231/7134 completed (loss: 0.03871341049671173, acc: 0.9880478382110596)
[2024-12-17 02:43:17,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:18,100][root][INFO] - Training Epoch: 2/2, step 2232/7134 completed (loss: 0.019130906090140343, acc: 0.9946523904800415)
[2024-12-17 02:43:18,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:18,442][root][INFO] - Training Epoch: 2/2, step 2233/7134 completed (loss: 0.03715907782316208, acc: 0.9928876161575317)
[2024-12-17 02:43:18,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:18,787][root][INFO] - Training Epoch: 2/2, step 2234/7134 completed (loss: 0.017914904281497, acc: 0.9959016442298889)
[2024-12-17 02:43:18,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:19,125][root][INFO] - Training Epoch: 2/2, step 2235/7134 completed (loss: 0.05044108256697655, acc: 0.9905956387519836)
[2024-12-17 02:43:19,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:19,446][root][INFO] - Training Epoch: 2/2, step 2236/7134 completed (loss: 0.025318603962659836, acc: 0.9925037622451782)
[2024-12-17 02:43:19,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:19,788][root][INFO] - Training Epoch: 2/2, step 2237/7134 completed (loss: 0.0783744677901268, acc: 0.987270176410675)
[2024-12-17 02:43:19,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:20,146][root][INFO] - Training Epoch: 2/2, step 2238/7134 completed (loss: 0.08800995349884033, acc: 0.9797394871711731)
[2024-12-17 02:43:20,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:20,496][root][INFO] - Training Epoch: 2/2, step 2239/7134 completed (loss: 0.09637640416622162, acc: 0.9753246903419495)
[2024-12-17 02:43:20,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:20,846][root][INFO] - Training Epoch: 2/2, step 2240/7134 completed (loss: 0.06801052391529083, acc: 0.9857142567634583)
[2024-12-17 02:43:20,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:21,148][root][INFO] - Training Epoch: 2/2, step 2241/7134 completed (loss: 0.0972733274102211, acc: 0.9739952683448792)
[2024-12-17 02:43:21,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:21,485][root][INFO] - Training Epoch: 2/2, step 2242/7134 completed (loss: 0.11909253895282745, acc: 0.9667458534240723)
[2024-12-17 02:43:21,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:21,863][root][INFO] - Training Epoch: 2/2, step 2243/7134 completed (loss: 0.16414764523506165, acc: 0.9603053331375122)
[2024-12-17 02:43:21,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:22,221][root][INFO] - Training Epoch: 2/2, step 2244/7134 completed (loss: 0.05575380474328995, acc: 0.9858490824699402)
[2024-12-17 02:43:22,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:22,536][root][INFO] - Training Epoch: 2/2, step 2245/7134 completed (loss: 0.09540972858667374, acc: 0.96278315782547)
[2024-12-17 02:43:22,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:22,892][root][INFO] - Training Epoch: 2/2, step 2246/7134 completed (loss: 0.1366821527481079, acc: 0.9635134935379028)
[2024-12-17 02:43:23,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:23,231][root][INFO] - Training Epoch: 2/2, step 2247/7134 completed (loss: 0.11769598722457886, acc: 0.977011501789093)
[2024-12-17 02:43:23,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:23,578][root][INFO] - Training Epoch: 2/2, step 2248/7134 completed (loss: 0.08483177423477173, acc: 0.9861687421798706)
[2024-12-17 02:43:23,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:23,928][root][INFO] - Training Epoch: 2/2, step 2249/7134 completed (loss: 0.05270484462380409, acc: 0.9818435907363892)
[2024-12-17 02:43:24,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:24,272][root][INFO] - Training Epoch: 2/2, step 2250/7134 completed (loss: 0.08454252034425735, acc: 0.9745989441871643)
[2024-12-17 02:43:24,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:24,590][root][INFO] - Training Epoch: 2/2, step 2251/7134 completed (loss: 0.05844100937247276, acc: 0.9818593859672546)
[2024-12-17 02:43:24,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:24,915][root][INFO] - Training Epoch: 2/2, step 2252/7134 completed (loss: 0.07918678224086761, acc: 0.9775910377502441)
[2024-12-17 02:43:25,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:25,224][root][INFO] - Training Epoch: 2/2, step 2253/7134 completed (loss: 0.06647130101919174, acc: 0.97826087474823)
[2024-12-17 02:43:25,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:25,530][root][INFO] - Training Epoch: 2/2, step 2254/7134 completed (loss: 0.12307020276784897, acc: 0.9661354422569275)
[2024-12-17 02:43:25,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:25,872][root][INFO] - Training Epoch: 2/2, step 2255/7134 completed (loss: 0.06574662029743195, acc: 0.9817906022071838)
[2024-12-17 02:43:25,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:26,144][root][INFO] - Training Epoch: 2/2, step 2256/7134 completed (loss: 0.1462029367685318, acc: 0.9601770043373108)
[2024-12-17 02:43:26,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:26,484][root][INFO] - Training Epoch: 2/2, step 2257/7134 completed (loss: 0.04744391515851021, acc: 0.981873095035553)
[2024-12-17 02:43:26,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:26,808][root][INFO] - Training Epoch: 2/2, step 2258/7134 completed (loss: 0.04032271355390549, acc: 0.9884615540504456)
[2024-12-17 02:43:26,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:27,116][root][INFO] - Training Epoch: 2/2, step 2259/7134 completed (loss: 0.03183235228061676, acc: 0.9888888597488403)
[2024-12-17 02:43:27,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:27,437][root][INFO] - Training Epoch: 2/2, step 2260/7134 completed (loss: 0.08954044431447983, acc: 0.9742424488067627)
[2024-12-17 02:43:27,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:27,728][root][INFO] - Training Epoch: 2/2, step 2261/7134 completed (loss: 0.12910881638526917, acc: 0.970802903175354)
[2024-12-17 02:43:27,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:28,039][root][INFO] - Training Epoch: 2/2, step 2262/7134 completed (loss: 0.029160261154174805, acc: 0.9926335215568542)
[2024-12-17 02:43:28,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:28,374][root][INFO] - Training Epoch: 2/2, step 2263/7134 completed (loss: 0.050557538866996765, acc: 0.9855855703353882)
[2024-12-17 02:43:28,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:28,702][root][INFO] - Training Epoch: 2/2, step 2264/7134 completed (loss: 0.09287858754396439, acc: 0.9718706011772156)
[2024-12-17 02:43:28,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:29,043][root][INFO] - Training Epoch: 2/2, step 2265/7134 completed (loss: 0.1166263222694397, acc: 0.9707903861999512)
[2024-12-17 02:43:29,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:29,380][root][INFO] - Training Epoch: 2/2, step 2266/7134 completed (loss: 0.048383064568042755, acc: 0.9839141964912415)
[2024-12-17 02:43:29,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:29,702][root][INFO] - Training Epoch: 2/2, step 2267/7134 completed (loss: 0.03313206881284714, acc: 0.991769552230835)
[2024-12-17 02:43:29,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:30,063][root][INFO] - Training Epoch: 2/2, step 2268/7134 completed (loss: 0.044603027403354645, acc: 0.9899569749832153)
[2024-12-17 02:43:30,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:30,417][root][INFO] - Training Epoch: 2/2, step 2269/7134 completed (loss: 0.031799547374248505, acc: 0.9886792302131653)
[2024-12-17 02:43:30,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:30,744][root][INFO] - Training Epoch: 2/2, step 2270/7134 completed (loss: 0.09869974851608276, acc: 0.9734659790992737)
[2024-12-17 02:43:30,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:31,116][root][INFO] - Training Epoch: 2/2, step 2271/7134 completed (loss: 0.06519908457994461, acc: 0.9815880060195923)
[2024-12-17 02:43:31,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:31,466][root][INFO] - Training Epoch: 2/2, step 2272/7134 completed (loss: 0.04938032478094101, acc: 0.9902200698852539)
[2024-12-17 02:43:31,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:31,812][root][INFO] - Training Epoch: 2/2, step 2273/7134 completed (loss: 0.023978043347597122, acc: 0.9904191493988037)
[2024-12-17 02:43:31,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:32,170][root][INFO] - Training Epoch: 2/2, step 2274/7134 completed (loss: 0.11774914711713791, acc: 0.9783439636230469)
[2024-12-17 02:43:32,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:32,524][root][INFO] - Training Epoch: 2/2, step 2275/7134 completed (loss: 0.0374608114361763, acc: 0.9882628917694092)
[2024-12-17 02:43:32,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:32,885][root][INFO] - Training Epoch: 2/2, step 2276/7134 completed (loss: 0.055812619626522064, acc: 0.9881516695022583)
[2024-12-17 02:43:33,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:33,250][root][INFO] - Training Epoch: 2/2, step 2277/7134 completed (loss: 0.05438098683953285, acc: 0.986143171787262)
[2024-12-17 02:43:33,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:33,594][root][INFO] - Training Epoch: 2/2, step 2278/7134 completed (loss: 0.1247812807559967, acc: 0.9728434681892395)
[2024-12-17 02:43:33,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:33,946][root][INFO] - Training Epoch: 2/2, step 2279/7134 completed (loss: 0.05677042528986931, acc: 0.9870129823684692)
[2024-12-17 02:43:34,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:34,313][root][INFO] - Training Epoch: 2/2, step 2280/7134 completed (loss: 0.07301849126815796, acc: 0.9811097979545593)
[2024-12-17 02:43:34,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:34,638][root][INFO] - Training Epoch: 2/2, step 2281/7134 completed (loss: 0.10600565373897552, acc: 0.9773333072662354)
[2024-12-17 02:43:34,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:34,993][root][INFO] - Training Epoch: 2/2, step 2282/7134 completed (loss: 0.016977548599243164, acc: 0.9962916970252991)
[2024-12-17 02:43:35,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:35,342][root][INFO] - Training Epoch: 2/2, step 2283/7134 completed (loss: 0.045737311244010925, acc: 0.9841075539588928)
[2024-12-17 02:43:35,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:35,680][root][INFO] - Training Epoch: 2/2, step 2284/7134 completed (loss: 0.0646553635597229, acc: 0.9807976484298706)
[2024-12-17 02:43:35,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:36,052][root][INFO] - Training Epoch: 2/2, step 2285/7134 completed (loss: 0.03542480245232582, acc: 0.9866220951080322)
[2024-12-17 02:43:36,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:36,404][root][INFO] - Training Epoch: 2/2, step 2286/7134 completed (loss: 0.07685162127017975, acc: 0.9792477488517761)
[2024-12-17 02:43:36,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:36,771][root][INFO] - Training Epoch: 2/2, step 2287/7134 completed (loss: 0.03232292830944061, acc: 0.98525470495224)
[2024-12-17 02:43:36,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:37,142][root][INFO] - Training Epoch: 2/2, step 2288/7134 completed (loss: 0.036570798605680466, acc: 0.9905771613121033)
[2024-12-17 02:43:37,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:37,472][root][INFO] - Training Epoch: 2/2, step 2289/7134 completed (loss: 0.0377633199095726, acc: 0.9922978281974792)
[2024-12-17 02:43:37,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:37,815][root][INFO] - Training Epoch: 2/2, step 2290/7134 completed (loss: 0.04640331491827965, acc: 0.9898089170455933)
[2024-12-17 02:43:37,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:38,166][root][INFO] - Training Epoch: 2/2, step 2291/7134 completed (loss: 0.05370449647307396, acc: 0.9838056564331055)
[2024-12-17 02:43:38,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:38,511][root][INFO] - Training Epoch: 2/2, step 2292/7134 completed (loss: 0.08523532748222351, acc: 0.9819355010986328)
[2024-12-17 02:43:38,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:38,881][root][INFO] - Training Epoch: 2/2, step 2293/7134 completed (loss: 0.06793157756328583, acc: 0.9799554347991943)
[2024-12-17 02:43:38,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:39,226][root][INFO] - Training Epoch: 2/2, step 2294/7134 completed (loss: 0.06846530735492706, acc: 0.9808773994445801)
[2024-12-17 02:43:39,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:39,630][root][INFO] - Training Epoch: 2/2, step 2295/7134 completed (loss: 0.05194070190191269, acc: 0.983855664730072)
[2024-12-17 02:43:39,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:39,998][root][INFO] - Training Epoch: 2/2, step 2296/7134 completed (loss: 0.031980592757463455, acc: 0.9893617033958435)
[2024-12-17 02:43:40,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:40,380][root][INFO] - Training Epoch: 2/2, step 2297/7134 completed (loss: 0.03066311404109001, acc: 0.9908536672592163)
[2024-12-17 02:43:40,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:40,734][root][INFO] - Training Epoch: 2/2, step 2298/7134 completed (loss: 0.07597895711660385, acc: 0.980021059513092)
[2024-12-17 02:43:40,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:41,117][root][INFO] - Training Epoch: 2/2, step 2299/7134 completed (loss: 0.04042940214276314, acc: 0.9874857664108276)
[2024-12-17 02:43:41,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:41,500][root][INFO] - Training Epoch: 2/2, step 2300/7134 completed (loss: 0.013235822319984436, acc: 0.9977452158927917)
[2024-12-17 02:43:41,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:41,865][root][INFO] - Training Epoch: 2/2, step 2301/7134 completed (loss: 0.04242146015167236, acc: 0.9841059446334839)
[2024-12-17 02:43:41,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:42,229][root][INFO] - Training Epoch: 2/2, step 2302/7134 completed (loss: 0.06801392883062363, acc: 0.9803921580314636)
[2024-12-17 02:43:42,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:42,562][root][INFO] - Training Epoch: 2/2, step 2303/7134 completed (loss: 0.0408703088760376, acc: 0.9863325953483582)
[2024-12-17 02:43:42,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:42,934][root][INFO] - Training Epoch: 2/2, step 2304/7134 completed (loss: 0.05541126802563667, acc: 0.9845837354660034)
[2024-12-17 02:43:43,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:43,306][root][INFO] - Training Epoch: 2/2, step 2305/7134 completed (loss: 0.02985425665974617, acc: 0.99148029088974)
[2024-12-17 02:43:43,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:43,663][root][INFO] - Training Epoch: 2/2, step 2306/7134 completed (loss: 0.038383569568395615, acc: 0.9878048896789551)
[2024-12-17 02:43:43,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:44,029][root][INFO] - Training Epoch: 2/2, step 2307/7134 completed (loss: 0.051574770361185074, acc: 0.9876033067703247)
[2024-12-17 02:43:44,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:44,394][root][INFO] - Training Epoch: 2/2, step 2308/7134 completed (loss: 0.05171802267432213, acc: 0.9867211580276489)
[2024-12-17 02:43:44,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:44,737][root][INFO] - Training Epoch: 2/2, step 2309/7134 completed (loss: 0.03648338094353676, acc: 0.9892086386680603)
[2024-12-17 02:43:44,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:45,086][root][INFO] - Training Epoch: 2/2, step 2310/7134 completed (loss: 0.026009056717157364, acc: 0.994350254535675)
[2024-12-17 02:43:45,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:45,439][root][INFO] - Training Epoch: 2/2, step 2311/7134 completed (loss: 0.036969706416130066, acc: 0.9873853325843811)
[2024-12-17 02:43:45,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:45,813][root][INFO] - Training Epoch: 2/2, step 2312/7134 completed (loss: 0.031125379726290703, acc: 0.99028080701828)
[2024-12-17 02:43:45,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:46,161][root][INFO] - Training Epoch: 2/2, step 2313/7134 completed (loss: 0.0742354691028595, acc: 0.9805936217308044)
[2024-12-17 02:43:46,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:46,539][root][INFO] - Training Epoch: 2/2, step 2314/7134 completed (loss: 0.03191816434264183, acc: 0.9922308325767517)
[2024-12-17 02:43:46,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:46,918][root][INFO] - Training Epoch: 2/2, step 2315/7134 completed (loss: 0.039521295577287674, acc: 0.9882352948188782)
[2024-12-17 02:43:47,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:47,274][root][INFO] - Training Epoch: 2/2, step 2316/7134 completed (loss: 0.04082624986767769, acc: 0.9896432757377625)
[2024-12-17 02:43:47,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:47,647][root][INFO] - Training Epoch: 2/2, step 2317/7134 completed (loss: 0.03873211145401001, acc: 0.9936507940292358)
[2024-12-17 02:43:47,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:48,022][root][INFO] - Training Epoch: 2/2, step 2318/7134 completed (loss: 0.02502109482884407, acc: 0.9937238693237305)
[2024-12-17 02:43:48,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:48,389][root][INFO] - Training Epoch: 2/2, step 2319/7134 completed (loss: 0.03164339438080788, acc: 0.9912472367286682)
[2024-12-17 02:43:48,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:48,762][root][INFO] - Training Epoch: 2/2, step 2320/7134 completed (loss: 0.03186546638607979, acc: 0.9897727370262146)
[2024-12-17 02:43:48,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:49,100][root][INFO] - Training Epoch: 2/2, step 2321/7134 completed (loss: 0.03627282381057739, acc: 0.987500011920929)
[2024-12-17 02:43:49,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:49,441][root][INFO] - Training Epoch: 2/2, step 2322/7134 completed (loss: 0.026091443374753, acc: 0.9851852059364319)
[2024-12-17 02:43:49,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:49,769][root][INFO] - Training Epoch: 2/2, step 2323/7134 completed (loss: 0.0489494688808918, acc: 0.9747633934020996)
[2024-12-17 02:43:49,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:50,113][root][INFO] - Training Epoch: 2/2, step 2324/7134 completed (loss: 0.0751773789525032, acc: 0.9843304753303528)
[2024-12-17 02:43:50,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:50,466][root][INFO] - Training Epoch: 2/2, step 2325/7134 completed (loss: 0.046298932284116745, acc: 0.9811965823173523)
[2024-12-17 02:43:50,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:50,812][root][INFO] - Training Epoch: 2/2, step 2326/7134 completed (loss: 0.02521732822060585, acc: 0.9908088445663452)
[2024-12-17 02:43:50,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:51,149][root][INFO] - Training Epoch: 2/2, step 2327/7134 completed (loss: 0.02870323322713375, acc: 0.9852458834648132)
[2024-12-17 02:43:51,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:51,488][root][INFO] - Training Epoch: 2/2, step 2328/7134 completed (loss: 0.1034528985619545, acc: 0.9767025113105774)
[2024-12-17 02:43:51,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:51,824][root][INFO] - Training Epoch: 2/2, step 2329/7134 completed (loss: 0.03645483776926994, acc: 0.9968992471694946)
[2024-12-17 02:43:51,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:52,147][root][INFO] - Training Epoch: 2/2, step 2330/7134 completed (loss: 0.020345250144600868, acc: 0.9954198598861694)
[2024-12-17 02:43:52,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:52,487][root][INFO] - Training Epoch: 2/2, step 2331/7134 completed (loss: 0.02107919566333294, acc: 0.9938650131225586)
[2024-12-17 02:43:52,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:52,824][root][INFO] - Training Epoch: 2/2, step 2332/7134 completed (loss: 0.05261898785829544, acc: 0.9910846948623657)
[2024-12-17 02:43:52,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:53,164][root][INFO] - Training Epoch: 2/2, step 2333/7134 completed (loss: 0.026289403438568115, acc: 0.992559552192688)
[2024-12-17 02:43:53,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:53,502][root][INFO] - Training Epoch: 2/2, step 2334/7134 completed (loss: 0.028231032192707062, acc: 0.9910447597503662)
[2024-12-17 02:43:53,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:53,846][root][INFO] - Training Epoch: 2/2, step 2335/7134 completed (loss: 0.055391471832990646, acc: 0.9838709831237793)
[2024-12-17 02:43:53,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:54,171][root][INFO] - Training Epoch: 2/2, step 2336/7134 completed (loss: 0.01352340541779995, acc: 0.9953632354736328)
[2024-12-17 02:43:54,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:54,505][root][INFO] - Training Epoch: 2/2, step 2337/7134 completed (loss: 0.005372006446123123, acc: 1.0)
[2024-12-17 02:43:54,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:54,843][root][INFO] - Training Epoch: 2/2, step 2338/7134 completed (loss: 0.02546769753098488, acc: 0.9938176274299622)
[2024-12-17 02:43:54,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:55,177][root][INFO] - Training Epoch: 2/2, step 2339/7134 completed (loss: 0.0494961142539978, acc: 0.990212082862854)
[2024-12-17 02:43:55,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:55,508][root][INFO] - Training Epoch: 2/2, step 2340/7134 completed (loss: 0.024200694635510445, acc: 0.9909502267837524)
[2024-12-17 02:43:55,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:55,834][root][INFO] - Training Epoch: 2/2, step 2341/7134 completed (loss: 0.0214508268982172, acc: 0.9962406158447266)
[2024-12-17 02:43:55,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:56,155][root][INFO] - Training Epoch: 2/2, step 2342/7134 completed (loss: 0.02363397181034088, acc: 0.9926144480705261)
[2024-12-17 02:43:56,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:56,484][root][INFO] - Training Epoch: 2/2, step 2343/7134 completed (loss: 0.030392609536647797, acc: 0.9904000163078308)
[2024-12-17 02:43:56,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:56,818][root][INFO] - Training Epoch: 2/2, step 2344/7134 completed (loss: 0.029548566788434982, acc: 0.9890453815460205)
[2024-12-17 02:43:56,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:57,149][root][INFO] - Training Epoch: 2/2, step 2345/7134 completed (loss: 0.02718452550470829, acc: 0.988811194896698)
[2024-12-17 02:43:57,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:57,486][root][INFO] - Training Epoch: 2/2, step 2346/7134 completed (loss: 0.02557079866528511, acc: 0.9900850057601929)
[2024-12-17 02:43:57,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:57,820][root][INFO] - Training Epoch: 2/2, step 2347/7134 completed (loss: 0.061211686581373215, acc: 0.9851973652839661)
[2024-12-17 02:43:57,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:58,181][root][INFO] - Training Epoch: 2/2, step 2348/7134 completed (loss: 0.10598590970039368, acc: 0.9697352051734924)
[2024-12-17 02:43:58,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:58,521][root][INFO] - Training Epoch: 2/2, step 2349/7134 completed (loss: 0.07668046653270721, acc: 0.9777777791023254)
[2024-12-17 02:43:58,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:58,893][root][INFO] - Training Epoch: 2/2, step 2350/7134 completed (loss: 0.08886700868606567, acc: 0.980182945728302)
[2024-12-17 02:43:59,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:59,256][root][INFO] - Training Epoch: 2/2, step 2351/7134 completed (loss: 0.05575668439269066, acc: 0.9836065769195557)
[2024-12-17 02:43:59,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:59,585][root][INFO] - Training Epoch: 2/2, step 2352/7134 completed (loss: 0.048487983644008636, acc: 0.9871794581413269)
[2024-12-17 02:43:59,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:59,943][root][INFO] - Training Epoch: 2/2, step 2353/7134 completed (loss: 0.06974951922893524, acc: 0.9858155846595764)
[2024-12-17 02:44:00,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:00,285][root][INFO] - Training Epoch: 2/2, step 2354/7134 completed (loss: 0.04470347613096237, acc: 0.9860759377479553)
[2024-12-17 02:44:00,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:00,635][root][INFO] - Training Epoch: 2/2, step 2355/7134 completed (loss: 0.060741525143384933, acc: 0.9839506149291992)
[2024-12-17 02:44:00,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:00,963][root][INFO] - Training Epoch: 2/2, step 2356/7134 completed (loss: 0.07336334139108658, acc: 0.9805653691291809)
[2024-12-17 02:44:01,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:01,280][root][INFO] - Training Epoch: 2/2, step 2357/7134 completed (loss: 0.06395260989665985, acc: 0.9821428656578064)
[2024-12-17 02:44:01,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:01,636][root][INFO] - Training Epoch: 2/2, step 2358/7134 completed (loss: 0.07085686177015305, acc: 0.9819276928901672)
[2024-12-17 02:44:01,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:01,967][root][INFO] - Training Epoch: 2/2, step 2359/7134 completed (loss: 0.07485426217317581, acc: 0.9779735803604126)
[2024-12-17 02:44:02,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:02,337][root][INFO] - Training Epoch: 2/2, step 2360/7134 completed (loss: 0.04612534120678902, acc: 0.9838945865631104)
[2024-12-17 02:44:02,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:02,672][root][INFO] - Training Epoch: 2/2, step 2361/7134 completed (loss: 0.04859032854437828, acc: 0.9881656765937805)
[2024-12-17 02:44:02,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:02,947][root][INFO] - Training Epoch: 2/2, step 2362/7134 completed (loss: 0.037843648344278336, acc: 0.9887892603874207)
[2024-12-17 02:44:03,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:03,319][root][INFO] - Training Epoch: 2/2, step 2363/7134 completed (loss: 0.05371236801147461, acc: 0.9860950112342834)
[2024-12-17 02:44:03,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:03,647][root][INFO] - Training Epoch: 2/2, step 2364/7134 completed (loss: 0.04525585100054741, acc: 0.9863013625144958)
[2024-12-17 02:44:03,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:03,973][root][INFO] - Training Epoch: 2/2, step 2365/7134 completed (loss: 0.03227650746703148, acc: 0.9903581142425537)
[2024-12-17 02:44:04,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:04,324][root][INFO] - Training Epoch: 2/2, step 2366/7134 completed (loss: 0.031190641224384308, acc: 0.9918981194496155)
[2024-12-17 02:44:04,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:04,695][root][INFO] - Training Epoch: 2/2, step 2367/7134 completed (loss: 0.09371014684438705, acc: 0.9861809015274048)
[2024-12-17 02:44:04,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:05,057][root][INFO] - Training Epoch: 2/2, step 2368/7134 completed (loss: 0.04541744664311409, acc: 0.9890909194946289)
[2024-12-17 02:44:05,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:05,416][root][INFO] - Training Epoch: 2/2, step 2369/7134 completed (loss: 0.029083868488669395, acc: 0.9905882477760315)
[2024-12-17 02:44:05,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:05,720][root][INFO] - Training Epoch: 2/2, step 2370/7134 completed (loss: 0.04774175584316254, acc: 0.9938271641731262)
[2024-12-17 02:44:05,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:06,084][root][INFO] - Training Epoch: 2/2, step 2371/7134 completed (loss: 0.03839707374572754, acc: 0.9870316982269287)
[2024-12-17 02:44:06,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:06,432][root][INFO] - Training Epoch: 2/2, step 2372/7134 completed (loss: 0.03434140235185623, acc: 0.9920634627342224)
[2024-12-17 02:44:06,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:06,762][root][INFO] - Training Epoch: 2/2, step 2373/7134 completed (loss: 0.018782705068588257, acc: 0.996277928352356)
[2024-12-17 02:44:06,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:07,114][root][INFO] - Training Epoch: 2/2, step 2374/7134 completed (loss: 0.03393148258328438, acc: 0.9919678568840027)
[2024-12-17 02:44:07,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:07,469][root][INFO] - Training Epoch: 2/2, step 2375/7134 completed (loss: 0.06585092097520828, acc: 0.989393949508667)
[2024-12-17 02:44:07,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:07,807][root][INFO] - Training Epoch: 2/2, step 2376/7134 completed (loss: 0.122346892952919, acc: 0.9710391759872437)
[2024-12-17 02:44:07,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:08,169][root][INFO] - Training Epoch: 2/2, step 2377/7134 completed (loss: 0.07680100947618484, acc: 0.9856630563735962)
[2024-12-17 02:44:08,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:08,531][root][INFO] - Training Epoch: 2/2, step 2378/7134 completed (loss: 0.065360888838768, acc: 0.98591548204422)
[2024-12-17 02:44:08,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:08,903][root][INFO] - Training Epoch: 2/2, step 2379/7134 completed (loss: 0.111235611140728, acc: 0.9668965339660645)
[2024-12-17 02:44:09,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:09,260][root][INFO] - Training Epoch: 2/2, step 2380/7134 completed (loss: 0.05473894625902176, acc: 0.990326464176178)
[2024-12-17 02:44:09,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:09,561][root][INFO] - Training Epoch: 2/2, step 2381/7134 completed (loss: 0.10177237540483475, acc: 0.9661590456962585)
[2024-12-17 02:44:09,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:09,884][root][INFO] - Training Epoch: 2/2, step 2382/7134 completed (loss: 0.052630066871643066, acc: 0.9877675771713257)
[2024-12-17 02:44:09,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:10,212][root][INFO] - Training Epoch: 2/2, step 2383/7134 completed (loss: 0.10756254196166992, acc: 0.9758672714233398)
[2024-12-17 02:44:10,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:10,570][root][INFO] - Training Epoch: 2/2, step 2384/7134 completed (loss: 0.09871332347393036, acc: 0.9764705896377563)
[2024-12-17 02:44:10,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:10,943][root][INFO] - Training Epoch: 2/2, step 2385/7134 completed (loss: 0.0697445347905159, acc: 0.9861878156661987)
[2024-12-17 02:44:11,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:11,348][root][INFO] - Training Epoch: 2/2, step 2386/7134 completed (loss: 0.061878450214862823, acc: 0.9842932224273682)
[2024-12-17 02:44:11,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:11,721][root][INFO] - Training Epoch: 2/2, step 2387/7134 completed (loss: 0.0763363242149353, acc: 0.9802784323692322)
[2024-12-17 02:44:11,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:12,076][root][INFO] - Training Epoch: 2/2, step 2388/7134 completed (loss: 0.11312586069107056, acc: 0.9713945388793945)
[2024-12-17 02:44:12,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:12,485][root][INFO] - Training Epoch: 2/2, step 2389/7134 completed (loss: 0.07871590554714203, acc: 0.9793341159820557)
[2024-12-17 02:44:12,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:12,840][root][INFO] - Training Epoch: 2/2, step 2390/7134 completed (loss: 0.08556907624006271, acc: 0.9749103784561157)
[2024-12-17 02:44:12,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:13,182][root][INFO] - Training Epoch: 2/2, step 2391/7134 completed (loss: 0.1214529499411583, acc: 0.975857675075531)
[2024-12-17 02:44:13,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:13,531][root][INFO] - Training Epoch: 2/2, step 2392/7134 completed (loss: 0.07143455743789673, acc: 0.9813084006309509)
[2024-12-17 02:44:13,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:13,879][root][INFO] - Training Epoch: 2/2, step 2393/7134 completed (loss: 0.06788366287946701, acc: 0.9805447459220886)
[2024-12-17 02:44:14,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:14,240][root][INFO] - Training Epoch: 2/2, step 2394/7134 completed (loss: 0.05693580210208893, acc: 0.9866666793823242)
[2024-12-17 02:44:14,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:14,575][root][INFO] - Training Epoch: 2/2, step 2395/7134 completed (loss: 0.19992601871490479, acc: 0.9592834115028381)
[2024-12-17 02:44:14,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:14,944][root][INFO] - Training Epoch: 2/2, step 2396/7134 completed (loss: 0.09412919729948044, acc: 0.9724518060684204)
[2024-12-17 02:44:15,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:15,252][root][INFO] - Training Epoch: 2/2, step 2397/7134 completed (loss: 0.10661521553993225, acc: 0.9723435044288635)
[2024-12-17 02:44:15,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:15,596][root][INFO] - Training Epoch: 2/2, step 2398/7134 completed (loss: 0.03966174274682999, acc: 0.9862448573112488)
[2024-12-17 02:44:15,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:15,939][root][INFO] - Training Epoch: 2/2, step 2399/7134 completed (loss: 0.07744376361370087, acc: 0.9785407781600952)
[2024-12-17 02:44:16,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:16,306][root][INFO] - Training Epoch: 2/2, step 2400/7134 completed (loss: 0.05015777423977852, acc: 0.9806896448135376)
[2024-12-17 02:44:16,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:16,637][root][INFO] - Training Epoch: 2/2, step 2401/7134 completed (loss: 0.13795578479766846, acc: 0.9620253443717957)
[2024-12-17 02:44:16,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:16,975][root][INFO] - Training Epoch: 2/2, step 2402/7134 completed (loss: 0.08679115772247314, acc: 0.9734395742416382)
[2024-12-17 02:44:17,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:17,316][root][INFO] - Training Epoch: 2/2, step 2403/7134 completed (loss: 0.035475581884384155, acc: 0.9858155846595764)
[2024-12-17 02:44:17,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:17,654][root][INFO] - Training Epoch: 2/2, step 2404/7134 completed (loss: 0.042150214314460754, acc: 0.9863387942314148)
[2024-12-17 02:44:17,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:18,011][root][INFO] - Training Epoch: 2/2, step 2405/7134 completed (loss: 0.07267424464225769, acc: 0.9765886068344116)
[2024-12-17 02:44:18,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:18,364][root][INFO] - Training Epoch: 2/2, step 2406/7134 completed (loss: 0.03321927785873413, acc: 0.9906914830207825)
[2024-12-17 02:44:18,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:18,718][root][INFO] - Training Epoch: 2/2, step 2407/7134 completed (loss: 0.045165225863456726, acc: 0.9863221645355225)
[2024-12-17 02:44:18,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:19,090][root][INFO] - Training Epoch: 2/2, step 2408/7134 completed (loss: 0.15878309309482574, acc: 0.9671052694320679)
[2024-12-17 02:44:19,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:19,437][root][INFO] - Training Epoch: 2/2, step 2409/7134 completed (loss: 0.040543004870414734, acc: 0.9877049326896667)
[2024-12-17 02:44:19,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:19,762][root][INFO] - Training Epoch: 2/2, step 2410/7134 completed (loss: 0.04131222516298294, acc: 0.9885222315788269)
[2024-12-17 02:44:19,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:20,119][root][INFO] - Training Epoch: 2/2, step 2411/7134 completed (loss: 0.06539173424243927, acc: 0.9805951118469238)
[2024-12-17 02:44:20,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:20,447][root][INFO] - Training Epoch: 2/2, step 2412/7134 completed (loss: 0.03864707797765732, acc: 0.9884615540504456)
[2024-12-17 02:44:20,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:20,795][root][INFO] - Training Epoch: 2/2, step 2413/7134 completed (loss: 0.027206052094697952, acc: 0.9923760890960693)
[2024-12-17 02:44:20,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:21,165][root][INFO] - Training Epoch: 2/2, step 2414/7134 completed (loss: 0.03256956860423088, acc: 0.9888059496879578)
[2024-12-17 02:44:21,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:21,536][root][INFO] - Training Epoch: 2/2, step 2415/7134 completed (loss: 0.06923219561576843, acc: 0.9794238805770874)
[2024-12-17 02:44:21,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:21,877][root][INFO] - Training Epoch: 2/2, step 2416/7134 completed (loss: 0.04556772857904434, acc: 0.9903181195259094)
[2024-12-17 02:44:21,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:22,261][root][INFO] - Training Epoch: 2/2, step 2417/7134 completed (loss: 0.06893537938594818, acc: 0.9843924045562744)
[2024-12-17 02:44:22,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:22,573][root][INFO] - Training Epoch: 2/2, step 2418/7134 completed (loss: 0.05404675006866455, acc: 0.9817159175872803)
[2024-12-17 02:44:22,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:22,898][root][INFO] - Training Epoch: 2/2, step 2419/7134 completed (loss: 0.045047029852867126, acc: 0.9814019799232483)
[2024-12-17 02:44:23,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:23,240][root][INFO] - Training Epoch: 2/2, step 2420/7134 completed (loss: 0.034408457577228546, acc: 0.9883913993835449)
[2024-12-17 02:44:23,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:23,592][root][INFO] - Training Epoch: 2/2, step 2421/7134 completed (loss: 0.07729283720254898, acc: 0.9776119589805603)
[2024-12-17 02:44:23,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:23,967][root][INFO] - Training Epoch: 2/2, step 2422/7134 completed (loss: 0.031069384887814522, acc: 0.991725742816925)
[2024-12-17 02:44:24,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:24,291][root][INFO] - Training Epoch: 2/2, step 2423/7134 completed (loss: 0.028856465592980385, acc: 0.9930264949798584)
[2024-12-17 02:44:24,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:24,623][root][INFO] - Training Epoch: 2/2, step 2424/7134 completed (loss: 0.04888366162776947, acc: 0.9873595237731934)
[2024-12-17 02:44:24,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:24,953][root][INFO] - Training Epoch: 2/2, step 2425/7134 completed (loss: 0.04228254035115242, acc: 0.9853333234786987)
[2024-12-17 02:44:25,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:25,328][root][INFO] - Training Epoch: 2/2, step 2426/7134 completed (loss: 0.03799373283982277, acc: 0.9869203567504883)
[2024-12-17 02:44:25,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:25,696][root][INFO] - Training Epoch: 2/2, step 2427/7134 completed (loss: 0.024735277518630028, acc: 0.9930394291877747)
[2024-12-17 02:44:25,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:26,087][root][INFO] - Training Epoch: 2/2, step 2428/7134 completed (loss: 0.050056539475917816, acc: 0.9885350465774536)
[2024-12-17 02:44:26,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:26,448][root][INFO] - Training Epoch: 2/2, step 2429/7134 completed (loss: 0.05155627056956291, acc: 0.9890965819358826)
[2024-12-17 02:44:26,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:26,779][root][INFO] - Training Epoch: 2/2, step 2430/7134 completed (loss: 0.05429189279675484, acc: 0.9865871667861938)
[2024-12-17 02:44:26,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:27,135][root][INFO] - Training Epoch: 2/2, step 2431/7134 completed (loss: 0.08025303483009338, acc: 0.9824047088623047)
[2024-12-17 02:44:27,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:27,485][root][INFO] - Training Epoch: 2/2, step 2432/7134 completed (loss: 0.13120302557945251, acc: 0.971137523651123)
[2024-12-17 02:44:27,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:27,835][root][INFO] - Training Epoch: 2/2, step 2433/7134 completed (loss: 0.08303900063037872, acc: 0.9815340638160706)
[2024-12-17 02:44:27,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:28,154][root][INFO] - Training Epoch: 2/2, step 2434/7134 completed (loss: 0.08858128637075424, acc: 0.97826087474823)
[2024-12-17 02:44:28,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:28,520][root][INFO] - Training Epoch: 2/2, step 2435/7134 completed (loss: 0.04808029904961586, acc: 0.9855072498321533)
[2024-12-17 02:44:28,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:28,868][root][INFO] - Training Epoch: 2/2, step 2436/7134 completed (loss: 0.04183155298233032, acc: 0.9883585572242737)
[2024-12-17 02:44:28,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:29,202][root][INFO] - Training Epoch: 2/2, step 2437/7134 completed (loss: 0.05818711221218109, acc: 0.9834087491035461)
[2024-12-17 02:44:29,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:29,569][root][INFO] - Training Epoch: 2/2, step 2438/7134 completed (loss: 0.08389923721551895, acc: 0.9784688949584961)
[2024-12-17 02:44:29,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:29,936][root][INFO] - Training Epoch: 2/2, step 2439/7134 completed (loss: 0.053281817585229874, acc: 0.9881592988967896)
[2024-12-17 02:44:30,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:30,267][root][INFO] - Training Epoch: 2/2, step 2440/7134 completed (loss: 0.07148836553096771, acc: 0.9820627570152283)
[2024-12-17 02:44:30,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:30,593][root][INFO] - Training Epoch: 2/2, step 2441/7134 completed (loss: 0.1611744612455368, acc: 0.9654510617256165)
[2024-12-17 02:44:30,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:30,936][root][INFO] - Training Epoch: 2/2, step 2442/7134 completed (loss: 0.05800069496035576, acc: 0.9818181991577148)
[2024-12-17 02:44:31,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:31,291][root][INFO] - Training Epoch: 2/2, step 2443/7134 completed (loss: 0.06300994753837585, acc: 0.9833101630210876)
[2024-12-17 02:44:31,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:31,623][root][INFO] - Training Epoch: 2/2, step 2444/7134 completed (loss: 0.07138419151306152, acc: 0.9753788113594055)
[2024-12-17 02:44:31,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:31,984][root][INFO] - Training Epoch: 2/2, step 2445/7134 completed (loss: 0.07083229720592499, acc: 0.970812201499939)
[2024-12-17 02:44:32,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:32,361][root][INFO] - Training Epoch: 2/2, step 2446/7134 completed (loss: 0.13189227879047394, acc: 0.9652777910232544)
[2024-12-17 02:44:32,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:32,731][root][INFO] - Training Epoch: 2/2, step 2447/7134 completed (loss: 0.06687648594379425, acc: 0.9800221920013428)
[2024-12-17 02:44:32,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:33,095][root][INFO] - Training Epoch: 2/2, step 2448/7134 completed (loss: 0.06147557124495506, acc: 0.9826202988624573)
[2024-12-17 02:44:33,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:33,416][root][INFO] - Training Epoch: 2/2, step 2449/7134 completed (loss: 0.06897635012865067, acc: 0.9814323782920837)
[2024-12-17 02:44:33,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:33,761][root][INFO] - Training Epoch: 2/2, step 2450/7134 completed (loss: 0.05268973112106323, acc: 0.9809402823448181)
[2024-12-17 02:44:33,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:34,084][root][INFO] - Training Epoch: 2/2, step 2451/7134 completed (loss: 0.036386966705322266, acc: 0.9910827875137329)
[2024-12-17 02:44:34,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:34,459][root][INFO] - Training Epoch: 2/2, step 2452/7134 completed (loss: 0.03754182532429695, acc: 0.9908972978591919)
[2024-12-17 02:44:34,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:34,848][root][INFO] - Training Epoch: 2/2, step 2453/7134 completed (loss: 0.06872891634702682, acc: 0.9754838943481445)
[2024-12-17 02:44:34,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:35,179][root][INFO] - Training Epoch: 2/2, step 2454/7134 completed (loss: 0.05837053805589676, acc: 0.9849498271942139)
[2024-12-17 02:44:35,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:35,559][root][INFO] - Training Epoch: 2/2, step 2455/7134 completed (loss: 0.036428894847631454, acc: 0.9900850057601929)
[2024-12-17 02:44:35,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:35,900][root][INFO] - Training Epoch: 2/2, step 2456/7134 completed (loss: 0.07678794115781784, acc: 0.9805447459220886)
[2024-12-17 02:44:35,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:36,273][root][INFO] - Training Epoch: 2/2, step 2457/7134 completed (loss: 0.07955075800418854, acc: 0.980033278465271)
[2024-12-17 02:44:36,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:36,585][root][INFO] - Training Epoch: 2/2, step 2458/7134 completed (loss: 0.10227545350790024, acc: 0.9779874086380005)
[2024-12-17 02:44:36,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:36,952][root][INFO] - Training Epoch: 2/2, step 2459/7134 completed (loss: 0.024846361950039864, acc: 0.9940828680992126)
[2024-12-17 02:44:37,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:37,296][root][INFO] - Training Epoch: 2/2, step 2460/7134 completed (loss: 0.042980633676052094, acc: 0.9903181195259094)
[2024-12-17 02:44:37,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:37,641][root][INFO] - Training Epoch: 2/2, step 2461/7134 completed (loss: 0.030891714617609978, acc: 0.9927536249160767)
[2024-12-17 02:44:37,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:37,979][root][INFO] - Training Epoch: 2/2, step 2462/7134 completed (loss: 0.05688674747943878, acc: 0.9862068891525269)
[2024-12-17 02:44:38,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:38,337][root][INFO] - Training Epoch: 2/2, step 2463/7134 completed (loss: 0.04144889861345291, acc: 0.9909228682518005)
[2024-12-17 02:44:38,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:38,640][root][INFO] - Training Epoch: 2/2, step 2464/7134 completed (loss: 0.053558774292469025, acc: 0.9887640476226807)
[2024-12-17 02:44:38,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:38,993][root][INFO] - Training Epoch: 2/2, step 2465/7134 completed (loss: 0.047778308391571045, acc: 0.9854304790496826)
[2024-12-17 02:44:39,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:39,348][root][INFO] - Training Epoch: 2/2, step 2466/7134 completed (loss: 0.04147619009017944, acc: 0.990728497505188)
[2024-12-17 02:44:39,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:39,691][root][INFO] - Training Epoch: 2/2, step 2467/7134 completed (loss: 0.03990023955702782, acc: 0.9871465563774109)
[2024-12-17 02:44:39,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:40,042][root][INFO] - Training Epoch: 2/2, step 2468/7134 completed (loss: 0.01951773837208748, acc: 0.9944055676460266)
[2024-12-17 02:44:40,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:40,397][root][INFO] - Training Epoch: 2/2, step 2469/7134 completed (loss: 0.027475079521536827, acc: 0.9945429563522339)
[2024-12-17 02:44:40,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:40,719][root][INFO] - Training Epoch: 2/2, step 2470/7134 completed (loss: 0.04886353015899658, acc: 0.9882155060768127)
[2024-12-17 02:44:40,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:41,049][root][INFO] - Training Epoch: 2/2, step 2471/7134 completed (loss: 0.02553829550743103, acc: 0.9933110475540161)
[2024-12-17 02:44:41,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:41,369][root][INFO] - Training Epoch: 2/2, step 2472/7134 completed (loss: 0.020875059068202972, acc: 0.9954545497894287)
[2024-12-17 02:44:41,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:41,706][root][INFO] - Training Epoch: 2/2, step 2473/7134 completed (loss: 0.04431786760687828, acc: 0.9897540807723999)
[2024-12-17 02:44:41,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:42,052][root][INFO] - Training Epoch: 2/2, step 2474/7134 completed (loss: 0.034411102533340454, acc: 0.9873239398002625)
[2024-12-17 02:44:42,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:42,371][root][INFO] - Training Epoch: 2/2, step 2475/7134 completed (loss: 0.01888633705675602, acc: 0.9965694546699524)
[2024-12-17 02:44:42,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:42,749][root][INFO] - Training Epoch: 2/2, step 2476/7134 completed (loss: 0.06578822433948517, acc: 0.9860724210739136)
[2024-12-17 02:44:42,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:43,135][root][INFO] - Training Epoch: 2/2, step 2477/7134 completed (loss: 0.0386650525033474, acc: 0.9917126893997192)
[2024-12-17 02:44:43,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:43,470][root][INFO] - Training Epoch: 2/2, step 2478/7134 completed (loss: 0.015556173399090767, acc: 0.9953271150588989)
[2024-12-17 02:44:43,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:43,793][root][INFO] - Training Epoch: 2/2, step 2479/7134 completed (loss: 0.07904370129108429, acc: 0.9777424335479736)
[2024-12-17 02:44:43,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:44,110][root][INFO] - Training Epoch: 2/2, step 2480/7134 completed (loss: 0.005495615303516388, acc: 1.0)
[2024-12-17 02:44:44,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:44,434][root][INFO] - Training Epoch: 2/2, step 2481/7134 completed (loss: 0.04487404599785805, acc: 0.9825870394706726)
[2024-12-17 02:44:44,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:44,773][root][INFO] - Training Epoch: 2/2, step 2482/7134 completed (loss: 0.06405887007713318, acc: 0.9839486479759216)
[2024-12-17 02:44:44,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:45,125][root][INFO] - Training Epoch: 2/2, step 2483/7134 completed (loss: 0.02349410392343998, acc: 0.9958391189575195)
[2024-12-17 02:44:45,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:45,463][root][INFO] - Training Epoch: 2/2, step 2484/7134 completed (loss: 0.031810957938432693, acc: 0.9902777671813965)
[2024-12-17 02:44:45,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:45,793][root][INFO] - Training Epoch: 2/2, step 2485/7134 completed (loss: 0.021913332864642143, acc: 0.9968253970146179)
[2024-12-17 02:44:45,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:46,132][root][INFO] - Training Epoch: 2/2, step 2486/7134 completed (loss: 0.03991298750042915, acc: 0.9942528605461121)
[2024-12-17 02:44:46,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:46,463][root][INFO] - Training Epoch: 2/2, step 2487/7134 completed (loss: 0.11143378168344498, acc: 0.9811023473739624)
[2024-12-17 02:44:46,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:46,806][root][INFO] - Training Epoch: 2/2, step 2488/7134 completed (loss: 0.02258685976266861, acc: 0.9930939078330994)
[2024-12-17 02:44:46,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:47,161][root][INFO] - Training Epoch: 2/2, step 2489/7134 completed (loss: 0.018521258607506752, acc: 0.9958217144012451)
[2024-12-17 02:44:47,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:47,499][root][INFO] - Training Epoch: 2/2, step 2490/7134 completed (loss: 0.023233307525515556, acc: 0.9928673505783081)
[2024-12-17 02:44:47,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:47,833][root][INFO] - Training Epoch: 2/2, step 2491/7134 completed (loss: 0.12588946521282196, acc: 0.976190447807312)
[2024-12-17 02:44:47,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:48,167][root][INFO] - Training Epoch: 2/2, step 2492/7134 completed (loss: 0.04570336267352104, acc: 0.9863523840904236)
[2024-12-17 02:44:48,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:48,523][root][INFO] - Training Epoch: 2/2, step 2493/7134 completed (loss: 0.06456179171800613, acc: 0.9753521084785461)
[2024-12-17 02:44:48,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:48,848][root][INFO] - Training Epoch: 2/2, step 2494/7134 completed (loss: 0.06368469446897507, acc: 0.9837296605110168)
[2024-12-17 02:44:48,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:49,211][root][INFO] - Training Epoch: 2/2, step 2495/7134 completed (loss: 0.0539100207388401, acc: 0.9823608994483948)
[2024-12-17 02:44:49,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:49,570][root][INFO] - Training Epoch: 2/2, step 2496/7134 completed (loss: 0.028703078627586365, acc: 0.9887640476226807)
[2024-12-17 02:44:49,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:49,942][root][INFO] - Training Epoch: 2/2, step 2497/7134 completed (loss: 0.050686899572610855, acc: 0.989051103591919)
[2024-12-17 02:44:50,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:50,353][root][INFO] - Training Epoch: 2/2, step 2498/7134 completed (loss: 0.05232273414731026, acc: 0.9852104783058167)
[2024-12-17 02:44:50,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:50,728][root][INFO] - Training Epoch: 2/2, step 2499/7134 completed (loss: 0.031533319503068924, acc: 0.987922728061676)
[2024-12-17 02:44:50,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:51,077][root][INFO] - Training Epoch: 2/2, step 2500/7134 completed (loss: 0.03069598786532879, acc: 0.992277979850769)
[2024-12-17 02:44:51,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:51,425][root][INFO] - Training Epoch: 2/2, step 2501/7134 completed (loss: 0.054291773587465286, acc: 0.9839816689491272)
[2024-12-17 02:44:51,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:51,780][root][INFO] - Training Epoch: 2/2, step 2502/7134 completed (loss: 0.02419975772500038, acc: 0.9929328560829163)
[2024-12-17 02:44:51,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:52,096][root][INFO] - Training Epoch: 2/2, step 2503/7134 completed (loss: 0.04956524074077606, acc: 0.9886040091514587)
[2024-12-17 02:44:52,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:52,438][root][INFO] - Training Epoch: 2/2, step 2504/7134 completed (loss: 0.023929769173264503, acc: 0.9933333396911621)
[2024-12-17 02:44:52,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:52,795][root][INFO] - Training Epoch: 2/2, step 2505/7134 completed (loss: 0.0367334745824337, acc: 0.9908987283706665)
[2024-12-17 02:44:52,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:53,173][root][INFO] - Training Epoch: 2/2, step 2506/7134 completed (loss: 0.04379633814096451, acc: 0.9887820482254028)
[2024-12-17 02:44:53,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:53,528][root][INFO] - Training Epoch: 2/2, step 2507/7134 completed (loss: 0.014902990311384201, acc: 0.9941927790641785)
[2024-12-17 02:44:53,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:53,899][root][INFO] - Training Epoch: 2/2, step 2508/7134 completed (loss: 0.047729458659887314, acc: 0.9873272180557251)
[2024-12-17 02:44:54,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:54,238][root][INFO] - Training Epoch: 2/2, step 2509/7134 completed (loss: 0.027469992637634277, acc: 0.9889841079711914)
[2024-12-17 02:44:54,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:54,586][root][INFO] - Training Epoch: 2/2, step 2510/7134 completed (loss: 0.027835212647914886, acc: 0.9924127459526062)
[2024-12-17 02:44:54,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:54,944][root][INFO] - Training Epoch: 2/2, step 2511/7134 completed (loss: 0.07012684643268585, acc: 0.9854260087013245)
[2024-12-17 02:44:55,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:55,282][root][INFO] - Training Epoch: 2/2, step 2512/7134 completed (loss: 0.08432349562644958, acc: 0.9757084846496582)
[2024-12-17 02:44:55,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:55,646][root][INFO] - Training Epoch: 2/2, step 2513/7134 completed (loss: 0.05537046119570732, acc: 0.9869668483734131)
[2024-12-17 02:44:55,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:55,998][root][INFO] - Training Epoch: 2/2, step 2514/7134 completed (loss: 0.02791699394583702, acc: 0.9906651377677917)
[2024-12-17 02:44:56,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:56,350][root][INFO] - Training Epoch: 2/2, step 2515/7134 completed (loss: 0.025131935253739357, acc: 0.9921976327896118)
[2024-12-17 02:44:56,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:56,722][root][INFO] - Training Epoch: 2/2, step 2516/7134 completed (loss: 0.02494485303759575, acc: 0.9943181872367859)
[2024-12-17 02:44:56,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:57,125][root][INFO] - Training Epoch: 2/2, step 2517/7134 completed (loss: 0.04480065032839775, acc: 0.9896670579910278)
[2024-12-17 02:44:57,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:57,459][root][INFO] - Training Epoch: 2/2, step 2518/7134 completed (loss: 0.05011880397796631, acc: 0.9871244430541992)
[2024-12-17 02:44:57,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:57,826][root][INFO] - Training Epoch: 2/2, step 2519/7134 completed (loss: 0.015420901589095592, acc: 0.9944674968719482)
[2024-12-17 02:44:57,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:58,169][root][INFO] - Training Epoch: 2/2, step 2520/7134 completed (loss: 0.027422897517681122, acc: 0.9900285005569458)
[2024-12-17 02:44:58,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:58,527][root][INFO] - Training Epoch: 2/2, step 2521/7134 completed (loss: 0.08380482345819473, acc: 0.9819819927215576)
[2024-12-17 02:44:58,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:58,852][root][INFO] - Training Epoch: 2/2, step 2522/7134 completed (loss: 0.05227858945727348, acc: 0.9871060252189636)
[2024-12-17 02:44:58,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:59,195][root][INFO] - Training Epoch: 2/2, step 2523/7134 completed (loss: 0.059773337095975876, acc: 0.985602080821991)
[2024-12-17 02:44:59,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:59,539][root][INFO] - Training Epoch: 2/2, step 2524/7134 completed (loss: 0.009122002869844437, acc: 0.9972375631332397)
[2024-12-17 02:44:59,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:59,866][root][INFO] - Training Epoch: 2/2, step 2525/7134 completed (loss: 0.04919107258319855, acc: 0.9866443872451782)
[2024-12-17 02:44:59,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:00,138][root][INFO] - Training Epoch: 2/2, step 2526/7134 completed (loss: 0.012825069017708302, acc: 0.9929412007331848)
[2024-12-17 02:45:00,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:00,500][root][INFO] - Training Epoch: 2/2, step 2527/7134 completed (loss: 0.038551539182662964, acc: 0.9902439117431641)
[2024-12-17 02:45:00,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:00,841][root][INFO] - Training Epoch: 2/2, step 2528/7134 completed (loss: 0.013621039688587189, acc: 0.99726402759552)
[2024-12-17 02:45:00,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:01,202][root][INFO] - Training Epoch: 2/2, step 2529/7134 completed (loss: 0.024191496893763542, acc: 0.9933510422706604)
[2024-12-17 02:45:01,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:01,563][root][INFO] - Training Epoch: 2/2, step 2530/7134 completed (loss: 0.027036817744374275, acc: 0.9948052167892456)
[2024-12-17 02:45:01,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:01,894][root][INFO] - Training Epoch: 2/2, step 2531/7134 completed (loss: 0.02037087082862854, acc: 0.9903314709663391)
[2024-12-17 02:45:02,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:02,225][root][INFO] - Training Epoch: 2/2, step 2532/7134 completed (loss: 0.013708465732634068, acc: 0.9984591603279114)
[2024-12-17 02:45:02,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:02,556][root][INFO] - Training Epoch: 2/2, step 2533/7134 completed (loss: 0.04274570569396019, acc: 0.9909502267837524)
[2024-12-17 02:45:02,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:02,893][root][INFO] - Training Epoch: 2/2, step 2534/7134 completed (loss: 0.0420181080698967, acc: 0.9923567175865173)
[2024-12-17 02:45:03,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:03,238][root][INFO] - Training Epoch: 2/2, step 2535/7134 completed (loss: 0.03802144527435303, acc: 0.9903661012649536)
[2024-12-17 02:45:03,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:03,598][root][INFO] - Training Epoch: 2/2, step 2536/7134 completed (loss: 0.04978388175368309, acc: 0.9864698648452759)
[2024-12-17 02:45:03,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:03,932][root][INFO] - Training Epoch: 2/2, step 2537/7134 completed (loss: 0.07700896263122559, acc: 0.9785932898521423)
[2024-12-17 02:45:04,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:04,267][root][INFO] - Training Epoch: 2/2, step 2538/7134 completed (loss: 0.12054040282964706, acc: 0.9660056829452515)
[2024-12-17 02:45:04,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:04,550][root][INFO] - Training Epoch: 2/2, step 2539/7134 completed (loss: 0.0353853777050972, acc: 0.9910714030265808)
[2024-12-17 02:45:04,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:04,892][root][INFO] - Training Epoch: 2/2, step 2540/7134 completed (loss: 0.08224893361330032, acc: 0.9847095012664795)
[2024-12-17 02:45:04,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:05,217][root][INFO] - Training Epoch: 2/2, step 2541/7134 completed (loss: 0.04436074569821358, acc: 0.9900662302970886)
[2024-12-17 02:45:05,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:05,546][root][INFO] - Training Epoch: 2/2, step 2542/7134 completed (loss: 0.08114717155694962, acc: 0.9852070808410645)
[2024-12-17 02:45:05,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:05,901][root][INFO] - Training Epoch: 2/2, step 2543/7134 completed (loss: 0.0831027552485466, acc: 0.9795082211494446)
[2024-12-17 02:45:06,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:06,260][root][INFO] - Training Epoch: 2/2, step 2544/7134 completed (loss: 0.057628002017736435, acc: 0.9884020686149597)
[2024-12-17 02:45:06,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:06,603][root][INFO] - Training Epoch: 2/2, step 2545/7134 completed (loss: 0.06767859309911728, acc: 0.9808027744293213)
[2024-12-17 02:45:06,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:06,977][root][INFO] - Training Epoch: 2/2, step 2546/7134 completed (loss: 0.14784958958625793, acc: 0.9591836929321289)
[2024-12-17 02:45:07,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:07,312][root][INFO] - Training Epoch: 2/2, step 2547/7134 completed (loss: 0.06482624262571335, acc: 0.9822866320610046)
[2024-12-17 02:45:07,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:07,628][root][INFO] - Training Epoch: 2/2, step 2548/7134 completed (loss: 0.04587254300713539, acc: 0.9921259880065918)
[2024-12-17 02:45:07,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:07,964][root][INFO] - Training Epoch: 2/2, step 2549/7134 completed (loss: 0.08236348628997803, acc: 0.9742172956466675)
[2024-12-17 02:45:08,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:08,290][root][INFO] - Training Epoch: 2/2, step 2550/7134 completed (loss: 0.026057934388518333, acc: 0.990212082862854)
[2024-12-17 02:45:08,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:08,624][root][INFO] - Training Epoch: 2/2, step 2551/7134 completed (loss: 0.06308763474225998, acc: 0.9851484894752502)
[2024-12-17 02:45:08,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:08,904][root][INFO] - Training Epoch: 2/2, step 2552/7134 completed (loss: 0.023072348907589912, acc: 0.9936908483505249)
[2024-12-17 02:45:09,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:09,169][root][INFO] - Training Epoch: 2/2, step 2553/7134 completed (loss: 0.07106486707925797, acc: 0.9879153966903687)
[2024-12-17 02:45:09,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:09,520][root][INFO] - Training Epoch: 2/2, step 2554/7134 completed (loss: 0.08098150789737701, acc: 0.981574535369873)
[2024-12-17 02:45:09,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:09,835][root][INFO] - Training Epoch: 2/2, step 2555/7134 completed (loss: 0.061165083199739456, acc: 0.9855371713638306)
[2024-12-17 02:45:09,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:10,163][root][INFO] - Training Epoch: 2/2, step 2556/7134 completed (loss: 0.06921851634979248, acc: 0.9853249192237854)
[2024-12-17 02:45:10,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:10,510][root][INFO] - Training Epoch: 2/2, step 2557/7134 completed (loss: 0.04394606873393059, acc: 0.9868852496147156)
[2024-12-17 02:45:10,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:10,834][root][INFO] - Training Epoch: 2/2, step 2558/7134 completed (loss: 0.017741015180945396, acc: 0.9967637658119202)
[2024-12-17 02:45:10,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:11,179][root][INFO] - Training Epoch: 2/2, step 2559/7134 completed (loss: 0.02630620077252388, acc: 0.9918808937072754)
[2024-12-17 02:45:11,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:11,545][root][INFO] - Training Epoch: 2/2, step 2560/7134 completed (loss: 0.03917988762259483, acc: 0.9902439117431641)
[2024-12-17 02:45:11,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:11,884][root][INFO] - Training Epoch: 2/2, step 2561/7134 completed (loss: 0.05875514820218086, acc: 0.984749436378479)
[2024-12-17 02:45:12,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:12,203][root][INFO] - Training Epoch: 2/2, step 2562/7134 completed (loss: 0.0481419637799263, acc: 0.9846153855323792)
[2024-12-17 02:45:12,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:12,543][root][INFO] - Training Epoch: 2/2, step 2563/7134 completed (loss: 0.0427669920027256, acc: 0.9912023544311523)
[2024-12-17 02:45:12,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:12,893][root][INFO] - Training Epoch: 2/2, step 2564/7134 completed (loss: 0.13929501175880432, acc: 0.9748322367668152)
[2024-12-17 02:45:12,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:13,215][root][INFO] - Training Epoch: 2/2, step 2565/7134 completed (loss: 0.03133963793516159, acc: 0.9879153966903687)
[2024-12-17 02:45:13,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:13,575][root][INFO] - Training Epoch: 2/2, step 2566/7134 completed (loss: 0.037786439061164856, acc: 0.9859550595283508)
[2024-12-17 02:45:13,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:13,835][root][INFO] - Training Epoch: 2/2, step 2567/7134 completed (loss: 0.04446965083479881, acc: 0.9876543283462524)
[2024-12-17 02:45:13,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:14,165][root][INFO] - Training Epoch: 2/2, step 2568/7134 completed (loss: 0.06064021214842796, acc: 0.9826589822769165)
[2024-12-17 02:45:14,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:14,510][root][INFO] - Training Epoch: 2/2, step 2569/7134 completed (loss: 0.06997325271368027, acc: 0.9849397540092468)
[2024-12-17 02:45:14,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:14,843][root][INFO] - Training Epoch: 2/2, step 2570/7134 completed (loss: 0.052253901958465576, acc: 0.9880059957504272)
[2024-12-17 02:45:14,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:15,158][root][INFO] - Training Epoch: 2/2, step 2571/7134 completed (loss: 0.02198188751935959, acc: 0.994727611541748)
[2024-12-17 02:45:15,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:15,495][root][INFO] - Training Epoch: 2/2, step 2572/7134 completed (loss: 0.045881327241659164, acc: 0.988959014415741)
[2024-12-17 02:45:15,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:15,824][root][INFO] - Training Epoch: 2/2, step 2573/7134 completed (loss: 0.07778367400169373, acc: 0.9885246157646179)
[2024-12-17 02:45:15,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:16,143][root][INFO] - Training Epoch: 2/2, step 2574/7134 completed (loss: 0.04667988047003746, acc: 0.9890829920768738)
[2024-12-17 02:45:16,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:16,460][root][INFO] - Training Epoch: 2/2, step 2575/7134 completed (loss: 0.03425425663590431, acc: 0.9907063245773315)
[2024-12-17 02:45:16,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:16,783][root][INFO] - Training Epoch: 2/2, step 2576/7134 completed (loss: 0.04663008823990822, acc: 0.9896551966667175)
[2024-12-17 02:45:16,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:17,137][root][INFO] - Training Epoch: 2/2, step 2577/7134 completed (loss: 0.08272924274206161, acc: 0.9846153855323792)
[2024-12-17 02:45:17,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:17,465][root][INFO] - Training Epoch: 2/2, step 2578/7134 completed (loss: 0.08066520094871521, acc: 0.9739663004875183)
[2024-12-17 02:45:17,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:17,797][root][INFO] - Training Epoch: 2/2, step 2579/7134 completed (loss: 0.10913334786891937, acc: 0.9762658476829529)
[2024-12-17 02:45:17,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:18,165][root][INFO] - Training Epoch: 2/2, step 2580/7134 completed (loss: 0.06637798994779587, acc: 0.9817232489585876)
[2024-12-17 02:45:18,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:18,520][root][INFO] - Training Epoch: 2/2, step 2581/7134 completed (loss: 0.05121353641152382, acc: 0.9865410327911377)
[2024-12-17 02:45:18,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:18,874][root][INFO] - Training Epoch: 2/2, step 2582/7134 completed (loss: 0.04509816691279411, acc: 0.9850948452949524)
[2024-12-17 02:45:18,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:19,196][root][INFO] - Training Epoch: 2/2, step 2583/7134 completed (loss: 0.05320597067475319, acc: 0.9800853729248047)
[2024-12-17 02:45:19,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:19,507][root][INFO] - Training Epoch: 2/2, step 2584/7134 completed (loss: 0.062190063297748566, acc: 0.9895287752151489)
[2024-12-17 02:45:19,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:19,872][root][INFO] - Training Epoch: 2/2, step 2585/7134 completed (loss: 0.05695326626300812, acc: 0.9899280667304993)
[2024-12-17 02:45:20,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:20,219][root][INFO] - Training Epoch: 2/2, step 2586/7134 completed (loss: 0.0664583295583725, acc: 0.9823943376541138)
[2024-12-17 02:45:20,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:20,570][root][INFO] - Training Epoch: 2/2, step 2587/7134 completed (loss: 0.05816510692238808, acc: 0.9864864945411682)
[2024-12-17 02:45:20,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:20,919][root][INFO] - Training Epoch: 2/2, step 2588/7134 completed (loss: 0.025228407233953476, acc: 0.9931787252426147)
[2024-12-17 02:45:21,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:21,241][root][INFO] - Training Epoch: 2/2, step 2589/7134 completed (loss: 0.051510393619537354, acc: 0.9858657121658325)
[2024-12-17 02:45:21,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:21,553][root][INFO] - Training Epoch: 2/2, step 2590/7134 completed (loss: 0.06142866238951683, acc: 0.9852941036224365)
[2024-12-17 02:45:21,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:21,900][root][INFO] - Training Epoch: 2/2, step 2591/7134 completed (loss: 0.08392383903265, acc: 0.9744245409965515)
[2024-12-17 02:45:22,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:22,259][root][INFO] - Training Epoch: 2/2, step 2592/7134 completed (loss: 0.04937930405139923, acc: 0.9852398633956909)
[2024-12-17 02:45:22,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:22,609][root][INFO] - Training Epoch: 2/2, step 2593/7134 completed (loss: 0.04999834671616554, acc: 0.9895287752151489)
[2024-12-17 02:45:22,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:22,936][root][INFO] - Training Epoch: 2/2, step 2594/7134 completed (loss: 0.046101972460746765, acc: 0.9862385392189026)
[2024-12-17 02:45:23,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:23,286][root][INFO] - Training Epoch: 2/2, step 2595/7134 completed (loss: 0.04517265036702156, acc: 0.9879032373428345)
[2024-12-17 02:45:23,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:23,660][root][INFO] - Training Epoch: 2/2, step 2596/7134 completed (loss: 0.06366477161645889, acc: 0.9874686598777771)
[2024-12-17 02:45:23,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:24,009][root][INFO] - Training Epoch: 2/2, step 2597/7134 completed (loss: 0.07769370079040527, acc: 0.9824324250221252)
[2024-12-17 02:45:24,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:24,337][root][INFO] - Training Epoch: 2/2, step 2598/7134 completed (loss: 0.07306353747844696, acc: 0.9845201373100281)
[2024-12-17 02:45:24,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:24,661][root][INFO] - Training Epoch: 2/2, step 2599/7134 completed (loss: 0.021218273788690567, acc: 0.9973614811897278)
[2024-12-17 02:45:24,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:25,028][root][INFO] - Training Epoch: 2/2, step 2600/7134 completed (loss: 0.0485592857003212, acc: 0.9871959090232849)
[2024-12-17 02:45:25,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:25,379][root][INFO] - Training Epoch: 2/2, step 2601/7134 completed (loss: 0.09252921491861343, acc: 0.9769959449768066)
[2024-12-17 02:45:25,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:25,727][root][INFO] - Training Epoch: 2/2, step 2602/7134 completed (loss: 0.062013179063797, acc: 0.981840193271637)
[2024-12-17 02:45:25,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:26,109][root][INFO] - Training Epoch: 2/2, step 2603/7134 completed (loss: 0.06330779939889908, acc: 0.9844961166381836)
[2024-12-17 02:45:26,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:26,477][root][INFO] - Training Epoch: 2/2, step 2604/7134 completed (loss: 0.04822618141770363, acc: 0.984649121761322)
[2024-12-17 02:45:26,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:26,818][root][INFO] - Training Epoch: 2/2, step 2605/7134 completed (loss: 0.0885627418756485, acc: 0.9711191058158875)
[2024-12-17 02:45:26,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:27,167][root][INFO] - Training Epoch: 2/2, step 2606/7134 completed (loss: 0.05137212201952934, acc: 0.9827337861061096)
[2024-12-17 02:45:27,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:27,515][root][INFO] - Training Epoch: 2/2, step 2607/7134 completed (loss: 0.05072811245918274, acc: 0.9800000190734863)
[2024-12-17 02:45:27,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:27,860][root][INFO] - Training Epoch: 2/2, step 2608/7134 completed (loss: 0.08765791356563568, acc: 0.9765142202377319)
[2024-12-17 02:45:27,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:28,206][root][INFO] - Training Epoch: 2/2, step 2609/7134 completed (loss: 0.08784051984548569, acc: 0.9693593382835388)
[2024-12-17 02:45:28,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:28,470][root][INFO] - Training Epoch: 2/2, step 2610/7134 completed (loss: 0.0908723846077919, acc: 0.9786259531974792)
[2024-12-17 02:45:28,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:28,836][root][INFO] - Training Epoch: 2/2, step 2611/7134 completed (loss: 0.08548426628112793, acc: 0.9758898019790649)
[2024-12-17 02:45:28,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:29,201][root][INFO] - Training Epoch: 2/2, step 2612/7134 completed (loss: 0.0638413354754448, acc: 0.984054684638977)
[2024-12-17 02:45:29,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:29,580][root][INFO] - Training Epoch: 2/2, step 2613/7134 completed (loss: 0.04441659525036812, acc: 0.9822784662246704)
[2024-12-17 02:45:29,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:29,944][root][INFO] - Training Epoch: 2/2, step 2614/7134 completed (loss: 0.12243114411830902, acc: 0.9715262055397034)
[2024-12-17 02:45:30,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:30,295][root][INFO] - Training Epoch: 2/2, step 2615/7134 completed (loss: 0.08426278084516525, acc: 0.9730077385902405)
[2024-12-17 02:45:30,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:30,627][root][INFO] - Training Epoch: 2/2, step 2616/7134 completed (loss: 0.10308373719453812, acc: 0.9753086566925049)
[2024-12-17 02:45:30,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:30,985][root][INFO] - Training Epoch: 2/2, step 2617/7134 completed (loss: 0.12187528610229492, acc: 0.9689608812332153)
[2024-12-17 02:45:31,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:31,276][root][INFO] - Training Epoch: 2/2, step 2618/7134 completed (loss: 0.05411732569336891, acc: 0.9835729002952576)
[2024-12-17 02:45:31,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:31,607][root][INFO] - Training Epoch: 2/2, step 2619/7134 completed (loss: 0.07487158477306366, acc: 0.9765100479125977)
[2024-12-17 02:45:31,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:31,955][root][INFO] - Training Epoch: 2/2, step 2620/7134 completed (loss: 0.08813650161027908, acc: 0.9752168655395508)
[2024-12-17 02:45:32,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:32,306][root][INFO] - Training Epoch: 2/2, step 2621/7134 completed (loss: 0.05440249294042587, acc: 0.9845971465110779)
[2024-12-17 02:45:32,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:32,669][root][INFO] - Training Epoch: 2/2, step 2622/7134 completed (loss: 0.06667476147413254, acc: 0.9901800155639648)
[2024-12-17 02:45:32,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:33,034][root][INFO] - Training Epoch: 2/2, step 2623/7134 completed (loss: 0.08128398656845093, acc: 0.9758620858192444)
[2024-12-17 02:45:33,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:33,387][root][INFO] - Training Epoch: 2/2, step 2624/7134 completed (loss: 0.06622593104839325, acc: 0.9820022583007812)
[2024-12-17 02:45:33,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:33,739][root][INFO] - Training Epoch: 2/2, step 2625/7134 completed (loss: 0.0781773030757904, acc: 0.980555534362793)
[2024-12-17 02:45:33,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:34,093][root][INFO] - Training Epoch: 2/2, step 2626/7134 completed (loss: 0.06783226877450943, acc: 0.9764851331710815)
[2024-12-17 02:45:34,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:34,449][root][INFO] - Training Epoch: 2/2, step 2627/7134 completed (loss: 0.04858215153217316, acc: 0.9864681959152222)
[2024-12-17 02:45:34,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:34,777][root][INFO] - Training Epoch: 2/2, step 2628/7134 completed (loss: 0.07255011796951294, acc: 0.9835858345031738)
[2024-12-17 02:45:34,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:35,189][root][INFO] - Training Epoch: 2/2, step 2629/7134 completed (loss: 0.04028884693980217, acc: 0.984829306602478)
[2024-12-17 02:45:35,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:35,515][root][INFO] - Training Epoch: 2/2, step 2630/7134 completed (loss: 0.05116149038076401, acc: 0.9856230020523071)
[2024-12-17 02:45:35,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:35,864][root][INFO] - Training Epoch: 2/2, step 2631/7134 completed (loss: 0.0428997278213501, acc: 0.9918128848075867)
[2024-12-17 02:45:35,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:36,214][root][INFO] - Training Epoch: 2/2, step 2632/7134 completed (loss: 0.03294716030359268, acc: 0.9882121682167053)
[2024-12-17 02:45:36,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:36,565][root][INFO] - Training Epoch: 2/2, step 2633/7134 completed (loss: 0.09133352339267731, acc: 0.9730878472328186)
[2024-12-17 02:45:36,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:36,883][root][INFO] - Training Epoch: 2/2, step 2634/7134 completed (loss: 0.01652275212109089, acc: 0.9970015287399292)
[2024-12-17 02:45:36,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:37,242][root][INFO] - Training Epoch: 2/2, step 2635/7134 completed (loss: 0.10128939151763916, acc: 0.9791666865348816)
[2024-12-17 02:45:37,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:37,601][root][INFO] - Training Epoch: 2/2, step 2636/7134 completed (loss: 0.10344688594341278, acc: 0.9687055349349976)
[2024-12-17 02:45:37,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:37,932][root][INFO] - Training Epoch: 2/2, step 2637/7134 completed (loss: 0.23782731592655182, acc: 0.9524617791175842)
[2024-12-17 02:45:38,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:38,294][root][INFO] - Training Epoch: 2/2, step 2638/7134 completed (loss: 0.11827625334262848, acc: 0.9687092304229736)
[2024-12-17 02:45:38,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:38,629][root][INFO] - Training Epoch: 2/2, step 2639/7134 completed (loss: 0.1147274598479271, acc: 0.9688796401023865)
[2024-12-17 02:45:38,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:38,973][root][INFO] - Training Epoch: 2/2, step 2640/7134 completed (loss: 0.10921923816204071, acc: 0.9737827777862549)
[2024-12-17 02:45:39,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:39,319][root][INFO] - Training Epoch: 2/2, step 2641/7134 completed (loss: 0.07356048375368118, acc: 0.9779086709022522)
[2024-12-17 02:45:39,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:39,638][root][INFO] - Training Epoch: 2/2, step 2642/7134 completed (loss: 0.09849303960800171, acc: 0.9697508811950684)
[2024-12-17 02:45:39,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:39,984][root][INFO] - Training Epoch: 2/2, step 2643/7134 completed (loss: 0.09873073548078537, acc: 0.970099687576294)
[2024-12-17 02:45:40,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:40,373][root][INFO] - Training Epoch: 2/2, step 2644/7134 completed (loss: 0.07041223347187042, acc: 0.9830096960067749)
[2024-12-17 02:45:40,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:40,703][root][INFO] - Training Epoch: 2/2, step 2645/7134 completed (loss: 0.07638051360845566, acc: 0.9854227304458618)
[2024-12-17 02:45:40,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:41,023][root][INFO] - Training Epoch: 2/2, step 2646/7134 completed (loss: 0.1682807207107544, acc: 0.9554139971733093)
[2024-12-17 02:45:41,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:41,373][root][INFO] - Training Epoch: 2/2, step 2647/7134 completed (loss: 0.04275406524538994, acc: 0.9934980273246765)
[2024-12-17 02:45:41,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:41,709][root][INFO] - Training Epoch: 2/2, step 2648/7134 completed (loss: 0.04586926847696304, acc: 0.9845161437988281)
[2024-12-17 02:45:41,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:42,052][root][INFO] - Training Epoch: 2/2, step 2649/7134 completed (loss: 0.16705839335918427, acc: 0.9552906155586243)
[2024-12-17 02:45:42,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:42,364][root][INFO] - Training Epoch: 2/2, step 2650/7134 completed (loss: 0.14027215540409088, acc: 0.9576399326324463)
[2024-12-17 02:45:42,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:42,710][root][INFO] - Training Epoch: 2/2, step 2651/7134 completed (loss: 0.0485236681997776, acc: 0.9868891835212708)
[2024-12-17 02:45:42,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:43,043][root][INFO] - Training Epoch: 2/2, step 2652/7134 completed (loss: 0.05945989862084389, acc: 0.9810844659805298)
[2024-12-17 02:45:43,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:43,349][root][INFO] - Training Epoch: 2/2, step 2653/7134 completed (loss: 0.07282674312591553, acc: 0.9753289222717285)
[2024-12-17 02:45:43,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:43,677][root][INFO] - Training Epoch: 2/2, step 2654/7134 completed (loss: 0.04093213751912117, acc: 0.9901639223098755)
[2024-12-17 02:45:43,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:43,998][root][INFO] - Training Epoch: 2/2, step 2655/7134 completed (loss: 0.029757771641016006, acc: 0.9894099831581116)
[2024-12-17 02:45:44,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:44,337][root][INFO] - Training Epoch: 2/2, step 2656/7134 completed (loss: 0.0595499649643898, acc: 0.9805285334587097)
[2024-12-17 02:45:44,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:44,669][root][INFO] - Training Epoch: 2/2, step 2657/7134 completed (loss: 0.05720660835504532, acc: 0.9854838848114014)
[2024-12-17 02:45:44,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:44,997][root][INFO] - Training Epoch: 2/2, step 2658/7134 completed (loss: 0.11472795903682709, acc: 0.9746328592300415)
[2024-12-17 02:45:45,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:45,294][root][INFO] - Training Epoch: 2/2, step 2659/7134 completed (loss: 0.05819150060415268, acc: 0.984674334526062)
[2024-12-17 02:45:45,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:45,588][root][INFO] - Training Epoch: 2/2, step 2660/7134 completed (loss: 0.05178471654653549, acc: 0.9899193644523621)
[2024-12-17 02:45:45,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:45,919][root][INFO] - Training Epoch: 2/2, step 2661/7134 completed (loss: 0.04942922666668892, acc: 0.991584837436676)
[2024-12-17 02:45:46,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:46,271][root][INFO] - Training Epoch: 2/2, step 2662/7134 completed (loss: 0.0381452739238739, acc: 0.9886202216148376)
[2024-12-17 02:45:46,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:46,640][root][INFO] - Training Epoch: 2/2, step 2663/7134 completed (loss: 0.04332567751407623, acc: 0.9859648942947388)
[2024-12-17 02:45:46,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:46,992][root][INFO] - Training Epoch: 2/2, step 2664/7134 completed (loss: 0.02345949038863182, acc: 0.9896774291992188)
[2024-12-17 02:45:47,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:47,331][root][INFO] - Training Epoch: 2/2, step 2665/7134 completed (loss: 0.020076731219887733, acc: 0.9921875)
[2024-12-17 02:45:47,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:47,701][root][INFO] - Training Epoch: 2/2, step 2666/7134 completed (loss: 0.03198046237230301, acc: 0.990208089351654)
[2024-12-17 02:45:47,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:48,033][root][INFO] - Training Epoch: 2/2, step 2667/7134 completed (loss: 0.018373019993305206, acc: 0.9943342804908752)
[2024-12-17 02:45:48,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:48,362][root][INFO] - Training Epoch: 2/2, step 2668/7134 completed (loss: 0.027417635545134544, acc: 0.9946164488792419)
[2024-12-17 02:45:48,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:48,732][root][INFO] - Training Epoch: 2/2, step 2669/7134 completed (loss: 0.012009059078991413, acc: 0.9953970313072205)
[2024-12-17 02:45:48,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:49,070][root][INFO] - Training Epoch: 2/2, step 2670/7134 completed (loss: 0.04141123592853546, acc: 0.9868938326835632)
[2024-12-17 02:45:49,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:49,401][root][INFO] - Training Epoch: 2/2, step 2671/7134 completed (loss: 0.03089854307472706, acc: 0.9866310358047485)
[2024-12-17 02:45:49,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:49,753][root][INFO] - Training Epoch: 2/2, step 2672/7134 completed (loss: 0.025182262063026428, acc: 0.9956268072128296)
[2024-12-17 02:45:49,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:50,122][root][INFO] - Training Epoch: 2/2, step 2673/7134 completed (loss: 0.02034570649266243, acc: 0.9949495196342468)
[2024-12-17 02:45:50,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:50,445][root][INFO] - Training Epoch: 2/2, step 2674/7134 completed (loss: 0.023902270942926407, acc: 0.9902371168136597)
[2024-12-17 02:45:50,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:50,805][root][INFO] - Training Epoch: 2/2, step 2675/7134 completed (loss: 0.008491198532283306, acc: 0.998630166053772)
[2024-12-17 02:45:50,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:51,148][root][INFO] - Training Epoch: 2/2, step 2676/7134 completed (loss: 0.04009956866502762, acc: 0.9909090995788574)
[2024-12-17 02:45:51,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:51,497][root][INFO] - Training Epoch: 2/2, step 2677/7134 completed (loss: 0.040626976639032364, acc: 0.9866071343421936)
[2024-12-17 02:45:51,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:51,861][root][INFO] - Training Epoch: 2/2, step 2678/7134 completed (loss: 0.009968464262783527, acc: 0.9986807107925415)
[2024-12-17 02:45:51,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:52,228][root][INFO] - Training Epoch: 2/2, step 2679/7134 completed (loss: 0.014134186320006847, acc: 0.996632993221283)
[2024-12-17 02:45:52,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:52,578][root][INFO] - Training Epoch: 2/2, step 2680/7134 completed (loss: 0.03624947741627693, acc: 0.9876695275306702)
[2024-12-17 02:45:52,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:52,895][root][INFO] - Training Epoch: 2/2, step 2681/7134 completed (loss: 0.014542201533913612, acc: 0.9954476356506348)
[2024-12-17 02:45:52,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:53,180][root][INFO] - Training Epoch: 2/2, step 2682/7134 completed (loss: 0.008712733164429665, acc: 0.9984050989151001)
[2024-12-17 02:45:53,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:53,485][root][INFO] - Training Epoch: 2/2, step 2683/7134 completed (loss: 0.011210400611162186, acc: 0.9969651103019714)
[2024-12-17 02:45:53,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:53,800][root][INFO] - Training Epoch: 2/2, step 2684/7134 completed (loss: 0.0531635619699955, acc: 0.9856630563735962)
[2024-12-17 02:45:53,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:54,165][root][INFO] - Training Epoch: 2/2, step 2685/7134 completed (loss: 0.014030138030648232, acc: 0.9973992109298706)
[2024-12-17 02:45:54,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:54,537][root][INFO] - Training Epoch: 2/2, step 2686/7134 completed (loss: 0.057855233550071716, acc: 0.9849537014961243)
[2024-12-17 02:45:54,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:54,873][root][INFO] - Training Epoch: 2/2, step 2687/7134 completed (loss: 0.06900037080049515, acc: 0.9787985682487488)
[2024-12-17 02:45:54,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:55,218][root][INFO] - Training Epoch: 2/2, step 2688/7134 completed (loss: 0.07717487961053848, acc: 0.9811320900917053)
[2024-12-17 02:45:55,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:55,524][root][INFO] - Training Epoch: 2/2, step 2689/7134 completed (loss: 0.04207948222756386, acc: 0.9873417615890503)
[2024-12-17 02:45:55,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:55,863][root][INFO] - Training Epoch: 2/2, step 2690/7134 completed (loss: 0.11343015730381012, acc: 0.9706336855888367)
[2024-12-17 02:45:56,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:56,181][root][INFO] - Training Epoch: 2/2, step 2691/7134 completed (loss: 0.118514284491539, acc: 0.978515625)
[2024-12-17 02:45:56,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:56,520][root][INFO] - Training Epoch: 2/2, step 2692/7134 completed (loss: 0.14046905934810638, acc: 0.9646182656288147)
[2024-12-17 02:45:56,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:56,796][root][INFO] - Training Epoch: 2/2, step 2693/7134 completed (loss: 0.13260681927204132, acc: 0.9634615182876587)
[2024-12-17 02:45:56,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:57,131][root][INFO] - Training Epoch: 2/2, step 2694/7134 completed (loss: 0.14824965596199036, acc: 0.9750000238418579)
[2024-12-17 02:45:57,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:57,509][root][INFO] - Training Epoch: 2/2, step 2695/7134 completed (loss: 0.07131031900644302, acc: 0.9765493869781494)
[2024-12-17 02:45:57,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:57,855][root][INFO] - Training Epoch: 2/2, step 2696/7134 completed (loss: 0.09810154885053635, acc: 0.9713831543922424)
[2024-12-17 02:45:57,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:58,173][root][INFO] - Training Epoch: 2/2, step 2697/7134 completed (loss: 0.1346932053565979, acc: 0.9537750482559204)
[2024-12-17 02:45:58,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:58,524][root][INFO] - Training Epoch: 2/2, step 2698/7134 completed (loss: 0.08372197300195694, acc: 0.9743589758872986)
[2024-12-17 02:45:58,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:58,881][root][INFO] - Training Epoch: 2/2, step 2699/7134 completed (loss: 0.07967348396778107, acc: 0.9713024497032166)
[2024-12-17 02:45:58,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:59,127][root][INFO] - Training Epoch: 2/2, step 2700/7134 completed (loss: 0.0835101455450058, acc: 0.9792284965515137)
[2024-12-17 02:45:59,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:59,430][root][INFO] - Training Epoch: 2/2, step 2701/7134 completed (loss: 0.09246192127466202, acc: 0.9714285731315613)
[2024-12-17 02:45:59,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:59,614][root][INFO] - Training Epoch: 2/2, step 2702/7134 completed (loss: 0.10447903722524643, acc: 0.9739583134651184)
[2024-12-17 02:45:59,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:59,876][root][INFO] - Training Epoch: 2/2, step 2703/7134 completed (loss: 0.04713907837867737, acc: 0.977707028388977)
[2024-12-17 02:45:59,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:00,235][root][INFO] - Training Epoch: 2/2, step 2704/7134 completed (loss: 0.07133042067289352, acc: 0.979784369468689)
[2024-12-17 02:46:00,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:00,588][root][INFO] - Training Epoch: 2/2, step 2705/7134 completed (loss: 0.12386662513017654, acc: 0.9768518805503845)
[2024-12-17 02:46:00,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:00,971][root][INFO] - Training Epoch: 2/2, step 2706/7134 completed (loss: 0.10829955339431763, acc: 0.9709724187850952)
[2024-12-17 02:46:01,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:01,334][root][INFO] - Training Epoch: 2/2, step 2707/7134 completed (loss: 0.05070054531097412, acc: 0.982758641242981)
[2024-12-17 02:46:01,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:01,696][root][INFO] - Training Epoch: 2/2, step 2708/7134 completed (loss: 0.10212552547454834, acc: 0.9677419066429138)
[2024-12-17 02:46:01,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:02,060][root][INFO] - Training Epoch: 2/2, step 2709/7134 completed (loss: 0.04645700007677078, acc: 0.9837662577629089)
[2024-12-17 02:46:02,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:02,394][root][INFO] - Training Epoch: 2/2, step 2710/7134 completed (loss: 0.04453611746430397, acc: 0.9860140085220337)
[2024-12-17 02:46:02,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:02,716][root][INFO] - Training Epoch: 2/2, step 2711/7134 completed (loss: 0.04447144269943237, acc: 0.9882075190544128)
[2024-12-17 02:46:02,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:03,064][root][INFO] - Training Epoch: 2/2, step 2712/7134 completed (loss: 0.09063594043254852, acc: 0.9754464030265808)
[2024-12-17 02:46:03,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:03,418][root][INFO] - Training Epoch: 2/2, step 2713/7134 completed (loss: 0.09780970960855484, acc: 0.9832869172096252)
[2024-12-17 02:46:03,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:03,758][root][INFO] - Training Epoch: 2/2, step 2714/7134 completed (loss: 0.06582733988761902, acc: 0.9783693552017212)
[2024-12-17 02:46:03,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:04,101][root][INFO] - Training Epoch: 2/2, step 2715/7134 completed (loss: 0.043457891792058945, acc: 0.9879699349403381)
[2024-12-17 02:46:04,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:04,445][root][INFO] - Training Epoch: 2/2, step 2716/7134 completed (loss: 0.05729528144001961, acc: 0.9855832457542419)
[2024-12-17 02:46:04,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:04,782][root][INFO] - Training Epoch: 2/2, step 2717/7134 completed (loss: 0.11146695911884308, acc: 0.9733059406280518)
[2024-12-17 02:46:04,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:05,125][root][INFO] - Training Epoch: 2/2, step 2718/7134 completed (loss: 0.2316601723432541, acc: 0.9454225301742554)
[2024-12-17 02:46:05,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:05,474][root][INFO] - Training Epoch: 2/2, step 2719/7134 completed (loss: 0.08930480480194092, acc: 0.9763113260269165)
[2024-12-17 02:46:05,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:05,817][root][INFO] - Training Epoch: 2/2, step 2720/7134 completed (loss: 0.07567930966615677, acc: 0.9826498627662659)
[2024-12-17 02:46:05,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:06,118][root][INFO] - Training Epoch: 2/2, step 2721/7134 completed (loss: 0.07200825959444046, acc: 0.9826086759567261)
[2024-12-17 02:46:06,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:06,358][root][INFO] - Training Epoch: 2/2, step 2722/7134 completed (loss: 0.1682664304971695, acc: 0.9717391133308411)
[2024-12-17 02:46:06,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:06,698][root][INFO] - Training Epoch: 2/2, step 2723/7134 completed (loss: 0.13666890561580658, acc: 0.9680196642875671)
[2024-12-17 02:46:06,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:07,051][root][INFO] - Training Epoch: 2/2, step 2724/7134 completed (loss: 0.08110281825065613, acc: 0.9817739725112915)
[2024-12-17 02:46:07,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:07,395][root][INFO] - Training Epoch: 2/2, step 2725/7134 completed (loss: 0.030900487676262856, acc: 0.9917898178100586)
[2024-12-17 02:46:07,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:07,704][root][INFO] - Training Epoch: 2/2, step 2726/7134 completed (loss: 0.09015270322561264, acc: 0.9778597950935364)
[2024-12-17 02:46:07,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:08,080][root][INFO] - Training Epoch: 2/2, step 2727/7134 completed (loss: 0.08002036064863205, acc: 0.9777777791023254)
[2024-12-17 02:46:08,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:08,406][root][INFO] - Training Epoch: 2/2, step 2728/7134 completed (loss: 0.123515285551548, acc: 0.9724770784378052)
[2024-12-17 02:46:08,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:08,711][root][INFO] - Training Epoch: 2/2, step 2729/7134 completed (loss: 0.08579429239034653, acc: 0.9686411023139954)
[2024-12-17 02:46:08,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:09,035][root][INFO] - Training Epoch: 2/2, step 2730/7134 completed (loss: 0.10453308373689651, acc: 0.9708333611488342)
[2024-12-17 02:46:09,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:09,335][root][INFO] - Training Epoch: 2/2, step 2731/7134 completed (loss: 0.125910222530365, acc: 0.9610705375671387)
[2024-12-17 02:46:09,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:09,683][root][INFO] - Training Epoch: 2/2, step 2732/7134 completed (loss: 0.08017344772815704, acc: 0.9771573543548584)
[2024-12-17 02:46:09,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:10,024][root][INFO] - Training Epoch: 2/2, step 2733/7134 completed (loss: 0.0926668643951416, acc: 0.9687923789024353)
[2024-12-17 02:46:10,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:10,334][root][INFO] - Training Epoch: 2/2, step 2734/7134 completed (loss: 0.06980760395526886, acc: 0.98591548204422)
[2024-12-17 02:46:10,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:10,707][root][INFO] - Training Epoch: 2/2, step 2735/7134 completed (loss: 0.057655323296785355, acc: 0.9837398529052734)
[2024-12-17 02:46:10,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:10,983][root][INFO] - Training Epoch: 2/2, step 2736/7134 completed (loss: 0.09826340526342392, acc: 0.9682835936546326)
[2024-12-17 02:46:11,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:11,305][root][INFO] - Training Epoch: 2/2, step 2737/7134 completed (loss: 0.0870557501912117, acc: 0.9851484894752502)
[2024-12-17 02:46:11,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:11,631][root][INFO] - Training Epoch: 2/2, step 2738/7134 completed (loss: 0.067906454205513, acc: 0.9785714149475098)
[2024-12-17 02:46:11,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:11,956][root][INFO] - Training Epoch: 2/2, step 2739/7134 completed (loss: 0.09603873640298843, acc: 0.9727272987365723)
[2024-12-17 02:46:12,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:12,285][root][INFO] - Training Epoch: 2/2, step 2740/7134 completed (loss: 0.04461108520627022, acc: 0.9854862093925476)
[2024-12-17 02:46:12,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:12,590][root][INFO] - Training Epoch: 2/2, step 2741/7134 completed (loss: 0.09262225031852722, acc: 0.9649532437324524)
[2024-12-17 02:46:12,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:12,942][root][INFO] - Training Epoch: 2/2, step 2742/7134 completed (loss: 0.03663329780101776, acc: 0.9895833134651184)
[2024-12-17 02:46:13,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:13,247][root][INFO] - Training Epoch: 2/2, step 2743/7134 completed (loss: 0.03411297872662544, acc: 0.9894737005233765)
[2024-12-17 02:46:13,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:13,442][root][INFO] - Training Epoch: 2/2, step 2744/7134 completed (loss: 0.020877592265605927, acc: 1.0)
[2024-12-17 02:46:13,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:13,717][root][INFO] - Training Epoch: 2/2, step 2745/7134 completed (loss: 0.12367188930511475, acc: 0.9651567935943604)
[2024-12-17 02:46:13,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:14,016][root][INFO] - Training Epoch: 2/2, step 2746/7134 completed (loss: 0.06197480484843254, acc: 0.9871794581413269)
[2024-12-17 02:46:14,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:14,327][root][INFO] - Training Epoch: 2/2, step 2747/7134 completed (loss: 0.05146721005439758, acc: 0.9852579832077026)
[2024-12-17 02:46:14,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:14,554][root][INFO] - Training Epoch: 2/2, step 2748/7134 completed (loss: 0.024142738431692123, acc: 0.993630588054657)
[2024-12-17 02:46:14,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:14,840][root][INFO] - Training Epoch: 2/2, step 2749/7134 completed (loss: 0.07532158493995667, acc: 0.9863387942314148)
[2024-12-17 02:46:14,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:15,159][root][INFO] - Training Epoch: 2/2, step 2750/7134 completed (loss: 0.0429009385406971, acc: 0.9834586381912231)
[2024-12-17 02:46:15,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:15,459][root][INFO] - Training Epoch: 2/2, step 2751/7134 completed (loss: 0.051415763795375824, acc: 0.9873417615890503)
[2024-12-17 02:46:15,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:15,775][root][INFO] - Training Epoch: 2/2, step 2752/7134 completed (loss: 0.060193248093128204, acc: 0.9771863222122192)
[2024-12-17 02:46:15,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:16,094][root][INFO] - Training Epoch: 2/2, step 2753/7134 completed (loss: 0.08206746727228165, acc: 0.9774436354637146)
[2024-12-17 02:46:16,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:16,443][root][INFO] - Training Epoch: 2/2, step 2754/7134 completed (loss: 0.07443419843912125, acc: 0.9716024398803711)
[2024-12-17 02:46:16,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:16,765][root][INFO] - Training Epoch: 2/2, step 2755/7134 completed (loss: 0.03700880706310272, acc: 0.9883720874786377)
[2024-12-17 02:46:16,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:17,053][root][INFO] - Training Epoch: 2/2, step 2756/7134 completed (loss: 0.07737002521753311, acc: 0.9733333587646484)
[2024-12-17 02:46:17,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:17,270][root][INFO] - Training Epoch: 2/2, step 2757/7134 completed (loss: 0.07728296518325806, acc: 0.9808743000030518)
[2024-12-17 02:46:17,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:17,581][root][INFO] - Training Epoch: 2/2, step 2758/7134 completed (loss: 0.10373645275831223, acc: 0.9817351698875427)
[2024-12-17 02:46:17,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:17,854][root][INFO] - Training Epoch: 2/2, step 2759/7134 completed (loss: 0.054147083312273026, acc: 0.9899665713310242)
[2024-12-17 02:46:17,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:18,138][root][INFO] - Training Epoch: 2/2, step 2760/7134 completed (loss: 0.07018505781888962, acc: 0.9746031761169434)
[2024-12-17 02:46:18,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:18,472][root][INFO] - Training Epoch: 2/2, step 2761/7134 completed (loss: 0.11915022879838943, acc: 0.9760100841522217)
[2024-12-17 02:46:18,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:18,842][root][INFO] - Training Epoch: 2/2, step 2762/7134 completed (loss: 0.06690994650125504, acc: 0.9827387928962708)
[2024-12-17 02:46:18,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:19,195][root][INFO] - Training Epoch: 2/2, step 2763/7134 completed (loss: 0.062014516443014145, acc: 0.9861809015274048)
[2024-12-17 02:46:19,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:19,550][root][INFO] - Training Epoch: 2/2, step 2764/7134 completed (loss: 0.09726155549287796, acc: 0.9710144996643066)
[2024-12-17 02:46:19,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:19,902][root][INFO] - Training Epoch: 2/2, step 2765/7134 completed (loss: 0.0470174103975296, acc: 0.9928160905838013)
[2024-12-17 02:46:20,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:20,265][root][INFO] - Training Epoch: 2/2, step 2766/7134 completed (loss: 0.04135199636220932, acc: 0.9903069734573364)
[2024-12-17 02:46:20,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:20,613][root][INFO] - Training Epoch: 2/2, step 2767/7134 completed (loss: 0.10288039594888687, acc: 0.9740740656852722)
[2024-12-17 02:46:20,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:20,950][root][INFO] - Training Epoch: 2/2, step 2768/7134 completed (loss: 0.056353528052568436, acc: 0.985855758190155)
[2024-12-17 02:46:21,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:21,301][root][INFO] - Training Epoch: 2/2, step 2769/7134 completed (loss: 0.0689898431301117, acc: 0.9808558821678162)
[2024-12-17 02:46:21,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:21,664][root][INFO] - Training Epoch: 2/2, step 2770/7134 completed (loss: 0.065153107047081, acc: 0.9819193482398987)
[2024-12-17 02:46:21,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:22,059][root][INFO] - Training Epoch: 2/2, step 2771/7134 completed (loss: 0.07129527628421783, acc: 0.9807074069976807)
[2024-12-17 02:46:22,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:22,428][root][INFO] - Training Epoch: 2/2, step 2772/7134 completed (loss: 0.04716408625245094, acc: 0.9865771532058716)
[2024-12-17 02:46:22,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:22,797][root][INFO] - Training Epoch: 2/2, step 2773/7134 completed (loss: 0.042277976870536804, acc: 0.9817143082618713)
[2024-12-17 02:46:22,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:23,156][root][INFO] - Training Epoch: 2/2, step 2774/7134 completed (loss: 0.08433378487825394, acc: 0.9802631735801697)
[2024-12-17 02:46:23,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:23,500][root][INFO] - Training Epoch: 2/2, step 2775/7134 completed (loss: 0.05920786410570145, acc: 0.9865030646324158)
[2024-12-17 02:46:23,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:23,890][root][INFO] - Training Epoch: 2/2, step 2776/7134 completed (loss: 0.039771322160959244, acc: 0.9856850504875183)
[2024-12-17 02:46:24,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:24,238][root][INFO] - Training Epoch: 2/2, step 2777/7134 completed (loss: 0.06280066072940826, acc: 0.9853658676147461)
[2024-12-17 02:46:24,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:24,602][root][INFO] - Training Epoch: 2/2, step 2778/7134 completed (loss: 0.049999020993709564, acc: 0.9872537851333618)
[2024-12-17 02:46:24,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:24,962][root][INFO] - Training Epoch: 2/2, step 2779/7134 completed (loss: 0.07615580409765244, acc: 0.9841772317886353)
[2024-12-17 02:46:25,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:25,325][root][INFO] - Training Epoch: 2/2, step 2780/7134 completed (loss: 0.08667721599340439, acc: 0.9746835231781006)
[2024-12-17 02:46:25,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:25,691][root][INFO] - Training Epoch: 2/2, step 2781/7134 completed (loss: 0.04836495220661163, acc: 0.9831606149673462)
[2024-12-17 02:46:25,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:26,059][root][INFO] - Training Epoch: 2/2, step 2782/7134 completed (loss: 0.04570525512099266, acc: 0.9884454011917114)
[2024-12-17 02:46:26,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:26,408][root][INFO] - Training Epoch: 2/2, step 2783/7134 completed (loss: 0.039403822273015976, acc: 0.9864864945411682)
[2024-12-17 02:46:26,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:26,773][root][INFO] - Training Epoch: 2/2, step 2784/7134 completed (loss: 0.03718050941824913, acc: 0.9894847273826599)
[2024-12-17 02:46:26,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:27,151][root][INFO] - Training Epoch: 2/2, step 2785/7134 completed (loss: 0.033753857016563416, acc: 0.9912663698196411)
[2024-12-17 02:46:27,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:27,514][root][INFO] - Training Epoch: 2/2, step 2786/7134 completed (loss: 0.07405298203229904, acc: 0.979231595993042)
[2024-12-17 02:46:27,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:27,892][root][INFO] - Training Epoch: 2/2, step 2787/7134 completed (loss: 0.047680649906396866, acc: 0.9893758296966553)
[2024-12-17 02:46:27,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:28,243][root][INFO] - Training Epoch: 2/2, step 2788/7134 completed (loss: 0.043240875005722046, acc: 0.9842932224273682)
[2024-12-17 02:46:28,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:28,538][root][INFO] - Training Epoch: 2/2, step 2789/7134 completed (loss: 0.2185010015964508, acc: 0.9625360369682312)
[2024-12-17 02:46:28,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:28,846][root][INFO] - Training Epoch: 2/2, step 2790/7134 completed (loss: 0.1742071509361267, acc: 0.9536423683166504)
[2024-12-17 02:46:28,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:29,203][root][INFO] - Training Epoch: 2/2, step 2791/7134 completed (loss: 0.06272044032812119, acc: 0.9865471124649048)
[2024-12-17 02:46:29,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:29,571][root][INFO] - Training Epoch: 2/2, step 2792/7134 completed (loss: 0.042883455753326416, acc: 0.99068683385849)
[2024-12-17 02:46:29,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:29,929][root][INFO] - Training Epoch: 2/2, step 2793/7134 completed (loss: 0.05244309455156326, acc: 0.9811066389083862)
[2024-12-17 02:46:30,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:30,196][root][INFO] - Training Epoch: 2/2, step 2794/7134 completed (loss: 0.040949445217847824, acc: 0.9934853315353394)
[2024-12-17 02:46:30,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:30,526][root][INFO] - Training Epoch: 2/2, step 2795/7134 completed (loss: 0.2342708259820938, acc: 0.9373549818992615)
[2024-12-17 02:46:30,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:30,805][root][INFO] - Training Epoch: 2/2, step 2796/7134 completed (loss: 0.19318388402462006, acc: 0.9493087530136108)
[2024-12-17 02:46:30,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:31,034][root][INFO] - Training Epoch: 2/2, step 2797/7134 completed (loss: 0.137818843126297, acc: 0.9683544039726257)
[2024-12-17 02:46:31,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:31,353][root][INFO] - Training Epoch: 2/2, step 2798/7134 completed (loss: 0.14414510130882263, acc: 0.9558823704719543)
[2024-12-17 02:46:31,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:31,652][root][INFO] - Training Epoch: 2/2, step 2799/7134 completed (loss: 0.09652505069971085, acc: 0.9667250514030457)
[2024-12-17 02:46:31,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:31,936][root][INFO] - Training Epoch: 2/2, step 2800/7134 completed (loss: 0.11558589339256287, acc: 0.9771528840065002)
[2024-12-17 02:46:32,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:32,298][root][INFO] - Training Epoch: 2/2, step 2801/7134 completed (loss: 0.07396714389324188, acc: 0.9808183908462524)
[2024-12-17 02:46:32,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:32,659][root][INFO] - Training Epoch: 2/2, step 2802/7134 completed (loss: 0.06546138226985931, acc: 0.9850187301635742)
[2024-12-17 02:46:32,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:33,004][root][INFO] - Training Epoch: 2/2, step 2803/7134 completed (loss: 0.022432727739214897, acc: 0.9943422675132751)
[2024-12-17 02:46:33,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:33,379][root][INFO] - Training Epoch: 2/2, step 2804/7134 completed (loss: 0.07088863104581833, acc: 0.9863861203193665)
[2024-12-17 02:46:33,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:33,712][root][INFO] - Training Epoch: 2/2, step 2805/7134 completed (loss: 0.036358557641506195, acc: 0.9947299361228943)
[2024-12-17 02:46:33,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:34,037][root][INFO] - Training Epoch: 2/2, step 2806/7134 completed (loss: 0.07604163140058517, acc: 0.9852458834648132)
[2024-12-17 02:46:34,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:34,351][root][INFO] - Training Epoch: 2/2, step 2807/7134 completed (loss: 0.07916386425495148, acc: 0.9708939790725708)
[2024-12-17 02:46:34,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:34,704][root][INFO] - Training Epoch: 2/2, step 2808/7134 completed (loss: 0.038050178438425064, acc: 0.9874285459518433)
[2024-12-17 02:46:34,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:35,033][root][INFO] - Training Epoch: 2/2, step 2809/7134 completed (loss: 0.07493701577186584, acc: 0.9803921580314636)
[2024-12-17 02:46:35,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:35,423][root][INFO] - Training Epoch: 2/2, step 2810/7134 completed (loss: 0.04982728883624077, acc: 0.9869358539581299)
[2024-12-17 02:46:35,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:35,776][root][INFO] - Training Epoch: 2/2, step 2811/7134 completed (loss: 0.02487243339419365, acc: 0.9940333962440491)
[2024-12-17 02:46:35,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:36,130][root][INFO] - Training Epoch: 2/2, step 2812/7134 completed (loss: 0.06292291730642319, acc: 0.9876543283462524)
[2024-12-17 02:46:36,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:36,491][root][INFO] - Training Epoch: 2/2, step 2813/7134 completed (loss: 0.027047419920563698, acc: 0.99370276927948)
[2024-12-17 02:46:36,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:36,815][root][INFO] - Training Epoch: 2/2, step 2814/7134 completed (loss: 0.051588673144578934, acc: 0.9896103739738464)
[2024-12-17 02:46:36,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:37,167][root][INFO] - Training Epoch: 2/2, step 2815/7134 completed (loss: 0.06936871260404587, acc: 0.982206404209137)
[2024-12-17 02:46:37,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:37,548][root][INFO] - Training Epoch: 2/2, step 2816/7134 completed (loss: 0.06022176146507263, acc: 0.9815546870231628)
[2024-12-17 02:46:37,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:37,932][root][INFO] - Training Epoch: 2/2, step 2817/7134 completed (loss: 0.06530960649251938, acc: 0.9863731861114502)
[2024-12-17 02:46:38,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:38,302][root][INFO] - Training Epoch: 2/2, step 2818/7134 completed (loss: 0.05140756815671921, acc: 0.9824561476707458)
[2024-12-17 02:46:38,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:38,617][root][INFO] - Training Epoch: 2/2, step 2819/7134 completed (loss: 0.02862243540585041, acc: 0.9903069734573364)
[2024-12-17 02:46:38,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:38,953][root][INFO] - Training Epoch: 2/2, step 2820/7134 completed (loss: 0.12188302725553513, acc: 0.9705449342727661)
[2024-12-17 02:46:39,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:39,295][root][INFO] - Training Epoch: 2/2, step 2821/7134 completed (loss: 0.07809921354055405, acc: 0.9784946441650391)
[2024-12-17 02:46:39,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:39,650][root][INFO] - Training Epoch: 2/2, step 2822/7134 completed (loss: 0.14060626924037933, acc: 0.9620733261108398)
[2024-12-17 02:46:39,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:40,034][root][INFO] - Training Epoch: 2/2, step 2823/7134 completed (loss: 0.0987139642238617, acc: 0.9716312289237976)
[2024-12-17 02:46:40,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:40,375][root][INFO] - Training Epoch: 2/2, step 2824/7134 completed (loss: 0.12451706826686859, acc: 0.9659090638160706)
[2024-12-17 02:46:40,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:40,718][root][INFO] - Training Epoch: 2/2, step 2825/7134 completed (loss: 0.07997863739728928, acc: 0.9785234928131104)
[2024-12-17 02:46:40,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:41,074][root][INFO] - Training Epoch: 2/2, step 2826/7134 completed (loss: 0.09328828006982803, acc: 0.974397599697113)
[2024-12-17 02:46:41,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:41,435][root][INFO] - Training Epoch: 2/2, step 2827/7134 completed (loss: 0.097213514149189, acc: 0.969348669052124)
[2024-12-17 02:46:41,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:41,786][root][INFO] - Training Epoch: 2/2, step 2828/7134 completed (loss: 0.056335218250751495, acc: 0.9855999946594238)
[2024-12-17 02:46:41,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:42,142][root][INFO] - Training Epoch: 2/2, step 2829/7134 completed (loss: 0.08008208870887756, acc: 0.9768076539039612)
[2024-12-17 02:46:42,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:42,490][root][INFO] - Training Epoch: 2/2, step 2830/7134 completed (loss: 0.018266940489411354, acc: 0.994535505771637)
[2024-12-17 02:46:42,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:42,821][root][INFO] - Training Epoch: 2/2, step 2831/7134 completed (loss: 0.04234926775097847, acc: 0.9826224446296692)
[2024-12-17 02:46:42,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:43,159][root][INFO] - Training Epoch: 2/2, step 2832/7134 completed (loss: 0.06786242872476578, acc: 0.9876373410224915)
[2024-12-17 02:46:43,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:43,520][root][INFO] - Training Epoch: 2/2, step 2833/7134 completed (loss: 0.06101280450820923, acc: 0.9859648942947388)
[2024-12-17 02:46:43,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:43,872][root][INFO] - Training Epoch: 2/2, step 2834/7134 completed (loss: 0.0824786126613617, acc: 0.9796954393386841)
[2024-12-17 02:46:43,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:44,222][root][INFO] - Training Epoch: 2/2, step 2835/7134 completed (loss: 0.0814983993768692, acc: 0.9789983630180359)
[2024-12-17 02:46:44,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:44,570][root][INFO] - Training Epoch: 2/2, step 2836/7134 completed (loss: 0.08342199772596359, acc: 0.978672981262207)
[2024-12-17 02:46:44,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:44,928][root][INFO] - Training Epoch: 2/2, step 2837/7134 completed (loss: 0.041527945548295975, acc: 0.9864864945411682)
[2024-12-17 02:46:45,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:45,309][root][INFO] - Training Epoch: 2/2, step 2838/7134 completed (loss: 0.09548649191856384, acc: 0.973849356174469)
[2024-12-17 02:46:45,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:45,652][root][INFO] - Training Epoch: 2/2, step 2839/7134 completed (loss: 0.06117156520485878, acc: 0.9802731275558472)
[2024-12-17 02:46:45,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:46,022][root][INFO] - Training Epoch: 2/2, step 2840/7134 completed (loss: 0.044938668608665466, acc: 0.9848066568374634)
[2024-12-17 02:46:46,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:46,368][root][INFO] - Training Epoch: 2/2, step 2841/7134 completed (loss: 0.07880677282810211, acc: 0.9746543765068054)
[2024-12-17 02:46:46,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:46,737][root][INFO] - Training Epoch: 2/2, step 2842/7134 completed (loss: 0.0928434208035469, acc: 0.9753246903419495)
[2024-12-17 02:46:46,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:47,063][root][INFO] - Training Epoch: 2/2, step 2843/7134 completed (loss: 0.04410085082054138, acc: 0.9882352948188782)
[2024-12-17 02:46:47,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:47,419][root][INFO] - Training Epoch: 2/2, step 2844/7134 completed (loss: 0.1530921459197998, acc: 0.9548563361167908)
[2024-12-17 02:46:47,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:47,738][root][INFO] - Training Epoch: 2/2, step 2845/7134 completed (loss: 0.04840702563524246, acc: 0.9878683090209961)
[2024-12-17 02:46:47,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:48,073][root][INFO] - Training Epoch: 2/2, step 2846/7134 completed (loss: 0.11071885377168655, acc: 0.9785832166671753)
[2024-12-17 02:46:48,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:48,447][root][INFO] - Training Epoch: 2/2, step 2847/7134 completed (loss: 0.08917009830474854, acc: 0.9750733375549316)
[2024-12-17 02:46:48,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:48,708][root][INFO] - Training Epoch: 2/2, step 2848/7134 completed (loss: 0.08428266644477844, acc: 0.9883449673652649)
[2024-12-17 02:46:48,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:49,050][root][INFO] - Training Epoch: 2/2, step 2849/7134 completed (loss: 0.07692383229732513, acc: 0.9806362390518188)
[2024-12-17 02:46:49,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:49,377][root][INFO] - Training Epoch: 2/2, step 2850/7134 completed (loss: 0.04083969071507454, acc: 0.9806451797485352)
[2024-12-17 02:46:49,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:49,715][root][INFO] - Training Epoch: 2/2, step 2851/7134 completed (loss: 0.04488110914826393, acc: 0.9871086478233337)
[2024-12-17 02:46:49,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:50,035][root][INFO] - Training Epoch: 2/2, step 2852/7134 completed (loss: 0.031652066856622696, acc: 0.9900596141815186)
[2024-12-17 02:46:50,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:50,308][root][INFO] - Training Epoch: 2/2, step 2853/7134 completed (loss: 0.0724959746003151, acc: 0.9796954393386841)
[2024-12-17 02:46:50,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:50,643][root][INFO] - Training Epoch: 2/2, step 2854/7134 completed (loss: 0.058511149138212204, acc: 0.9866270422935486)
[2024-12-17 02:46:50,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:50,963][root][INFO] - Training Epoch: 2/2, step 2855/7134 completed (loss: 0.06998381018638611, acc: 0.9822294116020203)
[2024-12-17 02:46:51,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:51,323][root][INFO] - Training Epoch: 2/2, step 2856/7134 completed (loss: 0.019311435520648956, acc: 0.9915373921394348)
[2024-12-17 02:46:51,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:51,664][root][INFO] - Training Epoch: 2/2, step 2857/7134 completed (loss: 0.06008142605423927, acc: 0.9841040372848511)
[2024-12-17 02:46:51,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:51,974][root][INFO] - Training Epoch: 2/2, step 2858/7134 completed (loss: 0.033088475465774536, acc: 0.9936908483505249)
[2024-12-17 02:46:52,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:52,310][root][INFO] - Training Epoch: 2/2, step 2859/7134 completed (loss: 0.058111198246479034, acc: 0.9860529899597168)
[2024-12-17 02:46:52,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:52,630][root][INFO] - Training Epoch: 2/2, step 2860/7134 completed (loss: 0.05896658077836037, acc: 0.9779816269874573)
[2024-12-17 02:46:52,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:52,956][root][INFO] - Training Epoch: 2/2, step 2861/7134 completed (loss: 0.025941884145140648, acc: 0.993914783000946)
[2024-12-17 02:46:53,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:53,275][root][INFO] - Training Epoch: 2/2, step 2862/7134 completed (loss: 0.02804534323513508, acc: 0.9914236664772034)
[2024-12-17 02:46:53,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:53,635][root][INFO] - Training Epoch: 2/2, step 2863/7134 completed (loss: 0.011506378650665283, acc: 0.9974522590637207)
[2024-12-17 02:46:53,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:53,892][root][INFO] - Training Epoch: 2/2, step 2864/7134 completed (loss: 0.04172679781913757, acc: 0.9948052167892456)
[2024-12-17 02:46:53,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:54,224][root][INFO] - Training Epoch: 2/2, step 2865/7134 completed (loss: 0.03708885610103607, acc: 0.989130437374115)
[2024-12-17 02:46:54,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:54,553][root][INFO] - Training Epoch: 2/2, step 2866/7134 completed (loss: 0.04324330389499664, acc: 0.9895366430282593)
[2024-12-17 02:46:54,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:54,846][root][INFO] - Training Epoch: 2/2, step 2867/7134 completed (loss: 0.03767858073115349, acc: 0.9938650131225586)
[2024-12-17 02:46:54,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:55,158][root][INFO] - Training Epoch: 2/2, step 2868/7134 completed (loss: 0.029713360592722893, acc: 0.9887640476226807)
[2024-12-17 02:46:55,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:55,468][root][INFO] - Training Epoch: 2/2, step 2869/7134 completed (loss: 0.08159337192773819, acc: 0.9912152290344238)
[2024-12-17 02:46:55,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:55,803][root][INFO] - Training Epoch: 2/2, step 2870/7134 completed (loss: 0.09532372653484344, acc: 0.9790356159210205)
[2024-12-17 02:46:55,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:56,110][root][INFO] - Training Epoch: 2/2, step 2871/7134 completed (loss: 0.0639403909444809, acc: 0.9875195026397705)
[2024-12-17 02:46:56,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:56,438][root][INFO] - Training Epoch: 2/2, step 2872/7134 completed (loss: 0.029679201543331146, acc: 0.994140625)
[2024-12-17 02:46:56,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:56,759][root][INFO] - Training Epoch: 2/2, step 2873/7134 completed (loss: 0.026316793635487556, acc: 0.9908758997917175)
[2024-12-17 02:46:56,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:57,093][root][INFO] - Training Epoch: 2/2, step 2874/7134 completed (loss: 0.03147420287132263, acc: 0.9906396269798279)
[2024-12-17 02:46:57,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:57,436][root][INFO] - Training Epoch: 2/2, step 2875/7134 completed (loss: 0.03865381330251694, acc: 0.9886202216148376)
[2024-12-17 02:46:57,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:57,752][root][INFO] - Training Epoch: 2/2, step 2876/7134 completed (loss: 0.15231160819530487, acc: 0.9723502397537231)
[2024-12-17 02:46:57,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:58,074][root][INFO] - Training Epoch: 2/2, step 2877/7134 completed (loss: 0.018078867346048355, acc: 0.9956331849098206)
[2024-12-17 02:46:58,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:58,387][root][INFO] - Training Epoch: 2/2, step 2878/7134 completed (loss: 0.05100239813327789, acc: 0.9894067645072937)
[2024-12-17 02:46:58,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:58,709][root][INFO] - Training Epoch: 2/2, step 2879/7134 completed (loss: 0.017552627250552177, acc: 0.9968652129173279)
[2024-12-17 02:46:58,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:59,046][root][INFO] - Training Epoch: 2/2, step 2880/7134 completed (loss: 0.021426906809210777, acc: 0.995312511920929)
[2024-12-17 02:46:59,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:59,347][root][INFO] - Training Epoch: 2/2, step 2881/7134 completed (loss: 0.037769123911857605, acc: 0.9928443431854248)
[2024-12-17 02:46:59,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:59,694][root][INFO] - Training Epoch: 2/2, step 2882/7134 completed (loss: 0.06057656928896904, acc: 0.9790382385253906)
[2024-12-17 02:46:59,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:00,024][root][INFO] - Training Epoch: 2/2, step 2883/7134 completed (loss: 0.057914722710847855, acc: 0.9828042387962341)
[2024-12-17 02:47:00,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:00,341][root][INFO] - Training Epoch: 2/2, step 2884/7134 completed (loss: 0.0961906686425209, acc: 0.9803921580314636)
[2024-12-17 02:47:00,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:00,652][root][INFO] - Training Epoch: 2/2, step 2885/7134 completed (loss: 0.07175125181674957, acc: 0.9802731275558472)
[2024-12-17 02:47:00,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:00,967][root][INFO] - Training Epoch: 2/2, step 2886/7134 completed (loss: 0.10358787328004837, acc: 0.9701492786407471)
[2024-12-17 02:47:01,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:01,328][root][INFO] - Training Epoch: 2/2, step 2887/7134 completed (loss: 0.0830163061618805, acc: 0.9822485446929932)
[2024-12-17 02:47:01,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:01,683][root][INFO] - Training Epoch: 2/2, step 2888/7134 completed (loss: 0.08729846030473709, acc: 0.9791955351829529)
[2024-12-17 02:47:01,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:02,015][root][INFO] - Training Epoch: 2/2, step 2889/7134 completed (loss: 0.026377830654382706, acc: 0.9944598078727722)
[2024-12-17 02:47:02,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:02,363][root][INFO] - Training Epoch: 2/2, step 2890/7134 completed (loss: 0.033851660788059235, acc: 0.9906790852546692)
[2024-12-17 02:47:02,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:02,711][root][INFO] - Training Epoch: 2/2, step 2891/7134 completed (loss: 0.07007867842912674, acc: 0.9830769300460815)
[2024-12-17 02:47:02,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:03,064][root][INFO] - Training Epoch: 2/2, step 2892/7134 completed (loss: 0.0953328087925911, acc: 0.9798488616943359)
[2024-12-17 02:47:03,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:03,415][root][INFO] - Training Epoch: 2/2, step 2893/7134 completed (loss: 0.09159458428621292, acc: 0.9672130942344666)
[2024-12-17 02:47:03,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:03,755][root][INFO] - Training Epoch: 2/2, step 2894/7134 completed (loss: 0.052135903388261795, acc: 0.9865546226501465)
[2024-12-17 02:47:03,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:04,057][root][INFO] - Training Epoch: 2/2, step 2895/7134 completed (loss: 0.02647699974477291, acc: 0.9905481934547424)
[2024-12-17 02:47:04,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:04,404][root][INFO] - Training Epoch: 2/2, step 2896/7134 completed (loss: 0.03382386639714241, acc: 0.9923664331436157)
[2024-12-17 02:47:04,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:04,721][root][INFO] - Training Epoch: 2/2, step 2897/7134 completed (loss: 0.06191655993461609, acc: 0.980461835861206)
[2024-12-17 02:47:04,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:05,048][root][INFO] - Training Epoch: 2/2, step 2898/7134 completed (loss: 0.049666665494441986, acc: 0.9882352948188782)
[2024-12-17 02:47:05,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:05,373][root][INFO] - Training Epoch: 2/2, step 2899/7134 completed (loss: 0.042258743196725845, acc: 0.9898256063461304)
[2024-12-17 02:47:05,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:05,726][root][INFO] - Training Epoch: 2/2, step 2900/7134 completed (loss: 0.0428827702999115, acc: 0.9925925731658936)
[2024-12-17 02:47:05,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:06,056][root][INFO] - Training Epoch: 2/2, step 2901/7134 completed (loss: 0.04476780816912651, acc: 0.987261176109314)
[2024-12-17 02:47:06,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:06,329][root][INFO] - Training Epoch: 2/2, step 2902/7134 completed (loss: 0.05279271677136421, acc: 0.9849624037742615)
[2024-12-17 02:47:06,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:06,677][root][INFO] - Training Epoch: 2/2, step 2903/7134 completed (loss: 0.06821130216121674, acc: 0.9824561476707458)
[2024-12-17 02:47:06,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:07,027][root][INFO] - Training Epoch: 2/2, step 2904/7134 completed (loss: 0.025459090247750282, acc: 0.9900124669075012)
[2024-12-17 02:47:07,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:07,376][root][INFO] - Training Epoch: 2/2, step 2905/7134 completed (loss: 0.06174352392554283, acc: 0.9774718284606934)
[2024-12-17 02:47:07,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:07,732][root][INFO] - Training Epoch: 2/2, step 2906/7134 completed (loss: 0.026014108210802078, acc: 0.9916167855262756)
[2024-12-17 02:47:07,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:08,076][root][INFO] - Training Epoch: 2/2, step 2907/7134 completed (loss: 0.06348729133605957, acc: 0.9851951599121094)
[2024-12-17 02:47:08,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:08,424][root][INFO] - Training Epoch: 2/2, step 2908/7134 completed (loss: 0.03020000085234642, acc: 0.9922380447387695)
[2024-12-17 02:47:08,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:08,777][root][INFO] - Training Epoch: 2/2, step 2909/7134 completed (loss: 0.07236453890800476, acc: 0.9844124913215637)
[2024-12-17 02:47:08,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:09,129][root][INFO] - Training Epoch: 2/2, step 2910/7134 completed (loss: 0.09612081944942474, acc: 0.9764453768730164)
[2024-12-17 02:47:09,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:09,499][root][INFO] - Training Epoch: 2/2, step 2911/7134 completed (loss: 0.029262371361255646, acc: 0.991946280002594)
[2024-12-17 02:47:09,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:09,872][root][INFO] - Training Epoch: 2/2, step 2912/7134 completed (loss: 0.04865216091275215, acc: 0.9820689558982849)
[2024-12-17 02:47:09,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:10,229][root][INFO] - Training Epoch: 2/2, step 2913/7134 completed (loss: 0.04813311621546745, acc: 0.9886040091514587)
[2024-12-17 02:47:10,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:10,599][root][INFO] - Training Epoch: 2/2, step 2914/7134 completed (loss: 0.03736593574285507, acc: 0.9927623867988586)
[2024-12-17 02:47:10,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:10,935][root][INFO] - Training Epoch: 2/2, step 2915/7134 completed (loss: 0.10225718468427658, acc: 0.9740633964538574)
[2024-12-17 02:47:11,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:11,259][root][INFO] - Training Epoch: 2/2, step 2916/7134 completed (loss: 0.0716082751750946, acc: 0.9810996651649475)
[2024-12-17 02:47:11,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:11,607][root][INFO] - Training Epoch: 2/2, step 2917/7134 completed (loss: 0.04556698352098465, acc: 0.979899525642395)
[2024-12-17 02:47:11,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:11,970][root][INFO] - Training Epoch: 2/2, step 2918/7134 completed (loss: 0.036325544118881226, acc: 0.9895104765892029)
[2024-12-17 02:47:12,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:12,285][root][INFO] - Training Epoch: 2/2, step 2919/7134 completed (loss: 0.07048528641462326, acc: 0.9741480350494385)
[2024-12-17 02:47:12,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:12,664][root][INFO] - Training Epoch: 2/2, step 2920/7134 completed (loss: 0.03292205184698105, acc: 0.9894039630889893)
[2024-12-17 02:47:12,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:13,013][root][INFO] - Training Epoch: 2/2, step 2921/7134 completed (loss: 0.04046725481748581, acc: 0.9885057210922241)
[2024-12-17 02:47:13,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:13,338][root][INFO] - Training Epoch: 2/2, step 2922/7134 completed (loss: 0.08222398161888123, acc: 0.9786432385444641)
[2024-12-17 02:47:13,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:13,690][root][INFO] - Training Epoch: 2/2, step 2923/7134 completed (loss: 0.1930420696735382, acc: 0.9692780375480652)
[2024-12-17 02:47:13,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:14,014][root][INFO] - Training Epoch: 2/2, step 2924/7134 completed (loss: 0.03955775871872902, acc: 0.9858490824699402)
[2024-12-17 02:47:14,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:14,399][root][INFO] - Training Epoch: 2/2, step 2925/7134 completed (loss: 0.04886285215616226, acc: 0.9864864945411682)
[2024-12-17 02:47:14,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:14,771][root][INFO] - Training Epoch: 2/2, step 2926/7134 completed (loss: 0.13291919231414795, acc: 0.9783653616905212)
[2024-12-17 02:47:14,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:15,126][root][INFO] - Training Epoch: 2/2, step 2927/7134 completed (loss: 0.028998563066124916, acc: 0.990326464176178)
[2024-12-17 02:47:15,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:15,483][root][INFO] - Training Epoch: 2/2, step 2928/7134 completed (loss: 0.04681979864835739, acc: 0.9832317233085632)
[2024-12-17 02:47:15,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:15,854][root][INFO] - Training Epoch: 2/2, step 2929/7134 completed (loss: 0.030291419476270676, acc: 0.9921671152114868)
[2024-12-17 02:47:15,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:16,213][root][INFO] - Training Epoch: 2/2, step 2930/7134 completed (loss: 0.05575386807322502, acc: 0.988252580165863)
[2024-12-17 02:47:16,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:16,554][root][INFO] - Training Epoch: 2/2, step 2931/7134 completed (loss: 0.08565308898687363, acc: 0.9790732264518738)
[2024-12-17 02:47:16,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:16,896][root][INFO] - Training Epoch: 2/2, step 2932/7134 completed (loss: 0.03280000388622284, acc: 0.9895712733268738)
[2024-12-17 02:47:17,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:17,253][root][INFO] - Training Epoch: 2/2, step 2933/7134 completed (loss: 0.03827427700161934, acc: 0.9884560108184814)
[2024-12-17 02:47:17,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:17,620][root][INFO] - Training Epoch: 2/2, step 2934/7134 completed (loss: 0.0355733260512352, acc: 0.9915373921394348)
[2024-12-17 02:47:17,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:17,972][root][INFO] - Training Epoch: 2/2, step 2935/7134 completed (loss: 0.030240170657634735, acc: 0.9900881052017212)
[2024-12-17 02:47:18,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:18,347][root][INFO] - Training Epoch: 2/2, step 2936/7134 completed (loss: 0.05793159827589989, acc: 0.9867751598358154)
[2024-12-17 02:47:18,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:18,690][root][INFO] - Training Epoch: 2/2, step 2937/7134 completed (loss: 0.06737783551216125, acc: 0.9813486337661743)
[2024-12-17 02:47:18,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:19,033][root][INFO] - Training Epoch: 2/2, step 2938/7134 completed (loss: 0.041783515363931656, acc: 0.9888268113136292)
[2024-12-17 02:47:19,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:19,313][root][INFO] - Training Epoch: 2/2, step 2939/7134 completed (loss: 0.03181862831115723, acc: 0.9887820482254028)
[2024-12-17 02:47:19,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:19,648][root][INFO] - Training Epoch: 2/2, step 2940/7134 completed (loss: 0.07344705611467361, acc: 0.9822161197662354)
[2024-12-17 02:47:19,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:19,971][root][INFO] - Training Epoch: 2/2, step 2941/7134 completed (loss: 0.04271688684821129, acc: 0.9912917017936707)
[2024-12-17 02:47:20,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:20,279][root][INFO] - Training Epoch: 2/2, step 2942/7134 completed (loss: 0.047998249530792236, acc: 0.9940564632415771)
[2024-12-17 02:47:20,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:20,609][root][INFO] - Training Epoch: 2/2, step 2943/7134 completed (loss: 0.020079920068383217, acc: 0.9983136653900146)
[2024-12-17 02:47:20,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:20,941][root][INFO] - Training Epoch: 2/2, step 2944/7134 completed (loss: 0.03708823397755623, acc: 0.9911894202232361)
[2024-12-17 02:47:21,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:21,280][root][INFO] - Training Epoch: 2/2, step 2945/7134 completed (loss: 0.03830236196517944, acc: 0.9875583052635193)
[2024-12-17 02:47:21,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:21,596][root][INFO] - Training Epoch: 2/2, step 2946/7134 completed (loss: 0.04436919465661049, acc: 0.9912790656089783)
[2024-12-17 02:47:21,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:21,924][root][INFO] - Training Epoch: 2/2, step 2947/7134 completed (loss: 0.04537370800971985, acc: 0.9874213933944702)
[2024-12-17 02:47:22,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:22,260][root][INFO] - Training Epoch: 2/2, step 2948/7134 completed (loss: 0.04872937500476837, acc: 0.9851729869842529)
[2024-12-17 02:47:22,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:22,574][root][INFO] - Training Epoch: 2/2, step 2949/7134 completed (loss: 0.010958646424114704, acc: 0.9954128265380859)
[2024-12-17 02:47:22,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:22,903][root][INFO] - Training Epoch: 2/2, step 2950/7134 completed (loss: 0.02580784261226654, acc: 0.9917241334915161)
[2024-12-17 02:47:23,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:23,238][root][INFO] - Training Epoch: 2/2, step 2951/7134 completed (loss: 0.011271308176219463, acc: 0.9971014261245728)
[2024-12-17 02:47:23,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:23,575][root][INFO] - Training Epoch: 2/2, step 2952/7134 completed (loss: 0.016852835193276405, acc: 0.997032642364502)
[2024-12-17 02:47:23,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:23,892][root][INFO] - Training Epoch: 2/2, step 2953/7134 completed (loss: 0.044213905930519104, acc: 0.9881756901741028)
[2024-12-17 02:47:23,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:24,237][root][INFO] - Training Epoch: 2/2, step 2954/7134 completed (loss: 0.0440690852701664, acc: 0.9897040128707886)
[2024-12-17 02:47:24,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:24,538][root][INFO] - Training Epoch: 2/2, step 2955/7134 completed (loss: 0.0409286729991436, acc: 0.9857954382896423)
[2024-12-17 02:47:24,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:24,881][root][INFO] - Training Epoch: 2/2, step 2956/7134 completed (loss: 0.027154184877872467, acc: 0.9926793575286865)
[2024-12-17 02:47:24,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:25,223][root][INFO] - Training Epoch: 2/2, step 2957/7134 completed (loss: 0.020856378600001335, acc: 0.9959893226623535)
[2024-12-17 02:47:25,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:25,546][root][INFO] - Training Epoch: 2/2, step 2958/7134 completed (loss: 0.02583296410739422, acc: 0.9948717951774597)
[2024-12-17 02:47:25,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:25,867][root][INFO] - Training Epoch: 2/2, step 2959/7134 completed (loss: 0.030206618830561638, acc: 0.9897660613059998)
[2024-12-17 02:47:25,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:26,203][root][INFO] - Training Epoch: 2/2, step 2960/7134 completed (loss: 0.025002771988511086, acc: 0.9903581142425537)
[2024-12-17 02:47:26,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:26,556][root][INFO] - Training Epoch: 2/2, step 2961/7134 completed (loss: 0.02440265566110611, acc: 0.9918367266654968)
[2024-12-17 02:47:26,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:26,902][root][INFO] - Training Epoch: 2/2, step 2962/7134 completed (loss: 0.03195417672395706, acc: 0.9896507263183594)
[2024-12-17 02:47:27,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:27,265][root][INFO] - Training Epoch: 2/2, step 2963/7134 completed (loss: 0.023934172466397285, acc: 0.9921466112136841)
[2024-12-17 02:47:27,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:27,599][root][INFO] - Training Epoch: 2/2, step 2964/7134 completed (loss: 0.033240944147109985, acc: 0.9882869720458984)
[2024-12-17 02:47:27,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:27,928][root][INFO] - Training Epoch: 2/2, step 2965/7134 completed (loss: 0.06787903606891632, acc: 0.9820895791053772)
[2024-12-17 02:47:28,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:28,262][root][INFO] - Training Epoch: 2/2, step 2966/7134 completed (loss: 0.010423941537737846, acc: 0.9978678226470947)
[2024-12-17 02:47:28,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:28,598][root][INFO] - Training Epoch: 2/2, step 2967/7134 completed (loss: 0.048054855316877365, acc: 0.9860334992408752)
[2024-12-17 02:47:28,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:28,966][root][INFO] - Training Epoch: 2/2, step 2968/7134 completed (loss: 0.13080844283103943, acc: 0.971061110496521)
[2024-12-17 02:47:29,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:29,294][root][INFO] - Training Epoch: 2/2, step 2969/7134 completed (loss: 0.25696253776550293, acc: 0.9393491148948669)
[2024-12-17 02:47:29,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:29,629][root][INFO] - Training Epoch: 2/2, step 2970/7134 completed (loss: 0.3359144926071167, acc: 0.9411764740943909)
[2024-12-17 02:47:29,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:29,979][root][INFO] - Training Epoch: 2/2, step 2971/7134 completed (loss: 0.07846654951572418, acc: 0.9829171895980835)
[2024-12-17 02:47:30,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:30,310][root][INFO] - Training Epoch: 2/2, step 2972/7134 completed (loss: 0.04403730854392052, acc: 0.9896142482757568)
[2024-12-17 02:47:30,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:30,664][root][INFO] - Training Epoch: 2/2, step 2973/7134 completed (loss: 0.07946153730154037, acc: 0.9784809947013855)
[2024-12-17 02:47:30,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:31,014][root][INFO] - Training Epoch: 2/2, step 2974/7134 completed (loss: 0.051689647138118744, acc: 0.9870298504829407)
[2024-12-17 02:47:31,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:31,363][root][INFO] - Training Epoch: 2/2, step 2975/7134 completed (loss: 0.05086613819003105, acc: 0.9861878156661987)
[2024-12-17 02:47:31,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:31,737][root][INFO] - Training Epoch: 2/2, step 2976/7134 completed (loss: 0.055483344942331314, acc: 0.9851064085960388)
[2024-12-17 02:47:31,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:32,075][root][INFO] - Training Epoch: 2/2, step 2977/7134 completed (loss: 0.05179368704557419, acc: 0.9841040372848511)
[2024-12-17 02:47:32,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:32,417][root][INFO] - Training Epoch: 2/2, step 2978/7134 completed (loss: 0.052641015499830246, acc: 0.9843971729278564)
[2024-12-17 02:47:32,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:32,737][root][INFO] - Training Epoch: 2/2, step 2979/7134 completed (loss: 0.015086238272488117, acc: 0.9937694668769836)
[2024-12-17 02:47:32,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:33,095][root][INFO] - Training Epoch: 2/2, step 2980/7134 completed (loss: 0.056625090539455414, acc: 0.9859872460365295)
[2024-12-17 02:47:33,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:33,442][root][INFO] - Training Epoch: 2/2, step 2981/7134 completed (loss: 0.09246522933244705, acc: 0.9823608994483948)
[2024-12-17 02:47:33,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:33,773][root][INFO] - Training Epoch: 2/2, step 2982/7134 completed (loss: 0.05087103694677353, acc: 0.9895287752151489)
[2024-12-17 02:47:33,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:34,121][root][INFO] - Training Epoch: 2/2, step 2983/7134 completed (loss: 0.09076064079999924, acc: 0.9828042387962341)
[2024-12-17 02:47:34,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:34,481][root][INFO] - Training Epoch: 2/2, step 2984/7134 completed (loss: 0.04476217180490494, acc: 0.9886792302131653)
[2024-12-17 02:47:34,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:34,841][root][INFO] - Training Epoch: 2/2, step 2985/7134 completed (loss: 0.06428590416908264, acc: 0.9845053553581238)
[2024-12-17 02:47:34,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:35,214][root][INFO] - Training Epoch: 2/2, step 2986/7134 completed (loss: 0.025140095502138138, acc: 0.9929078221321106)
[2024-12-17 02:47:35,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:35,561][root][INFO] - Training Epoch: 2/2, step 2987/7134 completed (loss: 0.06438116729259491, acc: 0.9858657121658325)
[2024-12-17 02:47:35,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:35,916][root][INFO] - Training Epoch: 2/2, step 2988/7134 completed (loss: 0.040365658700466156, acc: 0.9866179823875427)
[2024-12-17 02:47:36,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:36,278][root][INFO] - Training Epoch: 2/2, step 2989/7134 completed (loss: 0.07579760253429413, acc: 0.9843137264251709)
[2024-12-17 02:47:36,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:36,589][root][INFO] - Training Epoch: 2/2, step 2990/7134 completed (loss: 0.1579856276512146, acc: 0.9685314893722534)
[2024-12-17 02:47:36,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:36,919][root][INFO] - Training Epoch: 2/2, step 2991/7134 completed (loss: 0.18341310322284698, acc: 0.957004189491272)
[2024-12-17 02:47:37,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:37,238][root][INFO] - Training Epoch: 2/2, step 2992/7134 completed (loss: 0.0848407968878746, acc: 0.9819004535675049)
[2024-12-17 02:47:37,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:37,604][root][INFO] - Training Epoch: 2/2, step 2993/7134 completed (loss: 0.05036129429936409, acc: 0.9902200698852539)
[2024-12-17 02:47:37,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:37,939][root][INFO] - Training Epoch: 2/2, step 2994/7134 completed (loss: 0.03463423624634743, acc: 0.9910072088241577)
[2024-12-17 02:47:38,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:38,319][root][INFO] - Training Epoch: 2/2, step 2995/7134 completed (loss: 0.03611515834927559, acc: 0.9909604787826538)
[2024-12-17 02:47:38,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:38,662][root][INFO] - Training Epoch: 2/2, step 2996/7134 completed (loss: 0.056959353387355804, acc: 0.9836257100105286)
[2024-12-17 02:47:38,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:39,026][root][INFO] - Training Epoch: 2/2, step 2997/7134 completed (loss: 0.03999533876776695, acc: 0.9916840195655823)
[2024-12-17 02:47:39,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:39,338][root][INFO] - Training Epoch: 2/2, step 2998/7134 completed (loss: 0.03721638768911362, acc: 0.9915151596069336)
[2024-12-17 02:47:39,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:39,722][root][INFO] - Training Epoch: 2/2, step 2999/7134 completed (loss: 0.035614240914583206, acc: 0.9884225726127625)
[2024-12-17 02:47:39,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:40,092][root][INFO] - Training Epoch: 2/2, step 3000/7134 completed (loss: 0.04263325035572052, acc: 0.9892933368682861)
[2024-12-17 02:47:40,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:40,456][root][INFO] - Training Epoch: 2/2, step 3001/7134 completed (loss: 0.04389023408293724, acc: 0.9845971465110779)
[2024-12-17 02:47:40,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:40,809][root][INFO] - Training Epoch: 2/2, step 3002/7134 completed (loss: 0.05081306770443916, acc: 0.9852607846260071)
[2024-12-17 02:47:40,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:41,178][root][INFO] - Training Epoch: 2/2, step 3003/7134 completed (loss: 0.031479544937610626, acc: 0.9895591735839844)
[2024-12-17 02:47:41,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:41,536][root][INFO] - Training Epoch: 2/2, step 3004/7134 completed (loss: 0.016015756875276566, acc: 0.9955307245254517)
[2024-12-17 02:47:41,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:41,911][root][INFO] - Training Epoch: 2/2, step 3005/7134 completed (loss: 0.020038694143295288, acc: 0.9931585192680359)
[2024-12-17 02:47:42,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:42,279][root][INFO] - Training Epoch: 2/2, step 3006/7134 completed (loss: 0.0326605848968029, acc: 0.9897828698158264)
[2024-12-17 02:47:42,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:42,626][root][INFO] - Training Epoch: 2/2, step 3007/7134 completed (loss: 0.06183741241693497, acc: 0.9824355840682983)
[2024-12-17 02:47:42,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:42,959][root][INFO] - Training Epoch: 2/2, step 3008/7134 completed (loss: 0.07802902162075043, acc: 0.9804195761680603)
[2024-12-17 02:47:43,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:43,278][root][INFO] - Training Epoch: 2/2, step 3009/7134 completed (loss: 0.13512298464775085, acc: 0.9721518754959106)
[2024-12-17 02:47:43,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:43,641][root][INFO] - Training Epoch: 2/2, step 3010/7134 completed (loss: 0.05161859467625618, acc: 0.9867403507232666)
[2024-12-17 02:47:43,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:43,989][root][INFO] - Training Epoch: 2/2, step 3011/7134 completed (loss: 0.10571598261594772, acc: 0.9786019921302795)
[2024-12-17 02:47:44,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:44,337][root][INFO] - Training Epoch: 2/2, step 3012/7134 completed (loss: 0.08747683465480804, acc: 0.9746434092521667)
[2024-12-17 02:47:44,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:44,715][root][INFO] - Training Epoch: 2/2, step 3013/7134 completed (loss: 0.03039989247918129, acc: 0.9896313548088074)
[2024-12-17 02:47:44,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:45,073][root][INFO] - Training Epoch: 2/2, step 3014/7134 completed (loss: 0.03889085352420807, acc: 0.991793692111969)
[2024-12-17 02:47:45,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:45,392][root][INFO] - Training Epoch: 2/2, step 3015/7134 completed (loss: 0.024805881083011627, acc: 0.994490385055542)
[2024-12-17 02:47:45,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:45,778][root][INFO] - Training Epoch: 2/2, step 3016/7134 completed (loss: 0.03062100149691105, acc: 0.9943740963935852)
[2024-12-17 02:47:45,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:46,120][root][INFO] - Training Epoch: 2/2, step 3017/7134 completed (loss: 0.06634441018104553, acc: 0.9779661297798157)
[2024-12-17 02:47:46,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:46,454][root][INFO] - Training Epoch: 2/2, step 3018/7134 completed (loss: 0.041649624705314636, acc: 0.9884297251701355)
[2024-12-17 02:47:46,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:46,795][root][INFO] - Training Epoch: 2/2, step 3019/7134 completed (loss: 0.05737096443772316, acc: 0.9869281053543091)
[2024-12-17 02:47:46,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:47,138][root][INFO] - Training Epoch: 2/2, step 3020/7134 completed (loss: 0.04565959796309471, acc: 0.9839572310447693)
[2024-12-17 02:47:47,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:47,454][root][INFO] - Training Epoch: 2/2, step 3021/7134 completed (loss: 0.044045884162187576, acc: 0.9909090995788574)
[2024-12-17 02:47:47,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:47,794][root][INFO] - Training Epoch: 2/2, step 3022/7134 completed (loss: 0.036477841436862946, acc: 0.9903537034988403)
[2024-12-17 02:47:47,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:48,087][root][INFO] - Training Epoch: 2/2, step 3023/7134 completed (loss: 0.06008186191320419, acc: 0.9821073412895203)
[2024-12-17 02:47:48,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:48,432][root][INFO] - Training Epoch: 2/2, step 3024/7134 completed (loss: 0.021533727645874023, acc: 0.992337167263031)
[2024-12-17 02:47:48,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:48,780][root][INFO] - Training Epoch: 2/2, step 3025/7134 completed (loss: 0.07424630969762802, acc: 0.9793103337287903)
[2024-12-17 02:47:48,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:49,108][root][INFO] - Training Epoch: 2/2, step 3026/7134 completed (loss: 0.04623151198029518, acc: 0.9910233616828918)
[2024-12-17 02:47:49,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:49,436][root][INFO] - Training Epoch: 2/2, step 3027/7134 completed (loss: 0.06451375037431717, acc: 0.9939393997192383)
[2024-12-17 02:47:49,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:49,745][root][INFO] - Training Epoch: 2/2, step 3028/7134 completed (loss: 0.018676841631531715, acc: 0.9954648613929749)
[2024-12-17 02:47:49,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:50,077][root][INFO] - Training Epoch: 2/2, step 3029/7134 completed (loss: 0.06214762106537819, acc: 0.9907264113426208)
[2024-12-17 02:47:50,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:50,450][root][INFO] - Training Epoch: 2/2, step 3030/7134 completed (loss: 0.038617853075265884, acc: 0.989313006401062)
[2024-12-17 02:47:50,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:50,769][root][INFO] - Training Epoch: 2/2, step 3031/7134 completed (loss: 0.022046241909265518, acc: 0.9957627058029175)
[2024-12-17 02:47:50,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:51,104][root][INFO] - Training Epoch: 2/2, step 3032/7134 completed (loss: 0.05952511727809906, acc: 0.9854809641838074)
[2024-12-17 02:47:51,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:51,425][root][INFO] - Training Epoch: 2/2, step 3033/7134 completed (loss: 0.03434650972485542, acc: 0.9876543283462524)
[2024-12-17 02:47:51,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:51,754][root][INFO] - Training Epoch: 2/2, step 3034/7134 completed (loss: 0.0536307767033577, acc: 0.9829787015914917)
[2024-12-17 02:47:51,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:52,071][root][INFO] - Training Epoch: 2/2, step 3035/7134 completed (loss: 0.020078616216778755, acc: 0.9937008023262024)
[2024-12-17 02:47:52,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:52,408][root][INFO] - Training Epoch: 2/2, step 3036/7134 completed (loss: 0.06950456649065018, acc: 0.9882943034172058)
[2024-12-17 02:47:52,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:52,764][root][INFO] - Training Epoch: 2/2, step 3037/7134 completed (loss: 0.04275539144873619, acc: 0.9876733422279358)
[2024-12-17 02:47:52,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:53,103][root][INFO] - Training Epoch: 2/2, step 3038/7134 completed (loss: 0.0189648624509573, acc: 0.9965217113494873)
[2024-12-17 02:47:53,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:53,433][root][INFO] - Training Epoch: 2/2, step 3039/7134 completed (loss: 0.06186836585402489, acc: 0.9892802238464355)
[2024-12-17 02:47:53,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:53,751][root][INFO] - Training Epoch: 2/2, step 3040/7134 completed (loss: 0.04370143637061119, acc: 0.9851577281951904)
[2024-12-17 02:47:53,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:54,083][root][INFO] - Training Epoch: 2/2, step 3041/7134 completed (loss: 0.06718183308839798, acc: 0.9872408509254456)
[2024-12-17 02:47:54,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:54,412][root][INFO] - Training Epoch: 2/2, step 3042/7134 completed (loss: 0.02779867872595787, acc: 0.9896602630615234)
[2024-12-17 02:47:54,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:54,726][root][INFO] - Training Epoch: 2/2, step 3043/7134 completed (loss: 0.03634606674313545, acc: 0.9923954606056213)
[2024-12-17 02:47:54,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:55,038][root][INFO] - Training Epoch: 2/2, step 3044/7134 completed (loss: 0.027104148641228676, acc: 0.9930915236473083)
[2024-12-17 02:47:55,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:55,355][root][INFO] - Training Epoch: 2/2, step 3045/7134 completed (loss: 0.024247387424111366, acc: 0.991525411605835)
[2024-12-17 02:47:55,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:55,722][root][INFO] - Training Epoch: 2/2, step 3046/7134 completed (loss: 0.03295410796999931, acc: 0.9904371500015259)
[2024-12-17 02:47:55,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:56,072][root][INFO] - Training Epoch: 2/2, step 3047/7134 completed (loss: 0.028375810012221336, acc: 0.99245285987854)
[2024-12-17 02:47:56,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:56,471][root][INFO] - Training Epoch: 2/2, step 3048/7134 completed (loss: 0.023136679083108902, acc: 0.994962215423584)
[2024-12-17 02:47:56,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:56,798][root][INFO] - Training Epoch: 2/2, step 3049/7134 completed (loss: 0.0334760807454586, acc: 0.9883720874786377)
[2024-12-17 02:47:56,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:57,153][root][INFO] - Training Epoch: 2/2, step 3050/7134 completed (loss: 0.03639012575149536, acc: 0.9881235361099243)
[2024-12-17 02:47:57,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:57,485][root][INFO] - Training Epoch: 2/2, step 3051/7134 completed (loss: 0.047276221215724945, acc: 0.9864661693572998)
[2024-12-17 02:47:57,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:57,835][root][INFO] - Training Epoch: 2/2, step 3052/7134 completed (loss: 0.03440646454691887, acc: 0.9896907210350037)
[2024-12-17 02:47:57,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:58,177][root][INFO] - Training Epoch: 2/2, step 3053/7134 completed (loss: 0.028342733159661293, acc: 0.9927536249160767)
[2024-12-17 02:47:58,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:58,523][root][INFO] - Training Epoch: 2/2, step 3054/7134 completed (loss: 0.05654682219028473, acc: 0.9883117079734802)
[2024-12-17 02:47:58,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:58,855][root][INFO] - Training Epoch: 2/2, step 3055/7134 completed (loss: 0.04664222523570061, acc: 0.988034188747406)
[2024-12-17 02:47:58,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:59,207][root][INFO] - Training Epoch: 2/2, step 3056/7134 completed (loss: 0.02976120077073574, acc: 0.9897172451019287)
[2024-12-17 02:47:59,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:59,577][root][INFO] - Training Epoch: 2/2, step 3057/7134 completed (loss: 0.019592076539993286, acc: 0.994452178478241)
[2024-12-17 02:47:59,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:59,919][root][INFO] - Training Epoch: 2/2, step 3058/7134 completed (loss: 0.08356945961713791, acc: 0.977979302406311)
[2024-12-17 02:48:00,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:00,261][root][INFO] - Training Epoch: 2/2, step 3059/7134 completed (loss: 0.023548969998955727, acc: 0.9890410900115967)
[2024-12-17 02:48:00,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:00,613][root][INFO] - Training Epoch: 2/2, step 3060/7134 completed (loss: 0.030053650960326195, acc: 0.9916467666625977)
[2024-12-17 02:48:00,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:00,927][root][INFO] - Training Epoch: 2/2, step 3061/7134 completed (loss: 0.01898549124598503, acc: 0.9954545497894287)
[2024-12-17 02:48:01,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:01,286][root][INFO] - Training Epoch: 2/2, step 3062/7134 completed (loss: 0.02353408932685852, acc: 0.993261456489563)
[2024-12-17 02:48:01,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:01,625][root][INFO] - Training Epoch: 2/2, step 3063/7134 completed (loss: 0.042006343603134155, acc: 0.9884467124938965)
[2024-12-17 02:48:01,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:01,956][root][INFO] - Training Epoch: 2/2, step 3064/7134 completed (loss: 0.018939286470413208, acc: 0.9915493130683899)
[2024-12-17 02:48:02,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:02,310][root][INFO] - Training Epoch: 2/2, step 3065/7134 completed (loss: 0.03475484624505043, acc: 0.9932795763015747)
[2024-12-17 02:48:02,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:02,647][root][INFO] - Training Epoch: 2/2, step 3066/7134 completed (loss: 0.011823093518614769, acc: 0.9983870983123779)
[2024-12-17 02:48:02,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:02,958][root][INFO] - Training Epoch: 2/2, step 3067/7134 completed (loss: 0.022340083494782448, acc: 0.9945454597473145)
[2024-12-17 02:48:03,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:03,316][root][INFO] - Training Epoch: 2/2, step 3068/7134 completed (loss: 0.0370999276638031, acc: 0.9932340979576111)
[2024-12-17 02:48:03,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:03,673][root][INFO] - Training Epoch: 2/2, step 3069/7134 completed (loss: 0.017553821206092834, acc: 0.9953917264938354)
[2024-12-17 02:48:03,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:04,072][root][INFO] - Training Epoch: 2/2, step 3070/7134 completed (loss: 0.016551772132515907, acc: 0.9936373233795166)
[2024-12-17 02:48:04,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:04,426][root][INFO] - Training Epoch: 2/2, step 3071/7134 completed (loss: 0.03603285551071167, acc: 0.992277979850769)
[2024-12-17 02:48:04,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:04,780][root][INFO] - Training Epoch: 2/2, step 3072/7134 completed (loss: 0.029844321310520172, acc: 0.9918319582939148)
[2024-12-17 02:48:04,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:05,101][root][INFO] - Training Epoch: 2/2, step 3073/7134 completed (loss: 0.024011405184864998, acc: 0.9923664331436157)
[2024-12-17 02:48:05,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:05,430][root][INFO] - Training Epoch: 2/2, step 3074/7134 completed (loss: 0.031196381896734238, acc: 0.9933444261550903)
[2024-12-17 02:48:05,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:05,761][root][INFO] - Training Epoch: 2/2, step 3075/7134 completed (loss: 0.007993298582732677, acc: 1.0)
[2024-12-17 02:48:05,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:06,113][root][INFO] - Training Epoch: 2/2, step 3076/7134 completed (loss: 0.03870739787817001, acc: 0.9877913594245911)
[2024-12-17 02:48:06,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:06,499][root][INFO] - Training Epoch: 2/2, step 3077/7134 completed (loss: 0.09918440878391266, acc: 0.9748634099960327)
[2024-12-17 02:48:06,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:06,859][root][INFO] - Training Epoch: 2/2, step 3078/7134 completed (loss: 0.0686039924621582, acc: 0.9792349934577942)
[2024-12-17 02:48:06,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:07,215][root][INFO] - Training Epoch: 2/2, step 3079/7134 completed (loss: 0.038018375635147095, acc: 0.9888888597488403)
[2024-12-17 02:48:07,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:07,588][root][INFO] - Training Epoch: 2/2, step 3080/7134 completed (loss: 0.06485023349523544, acc: 0.9814612865447998)
[2024-12-17 02:48:07,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:07,909][root][INFO] - Training Epoch: 2/2, step 3081/7134 completed (loss: 0.041122548282146454, acc: 0.9870689511299133)
[2024-12-17 02:48:08,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:08,260][root][INFO] - Training Epoch: 2/2, step 3082/7134 completed (loss: 0.08105598390102386, acc: 0.9723225235939026)
[2024-12-17 02:48:08,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:08,615][root][INFO] - Training Epoch: 2/2, step 3083/7134 completed (loss: 0.0620279498398304, acc: 0.9803664684295654)
[2024-12-17 02:48:08,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:08,964][root][INFO] - Training Epoch: 2/2, step 3084/7134 completed (loss: 0.06938419491052628, acc: 0.9821428656578064)
[2024-12-17 02:48:09,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:09,314][root][INFO] - Training Epoch: 2/2, step 3085/7134 completed (loss: 0.10130871087312698, acc: 0.9766423106193542)
[2024-12-17 02:48:09,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:09,698][root][INFO] - Training Epoch: 2/2, step 3086/7134 completed (loss: 0.05893776938319206, acc: 0.9797979593276978)
[2024-12-17 02:48:09,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:10,060][root][INFO] - Training Epoch: 2/2, step 3087/7134 completed (loss: 0.06300068646669388, acc: 0.9813486337661743)
[2024-12-17 02:48:10,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:10,427][root][INFO] - Training Epoch: 2/2, step 3088/7134 completed (loss: 0.04647556692361832, acc: 0.985343873500824)
[2024-12-17 02:48:10,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:10,810][root][INFO] - Training Epoch: 2/2, step 3089/7134 completed (loss: 0.050319232046604156, acc: 0.9881337881088257)
[2024-12-17 02:48:10,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:11,180][root][INFO] - Training Epoch: 2/2, step 3090/7134 completed (loss: 0.10181446373462677, acc: 0.9633151888847351)
[2024-12-17 02:48:11,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:11,552][root][INFO] - Training Epoch: 2/2, step 3091/7134 completed (loss: 0.04358619451522827, acc: 0.9896313548088074)
[2024-12-17 02:48:11,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:11,875][root][INFO] - Training Epoch: 2/2, step 3092/7134 completed (loss: 0.08032184839248657, acc: 0.9704251289367676)
[2024-12-17 02:48:11,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:12,227][root][INFO] - Training Epoch: 2/2, step 3093/7134 completed (loss: 0.0612558051943779, acc: 0.9867549538612366)
[2024-12-17 02:48:12,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:12,593][root][INFO] - Training Epoch: 2/2, step 3094/7134 completed (loss: 0.0160099845379591, acc: 0.9945504069328308)
[2024-12-17 02:48:12,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:12,928][root][INFO] - Training Epoch: 2/2, step 3095/7134 completed (loss: 0.092437244951725, acc: 0.9833333492279053)
[2024-12-17 02:48:13,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:13,286][root][INFO] - Training Epoch: 2/2, step 3096/7134 completed (loss: 0.08943400532007217, acc: 0.9743260741233826)
[2024-12-17 02:48:13,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:13,650][root][INFO] - Training Epoch: 2/2, step 3097/7134 completed (loss: 0.07920464873313904, acc: 0.9772079586982727)
[2024-12-17 02:48:13,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:14,002][root][INFO] - Training Epoch: 2/2, step 3098/7134 completed (loss: 0.04562506079673767, acc: 0.9811320900917053)
[2024-12-17 02:48:14,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:14,323][root][INFO] - Training Epoch: 2/2, step 3099/7134 completed (loss: 0.048950184136629105, acc: 0.9837925434112549)
[2024-12-17 02:48:14,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:14,702][root][INFO] - Training Epoch: 2/2, step 3100/7134 completed (loss: 0.054344866424798965, acc: 0.9872340559959412)
[2024-12-17 02:48:14,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:15,066][root][INFO] - Training Epoch: 2/2, step 3101/7134 completed (loss: 0.03991048410534859, acc: 0.985401451587677)
[2024-12-17 02:48:15,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:15,439][root][INFO] - Training Epoch: 2/2, step 3102/7134 completed (loss: 0.026215841993689537, acc: 0.995555579662323)
[2024-12-17 02:48:15,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:15,818][root][INFO] - Training Epoch: 2/2, step 3103/7134 completed (loss: 0.09030769765377045, acc: 0.9701810479164124)
[2024-12-17 02:48:15,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:16,099][root][INFO] - Training Epoch: 2/2, step 3104/7134 completed (loss: 0.05010031908750534, acc: 0.9904580116271973)
[2024-12-17 02:48:16,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:16,460][root][INFO] - Training Epoch: 2/2, step 3105/7134 completed (loss: 0.07521981745958328, acc: 0.9835164546966553)
[2024-12-17 02:48:16,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:16,796][root][INFO] - Training Epoch: 2/2, step 3106/7134 completed (loss: 0.05689415708184242, acc: 0.9832776188850403)
[2024-12-17 02:48:16,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:17,124][root][INFO] - Training Epoch: 2/2, step 3107/7134 completed (loss: 0.033990051597356796, acc: 0.9869281053543091)
[2024-12-17 02:48:17,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:17,477][root][INFO] - Training Epoch: 2/2, step 3108/7134 completed (loss: 0.07509952783584595, acc: 0.9846153855323792)
[2024-12-17 02:48:17,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:17,811][root][INFO] - Training Epoch: 2/2, step 3109/7134 completed (loss: 0.047484613955020905, acc: 0.9833948612213135)
[2024-12-17 02:48:17,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:18,151][root][INFO] - Training Epoch: 2/2, step 3110/7134 completed (loss: 0.042417462915182114, acc: 0.9878048896789551)
[2024-12-17 02:48:18,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:18,479][root][INFO] - Training Epoch: 2/2, step 3111/7134 completed (loss: 0.13052265346050262, acc: 0.9725086092948914)
[2024-12-17 02:48:18,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:18,795][root][INFO] - Training Epoch: 2/2, step 3112/7134 completed (loss: 0.04725484177470207, acc: 0.9894737005233765)
[2024-12-17 02:48:18,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:19,153][root][INFO] - Training Epoch: 2/2, step 3113/7134 completed (loss: 0.04250401630997658, acc: 0.9887640476226807)
[2024-12-17 02:48:19,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:19,496][root][INFO] - Training Epoch: 2/2, step 3114/7134 completed (loss: 0.037990134209394455, acc: 0.9896551966667175)
[2024-12-17 02:48:19,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:19,834][root][INFO] - Training Epoch: 2/2, step 3115/7134 completed (loss: 0.06457351893186569, acc: 0.9907407164573669)
[2024-12-17 02:48:19,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:20,190][root][INFO] - Training Epoch: 2/2, step 3116/7134 completed (loss: 0.03393230587244034, acc: 0.9897435903549194)
[2024-12-17 02:48:20,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:20,540][root][INFO] - Training Epoch: 2/2, step 3117/7134 completed (loss: 0.09289834648370743, acc: 0.97826087474823)
[2024-12-17 02:48:20,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:20,880][root][INFO] - Training Epoch: 2/2, step 3118/7134 completed (loss: 0.050049033015966415, acc: 0.9841897487640381)
[2024-12-17 02:48:20,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:21,228][root][INFO] - Training Epoch: 2/2, step 3119/7134 completed (loss: 0.0688643828034401, acc: 0.9805447459220886)
[2024-12-17 02:48:21,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:21,551][root][INFO] - Training Epoch: 2/2, step 3120/7134 completed (loss: 0.08031691610813141, acc: 0.9887164831161499)
[2024-12-17 02:48:21,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:21,885][root][INFO] - Training Epoch: 2/2, step 3121/7134 completed (loss: 0.05747296288609505, acc: 0.9832904934883118)
[2024-12-17 02:48:21,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:22,247][root][INFO] - Training Epoch: 2/2, step 3122/7134 completed (loss: 0.04595845192670822, acc: 0.989534854888916)
[2024-12-17 02:48:22,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:22,605][root][INFO] - Training Epoch: 2/2, step 3123/7134 completed (loss: 0.07773967832326889, acc: 0.9776119589805603)
[2024-12-17 02:48:22,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:22,941][root][INFO] - Training Epoch: 2/2, step 3124/7134 completed (loss: 0.05443299189209938, acc: 0.9888613820075989)
[2024-12-17 02:48:23,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:23,270][root][INFO] - Training Epoch: 2/2, step 3125/7134 completed (loss: 0.023739904165267944, acc: 0.9954614043235779)
[2024-12-17 02:48:23,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:23,646][root][INFO] - Training Epoch: 2/2, step 3126/7134 completed (loss: 0.047924380749464035, acc: 0.9860228896141052)
[2024-12-17 02:48:23,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:23,993][root][INFO] - Training Epoch: 2/2, step 3127/7134 completed (loss: 0.046710316091775894, acc: 0.9837209582328796)
[2024-12-17 02:48:24,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:24,336][root][INFO] - Training Epoch: 2/2, step 3128/7134 completed (loss: 0.039124663919210434, acc: 0.9896774291992188)
[2024-12-17 02:48:24,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:24,700][root][INFO] - Training Epoch: 2/2, step 3129/7134 completed (loss: 0.03524334728717804, acc: 0.9913473129272461)
[2024-12-17 02:48:24,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:25,077][root][INFO] - Training Epoch: 2/2, step 3130/7134 completed (loss: 0.033735547214746475, acc: 0.9931192398071289)
[2024-12-17 02:48:25,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:25,421][root][INFO] - Training Epoch: 2/2, step 3131/7134 completed (loss: 0.07278312742710114, acc: 0.9826086759567261)
[2024-12-17 02:48:25,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:25,709][root][INFO] - Training Epoch: 2/2, step 3132/7134 completed (loss: 0.040992699563503265, acc: 0.9848155975341797)
[2024-12-17 02:48:25,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:26,072][root][INFO] - Training Epoch: 2/2, step 3133/7134 completed (loss: 0.14319635927677155, acc: 0.9793956279754639)
[2024-12-17 02:48:26,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:26,433][root][INFO] - Training Epoch: 2/2, step 3134/7134 completed (loss: 0.040245965123176575, acc: 0.9853479862213135)
[2024-12-17 02:48:26,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:26,736][root][INFO] - Training Epoch: 2/2, step 3135/7134 completed (loss: 0.0559200644493103, acc: 0.9792147874832153)
[2024-12-17 02:48:26,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:27,074][root][INFO] - Training Epoch: 2/2, step 3136/7134 completed (loss: 0.02421499788761139, acc: 0.9895651936531067)
[2024-12-17 02:48:27,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:27,405][root][INFO] - Training Epoch: 2/2, step 3137/7134 completed (loss: 0.10126245766878128, acc: 0.9623016119003296)
[2024-12-17 02:48:27,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:27,717][root][INFO] - Training Epoch: 2/2, step 3138/7134 completed (loss: 0.1019301488995552, acc: 0.979411780834198)
[2024-12-17 02:48:27,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:28,002][root][INFO] - Training Epoch: 2/2, step 3139/7134 completed (loss: 0.100550077855587, acc: 0.9635193347930908)
[2024-12-17 02:48:28,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:28,310][root][INFO] - Training Epoch: 2/2, step 3140/7134 completed (loss: 0.050904255360364914, acc: 0.9863813519477844)
[2024-12-17 02:48:28,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:28,634][root][INFO] - Training Epoch: 2/2, step 3141/7134 completed (loss: 0.07406124472618103, acc: 0.9842657446861267)
[2024-12-17 02:48:28,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:28,965][root][INFO] - Training Epoch: 2/2, step 3142/7134 completed (loss: 0.030290333554148674, acc: 0.9925261735916138)
[2024-12-17 02:48:29,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:29,296][root][INFO] - Training Epoch: 2/2, step 3143/7134 completed (loss: 0.02836250700056553, acc: 0.9887459874153137)
[2024-12-17 02:48:29,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:29,632][root][INFO] - Training Epoch: 2/2, step 3144/7134 completed (loss: 0.036484215408563614, acc: 0.9905660152435303)
[2024-12-17 02:48:29,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:29,964][root][INFO] - Training Epoch: 2/2, step 3145/7134 completed (loss: 0.056689996272325516, acc: 0.9759299755096436)
[2024-12-17 02:48:30,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:30,298][root][INFO] - Training Epoch: 2/2, step 3146/7134 completed (loss: 0.04207439348101616, acc: 0.9869791865348816)
[2024-12-17 02:48:30,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:30,625][root][INFO] - Training Epoch: 2/2, step 3147/7134 completed (loss: 0.038671791553497314, acc: 0.9903692007064819)
[2024-12-17 02:48:30,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:30,979][root][INFO] - Training Epoch: 2/2, step 3148/7134 completed (loss: 0.050862569361925125, acc: 0.9859693646430969)
[2024-12-17 02:48:31,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:31,318][root][INFO] - Training Epoch: 2/2, step 3149/7134 completed (loss: 0.026988355442881584, acc: 0.9941434860229492)
[2024-12-17 02:48:31,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:31,654][root][INFO] - Training Epoch: 2/2, step 3150/7134 completed (loss: 0.1418766975402832, acc: 0.966469407081604)
[2024-12-17 02:48:31,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:31,976][root][INFO] - Training Epoch: 2/2, step 3151/7134 completed (loss: 0.11876919865608215, acc: 0.969348669052124)
[2024-12-17 02:48:32,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:32,295][root][INFO] - Training Epoch: 2/2, step 3152/7134 completed (loss: 0.05671503394842148, acc: 0.9803030490875244)
[2024-12-17 02:48:32,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:32,635][root][INFO] - Training Epoch: 2/2, step 3153/7134 completed (loss: 0.0582314170897007, acc: 0.9799498915672302)
[2024-12-17 02:48:32,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:32,967][root][INFO] - Training Epoch: 2/2, step 3154/7134 completed (loss: 0.05503556504845619, acc: 0.9893428087234497)
[2024-12-17 02:48:33,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:33,282][root][INFO] - Training Epoch: 2/2, step 3155/7134 completed (loss: 0.13228388130664825, acc: 0.9695740342140198)
[2024-12-17 02:48:33,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:33,630][root][INFO] - Training Epoch: 2/2, step 3156/7134 completed (loss: 0.1129225641489029, acc: 0.9658246636390686)
[2024-12-17 02:48:33,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:33,964][root][INFO] - Training Epoch: 2/2, step 3157/7134 completed (loss: 0.03622055426239967, acc: 0.9913978576660156)
[2024-12-17 02:48:34,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:34,309][root][INFO] - Training Epoch: 2/2, step 3158/7134 completed (loss: 0.030726803466677666, acc: 0.9869281053543091)
[2024-12-17 02:48:34,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:34,631][root][INFO] - Training Epoch: 2/2, step 3159/7134 completed (loss: 0.08844012022018433, acc: 0.9730392098426819)
[2024-12-17 02:48:34,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:34,977][root][INFO] - Training Epoch: 2/2, step 3160/7134 completed (loss: 0.01766735315322876, acc: 0.9944674968719482)
[2024-12-17 02:48:35,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:35,328][root][INFO] - Training Epoch: 2/2, step 3161/7134 completed (loss: 0.05162985995411873, acc: 0.9831932783126831)
[2024-12-17 02:48:35,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:35,664][root][INFO] - Training Epoch: 2/2, step 3162/7134 completed (loss: 0.028809763491153717, acc: 0.9927113652229309)
[2024-12-17 02:48:35,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:35,975][root][INFO] - Training Epoch: 2/2, step 3163/7134 completed (loss: 0.05198955535888672, acc: 0.9883138537406921)
[2024-12-17 02:48:36,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:36,302][root][INFO] - Training Epoch: 2/2, step 3164/7134 completed (loss: 0.07254341244697571, acc: 0.979899525642395)
[2024-12-17 02:48:36,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:36,632][root][INFO] - Training Epoch: 2/2, step 3165/7134 completed (loss: 0.026917366310954094, acc: 0.994991660118103)
[2024-12-17 02:48:36,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:36,965][root][INFO] - Training Epoch: 2/2, step 3166/7134 completed (loss: 0.09359847754240036, acc: 0.9774436354637146)
[2024-12-17 02:48:37,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:37,317][root][INFO] - Training Epoch: 2/2, step 3167/7134 completed (loss: 0.11302729696035385, acc: 0.965624988079071)
[2024-12-17 02:48:37,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:37,643][root][INFO] - Training Epoch: 2/2, step 3168/7134 completed (loss: 0.111504465341568, acc: 0.9740853905677795)
[2024-12-17 02:48:37,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:37,960][root][INFO] - Training Epoch: 2/2, step 3169/7134 completed (loss: 0.07737911492586136, acc: 0.9815573692321777)
[2024-12-17 02:48:38,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:38,290][root][INFO] - Training Epoch: 2/2, step 3170/7134 completed (loss: 0.033480819314718246, acc: 0.9818181991577148)
[2024-12-17 02:48:38,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:38,625][root][INFO] - Training Epoch: 2/2, step 3171/7134 completed (loss: 0.05694806948304176, acc: 0.9868938326835632)
[2024-12-17 02:48:38,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:38,946][root][INFO] - Training Epoch: 2/2, step 3172/7134 completed (loss: 0.015165776945650578, acc: 0.9961685538291931)
[2024-12-17 02:48:39,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:39,235][root][INFO] - Training Epoch: 2/2, step 3173/7134 completed (loss: 0.05602597817778587, acc: 0.9770408272743225)
[2024-12-17 02:48:39,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:39,573][root][INFO] - Training Epoch: 2/2, step 3174/7134 completed (loss: 0.0622984915971756, acc: 0.9837278127670288)
[2024-12-17 02:48:39,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:39,909][root][INFO] - Training Epoch: 2/2, step 3175/7134 completed (loss: 0.06588297337293625, acc: 0.9788732528686523)
[2024-12-17 02:48:40,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:40,246][root][INFO] - Training Epoch: 2/2, step 3176/7134 completed (loss: 0.07686841487884521, acc: 0.9759398698806763)
[2024-12-17 02:48:40,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:40,568][root][INFO] - Training Epoch: 2/2, step 3177/7134 completed (loss: 0.08249928057193756, acc: 0.9809027910232544)
[2024-12-17 02:48:40,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:40,889][root][INFO] - Training Epoch: 2/2, step 3178/7134 completed (loss: 0.03260745108127594, acc: 0.9885057210922241)
[2024-12-17 02:48:41,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:41,237][root][INFO] - Training Epoch: 2/2, step 3179/7134 completed (loss: 0.09579914808273315, acc: 0.9784411191940308)
[2024-12-17 02:48:41,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:41,557][root][INFO] - Training Epoch: 2/2, step 3180/7134 completed (loss: 0.05581655725836754, acc: 0.9842857122421265)
[2024-12-17 02:48:41,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:41,888][root][INFO] - Training Epoch: 2/2, step 3181/7134 completed (loss: 0.06507261097431183, acc: 0.9812792539596558)
[2024-12-17 02:48:42,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:42,234][root][INFO] - Training Epoch: 2/2, step 3182/7134 completed (loss: 0.03546127676963806, acc: 0.9940387606620789)
[2024-12-17 02:48:42,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:42,547][root][INFO] - Training Epoch: 2/2, step 3183/7134 completed (loss: 0.07044705003499985, acc: 0.9847715497016907)
[2024-12-17 02:48:42,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:42,882][root][INFO] - Training Epoch: 2/2, step 3184/7134 completed (loss: 0.06552467495203018, acc: 0.9866071343421936)
[2024-12-17 02:48:42,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:43,207][root][INFO] - Training Epoch: 2/2, step 3185/7134 completed (loss: 0.010557476431131363, acc: 0.9971510171890259)
[2024-12-17 02:48:43,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:43,541][root][INFO] - Training Epoch: 2/2, step 3186/7134 completed (loss: 0.034967485815286636, acc: 0.9896296262741089)
[2024-12-17 02:48:43,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:43,854][root][INFO] - Training Epoch: 2/2, step 3187/7134 completed (loss: 0.05017530545592308, acc: 0.9857594966888428)
[2024-12-17 02:48:43,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:44,187][root][INFO] - Training Epoch: 2/2, step 3188/7134 completed (loss: 0.04427441209554672, acc: 0.9883570671081543)
[2024-12-17 02:48:44,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:44,513][root][INFO] - Training Epoch: 2/2, step 3189/7134 completed (loss: 0.06727901846170425, acc: 0.986975371837616)
[2024-12-17 02:48:44,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:44,868][root][INFO] - Training Epoch: 2/2, step 3190/7134 completed (loss: 0.055908702313899994, acc: 0.9835442900657654)
[2024-12-17 02:48:44,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:45,180][root][INFO] - Training Epoch: 2/2, step 3191/7134 completed (loss: 0.04506206884980202, acc: 0.991428554058075)
[2024-12-17 02:48:45,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:45,498][root][INFO] - Training Epoch: 2/2, step 3192/7134 completed (loss: 0.05130873993039131, acc: 0.9886578321456909)
[2024-12-17 02:48:45,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:45,825][root][INFO] - Training Epoch: 2/2, step 3193/7134 completed (loss: 0.05731497332453728, acc: 0.9838945865631104)
[2024-12-17 02:48:45,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:46,161][root][INFO] - Training Epoch: 2/2, step 3194/7134 completed (loss: 0.05476012080907822, acc: 0.9869281053543091)
[2024-12-17 02:48:46,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:46,481][root][INFO] - Training Epoch: 2/2, step 3195/7134 completed (loss: 0.05490150302648544, acc: 0.9828473329544067)
[2024-12-17 02:48:46,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:46,799][root][INFO] - Training Epoch: 2/2, step 3196/7134 completed (loss: 0.03186781331896782, acc: 0.9906542301177979)
[2024-12-17 02:48:46,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:47,104][root][INFO] - Training Epoch: 2/2, step 3197/7134 completed (loss: 0.052329566329717636, acc: 0.9901408553123474)
[2024-12-17 02:48:47,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:47,433][root][INFO] - Training Epoch: 2/2, step 3198/7134 completed (loss: 0.03910806402564049, acc: 0.9878970980644226)
[2024-12-17 02:48:47,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:47,770][root][INFO] - Training Epoch: 2/2, step 3199/7134 completed (loss: 0.05179648473858833, acc: 0.9838472604751587)
[2024-12-17 02:48:47,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:48,066][root][INFO] - Training Epoch: 2/2, step 3200/7134 completed (loss: 0.07104247063398361, acc: 0.982425332069397)
[2024-12-17 02:48:48,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:48,418][root][INFO] - Training Epoch: 2/2, step 3201/7134 completed (loss: 0.1360580027103424, acc: 0.9761388301849365)
[2024-12-17 02:48:48,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:48,754][root][INFO] - Training Epoch: 2/2, step 3202/7134 completed (loss: 0.036064404994249344, acc: 0.9917012453079224)
[2024-12-17 02:48:48,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:49,076][root][INFO] - Training Epoch: 2/2, step 3203/7134 completed (loss: 0.04624881222844124, acc: 0.9921011328697205)
[2024-12-17 02:48:49,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:49,359][root][INFO] - Training Epoch: 2/2, step 3204/7134 completed (loss: 0.0920492485165596, acc: 0.9755638837814331)
[2024-12-17 02:48:49,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:49,694][root][INFO] - Training Epoch: 2/2, step 3205/7134 completed (loss: 0.022356493398547173, acc: 0.9946996569633484)
[2024-12-17 02:48:49,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:50,051][root][INFO] - Training Epoch: 2/2, step 3206/7134 completed (loss: 0.045145947486162186, acc: 0.9884225726127625)
[2024-12-17 02:48:50,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:50,377][root][INFO] - Training Epoch: 2/2, step 3207/7134 completed (loss: 0.04413137957453728, acc: 0.9816232919692993)
[2024-12-17 02:48:50,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:50,718][root][INFO] - Training Epoch: 2/2, step 3208/7134 completed (loss: 0.08156807720661163, acc: 0.9803921580314636)
[2024-12-17 02:48:50,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:51,045][root][INFO] - Training Epoch: 2/2, step 3209/7134 completed (loss: 0.03675561398267746, acc: 0.9910714030265808)
[2024-12-17 02:48:51,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:51,378][root][INFO] - Training Epoch: 2/2, step 3210/7134 completed (loss: 0.009488154202699661, acc: 0.9984939694404602)
[2024-12-17 02:48:51,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:51,694][root][INFO] - Training Epoch: 2/2, step 3211/7134 completed (loss: 0.05849875137209892, acc: 0.9916840195655823)
[2024-12-17 02:48:51,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:52,035][root][INFO] - Training Epoch: 2/2, step 3212/7134 completed (loss: 0.010222820565104485, acc: 0.9986013770103455)
[2024-12-17 02:48:52,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:52,371][root][INFO] - Training Epoch: 2/2, step 3213/7134 completed (loss: 0.03971758857369423, acc: 0.9899569749832153)
[2024-12-17 02:48:52,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:52,724][root][INFO] - Training Epoch: 2/2, step 3214/7134 completed (loss: 0.03107028268277645, acc: 0.9946452379226685)
[2024-12-17 02:48:52,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:53,071][root][INFO] - Training Epoch: 2/2, step 3215/7134 completed (loss: 0.04135117679834366, acc: 0.9957982897758484)
[2024-12-17 02:48:53,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:53,413][root][INFO] - Training Epoch: 2/2, step 3216/7134 completed (loss: 0.020649312064051628, acc: 0.9942693114280701)
[2024-12-17 02:48:53,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:53,770][root][INFO] - Training Epoch: 2/2, step 3217/7134 completed (loss: 0.01630992814898491, acc: 0.9987096786499023)
[2024-12-17 02:48:53,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:54,088][root][INFO] - Training Epoch: 2/2, step 3218/7134 completed (loss: 0.049821726977825165, acc: 0.9890453815460205)
[2024-12-17 02:48:54,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:54,416][root][INFO] - Training Epoch: 2/2, step 3219/7134 completed (loss: 0.05537416785955429, acc: 0.985228955745697)
[2024-12-17 02:48:54,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:54,758][root][INFO] - Training Epoch: 2/2, step 3220/7134 completed (loss: 0.05436168611049652, acc: 0.9839786291122437)
[2024-12-17 02:48:54,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:55,110][root][INFO] - Training Epoch: 2/2, step 3221/7134 completed (loss: 0.0507834330201149, acc: 0.983561635017395)
[2024-12-17 02:48:55,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:55,436][root][INFO] - Training Epoch: 2/2, step 3222/7134 completed (loss: 0.0700775608420372, acc: 0.9849812388420105)
[2024-12-17 02:48:55,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:55,767][root][INFO] - Training Epoch: 2/2, step 3223/7134 completed (loss: 0.06476903706789017, acc: 0.9888888597488403)
[2024-12-17 02:48:55,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:56,130][root][INFO] - Training Epoch: 2/2, step 3224/7134 completed (loss: 0.08308755606412888, acc: 0.9840810298919678)
[2024-12-17 02:48:56,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:56,485][root][INFO] - Training Epoch: 2/2, step 3225/7134 completed (loss: 0.04193609580397606, acc: 0.9898862242698669)
[2024-12-17 02:48:56,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:56,799][root][INFO] - Training Epoch: 2/2, step 3226/7134 completed (loss: 0.051553286612033844, acc: 0.9838420152664185)
[2024-12-17 02:48:56,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:57,174][root][INFO] - Training Epoch: 2/2, step 3227/7134 completed (loss: 0.10368741303682327, acc: 0.9714285731315613)
[2024-12-17 02:48:57,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:57,535][root][INFO] - Training Epoch: 2/2, step 3228/7134 completed (loss: 0.03869476169347763, acc: 0.9855453372001648)
[2024-12-17 02:48:57,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:57,881][root][INFO] - Training Epoch: 2/2, step 3229/7134 completed (loss: 0.048321668058633804, acc: 0.9853121042251587)
[2024-12-17 02:48:57,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:58,204][root][INFO] - Training Epoch: 2/2, step 3230/7134 completed (loss: 0.04645739123225212, acc: 0.9866864085197449)
[2024-12-17 02:48:58,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:58,515][root][INFO] - Training Epoch: 2/2, step 3231/7134 completed (loss: 0.08466368913650513, acc: 0.9802431464195251)
[2024-12-17 02:48:58,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:58,866][root][INFO] - Training Epoch: 2/2, step 3232/7134 completed (loss: 0.035381466150283813, acc: 0.988776683807373)
[2024-12-17 02:48:58,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:59,188][root][INFO] - Training Epoch: 2/2, step 3233/7134 completed (loss: 0.08726394176483154, acc: 0.9842209219932556)
[2024-12-17 02:48:59,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:59,507][root][INFO] - Training Epoch: 2/2, step 3234/7134 completed (loss: 0.029194243252277374, acc: 0.9921011328697205)
[2024-12-17 02:48:59,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:59,838][root][INFO] - Training Epoch: 2/2, step 3235/7134 completed (loss: 0.047499049454927444, acc: 0.9866666793823242)
[2024-12-17 02:48:59,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:00,153][root][INFO] - Training Epoch: 2/2, step 3236/7134 completed (loss: 0.1244574710726738, acc: 0.9734904170036316)
[2024-12-17 02:49:00,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:00,484][root][INFO] - Training Epoch: 2/2, step 3237/7134 completed (loss: 0.025270089507102966, acc: 0.9935587644577026)
[2024-12-17 02:49:00,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:00,815][root][INFO] - Training Epoch: 2/2, step 3238/7134 completed (loss: 0.06658490002155304, acc: 0.9815950989723206)
[2024-12-17 02:49:00,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:01,146][root][INFO] - Training Epoch: 2/2, step 3239/7134 completed (loss: 0.025889772921800613, acc: 0.9921135902404785)
[2024-12-17 02:49:01,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:01,471][root][INFO] - Training Epoch: 2/2, step 3240/7134 completed (loss: 0.038112737238407135, acc: 0.9895366430282593)
[2024-12-17 02:49:01,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:01,797][root][INFO] - Training Epoch: 2/2, step 3241/7134 completed (loss: 0.02773222327232361, acc: 0.9896142482757568)
[2024-12-17 02:49:01,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:02,127][root][INFO] - Training Epoch: 2/2, step 3242/7134 completed (loss: 0.02072836272418499, acc: 0.9934640526771545)
[2024-12-17 02:49:02,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:02,478][root][INFO] - Training Epoch: 2/2, step 3243/7134 completed (loss: 0.029995720833539963, acc: 0.9904631972312927)
[2024-12-17 02:49:02,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:02,801][root][INFO] - Training Epoch: 2/2, step 3244/7134 completed (loss: 0.01802501641213894, acc: 0.9928264021873474)
[2024-12-17 02:49:02,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:03,158][root][INFO] - Training Epoch: 2/2, step 3245/7134 completed (loss: 0.04443936049938202, acc: 0.9871134161949158)
[2024-12-17 02:49:03,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:03,505][root][INFO] - Training Epoch: 2/2, step 3246/7134 completed (loss: 0.06598743051290512, acc: 0.9833333492279053)
[2024-12-17 02:49:03,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:03,847][root][INFO] - Training Epoch: 2/2, step 3247/7134 completed (loss: 0.04219197854399681, acc: 0.987034022808075)
[2024-12-17 02:49:03,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:04,182][root][INFO] - Training Epoch: 2/2, step 3248/7134 completed (loss: 0.035827118903398514, acc: 0.9917898178100586)
[2024-12-17 02:49:04,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:04,517][root][INFO] - Training Epoch: 2/2, step 3249/7134 completed (loss: 0.03640180081129074, acc: 0.9916782379150391)
[2024-12-17 02:49:04,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:04,851][root][INFO] - Training Epoch: 2/2, step 3250/7134 completed (loss: 0.049301937222480774, acc: 0.9798561334609985)
[2024-12-17 02:49:04,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:05,179][root][INFO] - Training Epoch: 2/2, step 3251/7134 completed (loss: 0.013207986950874329, acc: 0.9942938685417175)
[2024-12-17 02:49:05,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:05,522][root][INFO] - Training Epoch: 2/2, step 3252/7134 completed (loss: 0.01784055307507515, acc: 0.9943262338638306)
[2024-12-17 02:49:05,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:05,862][root][INFO] - Training Epoch: 2/2, step 3253/7134 completed (loss: 0.022868294268846512, acc: 0.9919742941856384)
[2024-12-17 02:49:05,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:06,205][root][INFO] - Training Epoch: 2/2, step 3254/7134 completed (loss: 0.013534724712371826, acc: 0.9966273307800293)
[2024-12-17 02:49:06,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:06,534][root][INFO] - Training Epoch: 2/2, step 3255/7134 completed (loss: 0.01120268739759922, acc: 0.9920106530189514)
[2024-12-17 02:49:06,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:06,860][root][INFO] - Training Epoch: 2/2, step 3256/7134 completed (loss: 0.024256156757473946, acc: 0.9940740466117859)
[2024-12-17 02:49:06,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:07,183][root][INFO] - Training Epoch: 2/2, step 3257/7134 completed (loss: 0.025978857651352882, acc: 0.9916782379150391)
[2024-12-17 02:49:07,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:07,518][root][INFO] - Training Epoch: 2/2, step 3258/7134 completed (loss: 0.036983612924814224, acc: 0.9903846383094788)
[2024-12-17 02:49:07,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:07,847][root][INFO] - Training Epoch: 2/2, step 3259/7134 completed (loss: 0.033434197306632996, acc: 0.9911764860153198)
[2024-12-17 02:49:07,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:08,153][root][INFO] - Training Epoch: 2/2, step 3260/7134 completed (loss: 0.10509715229272842, acc: 0.9777448177337646)
[2024-12-17 02:49:08,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:08,481][root][INFO] - Training Epoch: 2/2, step 3261/7134 completed (loss: 0.05563072860240936, acc: 0.9848993420600891)
[2024-12-17 02:49:08,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:08,815][root][INFO] - Training Epoch: 2/2, step 3262/7134 completed (loss: 0.030398869886994362, acc: 0.9913169145584106)
[2024-12-17 02:49:08,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:09,143][root][INFO] - Training Epoch: 2/2, step 3263/7134 completed (loss: 0.07091611623764038, acc: 0.9809104204177856)
[2024-12-17 02:49:09,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:09,469][root][INFO] - Training Epoch: 2/2, step 3264/7134 completed (loss: 0.028427908197045326, acc: 0.9902777671813965)
[2024-12-17 02:49:09,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:09,812][root][INFO] - Training Epoch: 2/2, step 3265/7134 completed (loss: 0.10287594050168991, acc: 0.9829059839248657)
[2024-12-17 02:49:09,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:10,153][root][INFO] - Training Epoch: 2/2, step 3266/7134 completed (loss: 0.03642446920275688, acc: 0.9894894957542419)
[2024-12-17 02:49:10,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:10,501][root][INFO] - Training Epoch: 2/2, step 3267/7134 completed (loss: 0.07191850244998932, acc: 0.982807993888855)
[2024-12-17 02:49:10,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:10,820][root][INFO] - Training Epoch: 2/2, step 3268/7134 completed (loss: 0.06308846175670624, acc: 0.9845916628837585)
[2024-12-17 02:49:10,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:11,171][root][INFO] - Training Epoch: 2/2, step 3269/7134 completed (loss: 0.03891072794795036, acc: 0.9886363744735718)
[2024-12-17 02:49:11,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:11,524][root][INFO] - Training Epoch: 2/2, step 3270/7134 completed (loss: 0.023354802280664444, acc: 0.9916267991065979)
[2024-12-17 02:49:11,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:11,754][root][INFO] - Training Epoch: 2/2, step 3271/7134 completed (loss: 0.011342586949467659, acc: 1.0)
[2024-12-17 02:49:11,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:12,084][root][INFO] - Training Epoch: 2/2, step 3272/7134 completed (loss: 0.038885679095983505, acc: 0.9938931465148926)
[2024-12-17 02:49:12,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:12,438][root][INFO] - Training Epoch: 2/2, step 3273/7134 completed (loss: 0.037745893001556396, acc: 0.984674334526062)
[2024-12-17 02:49:12,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:12,800][root][INFO] - Training Epoch: 2/2, step 3274/7134 completed (loss: 0.05060623958706856, acc: 0.988252580165863)
[2024-12-17 02:49:12,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:13,145][root][INFO] - Training Epoch: 2/2, step 3275/7134 completed (loss: 0.17104299366474152, acc: 0.9634503126144409)
[2024-12-17 02:49:13,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:13,478][root][INFO] - Training Epoch: 2/2, step 3276/7134 completed (loss: 0.08055367320775986, acc: 0.9738292098045349)
[2024-12-17 02:49:13,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:13,816][root][INFO] - Training Epoch: 2/2, step 3277/7134 completed (loss: 0.05938568338751793, acc: 0.9817073345184326)
[2024-12-17 02:49:13,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:14,092][root][INFO] - Training Epoch: 2/2, step 3278/7134 completed (loss: 0.05117768794298172, acc: 0.980879545211792)
[2024-12-17 02:49:14,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:14,444][root][INFO] - Training Epoch: 2/2, step 3279/7134 completed (loss: 0.05233485996723175, acc: 0.9863353967666626)
[2024-12-17 02:49:14,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:14,744][root][INFO] - Training Epoch: 2/2, step 3280/7134 completed (loss: 0.16816352307796478, acc: 0.9605808854103088)
[2024-12-17 02:49:14,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:15,086][root][INFO] - Training Epoch: 2/2, step 3281/7134 completed (loss: 0.07040653377771378, acc: 0.9826086759567261)
[2024-12-17 02:49:15,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:15,416][root][INFO] - Training Epoch: 2/2, step 3282/7134 completed (loss: 0.02987602911889553, acc: 0.9936708807945251)
[2024-12-17 02:49:15,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:15,761][root][INFO] - Training Epoch: 2/2, step 3283/7134 completed (loss: 0.04912099242210388, acc: 0.9814432859420776)
[2024-12-17 02:49:15,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:16,087][root][INFO] - Training Epoch: 2/2, step 3284/7134 completed (loss: 0.06821271032094955, acc: 0.978691041469574)
[2024-12-17 02:49:16,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:16,414][root][INFO] - Training Epoch: 2/2, step 3285/7134 completed (loss: 0.03740408271551132, acc: 0.9829721450805664)
[2024-12-17 02:49:16,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:16,746][root][INFO] - Training Epoch: 2/2, step 3286/7134 completed (loss: 0.06118236854672432, acc: 0.9864661693572998)
[2024-12-17 02:49:16,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:17,070][root][INFO] - Training Epoch: 2/2, step 3287/7134 completed (loss: 0.1292925775051117, acc: 0.9769737124443054)
[2024-12-17 02:49:17,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:17,408][root][INFO] - Training Epoch: 2/2, step 3288/7134 completed (loss: 0.08184085786342621, acc: 0.9820359349250793)
[2024-12-17 02:49:17,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:17,684][root][INFO] - Training Epoch: 2/2, step 3289/7134 completed (loss: 0.09132998436689377, acc: 0.9771929979324341)
[2024-12-17 02:49:17,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:17,998][root][INFO] - Training Epoch: 2/2, step 3290/7134 completed (loss: 0.07800816744565964, acc: 0.9791666865348816)
[2024-12-17 02:49:18,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:18,318][root][INFO] - Training Epoch: 2/2, step 3291/7134 completed (loss: 0.07291892170906067, acc: 0.9755011200904846)
[2024-12-17 02:49:18,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:18,637][root][INFO] - Training Epoch: 2/2, step 3292/7134 completed (loss: 0.05632096156477928, acc: 0.9894179701805115)
[2024-12-17 02:49:18,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:19,004][root][INFO] - Training Epoch: 2/2, step 3293/7134 completed (loss: 0.04540402814745903, acc: 0.9867256879806519)
[2024-12-17 02:49:19,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:19,333][root][INFO] - Training Epoch: 2/2, step 3294/7134 completed (loss: 0.06812238693237305, acc: 0.9800918698310852)
[2024-12-17 02:49:19,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:19,630][root][INFO] - Training Epoch: 2/2, step 3295/7134 completed (loss: 0.027388205751776695, acc: 0.9948805570602417)
[2024-12-17 02:49:19,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:19,945][root][INFO] - Training Epoch: 2/2, step 3296/7134 completed (loss: 0.06437717378139496, acc: 0.9817184805870056)
[2024-12-17 02:49:20,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:20,225][root][INFO] - Training Epoch: 2/2, step 3297/7134 completed (loss: 0.07013686001300812, acc: 0.9812206625938416)
[2024-12-17 02:49:20,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:20,543][root][INFO] - Training Epoch: 2/2, step 3298/7134 completed (loss: 0.11464683711528778, acc: 0.9840255379676819)
[2024-12-17 02:49:20,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:20,863][root][INFO] - Training Epoch: 2/2, step 3299/7134 completed (loss: 0.05495017021894455, acc: 0.9848993420600891)
[2024-12-17 02:49:20,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:21,177][root][INFO] - Training Epoch: 2/2, step 3300/7134 completed (loss: 0.07999726384878159, acc: 0.9750445485115051)
[2024-12-17 02:49:21,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:21,451][root][INFO] - Training Epoch: 2/2, step 3301/7134 completed (loss: 0.06687616556882858, acc: 0.9834024906158447)
[2024-12-17 02:49:21,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:21,761][root][INFO] - Training Epoch: 2/2, step 3302/7134 completed (loss: 0.08402133733034134, acc: 0.9797979593276978)
[2024-12-17 02:49:21,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:22,019][root][INFO] - Training Epoch: 2/2, step 3303/7134 completed (loss: 0.05657937377691269, acc: 0.9867841601371765)
[2024-12-17 02:49:22,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:22,369][root][INFO] - Training Epoch: 2/2, step 3304/7134 completed (loss: 0.025839535519480705, acc: 0.9916467666625977)
[2024-12-17 02:49:22,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:22,702][root][INFO] - Training Epoch: 2/2, step 3305/7134 completed (loss: 0.06192871183156967, acc: 0.9803921580314636)
[2024-12-17 02:49:22,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:23,077][root][INFO] - Training Epoch: 2/2, step 3306/7134 completed (loss: 0.03391493111848831, acc: 0.9896238446235657)
[2024-12-17 02:49:23,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:23,393][root][INFO] - Training Epoch: 2/2, step 3307/7134 completed (loss: 0.08629784733057022, acc: 0.9780033826828003)
[2024-12-17 02:49:23,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:23,714][root][INFO] - Training Epoch: 2/2, step 3308/7134 completed (loss: 0.057532697916030884, acc: 0.9855491518974304)
[2024-12-17 02:49:23,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:24,023][root][INFO] - Training Epoch: 2/2, step 3309/7134 completed (loss: 0.0733373835682869, acc: 0.976401150226593)
[2024-12-17 02:49:24,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:24,372][root][INFO] - Training Epoch: 2/2, step 3310/7134 completed (loss: 0.06026841327548027, acc: 0.9893389940261841)
[2024-12-17 02:49:24,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:24,598][root][INFO] - Training Epoch: 2/2, step 3311/7134 completed (loss: 0.04599269852042198, acc: 0.9870967864990234)
[2024-12-17 02:49:24,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:24,934][root][INFO] - Training Epoch: 2/2, step 3312/7134 completed (loss: 0.04275430738925934, acc: 0.9854545593261719)
[2024-12-17 02:49:25,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:25,261][root][INFO] - Training Epoch: 2/2, step 3313/7134 completed (loss: 0.026886405423283577, acc: 0.9976133704185486)
[2024-12-17 02:49:25,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:25,581][root][INFO] - Training Epoch: 2/2, step 3314/7134 completed (loss: 0.0608048290014267, acc: 0.9873188138008118)
[2024-12-17 02:49:25,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:25,936][root][INFO] - Training Epoch: 2/2, step 3315/7134 completed (loss: 0.1037403792142868, acc: 0.9769335389137268)
[2024-12-17 02:49:26,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:26,283][root][INFO] - Training Epoch: 2/2, step 3316/7134 completed (loss: 0.02827857807278633, acc: 0.9932773113250732)
[2024-12-17 02:49:26,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:26,615][root][INFO] - Training Epoch: 2/2, step 3317/7134 completed (loss: 0.08006135374307632, acc: 0.9788461327552795)
[2024-12-17 02:49:26,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:26,823][root][INFO] - Training Epoch: 2/2, step 3318/7134 completed (loss: 0.06231842190027237, acc: 0.9819494485855103)
[2024-12-17 02:49:26,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:27,175][root][INFO] - Training Epoch: 2/2, step 3319/7134 completed (loss: 0.05444144457578659, acc: 0.9869706630706787)
[2024-12-17 02:49:27,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:27,538][root][INFO] - Training Epoch: 2/2, step 3320/7134 completed (loss: 0.10241801291704178, acc: 0.9829843044281006)
[2024-12-17 02:49:27,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:27,862][root][INFO] - Training Epoch: 2/2, step 3321/7134 completed (loss: 0.10741253197193146, acc: 0.9724770784378052)
[2024-12-17 02:49:27,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:28,225][root][INFO] - Training Epoch: 2/2, step 3322/7134 completed (loss: 0.05799543857574463, acc: 0.977477490901947)
[2024-12-17 02:49:28,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:28,573][root][INFO] - Training Epoch: 2/2, step 3323/7134 completed (loss: 0.057861607521772385, acc: 0.9862068891525269)
[2024-12-17 02:49:28,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:28,944][root][INFO] - Training Epoch: 2/2, step 3324/7134 completed (loss: 0.09974072128534317, acc: 0.969375729560852)
[2024-12-17 02:49:29,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:29,297][root][INFO] - Training Epoch: 2/2, step 3325/7134 completed (loss: 0.05387754365801811, acc: 0.9879032373428345)
[2024-12-17 02:49:29,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:29,635][root][INFO] - Training Epoch: 2/2, step 3326/7134 completed (loss: 0.0876842811703682, acc: 0.9811023473739624)
[2024-12-17 02:49:29,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:29,958][root][INFO] - Training Epoch: 2/2, step 3327/7134 completed (loss: 0.05133325979113579, acc: 0.9891745448112488)
[2024-12-17 02:49:30,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:30,317][root][INFO] - Training Epoch: 2/2, step 3328/7134 completed (loss: 0.06389795988798141, acc: 0.9887217879295349)
[2024-12-17 02:49:30,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:30,657][root][INFO] - Training Epoch: 2/2, step 3329/7134 completed (loss: 0.02457701973617077, acc: 0.9939098954200745)
[2024-12-17 02:49:30,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:31,015][root][INFO] - Training Epoch: 2/2, step 3330/7134 completed (loss: 0.06930414587259293, acc: 0.9838709831237793)
[2024-12-17 02:49:31,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:31,340][root][INFO] - Training Epoch: 2/2, step 3331/7134 completed (loss: 0.11952724307775497, acc: 0.9694767594337463)
[2024-12-17 02:49:31,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:31,689][root][INFO] - Training Epoch: 2/2, step 3332/7134 completed (loss: 0.13192419707775116, acc: 0.9723183512687683)
[2024-12-17 02:49:31,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:31,990][root][INFO] - Training Epoch: 2/2, step 3333/7134 completed (loss: 0.10163893550634384, acc: 0.9836065769195557)
[2024-12-17 02:49:32,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:32,317][root][INFO] - Training Epoch: 2/2, step 3334/7134 completed (loss: 0.12682528793811798, acc: 0.9716216325759888)
[2024-12-17 02:49:32,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:32,636][root][INFO] - Training Epoch: 2/2, step 3335/7134 completed (loss: 0.045524124056100845, acc: 0.9873417615890503)
[2024-12-17 02:49:32,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:32,962][root][INFO] - Training Epoch: 2/2, step 3336/7134 completed (loss: 0.038109906017780304, acc: 0.9883381724357605)
[2024-12-17 02:49:33,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:33,288][root][INFO] - Training Epoch: 2/2, step 3337/7134 completed (loss: 0.01743769831955433, acc: 0.9921104311943054)
[2024-12-17 02:49:33,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:33,628][root][INFO] - Training Epoch: 2/2, step 3338/7134 completed (loss: 0.019351251423358917, acc: 0.9950310587882996)
[2024-12-17 02:49:33,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:33,981][root][INFO] - Training Epoch: 2/2, step 3339/7134 completed (loss: 0.08759386092424393, acc: 0.9773269891738892)
[2024-12-17 02:49:34,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:34,307][root][INFO] - Training Epoch: 2/2, step 3340/7134 completed (loss: 0.12661875784397125, acc: 0.9683257937431335)
[2024-12-17 02:49:34,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:34,654][root][INFO] - Training Epoch: 2/2, step 3341/7134 completed (loss: 0.07329190522432327, acc: 0.9762963056564331)
[2024-12-17 02:49:34,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:34,982][root][INFO] - Training Epoch: 2/2, step 3342/7134 completed (loss: 0.044668540358543396, acc: 0.9898648858070374)
[2024-12-17 02:49:35,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:35,329][root][INFO] - Training Epoch: 2/2, step 3343/7134 completed (loss: 0.03217358514666557, acc: 0.9899193644523621)
[2024-12-17 02:49:35,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:35,662][root][INFO] - Training Epoch: 2/2, step 3344/7134 completed (loss: 0.035973191261291504, acc: 0.9879931211471558)
[2024-12-17 02:49:35,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:35,999][root][INFO] - Training Epoch: 2/2, step 3345/7134 completed (loss: 0.06913518160581589, acc: 0.9886547923088074)
[2024-12-17 02:49:36,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:36,338][root][INFO] - Training Epoch: 2/2, step 3346/7134 completed (loss: 0.030742594972252846, acc: 0.9912280440330505)
[2024-12-17 02:49:36,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:36,655][root][INFO] - Training Epoch: 2/2, step 3347/7134 completed (loss: 0.10053713619709015, acc: 0.9771987199783325)
[2024-12-17 02:49:36,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:36,972][root][INFO] - Training Epoch: 2/2, step 3348/7134 completed (loss: 0.05445192754268646, acc: 0.9866666793823242)
[2024-12-17 02:49:37,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:37,261][root][INFO] - Training Epoch: 2/2, step 3349/7134 completed (loss: 0.02617759443819523, acc: 0.9929453134536743)
[2024-12-17 02:49:37,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:37,587][root][INFO] - Training Epoch: 2/2, step 3350/7134 completed (loss: 0.04624861106276512, acc: 0.9898374080657959)
[2024-12-17 02:49:37,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:37,903][root][INFO] - Training Epoch: 2/2, step 3351/7134 completed (loss: 0.0851096361875534, acc: 0.9814323782920837)
[2024-12-17 02:49:37,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:38,217][root][INFO] - Training Epoch: 2/2, step 3352/7134 completed (loss: 0.027239687740802765, acc: 0.991304337978363)
[2024-12-17 02:49:38,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:38,530][root][INFO] - Training Epoch: 2/2, step 3353/7134 completed (loss: 0.06708353012800217, acc: 0.9822485446929932)
[2024-12-17 02:49:38,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:38,848][root][INFO] - Training Epoch: 2/2, step 3354/7134 completed (loss: 0.031501732766628265, acc: 0.9953488111495972)
[2024-12-17 02:49:38,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:39,179][root][INFO] - Training Epoch: 2/2, step 3355/7134 completed (loss: 0.028992099687457085, acc: 0.9929478168487549)
[2024-12-17 02:49:39,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:39,509][root][INFO] - Training Epoch: 2/2, step 3356/7134 completed (loss: 0.01602015644311905, acc: 0.9982638955116272)
[2024-12-17 02:49:39,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:39,840][root][INFO] - Training Epoch: 2/2, step 3357/7134 completed (loss: 0.0363464280962944, acc: 0.9898989796638489)
[2024-12-17 02:49:39,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:40,152][root][INFO] - Training Epoch: 2/2, step 3358/7134 completed (loss: 0.06750500202178955, acc: 0.9896193742752075)
[2024-12-17 02:49:40,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:40,469][root][INFO] - Training Epoch: 2/2, step 3359/7134 completed (loss: 0.03616366535425186, acc: 0.9935275316238403)
[2024-12-17 02:49:40,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:40,790][root][INFO] - Training Epoch: 2/2, step 3360/7134 completed (loss: 0.10457354784011841, acc: 0.9699570536613464)
[2024-12-17 02:49:40,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:41,110][root][INFO] - Training Epoch: 2/2, step 3361/7134 completed (loss: 0.0626639798283577, acc: 0.9821029305458069)
[2024-12-17 02:49:41,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:41,424][root][INFO] - Training Epoch: 2/2, step 3362/7134 completed (loss: 0.05211580917239189, acc: 0.9863945841789246)
[2024-12-17 02:49:41,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:41,706][root][INFO] - Training Epoch: 2/2, step 3363/7134 completed (loss: 0.01421053521335125, acc: 0.9976525902748108)
[2024-12-17 02:49:41,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:42,045][root][INFO] - Training Epoch: 2/2, step 3364/7134 completed (loss: 0.1098281666636467, acc: 0.9708141088485718)
[2024-12-17 02:49:42,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:42,371][root][INFO] - Training Epoch: 2/2, step 3365/7134 completed (loss: 0.05927807092666626, acc: 0.9855421781539917)
[2024-12-17 02:49:42,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:42,695][root][INFO] - Training Epoch: 2/2, step 3366/7134 completed (loss: 0.03739718720316887, acc: 0.9865471124649048)
[2024-12-17 02:49:42,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:43,015][root][INFO] - Training Epoch: 2/2, step 3367/7134 completed (loss: 0.03911055251955986, acc: 0.9889807105064392)
[2024-12-17 02:49:43,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:43,351][root][INFO] - Training Epoch: 2/2, step 3368/7134 completed (loss: 0.06605029106140137, acc: 0.9828392863273621)
[2024-12-17 02:49:43,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:43,710][root][INFO] - Training Epoch: 2/2, step 3369/7134 completed (loss: 0.06060889735817909, acc: 0.9870503544807434)
[2024-12-17 02:49:43,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:44,039][root][INFO] - Training Epoch: 2/2, step 3370/7134 completed (loss: 0.023131510242819786, acc: 0.995708167552948)
[2024-12-17 02:49:44,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:44,356][root][INFO] - Training Epoch: 2/2, step 3371/7134 completed (loss: 0.019670331850647926, acc: 0.9934210777282715)
[2024-12-17 02:49:44,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:44,688][root][INFO] - Training Epoch: 2/2, step 3372/7134 completed (loss: 0.04194442555308342, acc: 0.9921630024909973)
[2024-12-17 02:49:44,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:45,010][root][INFO] - Training Epoch: 2/2, step 3373/7134 completed (loss: 0.021690651774406433, acc: 0.9922839403152466)
[2024-12-17 02:49:45,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:45,367][root][INFO] - Training Epoch: 2/2, step 3374/7134 completed (loss: 0.03156422823667526, acc: 0.9944289922714233)
[2024-12-17 02:49:45,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:45,724][root][INFO] - Training Epoch: 2/2, step 3375/7134 completed (loss: 0.031693849712610245, acc: 0.9913169145584106)
[2024-12-17 02:49:45,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:46,074][root][INFO] - Training Epoch: 2/2, step 3376/7134 completed (loss: 0.026319237425923347, acc: 0.992337167263031)
[2024-12-17 02:49:46,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:46,447][root][INFO] - Training Epoch: 2/2, step 3377/7134 completed (loss: 0.018021997064352036, acc: 0.9952324032783508)
[2024-12-17 02:49:46,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:46,788][root][INFO] - Training Epoch: 2/2, step 3378/7134 completed (loss: 0.01659686304628849, acc: 0.9947916865348816)
[2024-12-17 02:49:46,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:47,117][root][INFO] - Training Epoch: 2/2, step 3379/7134 completed (loss: 0.02525412105023861, acc: 0.9924812316894531)
[2024-12-17 02:49:47,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:47,446][root][INFO] - Training Epoch: 2/2, step 3380/7134 completed (loss: 0.04110121726989746, acc: 0.9876922965049744)
[2024-12-17 02:49:47,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:47,800][root][INFO] - Training Epoch: 2/2, step 3381/7134 completed (loss: 0.05513590946793556, acc: 0.9819121360778809)
[2024-12-17 02:49:47,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:48,130][root][INFO] - Training Epoch: 2/2, step 3382/7134 completed (loss: 0.01729457825422287, acc: 0.9982699155807495)
[2024-12-17 02:49:48,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:48,486][root][INFO] - Training Epoch: 2/2, step 3383/7134 completed (loss: 0.057578131556510925, acc: 0.9885222315788269)
[2024-12-17 02:49:48,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:48,798][root][INFO] - Training Epoch: 2/2, step 3384/7134 completed (loss: 0.04057516157627106, acc: 0.9862385392189026)
[2024-12-17 02:49:48,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:49,126][root][INFO] - Training Epoch: 2/2, step 3385/7134 completed (loss: 0.036140844225883484, acc: 0.9913669228553772)
[2024-12-17 02:49:49,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:49,457][root][INFO] - Training Epoch: 2/2, step 3386/7134 completed (loss: 0.029198575764894485, acc: 0.9901130199432373)
[2024-12-17 02:49:49,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:49,788][root][INFO] - Training Epoch: 2/2, step 3387/7134 completed (loss: 0.05758380517363548, acc: 0.9904761910438538)
[2024-12-17 02:49:49,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:50,119][root][INFO] - Training Epoch: 2/2, step 3388/7134 completed (loss: 0.046843599528074265, acc: 0.9819168448448181)
[2024-12-17 02:49:50,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:50,452][root][INFO] - Training Epoch: 2/2, step 3389/7134 completed (loss: 0.035916466265916824, acc: 0.9934123754501343)
[2024-12-17 02:49:50,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:50,811][root][INFO] - Training Epoch: 2/2, step 3390/7134 completed (loss: 0.04098518565297127, acc: 0.9857512712478638)
[2024-12-17 02:49:50,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:51,120][root][INFO] - Training Epoch: 2/2, step 3391/7134 completed (loss: 0.01216927357017994, acc: 0.9986263513565063)
[2024-12-17 02:49:51,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:51,426][root][INFO] - Training Epoch: 2/2, step 3392/7134 completed (loss: 0.017886672168970108, acc: 0.9905660152435303)
[2024-12-17 02:49:51,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:51,738][root][INFO] - Training Epoch: 2/2, step 3393/7134 completed (loss: 0.03086652234196663, acc: 0.9876543283462524)
[2024-12-17 02:49:51,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:52,072][root][INFO] - Training Epoch: 2/2, step 3394/7134 completed (loss: 0.03466367349028587, acc: 0.9905063509941101)
[2024-12-17 02:49:52,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:52,375][root][INFO] - Training Epoch: 2/2, step 3395/7134 completed (loss: 0.07567880302667618, acc: 0.9788960814476013)
[2024-12-17 02:49:52,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:52,728][root][INFO] - Training Epoch: 2/2, step 3396/7134 completed (loss: 0.043975889682769775, acc: 0.9928143620491028)
[2024-12-17 02:49:52,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:53,084][root][INFO] - Training Epoch: 2/2, step 3397/7134 completed (loss: 0.03893459960818291, acc: 0.9914425611495972)
[2024-12-17 02:49:53,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:53,419][root][INFO] - Training Epoch: 2/2, step 3398/7134 completed (loss: 0.052737053483724594, acc: 0.9874551892280579)
[2024-12-17 02:49:53,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:53,748][root][INFO] - Training Epoch: 2/2, step 3399/7134 completed (loss: 0.11838454008102417, acc: 0.970588207244873)
[2024-12-17 02:49:53,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:54,077][root][INFO] - Training Epoch: 2/2, step 3400/7134 completed (loss: 0.08994167298078537, acc: 0.9756592512130737)
[2024-12-17 02:49:54,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:54,400][root][INFO] - Training Epoch: 2/2, step 3401/7134 completed (loss: 0.06857483088970184, acc: 0.9807692170143127)
[2024-12-17 02:49:54,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:54,792][root][INFO] - Training Epoch: 2/2, step 3402/7134 completed (loss: 0.09434167295694351, acc: 0.9776021242141724)
[2024-12-17 02:49:54,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:55,165][root][INFO] - Training Epoch: 2/2, step 3403/7134 completed (loss: 0.10249707102775574, acc: 0.9674479365348816)
[2024-12-17 02:49:55,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:55,503][root][INFO] - Training Epoch: 2/2, step 3404/7134 completed (loss: 0.03005351684987545, acc: 0.9910314083099365)
[2024-12-17 02:49:55,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:55,829][root][INFO] - Training Epoch: 2/2, step 3405/7134 completed (loss: 0.09711849689483643, acc: 0.9784172773361206)
[2024-12-17 02:49:55,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:56,189][root][INFO] - Training Epoch: 2/2, step 3406/7134 completed (loss: 0.04806341975927353, acc: 0.9845361113548279)
[2024-12-17 02:49:56,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:56,491][root][INFO] - Training Epoch: 2/2, step 3407/7134 completed (loss: 0.06471042335033417, acc: 0.9875195026397705)
[2024-12-17 02:49:56,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:56,803][root][INFO] - Training Epoch: 2/2, step 3408/7134 completed (loss: 0.056873057037591934, acc: 0.97926265001297)
[2024-12-17 02:49:56,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:57,158][root][INFO] - Training Epoch: 2/2, step 3409/7134 completed (loss: 0.053875233978033066, acc: 0.9837618470191956)
[2024-12-17 02:49:57,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:57,485][root][INFO] - Training Epoch: 2/2, step 3410/7134 completed (loss: 0.04424098879098892, acc: 0.9917355179786682)
[2024-12-17 02:49:57,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:57,831][root][INFO] - Training Epoch: 2/2, step 3411/7134 completed (loss: 0.05565720796585083, acc: 0.9857697486877441)
[2024-12-17 02:49:57,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:58,140][root][INFO] - Training Epoch: 2/2, step 3412/7134 completed (loss: 0.04745977744460106, acc: 0.9848771095275879)
[2024-12-17 02:49:58,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:58,465][root][INFO] - Training Epoch: 2/2, step 3413/7134 completed (loss: 0.04800926521420479, acc: 0.9779999852180481)
[2024-12-17 02:49:58,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:58,786][root][INFO] - Training Epoch: 2/2, step 3414/7134 completed (loss: 0.051037054508924484, acc: 0.9866443872451782)
[2024-12-17 02:49:58,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:59,138][root][INFO] - Training Epoch: 2/2, step 3415/7134 completed (loss: 0.04031546041369438, acc: 0.9887820482254028)
[2024-12-17 02:49:59,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:59,504][root][INFO] - Training Epoch: 2/2, step 3416/7134 completed (loss: 0.05770174413919449, acc: 0.9879952073097229)
[2024-12-17 02:49:59,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:59,851][root][INFO] - Training Epoch: 2/2, step 3417/7134 completed (loss: 0.025733867660164833, acc: 0.9946019053459167)
[2024-12-17 02:49:59,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:00,182][root][INFO] - Training Epoch: 2/2, step 3418/7134 completed (loss: 0.03489765524864197, acc: 0.9896907210350037)
[2024-12-17 02:50:00,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:00,500][root][INFO] - Training Epoch: 2/2, step 3419/7134 completed (loss: 0.008747018873691559, acc: 0.9971181750297546)
[2024-12-17 02:50:00,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:00,834][root][INFO] - Training Epoch: 2/2, step 3420/7134 completed (loss: 0.016776932403445244, acc: 0.998420238494873)
[2024-12-17 02:50:00,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:01,174][root][INFO] - Training Epoch: 2/2, step 3421/7134 completed (loss: 0.04161098971962929, acc: 0.993779182434082)
[2024-12-17 02:50:01,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:01,480][root][INFO] - Training Epoch: 2/2, step 3422/7134 completed (loss: 0.013128729537129402, acc: 0.9947460889816284)
[2024-12-17 02:50:01,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:01,825][root][INFO] - Training Epoch: 2/2, step 3423/7134 completed (loss: 0.01670907437801361, acc: 0.9924242496490479)
[2024-12-17 02:50:01,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:02,156][root][INFO] - Training Epoch: 2/2, step 3424/7134 completed (loss: 0.0642281174659729, acc: 0.9849397540092468)
[2024-12-17 02:50:02,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:02,487][root][INFO] - Training Epoch: 2/2, step 3425/7134 completed (loss: 0.031022924929857254, acc: 0.9897435903549194)
[2024-12-17 02:50:02,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:02,838][root][INFO] - Training Epoch: 2/2, step 3426/7134 completed (loss: 0.057932108640670776, acc: 0.9903448224067688)
[2024-12-17 02:50:02,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:03,141][root][INFO] - Training Epoch: 2/2, step 3427/7134 completed (loss: 0.050518929958343506, acc: 0.9921011328697205)
[2024-12-17 02:50:03,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:03,485][root][INFO] - Training Epoch: 2/2, step 3428/7134 completed (loss: 0.019366905093193054, acc: 0.9942693114280701)
[2024-12-17 02:50:03,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:03,846][root][INFO] - Training Epoch: 2/2, step 3429/7134 completed (loss: 0.05097503587603569, acc: 0.9822006225585938)
[2024-12-17 02:50:03,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:04,178][root][INFO] - Training Epoch: 2/2, step 3430/7134 completed (loss: 0.08662311732769012, acc: 0.9821717739105225)
[2024-12-17 02:50:04,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:04,515][root][INFO] - Training Epoch: 2/2, step 3431/7134 completed (loss: 0.04745350778102875, acc: 0.9898132681846619)
[2024-12-17 02:50:04,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:04,869][root][INFO] - Training Epoch: 2/2, step 3432/7134 completed (loss: 0.051828864961862564, acc: 0.9903978109359741)
[2024-12-17 02:50:04,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:05,230][root][INFO] - Training Epoch: 2/2, step 3433/7134 completed (loss: 0.07496734708547592, acc: 0.9787581562995911)
[2024-12-17 02:50:05,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:05,554][root][INFO] - Training Epoch: 2/2, step 3434/7134 completed (loss: 0.04731113836169243, acc: 0.9872813820838928)
[2024-12-17 02:50:05,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:05,885][root][INFO] - Training Epoch: 2/2, step 3435/7134 completed (loss: 0.07970207929611206, acc: 0.9823151230812073)
[2024-12-17 02:50:05,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:06,221][root][INFO] - Training Epoch: 2/2, step 3436/7134 completed (loss: 0.06383105367422104, acc: 0.9804878234863281)
[2024-12-17 02:50:06,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:06,514][root][INFO] - Training Epoch: 2/2, step 3437/7134 completed (loss: 0.022372497245669365, acc: 0.994140625)
[2024-12-17 02:50:06,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:06,845][root][INFO] - Training Epoch: 2/2, step 3438/7134 completed (loss: 0.053827978670597076, acc: 0.9878787994384766)
[2024-12-17 02:50:06,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:07,149][root][INFO] - Training Epoch: 2/2, step 3439/7134 completed (loss: 0.04767853766679764, acc: 0.9819168448448181)
[2024-12-17 02:50:07,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:07,473][root][INFO] - Training Epoch: 2/2, step 3440/7134 completed (loss: 0.08103300631046295, acc: 0.9732510447502136)
[2024-12-17 02:50:07,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:07,793][root][INFO] - Training Epoch: 2/2, step 3441/7134 completed (loss: 0.07143513858318329, acc: 0.9855491518974304)
[2024-12-17 02:50:07,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:08,118][root][INFO] - Training Epoch: 2/2, step 3442/7134 completed (loss: 0.02556673437356949, acc: 0.9927007555961609)
[2024-12-17 02:50:08,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:08,402][root][INFO] - Training Epoch: 2/2, step 3443/7134 completed (loss: 0.1026817187666893, acc: 0.983146071434021)
[2024-12-17 02:50:08,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:08,732][root][INFO] - Training Epoch: 2/2, step 3444/7134 completed (loss: 0.0871952697634697, acc: 0.982594907283783)
[2024-12-17 02:50:08,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:09,008][root][INFO] - Training Epoch: 2/2, step 3445/7134 completed (loss: 0.11716348677873611, acc: 0.9698925018310547)
[2024-12-17 02:50:09,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:09,345][root][INFO] - Training Epoch: 2/2, step 3446/7134 completed (loss: 0.11393481492996216, acc: 0.974916398525238)
[2024-12-17 02:50:09,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:09,689][root][INFO] - Training Epoch: 2/2, step 3447/7134 completed (loss: 0.06239047273993492, acc: 0.9804560542106628)
[2024-12-17 02:50:09,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:10,014][root][INFO] - Training Epoch: 2/2, step 3448/7134 completed (loss: 0.03969176858663559, acc: 0.9849849939346313)
[2024-12-17 02:50:10,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:10,327][root][INFO] - Training Epoch: 2/2, step 3449/7134 completed (loss: 0.05510178953409195, acc: 0.9897959232330322)
[2024-12-17 02:50:10,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:10,656][root][INFO] - Training Epoch: 2/2, step 3450/7134 completed (loss: 0.06219565123319626, acc: 0.9822784662246704)
[2024-12-17 02:50:10,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:10,980][root][INFO] - Training Epoch: 2/2, step 3451/7134 completed (loss: 0.05626450479030609, acc: 0.9805653691291809)
[2024-12-17 02:50:11,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:11,305][root][INFO] - Training Epoch: 2/2, step 3452/7134 completed (loss: 0.0663667842745781, acc: 0.9869847893714905)
[2024-12-17 02:50:11,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:11,615][root][INFO] - Training Epoch: 2/2, step 3453/7134 completed (loss: 0.060788579285144806, acc: 0.9830220937728882)
[2024-12-17 02:50:11,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:11,957][root][INFO] - Training Epoch: 2/2, step 3454/7134 completed (loss: 0.05825892835855484, acc: 0.9858956336975098)
[2024-12-17 02:50:12,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:12,305][root][INFO] - Training Epoch: 2/2, step 3455/7134 completed (loss: 0.015743589028716087, acc: 0.9956521987915039)
[2024-12-17 02:50:12,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:12,659][root][INFO] - Training Epoch: 2/2, step 3456/7134 completed (loss: 0.0386299230158329, acc: 0.9976470470428467)
[2024-12-17 02:50:12,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:13,021][root][INFO] - Training Epoch: 2/2, step 3457/7134 completed (loss: 0.03972641006112099, acc: 0.9864406585693359)
[2024-12-17 02:50:13,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:13,383][root][INFO] - Training Epoch: 2/2, step 3458/7134 completed (loss: 0.07321082055568695, acc: 0.9824086427688599)
[2024-12-17 02:50:13,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:13,709][root][INFO] - Training Epoch: 2/2, step 3459/7134 completed (loss: 0.0569034144282341, acc: 0.9878234267234802)
[2024-12-17 02:50:13,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:13,994][root][INFO] - Training Epoch: 2/2, step 3460/7134 completed (loss: 0.21738854050636292, acc: 0.9487179517745972)
[2024-12-17 02:50:14,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:14,248][root][INFO] - Training Epoch: 2/2, step 3461/7134 completed (loss: 0.2441660612821579, acc: 0.9494252800941467)
[2024-12-17 02:50:14,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:14,579][root][INFO] - Training Epoch: 2/2, step 3462/7134 completed (loss: 0.09967254847288132, acc: 0.9748822450637817)
[2024-12-17 02:50:14,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:14,940][root][INFO] - Training Epoch: 2/2, step 3463/7134 completed (loss: 0.019362039864063263, acc: 0.9969834089279175)
[2024-12-17 02:50:15,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:15,283][root][INFO] - Training Epoch: 2/2, step 3464/7134 completed (loss: 0.06266848742961884, acc: 0.9785522818565369)
[2024-12-17 02:50:15,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:15,602][root][INFO] - Training Epoch: 2/2, step 3465/7134 completed (loss: 0.07220384478569031, acc: 0.9877800345420837)
[2024-12-17 02:50:15,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:15,927][root][INFO] - Training Epoch: 2/2, step 3466/7134 completed (loss: 0.02536051906645298, acc: 0.9889065027236938)
[2024-12-17 02:50:16,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:16,261][root][INFO] - Training Epoch: 2/2, step 3467/7134 completed (loss: 0.06852880120277405, acc: 0.9830148816108704)
[2024-12-17 02:50:16,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:16,597][root][INFO] - Training Epoch: 2/2, step 3468/7134 completed (loss: 0.011314069852232933, acc: 0.9985527992248535)
[2024-12-17 02:50:16,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:16,927][root][INFO] - Training Epoch: 2/2, step 3469/7134 completed (loss: 0.040778957307338715, acc: 0.9886792302131653)
[2024-12-17 02:50:17,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:17,243][root][INFO] - Training Epoch: 2/2, step 3470/7134 completed (loss: 0.027282511815428734, acc: 0.9930875301361084)
[2024-12-17 02:50:17,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:17,576][root][INFO] - Training Epoch: 2/2, step 3471/7134 completed (loss: 0.06999748945236206, acc: 0.9834254384040833)
[2024-12-17 02:50:17,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:17,916][root][INFO] - Training Epoch: 2/2, step 3472/7134 completed (loss: 0.022079158574342728, acc: 0.9940387606620789)
[2024-12-17 02:50:18,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:18,292][root][INFO] - Training Epoch: 2/2, step 3473/7134 completed (loss: 0.03639262914657593, acc: 0.9867549538612366)
[2024-12-17 02:50:18,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:18,597][root][INFO] - Training Epoch: 2/2, step 3474/7134 completed (loss: 0.05301941931247711, acc: 0.9876325130462646)
[2024-12-17 02:50:18,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:18,916][root][INFO] - Training Epoch: 2/2, step 3475/7134 completed (loss: 0.03487391769886017, acc: 0.9875665903091431)
[2024-12-17 02:50:19,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:19,254][root][INFO] - Training Epoch: 2/2, step 3476/7134 completed (loss: 0.06268381327390671, acc: 0.9777397513389587)
[2024-12-17 02:50:19,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:19,579][root][INFO] - Training Epoch: 2/2, step 3477/7134 completed (loss: 0.05729461833834648, acc: 0.9868420958518982)
[2024-12-17 02:50:19,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:19,902][root][INFO] - Training Epoch: 2/2, step 3478/7134 completed (loss: 0.028519384562969208, acc: 0.9940119981765747)
[2024-12-17 02:50:20,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:20,232][root][INFO] - Training Epoch: 2/2, step 3479/7134 completed (loss: 0.015862973406910896, acc: 0.998487114906311)
[2024-12-17 02:50:20,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:20,583][root][INFO] - Training Epoch: 2/2, step 3480/7134 completed (loss: 0.044069450348615646, acc: 0.9918256402015686)
[2024-12-17 02:50:20,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:20,911][root][INFO] - Training Epoch: 2/2, step 3481/7134 completed (loss: 0.04608453810214996, acc: 0.9946808218955994)
[2024-12-17 02:50:21,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:21,233][root][INFO] - Training Epoch: 2/2, step 3482/7134 completed (loss: 0.016417669132351875, acc: 0.9946042895317078)
[2024-12-17 02:50:21,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:21,576][root][INFO] - Training Epoch: 2/2, step 3483/7134 completed (loss: 0.01212448813021183, acc: 0.9984591603279114)
[2024-12-17 02:50:21,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:21,890][root][INFO] - Training Epoch: 2/2, step 3484/7134 completed (loss: 0.03494953364133835, acc: 0.991150438785553)
[2024-12-17 02:50:21,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:22,191][root][INFO] - Training Epoch: 2/2, step 3485/7134 completed (loss: 0.0413859486579895, acc: 0.9884560108184814)
[2024-12-17 02:50:22,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:22,517][root][INFO] - Training Epoch: 2/2, step 3486/7134 completed (loss: 0.025267884135246277, acc: 0.9928057789802551)
[2024-12-17 02:50:22,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:22,847][root][INFO] - Training Epoch: 2/2, step 3487/7134 completed (loss: 0.05760522559285164, acc: 0.9823269248008728)
[2024-12-17 02:50:22,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:23,181][root][INFO] - Training Epoch: 2/2, step 3488/7134 completed (loss: 0.0319511741399765, acc: 0.9901315569877625)
[2024-12-17 02:50:23,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:23,488][root][INFO] - Training Epoch: 2/2, step 3489/7134 completed (loss: 0.06559261679649353, acc: 0.979742169380188)
[2024-12-17 02:50:23,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:23,848][root][INFO] - Training Epoch: 2/2, step 3490/7134 completed (loss: 0.0815926194190979, acc: 0.985228955745697)
[2024-12-17 02:50:23,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:24,176][root][INFO] - Training Epoch: 2/2, step 3491/7134 completed (loss: 0.045733269304037094, acc: 0.9886524677276611)
[2024-12-17 02:50:24,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:24,454][root][INFO] - Training Epoch: 2/2, step 3492/7134 completed (loss: 0.056625451892614365, acc: 0.9917864203453064)
[2024-12-17 02:50:24,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:24,795][root][INFO] - Training Epoch: 2/2, step 3493/7134 completed (loss: 0.019447145983576775, acc: 0.9901960492134094)
[2024-12-17 02:50:24,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:25,104][root][INFO] - Training Epoch: 2/2, step 3494/7134 completed (loss: 0.03662047162652016, acc: 0.9931034445762634)
[2024-12-17 02:50:25,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:25,424][root][INFO] - Training Epoch: 2/2, step 3495/7134 completed (loss: 0.018262645229697227, acc: 0.9904076457023621)
[2024-12-17 02:50:25,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:25,737][root][INFO] - Training Epoch: 2/2, step 3496/7134 completed (loss: 0.05617307871580124, acc: 0.9887387156486511)
[2024-12-17 02:50:25,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:26,053][root][INFO] - Training Epoch: 2/2, step 3497/7134 completed (loss: 0.05000709369778633, acc: 0.9881305694580078)
[2024-12-17 02:50:26,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:26,391][root][INFO] - Training Epoch: 2/2, step 3498/7134 completed (loss: 0.04312549903988838, acc: 0.9878048896789551)
[2024-12-17 02:50:26,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:26,733][root][INFO] - Training Epoch: 2/2, step 3499/7134 completed (loss: 0.021837599575519562, acc: 0.9951377511024475)
[2024-12-17 02:50:26,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:27,060][root][INFO] - Training Epoch: 2/2, step 3500/7134 completed (loss: 0.05678758770227432, acc: 0.98531574010849)
[2024-12-17 02:50:27,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:27,387][root][INFO] - Training Epoch: 2/2, step 3501/7134 completed (loss: 0.08223646134138107, acc: 0.9758551120758057)
[2024-12-17 02:50:27,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:27,697][root][INFO] - Training Epoch: 2/2, step 3502/7134 completed (loss: 0.10237111896276474, acc: 0.9754385948181152)
[2024-12-17 02:50:27,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:28,033][root][INFO] - Training Epoch: 2/2, step 3503/7134 completed (loss: 0.0674005076289177, acc: 0.9878683090209961)
[2024-12-17 02:50:28,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:28,362][root][INFO] - Training Epoch: 2/2, step 3504/7134 completed (loss: 0.01989097148180008, acc: 0.9954751133918762)
[2024-12-17 02:50:28,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:28,708][root][INFO] - Training Epoch: 2/2, step 3505/7134 completed (loss: 0.020124943926930428, acc: 0.9946332573890686)
[2024-12-17 02:50:28,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:29,001][root][INFO] - Training Epoch: 2/2, step 3506/7134 completed (loss: 0.0465877391397953, acc: 0.9867674708366394)
[2024-12-17 02:50:29,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:29,352][root][INFO] - Training Epoch: 2/2, step 3507/7134 completed (loss: 0.02446087822318077, acc: 0.9867549538612366)
[2024-12-17 02:50:29,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:29,687][root][INFO] - Training Epoch: 2/2, step 3508/7134 completed (loss: 0.03925410658121109, acc: 0.9926900863647461)
[2024-12-17 02:50:29,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:30,029][root][INFO] - Training Epoch: 2/2, step 3509/7134 completed (loss: 0.02417990379035473, acc: 0.9903314709663391)
[2024-12-17 02:50:30,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:30,334][root][INFO] - Training Epoch: 2/2, step 3510/7134 completed (loss: 0.04593358561396599, acc: 0.9879931211471558)
[2024-12-17 02:50:30,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:30,689][root][INFO] - Training Epoch: 2/2, step 3511/7134 completed (loss: 0.007220714818686247, acc: 0.9981982111930847)
[2024-12-17 02:50:30,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:31,016][root][INFO] - Training Epoch: 2/2, step 3512/7134 completed (loss: 0.04650670289993286, acc: 0.9873217344284058)
[2024-12-17 02:50:31,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:31,351][root][INFO] - Training Epoch: 2/2, step 3513/7134 completed (loss: 0.04040928930044174, acc: 0.9946902394294739)
[2024-12-17 02:50:31,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:31,707][root][INFO] - Training Epoch: 2/2, step 3514/7134 completed (loss: 0.047996316105127335, acc: 0.9827188849449158)
[2024-12-17 02:50:31,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:32,032][root][INFO] - Training Epoch: 2/2, step 3515/7134 completed (loss: 0.02248518168926239, acc: 0.9916201233863831)
[2024-12-17 02:50:32,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:32,398][root][INFO] - Training Epoch: 2/2, step 3516/7134 completed (loss: 0.03078068420290947, acc: 0.9924160242080688)
[2024-12-17 02:50:32,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:32,751][root][INFO] - Training Epoch: 2/2, step 3517/7134 completed (loss: 0.01859380677342415, acc: 0.9928486347198486)
[2024-12-17 02:50:32,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:33,109][root][INFO] - Training Epoch: 2/2, step 3518/7134 completed (loss: 0.020740028470754623, acc: 0.9926062822341919)
[2024-12-17 02:50:33,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:33,465][root][INFO] - Training Epoch: 2/2, step 3519/7134 completed (loss: 0.02538723312318325, acc: 0.9943820238113403)
[2024-12-17 02:50:33,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:33,829][root][INFO] - Training Epoch: 2/2, step 3520/7134 completed (loss: 0.07566548883914948, acc: 0.9835293889045715)
[2024-12-17 02:50:33,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:34,188][root][INFO] - Training Epoch: 2/2, step 3521/7134 completed (loss: 0.018977351486682892, acc: 0.991465151309967)
[2024-12-17 02:50:34,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:34,505][root][INFO] - Training Epoch: 2/2, step 3522/7134 completed (loss: 0.014227325096726418, acc: 0.9973261952400208)
[2024-12-17 02:50:34,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:34,861][root][INFO] - Training Epoch: 2/2, step 3523/7134 completed (loss: 0.014829595573246479, acc: 0.9969183206558228)
[2024-12-17 02:50:34,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:35,217][root][INFO] - Training Epoch: 2/2, step 3524/7134 completed (loss: 0.04227672144770622, acc: 0.9908854365348816)
[2024-12-17 02:50:35,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:35,568][root][INFO] - Training Epoch: 2/2, step 3525/7134 completed (loss: 0.03099343739449978, acc: 0.9901153445243835)
[2024-12-17 02:50:35,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:35,919][root][INFO] - Training Epoch: 2/2, step 3526/7134 completed (loss: 0.04926157370209694, acc: 0.9860582947731018)
[2024-12-17 02:50:36,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:36,288][root][INFO] - Training Epoch: 2/2, step 3527/7134 completed (loss: 0.03295126184821129, acc: 0.9923175573348999)
[2024-12-17 02:50:36,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:36,644][root][INFO] - Training Epoch: 2/2, step 3528/7134 completed (loss: 0.00825540628284216, acc: 0.9988465905189514)
[2024-12-17 02:50:36,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:36,983][root][INFO] - Training Epoch: 2/2, step 3529/7134 completed (loss: 0.01818251982331276, acc: 0.9929412007331848)
[2024-12-17 02:50:37,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:37,369][root][INFO] - Training Epoch: 2/2, step 3530/7134 completed (loss: 0.03068501129746437, acc: 0.9942660331726074)
[2024-12-17 02:50:37,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:37,721][root][INFO] - Training Epoch: 2/2, step 3531/7134 completed (loss: 0.027931462973356247, acc: 0.9924699068069458)
[2024-12-17 02:50:37,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:38,075][root][INFO] - Training Epoch: 2/2, step 3532/7134 completed (loss: 0.011313499882817268, acc: 0.9983165264129639)
[2024-12-17 02:50:38,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:38,432][root][INFO] - Training Epoch: 2/2, step 3533/7134 completed (loss: 0.017458492890000343, acc: 0.9941792488098145)
[2024-12-17 02:50:38,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:38,775][root][INFO] - Training Epoch: 2/2, step 3534/7134 completed (loss: 0.043449413031339645, acc: 0.9888734221458435)
[2024-12-17 02:50:38,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:39,118][root][INFO] - Training Epoch: 2/2, step 3535/7134 completed (loss: 0.03245628625154495, acc: 0.9923195242881775)
[2024-12-17 02:50:39,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:39,460][root][INFO] - Training Epoch: 2/2, step 3536/7134 completed (loss: 0.05606909096240997, acc: 0.9849726557731628)
[2024-12-17 02:50:39,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:39,775][root][INFO] - Training Epoch: 2/2, step 3537/7134 completed (loss: 0.03849734738469124, acc: 0.9899328947067261)
[2024-12-17 02:50:39,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:40,096][root][INFO] - Training Epoch: 2/2, step 3538/7134 completed (loss: 0.05302375927567482, acc: 0.9923954606056213)
[2024-12-17 02:50:40,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:40,352][root][INFO] - Training Epoch: 2/2, step 3539/7134 completed (loss: 0.020003193989396095, acc: 0.9927184581756592)
[2024-12-17 02:50:40,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:40,676][root][INFO] - Training Epoch: 2/2, step 3540/7134 completed (loss: 0.05115381255745888, acc: 0.9863429665565491)
[2024-12-17 02:50:40,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:41,019][root][INFO] - Training Epoch: 2/2, step 3541/7134 completed (loss: 0.049477625638246536, acc: 0.98531574010849)
[2024-12-17 02:50:41,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:41,346][root][INFO] - Training Epoch: 2/2, step 3542/7134 completed (loss: 0.04561629146337509, acc: 0.9815384745597839)
[2024-12-17 02:50:41,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:41,657][root][INFO] - Training Epoch: 2/2, step 3543/7134 completed (loss: 0.05571723356842995, acc: 0.9841549396514893)
[2024-12-17 02:50:41,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:42,005][root][INFO] - Training Epoch: 2/2, step 3544/7134 completed (loss: 0.04521973058581352, acc: 0.989230751991272)
[2024-12-17 02:50:42,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:42,362][root][INFO] - Training Epoch: 2/2, step 3545/7134 completed (loss: 0.025489114224910736, acc: 0.9906832575798035)
[2024-12-17 02:50:42,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:42,695][root][INFO] - Training Epoch: 2/2, step 3546/7134 completed (loss: 0.042480867356061935, acc: 0.9884488582611084)
[2024-12-17 02:50:42,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:43,058][root][INFO] - Training Epoch: 2/2, step 3547/7134 completed (loss: 0.059060387313365936, acc: 0.9832167625427246)
[2024-12-17 02:50:43,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:43,396][root][INFO] - Training Epoch: 2/2, step 3548/7134 completed (loss: 0.03539342060685158, acc: 0.991150438785553)
[2024-12-17 02:50:43,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:43,721][root][INFO] - Training Epoch: 2/2, step 3549/7134 completed (loss: 0.049374066293239594, acc: 0.9858906269073486)
[2024-12-17 02:50:43,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:44,049][root][INFO] - Training Epoch: 2/2, step 3550/7134 completed (loss: 0.03028152510523796, acc: 0.9894921183586121)
[2024-12-17 02:50:44,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:44,379][root][INFO] - Training Epoch: 2/2, step 3551/7134 completed (loss: 0.04242663085460663, acc: 0.9898989796638489)
[2024-12-17 02:50:44,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:44,726][root][INFO] - Training Epoch: 2/2, step 3552/7134 completed (loss: 0.1496097594499588, acc: 0.9644194841384888)
[2024-12-17 02:50:44,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:45,052][root][INFO] - Training Epoch: 2/2, step 3553/7134 completed (loss: 0.07998842000961304, acc: 0.9868420958518982)
[2024-12-17 02:50:45,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:45,384][root][INFO] - Training Epoch: 2/2, step 3554/7134 completed (loss: 0.04725014045834541, acc: 0.9849397540092468)
[2024-12-17 02:50:45,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:45,710][root][INFO] - Training Epoch: 2/2, step 3555/7134 completed (loss: 0.04491394758224487, acc: 0.9843013882637024)
[2024-12-17 02:50:45,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:46,025][root][INFO] - Training Epoch: 2/2, step 3556/7134 completed (loss: 0.052255354821681976, acc: 0.984644889831543)
[2024-12-17 02:50:46,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:46,392][root][INFO] - Training Epoch: 2/2, step 3557/7134 completed (loss: 0.04391071945428848, acc: 0.9891107082366943)
[2024-12-17 02:50:46,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:46,718][root][INFO] - Training Epoch: 2/2, step 3558/7134 completed (loss: 0.05101729556918144, acc: 0.985567033290863)
[2024-12-17 02:50:46,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:47,050][root][INFO] - Training Epoch: 2/2, step 3559/7134 completed (loss: 0.0333409421145916, acc: 0.9883720874786377)
[2024-12-17 02:50:47,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:47,374][root][INFO] - Training Epoch: 2/2, step 3560/7134 completed (loss: 0.026378760114312172, acc: 0.9917808175086975)
[2024-12-17 02:50:47,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:47,718][root][INFO] - Training Epoch: 2/2, step 3561/7134 completed (loss: 0.05020018666982651, acc: 0.9845938086509705)
[2024-12-17 02:50:47,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:48,041][root][INFO] - Training Epoch: 2/2, step 3562/7134 completed (loss: 0.046066898852586746, acc: 0.9803571701049805)
[2024-12-17 02:50:48,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:48,371][root][INFO] - Training Epoch: 2/2, step 3563/7134 completed (loss: 0.03320884332060814, acc: 0.9920508861541748)
[2024-12-17 02:50:49,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:49,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:49,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:49,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:49,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:50,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:50,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:50,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:50,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:51,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:51,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:51,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:52,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:52,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:52,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:52,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:53,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:53,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:53,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:54,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:54,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:54,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:54,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:55,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:55,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:55,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:55,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:56,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:56,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:56,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:57,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:57,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:57,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:58,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:58,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:58,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:58,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:59,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:59,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:59,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:59,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:00,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:00,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:00,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:01,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:01,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:01,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:02,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:02,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:02,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:03,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:03,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:03,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:03,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:04,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:04,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:04,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:05,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:05,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:05,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:05,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:06,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:06,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:06,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:06,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:07,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:07,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:07,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:07,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:08,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:08,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:08,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:08,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:09,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:09,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:09,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:10,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:10,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:10,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:10,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:11,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:11,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:11,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:11,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:12,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:12,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:12,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:13,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:13,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:13,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:13,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:13,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:14,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:14,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:14,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:15,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:15,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:15,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:15,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:16,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:16,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:16,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:17,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:17,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:17,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:17,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:18,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:18,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:18,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:18,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:19,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:19,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:19,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:19,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:20,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:20,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:20,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:21,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:21,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:21,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:22,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:22,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:22,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:23,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:23,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:23,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:23,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:24,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:24,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:24,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:24,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:25,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:25,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:25,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:26,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:26,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:26,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:26,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:27,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:27,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:27,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:28,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:28,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:28,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:28,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:29,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:29,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:29,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:29,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:30,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:30,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:30,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:30,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:31,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:31,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:31,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:32,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:32,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:32,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:32,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:33,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:33,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:33,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:33,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:34,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:34,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:34,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:35,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:35,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:35,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:35,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:36,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:36,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:36,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:37,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:37,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:37,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:37,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:38,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:38,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:38,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:38,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:39,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:39,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:39,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:40,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:40,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:40,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:40,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:41,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:41,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:41,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:42,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:42,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:42,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:43,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:43,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:43,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:43,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:44,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:44,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:44,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:45,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:45,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:45,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:46,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:46,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:46,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:46,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:47,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:47,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:47,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:48,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:48,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:48,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:49,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:49,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:49,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:49,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:50,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:50,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:50,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:51,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:51,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:51,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:52,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:52,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:52,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:52,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:53,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:53,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:53,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:53,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:54,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:54,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:54,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:55,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:55,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:55,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:55,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:56,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:56,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:56,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:56,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:57,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:57,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:57,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:58,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:58,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:59,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:59,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:59,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:59,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:00,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:00,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:00,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:01,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:01,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:01,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:02,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:02,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:02,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:03,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:03,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:03,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:03,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:04,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:04,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:04,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:04,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:05,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:05,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:05,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:06,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:06,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:07,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:07,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:07,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:07,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:08,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:08,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:08,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:09,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:09,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:09,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:10,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:10,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:11,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:11,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:11,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:12,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:12,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:12,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:13,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:13,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:14,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:14,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:14,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:14,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:15,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:15,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:15,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:15,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:16,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:16,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:16,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:16,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:17,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:17,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:17,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:17,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:18,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:18,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:18,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:19,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:19,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:19,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:19,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:20,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:20,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:20,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:21,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:21,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:21,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:21,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:22,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:22,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:22,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:23,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:23,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:23,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:24,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:24,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:24,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:24,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:25,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:25,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:25,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:25,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:26,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:26,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:26,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:27,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:27,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:27,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:27,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:28,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:28,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:28,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:29,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:29,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:29,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:29,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:30,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:30,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:30,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:31,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:31,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:31,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:32,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:32,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:33,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:33,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:33,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:34,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:34,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:35,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:35,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:35,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:36,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:36,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:36,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:36,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:36,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:37,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:37,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:37,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:37,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:38,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:38,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:38,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:38,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:39,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:39,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:39,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:39,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:40,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:40,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:40,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:41,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:41,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:41,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:41,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:42,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:42,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:42,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:42,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:43,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:43,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:43,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:43,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:43,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:44,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:44,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:44,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:44,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:45,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:45,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:45,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:45,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:46,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:46,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:46,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:46,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:47,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:47,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:47,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:48,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:48,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:48,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:49,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:49,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:49,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:49,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:50,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:50,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:50,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:50,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:51,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:51,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:51,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:51,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:52,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:52,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:52,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:53,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:53,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:53,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:53,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:53,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:54,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:54,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:54,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:55,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:55,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:55,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:56,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:56,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:56,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:57,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:57,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:57,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:57,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:58,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:58,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:58,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:58,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:59,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:59,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:59,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:59,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:00,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:00,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:00,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:00,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:01,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:01,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:01,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:02,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:02,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:02,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:03,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:03,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:03,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:04,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:04,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:04,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:04,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:05,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:05,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:05,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:06,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:06,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:06,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:07,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:07,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:07,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:07,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:08,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:08,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:08,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:09,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:09,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:09,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:10,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:10,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:10,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:10,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:11,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:11,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:11,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:12,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:12,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:12,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:13,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:13,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:13,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:13,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:14,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:14,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:14,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:15,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:15,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:15,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:15,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:16,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:16,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:16,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:16,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:17,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:17,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:17,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:17,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:18,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:18,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:18,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:19,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:19,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:19,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:19,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:20,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:20,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:20,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:20,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:21,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:21,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:21,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:22,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:22,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:22,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:22,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:23,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:23,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:23,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:23,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:24,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:24,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:24,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:24,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:25,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:25,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:25,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:26,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:26,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:26,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:26,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:27,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:27,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:27,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:28,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:28,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:28,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:28,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:29,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:29,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:29,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:29,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:30,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:30,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:30,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:31,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:31,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:31,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:31,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:32,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:32,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:32,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:33,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:33,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:33,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:34,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:34,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:34,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:35,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:35,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:35,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:36,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:36,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:36,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:36,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:37,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:37,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:37,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:37,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:38,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:38,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:38,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:38,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:39,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:39,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:39,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:39,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:40,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:40,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:40,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:41,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:41,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:41,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:42,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:42,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:42,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:42,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:43,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:43,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:43,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:43,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:44,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:44,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:44,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:45,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:45,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:45,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:46,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:46,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:46,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:47,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:47,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:48,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:49,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:49,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:49,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:50,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:50,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:50,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:51,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:51,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:52,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:52,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:52,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:52,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:53,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:53,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:53,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:53,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:54,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:54,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:54,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:55,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:55,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:55,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:55,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:56,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:56,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:56,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:56,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:57,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:57,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:57,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:58,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:58,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:58,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:58,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:59,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:59,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:59,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:59,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:00,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:00,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:00,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:00,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:01,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:01,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:01,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:02,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:02,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:02,999][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.0705, device='cuda:0') eval_epoch_loss=tensor(0.0681, device='cuda:0') eval_epoch_acc=tensor(0.9824, device='cuda:0')
[2024-12-17 02:54:03,001][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-12-17 02:54:03,002][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 02:54:03,199][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_2_step_3564_loss_0.06808644533157349/model.pt
[2024-12-17 02:54:03,203][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 0.06808644533157349
[2024-12-17 02:54:03,203][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.982357919216156
[2024-12-17 02:54:03,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:03,562][root][INFO] - Training Epoch: 2/2, step 3564/7134 completed (loss: 0.054267458617687225, acc: 0.9849624037742615)
[2024-12-17 02:54:03,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:03,893][root][INFO] - Training Epoch: 2/2, step 3565/7134 completed (loss: 0.09671026468276978, acc: 0.9755638837814331)
[2024-12-17 02:54:03,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:04,221][root][INFO] - Training Epoch: 2/2, step 3566/7134 completed (loss: 0.06961145997047424, acc: 0.9820716977119446)
[2024-12-17 02:54:04,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:04,549][root][INFO] - Training Epoch: 2/2, step 3567/7134 completed (loss: 0.11104993522167206, acc: 0.9780077338218689)
[2024-12-17 02:54:04,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:04,884][root][INFO] - Training Epoch: 2/2, step 3568/7134 completed (loss: 0.09907650202512741, acc: 0.978723406791687)
[2024-12-17 02:54:05,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:05,206][root][INFO] - Training Epoch: 2/2, step 3569/7134 completed (loss: 0.07994549721479416, acc: 0.9767025113105774)
[2024-12-17 02:54:05,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:05,566][root][INFO] - Training Epoch: 2/2, step 3570/7134 completed (loss: 0.0982067659497261, acc: 0.9768595099449158)
[2024-12-17 02:54:05,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:05,904][root][INFO] - Training Epoch: 2/2, step 3571/7134 completed (loss: 0.08114133030176163, acc: 0.9840849041938782)
[2024-12-17 02:54:06,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:06,297][root][INFO] - Training Epoch: 2/2, step 3572/7134 completed (loss: 0.025489646941423416, acc: 0.9934123754501343)
[2024-12-17 02:54:06,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:06,648][root][INFO] - Training Epoch: 2/2, step 3573/7134 completed (loss: 0.06478121876716614, acc: 0.9837037324905396)
[2024-12-17 02:54:06,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:06,969][root][INFO] - Training Epoch: 2/2, step 3574/7134 completed (loss: 0.09167974442243576, acc: 0.975095808506012)
[2024-12-17 02:54:07,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:07,303][root][INFO] - Training Epoch: 2/2, step 3575/7134 completed (loss: 0.12502342462539673, acc: 0.9691252112388611)
[2024-12-17 02:54:07,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:07,629][root][INFO] - Training Epoch: 2/2, step 3576/7134 completed (loss: 0.0892208069562912, acc: 0.9723756909370422)
[2024-12-17 02:54:07,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:08,030][root][INFO] - Training Epoch: 2/2, step 3577/7134 completed (loss: 0.04853876307606697, acc: 0.984829306602478)
[2024-12-17 02:54:08,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:08,385][root][INFO] - Training Epoch: 2/2, step 3578/7134 completed (loss: 0.047571029514074326, acc: 0.9854439496994019)
[2024-12-17 02:54:08,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:08,728][root][INFO] - Training Epoch: 2/2, step 3579/7134 completed (loss: 0.06094355881214142, acc: 0.9879999756813049)
[2024-12-17 02:54:08,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:09,063][root][INFO] - Training Epoch: 2/2, step 3580/7134 completed (loss: 0.08754128217697144, acc: 0.9748031497001648)
[2024-12-17 02:54:09,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:09,407][root][INFO] - Training Epoch: 2/2, step 3581/7134 completed (loss: 0.0825694277882576, acc: 0.9793814420700073)
[2024-12-17 02:54:09,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:09,675][root][INFO] - Training Epoch: 2/2, step 3582/7134 completed (loss: 0.07231029868125916, acc: 0.9857819676399231)
[2024-12-17 02:54:09,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:10,029][root][INFO] - Training Epoch: 2/2, step 3583/7134 completed (loss: 0.06470006704330444, acc: 0.9832826852798462)
[2024-12-17 02:54:10,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:10,304][root][INFO] - Training Epoch: 2/2, step 3584/7134 completed (loss: 0.09559588879346848, acc: 0.9788359999656677)
[2024-12-17 02:54:10,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:10,648][root][INFO] - Training Epoch: 2/2, step 3585/7134 completed (loss: 0.08414002507925034, acc: 0.9704861044883728)
[2024-12-17 02:54:10,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:10,976][root][INFO] - Training Epoch: 2/2, step 3586/7134 completed (loss: 0.06414816528558731, acc: 0.9775280952453613)
[2024-12-17 02:54:11,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:11,308][root][INFO] - Training Epoch: 2/2, step 3587/7134 completed (loss: 0.05754496529698372, acc: 0.9864636063575745)
[2024-12-17 02:54:11,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:11,678][root][INFO] - Training Epoch: 2/2, step 3588/7134 completed (loss: 0.0966673195362091, acc: 0.9748520851135254)
[2024-12-17 02:54:11,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:12,029][root][INFO] - Training Epoch: 2/2, step 3589/7134 completed (loss: 0.09356623888015747, acc: 0.9788199663162231)
[2024-12-17 02:54:12,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:12,391][root][INFO] - Training Epoch: 2/2, step 3590/7134 completed (loss: 0.03835614398121834, acc: 0.9859550595283508)
[2024-12-17 02:54:12,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:12,711][root][INFO] - Training Epoch: 2/2, step 3591/7134 completed (loss: 0.059513602405786514, acc: 0.9804804921150208)
[2024-12-17 02:54:12,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:13,040][root][INFO] - Training Epoch: 2/2, step 3592/7134 completed (loss: 0.03380390629172325, acc: 0.9917355179786682)
[2024-12-17 02:54:13,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:13,389][root][INFO] - Training Epoch: 2/2, step 3593/7134 completed (loss: 0.06280678510665894, acc: 0.9807355403900146)
[2024-12-17 02:54:13,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:13,716][root][INFO] - Training Epoch: 2/2, step 3594/7134 completed (loss: 0.034857627004384995, acc: 0.9902597665786743)
[2024-12-17 02:54:13,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:14,076][root][INFO] - Training Epoch: 2/2, step 3595/7134 completed (loss: 0.05245524272322655, acc: 0.9800918698310852)
[2024-12-17 02:54:14,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:14,408][root][INFO] - Training Epoch: 2/2, step 3596/7134 completed (loss: 0.04378286749124527, acc: 0.9889958500862122)
[2024-12-17 02:54:14,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:14,768][root][INFO] - Training Epoch: 2/2, step 3597/7134 completed (loss: 0.03977043181657791, acc: 0.9899280667304993)
[2024-12-17 02:54:14,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:15,157][root][INFO] - Training Epoch: 2/2, step 3598/7134 completed (loss: 0.07191015034914017, acc: 0.9828375577926636)
[2024-12-17 02:54:15,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:15,512][root][INFO] - Training Epoch: 2/2, step 3599/7134 completed (loss: 0.0865527093410492, acc: 0.9722572565078735)
[2024-12-17 02:54:15,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:15,881][root][INFO] - Training Epoch: 2/2, step 3600/7134 completed (loss: 0.060664478689432144, acc: 0.9809203147888184)
[2024-12-17 02:54:15,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:16,236][root][INFO] - Training Epoch: 2/2, step 3601/7134 completed (loss: 0.15267623960971832, acc: 0.9668965339660645)
[2024-12-17 02:54:16,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:16,595][root][INFO] - Training Epoch: 2/2, step 3602/7134 completed (loss: 0.10744814574718475, acc: 0.9708284735679626)
[2024-12-17 02:54:16,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:16,917][root][INFO] - Training Epoch: 2/2, step 3603/7134 completed (loss: 0.03769611194729805, acc: 0.987500011920929)
[2024-12-17 02:54:17,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:17,260][root][INFO] - Training Epoch: 2/2, step 3604/7134 completed (loss: 0.039938174188137054, acc: 0.9849905967712402)
[2024-12-17 02:54:17,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:17,661][root][INFO] - Training Epoch: 2/2, step 3605/7134 completed (loss: 0.06591997295618057, acc: 0.9855072498321533)
[2024-12-17 02:54:17,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:18,039][root][INFO] - Training Epoch: 2/2, step 3606/7134 completed (loss: 0.08931416273117065, acc: 0.9715808033943176)
[2024-12-17 02:54:18,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:18,395][root][INFO] - Training Epoch: 2/2, step 3607/7134 completed (loss: 0.04662206768989563, acc: 0.9899328947067261)
[2024-12-17 02:54:18,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:18,786][root][INFO] - Training Epoch: 2/2, step 3608/7134 completed (loss: 0.12006748467683792, acc: 0.971238911151886)
[2024-12-17 02:54:18,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:19,171][root][INFO] - Training Epoch: 2/2, step 3609/7134 completed (loss: 0.09002631157636642, acc: 0.9771573543548584)
[2024-12-17 02:54:19,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:19,542][root][INFO] - Training Epoch: 2/2, step 3610/7134 completed (loss: 0.10465642809867859, acc: 0.9714285731315613)
[2024-12-17 02:54:19,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:19,907][root][INFO] - Training Epoch: 2/2, step 3611/7134 completed (loss: 0.06543400883674622, acc: 0.9852150678634644)
[2024-12-17 02:54:20,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:20,292][root][INFO] - Training Epoch: 2/2, step 3612/7134 completed (loss: 0.11092647165060043, acc: 0.9730290174484253)
[2024-12-17 02:54:20,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:20,661][root][INFO] - Training Epoch: 2/2, step 3613/7134 completed (loss: 0.07700590044260025, acc: 0.9758269786834717)
[2024-12-17 02:54:20,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:21,008][root][INFO] - Training Epoch: 2/2, step 3614/7134 completed (loss: 0.05633953586220741, acc: 0.9785810112953186)
[2024-12-17 02:54:21,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:21,362][root][INFO] - Training Epoch: 2/2, step 3615/7134 completed (loss: 0.039525341242551804, acc: 0.9892966151237488)
[2024-12-17 02:54:21,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:21,708][root][INFO] - Training Epoch: 2/2, step 3616/7134 completed (loss: 0.05103088170289993, acc: 0.9843013882637024)
[2024-12-17 02:54:21,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:22,077][root][INFO] - Training Epoch: 2/2, step 3617/7134 completed (loss: 0.057480935007333755, acc: 0.9826732873916626)
[2024-12-17 02:54:22,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:22,406][root][INFO] - Training Epoch: 2/2, step 3618/7134 completed (loss: 0.14520297944545746, acc: 0.9640522599220276)
[2024-12-17 02:54:22,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:22,763][root][INFO] - Training Epoch: 2/2, step 3619/7134 completed (loss: 0.12479507923126221, acc: 0.961904764175415)
[2024-12-17 02:54:22,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:23,134][root][INFO] - Training Epoch: 2/2, step 3620/7134 completed (loss: 0.08357017487287521, acc: 0.9789029359817505)
[2024-12-17 02:54:23,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:23,464][root][INFO] - Training Epoch: 2/2, step 3621/7134 completed (loss: 0.047738149762153625, acc: 0.9861303567886353)
[2024-12-17 02:54:23,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:23,834][root][INFO] - Training Epoch: 2/2, step 3622/7134 completed (loss: 0.04459521919488907, acc: 0.9879879951477051)
[2024-12-17 02:54:23,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:24,115][root][INFO] - Training Epoch: 2/2, step 3623/7134 completed (loss: 0.029998861253261566, acc: 0.9962825179100037)
[2024-12-17 02:54:24,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:24,459][root][INFO] - Training Epoch: 2/2, step 3624/7134 completed (loss: 0.031133782118558884, acc: 0.9950000047683716)
[2024-12-17 02:54:24,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:24,757][root][INFO] - Training Epoch: 2/2, step 3625/7134 completed (loss: 0.06721557676792145, acc: 0.9718309640884399)
[2024-12-17 02:54:24,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:25,061][root][INFO] - Training Epoch: 2/2, step 3626/7134 completed (loss: 0.20019343495368958, acc: 0.9546666741371155)
[2024-12-17 02:54:25,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:25,404][root][INFO] - Training Epoch: 2/2, step 3627/7134 completed (loss: 0.10852262377738953, acc: 0.978723406791687)
[2024-12-17 02:54:25,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:25,709][root][INFO] - Training Epoch: 2/2, step 3628/7134 completed (loss: 0.15445378422737122, acc: 0.9517045617103577)
[2024-12-17 02:54:25,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:25,994][root][INFO] - Training Epoch: 2/2, step 3629/7134 completed (loss: 0.13287608325481415, acc: 0.9695122241973877)
[2024-12-17 02:54:26,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:26,315][root][INFO] - Training Epoch: 2/2, step 3630/7134 completed (loss: 0.0831441655755043, acc: 0.9741601943969727)
[2024-12-17 02:54:26,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:26,655][root][INFO] - Training Epoch: 2/2, step 3631/7134 completed (loss: 0.1061042919754982, acc: 0.9754098653793335)
[2024-12-17 02:54:26,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:26,990][root][INFO] - Training Epoch: 2/2, step 3632/7134 completed (loss: 0.0655064508318901, acc: 0.9798792600631714)
[2024-12-17 02:54:27,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:27,317][root][INFO] - Training Epoch: 2/2, step 3633/7134 completed (loss: 0.099651038646698, acc: 0.9770444631576538)
[2024-12-17 02:54:27,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:27,633][root][INFO] - Training Epoch: 2/2, step 3634/7134 completed (loss: 0.12136276066303253, acc: 0.9797570705413818)
[2024-12-17 02:54:27,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:27,959][root][INFO] - Training Epoch: 2/2, step 3635/7134 completed (loss: 0.03976045176386833, acc: 0.9928315281867981)
[2024-12-17 02:54:28,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:28,311][root][INFO] - Training Epoch: 2/2, step 3636/7134 completed (loss: 0.05202120915055275, acc: 0.9842519760131836)
[2024-12-17 02:54:28,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:28,654][root][INFO] - Training Epoch: 2/2, step 3637/7134 completed (loss: 0.04691004380583763, acc: 0.98591548204422)
[2024-12-17 02:54:28,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:28,974][root][INFO] - Training Epoch: 2/2, step 3638/7134 completed (loss: 0.03423185274004936, acc: 0.9882352948188782)
[2024-12-17 02:54:29,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:29,307][root][INFO] - Training Epoch: 2/2, step 3639/7134 completed (loss: 0.030978064984083176, acc: 0.9909909963607788)
[2024-12-17 02:54:29,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:29,653][root][INFO] - Training Epoch: 2/2, step 3640/7134 completed (loss: 0.05112755298614502, acc: 0.9885495901107788)
[2024-12-17 02:54:29,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:29,936][root][INFO] - Training Epoch: 2/2, step 3641/7134 completed (loss: 0.03626317158341408, acc: 0.9883268475532532)
[2024-12-17 02:54:30,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:30,277][root][INFO] - Training Epoch: 2/2, step 3642/7134 completed (loss: 0.036172252148389816, acc: 0.9907264113426208)
[2024-12-17 02:54:30,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:30,621][root][INFO] - Training Epoch: 2/2, step 3643/7134 completed (loss: 0.03506177291274071, acc: 0.9914089441299438)
[2024-12-17 02:54:30,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:30,957][root][INFO] - Training Epoch: 2/2, step 3644/7134 completed (loss: 0.05576612800359726, acc: 0.9886178970336914)
[2024-12-17 02:54:31,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:31,310][root][INFO] - Training Epoch: 2/2, step 3645/7134 completed (loss: 0.0744437649846077, acc: 0.9841549396514893)
[2024-12-17 02:54:31,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:31,661][root][INFO] - Training Epoch: 2/2, step 3646/7134 completed (loss: 0.13637015223503113, acc: 0.9652777910232544)
[2024-12-17 02:54:31,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:31,983][root][INFO] - Training Epoch: 2/2, step 3647/7134 completed (loss: 0.02515588141977787, acc: 0.9974160194396973)
[2024-12-17 02:54:32,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:32,354][root][INFO] - Training Epoch: 2/2, step 3648/7134 completed (loss: 0.06655259430408478, acc: 0.9753086566925049)
[2024-12-17 02:54:32,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:32,704][root][INFO] - Training Epoch: 2/2, step 3649/7134 completed (loss: 0.06983774900436401, acc: 0.9845938086509705)
[2024-12-17 02:54:32,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:33,068][root][INFO] - Training Epoch: 2/2, step 3650/7134 completed (loss: 0.0659746378660202, acc: 0.9803921580314636)
[2024-12-17 02:54:33,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:33,428][root][INFO] - Training Epoch: 2/2, step 3651/7134 completed (loss: 0.08203288912773132, acc: 0.9812332391738892)
[2024-12-17 02:54:33,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:33,757][root][INFO] - Training Epoch: 2/2, step 3652/7134 completed (loss: 0.0719527080655098, acc: 0.9834087491035461)
[2024-12-17 02:54:33,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:34,098][root][INFO] - Training Epoch: 2/2, step 3653/7134 completed (loss: 0.11305887252092361, acc: 0.9758672714233398)
[2024-12-17 02:54:34,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:34,456][root][INFO] - Training Epoch: 2/2, step 3654/7134 completed (loss: 0.03436780348420143, acc: 0.9879102110862732)
[2024-12-17 02:54:34,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:34,799][root][INFO] - Training Epoch: 2/2, step 3655/7134 completed (loss: 0.06925211101770401, acc: 0.9876373410224915)
[2024-12-17 02:54:34,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:35,084][root][INFO] - Training Epoch: 2/2, step 3656/7134 completed (loss: 0.1257319152355194, acc: 0.9763636589050293)
[2024-12-17 02:54:35,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:35,422][root][INFO] - Training Epoch: 2/2, step 3657/7134 completed (loss: 0.025328094139695168, acc: 0.9935897588729858)
[2024-12-17 02:54:35,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:35,764][root][INFO] - Training Epoch: 2/2, step 3658/7134 completed (loss: 0.05433621630072594, acc: 0.9844236969947815)
[2024-12-17 02:54:35,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:36,112][root][INFO] - Training Epoch: 2/2, step 3659/7134 completed (loss: 0.045893918722867966, acc: 0.9850522875785828)
[2024-12-17 02:54:36,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:36,350][root][INFO] - Training Epoch: 2/2, step 3660/7134 completed (loss: 0.05221092328429222, acc: 0.9868852496147156)
[2024-12-17 02:54:36,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:36,630][root][INFO] - Training Epoch: 2/2, step 3661/7134 completed (loss: 0.08045347779989243, acc: 0.9785714149475098)
[2024-12-17 02:54:36,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:36,998][root][INFO] - Training Epoch: 2/2, step 3662/7134 completed (loss: 0.0745057538151741, acc: 0.9817073345184326)
[2024-12-17 02:54:37,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:37,331][root][INFO] - Training Epoch: 2/2, step 3663/7134 completed (loss: 0.049714650958776474, acc: 0.9853479862213135)
[2024-12-17 02:54:37,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:37,670][root][INFO] - Training Epoch: 2/2, step 3664/7134 completed (loss: 0.06208115443587303, acc: 0.9878419637680054)
[2024-12-17 02:54:37,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:38,003][root][INFO] - Training Epoch: 2/2, step 3665/7134 completed (loss: 0.031202293932437897, acc: 0.9934318661689758)
[2024-12-17 02:54:38,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:38,355][root][INFO] - Training Epoch: 2/2, step 3666/7134 completed (loss: 0.06464856117963791, acc: 0.9835766553878784)
[2024-12-17 02:54:38,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:38,674][root][INFO] - Training Epoch: 2/2, step 3667/7134 completed (loss: 0.1955953985452652, acc: 0.9567198157310486)
[2024-12-17 02:54:38,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:39,021][root][INFO] - Training Epoch: 2/2, step 3668/7134 completed (loss: 0.05043946951627731, acc: 0.9912739992141724)
[2024-12-17 02:54:39,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:39,362][root][INFO] - Training Epoch: 2/2, step 3669/7134 completed (loss: 0.02280137874186039, acc: 0.9943289160728455)
[2024-12-17 02:54:39,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:39,696][root][INFO] - Training Epoch: 2/2, step 3670/7134 completed (loss: 0.024204300716519356, acc: 0.9945054650306702)
[2024-12-17 02:54:39,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:40,012][root][INFO] - Training Epoch: 2/2, step 3671/7134 completed (loss: 0.04377852380275726, acc: 0.9884393215179443)
[2024-12-17 02:54:40,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:40,376][root][INFO] - Training Epoch: 2/2, step 3672/7134 completed (loss: 0.030686622485518456, acc: 0.9911616444587708)
[2024-12-17 02:54:40,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:40,706][root][INFO] - Training Epoch: 2/2, step 3673/7134 completed (loss: 0.06264682114124298, acc: 0.9816053509712219)
[2024-12-17 02:54:40,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:41,049][root][INFO] - Training Epoch: 2/2, step 3674/7134 completed (loss: 0.027848515659570694, acc: 0.9937008023262024)
[2024-12-17 02:54:41,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:41,394][root][INFO] - Training Epoch: 2/2, step 3675/7134 completed (loss: 0.028903529047966003, acc: 0.9936224222183228)
[2024-12-17 02:54:41,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:41,733][root][INFO] - Training Epoch: 2/2, step 3676/7134 completed (loss: 0.031836383044719696, acc: 0.9897959232330322)
[2024-12-17 02:54:41,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:42,102][root][INFO] - Training Epoch: 2/2, step 3677/7134 completed (loss: 0.05429794639348984, acc: 0.9863013625144958)
[2024-12-17 02:54:42,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:42,443][root][INFO] - Training Epoch: 2/2, step 3678/7134 completed (loss: 0.036826759576797485, acc: 0.9878542423248291)
[2024-12-17 02:54:42,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:42,808][root][INFO] - Training Epoch: 2/2, step 3679/7134 completed (loss: 0.014454316347837448, acc: 0.9983471035957336)
[2024-12-17 02:54:42,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:43,164][root][INFO] - Training Epoch: 2/2, step 3680/7134 completed (loss: 0.056137364357709885, acc: 0.9853895902633667)
[2024-12-17 02:54:43,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:43,518][root][INFO] - Training Epoch: 2/2, step 3681/7134 completed (loss: 0.05445960909128189, acc: 0.9832402467727661)
[2024-12-17 02:54:43,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:43,871][root][INFO] - Training Epoch: 2/2, step 3682/7134 completed (loss: 0.02360307052731514, acc: 0.992094874382019)
[2024-12-17 02:54:44,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:44,244][root][INFO] - Training Epoch: 2/2, step 3683/7134 completed (loss: 0.03066118247807026, acc: 0.9921259880065918)
[2024-12-17 02:54:44,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:44,571][root][INFO] - Training Epoch: 2/2, step 3684/7134 completed (loss: 0.03467301279306412, acc: 0.9884560108184814)
[2024-12-17 02:54:44,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:44,915][root][INFO] - Training Epoch: 2/2, step 3685/7134 completed (loss: 0.029961714521050453, acc: 0.9865125417709351)
[2024-12-17 02:54:45,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:45,254][root][INFO] - Training Epoch: 2/2, step 3686/7134 completed (loss: 0.02197788655757904, acc: 0.995502233505249)
[2024-12-17 02:54:45,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:45,594][root][INFO] - Training Epoch: 2/2, step 3687/7134 completed (loss: 0.012885164469480515, acc: 0.9969230890274048)
[2024-12-17 02:54:45,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:45,924][root][INFO] - Training Epoch: 2/2, step 3688/7134 completed (loss: 0.012871268205344677, acc: 0.9979715943336487)
[2024-12-17 02:54:46,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:46,260][root][INFO] - Training Epoch: 2/2, step 3689/7134 completed (loss: 0.01921805925667286, acc: 0.9950980544090271)
[2024-12-17 02:54:46,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:46,624][root][INFO] - Training Epoch: 2/2, step 3690/7134 completed (loss: 0.026268474757671356, acc: 0.9885550737380981)
[2024-12-17 02:54:46,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:46,946][root][INFO] - Training Epoch: 2/2, step 3691/7134 completed (loss: 0.05704886466264725, acc: 0.9801489114761353)
[2024-12-17 02:54:47,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:47,284][root][INFO] - Training Epoch: 2/2, step 3692/7134 completed (loss: 0.05707089602947235, acc: 0.9817351698875427)
[2024-12-17 02:54:47,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:47,630][root][INFO] - Training Epoch: 2/2, step 3693/7134 completed (loss: 0.05716163292527199, acc: 0.9858044385910034)
[2024-12-17 02:54:47,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:47,972][root][INFO] - Training Epoch: 2/2, step 3694/7134 completed (loss: 0.025511344894766808, acc: 0.9928876161575317)
[2024-12-17 02:54:48,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:48,320][root][INFO] - Training Epoch: 2/2, step 3695/7134 completed (loss: 0.039729200303554535, acc: 0.9915013909339905)
[2024-12-17 02:54:48,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:48,683][root][INFO] - Training Epoch: 2/2, step 3696/7134 completed (loss: 0.03351014852523804, acc: 0.9897172451019287)
[2024-12-17 02:54:48,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:49,009][root][INFO] - Training Epoch: 2/2, step 3697/7134 completed (loss: 0.022353865206241608, acc: 0.991253674030304)
[2024-12-17 02:54:49,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:49,326][root][INFO] - Training Epoch: 2/2, step 3698/7134 completed (loss: 0.02926775999367237, acc: 0.9903692007064819)
[2024-12-17 02:54:49,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:49,647][root][INFO] - Training Epoch: 2/2, step 3699/7134 completed (loss: 0.009105411358177662, acc: 0.9983108043670654)
[2024-12-17 02:54:49,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:49,991][root][INFO] - Training Epoch: 2/2, step 3700/7134 completed (loss: 0.036922886967659, acc: 0.9927113652229309)
[2024-12-17 02:54:50,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:50,353][root][INFO] - Training Epoch: 2/2, step 3701/7134 completed (loss: 0.024083228781819344, acc: 0.996688723564148)
[2024-12-17 02:54:50,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:50,685][root][INFO] - Training Epoch: 2/2, step 3702/7134 completed (loss: 0.027182182297110558, acc: 0.9903581142425537)
[2024-12-17 02:54:50,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:51,042][root][INFO] - Training Epoch: 2/2, step 3703/7134 completed (loss: 0.037818994373083115, acc: 0.992337167263031)
[2024-12-17 02:54:51,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:51,368][root][INFO] - Training Epoch: 2/2, step 3704/7134 completed (loss: 0.020974595099687576, acc: 0.9895397424697876)
[2024-12-17 02:54:51,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:51,712][root][INFO] - Training Epoch: 2/2, step 3705/7134 completed (loss: 0.06741005927324295, acc: 0.977707028388977)
[2024-12-17 02:54:51,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:52,064][root][INFO] - Training Epoch: 2/2, step 3706/7134 completed (loss: 0.11080321669578552, acc: 0.9729397296905518)
[2024-12-17 02:54:52,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:52,408][root][INFO] - Training Epoch: 2/2, step 3707/7134 completed (loss: 0.030407391488552094, acc: 0.9887797832489014)
[2024-12-17 02:54:52,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:52,772][root][INFO] - Training Epoch: 2/2, step 3708/7134 completed (loss: 0.07169010490179062, acc: 0.9821428656578064)
[2024-12-17 02:54:52,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:53,156][root][INFO] - Training Epoch: 2/2, step 3709/7134 completed (loss: 0.04550531134009361, acc: 0.9888437986373901)
[2024-12-17 02:54:53,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:53,541][root][INFO] - Training Epoch: 2/2, step 3710/7134 completed (loss: 0.059669241309165955, acc: 0.9805327653884888)
[2024-12-17 02:54:53,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:53,871][root][INFO] - Training Epoch: 2/2, step 3711/7134 completed (loss: 0.03464270383119583, acc: 0.9913151264190674)
[2024-12-17 02:54:53,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:54,247][root][INFO] - Training Epoch: 2/2, step 3712/7134 completed (loss: 0.032077159732580185, acc: 0.9916368126869202)
[2024-12-17 02:54:54,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:54,591][root][INFO] - Training Epoch: 2/2, step 3713/7134 completed (loss: 0.06344718486070633, acc: 0.9852216839790344)
[2024-12-17 02:54:54,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:54,959][root][INFO] - Training Epoch: 2/2, step 3714/7134 completed (loss: 0.04364863038063049, acc: 0.9878453016281128)
[2024-12-17 02:54:55,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:55,316][root][INFO] - Training Epoch: 2/2, step 3715/7134 completed (loss: 0.03004986047744751, acc: 0.9891172647476196)
[2024-12-17 02:54:55,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:55,691][root][INFO] - Training Epoch: 2/2, step 3716/7134 completed (loss: 0.0654996708035469, acc: 0.9802712798118591)
[2024-12-17 02:54:55,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:56,043][root][INFO] - Training Epoch: 2/2, step 3717/7134 completed (loss: 0.03197910636663437, acc: 0.9918032884597778)
[2024-12-17 02:54:56,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:56,418][root][INFO] - Training Epoch: 2/2, step 3718/7134 completed (loss: 0.06363848596811295, acc: 0.9812426567077637)
[2024-12-17 02:54:56,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:56,776][root][INFO] - Training Epoch: 2/2, step 3719/7134 completed (loss: 0.08465833961963654, acc: 0.9838235378265381)
[2024-12-17 02:54:56,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:57,086][root][INFO] - Training Epoch: 2/2, step 3720/7134 completed (loss: 0.026391049847006798, acc: 0.9912023544311523)
[2024-12-17 02:54:57,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:57,453][root][INFO] - Training Epoch: 2/2, step 3721/7134 completed (loss: 0.05337657034397125, acc: 0.9853528738021851)
[2024-12-17 02:54:57,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:57,805][root][INFO] - Training Epoch: 2/2, step 3722/7134 completed (loss: 0.025085827335715294, acc: 0.9926108121871948)
[2024-12-17 02:54:57,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:58,138][root][INFO] - Training Epoch: 2/2, step 3723/7134 completed (loss: 0.0588652677834034, acc: 0.9884892106056213)
[2024-12-17 02:54:58,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:58,486][root][INFO] - Training Epoch: 2/2, step 3724/7134 completed (loss: 0.04901308938860893, acc: 0.9870689511299133)
[2024-12-17 02:54:58,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:58,853][root][INFO] - Training Epoch: 2/2, step 3725/7134 completed (loss: 0.11631171405315399, acc: 0.976401150226593)
[2024-12-17 02:54:58,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:59,218][root][INFO] - Training Epoch: 2/2, step 3726/7134 completed (loss: 0.039672162383794785, acc: 0.9914984107017517)
[2024-12-17 02:54:59,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:59,559][root][INFO] - Training Epoch: 2/2, step 3727/7134 completed (loss: 0.04966405779123306, acc: 0.9906542301177979)
[2024-12-17 02:54:59,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:59,918][root][INFO] - Training Epoch: 2/2, step 3728/7134 completed (loss: 0.024759583175182343, acc: 0.990980863571167)
[2024-12-17 02:55:00,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:00,275][root][INFO] - Training Epoch: 2/2, step 3729/7134 completed (loss: 0.0434311218559742, acc: 0.9897727370262146)
[2024-12-17 02:55:00,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:00,634][root][INFO] - Training Epoch: 2/2, step 3730/7134 completed (loss: 0.02695346064865589, acc: 0.9918588995933533)
[2024-12-17 02:55:00,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:00,994][root][INFO] - Training Epoch: 2/2, step 3731/7134 completed (loss: 0.02510097622871399, acc: 0.9925280213356018)
[2024-12-17 02:55:01,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:01,350][root][INFO] - Training Epoch: 2/2, step 3732/7134 completed (loss: 0.014399292878806591, acc: 0.9988649487495422)
[2024-12-17 02:55:01,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:01,712][root][INFO] - Training Epoch: 2/2, step 3733/7134 completed (loss: 0.06454836577177048, acc: 0.9845722317695618)
[2024-12-17 02:55:01,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:02,049][root][INFO] - Training Epoch: 2/2, step 3734/7134 completed (loss: 0.05923548340797424, acc: 0.983818769454956)
[2024-12-17 02:55:02,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:02,435][root][INFO] - Training Epoch: 2/2, step 3735/7134 completed (loss: 0.06805235147476196, acc: 0.9804216623306274)
[2024-12-17 02:55:02,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:02,806][root][INFO] - Training Epoch: 2/2, step 3736/7134 completed (loss: 0.11978036910295486, acc: 0.9686956405639648)
[2024-12-17 02:55:02,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:03,144][root][INFO] - Training Epoch: 2/2, step 3737/7134 completed (loss: 0.0866803377866745, acc: 0.9743589758872986)
[2024-12-17 02:55:03,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:03,466][root][INFO] - Training Epoch: 2/2, step 3738/7134 completed (loss: 0.046281155198812485, acc: 0.9884488582611084)
[2024-12-17 02:55:03,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:03,755][root][INFO] - Training Epoch: 2/2, step 3739/7134 completed (loss: 0.10448083281517029, acc: 0.9691011309623718)
[2024-12-17 02:55:03,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:04,088][root][INFO] - Training Epoch: 2/2, step 3740/7134 completed (loss: 0.04059864580631256, acc: 0.9837662577629089)
[2024-12-17 02:55:04,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:04,428][root][INFO] - Training Epoch: 2/2, step 3741/7134 completed (loss: 0.07500702887773514, acc: 0.9786019921302795)
[2024-12-17 02:55:04,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:04,721][root][INFO] - Training Epoch: 2/2, step 3742/7134 completed (loss: 0.07076387107372284, acc: 0.9829059839248657)
[2024-12-17 02:55:04,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:05,068][root][INFO] - Training Epoch: 2/2, step 3743/7134 completed (loss: 0.10735080391168594, acc: 0.9734513163566589)
[2024-12-17 02:55:05,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:05,416][root][INFO] - Training Epoch: 2/2, step 3744/7134 completed (loss: 0.09110686928033829, acc: 0.9736495614051819)
[2024-12-17 02:55:05,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:05,724][root][INFO] - Training Epoch: 2/2, step 3745/7134 completed (loss: 0.114195317029953, acc: 0.9767981171607971)
[2024-12-17 02:55:05,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:06,073][root][INFO] - Training Epoch: 2/2, step 3746/7134 completed (loss: 0.07371820509433746, acc: 0.977748692035675)
[2024-12-17 02:55:06,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:06,418][root][INFO] - Training Epoch: 2/2, step 3747/7134 completed (loss: 0.08222083002328873, acc: 0.9795918464660645)
[2024-12-17 02:55:06,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:06,721][root][INFO] - Training Epoch: 2/2, step 3748/7134 completed (loss: 0.0792422890663147, acc: 0.9841549396514893)
[2024-12-17 02:55:06,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:07,052][root][INFO] - Training Epoch: 2/2, step 3749/7134 completed (loss: 0.1074141412973404, acc: 0.9775112271308899)
[2024-12-17 02:55:07,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:07,399][root][INFO] - Training Epoch: 2/2, step 3750/7134 completed (loss: 0.04774387180805206, acc: 0.9832636117935181)
[2024-12-17 02:55:07,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:07,748][root][INFO] - Training Epoch: 2/2, step 3751/7134 completed (loss: 0.07992283254861832, acc: 0.9729729890823364)
[2024-12-17 02:55:07,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:08,098][root][INFO] - Training Epoch: 2/2, step 3752/7134 completed (loss: 0.06940572708845139, acc: 0.9805970191955566)
[2024-12-17 02:55:08,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:08,444][root][INFO] - Training Epoch: 2/2, step 3753/7134 completed (loss: 0.10651775449514389, acc: 0.9686098694801331)
[2024-12-17 02:55:08,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:08,768][root][INFO] - Training Epoch: 2/2, step 3754/7134 completed (loss: 0.03564736619591713, acc: 0.9893778562545776)
[2024-12-17 02:55:08,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:09,095][root][INFO] - Training Epoch: 2/2, step 3755/7134 completed (loss: 0.040590621531009674, acc: 0.9888682961463928)
[2024-12-17 02:55:09,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:09,431][root][INFO] - Training Epoch: 2/2, step 3756/7134 completed (loss: 0.07991653680801392, acc: 0.9819944500923157)
[2024-12-17 02:55:09,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:09,771][root][INFO] - Training Epoch: 2/2, step 3757/7134 completed (loss: 0.10440085828304291, acc: 0.9737274050712585)
[2024-12-17 02:55:09,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:10,075][root][INFO] - Training Epoch: 2/2, step 3758/7134 completed (loss: 0.07193810492753983, acc: 0.9837837815284729)
[2024-12-17 02:55:10,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:10,409][root][INFO] - Training Epoch: 2/2, step 3759/7134 completed (loss: 0.08409588783979416, acc: 0.974662184715271)
[2024-12-17 02:55:10,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:10,782][root][INFO] - Training Epoch: 2/2, step 3760/7134 completed (loss: 0.0812959149479866, acc: 0.9816384315490723)
[2024-12-17 02:55:10,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:11,121][root][INFO] - Training Epoch: 2/2, step 3761/7134 completed (loss: 0.05760158598423004, acc: 0.984544038772583)
[2024-12-17 02:55:11,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:11,479][root][INFO] - Training Epoch: 2/2, step 3762/7134 completed (loss: 0.041565269231796265, acc: 0.9889958500862122)
[2024-12-17 02:55:11,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:11,815][root][INFO] - Training Epoch: 2/2, step 3763/7134 completed (loss: 0.027418483048677444, acc: 0.9938271641731262)
[2024-12-17 02:55:11,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:12,152][root][INFO] - Training Epoch: 2/2, step 3764/7134 completed (loss: 0.058050159364938736, acc: 0.9835841059684753)
[2024-12-17 02:55:12,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:12,532][root][INFO] - Training Epoch: 2/2, step 3765/7134 completed (loss: 0.028925055637955666, acc: 0.9927971363067627)
[2024-12-17 02:55:12,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:12,845][root][INFO] - Training Epoch: 2/2, step 3766/7134 completed (loss: 0.10433043539524078, acc: 0.9772079586982727)
[2024-12-17 02:55:12,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:13,195][root][INFO] - Training Epoch: 2/2, step 3767/7134 completed (loss: 0.029771985486149788, acc: 0.9875311851501465)
[2024-12-17 02:55:13,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:13,546][root][INFO] - Training Epoch: 2/2, step 3768/7134 completed (loss: 0.02144775353372097, acc: 0.9958506226539612)
[2024-12-17 02:55:13,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:13,918][root][INFO] - Training Epoch: 2/2, step 3769/7134 completed (loss: 0.03997817263007164, acc: 0.988664984703064)
[2024-12-17 02:55:14,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:14,289][root][INFO] - Training Epoch: 2/2, step 3770/7134 completed (loss: 0.05803567171096802, acc: 0.9858757257461548)
[2024-12-17 02:55:14,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:14,643][root][INFO] - Training Epoch: 2/2, step 3771/7134 completed (loss: 0.03245077654719353, acc: 0.9896103739738464)
[2024-12-17 02:55:14,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:14,986][root][INFO] - Training Epoch: 2/2, step 3772/7134 completed (loss: 0.07534285634756088, acc: 0.9775784611701965)
[2024-12-17 02:55:15,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:15,350][root][INFO] - Training Epoch: 2/2, step 3773/7134 completed (loss: 0.04967648535966873, acc: 0.9888392686843872)
[2024-12-17 02:55:15,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:15,710][root][INFO] - Training Epoch: 2/2, step 3774/7134 completed (loss: 0.026140699163079262, acc: 0.9930394291877747)
[2024-12-17 02:55:15,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:16,059][root][INFO] - Training Epoch: 2/2, step 3775/7134 completed (loss: 0.027807055041193962, acc: 0.9914039969444275)
[2024-12-17 02:55:16,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:16,412][root][INFO] - Training Epoch: 2/2, step 3776/7134 completed (loss: 0.04438203573226929, acc: 0.9866666793823242)
[2024-12-17 02:55:16,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:16,754][root][INFO] - Training Epoch: 2/2, step 3777/7134 completed (loss: 0.03795475512742996, acc: 0.9912280440330505)
[2024-12-17 02:55:16,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:17,105][root][INFO] - Training Epoch: 2/2, step 3778/7134 completed (loss: 0.08581706136465073, acc: 0.9815078377723694)
[2024-12-17 02:55:17,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:17,440][root][INFO] - Training Epoch: 2/2, step 3779/7134 completed (loss: 0.03634989261627197, acc: 0.9900285005569458)
[2024-12-17 02:55:17,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:17,798][root][INFO] - Training Epoch: 2/2, step 3780/7134 completed (loss: 0.033835235983133316, acc: 0.9884726405143738)
[2024-12-17 02:55:17,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:18,128][root][INFO] - Training Epoch: 2/2, step 3781/7134 completed (loss: 0.07948529720306396, acc: 0.9807956218719482)
[2024-12-17 02:55:18,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:18,476][root][INFO] - Training Epoch: 2/2, step 3782/7134 completed (loss: 0.045955270528793335, acc: 0.9786324501037598)
[2024-12-17 02:55:18,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:18,821][root][INFO] - Training Epoch: 2/2, step 3783/7134 completed (loss: 0.05612126365303993, acc: 0.9832258224487305)
[2024-12-17 02:55:18,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:19,148][root][INFO] - Training Epoch: 2/2, step 3784/7134 completed (loss: 0.05861154571175575, acc: 0.9876352548599243)
[2024-12-17 02:55:19,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:19,479][root][INFO] - Training Epoch: 2/2, step 3785/7134 completed (loss: 0.015124517492949963, acc: 0.9937597513198853)
[2024-12-17 02:55:19,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:19,811][root][INFO] - Training Epoch: 2/2, step 3786/7134 completed (loss: 0.07109317928552628, acc: 0.9818887710571289)
[2024-12-17 02:55:19,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:20,114][root][INFO] - Training Epoch: 2/2, step 3787/7134 completed (loss: 0.05719904974102974, acc: 0.9856459498405457)
[2024-12-17 02:55:20,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:20,491][root][INFO] - Training Epoch: 2/2, step 3788/7134 completed (loss: 0.04349427670240402, acc: 0.9851552248001099)
[2024-12-17 02:55:20,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:20,838][root][INFO] - Training Epoch: 2/2, step 3789/7134 completed (loss: 0.06669869273900986, acc: 0.9789029359817505)
[2024-12-17 02:55:20,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:21,188][root][INFO] - Training Epoch: 2/2, step 3790/7134 completed (loss: 0.11782599985599518, acc: 0.9746514558792114)
[2024-12-17 02:55:21,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:21,519][root][INFO] - Training Epoch: 2/2, step 3791/7134 completed (loss: 0.0370430164039135, acc: 0.9922580718994141)
[2024-12-17 02:55:21,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:21,848][root][INFO] - Training Epoch: 2/2, step 3792/7134 completed (loss: 0.044583503156900406, acc: 0.9835796356201172)
[2024-12-17 02:55:21,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:22,193][root][INFO] - Training Epoch: 2/2, step 3793/7134 completed (loss: 0.06732561439275742, acc: 0.9837837815284729)
[2024-12-17 02:55:22,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:22,527][root][INFO] - Training Epoch: 2/2, step 3794/7134 completed (loss: 0.03820541128516197, acc: 0.9922178983688354)
[2024-12-17 02:55:22,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:22,898][root][INFO] - Training Epoch: 2/2, step 3795/7134 completed (loss: 0.06334862858057022, acc: 0.9855421781539917)
[2024-12-17 02:55:23,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:23,247][root][INFO] - Training Epoch: 2/2, step 3796/7134 completed (loss: 0.042740967124700546, acc: 0.9874371886253357)
[2024-12-17 02:55:23,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:23,588][root][INFO] - Training Epoch: 2/2, step 3797/7134 completed (loss: 0.03829911723732948, acc: 0.9908735156059265)
[2024-12-17 02:55:23,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:23,934][root][INFO] - Training Epoch: 2/2, step 3798/7134 completed (loss: 0.07340442389249802, acc: 0.9813218116760254)
[2024-12-17 02:55:24,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:24,276][root][INFO] - Training Epoch: 2/2, step 3799/7134 completed (loss: 0.051310691982507706, acc: 0.9871299862861633)
[2024-12-17 02:55:24,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:24,613][root][INFO] - Training Epoch: 2/2, step 3800/7134 completed (loss: 0.05648647993803024, acc: 0.9892966151237488)
[2024-12-17 02:55:24,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:24,974][root][INFO] - Training Epoch: 2/2, step 3801/7134 completed (loss: 0.031848322600126266, acc: 0.9888888597488403)
[2024-12-17 02:55:25,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:25,327][root][INFO] - Training Epoch: 2/2, step 3802/7134 completed (loss: 0.040587108582258224, acc: 0.991725742816925)
[2024-12-17 02:55:25,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:25,656][root][INFO] - Training Epoch: 2/2, step 3803/7134 completed (loss: 0.06302408874034882, acc: 0.9803921580314636)
[2024-12-17 02:55:25,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:26,016][root][INFO] - Training Epoch: 2/2, step 3804/7134 completed (loss: 0.030861761420965195, acc: 0.9906687140464783)
[2024-12-17 02:55:26,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:26,370][root][INFO] - Training Epoch: 2/2, step 3805/7134 completed (loss: 0.03143678605556488, acc: 0.9908376932144165)
[2024-12-17 02:55:26,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:26,742][root][INFO] - Training Epoch: 2/2, step 3806/7134 completed (loss: 0.06790531426668167, acc: 0.9822485446929932)
[2024-12-17 02:55:26,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:27,085][root][INFO] - Training Epoch: 2/2, step 3807/7134 completed (loss: 0.012066143564879894, acc: 0.9970760345458984)
[2024-12-17 02:55:27,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:27,451][root][INFO] - Training Epoch: 2/2, step 3808/7134 completed (loss: 0.04304775595664978, acc: 0.9911392331123352)
[2024-12-17 02:55:27,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:27,794][root][INFO] - Training Epoch: 2/2, step 3809/7134 completed (loss: 0.07301265746355057, acc: 0.9796954393386841)
[2024-12-17 02:55:27,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:28,122][root][INFO] - Training Epoch: 2/2, step 3810/7134 completed (loss: 0.04913027957081795, acc: 0.9851190447807312)
[2024-12-17 02:55:28,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:28,469][root][INFO] - Training Epoch: 2/2, step 3811/7134 completed (loss: 0.04279044643044472, acc: 0.9903448224067688)
[2024-12-17 02:55:28,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:28,819][root][INFO] - Training Epoch: 2/2, step 3812/7134 completed (loss: 0.067036934196949, acc: 0.9777015447616577)
[2024-12-17 02:55:28,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:29,173][root][INFO] - Training Epoch: 2/2, step 3813/7134 completed (loss: 0.08031164854764938, acc: 0.9749340415000916)
[2024-12-17 02:55:29,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:29,525][root][INFO] - Training Epoch: 2/2, step 3814/7134 completed (loss: 0.023573074489831924, acc: 0.9946380853652954)
[2024-12-17 02:55:29,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:29,863][root][INFO] - Training Epoch: 2/2, step 3815/7134 completed (loss: 0.04149091616272926, acc: 0.9896296262741089)
[2024-12-17 02:55:29,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:30,230][root][INFO] - Training Epoch: 2/2, step 3816/7134 completed (loss: 0.03413742780685425, acc: 0.9905362725257874)
[2024-12-17 02:55:30,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:30,553][root][INFO] - Training Epoch: 2/2, step 3817/7134 completed (loss: 0.05602133646607399, acc: 0.9784172773361206)
[2024-12-17 02:55:30,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:30,864][root][INFO] - Training Epoch: 2/2, step 3818/7134 completed (loss: 0.09934426844120026, acc: 0.9838383793830872)
[2024-12-17 02:55:30,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:31,144][root][INFO] - Training Epoch: 2/2, step 3819/7134 completed (loss: 0.08282399922609329, acc: 0.9759036302566528)
[2024-12-17 02:55:31,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:31,464][root][INFO] - Training Epoch: 2/2, step 3820/7134 completed (loss: 0.06095826253294945, acc: 0.9738717079162598)
[2024-12-17 02:55:31,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:31,786][root][INFO] - Training Epoch: 2/2, step 3821/7134 completed (loss: 0.04264242202043533, acc: 0.9847715497016907)
[2024-12-17 02:55:31,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:32,104][root][INFO] - Training Epoch: 2/2, step 3822/7134 completed (loss: 0.058892711997032166, acc: 0.9803536534309387)
[2024-12-17 02:55:32,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:32,449][root][INFO] - Training Epoch: 2/2, step 3823/7134 completed (loss: 0.030173655599355698, acc: 0.9917012453079224)
[2024-12-17 02:55:32,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:32,767][root][INFO] - Training Epoch: 2/2, step 3824/7134 completed (loss: 0.08009786903858185, acc: 0.9747048616409302)
[2024-12-17 02:55:32,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:33,103][root][INFO] - Training Epoch: 2/2, step 3825/7134 completed (loss: 0.04018499702215195, acc: 0.9880239367485046)
[2024-12-17 02:55:33,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:33,453][root][INFO] - Training Epoch: 2/2, step 3826/7134 completed (loss: 0.05982571095228195, acc: 0.979411780834198)
[2024-12-17 02:55:33,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:33,805][root][INFO] - Training Epoch: 2/2, step 3827/7134 completed (loss: 0.05757085606455803, acc: 0.9873949289321899)
[2024-12-17 02:55:33,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:34,098][root][INFO] - Training Epoch: 2/2, step 3828/7134 completed (loss: 0.04075297340750694, acc: 0.9893898963928223)
[2024-12-17 02:55:34,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:34,462][root][INFO] - Training Epoch: 2/2, step 3829/7134 completed (loss: 0.04080907627940178, acc: 0.9894419312477112)
[2024-12-17 02:55:34,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:34,798][root][INFO] - Training Epoch: 2/2, step 3830/7134 completed (loss: 0.06394914537668228, acc: 0.9865996837615967)
[2024-12-17 02:55:34,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:35,143][root][INFO] - Training Epoch: 2/2, step 3831/7134 completed (loss: 0.047468848526477814, acc: 0.9879879951477051)
[2024-12-17 02:55:35,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:35,459][root][INFO] - Training Epoch: 2/2, step 3832/7134 completed (loss: 0.037719517946243286, acc: 0.994106113910675)
[2024-12-17 02:55:35,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:35,801][root][INFO] - Training Epoch: 2/2, step 3833/7134 completed (loss: 0.017053430899977684, acc: 0.9950494766235352)
[2024-12-17 02:55:35,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:36,139][root][INFO] - Training Epoch: 2/2, step 3834/7134 completed (loss: 0.0061310576274991035, acc: 1.0)
[2024-12-17 02:55:36,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:36,465][root][INFO] - Training Epoch: 2/2, step 3835/7134 completed (loss: 0.017105473205447197, acc: 0.9915048480033875)
[2024-12-17 02:55:36,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:36,722][root][INFO] - Training Epoch: 2/2, step 3836/7134 completed (loss: 0.08504873514175415, acc: 0.9884058237075806)
[2024-12-17 02:55:36,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:37,035][root][INFO] - Training Epoch: 2/2, step 3837/7134 completed (loss: 0.054501280188560486, acc: 0.9899425506591797)
[2024-12-17 02:55:37,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:37,377][root][INFO] - Training Epoch: 2/2, step 3838/7134 completed (loss: 0.016316348686814308, acc: 0.9960159659385681)
[2024-12-17 02:55:37,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:37,738][root][INFO] - Training Epoch: 2/2, step 3839/7134 completed (loss: 0.0444098562002182, acc: 0.9903314709663391)
[2024-12-17 02:55:37,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:38,075][root][INFO] - Training Epoch: 2/2, step 3840/7134 completed (loss: 0.030128180980682373, acc: 0.9919678568840027)
[2024-12-17 02:55:38,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:38,449][root][INFO] - Training Epoch: 2/2, step 3841/7134 completed (loss: 0.06956421583890915, acc: 0.9822419285774231)
[2024-12-17 02:55:38,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:38,692][root][INFO] - Training Epoch: 2/2, step 3842/7134 completed (loss: 0.007416611071676016, acc: 0.9975489974021912)
[2024-12-17 02:55:38,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:39,075][root][INFO] - Training Epoch: 2/2, step 3843/7134 completed (loss: 0.037267010658979416, acc: 0.9895724654197693)
[2024-12-17 02:55:39,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:39,430][root][INFO] - Training Epoch: 2/2, step 3844/7134 completed (loss: 0.035155512392520905, acc: 0.9923760890960693)
[2024-12-17 02:55:39,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:39,744][root][INFO] - Training Epoch: 2/2, step 3845/7134 completed (loss: 0.0569685623049736, acc: 0.9865319728851318)
[2024-12-17 02:55:39,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:40,047][root][INFO] - Training Epoch: 2/2, step 3846/7134 completed (loss: 0.025756198912858963, acc: 0.9932088255882263)
[2024-12-17 02:55:40,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:40,377][root][INFO] - Training Epoch: 2/2, step 3847/7134 completed (loss: 0.022884979844093323, acc: 0.995199978351593)
[2024-12-17 02:55:40,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:40,751][root][INFO] - Training Epoch: 2/2, step 3848/7134 completed (loss: 0.06495188921689987, acc: 0.9885495901107788)
[2024-12-17 02:55:40,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:41,069][root][INFO] - Training Epoch: 2/2, step 3849/7134 completed (loss: 0.04768501967191696, acc: 0.9839572310447693)
[2024-12-17 02:55:41,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:41,401][root][INFO] - Training Epoch: 2/2, step 3850/7134 completed (loss: 0.08442048728466034, acc: 0.9779950976371765)
[2024-12-17 02:55:41,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:41,764][root][INFO] - Training Epoch: 2/2, step 3851/7134 completed (loss: 0.052670110017061234, acc: 0.9846583008766174)
[2024-12-17 02:55:41,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:42,088][root][INFO] - Training Epoch: 2/2, step 3852/7134 completed (loss: 0.034241653978824615, acc: 0.9887459874153137)
[2024-12-17 02:55:42,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:42,424][root][INFO] - Training Epoch: 2/2, step 3853/7134 completed (loss: 0.07772555947303772, acc: 0.9760900139808655)
[2024-12-17 02:55:42,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:42,760][root][INFO] - Training Epoch: 2/2, step 3854/7134 completed (loss: 0.03429681435227394, acc: 0.9859550595283508)
[2024-12-17 02:55:42,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:43,115][root][INFO] - Training Epoch: 2/2, step 3855/7134 completed (loss: 0.06425537914037704, acc: 0.9850373864173889)
[2024-12-17 02:55:43,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:43,436][root][INFO] - Training Epoch: 2/2, step 3856/7134 completed (loss: 0.06841612607240677, acc: 0.9860529899597168)
[2024-12-17 02:55:43,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:43,741][root][INFO] - Training Epoch: 2/2, step 3857/7134 completed (loss: 0.04311984032392502, acc: 0.9855305552482605)
[2024-12-17 02:55:43,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:44,081][root][INFO] - Training Epoch: 2/2, step 3858/7134 completed (loss: 0.07246585935354233, acc: 0.977337121963501)
[2024-12-17 02:55:44,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:44,434][root][INFO] - Training Epoch: 2/2, step 3859/7134 completed (loss: 0.05818628519773483, acc: 0.9809160232543945)
[2024-12-17 02:55:44,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:44,791][root][INFO] - Training Epoch: 2/2, step 3860/7134 completed (loss: 0.043375201523303986, acc: 0.9877095222473145)
[2024-12-17 02:55:44,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:45,137][root][INFO] - Training Epoch: 2/2, step 3861/7134 completed (loss: 0.0550396628677845, acc: 0.9904761910438538)
[2024-12-17 02:55:45,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:45,467][root][INFO] - Training Epoch: 2/2, step 3862/7134 completed (loss: 0.0758703425526619, acc: 0.9786535501480103)
[2024-12-17 02:55:45,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:45,838][root][INFO] - Training Epoch: 2/2, step 3863/7134 completed (loss: 0.04232245683670044, acc: 0.9876543283462524)
[2024-12-17 02:55:45,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:46,194][root][INFO] - Training Epoch: 2/2, step 3864/7134 completed (loss: 0.04534153267741203, acc: 0.9895561337471008)
[2024-12-17 02:55:46,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:46,540][root][INFO] - Training Epoch: 2/2, step 3865/7134 completed (loss: 0.06279081851243973, acc: 0.9780876636505127)
[2024-12-17 02:55:46,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:46,871][root][INFO] - Training Epoch: 2/2, step 3866/7134 completed (loss: 0.05226466804742813, acc: 0.9890109896659851)
[2024-12-17 02:55:46,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:47,221][root][INFO] - Training Epoch: 2/2, step 3867/7134 completed (loss: 0.040519192814826965, acc: 0.9886363744735718)
[2024-12-17 02:55:47,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:47,541][root][INFO] - Training Epoch: 2/2, step 3868/7134 completed (loss: 0.04610643908381462, acc: 0.9864636063575745)
[2024-12-17 02:55:47,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:47,868][root][INFO] - Training Epoch: 2/2, step 3869/7134 completed (loss: 0.047998227179050446, acc: 0.9848713874816895)
[2024-12-17 02:55:47,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:48,193][root][INFO] - Training Epoch: 2/2, step 3870/7134 completed (loss: 0.07665400207042694, acc: 0.980555534362793)
[2024-12-17 02:55:48,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:48,518][root][INFO] - Training Epoch: 2/2, step 3871/7134 completed (loss: 0.059248413890600204, acc: 0.9875311851501465)
[2024-12-17 02:55:48,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:48,886][root][INFO] - Training Epoch: 2/2, step 3872/7134 completed (loss: 0.07074856758117676, acc: 0.983940064907074)
[2024-12-17 02:55:48,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:49,232][root][INFO] - Training Epoch: 2/2, step 3873/7134 completed (loss: 0.05265286937355995, acc: 0.9846547245979309)
[2024-12-17 02:55:49,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:49,564][root][INFO] - Training Epoch: 2/2, step 3874/7134 completed (loss: 0.07761713117361069, acc: 0.9834024906158447)
[2024-12-17 02:55:49,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:49,926][root][INFO] - Training Epoch: 2/2, step 3875/7134 completed (loss: 0.07337193191051483, acc: 0.9827127456665039)
[2024-12-17 02:55:50,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:50,247][root][INFO] - Training Epoch: 2/2, step 3876/7134 completed (loss: 0.06729654967784882, acc: 0.9812382459640503)
[2024-12-17 02:55:50,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:50,576][root][INFO] - Training Epoch: 2/2, step 3877/7134 completed (loss: 0.07573350518941879, acc: 0.9843342304229736)
[2024-12-17 02:55:50,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:50,900][root][INFO] - Training Epoch: 2/2, step 3878/7134 completed (loss: 0.0841921716928482, acc: 0.9770889282226562)
[2024-12-17 02:55:50,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:51,244][root][INFO] - Training Epoch: 2/2, step 3879/7134 completed (loss: 0.030065180733799934, acc: 0.9907578825950623)
[2024-12-17 02:55:51,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:51,598][root][INFO] - Training Epoch: 2/2, step 3880/7134 completed (loss: 0.10472665727138519, acc: 0.9765051603317261)
[2024-12-17 02:55:51,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:51,928][root][INFO] - Training Epoch: 2/2, step 3881/7134 completed (loss: 0.12465422600507736, acc: 0.9693333506584167)
[2024-12-17 02:55:52,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:52,267][root][INFO] - Training Epoch: 2/2, step 3882/7134 completed (loss: 0.08076142519712448, acc: 0.9800000190734863)
[2024-12-17 02:55:52,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:52,612][root][INFO] - Training Epoch: 2/2, step 3883/7134 completed (loss: 0.03405531495809555, acc: 0.9916083812713623)
[2024-12-17 02:55:52,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:52,947][root][INFO] - Training Epoch: 2/2, step 3884/7134 completed (loss: 0.031528133898973465, acc: 0.9918367266654968)
[2024-12-17 02:55:53,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:53,270][root][INFO] - Training Epoch: 2/2, step 3885/7134 completed (loss: 0.04322393611073494, acc: 0.9882506728172302)
[2024-12-17 02:55:53,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:53,624][root][INFO] - Training Epoch: 2/2, step 3886/7134 completed (loss: 0.03480420634150505, acc: 0.9867149591445923)
[2024-12-17 02:55:53,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:53,949][root][INFO] - Training Epoch: 2/2, step 3887/7134 completed (loss: 0.037651415914297104, acc: 0.993966817855835)
[2024-12-17 02:55:54,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:54,297][root][INFO] - Training Epoch: 2/2, step 3888/7134 completed (loss: 0.048392653465270996, acc: 0.9887499809265137)
[2024-12-17 02:55:54,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:54,669][root][INFO] - Training Epoch: 2/2, step 3889/7134 completed (loss: 0.029683202505111694, acc: 0.9936143159866333)
[2024-12-17 02:55:54,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:55,024][root][INFO] - Training Epoch: 2/2, step 3890/7134 completed (loss: 0.02863634191453457, acc: 0.9939831495285034)
[2024-12-17 02:55:55,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:55,388][root][INFO] - Training Epoch: 2/2, step 3891/7134 completed (loss: 0.02788451500236988, acc: 0.9908496737480164)
[2024-12-17 02:55:55,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:55,737][root][INFO] - Training Epoch: 2/2, step 3892/7134 completed (loss: 0.031415171921253204, acc: 0.9907692074775696)
[2024-12-17 02:55:55,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:56,071][root][INFO] - Training Epoch: 2/2, step 3893/7134 completed (loss: 0.08530352264642715, acc: 0.9755154848098755)
[2024-12-17 02:55:56,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:56,390][root][INFO] - Training Epoch: 2/2, step 3894/7134 completed (loss: 0.020601700991392136, acc: 0.9943820238113403)
[2024-12-17 02:55:56,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:56,735][root][INFO] - Training Epoch: 2/2, step 3895/7134 completed (loss: 0.04223402962088585, acc: 0.9896774291992188)
[2024-12-17 02:55:56,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:57,107][root][INFO] - Training Epoch: 2/2, step 3896/7134 completed (loss: 0.01454686839133501, acc: 0.9966139793395996)
[2024-12-17 02:55:57,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:57,468][root][INFO] - Training Epoch: 2/2, step 3897/7134 completed (loss: 0.08761662244796753, acc: 0.9774647951126099)
[2024-12-17 02:55:57,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:57,808][root][INFO] - Training Epoch: 2/2, step 3898/7134 completed (loss: 0.0698971301317215, acc: 0.9809160232543945)
[2024-12-17 02:55:57,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:58,163][root][INFO] - Training Epoch: 2/2, step 3899/7134 completed (loss: 0.031309742480516434, acc: 0.9922380447387695)
[2024-12-17 02:55:58,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:58,552][root][INFO] - Training Epoch: 2/2, step 3900/7134 completed (loss: 0.03764687106013298, acc: 0.9872537851333618)
[2024-12-17 02:55:58,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:58,879][root][INFO] - Training Epoch: 2/2, step 3901/7134 completed (loss: 0.10541793704032898, acc: 0.9757412672042847)
[2024-12-17 02:55:59,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:59,217][root][INFO] - Training Epoch: 2/2, step 3902/7134 completed (loss: 0.1064622700214386, acc: 0.9748344421386719)
[2024-12-17 02:55:59,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:59,587][root][INFO] - Training Epoch: 2/2, step 3903/7134 completed (loss: 0.12124495953321457, acc: 0.9651474356651306)
[2024-12-17 02:55:59,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:59,914][root][INFO] - Training Epoch: 2/2, step 3904/7134 completed (loss: 0.06419503688812256, acc: 0.9832572340965271)
[2024-12-17 02:56:00,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:00,267][root][INFO] - Training Epoch: 2/2, step 3905/7134 completed (loss: 0.037953171879053116, acc: 0.9873060584068298)
[2024-12-17 02:56:00,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:00,621][root][INFO] - Training Epoch: 2/2, step 3906/7134 completed (loss: 0.026100125163793564, acc: 0.9956896305084229)
[2024-12-17 02:56:00,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:00,946][root][INFO] - Training Epoch: 2/2, step 3907/7134 completed (loss: 0.038638386875391006, acc: 0.9897172451019287)
[2024-12-17 02:56:01,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:01,292][root][INFO] - Training Epoch: 2/2, step 3908/7134 completed (loss: 0.07898616045713425, acc: 0.9831546545028687)
[2024-12-17 02:56:01,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:01,625][root][INFO] - Training Epoch: 2/2, step 3909/7134 completed (loss: 0.0344545803964138, acc: 0.9822294116020203)
[2024-12-17 02:56:01,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:01,945][root][INFO] - Training Epoch: 2/2, step 3910/7134 completed (loss: 0.04203355312347412, acc: 0.9847009778022766)
[2024-12-17 02:56:02,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:02,297][root][INFO] - Training Epoch: 2/2, step 3911/7134 completed (loss: 0.03985024243593216, acc: 0.9902912378311157)
[2024-12-17 02:56:02,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:02,639][root][INFO] - Training Epoch: 2/2, step 3912/7134 completed (loss: 0.023285314440727234, acc: 0.988095223903656)
[2024-12-17 02:56:02,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:02,984][root][INFO] - Training Epoch: 2/2, step 3913/7134 completed (loss: 0.041461434215307236, acc: 0.9871794581413269)
[2024-12-17 02:56:03,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:03,306][root][INFO] - Training Epoch: 2/2, step 3914/7134 completed (loss: 0.03941376507282257, acc: 0.9898989796638489)
[2024-12-17 02:56:03,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:03,659][root][INFO] - Training Epoch: 2/2, step 3915/7134 completed (loss: 0.028325295075774193, acc: 0.9915373921394348)
[2024-12-17 02:56:03,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:04,011][root][INFO] - Training Epoch: 2/2, step 3916/7134 completed (loss: 0.03881833702325821, acc: 0.9847133755683899)
[2024-12-17 02:56:04,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:04,363][root][INFO] - Training Epoch: 2/2, step 3917/7134 completed (loss: 0.02192649058997631, acc: 0.9927797913551331)
[2024-12-17 02:56:04,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:04,706][root][INFO] - Training Epoch: 2/2, step 3918/7134 completed (loss: 0.06427985429763794, acc: 0.9791666865348816)
[2024-12-17 02:56:04,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:05,060][root][INFO] - Training Epoch: 2/2, step 3919/7134 completed (loss: 0.07330191880464554, acc: 0.9788273572921753)
[2024-12-17 02:56:05,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:05,413][root][INFO] - Training Epoch: 2/2, step 3920/7134 completed (loss: 0.054147668182849884, acc: 0.9844236969947815)
[2024-12-17 02:56:05,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:05,739][root][INFO] - Training Epoch: 2/2, step 3921/7134 completed (loss: 0.08748522400856018, acc: 0.9760000109672546)
[2024-12-17 02:56:05,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:06,050][root][INFO] - Training Epoch: 2/2, step 3922/7134 completed (loss: 0.16513711214065552, acc: 0.9517819881439209)
[2024-12-17 02:56:06,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:06,371][root][INFO] - Training Epoch: 2/2, step 3923/7134 completed (loss: 0.1776386797428131, acc: 0.9691780805587769)
[2024-12-17 02:56:06,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:06,723][root][INFO] - Training Epoch: 2/2, step 3924/7134 completed (loss: 0.09705585986375809, acc: 0.9727011322975159)
[2024-12-17 02:56:06,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:07,056][root][INFO] - Training Epoch: 2/2, step 3925/7134 completed (loss: 0.08998783677816391, acc: 0.9736456871032715)
[2024-12-17 02:56:07,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:07,373][root][INFO] - Training Epoch: 2/2, step 3926/7134 completed (loss: 0.06973840296268463, acc: 0.9827337861061096)
[2024-12-17 02:56:07,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:07,709][root][INFO] - Training Epoch: 2/2, step 3927/7134 completed (loss: 0.03223360329866409, acc: 0.9876203536987305)
[2024-12-17 02:56:07,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:08,048][root][INFO] - Training Epoch: 2/2, step 3928/7134 completed (loss: 0.07381033152341843, acc: 0.9813218116760254)
[2024-12-17 02:56:08,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:08,359][root][INFO] - Training Epoch: 2/2, step 3929/7134 completed (loss: 0.038988322019577026, acc: 0.9904610514640808)
[2024-12-17 02:56:08,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:08,705][root][INFO] - Training Epoch: 2/2, step 3930/7134 completed (loss: 0.06427393108606339, acc: 0.9831932783126831)
[2024-12-17 02:56:08,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:09,036][root][INFO] - Training Epoch: 2/2, step 3931/7134 completed (loss: 0.03810480982065201, acc: 0.9865471124649048)
[2024-12-17 02:56:09,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:09,374][root][INFO] - Training Epoch: 2/2, step 3932/7134 completed (loss: 0.05476297438144684, acc: 0.9762845635414124)
[2024-12-17 02:56:09,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:09,663][root][INFO] - Training Epoch: 2/2, step 3933/7134 completed (loss: 0.029653605073690414, acc: 0.9901315569877625)
[2024-12-17 02:56:09,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:09,981][root][INFO] - Training Epoch: 2/2, step 3934/7134 completed (loss: 0.027161868289113045, acc: 0.9859485030174255)
[2024-12-17 02:56:10,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:10,293][root][INFO] - Training Epoch: 2/2, step 3935/7134 completed (loss: 0.023187031969428062, acc: 0.9929328560829163)
[2024-12-17 02:56:10,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:10,616][root][INFO] - Training Epoch: 2/2, step 3936/7134 completed (loss: 0.06910979747772217, acc: 0.9867924451828003)
[2024-12-17 02:56:10,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:10,948][root][INFO] - Training Epoch: 2/2, step 3937/7134 completed (loss: 0.05330315977334976, acc: 0.981632649898529)
[2024-12-17 02:56:11,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:11,258][root][INFO] - Training Epoch: 2/2, step 3938/7134 completed (loss: 0.022524643689393997, acc: 0.9932126402854919)
[2024-12-17 02:56:11,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:11,592][root][INFO] - Training Epoch: 2/2, step 3939/7134 completed (loss: 0.08996111899614334, acc: 0.9695431590080261)
[2024-12-17 02:56:11,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:11,915][root][INFO] - Training Epoch: 2/2, step 3940/7134 completed (loss: 0.051524385809898376, acc: 0.9899497628211975)
[2024-12-17 02:56:12,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:12,204][root][INFO] - Training Epoch: 2/2, step 3941/7134 completed (loss: 0.0285774115473032, acc: 0.9908536672592163)
[2024-12-17 02:56:12,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:12,518][root][INFO] - Training Epoch: 2/2, step 3942/7134 completed (loss: 0.038371674716472626, acc: 0.9856557250022888)
[2024-12-17 02:56:12,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:12,766][root][INFO] - Training Epoch: 2/2, step 3943/7134 completed (loss: 0.04019014537334442, acc: 0.9884169697761536)
[2024-12-17 02:56:12,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:13,120][root][INFO] - Training Epoch: 2/2, step 3944/7134 completed (loss: 0.04500693827867508, acc: 0.990774929523468)
[2024-12-17 02:56:13,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:13,453][root][INFO] - Training Epoch: 2/2, step 3945/7134 completed (loss: 0.04335338622331619, acc: 0.9847561120986938)
[2024-12-17 02:56:13,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:13,745][root][INFO] - Training Epoch: 2/2, step 3946/7134 completed (loss: 0.035106923431158066, acc: 0.9895615577697754)
[2024-12-17 02:56:13,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:14,077][root][INFO] - Training Epoch: 2/2, step 3947/7134 completed (loss: 0.05823452025651932, acc: 0.9896373152732849)
[2024-12-17 02:56:14,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:14,394][root][INFO] - Training Epoch: 2/2, step 3948/7134 completed (loss: 0.02938053384423256, acc: 0.9874371886253357)
[2024-12-17 02:56:14,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:14,718][root][INFO] - Training Epoch: 2/2, step 3949/7134 completed (loss: 0.04178769886493683, acc: 0.9888059496879578)
[2024-12-17 02:56:14,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:14,985][root][INFO] - Training Epoch: 2/2, step 3950/7134 completed (loss: 0.07043024897575378, acc: 0.9866071343421936)
[2024-12-17 02:56:15,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:15,278][root][INFO] - Training Epoch: 2/2, step 3951/7134 completed (loss: 0.05149191617965698, acc: 0.9849624037742615)
[2024-12-17 02:56:15,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:15,591][root][INFO] - Training Epoch: 2/2, step 3952/7134 completed (loss: 0.037113312631845474, acc: 0.9897435903549194)
[2024-12-17 02:56:15,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:15,882][root][INFO] - Training Epoch: 2/2, step 3953/7134 completed (loss: 0.04112720116972923, acc: 0.9905123114585876)
[2024-12-17 02:56:15,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:16,165][root][INFO] - Training Epoch: 2/2, step 3954/7134 completed (loss: 0.04042898118495941, acc: 0.9896907210350037)
[2024-12-17 02:56:16,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:16,484][root][INFO] - Training Epoch: 2/2, step 3955/7134 completed (loss: 0.04149573668837547, acc: 0.9932546615600586)
[2024-12-17 02:56:16,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:16,814][root][INFO] - Training Epoch: 2/2, step 3956/7134 completed (loss: 0.030777020379900932, acc: 0.9919999837875366)
[2024-12-17 02:56:16,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:17,135][root][INFO] - Training Epoch: 2/2, step 3957/7134 completed (loss: 0.049031149595975876, acc: 0.9887387156486511)
[2024-12-17 02:56:17,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:17,429][root][INFO] - Training Epoch: 2/2, step 3958/7134 completed (loss: 0.06509526818990707, acc: 0.9775640964508057)
[2024-12-17 02:56:17,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:17,771][root][INFO] - Training Epoch: 2/2, step 3959/7134 completed (loss: 0.021782860159873962, acc: 0.997802197933197)
[2024-12-17 02:56:17,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:18,119][root][INFO] - Training Epoch: 2/2, step 3960/7134 completed (loss: 0.035658445209264755, acc: 0.9900285005569458)
[2024-12-17 02:56:18,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:18,464][root][INFO] - Training Epoch: 2/2, step 3961/7134 completed (loss: 0.020038872957229614, acc: 0.9925037622451782)
[2024-12-17 02:56:18,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:18,788][root][INFO] - Training Epoch: 2/2, step 3962/7134 completed (loss: 0.029217936098575592, acc: 0.991909384727478)
[2024-12-17 02:56:18,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:19,126][root][INFO] - Training Epoch: 2/2, step 3963/7134 completed (loss: 0.08880266547203064, acc: 0.9824047088623047)
[2024-12-17 02:56:19,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:19,444][root][INFO] - Training Epoch: 2/2, step 3964/7134 completed (loss: 0.09874093532562256, acc: 0.979629635810852)
[2024-12-17 02:56:19,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:19,769][root][INFO] - Training Epoch: 2/2, step 3965/7134 completed (loss: 0.04343055561184883, acc: 0.9899857044219971)
[2024-12-17 02:56:19,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:20,092][root][INFO] - Training Epoch: 2/2, step 3966/7134 completed (loss: 0.02803247794508934, acc: 0.9909747242927551)
[2024-12-17 02:56:20,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:20,443][root][INFO] - Training Epoch: 2/2, step 3967/7134 completed (loss: 0.11927788704633713, acc: 0.9722703695297241)
[2024-12-17 02:56:20,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:20,800][root][INFO] - Training Epoch: 2/2, step 3968/7134 completed (loss: 0.0428193025290966, acc: 0.9882965087890625)
[2024-12-17 02:56:20,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:21,090][root][INFO] - Training Epoch: 2/2, step 3969/7134 completed (loss: 0.04065896198153496, acc: 0.981675386428833)
[2024-12-17 02:56:21,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:21,420][root][INFO] - Training Epoch: 2/2, step 3970/7134 completed (loss: 0.11272545903921127, acc: 0.9798561334609985)
[2024-12-17 02:56:21,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:21,780][root][INFO] - Training Epoch: 2/2, step 3971/7134 completed (loss: 0.196459099650383, acc: 0.9603580832481384)
[2024-12-17 02:56:21,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:22,107][root][INFO] - Training Epoch: 2/2, step 3972/7134 completed (loss: 0.18945300579071045, acc: 0.9561855792999268)
[2024-12-17 02:56:22,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:22,439][root][INFO] - Training Epoch: 2/2, step 3973/7134 completed (loss: 0.041997700929641724, acc: 0.984455943107605)
[2024-12-17 02:56:22,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:22,785][root][INFO] - Training Epoch: 2/2, step 3974/7134 completed (loss: 0.11148140579462051, acc: 0.9769647717475891)
[2024-12-17 02:56:22,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:23,108][root][INFO] - Training Epoch: 2/2, step 3975/7134 completed (loss: 0.043009202927351, acc: 0.9864048361778259)
[2024-12-17 02:56:23,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:23,471][root][INFO] - Training Epoch: 2/2, step 3976/7134 completed (loss: 0.1258583515882492, acc: 0.9734513163566589)
[2024-12-17 02:56:23,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:23,814][root][INFO] - Training Epoch: 2/2, step 3977/7134 completed (loss: 0.035251129418611526, acc: 0.991304337978363)
[2024-12-17 02:56:23,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:24,144][root][INFO] - Training Epoch: 2/2, step 3978/7134 completed (loss: 0.02752995304763317, acc: 0.9922380447387695)
[2024-12-17 02:56:24,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:24,502][root][INFO] - Training Epoch: 2/2, step 3979/7134 completed (loss: 0.08937419950962067, acc: 0.9781420826911926)
[2024-12-17 02:56:24,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:24,840][root][INFO] - Training Epoch: 2/2, step 3980/7134 completed (loss: 0.03404532000422478, acc: 0.9954268336296082)
[2024-12-17 02:56:24,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:25,166][root][INFO] - Training Epoch: 2/2, step 3981/7134 completed (loss: 0.07975731045007706, acc: 0.9816513657569885)
[2024-12-17 02:56:25,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:25,503][root][INFO] - Training Epoch: 2/2, step 3982/7134 completed (loss: 0.11697285622358322, acc: 0.9727402925491333)
[2024-12-17 02:56:25,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:25,838][root][INFO] - Training Epoch: 2/2, step 3983/7134 completed (loss: 0.3643260896205902, acc: 0.9191489219665527)
[2024-12-17 02:56:25,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:26,190][root][INFO] - Training Epoch: 2/2, step 3984/7134 completed (loss: 0.09452015161514282, acc: 0.9753246903419495)
[2024-12-17 02:56:26,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:26,510][root][INFO] - Training Epoch: 2/2, step 3985/7134 completed (loss: 0.04767778515815735, acc: 0.987522304058075)
[2024-12-17 02:56:26,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:26,852][root][INFO] - Training Epoch: 2/2, step 3986/7134 completed (loss: 0.23148468136787415, acc: 0.9560605883598328)
[2024-12-17 02:56:26,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:27,195][root][INFO] - Training Epoch: 2/2, step 3987/7134 completed (loss: 0.09987767040729523, acc: 0.9827255010604858)
[2024-12-17 02:56:27,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:27,563][root][INFO] - Training Epoch: 2/2, step 3988/7134 completed (loss: 0.11865615099668503, acc: 0.9721871018409729)
[2024-12-17 02:56:27,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:27,860][root][INFO] - Training Epoch: 2/2, step 3989/7134 completed (loss: 0.22164691984653473, acc: 0.9530916810035706)
[2024-12-17 02:56:27,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:28,198][root][INFO] - Training Epoch: 2/2, step 3990/7134 completed (loss: 0.06205035746097565, acc: 0.9800994992256165)
[2024-12-17 02:56:28,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:28,468][root][INFO] - Training Epoch: 2/2, step 3991/7134 completed (loss: 0.04068727791309357, acc: 0.9900990128517151)
[2024-12-17 02:56:28,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:28,784][root][INFO] - Training Epoch: 2/2, step 3992/7134 completed (loss: 0.09753213822841644, acc: 0.9756757020950317)
[2024-12-17 02:56:28,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:29,083][root][INFO] - Training Epoch: 2/2, step 3993/7134 completed (loss: 0.07692935317754745, acc: 0.9816513657569885)
[2024-12-17 02:56:29,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:29,402][root][INFO] - Training Epoch: 2/2, step 3994/7134 completed (loss: 0.06645697355270386, acc: 0.9833333492279053)
[2024-12-17 02:56:29,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:29,706][root][INFO] - Training Epoch: 2/2, step 3995/7134 completed (loss: 0.12900611758232117, acc: 0.9728682041168213)
[2024-12-17 02:56:29,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:30,035][root][INFO] - Training Epoch: 2/2, step 3996/7134 completed (loss: 0.054783470928668976, acc: 0.9856262803077698)
[2024-12-17 02:56:30,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:30,366][root][INFO] - Training Epoch: 2/2, step 3997/7134 completed (loss: 0.2045643925666809, acc: 0.9494505524635315)
[2024-12-17 02:56:30,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:30,675][root][INFO] - Training Epoch: 2/2, step 3998/7134 completed (loss: 0.1111312136054039, acc: 0.9693654179573059)
[2024-12-17 02:56:30,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:31,015][root][INFO] - Training Epoch: 2/2, step 3999/7134 completed (loss: 0.07110945135354996, acc: 0.9820359349250793)
[2024-12-17 02:56:31,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:31,335][root][INFO] - Training Epoch: 2/2, step 4000/7134 completed (loss: 0.06053588166832924, acc: 0.9826254844665527)
[2024-12-17 02:56:31,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:31,654][root][INFO] - Training Epoch: 2/2, step 4001/7134 completed (loss: 0.10244783014059067, acc: 0.974155068397522)
[2024-12-17 02:56:31,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:31,973][root][INFO] - Training Epoch: 2/2, step 4002/7134 completed (loss: 0.1037304699420929, acc: 0.9734939932823181)
[2024-12-17 02:56:32,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:32,315][root][INFO] - Training Epoch: 2/2, step 4003/7134 completed (loss: 0.12964124977588654, acc: 0.9704797267913818)
[2024-12-17 02:56:32,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:32,594][root][INFO] - Training Epoch: 2/2, step 4004/7134 completed (loss: 0.07517354190349579, acc: 0.9860140085220337)
[2024-12-17 02:56:32,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:32,910][root][INFO] - Training Epoch: 2/2, step 4005/7134 completed (loss: 0.02715463750064373, acc: 0.9968602657318115)
[2024-12-17 02:56:33,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:33,281][root][INFO] - Training Epoch: 2/2, step 4006/7134 completed (loss: 0.0461401641368866, acc: 0.9864724278450012)
[2024-12-17 02:56:33,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:33,620][root][INFO] - Training Epoch: 2/2, step 4007/7134 completed (loss: 0.062321703881025314, acc: 0.9775112271308899)
[2024-12-17 02:56:33,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:33,981][root][INFO] - Training Epoch: 2/2, step 4008/7134 completed (loss: 0.03160860389471054, acc: 0.9947145581245422)
[2024-12-17 02:56:34,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:34,328][root][INFO] - Training Epoch: 2/2, step 4009/7134 completed (loss: 0.02887364663183689, acc: 0.9920106530189514)
[2024-12-17 02:56:34,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:34,694][root][INFO] - Training Epoch: 2/2, step 4010/7134 completed (loss: 0.03401795029640198, acc: 0.9888142943382263)
[2024-12-17 02:56:34,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:35,048][root][INFO] - Training Epoch: 2/2, step 4011/7134 completed (loss: 0.04650063440203667, acc: 0.9893758296966553)
[2024-12-17 02:56:35,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:35,361][root][INFO] - Training Epoch: 2/2, step 4012/7134 completed (loss: 0.023505685850977898, acc: 0.9929378628730774)
[2024-12-17 02:56:35,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:35,706][root][INFO] - Training Epoch: 2/2, step 4013/7134 completed (loss: 0.015011372044682503, acc: 0.9951768517494202)
[2024-12-17 02:56:35,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:36,063][root][INFO] - Training Epoch: 2/2, step 4014/7134 completed (loss: 0.020809371024370193, acc: 0.9952977895736694)
[2024-12-17 02:56:36,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:36,401][root][INFO] - Training Epoch: 2/2, step 4015/7134 completed (loss: 0.02527516707777977, acc: 0.9907833933830261)
[2024-12-17 02:56:36,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:36,777][root][INFO] - Training Epoch: 2/2, step 4016/7134 completed (loss: 0.047591738402843475, acc: 0.9872449040412903)
[2024-12-17 02:56:36,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:37,144][root][INFO] - Training Epoch: 2/2, step 4017/7134 completed (loss: 0.03330676257610321, acc: 0.9953810572624207)
[2024-12-17 02:56:37,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:37,507][root][INFO] - Training Epoch: 2/2, step 4018/7134 completed (loss: 0.04362305626273155, acc: 0.9927272796630859)
[2024-12-17 02:56:37,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:37,894][root][INFO] - Training Epoch: 2/2, step 4019/7134 completed (loss: 0.0603693462908268, acc: 0.9847715497016907)
[2024-12-17 02:56:37,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:38,218][root][INFO] - Training Epoch: 2/2, step 4020/7134 completed (loss: 0.04276445508003235, acc: 0.9836065769195557)
[2024-12-17 02:56:38,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:38,516][root][INFO] - Training Epoch: 2/2, step 4021/7134 completed (loss: 0.0431288480758667, acc: 0.9893048405647278)
[2024-12-17 02:56:38,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:38,867][root][INFO] - Training Epoch: 2/2, step 4022/7134 completed (loss: 0.05244791880249977, acc: 0.987730085849762)
[2024-12-17 02:56:38,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:39,236][root][INFO] - Training Epoch: 2/2, step 4023/7134 completed (loss: 0.05246082693338394, acc: 0.9861634969711304)
[2024-12-17 02:56:39,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:39,599][root][INFO] - Training Epoch: 2/2, step 4024/7134 completed (loss: 0.04505019262433052, acc: 0.9868766665458679)
[2024-12-17 02:56:39,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:39,957][root][INFO] - Training Epoch: 2/2, step 4025/7134 completed (loss: 0.07187353819608688, acc: 0.9841449856758118)
[2024-12-17 02:56:40,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:40,312][root][INFO] - Training Epoch: 2/2, step 4026/7134 completed (loss: 0.10626937448978424, acc: 0.983775794506073)
[2024-12-17 02:56:40,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:40,662][root][INFO] - Training Epoch: 2/2, step 4027/7134 completed (loss: 0.056255042552948, acc: 0.986810564994812)
[2024-12-17 02:56:40,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:40,996][root][INFO] - Training Epoch: 2/2, step 4028/7134 completed (loss: 0.05329285189509392, acc: 0.9845094680786133)
[2024-12-17 02:56:41,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:41,353][root][INFO] - Training Epoch: 2/2, step 4029/7134 completed (loss: 0.02748965658247471, acc: 0.9938499331474304)
[2024-12-17 02:56:41,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:41,696][root][INFO] - Training Epoch: 2/2, step 4030/7134 completed (loss: 0.029569027945399284, acc: 0.9917864203453064)
[2024-12-17 02:56:41,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:42,023][root][INFO] - Training Epoch: 2/2, step 4031/7134 completed (loss: 0.03373001143336296, acc: 0.9912023544311523)
[2024-12-17 02:56:42,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:42,376][root][INFO] - Training Epoch: 2/2, step 4032/7134 completed (loss: 0.0858101174235344, acc: 0.9799196720123291)
[2024-12-17 02:56:42,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:42,711][root][INFO] - Training Epoch: 2/2, step 4033/7134 completed (loss: 0.020693955942988396, acc: 0.9937106966972351)
[2024-12-17 02:56:42,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:43,056][root][INFO] - Training Epoch: 2/2, step 4034/7134 completed (loss: 0.020706385374069214, acc: 0.9963459372520447)
[2024-12-17 02:56:43,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:43,474][root][INFO] - Training Epoch: 2/2, step 4035/7134 completed (loss: 0.05602407455444336, acc: 0.9846516847610474)
[2024-12-17 02:56:43,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:43,794][root][INFO] - Training Epoch: 2/2, step 4036/7134 completed (loss: 0.040997955948114395, acc: 0.9816849827766418)
[2024-12-17 02:56:43,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:44,152][root][INFO] - Training Epoch: 2/2, step 4037/7134 completed (loss: 0.02604944445192814, acc: 0.9927797913551331)
[2024-12-17 02:56:44,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:44,483][root][INFO] - Training Epoch: 2/2, step 4038/7134 completed (loss: 0.0471888966858387, acc: 0.9834938049316406)
[2024-12-17 02:56:44,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:44,795][root][INFO] - Training Epoch: 2/2, step 4039/7134 completed (loss: 0.046175822615623474, acc: 0.9872340559959412)
[2024-12-17 02:56:44,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:45,128][root][INFO] - Training Epoch: 2/2, step 4040/7134 completed (loss: 0.02655603177845478, acc: 0.993842363357544)
[2024-12-17 02:56:45,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:45,482][root][INFO] - Training Epoch: 2/2, step 4041/7134 completed (loss: 0.052819181233644485, acc: 0.9879032373428345)
[2024-12-17 02:56:45,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:45,817][root][INFO] - Training Epoch: 2/2, step 4042/7134 completed (loss: 0.02283407188951969, acc: 0.9955882430076599)
[2024-12-17 02:56:45,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:46,120][root][INFO] - Training Epoch: 2/2, step 4043/7134 completed (loss: 0.03394817188382149, acc: 0.9897210001945496)
[2024-12-17 02:56:46,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:46,468][root][INFO] - Training Epoch: 2/2, step 4044/7134 completed (loss: 0.025901159271597862, acc: 0.993686854839325)
[2024-12-17 02:56:46,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:46,828][root][INFO] - Training Epoch: 2/2, step 4045/7134 completed (loss: 0.047823842614889145, acc: 0.9888888597488403)
[2024-12-17 02:56:46,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:47,171][root][INFO] - Training Epoch: 2/2, step 4046/7134 completed (loss: 0.03148432821035385, acc: 0.9903846383094788)
[2024-12-17 02:56:47,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:47,529][root][INFO] - Training Epoch: 2/2, step 4047/7134 completed (loss: 0.0630115419626236, acc: 0.9880668520927429)
[2024-12-17 02:56:47,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:47,889][root][INFO] - Training Epoch: 2/2, step 4048/7134 completed (loss: 0.024889487773180008, acc: 0.9918414950370789)
[2024-12-17 02:56:47,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:48,257][root][INFO] - Training Epoch: 2/2, step 4049/7134 completed (loss: 0.03689965605735779, acc: 0.9885057210922241)
[2024-12-17 02:56:48,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:48,585][root][INFO] - Training Epoch: 2/2, step 4050/7134 completed (loss: 0.06355386227369308, acc: 0.9858155846595764)
[2024-12-17 02:56:48,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:48,942][root][INFO] - Training Epoch: 2/2, step 4051/7134 completed (loss: 0.09885977953672409, acc: 0.980861246585846)
[2024-12-17 02:56:49,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:49,254][root][INFO] - Training Epoch: 2/2, step 4052/7134 completed (loss: 0.026039736345410347, acc: 0.9922480583190918)
[2024-12-17 02:56:49,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:49,606][root][INFO] - Training Epoch: 2/2, step 4053/7134 completed (loss: 0.04174333065748215, acc: 0.988063633441925)
[2024-12-17 02:56:49,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:49,961][root][INFO] - Training Epoch: 2/2, step 4054/7134 completed (loss: 0.058365244418382645, acc: 0.9860000014305115)
[2024-12-17 02:56:50,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:50,328][root][INFO] - Training Epoch: 2/2, step 4055/7134 completed (loss: 0.04514596238732338, acc: 0.9866504669189453)
[2024-12-17 02:56:50,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:50,689][root][INFO] - Training Epoch: 2/2, step 4056/7134 completed (loss: 0.03388972952961922, acc: 0.9890909194946289)
[2024-12-17 02:56:50,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:51,042][root][INFO] - Training Epoch: 2/2, step 4057/7134 completed (loss: 0.06414827704429626, acc: 0.9860917925834656)
[2024-12-17 02:56:51,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:51,320][root][INFO] - Training Epoch: 2/2, step 4058/7134 completed (loss: 0.08575138449668884, acc: 0.9751434326171875)
[2024-12-17 02:56:51,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:51,648][root][INFO] - Training Epoch: 2/2, step 4059/7134 completed (loss: 0.04755297303199768, acc: 0.9872262477874756)
[2024-12-17 02:56:51,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:51,968][root][INFO] - Training Epoch: 2/2, step 4060/7134 completed (loss: 0.04157271981239319, acc: 0.9876352548599243)
[2024-12-17 02:56:52,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:52,308][root][INFO] - Training Epoch: 2/2, step 4061/7134 completed (loss: 0.029884079471230507, acc: 0.9900285005569458)
[2024-12-17 02:56:52,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:52,630][root][INFO] - Training Epoch: 2/2, step 4062/7134 completed (loss: 0.01561091560870409, acc: 0.995275616645813)
[2024-12-17 02:56:52,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:52,922][root][INFO] - Training Epoch: 2/2, step 4063/7134 completed (loss: 0.024523703381419182, acc: 0.9911660552024841)
[2024-12-17 02:56:53,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:53,263][root][INFO] - Training Epoch: 2/2, step 4064/7134 completed (loss: 0.013443663716316223, acc: 0.9969742894172668)
[2024-12-17 02:56:53,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:53,606][root][INFO] - Training Epoch: 2/2, step 4065/7134 completed (loss: 0.03233920782804489, acc: 0.9917241334915161)
[2024-12-17 02:56:53,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:53,960][root][INFO] - Training Epoch: 2/2, step 4066/7134 completed (loss: 0.016597645357251167, acc: 0.9944444298744202)
[2024-12-17 02:56:54,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:54,285][root][INFO] - Training Epoch: 2/2, step 4067/7134 completed (loss: 0.045232877135276794, acc: 0.9901960492134094)
[2024-12-17 02:56:54,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:54,610][root][INFO] - Training Epoch: 2/2, step 4068/7134 completed (loss: 0.03665374591946602, acc: 0.9907407164573669)
[2024-12-17 02:56:54,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:54,935][root][INFO] - Training Epoch: 2/2, step 4069/7134 completed (loss: 0.03937859460711479, acc: 0.9937402009963989)
[2024-12-17 02:56:55,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:55,266][root][INFO] - Training Epoch: 2/2, step 4070/7134 completed (loss: 0.03399960696697235, acc: 0.9893454909324646)
[2024-12-17 02:56:55,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:55,582][root][INFO] - Training Epoch: 2/2, step 4071/7134 completed (loss: 0.041131392121315, acc: 0.9884678721427917)
[2024-12-17 02:56:55,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:55,919][root][INFO] - Training Epoch: 2/2, step 4072/7134 completed (loss: 0.0165397971868515, acc: 0.9971140027046204)
[2024-12-17 02:56:56,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:56,268][root][INFO] - Training Epoch: 2/2, step 4073/7134 completed (loss: 0.03701227903366089, acc: 0.9885057210922241)
[2024-12-17 02:56:56,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:56,611][root][INFO] - Training Epoch: 2/2, step 4074/7134 completed (loss: 0.02915278449654579, acc: 0.991416335105896)
[2024-12-17 02:56:56,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:56,978][root][INFO] - Training Epoch: 2/2, step 4075/7134 completed (loss: 0.02166518196463585, acc: 0.9925037622451782)
[2024-12-17 02:56:57,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:57,333][root][INFO] - Training Epoch: 2/2, step 4076/7134 completed (loss: 0.02014986053109169, acc: 0.9927641153335571)
[2024-12-17 02:56:57,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:57,649][root][INFO] - Training Epoch: 2/2, step 4077/7134 completed (loss: 0.0426328182220459, acc: 0.9847715497016907)
[2024-12-17 02:56:57,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:57,979][root][INFO] - Training Epoch: 2/2, step 4078/7134 completed (loss: 0.018206821754574776, acc: 0.995726466178894)
[2024-12-17 02:56:58,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:58,259][root][INFO] - Training Epoch: 2/2, step 4079/7134 completed (loss: 0.035851407796144485, acc: 0.9928698539733887)
[2024-12-17 02:56:58,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:58,569][root][INFO] - Training Epoch: 2/2, step 4080/7134 completed (loss: 0.012926057912409306, acc: 0.996835470199585)
[2024-12-17 02:56:58,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:58,881][root][INFO] - Training Epoch: 2/2, step 4081/7134 completed (loss: 0.010408885776996613, acc: 0.9983498454093933)
[2024-12-17 02:56:59,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:59,199][root][INFO] - Training Epoch: 2/2, step 4082/7134 completed (loss: 0.0696079432964325, acc: 0.9778188467025757)
[2024-12-17 02:56:59,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:59,528][root][INFO] - Training Epoch: 2/2, step 4083/7134 completed (loss: 0.0640944391489029, acc: 0.9790419340133667)
[2024-12-17 02:56:59,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:59,851][root][INFO] - Training Epoch: 2/2, step 4084/7134 completed (loss: 0.12341593950986862, acc: 0.9686274528503418)
[2024-12-17 02:56:59,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:00,183][root][INFO] - Training Epoch: 2/2, step 4085/7134 completed (loss: 0.05195947363972664, acc: 0.9851751923561096)
[2024-12-17 02:57:00,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:00,509][root][INFO] - Training Epoch: 2/2, step 4086/7134 completed (loss: 0.08225801587104797, acc: 0.978723406791687)
[2024-12-17 02:57:00,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:00,861][root][INFO] - Training Epoch: 2/2, step 4087/7134 completed (loss: 0.028698187321424484, acc: 0.9935400485992432)
[2024-12-17 02:57:00,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:01,213][root][INFO] - Training Epoch: 2/2, step 4088/7134 completed (loss: 0.11485506594181061, acc: 0.9713930487632751)
[2024-12-17 02:57:01,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:01,535][root][INFO] - Training Epoch: 2/2, step 4089/7134 completed (loss: 0.07015308737754822, acc: 0.9822379946708679)
[2024-12-17 02:57:01,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:01,875][root][INFO] - Training Epoch: 2/2, step 4090/7134 completed (loss: 0.11653648316860199, acc: 0.9775725603103638)
[2024-12-17 02:57:01,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:02,202][root][INFO] - Training Epoch: 2/2, step 4091/7134 completed (loss: 0.1776139736175537, acc: 0.9629005193710327)
[2024-12-17 02:57:02,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:02,560][root][INFO] - Training Epoch: 2/2, step 4092/7134 completed (loss: 0.06821584701538086, acc: 0.9819819927215576)
[2024-12-17 02:57:02,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:02,862][root][INFO] - Training Epoch: 2/2, step 4093/7134 completed (loss: 0.03324589878320694, acc: 0.9872495532035828)
[2024-12-17 02:57:02,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:03,191][root][INFO] - Training Epoch: 2/2, step 4094/7134 completed (loss: 0.06314301490783691, acc: 0.9789789915084839)
[2024-12-17 02:57:03,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:03,552][root][INFO] - Training Epoch: 2/2, step 4095/7134 completed (loss: 0.03324692323803902, acc: 0.9898697733879089)
[2024-12-17 02:57:03,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:03,838][root][INFO] - Training Epoch: 2/2, step 4096/7134 completed (loss: 0.075376495718956, acc: 0.9850746393203735)
[2024-12-17 02:57:03,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:04,209][root][INFO] - Training Epoch: 2/2, step 4097/7134 completed (loss: 0.07355102151632309, acc: 0.9854838848114014)
[2024-12-17 02:57:04,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:04,544][root][INFO] - Training Epoch: 2/2, step 4098/7134 completed (loss: 0.048854004591703415, acc: 0.989159882068634)
[2024-12-17 02:57:04,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:04,872][root][INFO] - Training Epoch: 2/2, step 4099/7134 completed (loss: 0.0711166113615036, acc: 0.9806337952613831)
[2024-12-17 02:57:04,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:05,237][root][INFO] - Training Epoch: 2/2, step 4100/7134 completed (loss: 0.007178420666605234, acc: 1.0)
[2024-12-17 02:57:05,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:05,553][root][INFO] - Training Epoch: 2/2, step 4101/7134 completed (loss: 0.017239807173609734, acc: 0.9942965507507324)
[2024-12-17 02:57:05,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:05,881][root][INFO] - Training Epoch: 2/2, step 4102/7134 completed (loss: 0.04083828255534172, acc: 0.9853747487068176)
[2024-12-17 02:57:05,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:06,213][root][INFO] - Training Epoch: 2/2, step 4103/7134 completed (loss: 0.010664583183825016, acc: 0.9970104694366455)
[2024-12-17 02:57:06,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:06,540][root][INFO] - Training Epoch: 2/2, step 4104/7134 completed (loss: 0.01161999348551035, acc: 1.0)
[2024-12-17 02:57:06,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:06,874][root][INFO] - Training Epoch: 2/2, step 4105/7134 completed (loss: 0.03135545179247856, acc: 0.9909365773200989)
[2024-12-17 02:57:06,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:07,200][root][INFO] - Training Epoch: 2/2, step 4106/7134 completed (loss: 0.03345629572868347, acc: 0.9892638325691223)
[2024-12-17 02:57:07,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:07,522][root][INFO] - Training Epoch: 2/2, step 4107/7134 completed (loss: 0.04216397926211357, acc: 0.9932773113250732)
[2024-12-17 02:57:07,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:07,838][root][INFO] - Training Epoch: 2/2, step 4108/7134 completed (loss: 0.02402680180966854, acc: 0.9935275316238403)
[2024-12-17 02:57:07,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:08,171][root][INFO] - Training Epoch: 2/2, step 4109/7134 completed (loss: 0.029967324808239937, acc: 0.9903692007064819)
[2024-12-17 02:57:08,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:08,491][root][INFO] - Training Epoch: 2/2, step 4110/7134 completed (loss: 0.013262392953038216, acc: 0.9982993006706238)
[2024-12-17 02:57:08,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:08,838][root][INFO] - Training Epoch: 2/2, step 4111/7134 completed (loss: 0.020831460133194923, acc: 0.9936908483505249)
[2024-12-17 02:57:08,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:09,180][root][INFO] - Training Epoch: 2/2, step 4112/7134 completed (loss: 0.044902604073286057, acc: 0.9892473220825195)
[2024-12-17 02:57:09,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:09,520][root][INFO] - Training Epoch: 2/2, step 4113/7134 completed (loss: 0.03380906581878662, acc: 0.9891473054885864)
[2024-12-17 02:57:09,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:09,862][root][INFO] - Training Epoch: 2/2, step 4114/7134 completed (loss: 0.08496856689453125, acc: 0.9735772609710693)
[2024-12-17 02:57:09,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:10,186][root][INFO] - Training Epoch: 2/2, step 4115/7134 completed (loss: 0.04811302199959755, acc: 0.9850746393203735)
[2024-12-17 02:57:10,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:10,533][root][INFO] - Training Epoch: 2/2, step 4116/7134 completed (loss: 0.02539335936307907, acc: 0.9983713626861572)
[2024-12-17 02:57:10,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:10,859][root][INFO] - Training Epoch: 2/2, step 4117/7134 completed (loss: 0.04094894230365753, acc: 0.9858044385910034)
[2024-12-17 02:57:10,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:11,132][root][INFO] - Training Epoch: 2/2, step 4118/7134 completed (loss: 0.02010548859834671, acc: 0.9950860142707825)
[2024-12-17 02:57:11,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:11,454][root][INFO] - Training Epoch: 2/2, step 4119/7134 completed (loss: 0.0541253536939621, acc: 0.987075924873352)
[2024-12-17 02:57:11,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:11,763][root][INFO] - Training Epoch: 2/2, step 4120/7134 completed (loss: 0.04632391035556793, acc: 0.9917627573013306)
[2024-12-17 02:57:11,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:12,097][root][INFO] - Training Epoch: 2/2, step 4121/7134 completed (loss: 0.05438147857785225, acc: 0.9914772510528564)
[2024-12-17 02:57:12,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:12,422][root][INFO] - Training Epoch: 2/2, step 4122/7134 completed (loss: 0.023727577179670334, acc: 0.9923664331436157)
[2024-12-17 02:57:12,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:12,749][root][INFO] - Training Epoch: 2/2, step 4123/7134 completed (loss: 0.043569739907979965, acc: 0.9864253401756287)
[2024-12-17 02:57:12,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:13,092][root][INFO] - Training Epoch: 2/2, step 4124/7134 completed (loss: 0.03367965295910835, acc: 0.9886845946311951)
[2024-12-17 02:57:13,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:13,417][root][INFO] - Training Epoch: 2/2, step 4125/7134 completed (loss: 0.021726008504629135, acc: 0.9941176176071167)
[2024-12-17 02:57:13,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:13,748][root][INFO] - Training Epoch: 2/2, step 4126/7134 completed (loss: 0.031942568719387054, acc: 0.9915013909339905)
[2024-12-17 02:57:13,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:14,065][root][INFO] - Training Epoch: 2/2, step 4127/7134 completed (loss: 0.029826292768120766, acc: 0.9921875)
[2024-12-17 02:57:14,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:14,383][root][INFO] - Training Epoch: 2/2, step 4128/7134 completed (loss: 0.024491721764206886, acc: 0.9953051805496216)
[2024-12-17 02:57:14,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:14,742][root][INFO] - Training Epoch: 2/2, step 4129/7134 completed (loss: 0.02301139198243618, acc: 0.9955489635467529)
[2024-12-17 02:57:14,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:15,053][root][INFO] - Training Epoch: 2/2, step 4130/7134 completed (loss: 0.030978238210082054, acc: 0.9922928810119629)
[2024-12-17 02:57:15,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:15,374][root][INFO] - Training Epoch: 2/2, step 4131/7134 completed (loss: 0.018297012895345688, acc: 0.9944547414779663)
[2024-12-17 02:57:15,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:15,692][root][INFO] - Training Epoch: 2/2, step 4132/7134 completed (loss: 0.023975130170583725, acc: 0.9910714030265808)
[2024-12-17 02:57:15,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:15,986][root][INFO] - Training Epoch: 2/2, step 4133/7134 completed (loss: 0.05139506235718727, acc: 0.9870370626449585)
[2024-12-17 02:57:16,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:16,279][root][INFO] - Training Epoch: 2/2, step 4134/7134 completed (loss: 0.05797451362013817, acc: 0.978672981262207)
[2024-12-17 02:57:16,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:16,613][root][INFO] - Training Epoch: 2/2, step 4135/7134 completed (loss: 0.026539243757724762, acc: 0.9911190271377563)
[2024-12-17 02:57:16,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:16,961][root][INFO] - Training Epoch: 2/2, step 4136/7134 completed (loss: 0.026134179905056953, acc: 0.9946902394294739)
[2024-12-17 02:57:17,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:17,294][root][INFO] - Training Epoch: 2/2, step 4137/7134 completed (loss: 0.03378474712371826, acc: 0.98828125)
[2024-12-17 02:57:17,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:17,626][root][INFO] - Training Epoch: 2/2, step 4138/7134 completed (loss: 0.05534369871020317, acc: 0.9858934283256531)
[2024-12-17 02:57:17,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:17,949][root][INFO] - Training Epoch: 2/2, step 4139/7134 completed (loss: 0.028254710137844086, acc: 0.9935622215270996)
[2024-12-17 02:57:18,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:18,277][root][INFO] - Training Epoch: 2/2, step 4140/7134 completed (loss: 0.04463993012905121, acc: 0.9834482669830322)
[2024-12-17 02:57:18,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:18,649][root][INFO] - Training Epoch: 2/2, step 4141/7134 completed (loss: 0.14634239673614502, acc: 0.9713466763496399)
[2024-12-17 02:57:18,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:19,004][root][INFO] - Training Epoch: 2/2, step 4142/7134 completed (loss: 0.0985683873295784, acc: 0.9748283624649048)
[2024-12-17 02:57:19,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:19,398][root][INFO] - Training Epoch: 2/2, step 4143/7134 completed (loss: 0.05254404991865158, acc: 0.9887754917144775)
[2024-12-17 02:57:19,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:19,778][root][INFO] - Training Epoch: 2/2, step 4144/7134 completed (loss: 0.11276645958423615, acc: 0.9760820269584656)
[2024-12-17 02:57:19,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:20,125][root][INFO] - Training Epoch: 2/2, step 4145/7134 completed (loss: 0.061978839337825775, acc: 0.9783393740653992)
[2024-12-17 02:57:20,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:20,406][root][INFO] - Training Epoch: 2/2, step 4146/7134 completed (loss: 0.10088570415973663, acc: 0.9757575988769531)
[2024-12-17 02:57:20,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:20,740][root][INFO] - Training Epoch: 2/2, step 4147/7134 completed (loss: 0.13180150091648102, acc: 0.967432975769043)
[2024-12-17 02:57:20,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:21,062][root][INFO] - Training Epoch: 2/2, step 4148/7134 completed (loss: 0.2104705274105072, acc: 0.9459459185600281)
[2024-12-17 02:57:21,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:21,373][root][INFO] - Training Epoch: 2/2, step 4149/7134 completed (loss: 0.14179545640945435, acc: 0.9679999947547913)
[2024-12-17 02:57:21,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:21,704][root][INFO] - Training Epoch: 2/2, step 4150/7134 completed (loss: 0.1535567343235016, acc: 0.9617705941200256)
[2024-12-17 02:57:21,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:22,079][root][INFO] - Training Epoch: 2/2, step 4151/7134 completed (loss: 0.22174526751041412, acc: 0.9637681245803833)
[2024-12-17 02:57:22,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:22,430][root][INFO] - Training Epoch: 2/2, step 4152/7134 completed (loss: 0.06990902125835419, acc: 0.9768160581588745)
[2024-12-17 02:57:22,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:22,782][root][INFO] - Training Epoch: 2/2, step 4153/7134 completed (loss: 0.11889960616827011, acc: 0.9693251252174377)
[2024-12-17 02:57:22,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:23,152][root][INFO] - Training Epoch: 2/2, step 4154/7134 completed (loss: 0.10442259907722473, acc: 0.9699074029922485)
[2024-12-17 02:57:23,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:23,508][root][INFO] - Training Epoch: 2/2, step 4155/7134 completed (loss: 0.1013236790895462, acc: 0.9708404541015625)
[2024-12-17 02:57:23,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:23,884][root][INFO] - Training Epoch: 2/2, step 4156/7134 completed (loss: 0.10132918506860733, acc: 0.9694019556045532)
[2024-12-17 02:57:23,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:24,205][root][INFO] - Training Epoch: 2/2, step 4157/7134 completed (loss: 0.05782473087310791, acc: 0.9840319156646729)
[2024-12-17 02:57:24,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:24,486][root][INFO] - Training Epoch: 2/2, step 4158/7134 completed (loss: 0.19130103290081024, acc: 0.9562981724739075)
[2024-12-17 02:57:24,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:24,845][root][INFO] - Training Epoch: 2/2, step 4159/7134 completed (loss: 0.0705031082034111, acc: 0.9813242554664612)
[2024-12-17 02:57:24,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:25,221][root][INFO] - Training Epoch: 2/2, step 4160/7134 completed (loss: 0.11480765789747238, acc: 0.9641509652137756)
[2024-12-17 02:57:25,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:25,584][root][INFO] - Training Epoch: 2/2, step 4161/7134 completed (loss: 0.10290179401636124, acc: 0.9738956093788147)
[2024-12-17 02:57:25,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:25,930][root][INFO] - Training Epoch: 2/2, step 4162/7134 completed (loss: 0.07839074730873108, acc: 0.9806259274482727)
[2024-12-17 02:57:26,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:26,277][root][INFO] - Training Epoch: 2/2, step 4163/7134 completed (loss: 0.07853682339191437, acc: 0.9803328514099121)
[2024-12-17 02:57:26,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:26,632][root][INFO] - Training Epoch: 2/2, step 4164/7134 completed (loss: 0.07973067462444305, acc: 0.9825834631919861)
[2024-12-17 02:57:26,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:27,013][root][INFO] - Training Epoch: 2/2, step 4165/7134 completed (loss: 0.06430123001337051, acc: 0.9862671494483948)
[2024-12-17 02:57:27,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:27,379][root][INFO] - Training Epoch: 2/2, step 4166/7134 completed (loss: 0.07584498822689056, acc: 0.9838472604751587)
[2024-12-17 02:57:27,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:27,694][root][INFO] - Training Epoch: 2/2, step 4167/7134 completed (loss: 0.05107801407575607, acc: 0.984375)
[2024-12-17 02:57:27,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:28,049][root][INFO] - Training Epoch: 2/2, step 4168/7134 completed (loss: 0.06431407481431961, acc: 0.9809027910232544)
[2024-12-17 02:57:28,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:28,424][root][INFO] - Training Epoch: 2/2, step 4169/7134 completed (loss: 0.09086453914642334, acc: 0.9778246879577637)
[2024-12-17 02:57:28,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:28,813][root][INFO] - Training Epoch: 2/2, step 4170/7134 completed (loss: 0.1339123398065567, acc: 0.9681528806686401)
[2024-12-17 02:57:28,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:29,201][root][INFO] - Training Epoch: 2/2, step 4171/7134 completed (loss: 0.04824087768793106, acc: 0.9861591458320618)
[2024-12-17 02:57:29,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:29,542][root][INFO] - Training Epoch: 2/2, step 4172/7134 completed (loss: 0.08171837776899338, acc: 0.9850373864173889)
[2024-12-17 02:57:29,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:29,863][root][INFO] - Training Epoch: 2/2, step 4173/7134 completed (loss: 0.08748366683721542, acc: 0.9871244430541992)
[2024-12-17 02:57:29,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:30,179][root][INFO] - Training Epoch: 2/2, step 4174/7134 completed (loss: 0.01737053319811821, acc: 0.992337167263031)
[2024-12-17 02:57:30,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:30,506][root][INFO] - Training Epoch: 2/2, step 4175/7134 completed (loss: 0.0569302998483181, acc: 0.9879724979400635)
[2024-12-17 02:57:30,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:30,855][root][INFO] - Training Epoch: 2/2, step 4176/7134 completed (loss: 0.02591961808502674, acc: 0.995529055595398)
[2024-12-17 02:57:30,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:31,233][root][INFO] - Training Epoch: 2/2, step 4177/7134 completed (loss: 0.022870685905218124, acc: 0.9947437644004822)
[2024-12-17 02:57:31,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:31,587][root][INFO] - Training Epoch: 2/2, step 4178/7134 completed (loss: 0.03780078887939453, acc: 0.9894259572029114)
[2024-12-17 02:57:31,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:31,967][root][INFO] - Training Epoch: 2/2, step 4179/7134 completed (loss: 0.026059651747345924, acc: 0.990813672542572)
[2024-12-17 02:57:32,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:32,325][root][INFO] - Training Epoch: 2/2, step 4180/7134 completed (loss: 0.03174016997218132, acc: 0.9929378628730774)
[2024-12-17 02:57:32,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:32,677][root][INFO] - Training Epoch: 2/2, step 4181/7134 completed (loss: 0.017643779516220093, acc: 0.9934747219085693)
[2024-12-17 02:57:32,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:33,039][root][INFO] - Training Epoch: 2/2, step 4182/7134 completed (loss: 0.01371814776211977, acc: 0.9958275556564331)
[2024-12-17 02:57:33,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:33,488][root][INFO] - Training Epoch: 2/2, step 4183/7134 completed (loss: 0.024898936972022057, acc: 0.9944367408752441)
[2024-12-17 02:57:33,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:33,824][root][INFO] - Training Epoch: 2/2, step 4184/7134 completed (loss: 0.04441797733306885, acc: 0.988063633441925)
[2024-12-17 02:57:33,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:34,179][root][INFO] - Training Epoch: 2/2, step 4185/7134 completed (loss: 0.03376159071922302, acc: 0.9931507110595703)
[2024-12-17 02:57:34,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:34,558][root][INFO] - Training Epoch: 2/2, step 4186/7134 completed (loss: 0.07480652630329132, acc: 0.9843562245368958)
[2024-12-17 02:57:34,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:34,885][root][INFO] - Training Epoch: 2/2, step 4187/7134 completed (loss: 0.015503592789173126, acc: 0.998046875)
[2024-12-17 02:57:35,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:35,242][root][INFO] - Training Epoch: 2/2, step 4188/7134 completed (loss: 0.02220039814710617, acc: 0.9950000047683716)
[2024-12-17 02:57:35,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:35,597][root][INFO] - Training Epoch: 2/2, step 4189/7134 completed (loss: 0.03127209469676018, acc: 0.9930070042610168)
[2024-12-17 02:57:35,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:35,974][root][INFO] - Training Epoch: 2/2, step 4190/7134 completed (loss: 0.03487178683280945, acc: 0.9943181872367859)
[2024-12-17 02:57:36,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:36,255][root][INFO] - Training Epoch: 2/2, step 4191/7134 completed (loss: 0.04471198469400406, acc: 0.9930875301361084)
[2024-12-17 02:57:36,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:36,614][root][INFO] - Training Epoch: 2/2, step 4192/7134 completed (loss: 0.030532851815223694, acc: 0.9856230020523071)
[2024-12-17 02:57:36,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:36,973][root][INFO] - Training Epoch: 2/2, step 4193/7134 completed (loss: 0.034019336104393005, acc: 0.9933155179023743)
[2024-12-17 02:57:37,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:37,331][root][INFO] - Training Epoch: 2/2, step 4194/7134 completed (loss: 0.011356326751410961, acc: 0.9969742894172668)
[2024-12-17 02:57:37,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:37,663][root][INFO] - Training Epoch: 2/2, step 4195/7134 completed (loss: 0.046611666679382324, acc: 0.9932249188423157)
[2024-12-17 02:57:37,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:37,990][root][INFO] - Training Epoch: 2/2, step 4196/7134 completed (loss: 0.022322911769151688, acc: 0.9930796027183533)
[2024-12-17 02:57:38,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:38,358][root][INFO] - Training Epoch: 2/2, step 4197/7134 completed (loss: 0.050878141075372696, acc: 0.9909443855285645)
[2024-12-17 02:57:38,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:38,735][root][INFO] - Training Epoch: 2/2, step 4198/7134 completed (loss: 0.04237186908721924, acc: 0.9902777671813965)
[2024-12-17 02:57:38,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:39,079][root][INFO] - Training Epoch: 2/2, step 4199/7134 completed (loss: 0.05253126472234726, acc: 0.985401451587677)
[2024-12-17 02:57:39,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:39,419][root][INFO] - Training Epoch: 2/2, step 4200/7134 completed (loss: 0.04734383895993233, acc: 0.9874551892280579)
[2024-12-17 02:57:39,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:39,786][root][INFO] - Training Epoch: 2/2, step 4201/7134 completed (loss: 0.018252074718475342, acc: 0.9982876777648926)
[2024-12-17 02:57:39,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:40,138][root][INFO] - Training Epoch: 2/2, step 4202/7134 completed (loss: 0.07065265625715256, acc: 0.9844961166381836)
[2024-12-17 02:57:40,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:40,505][root][INFO] - Training Epoch: 2/2, step 4203/7134 completed (loss: 0.04695602133870125, acc: 0.9921996593475342)
[2024-12-17 02:57:40,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:40,837][root][INFO] - Training Epoch: 2/2, step 4204/7134 completed (loss: 0.08842454850673676, acc: 0.9780701994895935)
[2024-12-17 02:57:40,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:41,157][root][INFO] - Training Epoch: 2/2, step 4205/7134 completed (loss: 0.05932269245386124, acc: 0.9841726422309875)
[2024-12-17 02:57:41,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:41,522][root][INFO] - Training Epoch: 2/2, step 4206/7134 completed (loss: 0.10638413578271866, acc: 0.9816642999649048)
[2024-12-17 02:57:41,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:41,861][root][INFO] - Training Epoch: 2/2, step 4207/7134 completed (loss: 0.12831352651119232, acc: 0.9808917045593262)
[2024-12-17 02:57:41,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:42,191][root][INFO] - Training Epoch: 2/2, step 4208/7134 completed (loss: 0.0841669961810112, acc: 0.9856459498405457)
[2024-12-17 02:57:42,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:42,536][root][INFO] - Training Epoch: 2/2, step 4209/7134 completed (loss: 0.1029772236943245, acc: 0.977337121963501)
[2024-12-17 02:57:42,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:42,890][root][INFO] - Training Epoch: 2/2, step 4210/7134 completed (loss: 0.013612193055450916, acc: 1.0)
[2024-12-17 02:57:42,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:43,131][root][INFO] - Training Epoch: 2/2, step 4211/7134 completed (loss: 0.03543834388256073, acc: 0.9953917264938354)
[2024-12-17 02:57:43,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:43,492][root][INFO] - Training Epoch: 2/2, step 4212/7134 completed (loss: 0.0484645701944828, acc: 0.9885433912277222)
[2024-12-17 02:57:43,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:43,900][root][INFO] - Training Epoch: 2/2, step 4213/7134 completed (loss: 0.03913391754031181, acc: 0.9899857044219971)
[2024-12-17 02:57:44,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:44,264][root][INFO] - Training Epoch: 2/2, step 4214/7134 completed (loss: 0.0635794922709465, acc: 0.9850746393203735)
[2024-12-17 02:57:44,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:44,582][root][INFO] - Training Epoch: 2/2, step 4215/7134 completed (loss: 0.06804381310939789, acc: 0.9868131875991821)
[2024-12-17 02:57:44,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:44,906][root][INFO] - Training Epoch: 2/2, step 4216/7134 completed (loss: 0.0551132895052433, acc: 0.9908592104911804)
[2024-12-17 02:57:45,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:45,214][root][INFO] - Training Epoch: 2/2, step 4217/7134 completed (loss: 0.03614966571331024, acc: 0.988811194896698)
[2024-12-17 02:57:45,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:45,498][root][INFO] - Training Epoch: 2/2, step 4218/7134 completed (loss: 0.08035673201084137, acc: 0.9814432859420776)
[2024-12-17 02:57:45,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:45,737][root][INFO] - Training Epoch: 2/2, step 4219/7134 completed (loss: 0.06158662214875221, acc: 0.9839357137680054)
[2024-12-17 02:57:45,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:46,091][root][INFO] - Training Epoch: 2/2, step 4220/7134 completed (loss: 0.07091174274682999, acc: 0.9856114983558655)
[2024-12-17 02:57:46,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:46,449][root][INFO] - Training Epoch: 2/2, step 4221/7134 completed (loss: 0.026411639526486397, acc: 0.9929203391075134)
[2024-12-17 02:57:46,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:46,799][root][INFO] - Training Epoch: 2/2, step 4222/7134 completed (loss: 0.15008088946342468, acc: 0.9822221994400024)
[2024-12-17 02:57:46,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:47,166][root][INFO] - Training Epoch: 2/2, step 4223/7134 completed (loss: 0.07396873086690903, acc: 0.9748344421386719)
[2024-12-17 02:57:47,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:47,487][root][INFO] - Training Epoch: 2/2, step 4224/7134 completed (loss: 0.07484030723571777, acc: 0.9784017205238342)
[2024-12-17 02:57:47,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:47,831][root][INFO] - Training Epoch: 2/2, step 4225/7134 completed (loss: 0.10718178749084473, acc: 0.9779286980628967)
[2024-12-17 02:57:47,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:48,185][root][INFO] - Training Epoch: 2/2, step 4226/7134 completed (loss: 0.07249292731285095, acc: 0.9859514832496643)
[2024-12-17 02:57:48,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:48,486][root][INFO] - Training Epoch: 2/2, step 4227/7134 completed (loss: 0.12318359315395355, acc: 0.9656019806861877)
[2024-12-17 02:57:48,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:48,825][root][INFO] - Training Epoch: 2/2, step 4228/7134 completed (loss: 0.17386046051979065, acc: 0.9620689749717712)
[2024-12-17 02:57:48,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:49,147][root][INFO] - Training Epoch: 2/2, step 4229/7134 completed (loss: 0.1216123029589653, acc: 0.9769392013549805)
[2024-12-17 02:57:49,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:49,451][root][INFO] - Training Epoch: 2/2, step 4230/7134 completed (loss: 0.08862859010696411, acc: 0.9764705896377563)
[2024-12-17 02:57:49,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:49,794][root][INFO] - Training Epoch: 2/2, step 4231/7134 completed (loss: 0.15205542743206024, acc: 0.970534086227417)
[2024-12-17 02:57:49,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:50,128][root][INFO] - Training Epoch: 2/2, step 4232/7134 completed (loss: 0.1566646695137024, acc: 0.9648854732513428)
[2024-12-17 02:57:50,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:50,466][root][INFO] - Training Epoch: 2/2, step 4233/7134 completed (loss: 0.08775072544813156, acc: 0.9833055138587952)
[2024-12-17 02:57:50,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:50,805][root][INFO] - Training Epoch: 2/2, step 4234/7134 completed (loss: 0.0881623923778534, acc: 0.9856915473937988)
[2024-12-17 02:57:50,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:51,185][root][INFO] - Training Epoch: 2/2, step 4235/7134 completed (loss: 0.054674532264471054, acc: 0.9857819676399231)
[2024-12-17 02:57:51,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:51,514][root][INFO] - Training Epoch: 2/2, step 4236/7134 completed (loss: 0.0119882607832551, acc: 1.0)
[2024-12-17 02:57:51,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:51,841][root][INFO] - Training Epoch: 2/2, step 4237/7134 completed (loss: 0.06342999637126923, acc: 0.9793814420700073)
[2024-12-17 02:57:52,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:52,203][root][INFO] - Training Epoch: 2/2, step 4238/7134 completed (loss: 0.07954404503107071, acc: 0.9852700233459473)
[2024-12-17 02:57:52,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:52,520][root][INFO] - Training Epoch: 2/2, step 4239/7134 completed (loss: 0.04345826432108879, acc: 0.9872000217437744)
[2024-12-17 02:57:52,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:52,845][root][INFO] - Training Epoch: 2/2, step 4240/7134 completed (loss: 0.0725504606962204, acc: 0.9854604005813599)
[2024-12-17 02:57:52,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:53,187][root][INFO] - Training Epoch: 2/2, step 4241/7134 completed (loss: 0.020798370242118835, acc: 0.9934924244880676)
[2024-12-17 02:57:53,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:53,482][root][INFO] - Training Epoch: 2/2, step 4242/7134 completed (loss: 0.056509047746658325, acc: 0.9799554347991943)
[2024-12-17 02:57:53,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:53,829][root][INFO] - Training Epoch: 2/2, step 4243/7134 completed (loss: 0.09676387161016464, acc: 0.9837251305580139)
[2024-12-17 02:57:53,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:54,110][root][INFO] - Training Epoch: 2/2, step 4244/7134 completed (loss: 0.05106781795620918, acc: 0.9889135360717773)
[2024-12-17 02:57:54,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:54,419][root][INFO] - Training Epoch: 2/2, step 4245/7134 completed (loss: 0.05303062126040459, acc: 0.9902200698852539)
[2024-12-17 02:57:54,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:54,761][root][INFO] - Training Epoch: 2/2, step 4246/7134 completed (loss: 0.037305641919374466, acc: 0.9936608672142029)
[2024-12-17 02:57:54,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:55,082][root][INFO] - Training Epoch: 2/2, step 4247/7134 completed (loss: 0.045932117849588394, acc: 0.9910873174667358)
[2024-12-17 02:57:55,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:55,416][root][INFO] - Training Epoch: 2/2, step 4248/7134 completed (loss: 0.0855896919965744, acc: 0.9759615659713745)
[2024-12-17 02:57:55,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:55,804][root][INFO] - Training Epoch: 2/2, step 4249/7134 completed (loss: 0.0801485925912857, acc: 0.9825396537780762)
[2024-12-17 02:57:55,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:56,094][root][INFO] - Training Epoch: 2/2, step 4250/7134 completed (loss: 0.07566038519144058, acc: 0.9851379990577698)
[2024-12-17 02:57:56,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:56,420][root][INFO] - Training Epoch: 2/2, step 4251/7134 completed (loss: 0.03155544400215149, acc: 0.9934210777282715)
[2024-12-17 02:57:56,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:56,749][root][INFO] - Training Epoch: 2/2, step 4252/7134 completed (loss: 0.05569947510957718, acc: 0.9888712167739868)
[2024-12-17 02:57:56,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:57,080][root][INFO] - Training Epoch: 2/2, step 4253/7134 completed (loss: 0.054884158074855804, acc: 0.989154040813446)
[2024-12-17 02:57:57,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:57,397][root][INFO] - Training Epoch: 2/2, step 4254/7134 completed (loss: 0.02909991145133972, acc: 0.9900249242782593)
[2024-12-17 02:57:57,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:57,750][root][INFO] - Training Epoch: 2/2, step 4255/7134 completed (loss: 0.045473363250494, acc: 0.9897260069847107)
[2024-12-17 02:57:57,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:58,070][root][INFO] - Training Epoch: 2/2, step 4256/7134 completed (loss: 0.04105086624622345, acc: 0.9909502267837524)
[2024-12-17 02:57:58,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:58,403][root][INFO] - Training Epoch: 2/2, step 4257/7134 completed (loss: 0.038097746670246124, acc: 0.9910873174667358)
[2024-12-17 02:57:58,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:58,734][root][INFO] - Training Epoch: 2/2, step 4258/7134 completed (loss: 0.01586199551820755, acc: 0.9961832165718079)
[2024-12-17 02:57:58,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:59,092][root][INFO] - Training Epoch: 2/2, step 4259/7134 completed (loss: 0.11063731461763382, acc: 0.9770773649215698)
[2024-12-17 02:57:59,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:59,442][root][INFO] - Training Epoch: 2/2, step 4260/7134 completed (loss: 0.029615553095936775, acc: 0.9896480441093445)
[2024-12-17 02:57:59,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:59,784][root][INFO] - Training Epoch: 2/2, step 4261/7134 completed (loss: 0.04234638065099716, acc: 0.9866156578063965)
[2024-12-17 02:57:59,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:00,139][root][INFO] - Training Epoch: 2/2, step 4262/7134 completed (loss: 0.0535217709839344, acc: 0.9827855825424194)
[2024-12-17 02:58:00,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:00,473][root][INFO] - Training Epoch: 2/2, step 4263/7134 completed (loss: 0.10175292938947678, acc: 0.9797297120094299)
[2024-12-17 02:58:00,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:00,809][root][INFO] - Training Epoch: 2/2, step 4264/7134 completed (loss: 0.08043955266475677, acc: 0.9762202501296997)
[2024-12-17 02:58:00,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:01,155][root][INFO] - Training Epoch: 2/2, step 4265/7134 completed (loss: 0.048725906759500504, acc: 0.9861111044883728)
[2024-12-17 02:58:01,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:01,522][root][INFO] - Training Epoch: 2/2, step 4266/7134 completed (loss: 0.03720017522573471, acc: 0.9916167855262756)
[2024-12-17 02:58:01,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:01,893][root][INFO] - Training Epoch: 2/2, step 4267/7134 completed (loss: 0.04327014833688736, acc: 0.9903030395507812)
[2024-12-17 02:58:01,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:02,235][root][INFO] - Training Epoch: 2/2, step 4268/7134 completed (loss: 0.09905093908309937, acc: 0.9679358601570129)
[2024-12-17 02:58:02,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:02,598][root][INFO] - Training Epoch: 2/2, step 4269/7134 completed (loss: 0.152420312166214, acc: 0.971222996711731)
[2024-12-17 02:58:02,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:02,946][root][INFO] - Training Epoch: 2/2, step 4270/7134 completed (loss: 0.08774030208587646, acc: 0.9752604365348816)
[2024-12-17 02:58:03,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:03,300][root][INFO] - Training Epoch: 2/2, step 4271/7134 completed (loss: 0.034883905202150345, acc: 0.9900373816490173)
[2024-12-17 02:58:03,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:03,668][root][INFO] - Training Epoch: 2/2, step 4272/7134 completed (loss: 0.06601084768772125, acc: 0.9812206625938416)
[2024-12-17 02:58:03,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:04,024][root][INFO] - Training Epoch: 2/2, step 4273/7134 completed (loss: 0.05558672174811363, acc: 0.979924738407135)
[2024-12-17 02:58:04,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:04,402][root][INFO] - Training Epoch: 2/2, step 4274/7134 completed (loss: 0.10212884843349457, acc: 0.9754672646522522)
[2024-12-17 02:58:04,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:04,745][root][INFO] - Training Epoch: 2/2, step 4275/7134 completed (loss: 0.0392206646502018, acc: 0.9873737096786499)
[2024-12-17 02:58:04,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:05,101][root][INFO] - Training Epoch: 2/2, step 4276/7134 completed (loss: 0.07528124004602432, acc: 0.9845361113548279)
[2024-12-17 02:58:05,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:05,424][root][INFO] - Training Epoch: 2/2, step 4277/7134 completed (loss: 0.04060662165284157, acc: 0.9888888597488403)
[2024-12-17 02:58:05,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:05,777][root][INFO] - Training Epoch: 2/2, step 4278/7134 completed (loss: 0.06092635914683342, acc: 0.9790123701095581)
[2024-12-17 02:58:05,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:06,112][root][INFO] - Training Epoch: 2/2, step 4279/7134 completed (loss: 0.04417824000120163, acc: 0.9851190447807312)
[2024-12-17 02:58:06,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:06,465][root][INFO] - Training Epoch: 2/2, step 4280/7134 completed (loss: 0.0297725610435009, acc: 0.9936507940292358)
[2024-12-17 02:58:06,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:06,832][root][INFO] - Training Epoch: 2/2, step 4281/7134 completed (loss: 0.06335277110338211, acc: 0.9839109182357788)
[2024-12-17 02:58:06,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:07,180][root][INFO] - Training Epoch: 2/2, step 4282/7134 completed (loss: 0.015042894519865513, acc: 0.9981481432914734)
[2024-12-17 02:58:07,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:07,554][root][INFO] - Training Epoch: 2/2, step 4283/7134 completed (loss: 0.03520898520946503, acc: 0.9896789193153381)
[2024-12-17 02:58:07,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:07,868][root][INFO] - Training Epoch: 2/2, step 4284/7134 completed (loss: 0.04709416255354881, acc: 0.9927536249160767)
[2024-12-17 02:58:07,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:08,216][root][INFO] - Training Epoch: 2/2, step 4285/7134 completed (loss: 0.04744997248053551, acc: 0.9880136847496033)
[2024-12-17 02:58:08,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:08,530][root][INFO] - Training Epoch: 2/2, step 4286/7134 completed (loss: 0.04363223537802696, acc: 0.9838129281997681)
[2024-12-17 02:58:08,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:08,882][root][INFO] - Training Epoch: 2/2, step 4287/7134 completed (loss: 0.05446796491742134, acc: 0.9832473993301392)
[2024-12-17 02:58:08,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:09,241][root][INFO] - Training Epoch: 2/2, step 4288/7134 completed (loss: 0.05540696904063225, acc: 0.9815602898597717)
[2024-12-17 02:58:09,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:09,612][root][INFO] - Training Epoch: 2/2, step 4289/7134 completed (loss: 0.08761695772409439, acc: 0.9729323387145996)
[2024-12-17 02:58:09,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:09,967][root][INFO] - Training Epoch: 2/2, step 4290/7134 completed (loss: 0.039615072309970856, acc: 0.9864681959152222)
[2024-12-17 02:58:10,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:10,322][root][INFO] - Training Epoch: 2/2, step 4291/7134 completed (loss: 0.03062433749437332, acc: 0.9904648661613464)
[2024-12-17 02:58:10,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:10,657][root][INFO] - Training Epoch: 2/2, step 4292/7134 completed (loss: 0.027384772896766663, acc: 0.9939758777618408)
[2024-12-17 02:58:10,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:10,987][root][INFO] - Training Epoch: 2/2, step 4293/7134 completed (loss: 0.020492110401391983, acc: 0.9939516186714172)
[2024-12-17 02:58:11,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:11,318][root][INFO] - Training Epoch: 2/2, step 4294/7134 completed (loss: 0.028810853138566017, acc: 0.9912663698196411)
[2024-12-17 02:58:11,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:11,664][root][INFO] - Training Epoch: 2/2, step 4295/7134 completed (loss: 0.026519089937210083, acc: 0.9927007555961609)
[2024-12-17 02:58:11,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:11,996][root][INFO] - Training Epoch: 2/2, step 4296/7134 completed (loss: 0.03421826288104057, acc: 0.9951338171958923)
[2024-12-17 02:58:12,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:12,343][root][INFO] - Training Epoch: 2/2, step 4297/7134 completed (loss: 0.022357162088155746, acc: 0.9976525902748108)
[2024-12-17 02:58:12,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:12,687][root][INFO] - Training Epoch: 2/2, step 4298/7134 completed (loss: 0.044476110488176346, acc: 0.9917469024658203)
[2024-12-17 02:58:12,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:13,015][root][INFO] - Training Epoch: 2/2, step 4299/7134 completed (loss: 0.03184932842850685, acc: 0.9914039969444275)
[2024-12-17 02:58:13,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:13,342][root][INFO] - Training Epoch: 2/2, step 4300/7134 completed (loss: 0.028501959517598152, acc: 0.9868420958518982)
[2024-12-17 02:58:13,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:13,683][root][INFO] - Training Epoch: 2/2, step 4301/7134 completed (loss: 0.03708430379629135, acc: 0.9868852496147156)
[2024-12-17 02:58:13,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:14,020][root][INFO] - Training Epoch: 2/2, step 4302/7134 completed (loss: 0.03421587496995926, acc: 0.9895522594451904)
[2024-12-17 02:58:14,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:14,375][root][INFO] - Training Epoch: 2/2, step 4303/7134 completed (loss: 0.04203975573182106, acc: 0.9880668520927429)
[2024-12-17 02:58:14,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:14,737][root][INFO] - Training Epoch: 2/2, step 4304/7134 completed (loss: 0.027450116351246834, acc: 0.98959881067276)
[2024-12-17 02:58:14,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:15,110][root][INFO] - Training Epoch: 2/2, step 4305/7134 completed (loss: 0.038472190499305725, acc: 0.9882628917694092)
[2024-12-17 02:58:15,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:15,486][root][INFO] - Training Epoch: 2/2, step 4306/7134 completed (loss: 0.10714685916900635, acc: 0.980289101600647)
[2024-12-17 02:58:15,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:15,840][root][INFO] - Training Epoch: 2/2, step 4307/7134 completed (loss: 0.08497215807437897, acc: 0.9791332483291626)
[2024-12-17 02:58:15,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:16,205][root][INFO] - Training Epoch: 2/2, step 4308/7134 completed (loss: 0.03518287092447281, acc: 0.9907192587852478)
[2024-12-17 02:58:16,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:16,568][root][INFO] - Training Epoch: 2/2, step 4309/7134 completed (loss: 0.03909743204712868, acc: 0.9889025688171387)
[2024-12-17 02:58:16,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:16,920][root][INFO] - Training Epoch: 2/2, step 4310/7134 completed (loss: 0.028091341257095337, acc: 0.9941245317459106)
[2024-12-17 02:58:17,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:17,251][root][INFO] - Training Epoch: 2/2, step 4311/7134 completed (loss: 0.021248096600174904, acc: 0.9942029118537903)
[2024-12-17 02:58:17,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:17,580][root][INFO] - Training Epoch: 2/2, step 4312/7134 completed (loss: 0.01780593767762184, acc: 0.9931880235671997)
[2024-12-17 02:58:17,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:17,912][root][INFO] - Training Epoch: 2/2, step 4313/7134 completed (loss: 0.03226359933614731, acc: 0.9935064911842346)
[2024-12-17 02:58:18,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:18,250][root][INFO] - Training Epoch: 2/2, step 4314/7134 completed (loss: 0.029680557548999786, acc: 0.9909365773200989)
[2024-12-17 02:58:18,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:18,609][root][INFO] - Training Epoch: 2/2, step 4315/7134 completed (loss: 0.041818056255578995, acc: 0.9895424842834473)
[2024-12-17 02:58:18,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:18,962][root][INFO] - Training Epoch: 2/2, step 4316/7134 completed (loss: 0.04919767007231712, acc: 0.9846938848495483)
[2024-12-17 02:58:19,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:19,319][root][INFO] - Training Epoch: 2/2, step 4317/7134 completed (loss: 0.05191011354327202, acc: 0.9876084327697754)
[2024-12-17 02:58:19,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:19,666][root][INFO] - Training Epoch: 2/2, step 4318/7134 completed (loss: 0.04044202342629433, acc: 0.9932735562324524)
[2024-12-17 02:58:19,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:20,043][root][INFO] - Training Epoch: 2/2, step 4319/7134 completed (loss: 0.01404588483273983, acc: 0.9955406785011292)
[2024-12-17 02:58:20,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:20,384][root][INFO] - Training Epoch: 2/2, step 4320/7134 completed (loss: 0.03792108595371246, acc: 0.9878378510475159)
[2024-12-17 02:58:20,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:20,672][root][INFO] - Training Epoch: 2/2, step 4321/7134 completed (loss: 0.03755812346935272, acc: 0.986143171787262)
[2024-12-17 02:58:20,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:21,022][root][INFO] - Training Epoch: 2/2, step 4322/7134 completed (loss: 0.03970588371157646, acc: 0.9889937043190002)
[2024-12-17 02:58:21,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:21,338][root][INFO] - Training Epoch: 2/2, step 4323/7134 completed (loss: 0.0718131884932518, acc: 0.9807322025299072)
[2024-12-17 02:58:21,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:21,645][root][INFO] - Training Epoch: 2/2, step 4324/7134 completed (loss: 0.023183083161711693, acc: 0.9903100728988647)
[2024-12-17 02:58:21,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:21,977][root][INFO] - Training Epoch: 2/2, step 4325/7134 completed (loss: 0.022913770750164986, acc: 0.9904305934906006)
[2024-12-17 02:58:22,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:22,310][root][INFO] - Training Epoch: 2/2, step 4326/7134 completed (loss: 0.03138384968042374, acc: 0.9911971688270569)
[2024-12-17 02:58:22,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:22,625][root][INFO] - Training Epoch: 2/2, step 4327/7134 completed (loss: 0.027711138129234314, acc: 0.9895104765892029)
[2024-12-17 02:58:22,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:22,954][root][INFO] - Training Epoch: 2/2, step 4328/7134 completed (loss: 0.06523273885250092, acc: 0.9849624037742615)
[2024-12-17 02:58:23,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:23,317][root][INFO] - Training Epoch: 2/2, step 4329/7134 completed (loss: 0.0313284695148468, acc: 0.9908257126808167)
[2024-12-17 02:58:23,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:23,590][root][INFO] - Training Epoch: 2/2, step 4330/7134 completed (loss: 0.044010113924741745, acc: 0.9893389940261841)
[2024-12-17 02:58:23,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:23,893][root][INFO] - Training Epoch: 2/2, step 4331/7134 completed (loss: 0.01628849469125271, acc: 0.9943342804908752)
[2024-12-17 02:58:23,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:24,220][root][INFO] - Training Epoch: 2/2, step 4332/7134 completed (loss: 0.06397229433059692, acc: 0.980988621711731)
[2024-12-17 02:58:24,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:24,549][root][INFO] - Training Epoch: 2/2, step 4333/7134 completed (loss: 0.045169129967689514, acc: 0.987860381603241)
[2024-12-17 02:58:24,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:24,904][root][INFO] - Training Epoch: 2/2, step 4334/7134 completed (loss: 0.05971626937389374, acc: 0.985029935836792)
[2024-12-17 02:58:24,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:25,228][root][INFO] - Training Epoch: 2/2, step 4335/7134 completed (loss: 0.04310331493616104, acc: 0.9899193644523621)
[2024-12-17 02:58:25,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:25,558][root][INFO] - Training Epoch: 2/2, step 4336/7134 completed (loss: 0.011872713454067707, acc: 0.9951456189155579)
[2024-12-17 02:58:25,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:25,884][root][INFO] - Training Epoch: 2/2, step 4337/7134 completed (loss: 0.03069659136235714, acc: 0.9905063509941101)
[2024-12-17 02:58:25,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:26,207][root][INFO] - Training Epoch: 2/2, step 4338/7134 completed (loss: 0.029147276654839516, acc: 0.9889415502548218)
[2024-12-17 02:58:26,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:26,538][root][INFO] - Training Epoch: 2/2, step 4339/7134 completed (loss: 0.03839043900370598, acc: 0.9854227304458618)
[2024-12-17 02:58:26,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:26,900][root][INFO] - Training Epoch: 2/2, step 4340/7134 completed (loss: 0.021921448409557343, acc: 0.9949324131011963)
[2024-12-17 02:58:27,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:27,234][root][INFO] - Training Epoch: 2/2, step 4341/7134 completed (loss: 0.055121053010225296, acc: 0.9836552739143372)
[2024-12-17 02:58:27,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:27,604][root][INFO] - Training Epoch: 2/2, step 4342/7134 completed (loss: 0.052400752902030945, acc: 0.9839743375778198)
[2024-12-17 02:58:27,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:27,947][root][INFO] - Training Epoch: 2/2, step 4343/7134 completed (loss: 0.024076607078313828, acc: 0.9916805028915405)
[2024-12-17 02:58:28,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:28,273][root][INFO] - Training Epoch: 2/2, step 4344/7134 completed (loss: 0.011170364916324615, acc: 1.0)
[2024-12-17 02:58:28,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:28,573][root][INFO] - Training Epoch: 2/2, step 4345/7134 completed (loss: 0.0385940782725811, acc: 0.979296088218689)
[2024-12-17 02:58:28,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:28,874][root][INFO] - Training Epoch: 2/2, step 4346/7134 completed (loss: 0.008582704700529575, acc: 0.9979296326637268)
[2024-12-17 02:58:29,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:29,202][root][INFO] - Training Epoch: 2/2, step 4347/7134 completed (loss: 0.07434160262346268, acc: 0.9830268621444702)
[2024-12-17 02:58:29,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:29,515][root][INFO] - Training Epoch: 2/2, step 4348/7134 completed (loss: 0.026941413059830666, acc: 0.9936000108718872)
[2024-12-17 02:58:29,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:29,823][root][INFO] - Training Epoch: 2/2, step 4349/7134 completed (loss: 0.028971891850233078, acc: 0.986143171787262)
[2024-12-17 02:58:29,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:30,169][root][INFO] - Training Epoch: 2/2, step 4350/7134 completed (loss: 0.045154523104429245, acc: 0.9895287752151489)
[2024-12-17 02:58:30,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:30,507][root][INFO] - Training Epoch: 2/2, step 4351/7134 completed (loss: 0.06269621104001999, acc: 0.9835391044616699)
[2024-12-17 02:58:30,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:30,860][root][INFO] - Training Epoch: 2/2, step 4352/7134 completed (loss: 0.06005145609378815, acc: 0.9784537553787231)
[2024-12-17 02:58:30,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:31,215][root][INFO] - Training Epoch: 2/2, step 4353/7134 completed (loss: 0.04318680986762047, acc: 0.9854304790496826)
[2024-12-17 02:58:31,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:31,563][root][INFO] - Training Epoch: 2/2, step 4354/7134 completed (loss: 0.05113771930336952, acc: 0.9866666793823242)
[2024-12-17 02:58:31,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:31,918][root][INFO] - Training Epoch: 2/2, step 4355/7134 completed (loss: 0.03384864330291748, acc: 0.991239070892334)
[2024-12-17 02:58:32,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:32,283][root][INFO] - Training Epoch: 2/2, step 4356/7134 completed (loss: 0.03317961096763611, acc: 0.9904420375823975)
[2024-12-17 02:58:32,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:32,639][root][INFO] - Training Epoch: 2/2, step 4357/7134 completed (loss: 0.06498313695192337, acc: 0.9811023473739624)
[2024-12-17 02:58:32,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:33,006][root][INFO] - Training Epoch: 2/2, step 4358/7134 completed (loss: 0.04457272216677666, acc: 0.9868263602256775)
[2024-12-17 02:58:33,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:33,345][root][INFO] - Training Epoch: 2/2, step 4359/7134 completed (loss: 0.048169273883104324, acc: 0.9841521382331848)
[2024-12-17 02:58:33,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:33,657][root][INFO] - Training Epoch: 2/2, step 4360/7134 completed (loss: 0.07133831828832626, acc: 0.9832402467727661)
[2024-12-17 02:58:33,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:34,000][root][INFO] - Training Epoch: 2/2, step 4361/7134 completed (loss: 0.03209466487169266, acc: 0.9898843765258789)
[2024-12-17 02:58:34,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:34,362][root][INFO] - Training Epoch: 2/2, step 4362/7134 completed (loss: 0.04616730660200119, acc: 0.9876695275306702)
[2024-12-17 02:58:34,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:34,722][root][INFO] - Training Epoch: 2/2, step 4363/7134 completed (loss: 0.03855597972869873, acc: 0.9851239919662476)
[2024-12-17 02:58:34,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:35,040][root][INFO] - Training Epoch: 2/2, step 4364/7134 completed (loss: 0.03812957927584648, acc: 0.9828125238418579)
[2024-12-17 02:58:35,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:35,384][root][INFO] - Training Epoch: 2/2, step 4365/7134 completed (loss: 0.038881368935108185, acc: 0.9842767119407654)
[2024-12-17 02:58:35,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:35,750][root][INFO] - Training Epoch: 2/2, step 4366/7134 completed (loss: 0.08659100532531738, acc: 0.9755154848098755)
[2024-12-17 02:58:35,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:36,108][root][INFO] - Training Epoch: 2/2, step 4367/7134 completed (loss: 0.0440712533891201, acc: 0.9885386824607849)
[2024-12-17 02:58:36,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:36,490][root][INFO] - Training Epoch: 2/2, step 4368/7134 completed (loss: 0.02895420975983143, acc: 0.991183876991272)
[2024-12-17 02:58:36,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:36,829][root][INFO] - Training Epoch: 2/2, step 4369/7134 completed (loss: 0.031214246526360512, acc: 0.9933333396911621)
[2024-12-17 02:58:36,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:37,186][root][INFO] - Training Epoch: 2/2, step 4370/7134 completed (loss: 0.045597340911626816, acc: 0.9911727905273438)
[2024-12-17 02:58:37,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:37,552][root][INFO] - Training Epoch: 2/2, step 4371/7134 completed (loss: 0.05526891350746155, acc: 0.9828495979309082)
[2024-12-17 02:58:37,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:37,886][root][INFO] - Training Epoch: 2/2, step 4372/7134 completed (loss: 0.046272698789834976, acc: 0.9896729588508606)
[2024-12-17 02:58:38,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:38,229][root][INFO] - Training Epoch: 2/2, step 4373/7134 completed (loss: 0.02819765917956829, acc: 0.9892984628677368)
[2024-12-17 02:58:38,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:38,567][root][INFO] - Training Epoch: 2/2, step 4374/7134 completed (loss: 0.05174366384744644, acc: 0.9870503544807434)
[2024-12-17 02:58:38,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:38,918][root][INFO] - Training Epoch: 2/2, step 4375/7134 completed (loss: 0.029260536655783653, acc: 0.9884169697761536)
[2024-12-17 02:58:39,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:39,238][root][INFO] - Training Epoch: 2/2, step 4376/7134 completed (loss: 0.04488790035247803, acc: 0.9864253401756287)
[2024-12-17 02:58:39,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:39,592][root][INFO] - Training Epoch: 2/2, step 4377/7134 completed (loss: 0.0670422837138176, acc: 0.9913473129272461)
[2024-12-17 02:58:39,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:39,938][root][INFO] - Training Epoch: 2/2, step 4378/7134 completed (loss: 0.04471568390727043, acc: 0.9869281053543091)
[2024-12-17 02:58:40,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:40,306][root][INFO] - Training Epoch: 2/2, step 4379/7134 completed (loss: 0.09855814278125763, acc: 0.9753788113594055)
[2024-12-17 02:58:40,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:40,626][root][INFO] - Training Epoch: 2/2, step 4380/7134 completed (loss: 0.05842467397451401, acc: 0.9789842367172241)
[2024-12-17 02:58:40,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:40,996][root][INFO] - Training Epoch: 2/2, step 4381/7134 completed (loss: 0.03939211741089821, acc: 0.9889655113220215)
[2024-12-17 02:58:41,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:41,315][root][INFO] - Training Epoch: 2/2, step 4382/7134 completed (loss: 0.016675224527716637, acc: 0.996820330619812)
[2024-12-17 02:58:41,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:41,667][root][INFO] - Training Epoch: 2/2, step 4383/7134 completed (loss: 0.05742543563246727, acc: 0.9848693013191223)
[2024-12-17 02:58:41,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:42,002][root][INFO] - Training Epoch: 2/2, step 4384/7134 completed (loss: 0.030941931530833244, acc: 0.9899497628211975)
[2024-12-17 02:58:42,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:42,344][root][INFO] - Training Epoch: 2/2, step 4385/7134 completed (loss: 0.058916766196489334, acc: 0.9830508232116699)
[2024-12-17 02:58:42,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:42,723][root][INFO] - Training Epoch: 2/2, step 4386/7134 completed (loss: 0.057809509336948395, acc: 0.9822275042533875)
[2024-12-17 02:58:42,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:43,084][root][INFO] - Training Epoch: 2/2, step 4387/7134 completed (loss: 0.05641020089387894, acc: 0.9871175289154053)
[2024-12-17 02:58:43,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:43,417][root][INFO] - Training Epoch: 2/2, step 4388/7134 completed (loss: 0.05124564841389656, acc: 0.9829192757606506)
[2024-12-17 02:58:43,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:43,759][root][INFO] - Training Epoch: 2/2, step 4389/7134 completed (loss: 0.076827272772789, acc: 0.9787928462028503)
[2024-12-17 02:58:43,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:44,135][root][INFO] - Training Epoch: 2/2, step 4390/7134 completed (loss: 0.11028653383255005, acc: 0.9705469608306885)
[2024-12-17 02:58:44,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:44,467][root][INFO] - Training Epoch: 2/2, step 4391/7134 completed (loss: 0.10762818157672882, acc: 0.9739413857460022)
[2024-12-17 02:58:44,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:44,818][root][INFO] - Training Epoch: 2/2, step 4392/7134 completed (loss: 0.029187222942709923, acc: 0.9950980544090271)
[2024-12-17 02:58:44,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:45,174][root][INFO] - Training Epoch: 2/2, step 4393/7134 completed (loss: 0.03090727888047695, acc: 0.9915611743927002)
[2024-12-17 02:58:45,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:45,528][root][INFO] - Training Epoch: 2/2, step 4394/7134 completed (loss: 0.042783550918102264, acc: 0.9873060584068298)
[2024-12-17 02:58:45,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:45,864][root][INFO] - Training Epoch: 2/2, step 4395/7134 completed (loss: 0.06662549078464508, acc: 0.9748822450637817)
[2024-12-17 02:58:45,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:46,185][root][INFO] - Training Epoch: 2/2, step 4396/7134 completed (loss: 0.10779332369565964, acc: 0.9701896905899048)
[2024-12-17 02:58:46,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:46,526][root][INFO] - Training Epoch: 2/2, step 4397/7134 completed (loss: 0.06550706923007965, acc: 0.9788235425949097)
[2024-12-17 02:58:46,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:46,935][root][INFO] - Training Epoch: 2/2, step 4398/7134 completed (loss: 0.0191738773137331, acc: 0.9924242496490479)
[2024-12-17 02:58:47,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:47,267][root][INFO] - Training Epoch: 2/2, step 4399/7134 completed (loss: 0.05140820890665054, acc: 0.9855305552482605)
[2024-12-17 02:58:47,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:47,633][root][INFO] - Training Epoch: 2/2, step 4400/7134 completed (loss: 0.09324522316455841, acc: 0.9789343476295471)
[2024-12-17 02:58:47,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:47,947][root][INFO] - Training Epoch: 2/2, step 4401/7134 completed (loss: 0.09020817279815674, acc: 0.9811594486236572)
[2024-12-17 02:58:48,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:48,288][root][INFO] - Training Epoch: 2/2, step 4402/7134 completed (loss: 0.14306235313415527, acc: 0.9636628031730652)
[2024-12-17 02:58:48,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:48,638][root][INFO] - Training Epoch: 2/2, step 4403/7134 completed (loss: 0.18667082488536835, acc: 0.946891188621521)
[2024-12-17 02:58:48,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:48,969][root][INFO] - Training Epoch: 2/2, step 4404/7134 completed (loss: 0.1469215303659439, acc: 0.9640957713127136)
[2024-12-17 02:58:49,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:49,350][root][INFO] - Training Epoch: 2/2, step 4405/7134 completed (loss: 0.048552315682172775, acc: 0.988120973110199)
[2024-12-17 02:58:49,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:49,734][root][INFO] - Training Epoch: 2/2, step 4406/7134 completed (loss: 0.044599782675504684, acc: 0.9877505302429199)
[2024-12-17 02:58:49,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:50,103][root][INFO] - Training Epoch: 2/2, step 4407/7134 completed (loss: 0.05427582934498787, acc: 0.9872832298278809)
[2024-12-17 02:58:50,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:50,464][root][INFO] - Training Epoch: 2/2, step 4408/7134 completed (loss: 0.11291306465864182, acc: 0.9685680866241455)
[2024-12-17 02:58:50,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:50,830][root][INFO] - Training Epoch: 2/2, step 4409/7134 completed (loss: 0.10368913412094116, acc: 0.9767726063728333)
[2024-12-17 02:58:50,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:51,176][root][INFO] - Training Epoch: 2/2, step 4410/7134 completed (loss: 0.08531104028224945, acc: 0.9784946441650391)
[2024-12-17 02:58:51,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:51,517][root][INFO] - Training Epoch: 2/2, step 4411/7134 completed (loss: 0.15616150200366974, acc: 0.9553956985473633)
[2024-12-17 02:58:51,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:51,856][root][INFO] - Training Epoch: 2/2, step 4412/7134 completed (loss: 0.19176329672336578, acc: 0.946107804775238)
[2024-12-17 02:58:51,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:52,196][root][INFO] - Training Epoch: 2/2, step 4413/7134 completed (loss: 0.12935855984687805, acc: 0.9727891087532043)
[2024-12-17 02:58:52,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:52,527][root][INFO] - Training Epoch: 2/2, step 4414/7134 completed (loss: 0.0394984595477581, acc: 0.9881516695022583)
[2024-12-17 02:58:52,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:52,877][root][INFO] - Training Epoch: 2/2, step 4415/7134 completed (loss: 0.08056537806987762, acc: 0.975093424320221)
[2024-12-17 02:58:53,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:53,243][root][INFO] - Training Epoch: 2/2, step 4416/7134 completed (loss: 0.09012801945209503, acc: 0.9754959344863892)
[2024-12-17 02:58:53,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:53,596][root][INFO] - Training Epoch: 2/2, step 4417/7134 completed (loss: 0.1231667622923851, acc: 0.9747596383094788)
[2024-12-17 02:58:53,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:53,948][root][INFO] - Training Epoch: 2/2, step 4418/7134 completed (loss: 0.07681810855865479, acc: 0.98046875)
[2024-12-17 02:58:54,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:54,279][root][INFO] - Training Epoch: 2/2, step 4419/7134 completed (loss: 0.12139681726694107, acc: 0.9675480723381042)
[2024-12-17 02:58:54,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:54,639][root][INFO] - Training Epoch: 2/2, step 4420/7134 completed (loss: 0.10074468702077866, acc: 0.9709543585777283)
[2024-12-17 02:58:54,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:54,996][root][INFO] - Training Epoch: 2/2, step 4421/7134 completed (loss: 0.06469538062810898, acc: 0.9808773994445801)
[2024-12-17 02:58:55,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:55,366][root][INFO] - Training Epoch: 2/2, step 4422/7134 completed (loss: 0.1103605180978775, acc: 0.9686028361320496)
[2024-12-17 02:58:55,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:55,743][root][INFO] - Training Epoch: 2/2, step 4423/7134 completed (loss: 0.07764614373445511, acc: 0.9783105254173279)
[2024-12-17 02:58:55,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:56,110][root][INFO] - Training Epoch: 2/2, step 4424/7134 completed (loss: 0.08280656486749649, acc: 0.977477490901947)
[2024-12-17 02:58:56,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:56,470][root][INFO] - Training Epoch: 2/2, step 4425/7134 completed (loss: 0.052185919135808945, acc: 0.984795331954956)
[2024-12-17 02:58:56,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:56,852][root][INFO] - Training Epoch: 2/2, step 4426/7134 completed (loss: 0.07545699924230576, acc: 0.9824198484420776)
[2024-12-17 02:58:56,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:57,145][root][INFO] - Training Epoch: 2/2, step 4427/7134 completed (loss: 0.1725931018590927, acc: 0.9686747193336487)
[2024-12-17 02:58:57,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:57,509][root][INFO] - Training Epoch: 2/2, step 4428/7134 completed (loss: 0.040265992283821106, acc: 0.9929577708244324)
[2024-12-17 02:58:57,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:57,771][root][INFO] - Training Epoch: 2/2, step 4429/7134 completed (loss: 0.08599585294723511, acc: 0.9768041372299194)
[2024-12-17 02:58:57,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:58,106][root][INFO] - Training Epoch: 2/2, step 4430/7134 completed (loss: 0.08227416127920151, acc: 0.9740853905677795)
[2024-12-17 02:58:58,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:58,425][root][INFO] - Training Epoch: 2/2, step 4431/7134 completed (loss: 0.06647899746894836, acc: 0.9782270789146423)
[2024-12-17 02:58:58,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:58,742][root][INFO] - Training Epoch: 2/2, step 4432/7134 completed (loss: 0.03213828429579735, acc: 0.9923195242881775)
[2024-12-17 02:58:58,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:59,111][root][INFO] - Training Epoch: 2/2, step 4433/7134 completed (loss: 0.08114316314458847, acc: 0.9813519716262817)
[2024-12-17 02:58:59,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:59,462][root][INFO] - Training Epoch: 2/2, step 4434/7134 completed (loss: 0.05927547067403793, acc: 0.9879879951477051)
[2024-12-17 02:58:59,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:59,786][root][INFO] - Training Epoch: 2/2, step 4435/7134 completed (loss: 0.037555694580078125, acc: 0.9852125644683838)
[2024-12-17 02:58:59,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:00,156][root][INFO] - Training Epoch: 2/2, step 4436/7134 completed (loss: 0.07661379128694534, acc: 0.9748603105545044)
[2024-12-17 02:59:00,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:00,493][root][INFO] - Training Epoch: 2/2, step 4437/7134 completed (loss: 0.023283282294869423, acc: 0.9960629940032959)
[2024-12-17 02:59:00,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:00,830][root][INFO] - Training Epoch: 2/2, step 4438/7134 completed (loss: 0.048614099621772766, acc: 0.9864406585693359)
[2024-12-17 02:59:00,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:01,162][root][INFO] - Training Epoch: 2/2, step 4439/7134 completed (loss: 0.017999965697526932, acc: 0.995121955871582)
[2024-12-17 02:59:01,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:01,490][root][INFO] - Training Epoch: 2/2, step 4440/7134 completed (loss: 0.04146191477775574, acc: 0.9848066568374634)
[2024-12-17 02:59:01,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:01,888][root][INFO] - Training Epoch: 2/2, step 4441/7134 completed (loss: 0.04389652982354164, acc: 0.9892473220825195)
[2024-12-17 02:59:02,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:02,239][root][INFO] - Training Epoch: 2/2, step 4442/7134 completed (loss: 0.07866048812866211, acc: 0.9871299862861633)
[2024-12-17 02:59:02,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:02,597][root][INFO] - Training Epoch: 2/2, step 4443/7134 completed (loss: 0.05515730753540993, acc: 0.9833333492279053)
[2024-12-17 02:59:02,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:02,910][root][INFO] - Training Epoch: 2/2, step 4444/7134 completed (loss: 0.05621853843331337, acc: 0.9836868047714233)
[2024-12-17 02:59:03,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:03,235][root][INFO] - Training Epoch: 2/2, step 4445/7134 completed (loss: 0.07847339659929276, acc: 0.9776536226272583)
[2024-12-17 02:59:03,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:03,565][root][INFO] - Training Epoch: 2/2, step 4446/7134 completed (loss: 0.0392574742436409, acc: 0.9855072498321533)
[2024-12-17 02:59:03,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:03,936][root][INFO] - Training Epoch: 2/2, step 4447/7134 completed (loss: 0.03441843390464783, acc: 0.989386796951294)
[2024-12-17 02:59:04,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:04,281][root][INFO] - Training Epoch: 2/2, step 4448/7134 completed (loss: 0.042896293103694916, acc: 0.9817184805870056)
[2024-12-17 02:59:04,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:04,596][root][INFO] - Training Epoch: 2/2, step 4449/7134 completed (loss: 0.09794779121875763, acc: 0.9739776849746704)
[2024-12-17 02:59:04,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:04,958][root][INFO] - Training Epoch: 2/2, step 4450/7134 completed (loss: 0.08614421635866165, acc: 0.9733333587646484)
[2024-12-17 02:59:05,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:05,281][root][INFO] - Training Epoch: 2/2, step 4451/7134 completed (loss: 0.122198186814785, acc: 0.9734659790992737)
[2024-12-17 02:59:05,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:05,646][root][INFO] - Training Epoch: 2/2, step 4452/7134 completed (loss: 0.02905837632715702, acc: 0.9936000108718872)
[2024-12-17 02:59:05,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:05,977][root][INFO] - Training Epoch: 2/2, step 4453/7134 completed (loss: 0.05268709361553192, acc: 0.9877049326896667)
[2024-12-17 02:59:06,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:06,327][root][INFO] - Training Epoch: 2/2, step 4454/7134 completed (loss: 0.047129563987255096, acc: 0.9915013909339905)
[2024-12-17 02:59:06,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:06,626][root][INFO] - Training Epoch: 2/2, step 4455/7134 completed (loss: 0.1191331148147583, acc: 0.9779005646705627)
[2024-12-17 02:59:06,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:06,942][root][INFO] - Training Epoch: 2/2, step 4456/7134 completed (loss: 0.031165583059191704, acc: 0.9870550036430359)
[2024-12-17 02:59:07,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:07,221][root][INFO] - Training Epoch: 2/2, step 4457/7134 completed (loss: 0.03629206120967865, acc: 0.9775280952453613)
[2024-12-17 02:59:07,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:07,561][root][INFO] - Training Epoch: 2/2, step 4458/7134 completed (loss: 0.01561962254345417, acc: 0.9967266917228699)
[2024-12-17 02:59:07,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:07,921][root][INFO] - Training Epoch: 2/2, step 4459/7134 completed (loss: 0.030313774943351746, acc: 0.9890109896659851)
[2024-12-17 02:59:08,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:08,269][root][INFO] - Training Epoch: 2/2, step 4460/7134 completed (loss: 0.035057470202445984, acc: 0.9902200698852539)
[2024-12-17 02:59:08,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:08,622][root][INFO] - Training Epoch: 2/2, step 4461/7134 completed (loss: 0.07202999293804169, acc: 0.9901599287986755)
[2024-12-17 02:59:08,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:08,986][root][INFO] - Training Epoch: 2/2, step 4462/7134 completed (loss: 0.019554760307073593, acc: 0.9959127902984619)
[2024-12-17 02:59:09,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:09,344][root][INFO] - Training Epoch: 2/2, step 4463/7134 completed (loss: 0.031538452953100204, acc: 0.99245285987854)
[2024-12-17 02:59:09,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:09,712][root][INFO] - Training Epoch: 2/2, step 4464/7134 completed (loss: 0.0480308011174202, acc: 0.9898819327354431)
[2024-12-17 02:59:09,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:10,069][root][INFO] - Training Epoch: 2/2, step 4465/7134 completed (loss: 0.02305052988231182, acc: 0.9948453903198242)
[2024-12-17 02:59:10,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:10,428][root][INFO] - Training Epoch: 2/2, step 4466/7134 completed (loss: 0.024275977164506912, acc: 0.9913580417633057)
[2024-12-17 02:59:10,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:10,790][root][INFO] - Training Epoch: 2/2, step 4467/7134 completed (loss: 0.035346634685993195, acc: 0.9912060499191284)
[2024-12-17 02:59:10,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:11,146][root][INFO] - Training Epoch: 2/2, step 4468/7134 completed (loss: 0.00863275583833456, acc: 0.9988109469413757)
[2024-12-17 02:59:11,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:11,510][root][INFO] - Training Epoch: 2/2, step 4469/7134 completed (loss: 0.03880360722541809, acc: 0.9907514452934265)
[2024-12-17 02:59:11,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:11,883][root][INFO] - Training Epoch: 2/2, step 4470/7134 completed (loss: 0.032698459923267365, acc: 0.988950252532959)
[2024-12-17 02:59:11,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:12,225][root][INFO] - Training Epoch: 2/2, step 4471/7134 completed (loss: 0.010400782339274883, acc: 0.9987714886665344)
[2024-12-17 02:59:12,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:12,564][root][INFO] - Training Epoch: 2/2, step 4472/7134 completed (loss: 0.03635227307677269, acc: 0.9881423115730286)
[2024-12-17 02:59:12,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:12,907][root][INFO] - Training Epoch: 2/2, step 4473/7134 completed (loss: 0.08700898289680481, acc: 0.9775910377502441)
[2024-12-17 02:59:13,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:13,239][root][INFO] - Training Epoch: 2/2, step 4474/7134 completed (loss: 0.07273229211568832, acc: 0.9776847958564758)
[2024-12-17 02:59:13,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:13,594][root][INFO] - Training Epoch: 2/2, step 4475/7134 completed (loss: 0.11231014132499695, acc: 0.9727047085762024)
[2024-12-17 02:59:13,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:13,947][root][INFO] - Training Epoch: 2/2, step 4476/7134 completed (loss: 0.06711330264806747, acc: 0.9849108457565308)
[2024-12-17 02:59:14,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:14,295][root][INFO] - Training Epoch: 2/2, step 4477/7134 completed (loss: 0.019070900976657867, acc: 0.995110034942627)
[2024-12-17 02:59:14,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:14,659][root][INFO] - Training Epoch: 2/2, step 4478/7134 completed (loss: 0.02032620459794998, acc: 0.9975278377532959)
[2024-12-17 02:59:14,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:14,998][root][INFO] - Training Epoch: 2/2, step 4479/7134 completed (loss: 0.014875621534883976, acc: 0.9959568977355957)
[2024-12-17 02:59:15,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:15,360][root][INFO] - Training Epoch: 2/2, step 4480/7134 completed (loss: 0.04578210413455963, acc: 0.9906542301177979)
[2024-12-17 02:59:15,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:15,732][root][INFO] - Training Epoch: 2/2, step 4481/7134 completed (loss: 0.04128726199269295, acc: 0.9906542301177979)
[2024-12-17 02:59:15,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:16,098][root][INFO] - Training Epoch: 2/2, step 4482/7134 completed (loss: 0.01471747737377882, acc: 0.9988009333610535)
[2024-12-17 02:59:16,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:16,428][root][INFO] - Training Epoch: 2/2, step 4483/7134 completed (loss: 0.04033859446644783, acc: 0.9881129264831543)
[2024-12-17 02:59:16,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:16,797][root][INFO] - Training Epoch: 2/2, step 4484/7134 completed (loss: 0.015554116107523441, acc: 0.9960317611694336)
[2024-12-17 02:59:16,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:17,141][root][INFO] - Training Epoch: 2/2, step 4485/7134 completed (loss: 0.014224677346646786, acc: 0.9954057931900024)
[2024-12-17 02:59:17,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:17,462][root][INFO] - Training Epoch: 2/2, step 4486/7134 completed (loss: 0.010954922996461391, acc: 0.9970149397850037)
[2024-12-17 02:59:17,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:17,801][root][INFO] - Training Epoch: 2/2, step 4487/7134 completed (loss: 0.013689713552594185, acc: 0.9958620667457581)
[2024-12-17 02:59:17,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:18,105][root][INFO] - Training Epoch: 2/2, step 4488/7134 completed (loss: 0.013068551197648048, acc: 0.9946042895317078)
[2024-12-17 02:59:18,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:18,453][root][INFO] - Training Epoch: 2/2, step 4489/7134 completed (loss: 0.025762010365724564, acc: 0.993127167224884)
[2024-12-17 02:59:18,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:18,802][root][INFO] - Training Epoch: 2/2, step 4490/7134 completed (loss: 0.022965779528021812, acc: 0.9925925731658936)
[2024-12-17 02:59:18,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:19,149][root][INFO] - Training Epoch: 2/2, step 4491/7134 completed (loss: 0.006348114926367998, acc: 1.0)
[2024-12-17 02:59:19,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:19,475][root][INFO] - Training Epoch: 2/2, step 4492/7134 completed (loss: 0.023816470056772232, acc: 0.9944853186607361)
[2024-12-17 02:59:19,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:19,804][root][INFO] - Training Epoch: 2/2, step 4493/7134 completed (loss: 0.00648263655602932, acc: 0.9986245036125183)
[2024-12-17 02:59:19,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:20,152][root][INFO] - Training Epoch: 2/2, step 4494/7134 completed (loss: 0.02708030678331852, acc: 0.9942113161087036)
[2024-12-17 02:59:20,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:20,504][root][INFO] - Training Epoch: 2/2, step 4495/7134 completed (loss: 0.026037000119686127, acc: 0.9936143159866333)
[2024-12-17 02:59:20,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:20,836][root][INFO] - Training Epoch: 2/2, step 4496/7134 completed (loss: 0.024759184569120407, acc: 0.9928774833679199)
[2024-12-17 02:59:20,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:21,162][root][INFO] - Training Epoch: 2/2, step 4497/7134 completed (loss: 0.014285704120993614, acc: 0.9973509907722473)
[2024-12-17 02:59:21,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:21,506][root][INFO] - Training Epoch: 2/2, step 4498/7134 completed (loss: 0.04234931617975235, acc: 0.9912917017936707)
[2024-12-17 02:59:21,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:21,785][root][INFO] - Training Epoch: 2/2, step 4499/7134 completed (loss: 0.02498340979218483, acc: 0.9947826266288757)
[2024-12-17 02:59:21,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:22,136][root][INFO] - Training Epoch: 2/2, step 4500/7134 completed (loss: 0.018431369215250015, acc: 0.9958041906356812)
[2024-12-17 02:59:22,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:22,470][root][INFO] - Training Epoch: 2/2, step 4501/7134 completed (loss: 0.016596727073192596, acc: 0.99589604139328)
[2024-12-17 02:59:22,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:22,776][root][INFO] - Training Epoch: 2/2, step 4502/7134 completed (loss: 0.02220773510634899, acc: 0.9940029978752136)
[2024-12-17 02:59:22,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:23,074][root][INFO] - Training Epoch: 2/2, step 4503/7134 completed (loss: 0.01033723820000887, acc: 0.9983948469161987)
[2024-12-17 02:59:23,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:23,416][root][INFO] - Training Epoch: 2/2, step 4504/7134 completed (loss: 0.05705922842025757, acc: 0.9850522875785828)
[2024-12-17 02:59:23,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:23,779][root][INFO] - Training Epoch: 2/2, step 4505/7134 completed (loss: 0.042227622121572495, acc: 0.9864864945411682)
[2024-12-17 02:59:23,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:24,107][root][INFO] - Training Epoch: 2/2, step 4506/7134 completed (loss: 0.02359747514128685, acc: 0.9909909963607788)
[2024-12-17 02:59:24,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:24,436][root][INFO] - Training Epoch: 2/2, step 4507/7134 completed (loss: 0.030100112780928612, acc: 0.9886202216148376)
[2024-12-17 02:59:24,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:24,771][root][INFO] - Training Epoch: 2/2, step 4508/7134 completed (loss: 0.03635120764374733, acc: 0.9900285005569458)
[2024-12-17 02:59:24,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:25,133][root][INFO] - Training Epoch: 2/2, step 4509/7134 completed (loss: 0.05234135314822197, acc: 0.9879194498062134)
[2024-12-17 02:59:25,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:25,498][root][INFO] - Training Epoch: 2/2, step 4510/7134 completed (loss: 0.044419191777706146, acc: 0.9887164831161499)
[2024-12-17 02:59:25,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:25,863][root][INFO] - Training Epoch: 2/2, step 4511/7134 completed (loss: 0.07977881282567978, acc: 0.9760900139808655)
[2024-12-17 02:59:25,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:26,189][root][INFO] - Training Epoch: 2/2, step 4512/7134 completed (loss: 0.057335015386343, acc: 0.9731183052062988)
[2024-12-17 02:59:26,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:26,544][root][INFO] - Training Epoch: 2/2, step 4513/7134 completed (loss: 0.02499564364552498, acc: 0.992977499961853)
[2024-12-17 02:59:26,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:26,888][root][INFO] - Training Epoch: 2/2, step 4514/7134 completed (loss: 0.1026948019862175, acc: 0.9751824736595154)
[2024-12-17 02:59:26,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:27,235][root][INFO] - Training Epoch: 2/2, step 4515/7134 completed (loss: 0.05243130400776863, acc: 0.9805970191955566)
[2024-12-17 02:59:27,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:27,576][root][INFO] - Training Epoch: 2/2, step 4516/7134 completed (loss: 0.030343594029545784, acc: 0.9865360856056213)
[2024-12-17 02:59:27,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:27,925][root][INFO] - Training Epoch: 2/2, step 4517/7134 completed (loss: 0.04788995534181595, acc: 0.9884763360023499)
[2024-12-17 02:59:28,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:28,289][root][INFO] - Training Epoch: 2/2, step 4518/7134 completed (loss: 0.0765097364783287, acc: 0.9846938848495483)
[2024-12-17 02:59:28,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:28,645][root][INFO] - Training Epoch: 2/2, step 4519/7134 completed (loss: 0.029173266142606735, acc: 0.9915356636047363)
[2024-12-17 02:59:28,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:28,994][root][INFO] - Training Epoch: 2/2, step 4520/7134 completed (loss: 0.05790134519338608, acc: 0.9887005686759949)
[2024-12-17 02:59:29,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:29,361][root][INFO] - Training Epoch: 2/2, step 4521/7134 completed (loss: 0.05746150389313698, acc: 0.9891696572303772)
[2024-12-17 02:59:29,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:29,716][root][INFO] - Training Epoch: 2/2, step 4522/7134 completed (loss: 0.06175956130027771, acc: 0.9785894155502319)
[2024-12-17 02:59:29,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:30,069][root][INFO] - Training Epoch: 2/2, step 4523/7134 completed (loss: 0.034106943756341934, acc: 0.9881656765937805)
[2024-12-17 02:59:30,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:30,438][root][INFO] - Training Epoch: 2/2, step 4524/7134 completed (loss: 0.052354976534843445, acc: 0.9919028282165527)
[2024-12-17 02:59:30,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:30,795][root][INFO] - Training Epoch: 2/2, step 4525/7134 completed (loss: 0.03243853151798248, acc: 0.9866666793823242)
[2024-12-17 02:59:30,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:31,154][root][INFO] - Training Epoch: 2/2, step 4526/7134 completed (loss: 0.07220437377691269, acc: 0.9741935729980469)
[2024-12-17 02:59:31,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:31,541][root][INFO] - Training Epoch: 2/2, step 4527/7134 completed (loss: 0.04535087198019028, acc: 0.9843924045562744)
[2024-12-17 02:59:31,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:31,896][root][INFO] - Training Epoch: 2/2, step 4528/7134 completed (loss: 0.08873575180768967, acc: 0.9820051193237305)
[2024-12-17 02:59:32,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:32,223][root][INFO] - Training Epoch: 2/2, step 4529/7134 completed (loss: 0.07880612462759018, acc: 0.9792746305465698)
[2024-12-17 02:59:32,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:32,565][root][INFO] - Training Epoch: 2/2, step 4530/7134 completed (loss: 0.030905667692422867, acc: 0.9915966391563416)
[2024-12-17 02:59:32,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:32,920][root][INFO] - Training Epoch: 2/2, step 4531/7134 completed (loss: 0.02016156166791916, acc: 0.9964093565940857)
[2024-12-17 02:59:33,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:33,291][root][INFO] - Training Epoch: 2/2, step 4532/7134 completed (loss: 0.06917256116867065, acc: 0.9790836572647095)
[2024-12-17 02:59:33,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:33,637][root][INFO] - Training Epoch: 2/2, step 4533/7134 completed (loss: 0.03138241916894913, acc: 0.990510106086731)
[2024-12-17 02:59:33,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:33,984][root][INFO] - Training Epoch: 2/2, step 4534/7134 completed (loss: 0.02231321670114994, acc: 0.9929577708244324)
[2024-12-17 02:59:34,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:34,331][root][INFO] - Training Epoch: 2/2, step 4535/7134 completed (loss: 0.03123793937265873, acc: 0.9920273423194885)
[2024-12-17 02:59:34,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:34,712][root][INFO] - Training Epoch: 2/2, step 4536/7134 completed (loss: 0.0327947698533535, acc: 0.9913793206214905)
[2024-12-17 02:59:34,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:35,081][root][INFO] - Training Epoch: 2/2, step 4537/7134 completed (loss: 0.026764078065752983, acc: 0.9910614490509033)
[2024-12-17 02:59:35,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:35,452][root][INFO] - Training Epoch: 2/2, step 4538/7134 completed (loss: 0.039740484207868576, acc: 0.9931034445762634)
[2024-12-17 02:59:35,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:35,821][root][INFO] - Training Epoch: 2/2, step 4539/7134 completed (loss: 0.02772480808198452, acc: 0.9913700222969055)
[2024-12-17 02:59:35,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:36,181][root][INFO] - Training Epoch: 2/2, step 4540/7134 completed (loss: 0.03371771425008774, acc: 0.9898843765258789)
[2024-12-17 02:59:36,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:36,466][root][INFO] - Training Epoch: 2/2, step 4541/7134 completed (loss: 0.06179336830973625, acc: 0.9815195202827454)
[2024-12-17 02:59:36,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:36,760][root][INFO] - Training Epoch: 2/2, step 4542/7134 completed (loss: 0.08246723562479019, acc: 0.9826839566230774)
[2024-12-17 02:59:36,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:37,059][root][INFO] - Training Epoch: 2/2, step 4543/7134 completed (loss: 0.08452712744474411, acc: 0.9750445485115051)
[2024-12-17 02:59:37,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:37,401][root][INFO] - Training Epoch: 2/2, step 4544/7134 completed (loss: 0.05111261084675789, acc: 0.9862805008888245)
[2024-12-17 02:59:37,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:37,724][root][INFO] - Training Epoch: 2/2, step 4545/7134 completed (loss: 0.09983458369970322, acc: 0.9710982441902161)
[2024-12-17 02:59:37,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:38,047][root][INFO] - Training Epoch: 2/2, step 4546/7134 completed (loss: 0.07026129961013794, acc: 0.9865546226501465)
[2024-12-17 02:59:38,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:38,372][root][INFO] - Training Epoch: 2/2, step 4547/7134 completed (loss: 0.02548692747950554, acc: 0.991349458694458)
[2024-12-17 02:59:38,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:38,724][root][INFO] - Training Epoch: 2/2, step 4548/7134 completed (loss: 0.03998591750860214, acc: 0.9900497794151306)
[2024-12-17 02:59:38,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:39,019][root][INFO] - Training Epoch: 2/2, step 4549/7134 completed (loss: 0.05447982996702194, acc: 0.9849785566329956)
[2024-12-17 02:59:39,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:39,374][root][INFO] - Training Epoch: 2/2, step 4550/7134 completed (loss: 0.07308287918567657, acc: 0.9865996837615967)
[2024-12-17 02:59:39,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:39,695][root][INFO] - Training Epoch: 2/2, step 4551/7134 completed (loss: 0.04733835533261299, acc: 0.9885714054107666)
[2024-12-17 02:59:39,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:40,015][root][INFO] - Training Epoch: 2/2, step 4552/7134 completed (loss: 0.034981392323970795, acc: 0.9904761910438538)
[2024-12-17 02:59:40,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:40,325][root][INFO] - Training Epoch: 2/2, step 4553/7134 completed (loss: 0.052896227687597275, acc: 0.9847715497016907)
[2024-12-17 02:59:40,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:40,642][root][INFO] - Training Epoch: 2/2, step 4554/7134 completed (loss: 0.05341753736138344, acc: 0.9873873591423035)
[2024-12-17 02:59:40,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:40,971][root][INFO] - Training Epoch: 2/2, step 4555/7134 completed (loss: 0.06790092587471008, acc: 0.9806094169616699)
[2024-12-17 02:59:41,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:41,334][root][INFO] - Training Epoch: 2/2, step 4556/7134 completed (loss: 0.06666185706853867, acc: 0.9759398698806763)
[2024-12-17 02:59:41,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:41,614][root][INFO] - Training Epoch: 2/2, step 4557/7134 completed (loss: 0.07050447165966034, acc: 0.985401451587677)
[2024-12-17 02:59:41,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:41,936][root][INFO] - Training Epoch: 2/2, step 4558/7134 completed (loss: 0.052067238837480545, acc: 0.9882155060768127)
[2024-12-17 02:59:42,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:42,273][root][INFO] - Training Epoch: 2/2, step 4559/7134 completed (loss: 0.07200747728347778, acc: 0.9831932783126831)
[2024-12-17 02:59:42,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:42,594][root][INFO] - Training Epoch: 2/2, step 4560/7134 completed (loss: 0.047249265015125275, acc: 0.9873188138008118)
[2024-12-17 02:59:42,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:42,912][root][INFO] - Training Epoch: 2/2, step 4561/7134 completed (loss: 0.06681413948535919, acc: 0.9843137264251709)
[2024-12-17 02:59:43,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:43,230][root][INFO] - Training Epoch: 2/2, step 4562/7134 completed (loss: 0.05179823935031891, acc: 0.9852670431137085)
[2024-12-17 02:59:43,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:43,582][root][INFO] - Training Epoch: 2/2, step 4563/7134 completed (loss: 0.03311929479241371, acc: 0.9938931465148926)
[2024-12-17 02:59:43,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:43,943][root][INFO] - Training Epoch: 2/2, step 4564/7134 completed (loss: 0.06342901289463043, acc: 0.9844852089881897)
[2024-12-17 02:59:44,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:44,251][root][INFO] - Training Epoch: 2/2, step 4565/7134 completed (loss: 0.055665839463472366, acc: 0.9847036600112915)
[2024-12-17 02:59:44,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:44,583][root][INFO] - Training Epoch: 2/2, step 4566/7134 completed (loss: 0.0436905100941658, acc: 0.9856630563735962)
[2024-12-17 02:59:44,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:44,891][root][INFO] - Training Epoch: 2/2, step 4567/7134 completed (loss: 0.021666154265403748, acc: 0.9926470518112183)
[2024-12-17 02:59:45,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:45,191][root][INFO] - Training Epoch: 2/2, step 4568/7134 completed (loss: 0.04214081913232803, acc: 0.9908257126808167)
[2024-12-17 02:59:45,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:45,523][root][INFO] - Training Epoch: 2/2, step 4569/7134 completed (loss: 0.025150636211037636, acc: 0.9921568632125854)
[2024-12-17 02:59:45,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:45,850][root][INFO] - Training Epoch: 2/2, step 4570/7134 completed (loss: 0.02738240547478199, acc: 0.9927113652229309)
[2024-12-17 02:59:45,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:46,198][root][INFO] - Training Epoch: 2/2, step 4571/7134 completed (loss: 0.04120912775397301, acc: 0.9910141229629517)
[2024-12-17 02:59:46,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:46,529][root][INFO] - Training Epoch: 2/2, step 4572/7134 completed (loss: 0.06048162654042244, acc: 0.9828660488128662)
[2024-12-17 02:59:46,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:46,872][root][INFO] - Training Epoch: 2/2, step 4573/7134 completed (loss: 0.04174089804291725, acc: 0.9901960492134094)
[2024-12-17 02:59:47,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:47,223][root][INFO] - Training Epoch: 2/2, step 4574/7134 completed (loss: 0.01981988735496998, acc: 0.9946996569633484)
[2024-12-17 02:59:47,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:47,569][root][INFO] - Training Epoch: 2/2, step 4575/7134 completed (loss: 0.051834892481565475, acc: 0.9880319237709045)
[2024-12-17 02:59:47,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:47,907][root][INFO] - Training Epoch: 2/2, step 4576/7134 completed (loss: 0.019414151087403297, acc: 0.9962359070777893)
[2024-12-17 02:59:47,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:48,240][root][INFO] - Training Epoch: 2/2, step 4577/7134 completed (loss: 0.03742547333240509, acc: 0.9859550595283508)
[2024-12-17 02:59:48,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:48,569][root][INFO] - Training Epoch: 2/2, step 4578/7134 completed (loss: 0.026109129190444946, acc: 0.9927219748497009)
[2024-12-17 02:59:48,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:48,891][root][INFO] - Training Epoch: 2/2, step 4579/7134 completed (loss: 0.0651896744966507, acc: 0.9873217344284058)
[2024-12-17 02:59:48,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:49,221][root][INFO] - Training Epoch: 2/2, step 4580/7134 completed (loss: 0.025411788374185562, acc: 0.9940298795700073)
[2024-12-17 02:59:49,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:49,566][root][INFO] - Training Epoch: 2/2, step 4581/7134 completed (loss: 0.037647753953933716, acc: 0.9876543283462524)
[2024-12-17 02:59:49,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:49,909][root][INFO] - Training Epoch: 2/2, step 4582/7134 completed (loss: 0.029832923784852028, acc: 0.9868420958518982)
[2024-12-17 02:59:50,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:50,227][root][INFO] - Training Epoch: 2/2, step 4583/7134 completed (loss: 0.029403463006019592, acc: 0.9869281053543091)
[2024-12-17 02:59:50,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:50,572][root][INFO] - Training Epoch: 2/2, step 4584/7134 completed (loss: 0.031228769570589066, acc: 0.990338146686554)
[2024-12-17 02:59:50,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:50,921][root][INFO] - Training Epoch: 2/2, step 4585/7134 completed (loss: 0.03154689073562622, acc: 0.9870550036430359)
[2024-12-17 02:59:51,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:51,297][root][INFO] - Training Epoch: 2/2, step 4586/7134 completed (loss: 0.041102297604084015, acc: 0.9856957197189331)
[2024-12-17 02:59:51,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:51,646][root][INFO] - Training Epoch: 2/2, step 4587/7134 completed (loss: 0.03023013472557068, acc: 0.9931507110595703)
[2024-12-17 02:59:51,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:51,991][root][INFO] - Training Epoch: 2/2, step 4588/7134 completed (loss: 0.06748940795660019, acc: 0.9811046719551086)
[2024-12-17 02:59:52,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:52,309][root][INFO] - Training Epoch: 2/2, step 4589/7134 completed (loss: 0.0760415643453598, acc: 0.9805389046669006)
[2024-12-17 02:59:52,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:52,654][root][INFO] - Training Epoch: 2/2, step 4590/7134 completed (loss: 0.0487852618098259, acc: 0.988950252532959)
[2024-12-17 02:59:52,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:52,998][root][INFO] - Training Epoch: 2/2, step 4591/7134 completed (loss: 0.0372685082256794, acc: 0.9881266355514526)
[2024-12-17 02:59:53,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:53,322][root][INFO] - Training Epoch: 2/2, step 4592/7134 completed (loss: 0.04114029183983803, acc: 0.9883889555931091)
[2024-12-17 02:59:53,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:53,665][root][INFO] - Training Epoch: 2/2, step 4593/7134 completed (loss: 0.04409368708729744, acc: 0.9896296262741089)
[2024-12-17 02:59:53,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:54,045][root][INFO] - Training Epoch: 2/2, step 4594/7134 completed (loss: 0.0510709285736084, acc: 0.9786666631698608)
[2024-12-17 02:59:54,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:54,409][root][INFO] - Training Epoch: 2/2, step 4595/7134 completed (loss: 0.030032020062208176, acc: 0.9881129264831543)
[2024-12-17 02:59:54,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:54,742][root][INFO] - Training Epoch: 2/2, step 4596/7134 completed (loss: 0.06850753724575043, acc: 0.9793650507926941)
[2024-12-17 02:59:54,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:55,088][root][INFO] - Training Epoch: 2/2, step 4597/7134 completed (loss: 0.036529429256916046, acc: 0.9902794361114502)
[2024-12-17 02:59:55,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:55,447][root][INFO] - Training Epoch: 2/2, step 4598/7134 completed (loss: 0.055382564663887024, acc: 0.9889570474624634)
[2024-12-17 02:59:55,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:55,769][root][INFO] - Training Epoch: 2/2, step 4599/7134 completed (loss: 0.02701985463500023, acc: 0.9936407208442688)
[2024-12-17 02:59:55,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:56,114][root][INFO] - Training Epoch: 2/2, step 4600/7134 completed (loss: 0.03137418255209923, acc: 0.9851149916648865)
[2024-12-17 02:59:56,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:56,497][root][INFO] - Training Epoch: 2/2, step 4601/7134 completed (loss: 0.04417037591338158, acc: 0.9869621992111206)
[2024-12-17 02:59:56,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:56,855][root][INFO] - Training Epoch: 2/2, step 4602/7134 completed (loss: 0.051225677132606506, acc: 0.9904631972312927)
[2024-12-17 02:59:56,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:57,205][root][INFO] - Training Epoch: 2/2, step 4603/7134 completed (loss: 0.0502166748046875, acc: 0.9875862002372742)
[2024-12-17 02:59:57,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:57,539][root][INFO] - Training Epoch: 2/2, step 4604/7134 completed (loss: 0.028177257627248764, acc: 0.9887640476226807)
[2024-12-17 02:59:57,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:57,880][root][INFO] - Training Epoch: 2/2, step 4605/7134 completed (loss: 0.0570247583091259, acc: 0.9847161769866943)
[2024-12-17 02:59:58,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:58,229][root][INFO] - Training Epoch: 2/2, step 4606/7134 completed (loss: 0.018583979457616806, acc: 0.9923547506332397)
[2024-12-17 02:59:58,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:58,532][root][INFO] - Training Epoch: 2/2, step 4607/7134 completed (loss: 0.015166025608778, acc: 0.9949495196342468)
[2024-12-17 02:59:58,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:58,873][root][INFO] - Training Epoch: 2/2, step 4608/7134 completed (loss: 0.016341041773557663, acc: 0.9940740466117859)
[2024-12-17 02:59:59,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:59,212][root][INFO] - Training Epoch: 2/2, step 4609/7134 completed (loss: 0.020854735746979713, acc: 0.9926605224609375)
[2024-12-17 02:59:59,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:59,557][root][INFO] - Training Epoch: 2/2, step 4610/7134 completed (loss: 0.027847586199641228, acc: 0.9867197871208191)
[2024-12-17 02:59:59,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:59,897][root][INFO] - Training Epoch: 2/2, step 4611/7134 completed (loss: 0.016811426728963852, acc: 0.9953051805496216)
[2024-12-17 03:00:00,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:00,199][root][INFO] - Training Epoch: 2/2, step 4612/7134 completed (loss: 0.025362959131598473, acc: 0.9869888424873352)
[2024-12-17 03:00:00,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:00,521][root][INFO] - Training Epoch: 2/2, step 4613/7134 completed (loss: 0.025960393249988556, acc: 0.9930555820465088)
[2024-12-17 03:00:00,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:00,839][root][INFO] - Training Epoch: 2/2, step 4614/7134 completed (loss: 0.03566322475671768, acc: 0.9905303120613098)
[2024-12-17 03:00:00,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:01,200][root][INFO] - Training Epoch: 2/2, step 4615/7134 completed (loss: 0.055927153676748276, acc: 0.9796472191810608)
[2024-12-17 03:00:01,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:01,534][root][INFO] - Training Epoch: 2/2, step 4616/7134 completed (loss: 0.07469489425420761, acc: 0.9748520851135254)
[2024-12-17 03:00:01,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:01,844][root][INFO] - Training Epoch: 2/2, step 4617/7134 completed (loss: 0.03904195874929428, acc: 0.9834834933280945)
[2024-12-17 03:00:01,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:02,175][root][INFO] - Training Epoch: 2/2, step 4618/7134 completed (loss: 0.03588419407606125, acc: 0.9883494973182678)
[2024-12-17 03:00:02,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:02,532][root][INFO] - Training Epoch: 2/2, step 4619/7134 completed (loss: 0.021079357713460922, acc: 0.9969834089279175)
[2024-12-17 03:00:02,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:02,875][root][INFO] - Training Epoch: 2/2, step 4620/7134 completed (loss: 0.022205093875527382, acc: 0.9927536249160767)
[2024-12-17 03:00:02,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:03,204][root][INFO] - Training Epoch: 2/2, step 4621/7134 completed (loss: 0.01842929981648922, acc: 0.9953703880310059)
[2024-12-17 03:00:03,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:03,581][root][INFO] - Training Epoch: 2/2, step 4622/7134 completed (loss: 0.07374146580696106, acc: 0.9862671494483948)
[2024-12-17 03:00:03,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:03,955][root][INFO] - Training Epoch: 2/2, step 4623/7134 completed (loss: 0.05286988243460655, acc: 0.9869281053543091)
[2024-12-17 03:00:04,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:04,398][root][INFO] - Training Epoch: 2/2, step 4624/7134 completed (loss: 0.08118459582328796, acc: 0.9794238805770874)
[2024-12-17 03:00:04,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:04,743][root][INFO] - Training Epoch: 2/2, step 4625/7134 completed (loss: 0.12084677815437317, acc: 0.9737274050712585)
[2024-12-17 03:00:04,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:05,115][root][INFO] - Training Epoch: 2/2, step 4626/7134 completed (loss: 0.06506014615297318, acc: 0.9879194498062134)
[2024-12-17 03:00:05,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:05,458][root][INFO] - Training Epoch: 2/2, step 4627/7134 completed (loss: 0.086517833173275, acc: 0.9772382378578186)
[2024-12-17 03:00:05,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:05,822][root][INFO] - Training Epoch: 2/2, step 4628/7134 completed (loss: 0.06020236387848854, acc: 0.9826086759567261)
[2024-12-17 03:00:05,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:06,171][root][INFO] - Training Epoch: 2/2, step 4629/7134 completed (loss: 0.0871773287653923, acc: 0.9743589758872986)
[2024-12-17 03:00:06,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:06,544][root][INFO] - Training Epoch: 2/2, step 4630/7134 completed (loss: 0.06685888767242432, acc: 0.9881109595298767)
[2024-12-17 03:00:06,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:06,907][root][INFO] - Training Epoch: 2/2, step 4631/7134 completed (loss: 0.04696335271000862, acc: 0.9856194853782654)
[2024-12-17 03:00:07,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:07,292][root][INFO] - Training Epoch: 2/2, step 4632/7134 completed (loss: 0.0656764954328537, acc: 0.9838235378265381)
[2024-12-17 03:00:07,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:07,644][root][INFO] - Training Epoch: 2/2, step 4633/7134 completed (loss: 0.07835868746042252, acc: 0.981502890586853)
[2024-12-17 03:00:07,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:07,978][root][INFO] - Training Epoch: 2/2, step 4634/7134 completed (loss: 0.03808002918958664, acc: 0.9902912378311157)
[2024-12-17 03:00:08,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:08,298][root][INFO] - Training Epoch: 2/2, step 4635/7134 completed (loss: 0.07112014293670654, acc: 0.980182945728302)
[2024-12-17 03:00:08,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:08,566][root][INFO] - Training Epoch: 2/2, step 4636/7134 completed (loss: 0.02255174145102501, acc: 0.9974226951599121)
[2024-12-17 03:00:08,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:08,913][root][INFO] - Training Epoch: 2/2, step 4637/7134 completed (loss: 0.06915589421987534, acc: 0.9818548560142517)
[2024-12-17 03:00:09,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:09,263][root][INFO] - Training Epoch: 2/2, step 4638/7134 completed (loss: 0.04928787797689438, acc: 0.9841479659080505)
[2024-12-17 03:00:09,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:09,609][root][INFO] - Training Epoch: 2/2, step 4639/7134 completed (loss: 0.04909541457891464, acc: 0.9914841651916504)
[2024-12-17 03:00:09,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:09,986][root][INFO] - Training Epoch: 2/2, step 4640/7134 completed (loss: 0.06759200245141983, acc: 0.9833333492279053)
[2024-12-17 03:00:10,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:10,327][root][INFO] - Training Epoch: 2/2, step 4641/7134 completed (loss: 0.03519206866621971, acc: 0.9900568127632141)
[2024-12-17 03:00:10,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:10,672][root][INFO] - Training Epoch: 2/2, step 4642/7134 completed (loss: 0.015021600760519505, acc: 0.9960317611694336)
[2024-12-17 03:00:10,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:11,035][root][INFO] - Training Epoch: 2/2, step 4643/7134 completed (loss: 0.040103450417518616, acc: 0.9905325174331665)
[2024-12-17 03:00:11,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:11,410][root][INFO] - Training Epoch: 2/2, step 4644/7134 completed (loss: 0.026268385350704193, acc: 0.9928994178771973)
[2024-12-17 03:00:11,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:11,780][root][INFO] - Training Epoch: 2/2, step 4645/7134 completed (loss: 0.027491603046655655, acc: 0.9944367408752441)
[2024-12-17 03:00:11,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:12,157][root][INFO] - Training Epoch: 2/2, step 4646/7134 completed (loss: 0.021664291620254517, acc: 0.9952903985977173)
[2024-12-17 03:00:12,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:12,530][root][INFO] - Training Epoch: 2/2, step 4647/7134 completed (loss: 0.07108099013566971, acc: 0.9869791865348816)
[2024-12-17 03:00:12,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:12,887][root][INFO] - Training Epoch: 2/2, step 4648/7134 completed (loss: 0.043610528111457825, acc: 0.9876543283462524)
[2024-12-17 03:00:13,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:13,250][root][INFO] - Training Epoch: 2/2, step 4649/7134 completed (loss: 0.052860792726278305, acc: 0.9912434220314026)
[2024-12-17 03:00:13,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:13,618][root][INFO] - Training Epoch: 2/2, step 4650/7134 completed (loss: 0.0553475059568882, acc: 0.9821428656578064)
[2024-12-17 03:00:13,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:13,977][root][INFO] - Training Epoch: 2/2, step 4651/7134 completed (loss: 0.13559868931770325, acc: 0.963244616985321)
[2024-12-17 03:00:14,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:14,323][root][INFO] - Training Epoch: 2/2, step 4652/7134 completed (loss: 0.05462292209267616, acc: 0.9847561120986938)
[2024-12-17 03:00:14,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:14,711][root][INFO] - Training Epoch: 2/2, step 4653/7134 completed (loss: 0.07314036041498184, acc: 0.9817204475402832)
[2024-12-17 03:00:14,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:15,069][root][INFO] - Training Epoch: 2/2, step 4654/7134 completed (loss: 0.10195448249578476, acc: 0.9744214415550232)
[2024-12-17 03:00:15,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:15,418][root][INFO] - Training Epoch: 2/2, step 4655/7134 completed (loss: 0.05377920717000961, acc: 0.9876881241798401)
[2024-12-17 03:00:15,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:15,782][root][INFO] - Training Epoch: 2/2, step 4656/7134 completed (loss: 0.044623974710702896, acc: 0.9848484992980957)
[2024-12-17 03:00:15,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:16,115][root][INFO] - Training Epoch: 2/2, step 4657/7134 completed (loss: 0.0717434361577034, acc: 0.9844192862510681)
[2024-12-17 03:00:16,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:16,447][root][INFO] - Training Epoch: 2/2, step 4658/7134 completed (loss: 0.0619647279381752, acc: 0.9783491492271423)
[2024-12-17 03:00:16,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:16,809][root][INFO] - Training Epoch: 2/2, step 4659/7134 completed (loss: 0.10156980901956558, acc: 0.980719804763794)
[2024-12-17 03:00:16,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:17,163][root][INFO] - Training Epoch: 2/2, step 4660/7134 completed (loss: 0.08279266208410263, acc: 0.9780564308166504)
[2024-12-17 03:00:17,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:17,478][root][INFO] - Training Epoch: 2/2, step 4661/7134 completed (loss: 0.05375220254063606, acc: 0.9878048896789551)
[2024-12-17 03:00:17,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:17,801][root][INFO] - Training Epoch: 2/2, step 4662/7134 completed (loss: 0.10848104953765869, acc: 0.9812925457954407)
[2024-12-17 03:00:17,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:18,163][root][INFO] - Training Epoch: 2/2, step 4663/7134 completed (loss: 0.07052632421255112, acc: 0.9799465537071228)
[2024-12-17 03:00:18,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:18,533][root][INFO] - Training Epoch: 2/2, step 4664/7134 completed (loss: 0.04190339148044586, acc: 0.9920739531517029)
[2024-12-17 03:00:18,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:18,884][root][INFO] - Training Epoch: 2/2, step 4665/7134 completed (loss: 0.037492383271455765, acc: 0.9849931597709656)
[2024-12-17 03:00:19,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:19,283][root][INFO] - Training Epoch: 2/2, step 4666/7134 completed (loss: 0.059453319758176804, acc: 0.9843546152114868)
[2024-12-17 03:00:19,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:19,601][root][INFO] - Training Epoch: 2/2, step 4667/7134 completed (loss: 0.07271333038806915, acc: 0.977624773979187)
[2024-12-17 03:00:19,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:19,928][root][INFO] - Training Epoch: 2/2, step 4668/7134 completed (loss: 0.03405778110027313, acc: 0.9856630563735962)
[2024-12-17 03:00:20,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:20,271][root][INFO] - Training Epoch: 2/2, step 4669/7134 completed (loss: 0.036581605672836304, acc: 0.9896449446678162)
[2024-12-17 03:00:20,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:20,593][root][INFO] - Training Epoch: 2/2, step 4670/7134 completed (loss: 0.08708293735980988, acc: 0.9766082167625427)
[2024-12-17 03:00:20,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:20,925][root][INFO] - Training Epoch: 2/2, step 4671/7134 completed (loss: 0.06628942489624023, acc: 0.9802538752555847)
[2024-12-17 03:00:21,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:21,246][root][INFO] - Training Epoch: 2/2, step 4672/7134 completed (loss: 0.07756658643484116, acc: 0.9773519039154053)
[2024-12-17 03:00:21,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:21,575][root][INFO] - Training Epoch: 2/2, step 4673/7134 completed (loss: 0.0598599798977375, acc: 0.9812792539596558)
[2024-12-17 03:00:21,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:21,912][root][INFO] - Training Epoch: 2/2, step 4674/7134 completed (loss: 0.05616426095366478, acc: 0.9841521382331848)
[2024-12-17 03:00:22,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:22,267][root][INFO] - Training Epoch: 2/2, step 4675/7134 completed (loss: 0.047482579946517944, acc: 0.987261176109314)
[2024-12-17 03:00:22,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:22,596][root][INFO] - Training Epoch: 2/2, step 4676/7134 completed (loss: 0.041347846388816833, acc: 0.9864457845687866)
[2024-12-17 03:00:22,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:22,906][root][INFO] - Training Epoch: 2/2, step 4677/7134 completed (loss: 0.05467616766691208, acc: 0.9868420958518982)
[2024-12-17 03:00:23,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:23,240][root][INFO] - Training Epoch: 2/2, step 4678/7134 completed (loss: 0.0911221131682396, acc: 0.9762258529663086)
[2024-12-17 03:00:23,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:23,584][root][INFO] - Training Epoch: 2/2, step 4679/7134 completed (loss: 0.038716647773981094, acc: 0.9917241334915161)
[2024-12-17 03:00:23,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:23,906][root][INFO] - Training Epoch: 2/2, step 4680/7134 completed (loss: 0.08005391061306, acc: 0.9813084006309509)
[2024-12-17 03:00:24,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:24,240][root][INFO] - Training Epoch: 2/2, step 4681/7134 completed (loss: 0.05276218056678772, acc: 0.9861538410186768)
[2024-12-17 03:00:24,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:24,619][root][INFO] - Training Epoch: 2/2, step 4682/7134 completed (loss: 0.034714799374341965, acc: 0.9902676343917847)
[2024-12-17 03:00:24,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:24,943][root][INFO] - Training Epoch: 2/2, step 4683/7134 completed (loss: 0.040274154394865036, acc: 0.984308123588562)
[2024-12-17 03:00:25,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:25,313][root][INFO] - Training Epoch: 2/2, step 4684/7134 completed (loss: 0.06455355137586594, acc: 0.9821802973747253)
[2024-12-17 03:00:25,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:25,677][root][INFO] - Training Epoch: 2/2, step 4685/7134 completed (loss: 0.03550725430250168, acc: 0.9918032884597778)
[2024-12-17 03:00:25,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:26,055][root][INFO] - Training Epoch: 2/2, step 4686/7134 completed (loss: 0.03879933804273605, acc: 0.9895226955413818)
[2024-12-17 03:00:26,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:26,326][root][INFO] - Training Epoch: 2/2, step 4687/7134 completed (loss: 0.18294250965118408, acc: 0.9570552110671997)
[2024-12-17 03:00:26,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:26,683][root][INFO] - Training Epoch: 2/2, step 4688/7134 completed (loss: 0.25591644644737244, acc: 0.9404517412185669)
[2024-12-17 03:00:26,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:27,052][root][INFO] - Training Epoch: 2/2, step 4689/7134 completed (loss: 0.1709585338830948, acc: 0.9528718590736389)
[2024-12-17 03:00:27,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:27,411][root][INFO] - Training Epoch: 2/2, step 4690/7134 completed (loss: 0.11356905847787857, acc: 0.9790356159210205)
[2024-12-17 03:00:27,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:27,754][root][INFO] - Training Epoch: 2/2, step 4691/7134 completed (loss: 0.04969489574432373, acc: 0.9852607846260071)
[2024-12-17 03:00:27,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:28,023][root][INFO] - Training Epoch: 2/2, step 4692/7134 completed (loss: 0.14382915198802948, acc: 0.9596602916717529)
[2024-12-17 03:00:28,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:28,425][root][INFO] - Training Epoch: 2/2, step 4693/7134 completed (loss: 0.21216559410095215, acc: 0.9443609118461609)
[2024-12-17 03:00:28,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:28,742][root][INFO] - Training Epoch: 2/2, step 4694/7134 completed (loss: 0.19768111407756805, acc: 0.9553752541542053)
[2024-12-17 03:00:28,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:29,082][root][INFO] - Training Epoch: 2/2, step 4695/7134 completed (loss: 0.08206500113010406, acc: 0.9819375872612)
[2024-12-17 03:00:29,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:29,432][root][INFO] - Training Epoch: 2/2, step 4696/7134 completed (loss: 0.03760410472750664, acc: 0.98959881067276)
[2024-12-17 03:00:29,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:29,743][root][INFO] - Training Epoch: 2/2, step 4697/7134 completed (loss: 0.0629069060087204, acc: 0.981203019618988)
[2024-12-17 03:00:29,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:30,058][root][INFO] - Training Epoch: 2/2, step 4698/7134 completed (loss: 0.13155357539653778, acc: 0.9790076613426208)
[2024-12-17 03:00:30,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:30,425][root][INFO] - Training Epoch: 2/2, step 4699/7134 completed (loss: 0.058545950800180435, acc: 0.9853747487068176)
[2024-12-17 03:00:30,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:30,780][root][INFO] - Training Epoch: 2/2, step 4700/7134 completed (loss: 0.06081856042146683, acc: 0.9821162223815918)
[2024-12-17 03:00:30,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:31,075][root][INFO] - Training Epoch: 2/2, step 4701/7134 completed (loss: 0.09185130894184113, acc: 0.9648562073707581)
[2024-12-17 03:00:31,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:31,444][root][INFO] - Training Epoch: 2/2, step 4702/7134 completed (loss: 0.05498643219470978, acc: 0.9824841022491455)
[2024-12-17 03:00:31,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:31,802][root][INFO] - Training Epoch: 2/2, step 4703/7134 completed (loss: 0.0713593065738678, acc: 0.9864864945411682)
[2024-12-17 03:00:31,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:32,136][root][INFO] - Training Epoch: 2/2, step 4704/7134 completed (loss: 0.031261686235666275, acc: 0.9906213283538818)
[2024-12-17 03:00:32,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:32,493][root][INFO] - Training Epoch: 2/2, step 4705/7134 completed (loss: 0.03799533098936081, acc: 0.9871345162391663)
[2024-12-17 03:00:32,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:32,883][root][INFO] - Training Epoch: 2/2, step 4706/7134 completed (loss: 0.07644276320934296, acc: 0.9797507524490356)
[2024-12-17 03:00:32,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:33,214][root][INFO] - Training Epoch: 2/2, step 4707/7134 completed (loss: 0.2444300800561905, acc: 0.9438775777816772)
[2024-12-17 03:00:33,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:33,546][root][INFO] - Training Epoch: 2/2, step 4708/7134 completed (loss: 0.03348415717482567, acc: 0.9887780547142029)
[2024-12-17 03:00:33,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:33,903][root][INFO] - Training Epoch: 2/2, step 4709/7134 completed (loss: 0.029580535367131233, acc: 0.9934123754501343)
[2024-12-17 03:00:33,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:34,256][root][INFO] - Training Epoch: 2/2, step 4710/7134 completed (loss: 0.054778534919023514, acc: 0.9854439496994019)
[2024-12-17 03:00:34,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:34,645][root][INFO] - Training Epoch: 2/2, step 4711/7134 completed (loss: 0.09793314337730408, acc: 0.9677419066429138)
[2024-12-17 03:00:34,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:34,975][root][INFO] - Training Epoch: 2/2, step 4712/7134 completed (loss: 0.12475739419460297, acc: 0.9651514887809753)
[2024-12-17 03:00:35,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:35,337][root][INFO] - Training Epoch: 2/2, step 4713/7134 completed (loss: 0.050626177340745926, acc: 0.9839285612106323)
[2024-12-17 03:00:35,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:35,651][root][INFO] - Training Epoch: 2/2, step 4714/7134 completed (loss: 0.0894564539194107, acc: 0.9794392585754395)
[2024-12-17 03:00:35,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:35,986][root][INFO] - Training Epoch: 2/2, step 4715/7134 completed (loss: 0.11364944279193878, acc: 0.968017041683197)
[2024-12-17 03:00:36,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:36,300][root][INFO] - Training Epoch: 2/2, step 4716/7134 completed (loss: 0.017401613295078278, acc: 0.9939024448394775)
[2024-12-17 03:00:36,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:36,622][root][INFO] - Training Epoch: 2/2, step 4717/7134 completed (loss: 0.042590830475091934, acc: 0.9911110997200012)
[2024-12-17 03:00:36,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:36,955][root][INFO] - Training Epoch: 2/2, step 4718/7134 completed (loss: 0.030618462711572647, acc: 0.9850993156433105)
[2024-12-17 03:00:37,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:37,295][root][INFO] - Training Epoch: 2/2, step 4719/7134 completed (loss: 0.0345451794564724, acc: 0.991150438785553)
[2024-12-17 03:00:37,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:37,637][root][INFO] - Training Epoch: 2/2, step 4720/7134 completed (loss: 0.008743143640458584, acc: 0.9971949458122253)
[2024-12-17 03:00:37,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:37,953][root][INFO] - Training Epoch: 2/2, step 4721/7134 completed (loss: 0.01773145981132984, acc: 0.9942362904548645)
[2024-12-17 03:00:38,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:38,289][root][INFO] - Training Epoch: 2/2, step 4722/7134 completed (loss: 0.01833837665617466, acc: 0.9955621361732483)
[2024-12-17 03:00:38,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:38,618][root][INFO] - Training Epoch: 2/2, step 4723/7134 completed (loss: 0.017928346991539, acc: 0.9954268336296082)
[2024-12-17 03:00:38,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:38,988][root][INFO] - Training Epoch: 2/2, step 4724/7134 completed (loss: 0.03070603311061859, acc: 0.9911242723464966)
[2024-12-17 03:00:39,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:39,332][root][INFO] - Training Epoch: 2/2, step 4725/7134 completed (loss: 0.014435093849897385, acc: 0.9960421919822693)
[2024-12-17 03:00:39,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:39,682][root][INFO] - Training Epoch: 2/2, step 4726/7134 completed (loss: 0.0621948279440403, acc: 0.9829787015914917)
[2024-12-17 03:00:39,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:40,008][root][INFO] - Training Epoch: 2/2, step 4727/7134 completed (loss: 0.028905600309371948, acc: 0.9937304258346558)
[2024-12-17 03:00:40,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:40,341][root][INFO] - Training Epoch: 2/2, step 4728/7134 completed (loss: 0.052022069692611694, acc: 0.9884678721427917)
[2024-12-17 03:00:40,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:40,671][root][INFO] - Training Epoch: 2/2, step 4729/7134 completed (loss: 0.019253673031926155, acc: 0.9957746267318726)
[2024-12-17 03:00:40,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:41,009][root][INFO] - Training Epoch: 2/2, step 4730/7134 completed (loss: 0.024588659405708313, acc: 0.9938744306564331)
[2024-12-17 03:00:41,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:41,336][root][INFO] - Training Epoch: 2/2, step 4731/7134 completed (loss: 0.04956080764532089, acc: 0.9877862334251404)
[2024-12-17 03:00:41,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:41,661][root][INFO] - Training Epoch: 2/2, step 4732/7134 completed (loss: 0.07336635887622833, acc: 0.9800363183021545)
[2024-12-17 03:00:41,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:42,009][root][INFO] - Training Epoch: 2/2, step 4733/7134 completed (loss: 0.01479940302670002, acc: 0.9951534867286682)
[2024-12-17 03:00:42,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:42,358][root][INFO] - Training Epoch: 2/2, step 4734/7134 completed (loss: 0.05230853706598282, acc: 0.9809221029281616)
[2024-12-17 03:00:42,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:42,711][root][INFO] - Training Epoch: 2/2, step 4735/7134 completed (loss: 0.03662867471575737, acc: 0.9924924969673157)
[2024-12-17 03:00:42,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:43,005][root][INFO] - Training Epoch: 2/2, step 4736/7134 completed (loss: 0.05636870115995407, acc: 0.990138053894043)
[2024-12-17 03:00:43,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:43,347][root][INFO] - Training Epoch: 2/2, step 4737/7134 completed (loss: 0.047148607671260834, acc: 0.9890282154083252)
[2024-12-17 03:00:43,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:43,676][root][INFO] - Training Epoch: 2/2, step 4738/7134 completed (loss: 0.028113050386309624, acc: 0.9924127459526062)
[2024-12-17 03:00:43,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:44,017][root][INFO] - Training Epoch: 2/2, step 4739/7134 completed (loss: 0.10866257548332214, acc: 0.969648540019989)
[2024-12-17 03:00:44,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:44,365][root][INFO] - Training Epoch: 2/2, step 4740/7134 completed (loss: 0.09283333271741867, acc: 0.977544903755188)
[2024-12-17 03:00:44,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:44,655][root][INFO] - Training Epoch: 2/2, step 4741/7134 completed (loss: 0.09087534993886948, acc: 0.975970447063446)
[2024-12-17 03:00:44,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:44,982][root][INFO] - Training Epoch: 2/2, step 4742/7134 completed (loss: 0.13077688217163086, acc: 0.9681416153907776)
[2024-12-17 03:00:45,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:45,327][root][INFO] - Training Epoch: 2/2, step 4743/7134 completed (loss: 0.05426895618438721, acc: 0.9804270267486572)
[2024-12-17 03:00:45,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:45,598][root][INFO] - Training Epoch: 2/2, step 4744/7134 completed (loss: 0.04331982135772705, acc: 0.9876033067703247)
[2024-12-17 03:00:45,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:45,879][root][INFO] - Training Epoch: 2/2, step 4745/7134 completed (loss: 0.08287514001131058, acc: 0.9765886068344116)
[2024-12-17 03:00:46,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:46,205][root][INFO] - Training Epoch: 2/2, step 4746/7134 completed (loss: 0.07020041346549988, acc: 0.9816176295280457)
[2024-12-17 03:00:46,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:46,551][root][INFO] - Training Epoch: 2/2, step 4747/7134 completed (loss: 0.06788866966962814, acc: 0.9770580530166626)
[2024-12-17 03:00:46,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:46,908][root][INFO] - Training Epoch: 2/2, step 4748/7134 completed (loss: 0.08283061534166336, acc: 0.9734513163566589)
[2024-12-17 03:00:47,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:47,267][root][INFO] - Training Epoch: 2/2, step 4749/7134 completed (loss: 0.07459025830030441, acc: 0.9826666712760925)
[2024-12-17 03:00:47,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:47,608][root][INFO] - Training Epoch: 2/2, step 4750/7134 completed (loss: 0.11847734451293945, acc: 0.9710982441902161)
[2024-12-17 03:00:47,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:47,976][root][INFO] - Training Epoch: 2/2, step 4751/7134 completed (loss: 0.02630774863064289, acc: 0.9943422675132751)
[2024-12-17 03:00:48,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:48,327][root][INFO] - Training Epoch: 2/2, step 4752/7134 completed (loss: 0.07480427622795105, acc: 0.9877111911773682)
[2024-12-17 03:00:48,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:48,647][root][INFO] - Training Epoch: 2/2, step 4753/7134 completed (loss: 0.09167034924030304, acc: 0.9774096608161926)
[2024-12-17 03:00:48,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:48,982][root][INFO] - Training Epoch: 2/2, step 4754/7134 completed (loss: 0.04600128158926964, acc: 0.9867841601371765)
[2024-12-17 03:00:49,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:49,336][root][INFO] - Training Epoch: 2/2, step 4755/7134 completed (loss: 0.057851746678352356, acc: 0.9861303567886353)
[2024-12-17 03:00:49,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:49,656][root][INFO] - Training Epoch: 2/2, step 4756/7134 completed (loss: 0.08379320800304413, acc: 0.9811715483665466)
[2024-12-17 03:00:49,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:50,035][root][INFO] - Training Epoch: 2/2, step 4757/7134 completed (loss: 0.048324428498744965, acc: 0.9908151626586914)
[2024-12-17 03:00:50,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:50,380][root][INFO] - Training Epoch: 2/2, step 4758/7134 completed (loss: 0.05012952536344528, acc: 0.9887955188751221)
[2024-12-17 03:00:50,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:50,732][root][INFO] - Training Epoch: 2/2, step 4759/7134 completed (loss: 0.029746318235993385, acc: 0.9948275685310364)
[2024-12-17 03:00:50,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:51,070][root][INFO] - Training Epoch: 2/2, step 4760/7134 completed (loss: 0.05922333151102066, acc: 0.9896480441093445)
[2024-12-17 03:00:51,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:51,411][root][INFO] - Training Epoch: 2/2, step 4761/7134 completed (loss: 0.058268383145332336, acc: 0.9877862334251404)
[2024-12-17 03:00:51,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:51,759][root][INFO] - Training Epoch: 2/2, step 4762/7134 completed (loss: 0.07540511339902878, acc: 0.9824324250221252)
[2024-12-17 03:00:51,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:52,097][root][INFO] - Training Epoch: 2/2, step 4763/7134 completed (loss: 0.08090662956237793, acc: 0.9817629456520081)
[2024-12-17 03:00:52,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:52,452][root][INFO] - Training Epoch: 2/2, step 4764/7134 completed (loss: 0.07240821421146393, acc: 0.9851668477058411)
[2024-12-17 03:00:52,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:52,788][root][INFO] - Training Epoch: 2/2, step 4765/7134 completed (loss: 0.056121326982975006, acc: 0.9899280667304993)
[2024-12-17 03:00:52,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:53,140][root][INFO] - Training Epoch: 2/2, step 4766/7134 completed (loss: 0.055347293615341187, acc: 0.9897040128707886)
[2024-12-17 03:00:53,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:53,417][root][INFO] - Training Epoch: 2/2, step 4767/7134 completed (loss: 0.0581311471760273, acc: 0.9821882843971252)
[2024-12-17 03:00:53,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:53,789][root][INFO] - Training Epoch: 2/2, step 4768/7134 completed (loss: 0.0714031308889389, acc: 0.9837398529052734)
[2024-12-17 03:00:53,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:54,102][root][INFO] - Training Epoch: 2/2, step 4769/7134 completed (loss: 0.06958837062120438, acc: 0.9839486479759216)
[2024-12-17 03:00:54,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:54,421][root][INFO] - Training Epoch: 2/2, step 4770/7134 completed (loss: 0.015086975879967213, acc: 0.9959595799446106)
[2024-12-17 03:00:54,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:54,737][root][INFO] - Training Epoch: 2/2, step 4771/7134 completed (loss: 0.09903299808502197, acc: 0.9709302186965942)
[2024-12-17 03:00:54,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:55,061][root][INFO] - Training Epoch: 2/2, step 4772/7134 completed (loss: 0.08163662999868393, acc: 0.9856459498405457)
[2024-12-17 03:00:55,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:55,379][root][INFO] - Training Epoch: 2/2, step 4773/7134 completed (loss: 0.04716356843709946, acc: 0.9876712560653687)
[2024-12-17 03:00:55,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:55,688][root][INFO] - Training Epoch: 2/2, step 4774/7134 completed (loss: 0.054674308747053146, acc: 0.9901685118675232)
[2024-12-17 03:00:55,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:56,010][root][INFO] - Training Epoch: 2/2, step 4775/7134 completed (loss: 0.07580917328596115, acc: 0.9838969111442566)
[2024-12-17 03:00:56,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:56,353][root][INFO] - Training Epoch: 2/2, step 4776/7134 completed (loss: 0.06054694950580597, acc: 0.9855538010597229)
[2024-12-17 03:00:56,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:56,715][root][INFO] - Training Epoch: 2/2, step 4777/7134 completed (loss: 0.03836965933442116, acc: 0.989983320236206)
[2024-12-17 03:00:56,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:57,049][root][INFO] - Training Epoch: 2/2, step 4778/7134 completed (loss: 0.04417744278907776, acc: 0.9912472367286682)
[2024-12-17 03:00:57,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:57,409][root][INFO] - Training Epoch: 2/2, step 4779/7134 completed (loss: 0.0295872800052166, acc: 0.988950252532959)
[2024-12-17 03:00:57,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:57,767][root][INFO] - Training Epoch: 2/2, step 4780/7134 completed (loss: 0.023493513464927673, acc: 0.9922118186950684)
[2024-12-17 03:00:57,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:58,113][root][INFO] - Training Epoch: 2/2, step 4781/7134 completed (loss: 0.02642485499382019, acc: 0.9941291809082031)
[2024-12-17 03:00:58,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:58,458][root][INFO] - Training Epoch: 2/2, step 4782/7134 completed (loss: 0.017151400446891785, acc: 0.9935170412063599)
[2024-12-17 03:00:58,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:58,795][root][INFO] - Training Epoch: 2/2, step 4783/7134 completed (loss: 0.07749166339635849, acc: 0.9786477088928223)
[2024-12-17 03:00:58,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:59,159][root][INFO] - Training Epoch: 2/2, step 4784/7134 completed (loss: 0.03376771882176399, acc: 0.9918144345283508)
[2024-12-17 03:00:59,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:59,491][root][INFO] - Training Epoch: 2/2, step 4785/7134 completed (loss: 0.052973274141550064, acc: 0.9868913888931274)
[2024-12-17 03:00:59,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:59,826][root][INFO] - Training Epoch: 2/2, step 4786/7134 completed (loss: 0.06637639552354813, acc: 0.9829192757606506)
[2024-12-17 03:00:59,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:00,173][root][INFO] - Training Epoch: 2/2, step 4787/7134 completed (loss: 0.0189457219094038, acc: 0.9920886158943176)
[2024-12-17 03:01:00,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:00,509][root][INFO] - Training Epoch: 2/2, step 4788/7134 completed (loss: 0.016324833035469055, acc: 0.9929078221321106)
[2024-12-17 03:01:00,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:00,840][root][INFO] - Training Epoch: 2/2, step 4789/7134 completed (loss: 0.0531407929956913, acc: 0.987261176109314)
[2024-12-17 03:01:00,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:01,195][root][INFO] - Training Epoch: 2/2, step 4790/7134 completed (loss: 0.03418761119246483, acc: 0.99048912525177)
[2024-12-17 03:01:01,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:01,526][root][INFO] - Training Epoch: 2/2, step 4791/7134 completed (loss: 0.021583758294582367, acc: 0.9962756037712097)
[2024-12-17 03:01:01,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:01,872][root][INFO] - Training Epoch: 2/2, step 4792/7134 completed (loss: 0.03344598412513733, acc: 0.9899665713310242)
[2024-12-17 03:01:01,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:02,162][root][INFO] - Training Epoch: 2/2, step 4793/7134 completed (loss: 0.0855179950594902, acc: 0.9753424525260925)
[2024-12-17 03:01:02,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:02,505][root][INFO] - Training Epoch: 2/2, step 4794/7134 completed (loss: 0.09919049590826035, acc: 0.9714285731315613)
[2024-12-17 03:01:02,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:02,859][root][INFO] - Training Epoch: 2/2, step 4795/7134 completed (loss: 0.03504146635532379, acc: 0.9901130199432373)
[2024-12-17 03:01:02,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:03,182][root][INFO] - Training Epoch: 2/2, step 4796/7134 completed (loss: 0.03244626894593239, acc: 0.9921383857727051)
[2024-12-17 03:01:03,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:03,535][root][INFO] - Training Epoch: 2/2, step 4797/7134 completed (loss: 0.026212796568870544, acc: 0.9950310587882996)
[2024-12-17 03:01:03,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:03,866][root][INFO] - Training Epoch: 2/2, step 4798/7134 completed (loss: 0.04949947074055672, acc: 0.989347517490387)
[2024-12-17 03:01:03,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:04,228][root][INFO] - Training Epoch: 2/2, step 4799/7134 completed (loss: 0.03189413622021675, acc: 0.9900990128517151)
[2024-12-17 03:01:04,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:04,560][root][INFO] - Training Epoch: 2/2, step 4800/7134 completed (loss: 0.035704728215932846, acc: 0.9880775213241577)
[2024-12-17 03:01:04,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:04,924][root][INFO] - Training Epoch: 2/2, step 4801/7134 completed (loss: 0.023146087303757668, acc: 0.9943438768386841)
[2024-12-17 03:01:05,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:05,290][root][INFO] - Training Epoch: 2/2, step 4802/7134 completed (loss: 0.05860316753387451, acc: 0.981675386428833)
[2024-12-17 03:01:05,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:05,611][root][INFO] - Training Epoch: 2/2, step 4803/7134 completed (loss: 0.06872004270553589, acc: 0.9823529124259949)
[2024-12-17 03:01:05,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:05,967][root][INFO] - Training Epoch: 2/2, step 4804/7134 completed (loss: 0.05586127191781998, acc: 0.9815384745597839)
[2024-12-17 03:01:06,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:06,335][root][INFO] - Training Epoch: 2/2, step 4805/7134 completed (loss: 0.04327298700809479, acc: 0.9902912378311157)
[2024-12-17 03:01:06,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:06,685][root][INFO] - Training Epoch: 2/2, step 4806/7134 completed (loss: 0.04579642042517662, acc: 0.9916805028915405)
[2024-12-17 03:01:06,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:06,991][root][INFO] - Training Epoch: 2/2, step 4807/7134 completed (loss: 0.07541081309318542, acc: 0.9908814430236816)
[2024-12-17 03:01:07,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:07,326][root][INFO] - Training Epoch: 2/2, step 4808/7134 completed (loss: 0.06406896561384201, acc: 0.991134762763977)
[2024-12-17 03:01:07,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:07,667][root][INFO] - Training Epoch: 2/2, step 4809/7134 completed (loss: 0.029126230627298355, acc: 0.9936507940292358)
[2024-12-17 03:01:07,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:08,030][root][INFO] - Training Epoch: 2/2, step 4810/7134 completed (loss: 0.07880842685699463, acc: 0.9885877370834351)
[2024-12-17 03:01:08,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:08,347][root][INFO] - Training Epoch: 2/2, step 4811/7134 completed (loss: 0.09266828745603561, acc: 0.9844961166381836)
[2024-12-17 03:01:08,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:08,691][root][INFO] - Training Epoch: 2/2, step 4812/7134 completed (loss: 0.09946392476558685, acc: 0.9833101630210876)
[2024-12-17 03:01:08,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:08,979][root][INFO] - Training Epoch: 2/2, step 4813/7134 completed (loss: 0.014808578416705132, acc: 0.9896103739738464)
[2024-12-17 03:01:09,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:09,315][root][INFO] - Training Epoch: 2/2, step 4814/7134 completed (loss: 0.03554739058017731, acc: 0.9948979616165161)
[2024-12-17 03:01:09,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:09,602][root][INFO] - Training Epoch: 2/2, step 4815/7134 completed (loss: 0.0040339031256735325, acc: 1.0)
[2024-12-17 03:01:09,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:09,939][root][INFO] - Training Epoch: 2/2, step 4816/7134 completed (loss: 0.010366996750235558, acc: 0.9975247383117676)
[2024-12-17 03:01:10,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:10,257][root][INFO] - Training Epoch: 2/2, step 4817/7134 completed (loss: 0.01344018243253231, acc: 0.9975903630256653)
[2024-12-17 03:01:10,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:10,635][root][INFO] - Training Epoch: 2/2, step 4818/7134 completed (loss: 0.024391504004597664, acc: 0.9969230890274048)
[2024-12-17 03:01:10,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:10,964][root][INFO] - Training Epoch: 2/2, step 4819/7134 completed (loss: 0.028763655573129654, acc: 0.9918864369392395)
[2024-12-17 03:01:11,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:11,319][root][INFO] - Training Epoch: 2/2, step 4820/7134 completed (loss: 0.027426814660429955, acc: 0.9948520064353943)
[2024-12-17 03:01:11,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:11,671][root][INFO] - Training Epoch: 2/2, step 4821/7134 completed (loss: 0.02608984149992466, acc: 0.9902234673500061)
[2024-12-17 03:01:11,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:12,004][root][INFO] - Training Epoch: 2/2, step 4822/7134 completed (loss: 0.026394763961434364, acc: 0.996219277381897)
[2024-12-17 03:01:12,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:12,353][root][INFO] - Training Epoch: 2/2, step 4823/7134 completed (loss: 0.05942734330892563, acc: 0.9873617887496948)
[2024-12-17 03:01:12,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:12,659][root][INFO] - Training Epoch: 2/2, step 4824/7134 completed (loss: 0.06805736571550369, acc: 0.9748858213424683)
[2024-12-17 03:01:12,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:12,987][root][INFO] - Training Epoch: 2/2, step 4825/7134 completed (loss: 0.018837179988622665, acc: 0.9927007555961609)
[2024-12-17 03:01:13,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:13,356][root][INFO] - Training Epoch: 2/2, step 4826/7134 completed (loss: 0.023818200454115868, acc: 0.9935622215270996)
[2024-12-17 03:01:13,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:13,681][root][INFO] - Training Epoch: 2/2, step 4827/7134 completed (loss: 0.035919249057769775, acc: 0.9896193742752075)
[2024-12-17 03:01:13,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:14,063][root][INFO] - Training Epoch: 2/2, step 4828/7134 completed (loss: 0.028307851403951645, acc: 0.9914945363998413)
[2024-12-17 03:01:14,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:14,431][root][INFO] - Training Epoch: 2/2, step 4829/7134 completed (loss: 0.026481205597519875, acc: 0.9923076629638672)
[2024-12-17 03:01:14,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:14,788][root][INFO] - Training Epoch: 2/2, step 4830/7134 completed (loss: 0.016615239903330803, acc: 0.9955621361732483)
[2024-12-17 03:01:14,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:15,141][root][INFO] - Training Epoch: 2/2, step 4831/7134 completed (loss: 0.010224428027868271, acc: 0.9970760345458984)
[2024-12-17 03:01:15,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:15,475][root][INFO] - Training Epoch: 2/2, step 4832/7134 completed (loss: 0.021732335910201073, acc: 0.9967426657676697)
[2024-12-17 03:01:15,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:15,839][root][INFO] - Training Epoch: 2/2, step 4833/7134 completed (loss: 0.013135218061506748, acc: 0.9987293481826782)
[2024-12-17 03:01:15,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:16,191][root][INFO] - Training Epoch: 2/2, step 4834/7134 completed (loss: 0.026121510192751884, acc: 0.9892857074737549)
[2024-12-17 03:01:16,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:16,532][root][INFO] - Training Epoch: 2/2, step 4835/7134 completed (loss: 0.04384016990661621, acc: 0.9864864945411682)
[2024-12-17 03:01:16,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:16,882][root][INFO] - Training Epoch: 2/2, step 4836/7134 completed (loss: 0.016749633476138115, acc: 0.9954198598861694)
[2024-12-17 03:01:16,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:17,200][root][INFO] - Training Epoch: 2/2, step 4837/7134 completed (loss: 0.09471982717514038, acc: 0.9797794222831726)
[2024-12-17 03:01:17,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:17,538][root][INFO] - Training Epoch: 2/2, step 4838/7134 completed (loss: 0.04339301958680153, acc: 0.988727867603302)
[2024-12-17 03:01:17,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:17,849][root][INFO] - Training Epoch: 2/2, step 4839/7134 completed (loss: 0.043785423040390015, acc: 0.9896729588508606)
[2024-12-17 03:01:17,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:18,187][root][INFO] - Training Epoch: 2/2, step 4840/7134 completed (loss: 0.062400173395872116, acc: 0.9797688126564026)
[2024-12-17 03:01:18,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:18,517][root][INFO] - Training Epoch: 2/2, step 4841/7134 completed (loss: 0.03612727299332619, acc: 0.9910581111907959)
[2024-12-17 03:01:18,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:18,876][root][INFO] - Training Epoch: 2/2, step 4842/7134 completed (loss: 0.06639031320810318, acc: 0.9859693646430969)
[2024-12-17 03:01:18,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:19,236][root][INFO] - Training Epoch: 2/2, step 4843/7134 completed (loss: 0.047185324132442474, acc: 0.9851411581039429)
[2024-12-17 03:01:19,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:19,540][root][INFO] - Training Epoch: 2/2, step 4844/7134 completed (loss: 0.03126293048262596, acc: 0.9919224381446838)
[2024-12-17 03:01:19,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:19,894][root][INFO] - Training Epoch: 2/2, step 4845/7134 completed (loss: 0.028353488072752953, acc: 0.994535505771637)
[2024-12-17 03:01:19,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:20,224][root][INFO] - Training Epoch: 2/2, step 4846/7134 completed (loss: 0.046163782477378845, acc: 0.9878378510475159)
[2024-12-17 03:01:20,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:20,542][root][INFO] - Training Epoch: 2/2, step 4847/7134 completed (loss: 0.03392741084098816, acc: 0.9946091771125793)
[2024-12-17 03:01:20,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:20,889][root][INFO] - Training Epoch: 2/2, step 4848/7134 completed (loss: 0.04599250480532646, acc: 0.9944751262664795)
[2024-12-17 03:01:21,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:21,198][root][INFO] - Training Epoch: 2/2, step 4849/7134 completed (loss: 0.026966996490955353, acc: 0.9940564632415771)
[2024-12-17 03:01:21,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:21,546][root][INFO] - Training Epoch: 2/2, step 4850/7134 completed (loss: 0.04597118869423866, acc: 0.9865360856056213)
[2024-12-17 03:01:21,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:21,908][root][INFO] - Training Epoch: 2/2, step 4851/7134 completed (loss: 0.04902580752968788, acc: 0.985981285572052)
[2024-12-17 03:01:22,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:22,267][root][INFO] - Training Epoch: 2/2, step 4852/7134 completed (loss: 0.0592987984418869, acc: 0.9840213060379028)
[2024-12-17 03:01:22,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:22,610][root][INFO] - Training Epoch: 2/2, step 4853/7134 completed (loss: 0.0770883783698082, acc: 0.9786019921302795)
[2024-12-17 03:01:22,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:22,921][root][INFO] - Training Epoch: 2/2, step 4854/7134 completed (loss: 0.03692330792546272, acc: 0.9906666874885559)
[2024-12-17 03:01:23,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:23,273][root][INFO] - Training Epoch: 2/2, step 4855/7134 completed (loss: 0.041686076670885086, acc: 0.9830713272094727)
[2024-12-17 03:01:23,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:23,639][root][INFO] - Training Epoch: 2/2, step 4856/7134 completed (loss: 0.04483382776379585, acc: 0.983460545539856)
[2024-12-17 03:01:23,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:23,957][root][INFO] - Training Epoch: 2/2, step 4857/7134 completed (loss: 0.019004657864570618, acc: 0.9928057789802551)
[2024-12-17 03:01:24,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:24,305][root][INFO] - Training Epoch: 2/2, step 4858/7134 completed (loss: 0.03546741232275963, acc: 0.9900285005569458)
[2024-12-17 03:01:24,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:24,656][root][INFO] - Training Epoch: 2/2, step 4859/7134 completed (loss: 0.018783120438456535, acc: 0.9948520064353943)
[2024-12-17 03:01:24,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:24,991][root][INFO] - Training Epoch: 2/2, step 4860/7134 completed (loss: 0.03169630840420723, acc: 0.9931880235671997)
[2024-12-17 03:01:25,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:25,322][root][INFO] - Training Epoch: 2/2, step 4861/7134 completed (loss: 0.04008925333619118, acc: 0.9892183542251587)
[2024-12-17 03:01:25,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:25,653][root][INFO] - Training Epoch: 2/2, step 4862/7134 completed (loss: 0.0351414680480957, acc: 0.9856938719749451)
[2024-12-17 03:01:25,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:25,998][root][INFO] - Training Epoch: 2/2, step 4863/7134 completed (loss: 0.03619920462369919, acc: 0.989051103591919)
[2024-12-17 03:01:26,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:26,333][root][INFO] - Training Epoch: 2/2, step 4864/7134 completed (loss: 0.051591191440820694, acc: 0.9815384745597839)
[2024-12-17 03:01:26,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:26,696][root][INFO] - Training Epoch: 2/2, step 4865/7134 completed (loss: 0.044115450233221054, acc: 0.990231990814209)
[2024-12-17 03:01:26,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:27,062][root][INFO] - Training Epoch: 2/2, step 4866/7134 completed (loss: 0.027198877185583115, acc: 0.9922178983688354)
[2024-12-17 03:01:27,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:27,413][root][INFO] - Training Epoch: 2/2, step 4867/7134 completed (loss: 0.06566368788480759, acc: 0.9841269850730896)
[2024-12-17 03:01:27,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:27,728][root][INFO] - Training Epoch: 2/2, step 4868/7134 completed (loss: 0.05285480245947838, acc: 0.9844961166381836)
[2024-12-17 03:01:27,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:28,046][root][INFO] - Training Epoch: 2/2, step 4869/7134 completed (loss: 0.07627783715724945, acc: 0.9866666793823242)
[2024-12-17 03:01:28,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:28,402][root][INFO] - Training Epoch: 2/2, step 4870/7134 completed (loss: 0.031276438385248184, acc: 0.9906103014945984)
[2024-12-17 03:01:28,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:28,737][root][INFO] - Training Epoch: 2/2, step 4871/7134 completed (loss: 0.037830010056495667, acc: 0.9907407164573669)
[2024-12-17 03:01:28,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:29,086][root][INFO] - Training Epoch: 2/2, step 4872/7134 completed (loss: 0.026406634598970413, acc: 0.9944367408752441)
[2024-12-17 03:01:29,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:29,476][root][INFO] - Training Epoch: 2/2, step 4873/7134 completed (loss: 0.028744271025061607, acc: 0.9895833134651184)
[2024-12-17 03:01:29,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:29,833][root][INFO] - Training Epoch: 2/2, step 4874/7134 completed (loss: 0.025183450430631638, acc: 0.9908571243286133)
[2024-12-17 03:01:29,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:30,203][root][INFO] - Training Epoch: 2/2, step 4875/7134 completed (loss: 0.04558571055531502, acc: 0.9875173568725586)
[2024-12-17 03:01:30,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:30,482][root][INFO] - Training Epoch: 2/2, step 4876/7134 completed (loss: 0.09793461114168167, acc: 0.972515881061554)
[2024-12-17 03:01:30,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:30,828][root][INFO] - Training Epoch: 2/2, step 4877/7134 completed (loss: 0.05482707917690277, acc: 0.9819355010986328)
[2024-12-17 03:01:30,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:31,150][root][INFO] - Training Epoch: 2/2, step 4878/7134 completed (loss: 0.050625454634428024, acc: 0.9823269248008728)
[2024-12-17 03:01:31,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:31,510][root][INFO] - Training Epoch: 2/2, step 4879/7134 completed (loss: 0.0831092894077301, acc: 0.983433723449707)
[2024-12-17 03:01:31,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:31,865][root][INFO] - Training Epoch: 2/2, step 4880/7134 completed (loss: 0.018544482067227364, acc: 0.9948119521141052)
[2024-12-17 03:01:31,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:32,225][root][INFO] - Training Epoch: 2/2, step 4881/7134 completed (loss: 0.058783549815416336, acc: 0.985401451587677)
[2024-12-17 03:01:32,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:32,553][root][INFO] - Training Epoch: 2/2, step 4882/7134 completed (loss: 0.05447979271411896, acc: 0.9819079041481018)
[2024-12-17 03:01:32,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:32,905][root][INFO] - Training Epoch: 2/2, step 4883/7134 completed (loss: 0.05591623857617378, acc: 0.9883211851119995)
[2024-12-17 03:01:32,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:33,249][root][INFO] - Training Epoch: 2/2, step 4884/7134 completed (loss: 0.014814662747085094, acc: 0.9938555955886841)
[2024-12-17 03:01:33,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:33,572][root][INFO] - Training Epoch: 2/2, step 4885/7134 completed (loss: 0.018565712496638298, acc: 0.9947229623794556)
[2024-12-17 03:01:33,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:33,896][root][INFO] - Training Epoch: 2/2, step 4886/7134 completed (loss: 0.03322944417595863, acc: 0.9897435903549194)
[2024-12-17 03:01:34,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:34,261][root][INFO] - Training Epoch: 2/2, step 4887/7134 completed (loss: 0.024758711457252502, acc: 0.9952210187911987)
[2024-12-17 03:01:34,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:34,630][root][INFO] - Training Epoch: 2/2, step 4888/7134 completed (loss: 0.04287854582071304, acc: 0.9890109896659851)
[2024-12-17 03:01:34,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:34,984][root][INFO] - Training Epoch: 2/2, step 4889/7134 completed (loss: 0.02849038876593113, acc: 0.9903730154037476)
[2024-12-17 03:01:35,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:35,299][root][INFO] - Training Epoch: 2/2, step 4890/7134 completed (loss: 0.044809162616729736, acc: 0.9928571581840515)
[2024-12-17 03:01:35,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:35,649][root][INFO] - Training Epoch: 2/2, step 4891/7134 completed (loss: 0.058425404131412506, acc: 0.9863184094429016)
[2024-12-17 03:01:35,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:35,983][root][INFO] - Training Epoch: 2/2, step 4892/7134 completed (loss: 0.06966184079647064, acc: 0.9832214713096619)
[2024-12-17 03:01:36,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:36,321][root][INFO] - Training Epoch: 2/2, step 4893/7134 completed (loss: 0.15313895046710968, acc: 0.9577836394309998)
[2024-12-17 03:01:36,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:36,666][root][INFO] - Training Epoch: 2/2, step 4894/7134 completed (loss: 0.020304152742028236, acc: 0.9956772327423096)
[2024-12-17 03:01:36,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:37,022][root][INFO] - Training Epoch: 2/2, step 4895/7134 completed (loss: 0.011537719517946243, acc: 0.9975000023841858)
[2024-12-17 03:01:37,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:37,340][root][INFO] - Training Epoch: 2/2, step 4896/7134 completed (loss: 0.011136600747704506, acc: 0.9971910119056702)
[2024-12-17 03:01:37,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:37,695][root][INFO] - Training Epoch: 2/2, step 4897/7134 completed (loss: 0.037441615015268326, acc: 0.9894737005233765)
[2024-12-17 03:01:37,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:38,064][root][INFO] - Training Epoch: 2/2, step 4898/7134 completed (loss: 0.052023354917764664, acc: 0.9874213933944702)
[2024-12-17 03:01:38,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:38,412][root][INFO] - Training Epoch: 2/2, step 4899/7134 completed (loss: 0.029315531253814697, acc: 0.9912663698196411)
[2024-12-17 03:01:38,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:38,760][root][INFO] - Training Epoch: 2/2, step 4900/7134 completed (loss: 0.031168704852461815, acc: 0.9881578683853149)
[2024-12-17 03:01:38,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:39,107][root][INFO] - Training Epoch: 2/2, step 4901/7134 completed (loss: 0.03033514879643917, acc: 0.9924812316894531)
[2024-12-17 03:01:39,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:39,466][root][INFO] - Training Epoch: 2/2, step 4902/7134 completed (loss: 0.02057221159338951, acc: 0.9920424222946167)
[2024-12-17 03:01:39,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:39,804][root][INFO] - Training Epoch: 2/2, step 4903/7134 completed (loss: 0.019760631024837494, acc: 0.9928315281867981)
[2024-12-17 03:01:39,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:40,137][root][INFO] - Training Epoch: 2/2, step 4904/7134 completed (loss: 0.029086872935295105, acc: 0.9895522594451904)
[2024-12-17 03:01:40,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:40,474][root][INFO] - Training Epoch: 2/2, step 4905/7134 completed (loss: 0.022055717185139656, acc: 0.993630588054657)
[2024-12-17 03:01:40,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:40,810][root][INFO] - Training Epoch: 2/2, step 4906/7134 completed (loss: 0.02315322868525982, acc: 0.9932546615600586)
[2024-12-17 03:01:40,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:41,145][root][INFO] - Training Epoch: 2/2, step 4907/7134 completed (loss: 0.02290847897529602, acc: 0.996835470199585)
[2024-12-17 03:01:41,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:41,484][root][INFO] - Training Epoch: 2/2, step 4908/7134 completed (loss: 0.010594232007861137, acc: 0.9983999729156494)
[2024-12-17 03:01:41,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:41,849][root][INFO] - Training Epoch: 2/2, step 4909/7134 completed (loss: 0.01005631685256958, acc: 0.9983792304992676)
[2024-12-17 03:01:41,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:42,180][root][INFO] - Training Epoch: 2/2, step 4910/7134 completed (loss: 0.03851348161697388, acc: 0.9858934283256531)
[2024-12-17 03:01:42,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:42,531][root][INFO] - Training Epoch: 2/2, step 4911/7134 completed (loss: 0.02676340751349926, acc: 0.9881266355514526)
[2024-12-17 03:01:42,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:42,877][root][INFO] - Training Epoch: 2/2, step 4912/7134 completed (loss: 0.03358519449830055, acc: 0.9927361011505127)
[2024-12-17 03:01:42,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:43,212][root][INFO] - Training Epoch: 2/2, step 4913/7134 completed (loss: 0.015346108004450798, acc: 0.9932432174682617)
[2024-12-17 03:01:43,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:43,548][root][INFO] - Training Epoch: 2/2, step 4914/7134 completed (loss: 0.030682064592838287, acc: 0.9938837885856628)
[2024-12-17 03:01:43,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:43,894][root][INFO] - Training Epoch: 2/2, step 4915/7134 completed (loss: 0.017512459307909012, acc: 0.996820330619812)
[2024-12-17 03:01:44,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:44,221][root][INFO] - Training Epoch: 2/2, step 4916/7134 completed (loss: 0.04972190782427788, acc: 0.9781553149223328)
[2024-12-17 03:01:44,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:44,575][root][INFO] - Training Epoch: 2/2, step 4917/7134 completed (loss: 0.043786127120256424, acc: 0.9874826073646545)
[2024-12-17 03:01:44,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:44,910][root][INFO] - Training Epoch: 2/2, step 4918/7134 completed (loss: 0.011876384727656841, acc: 0.9972677826881409)
[2024-12-17 03:01:45,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:45,332][root][INFO] - Training Epoch: 2/2, step 4919/7134 completed (loss: 0.049188364297151566, acc: 0.9881578683853149)
[2024-12-17 03:01:45,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:45,696][root][INFO] - Training Epoch: 2/2, step 4920/7134 completed (loss: 0.09299959987401962, acc: 0.9780361652374268)
[2024-12-17 03:01:45,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:46,027][root][INFO] - Training Epoch: 2/2, step 4921/7134 completed (loss: 0.03740905225276947, acc: 0.991391658782959)
[2024-12-17 03:01:46,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:46,384][root][INFO] - Training Epoch: 2/2, step 4922/7134 completed (loss: 0.026049407199025154, acc: 0.994557797908783)
[2024-12-17 03:01:46,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:46,740][root][INFO] - Training Epoch: 2/2, step 4923/7134 completed (loss: 0.022527379915118217, acc: 0.9955947399139404)
[2024-12-17 03:01:46,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:47,057][root][INFO] - Training Epoch: 2/2, step 4924/7134 completed (loss: 0.028442859649658203, acc: 0.9940000176429749)
[2024-12-17 03:01:47,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:47,391][root][INFO] - Training Epoch: 2/2, step 4925/7134 completed (loss: 0.024727771058678627, acc: 0.9899857044219971)
[2024-12-17 03:01:47,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:47,716][root][INFO] - Training Epoch: 2/2, step 4926/7134 completed (loss: 0.018730882555246353, acc: 0.9971305727958679)
[2024-12-17 03:01:47,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:48,037][root][INFO] - Training Epoch: 2/2, step 4927/7134 completed (loss: 0.03757835924625397, acc: 0.9859943985939026)
[2024-12-17 03:01:48,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:48,395][root][INFO] - Training Epoch: 2/2, step 4928/7134 completed (loss: 0.018915068358182907, acc: 0.9930475354194641)
[2024-12-17 03:01:48,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:48,744][root][INFO] - Training Epoch: 2/2, step 4929/7134 completed (loss: 0.02614693157374859, acc: 0.9922480583190918)
[2024-12-17 03:01:48,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:49,072][root][INFO] - Training Epoch: 2/2, step 4930/7134 completed (loss: 0.03735046461224556, acc: 0.9954751133918762)
[2024-12-17 03:01:49,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:49,421][root][INFO] - Training Epoch: 2/2, step 4931/7134 completed (loss: 0.09520554542541504, acc: 0.9863013625144958)
[2024-12-17 03:01:49,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:49,772][root][INFO] - Training Epoch: 2/2, step 4932/7134 completed (loss: 0.028357602655887604, acc: 0.9932523369789124)
[2024-12-17 03:01:49,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:50,117][root][INFO] - Training Epoch: 2/2, step 4933/7134 completed (loss: 0.0388583242893219, acc: 0.990111231803894)
[2024-12-17 03:01:50,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:50,469][root][INFO] - Training Epoch: 2/2, step 4934/7134 completed (loss: 0.01625584252178669, acc: 0.9945873022079468)
[2024-12-17 03:01:50,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:50,821][root][INFO] - Training Epoch: 2/2, step 4935/7134 completed (loss: 0.02707294002175331, acc: 0.9904240965843201)
[2024-12-17 03:01:50,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:51,150][root][INFO] - Training Epoch: 2/2, step 4936/7134 completed (loss: 0.06484857201576233, acc: 0.9876543283462524)
[2024-12-17 03:01:51,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:51,483][root][INFO] - Training Epoch: 2/2, step 4937/7134 completed (loss: 0.02841528132557869, acc: 0.9910314083099365)
[2024-12-17 03:01:51,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:51,818][root][INFO] - Training Epoch: 2/2, step 4938/7134 completed (loss: 0.030455701053142548, acc: 0.9905533194541931)
[2024-12-17 03:01:51,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:52,154][root][INFO] - Training Epoch: 2/2, step 4939/7134 completed (loss: 0.02443723753094673, acc: 0.990212082862854)
[2024-12-17 03:01:52,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:52,494][root][INFO] - Training Epoch: 2/2, step 4940/7134 completed (loss: 0.040616340935230255, acc: 0.9909090995788574)
[2024-12-17 03:01:52,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:52,843][root][INFO] - Training Epoch: 2/2, step 4941/7134 completed (loss: 0.037198297679424286, acc: 0.9905787110328674)
[2024-12-17 03:01:52,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:53,195][root][INFO] - Training Epoch: 2/2, step 4942/7134 completed (loss: 0.038166459649801254, acc: 0.9879356622695923)
[2024-12-17 03:01:53,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:53,537][root][INFO] - Training Epoch: 2/2, step 4943/7134 completed (loss: 0.04639097675681114, acc: 0.9876881241798401)
[2024-12-17 03:01:53,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:53,870][root][INFO] - Training Epoch: 2/2, step 4944/7134 completed (loss: 0.03899063915014267, acc: 0.9852631688117981)
[2024-12-17 03:01:53,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:54,170][root][INFO] - Training Epoch: 2/2, step 4945/7134 completed (loss: 0.1035594642162323, acc: 0.9677419066429138)
[2024-12-17 03:01:54,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:54,500][root][INFO] - Training Epoch: 2/2, step 4946/7134 completed (loss: 0.06472545117139816, acc: 0.9824175834655762)
[2024-12-17 03:01:54,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:54,835][root][INFO] - Training Epoch: 2/2, step 4947/7134 completed (loss: 0.033450979739427567, acc: 0.9866962432861328)
[2024-12-17 03:01:54,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:55,135][root][INFO] - Training Epoch: 2/2, step 4948/7134 completed (loss: 0.06089944764971733, acc: 0.9839572310447693)
[2024-12-17 03:01:55,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:55,430][root][INFO] - Training Epoch: 2/2, step 4949/7134 completed (loss: 0.04955790936946869, acc: 0.9873015880584717)
[2024-12-17 03:01:55,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:55,758][root][INFO] - Training Epoch: 2/2, step 4950/7134 completed (loss: 0.027528975158929825, acc: 0.9912434220314026)
[2024-12-17 03:01:55,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:56,099][root][INFO] - Training Epoch: 2/2, step 4951/7134 completed (loss: 0.053379472345113754, acc: 0.9829059839248657)
[2024-12-17 03:01:56,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:56,479][root][INFO] - Training Epoch: 2/2, step 4952/7134 completed (loss: 0.03966563194990158, acc: 0.9917218685150146)
[2024-12-17 03:01:56,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:56,765][root][INFO] - Training Epoch: 2/2, step 4953/7134 completed (loss: 0.012410048395395279, acc: 0.9978213310241699)
[2024-12-17 03:01:56,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:57,086][root][INFO] - Training Epoch: 2/2, step 4954/7134 completed (loss: 0.035227347165346146, acc: 0.9885714054107666)
[2024-12-17 03:01:57,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:57,375][root][INFO] - Training Epoch: 2/2, step 4955/7134 completed (loss: 0.045495107769966125, acc: 0.9859485030174255)
[2024-12-17 03:01:57,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:57,709][root][INFO] - Training Epoch: 2/2, step 4956/7134 completed (loss: 0.02519184537231922, acc: 0.9928876161575317)
[2024-12-17 03:01:57,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:58,030][root][INFO] - Training Epoch: 2/2, step 4957/7134 completed (loss: 0.031175091862678528, acc: 0.9911816716194153)
[2024-12-17 03:01:58,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:58,362][root][INFO] - Training Epoch: 2/2, step 4958/7134 completed (loss: 0.013376213610172272, acc: 0.9971222877502441)
[2024-12-17 03:01:58,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:58,696][root][INFO] - Training Epoch: 2/2, step 4959/7134 completed (loss: 0.019064415246248245, acc: 0.9911764860153198)
[2024-12-17 03:01:58,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:59,023][root][INFO] - Training Epoch: 2/2, step 4960/7134 completed (loss: 0.018444163724780083, acc: 0.9948275685310364)
[2024-12-17 03:01:59,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:59,361][root][INFO] - Training Epoch: 2/2, step 4961/7134 completed (loss: 0.013512767851352692, acc: 0.994535505771637)
[2024-12-17 03:01:59,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:59,688][root][INFO] - Training Epoch: 2/2, step 4962/7134 completed (loss: 0.00833431351929903, acc: 0.996889591217041)
[2024-12-17 03:01:59,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:00,009][root][INFO] - Training Epoch: 2/2, step 4963/7134 completed (loss: 0.0243538748472929, acc: 0.9918830990791321)
[2024-12-17 03:02:00,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:00,337][root][INFO] - Training Epoch: 2/2, step 4964/7134 completed (loss: 0.02712000161409378, acc: 0.9918699264526367)
[2024-12-17 03:02:00,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:00,657][root][INFO] - Training Epoch: 2/2, step 4965/7134 completed (loss: 0.04414081573486328, acc: 0.9894958138465881)
[2024-12-17 03:02:00,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:00,972][root][INFO] - Training Epoch: 2/2, step 4966/7134 completed (loss: 0.07513117790222168, acc: 0.9889196753501892)
[2024-12-17 03:02:01,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:01,294][root][INFO] - Training Epoch: 2/2, step 4967/7134 completed (loss: 0.051983483135700226, acc: 0.984375)
[2024-12-17 03:02:01,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:01,635][root][INFO] - Training Epoch: 2/2, step 4968/7134 completed (loss: 0.07214316725730896, acc: 0.9786477088928223)
[2024-12-17 03:02:01,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:01,983][root][INFO] - Training Epoch: 2/2, step 4969/7134 completed (loss: 0.08456423133611679, acc: 0.9810996651649475)
[2024-12-17 03:02:02,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:02,301][root][INFO] - Training Epoch: 2/2, step 4970/7134 completed (loss: 0.0292915478348732, acc: 0.9916387796401978)
[2024-12-17 03:02:02,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:02,636][root][INFO] - Training Epoch: 2/2, step 4971/7134 completed (loss: 0.027566004544496536, acc: 0.988135576248169)
[2024-12-17 03:02:02,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:02,978][root][INFO] - Training Epoch: 2/2, step 4972/7134 completed (loss: 0.01934991031885147, acc: 0.994358241558075)
[2024-12-17 03:02:03,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:03,311][root][INFO] - Training Epoch: 2/2, step 4973/7134 completed (loss: 0.05165514349937439, acc: 0.9855967164039612)
[2024-12-17 03:02:03,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:03,611][root][INFO] - Training Epoch: 2/2, step 4974/7134 completed (loss: 0.0815073698759079, acc: 0.9819639325141907)
[2024-12-17 03:02:03,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:03,944][root][INFO] - Training Epoch: 2/2, step 4975/7134 completed (loss: 0.08858544379472733, acc: 0.9792332053184509)
[2024-12-17 03:02:04,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:04,211][root][INFO] - Training Epoch: 2/2, step 4976/7134 completed (loss: 0.03896448761224747, acc: 0.9906322956085205)
[2024-12-17 03:02:04,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:04,552][root][INFO] - Training Epoch: 2/2, step 4977/7134 completed (loss: 0.11104164272546768, acc: 0.9784946441650391)
[2024-12-17 03:02:04,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:04,880][root][INFO] - Training Epoch: 2/2, step 4978/7134 completed (loss: 0.044610340148210526, acc: 0.9875776171684265)
[2024-12-17 03:02:05,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:05,194][root][INFO] - Training Epoch: 2/2, step 4979/7134 completed (loss: 0.1275424212217331, acc: 0.9719933867454529)
[2024-12-17 03:02:05,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:05,550][root][INFO] - Training Epoch: 2/2, step 4980/7134 completed (loss: 0.05855746567249298, acc: 0.9919484853744507)
[2024-12-17 03:02:05,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:05,907][root][INFO] - Training Epoch: 2/2, step 4981/7134 completed (loss: 0.03987830504775047, acc: 0.9872408509254456)
[2024-12-17 03:02:06,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:06,230][root][INFO] - Training Epoch: 2/2, step 4982/7134 completed (loss: 0.09836839139461517, acc: 0.97773277759552)
[2024-12-17 03:02:06,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:06,583][root][INFO] - Training Epoch: 2/2, step 4983/7134 completed (loss: 0.058531489223241806, acc: 0.9828660488128662)
[2024-12-17 03:02:06,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:06,860][root][INFO] - Training Epoch: 2/2, step 4984/7134 completed (loss: 0.06941840052604675, acc: 0.9833333492279053)
[2024-12-17 03:02:06,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:07,161][root][INFO] - Training Epoch: 2/2, step 4985/7134 completed (loss: 0.04383518174290657, acc: 0.9847095012664795)
[2024-12-17 03:02:07,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:07,499][root][INFO] - Training Epoch: 2/2, step 4986/7134 completed (loss: 0.07787711918354034, acc: 0.9777117371559143)
[2024-12-17 03:02:07,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:07,825][root][INFO] - Training Epoch: 2/2, step 4987/7134 completed (loss: 0.05303274095058441, acc: 0.9880715608596802)
[2024-12-17 03:02:07,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:08,166][root][INFO] - Training Epoch: 2/2, step 4988/7134 completed (loss: 0.03528054803609848, acc: 0.9911660552024841)
[2024-12-17 03:02:08,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:08,517][root][INFO] - Training Epoch: 2/2, step 4989/7134 completed (loss: 0.07341303676366806, acc: 0.9851484894752502)
[2024-12-17 03:02:08,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:08,843][root][INFO] - Training Epoch: 2/2, step 4990/7134 completed (loss: 0.052778203040361404, acc: 0.9864864945411682)
[2024-12-17 03:02:08,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:09,176][root][INFO] - Training Epoch: 2/2, step 4991/7134 completed (loss: 0.03914260491728783, acc: 0.9865996837615967)
[2024-12-17 03:02:09,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:09,519][root][INFO] - Training Epoch: 2/2, step 4992/7134 completed (loss: 0.08763402700424194, acc: 0.9781181812286377)
[2024-12-17 03:02:09,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:09,766][root][INFO] - Training Epoch: 2/2, step 4993/7134 completed (loss: 0.02257610857486725, acc: 0.9954751133918762)
[2024-12-17 03:02:09,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:10,137][root][INFO] - Training Epoch: 2/2, step 4994/7134 completed (loss: 0.03423459827899933, acc: 0.9929078221321106)
[2024-12-17 03:02:10,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:10,416][root][INFO] - Training Epoch: 2/2, step 4995/7134 completed (loss: 0.05425523594021797, acc: 0.9877551198005676)
[2024-12-17 03:02:10,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:10,766][root][INFO] - Training Epoch: 2/2, step 4996/7134 completed (loss: 0.033055730164051056, acc: 0.990774929523468)
[2024-12-17 03:02:10,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:11,140][root][INFO] - Training Epoch: 2/2, step 4997/7134 completed (loss: 0.04386714845895767, acc: 0.9897260069847107)
[2024-12-17 03:02:11,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:11,405][root][INFO] - Training Epoch: 2/2, step 4998/7134 completed (loss: 0.08114272356033325, acc: 0.9836065769195557)
[2024-12-17 03:02:11,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:11,731][root][INFO] - Training Epoch: 2/2, step 4999/7134 completed (loss: 0.03044285625219345, acc: 0.9913941621780396)
[2024-12-17 03:02:11,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:12,061][root][INFO] - Training Epoch: 2/2, step 5000/7134 completed (loss: 0.028815273195505142, acc: 0.9953488111495972)
[2024-12-17 03:02:12,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:12,418][root][INFO] - Training Epoch: 2/2, step 5001/7134 completed (loss: 0.07663499563932419, acc: 0.9811046719551086)
[2024-12-17 03:02:12,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:12,756][root][INFO] - Training Epoch: 2/2, step 5002/7134 completed (loss: 0.036954861134290695, acc: 0.9944238066673279)
[2024-12-17 03:02:12,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:13,087][root][INFO] - Training Epoch: 2/2, step 5003/7134 completed (loss: 0.022185759618878365, acc: 0.9919999837875366)
[2024-12-17 03:02:13,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:13,374][root][INFO] - Training Epoch: 2/2, step 5004/7134 completed (loss: 0.024276303127408028, acc: 0.9955849647521973)
[2024-12-17 03:02:13,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:13,699][root][INFO] - Training Epoch: 2/2, step 5005/7134 completed (loss: 0.04402293637394905, acc: 0.995121955871582)
[2024-12-17 03:02:13,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:14,046][root][INFO] - Training Epoch: 2/2, step 5006/7134 completed (loss: 0.03598900884389877, acc: 0.9955947399139404)
[2024-12-17 03:02:14,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:14,377][root][INFO] - Training Epoch: 2/2, step 5007/7134 completed (loss: 0.023741822689771652, acc: 0.991525411605835)
[2024-12-17 03:02:14,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:14,746][root][INFO] - Training Epoch: 2/2, step 5008/7134 completed (loss: 0.05607392266392708, acc: 0.9842519760131836)
[2024-12-17 03:02:14,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:15,079][root][INFO] - Training Epoch: 2/2, step 5009/7134 completed (loss: 0.07747849822044373, acc: 0.9875930547714233)
[2024-12-17 03:02:15,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:15,397][root][INFO] - Training Epoch: 2/2, step 5010/7134 completed (loss: 0.04478689655661583, acc: 0.9898785352706909)
[2024-12-17 03:02:15,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:15,782][root][INFO] - Training Epoch: 2/2, step 5011/7134 completed (loss: 0.052600011229515076, acc: 0.9886178970336914)
[2024-12-17 03:02:15,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:16,002][root][INFO] - Training Epoch: 2/2, step 5012/7134 completed (loss: 0.11856009066104889, acc: 0.9712643623352051)
[2024-12-17 03:02:16,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:16,305][root][INFO] - Training Epoch: 2/2, step 5013/7134 completed (loss: 0.02894286811351776, acc: 0.9899799823760986)
[2024-12-17 03:02:16,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:16,677][root][INFO] - Training Epoch: 2/2, step 5014/7134 completed (loss: 0.05084852874279022, acc: 0.993852436542511)
[2024-12-17 03:02:16,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:17,025][root][INFO] - Training Epoch: 2/2, step 5015/7134 completed (loss: 0.08483226597309113, acc: 0.9834482669830322)
[2024-12-17 03:02:17,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:17,330][root][INFO] - Training Epoch: 2/2, step 5016/7134 completed (loss: 0.013462996110320091, acc: 0.994575023651123)
[2024-12-17 03:02:17,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:17,647][root][INFO] - Training Epoch: 2/2, step 5017/7134 completed (loss: 0.014406241476535797, acc: 0.9963964223861694)
[2024-12-17 03:02:17,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:17,967][root][INFO] - Training Epoch: 2/2, step 5018/7134 completed (loss: 0.02933853305876255, acc: 0.9946808218955994)
[2024-12-17 03:02:18,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:18,305][root][INFO] - Training Epoch: 2/2, step 5019/7134 completed (loss: 0.0425187349319458, acc: 0.9857549667358398)
[2024-12-17 03:02:18,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:18,675][root][INFO] - Training Epoch: 2/2, step 5020/7134 completed (loss: 0.039469681680202484, acc: 0.987500011920929)
[2024-12-17 03:02:18,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:18,999][root][INFO] - Training Epoch: 2/2, step 5021/7134 completed (loss: 0.06848069280385971, acc: 0.9839816689491272)
[2024-12-17 03:02:19,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:19,334][root][INFO] - Training Epoch: 2/2, step 5022/7134 completed (loss: 0.04770294949412346, acc: 0.9861111044883728)
[2024-12-17 03:02:19,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:19,697][root][INFO] - Training Epoch: 2/2, step 5023/7134 completed (loss: 0.06395385414361954, acc: 0.9802431464195251)
[2024-12-17 03:02:19,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:20,053][root][INFO] - Training Epoch: 2/2, step 5024/7134 completed (loss: 0.036716993898153305, acc: 0.9909909963607788)
[2024-12-17 03:02:20,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:20,385][root][INFO] - Training Epoch: 2/2, step 5025/7134 completed (loss: 0.03148691728711128, acc: 0.9963768124580383)
[2024-12-17 03:02:20,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:20,712][root][INFO] - Training Epoch: 2/2, step 5026/7134 completed (loss: 0.0394945964217186, acc: 0.9877408146858215)
[2024-12-17 03:02:20,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:21,035][root][INFO] - Training Epoch: 2/2, step 5027/7134 completed (loss: 0.026244649663567543, acc: 0.994535505771637)
[2024-12-17 03:02:21,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:21,361][root][INFO] - Training Epoch: 2/2, step 5028/7134 completed (loss: 0.02479979768395424, acc: 0.9952977895736694)
[2024-12-17 03:02:21,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:21,675][root][INFO] - Training Epoch: 2/2, step 5029/7134 completed (loss: 0.02047298662364483, acc: 0.9905303120613098)
[2024-12-17 03:02:21,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:22,031][root][INFO] - Training Epoch: 2/2, step 5030/7134 completed (loss: 0.025443436577916145, acc: 0.9931787252426147)
[2024-12-17 03:02:22,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:22,357][root][INFO] - Training Epoch: 2/2, step 5031/7134 completed (loss: 0.08613724261522293, acc: 0.9863945841789246)
[2024-12-17 03:02:22,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:22,681][root][INFO] - Training Epoch: 2/2, step 5032/7134 completed (loss: 0.03540700301527977, acc: 0.9951298832893372)
[2024-12-17 03:02:22,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:23,002][root][INFO] - Training Epoch: 2/2, step 5033/7134 completed (loss: 0.01927502080798149, acc: 0.995192289352417)
[2024-12-17 03:02:23,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:23,321][root][INFO] - Training Epoch: 2/2, step 5034/7134 completed (loss: 0.02416098862886429, acc: 0.991134762763977)
[2024-12-17 03:02:23,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:23,642][root][INFO] - Training Epoch: 2/2, step 5035/7134 completed (loss: 0.004546651616692543, acc: 1.0)
[2024-12-17 03:02:23,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:23,978][root][INFO] - Training Epoch: 2/2, step 5036/7134 completed (loss: 0.0448753722012043, acc: 0.9888392686843872)
[2024-12-17 03:02:24,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:24,310][root][INFO] - Training Epoch: 2/2, step 5037/7134 completed (loss: 0.06967581808567047, acc: 0.9879356622695923)
[2024-12-17 03:02:24,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:24,610][root][INFO] - Training Epoch: 2/2, step 5038/7134 completed (loss: 0.05351940914988518, acc: 0.9866369962692261)
[2024-12-17 03:02:24,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:24,912][root][INFO] - Training Epoch: 2/2, step 5039/7134 completed (loss: 0.03657395392656326, acc: 0.9905063509941101)
[2024-12-17 03:02:24,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:25,173][root][INFO] - Training Epoch: 2/2, step 5040/7134 completed (loss: 0.01141828391700983, acc: 0.9961758852005005)
[2024-12-17 03:02:25,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:25,519][root][INFO] - Training Epoch: 2/2, step 5041/7134 completed (loss: 0.009750740602612495, acc: 0.9960212111473083)
[2024-12-17 03:02:25,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:25,833][root][INFO] - Training Epoch: 2/2, step 5042/7134 completed (loss: 0.049807850271463394, acc: 0.9906759858131409)
[2024-12-17 03:02:25,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:26,110][root][INFO] - Training Epoch: 2/2, step 5043/7134 completed (loss: 0.03492997959256172, acc: 0.9881423115730286)
[2024-12-17 03:02:26,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:26,453][root][INFO] - Training Epoch: 2/2, step 5044/7134 completed (loss: 0.024911822751164436, acc: 0.9956140518188477)
[2024-12-17 03:02:26,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:26,807][root][INFO] - Training Epoch: 2/2, step 5045/7134 completed (loss: 0.06108430027961731, acc: 0.9851951599121094)
[2024-12-17 03:02:26,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:27,070][root][INFO] - Training Epoch: 2/2, step 5046/7134 completed (loss: 0.07204695791006088, acc: 0.9771929979324341)
[2024-12-17 03:02:27,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:27,338][root][INFO] - Training Epoch: 2/2, step 5047/7134 completed (loss: 0.07132729142904282, acc: 0.9785124063491821)
[2024-12-17 03:02:27,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:27,696][root][INFO] - Training Epoch: 2/2, step 5048/7134 completed (loss: 0.055837906897068024, acc: 0.9863013625144958)
[2024-12-17 03:02:27,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:28,010][root][INFO] - Training Epoch: 2/2, step 5049/7134 completed (loss: 0.05152034014463425, acc: 0.9836512207984924)
[2024-12-17 03:02:28,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:28,346][root][INFO] - Training Epoch: 2/2, step 5050/7134 completed (loss: 0.04966467618942261, acc: 0.9929676651954651)
[2024-12-17 03:02:28,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:28,683][root][INFO] - Training Epoch: 2/2, step 5051/7134 completed (loss: 0.05720212683081627, acc: 0.9840579628944397)
[2024-12-17 03:02:28,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:29,009][root][INFO] - Training Epoch: 2/2, step 5052/7134 completed (loss: 0.043632764369249344, acc: 0.9863636493682861)
[2024-12-17 03:02:29,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:29,336][root][INFO] - Training Epoch: 2/2, step 5053/7134 completed (loss: 0.10025247186422348, acc: 0.9735848903656006)
[2024-12-17 03:02:29,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:29,698][root][INFO] - Training Epoch: 2/2, step 5054/7134 completed (loss: 0.09217324107885361, acc: 0.9731861352920532)
[2024-12-17 03:02:29,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:29,971][root][INFO] - Training Epoch: 2/2, step 5055/7134 completed (loss: 0.028325699269771576, acc: 0.9897959232330322)
[2024-12-17 03:02:30,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:30,304][root][INFO] - Training Epoch: 2/2, step 5056/7134 completed (loss: 0.09177194535732269, acc: 0.9746031761169434)
[2024-12-17 03:02:30,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:30,637][root][INFO] - Training Epoch: 2/2, step 5057/7134 completed (loss: 0.08842001855373383, acc: 0.9815078377723694)
[2024-12-17 03:02:30,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:30,971][root][INFO] - Training Epoch: 2/2, step 5058/7134 completed (loss: 0.09476345777511597, acc: 0.9768115878105164)
[2024-12-17 03:02:31,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:31,327][root][INFO] - Training Epoch: 2/2, step 5059/7134 completed (loss: 0.07664604485034943, acc: 0.9829620122909546)
[2024-12-17 03:02:31,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:31,671][root][INFO] - Training Epoch: 2/2, step 5060/7134 completed (loss: 0.03636467084288597, acc: 0.9955423474311829)
[2024-12-17 03:02:31,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:31,970][root][INFO] - Training Epoch: 2/2, step 5061/7134 completed (loss: 0.05085540562868118, acc: 0.9827213883399963)
[2024-12-17 03:02:32,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:32,304][root][INFO] - Training Epoch: 2/2, step 5062/7134 completed (loss: 0.07210436463356018, acc: 0.9794167876243591)
[2024-12-17 03:02:32,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:32,646][root][INFO] - Training Epoch: 2/2, step 5063/7134 completed (loss: 0.057044994086027145, acc: 0.9866443872451782)
[2024-12-17 03:02:32,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:32,998][root][INFO] - Training Epoch: 2/2, step 5064/7134 completed (loss: 0.05232812091708183, acc: 0.9914383292198181)
[2024-12-17 03:02:33,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:33,360][root][INFO] - Training Epoch: 2/2, step 5065/7134 completed (loss: 0.055072393268346786, acc: 0.9915373921394348)
[2024-12-17 03:02:33,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:33,691][root][INFO] - Training Epoch: 2/2, step 5066/7134 completed (loss: 0.0730462595820427, acc: 0.9773070812225342)
[2024-12-17 03:02:33,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:34,036][root][INFO] - Training Epoch: 2/2, step 5067/7134 completed (loss: 0.029820475727319717, acc: 0.9922027587890625)
[2024-12-17 03:02:34,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:34,361][root][INFO] - Training Epoch: 2/2, step 5068/7134 completed (loss: 0.057629168033599854, acc: 0.9889415502548218)
[2024-12-17 03:02:34,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:34,694][root][INFO] - Training Epoch: 2/2, step 5069/7134 completed (loss: 0.03715583682060242, acc: 0.9906250238418579)
[2024-12-17 03:02:34,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:34,976][root][INFO] - Training Epoch: 2/2, step 5070/7134 completed (loss: 0.03185557574033737, acc: 0.9885057210922241)
[2024-12-17 03:02:35,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:35,312][root][INFO] - Training Epoch: 2/2, step 5071/7134 completed (loss: 0.06983227282762527, acc: 0.9845722317695618)
[2024-12-17 03:02:35,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:35,657][root][INFO] - Training Epoch: 2/2, step 5072/7134 completed (loss: 0.0691988617181778, acc: 0.9849435091018677)
[2024-12-17 03:02:35,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:35,993][root][INFO] - Training Epoch: 2/2, step 5073/7134 completed (loss: 0.09015441685914993, acc: 0.9729207158088684)
[2024-12-17 03:02:36,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:36,345][root][INFO] - Training Epoch: 2/2, step 5074/7134 completed (loss: 0.05566129833459854, acc: 0.9850746393203735)
[2024-12-17 03:02:36,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:36,665][root][INFO] - Training Epoch: 2/2, step 5075/7134 completed (loss: 0.05620588734745979, acc: 0.9844961166381836)
[2024-12-17 03:02:36,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:37,028][root][INFO] - Training Epoch: 2/2, step 5076/7134 completed (loss: 0.0626727044582367, acc: 0.980861246585846)
[2024-12-17 03:02:37,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:37,379][root][INFO] - Training Epoch: 2/2, step 5077/7134 completed (loss: 0.04165654629468918, acc: 0.9873417615890503)
[2024-12-17 03:02:37,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:37,706][root][INFO] - Training Epoch: 2/2, step 5078/7134 completed (loss: 0.08830317109823227, acc: 0.9790794849395752)
[2024-12-17 03:02:37,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:38,033][root][INFO] - Training Epoch: 2/2, step 5079/7134 completed (loss: 0.03420080617070198, acc: 0.994557797908783)
[2024-12-17 03:02:38,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:38,397][root][INFO] - Training Epoch: 2/2, step 5080/7134 completed (loss: 0.026673147454857826, acc: 0.991725742816925)
[2024-12-17 03:02:38,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:38,737][root][INFO] - Training Epoch: 2/2, step 5081/7134 completed (loss: 0.018950236961245537, acc: 0.9932065010070801)
[2024-12-17 03:02:38,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:39,094][root][INFO] - Training Epoch: 2/2, step 5082/7134 completed (loss: 0.022411758080124855, acc: 0.9948979616165161)
[2024-12-17 03:02:39,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:39,424][root][INFO] - Training Epoch: 2/2, step 5083/7134 completed (loss: 0.05207052081823349, acc: 0.9887482523918152)
[2024-12-17 03:02:39,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:39,794][root][INFO] - Training Epoch: 2/2, step 5084/7134 completed (loss: 0.038742631673812866, acc: 0.9884259104728699)
[2024-12-17 03:02:39,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:40,164][root][INFO] - Training Epoch: 2/2, step 5085/7134 completed (loss: 0.02655693329870701, acc: 0.9917159676551819)
[2024-12-17 03:02:40,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:40,502][root][INFO] - Training Epoch: 2/2, step 5086/7134 completed (loss: 0.04894182085990906, acc: 0.9885641932487488)
[2024-12-17 03:02:40,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:40,856][root][INFO] - Training Epoch: 2/2, step 5087/7134 completed (loss: 0.01256508007645607, acc: 0.9959839582443237)
[2024-12-17 03:02:40,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:41,187][root][INFO] - Training Epoch: 2/2, step 5088/7134 completed (loss: 0.010853681713342667, acc: 0.9985358715057373)
[2024-12-17 03:02:41,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:41,540][root][INFO] - Training Epoch: 2/2, step 5089/7134 completed (loss: 0.03265082836151123, acc: 0.9925187230110168)
[2024-12-17 03:02:41,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:41,893][root][INFO] - Training Epoch: 2/2, step 5090/7134 completed (loss: 0.02855636551976204, acc: 0.9906651377677917)
[2024-12-17 03:02:41,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:42,228][root][INFO] - Training Epoch: 2/2, step 5091/7134 completed (loss: 0.015020174905657768, acc: 0.9973649382591248)
[2024-12-17 03:02:42,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:42,561][root][INFO] - Training Epoch: 2/2, step 5092/7134 completed (loss: 0.034053388983011246, acc: 0.9958506226539612)
[2024-12-17 03:02:42,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:42,891][root][INFO] - Training Epoch: 2/2, step 5093/7134 completed (loss: 0.033827949315309525, acc: 0.9903314709663391)
[2024-12-17 03:02:42,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:43,229][root][INFO] - Training Epoch: 2/2, step 5094/7134 completed (loss: 0.027917921543121338, acc: 0.9927272796630859)
[2024-12-17 03:02:43,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:43,547][root][INFO] - Training Epoch: 2/2, step 5095/7134 completed (loss: 0.12149657309055328, acc: 0.9765990376472473)
[2024-12-17 03:02:43,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:43,904][root][INFO] - Training Epoch: 2/2, step 5096/7134 completed (loss: 0.03783215209841728, acc: 0.9872832298278809)
[2024-12-17 03:02:43,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:44,256][root][INFO] - Training Epoch: 2/2, step 5097/7134 completed (loss: 0.03911268338561058, acc: 0.9865689873695374)
[2024-12-17 03:02:44,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:44,609][root][INFO] - Training Epoch: 2/2, step 5098/7134 completed (loss: 0.03250139206647873, acc: 0.9876265525817871)
[2024-12-17 03:02:44,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:44,975][root][INFO] - Training Epoch: 2/2, step 5099/7134 completed (loss: 0.03412647545337677, acc: 0.986143171787262)
[2024-12-17 03:02:45,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:45,338][root][INFO] - Training Epoch: 2/2, step 5100/7134 completed (loss: 0.047154322266578674, acc: 0.9889867901802063)
[2024-12-17 03:02:45,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:45,689][root][INFO] - Training Epoch: 2/2, step 5101/7134 completed (loss: 0.02699398063123226, acc: 0.9930070042610168)
[2024-12-17 03:02:45,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:46,017][root][INFO] - Training Epoch: 2/2, step 5102/7134 completed (loss: 0.05472014471888542, acc: 0.9822646379470825)
[2024-12-17 03:02:46,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:46,395][root][INFO] - Training Epoch: 2/2, step 5103/7134 completed (loss: 0.04124130308628082, acc: 0.9896907210350037)
[2024-12-17 03:02:46,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:46,774][root][INFO] - Training Epoch: 2/2, step 5104/7134 completed (loss: 0.016308998689055443, acc: 0.9977851510047913)
[2024-12-17 03:02:46,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:47,099][root][INFO] - Training Epoch: 2/2, step 5105/7134 completed (loss: 0.025192072615027428, acc: 0.9910581111907959)
[2024-12-17 03:02:47,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:47,443][root][INFO] - Training Epoch: 2/2, step 5106/7134 completed (loss: 0.021939216181635857, acc: 0.995555579662323)
[2024-12-17 03:02:47,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:47,783][root][INFO] - Training Epoch: 2/2, step 5107/7134 completed (loss: 0.10391126573085785, acc: 0.9778130054473877)
[2024-12-17 03:02:47,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:48,111][root][INFO] - Training Epoch: 2/2, step 5108/7134 completed (loss: 0.07814353704452515, acc: 0.9756097793579102)
[2024-12-17 03:02:48,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:48,489][root][INFO] - Training Epoch: 2/2, step 5109/7134 completed (loss: 0.06894045323133469, acc: 0.9834070801734924)
[2024-12-17 03:02:48,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:48,845][root][INFO] - Training Epoch: 2/2, step 5110/7134 completed (loss: 0.0669688954949379, acc: 0.9794871807098389)
[2024-12-17 03:02:48,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:49,178][root][INFO] - Training Epoch: 2/2, step 5111/7134 completed (loss: 0.029230551794171333, acc: 0.9931507110595703)
[2024-12-17 03:02:49,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:49,543][root][INFO] - Training Epoch: 2/2, step 5112/7134 completed (loss: 0.04922069236636162, acc: 0.9900373816490173)
[2024-12-17 03:02:49,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:49,866][root][INFO] - Training Epoch: 2/2, step 5113/7134 completed (loss: 0.0676126703619957, acc: 0.983582079410553)
[2024-12-17 03:02:50,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:50,246][root][INFO] - Training Epoch: 2/2, step 5114/7134 completed (loss: 0.025848394259810448, acc: 0.9930459260940552)
[2024-12-17 03:02:50,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:50,591][root][INFO] - Training Epoch: 2/2, step 5115/7134 completed (loss: 0.030648058280348778, acc: 0.9922580718994141)
[2024-12-17 03:02:50,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:50,965][root][INFO] - Training Epoch: 2/2, step 5116/7134 completed (loss: 0.02783457189798355, acc: 0.9922077655792236)
[2024-12-17 03:02:51,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:51,305][root][INFO] - Training Epoch: 2/2, step 5117/7134 completed (loss: 0.035675715655088425, acc: 0.9902371168136597)
[2024-12-17 03:02:51,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:51,622][root][INFO] - Training Epoch: 2/2, step 5118/7134 completed (loss: 0.0723034143447876, acc: 0.9863429665565491)
[2024-12-17 03:02:51,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:51,967][root][INFO] - Training Epoch: 2/2, step 5119/7134 completed (loss: 0.05240493640303612, acc: 0.9917469024658203)
[2024-12-17 03:02:52,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:52,312][root][INFO] - Training Epoch: 2/2, step 5120/7134 completed (loss: 0.06803223490715027, acc: 0.9842932224273682)
[2024-12-17 03:02:52,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:52,660][root][INFO] - Training Epoch: 2/2, step 5121/7134 completed (loss: 0.02381114661693573, acc: 0.994452178478241)
[2024-12-17 03:02:52,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:53,055][root][INFO] - Training Epoch: 2/2, step 5122/7134 completed (loss: 0.0695641040802002, acc: 0.9831223487854004)
[2024-12-17 03:02:53,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:53,421][root][INFO] - Training Epoch: 2/2, step 5123/7134 completed (loss: 0.03120625577867031, acc: 0.9927623867988586)
[2024-12-17 03:02:53,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:53,770][root][INFO] - Training Epoch: 2/2, step 5124/7134 completed (loss: 0.05645182356238365, acc: 0.9826086759567261)
[2024-12-17 03:02:53,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:54,113][root][INFO] - Training Epoch: 2/2, step 5125/7134 completed (loss: 0.025984350591897964, acc: 0.9936808943748474)
[2024-12-17 03:02:54,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:54,486][root][INFO] - Training Epoch: 2/2, step 5126/7134 completed (loss: 0.015393693931400776, acc: 0.9965811967849731)
[2024-12-17 03:02:54,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:54,839][root][INFO] - Training Epoch: 2/2, step 5127/7134 completed (loss: 0.05004472658038139, acc: 0.9860140085220337)
[2024-12-17 03:02:54,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:55,194][root][INFO] - Training Epoch: 2/2, step 5128/7134 completed (loss: 0.01937127858400345, acc: 0.9967032670974731)
[2024-12-17 03:02:55,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:55,537][root][INFO] - Training Epoch: 2/2, step 5129/7134 completed (loss: 0.06993069499731064, acc: 0.9823529124259949)
[2024-12-17 03:02:55,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:55,870][root][INFO] - Training Epoch: 2/2, step 5130/7134 completed (loss: 0.023744456470012665, acc: 0.9906396269798279)
[2024-12-17 03:02:55,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:56,229][root][INFO] - Training Epoch: 2/2, step 5131/7134 completed (loss: 0.03529546409845352, acc: 0.9951298832893372)
[2024-12-17 03:02:56,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:56,539][root][INFO] - Training Epoch: 2/2, step 5132/7134 completed (loss: 0.020877232775092125, acc: 0.9940593838691711)
[2024-12-17 03:02:56,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:56,876][root][INFO] - Training Epoch: 2/2, step 5133/7134 completed (loss: 0.05964465066790581, acc: 0.9829192757606506)
[2024-12-17 03:02:57,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:57,228][root][INFO] - Training Epoch: 2/2, step 5134/7134 completed (loss: 0.019187578931450844, acc: 0.998123824596405)
[2024-12-17 03:02:57,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:57,570][root][INFO] - Training Epoch: 2/2, step 5135/7134 completed (loss: 0.06465259939432144, acc: 0.9885714054107666)
[2024-12-17 03:02:57,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:57,919][root][INFO] - Training Epoch: 2/2, step 5136/7134 completed (loss: 0.03257911652326584, acc: 0.9918032884597778)
[2024-12-17 03:02:58,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:58,264][root][INFO] - Training Epoch: 2/2, step 5137/7134 completed (loss: 0.026243947446346283, acc: 0.9908257126808167)
[2024-12-17 03:02:58,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:58,626][root][INFO] - Training Epoch: 2/2, step 5138/7134 completed (loss: 0.027012823149561882, acc: 0.9912499785423279)
[2024-12-17 03:02:58,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:58,987][root][INFO] - Training Epoch: 2/2, step 5139/7134 completed (loss: 0.025026842951774597, acc: 0.9942775368690491)
[2024-12-17 03:02:59,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:59,348][root][INFO] - Training Epoch: 2/2, step 5140/7134 completed (loss: 0.02903490886092186, acc: 0.9925768971443176)
[2024-12-17 03:02:59,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:59,603][root][INFO] - Training Epoch: 2/2, step 5141/7134 completed (loss: 0.05201287195086479, acc: 0.9884169697761536)
[2024-12-17 03:02:59,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:59,979][root][INFO] - Training Epoch: 2/2, step 5142/7134 completed (loss: 0.03341348469257355, acc: 0.9905882477760315)
[2024-12-17 03:03:00,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:00,343][root][INFO] - Training Epoch: 2/2, step 5143/7134 completed (loss: 0.041939664632081985, acc: 0.9911167621612549)
[2024-12-17 03:03:00,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:00,700][root][INFO] - Training Epoch: 2/2, step 5144/7134 completed (loss: 0.019780172035098076, acc: 0.9964994192123413)
[2024-12-17 03:03:00,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:01,075][root][INFO] - Training Epoch: 2/2, step 5145/7134 completed (loss: 0.021673763170838356, acc: 0.9948822855949402)
[2024-12-17 03:03:01,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:01,468][root][INFO] - Training Epoch: 2/2, step 5146/7134 completed (loss: 0.05720604211091995, acc: 0.9832776188850403)
[2024-12-17 03:03:01,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:01,779][root][INFO] - Training Epoch: 2/2, step 5147/7134 completed (loss: 0.020907221361994743, acc: 0.9959016442298889)
[2024-12-17 03:03:01,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:02,113][root][INFO] - Training Epoch: 2/2, step 5148/7134 completed (loss: 0.07831772416830063, acc: 0.9866844415664673)
[2024-12-17 03:03:02,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:02,488][root][INFO] - Training Epoch: 2/2, step 5149/7134 completed (loss: 0.04587329551577568, acc: 0.9860696792602539)
[2024-12-17 03:03:02,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:02,830][root][INFO] - Training Epoch: 2/2, step 5150/7134 completed (loss: 0.06972923129796982, acc: 0.9856584072113037)
[2024-12-17 03:03:02,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:03,171][root][INFO] - Training Epoch: 2/2, step 5151/7134 completed (loss: 0.04117107763886452, acc: 0.9876237511634827)
[2024-12-17 03:03:03,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:03,523][root][INFO] - Training Epoch: 2/2, step 5152/7134 completed (loss: 0.03323011472821236, acc: 0.989276111125946)
[2024-12-17 03:03:03,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:03,882][root][INFO] - Training Epoch: 2/2, step 5153/7134 completed (loss: 0.02553802914917469, acc: 0.9945130348205566)
[2024-12-17 03:03:03,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:04,254][root][INFO] - Training Epoch: 2/2, step 5154/7134 completed (loss: 0.04683048650622368, acc: 0.9886234402656555)
[2024-12-17 03:03:04,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:04,699][root][INFO] - Training Epoch: 2/2, step 5155/7134 completed (loss: 0.056654367595911026, acc: 0.9864457845687866)
[2024-12-17 03:03:04,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:05,172][root][INFO] - Training Epoch: 2/2, step 5156/7134 completed (loss: 0.02523517794907093, acc: 0.9950347542762756)
[2024-12-17 03:03:05,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:05,551][root][INFO] - Training Epoch: 2/2, step 5157/7134 completed (loss: 0.08153830468654633, acc: 0.9767726063728333)
[2024-12-17 03:03:05,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:05,910][root][INFO] - Training Epoch: 2/2, step 5158/7134 completed (loss: 0.08597970753908157, acc: 0.9762611389160156)
[2024-12-17 03:03:06,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:06,264][root][INFO] - Training Epoch: 2/2, step 5159/7134 completed (loss: 0.0384395606815815, acc: 0.9895969033241272)
[2024-12-17 03:03:06,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:06,604][root][INFO] - Training Epoch: 2/2, step 5160/7134 completed (loss: 0.06174837425351143, acc: 0.9798271059989929)
[2024-12-17 03:03:06,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:06,948][root][INFO] - Training Epoch: 2/2, step 5161/7134 completed (loss: 0.08625070005655289, acc: 0.9748252034187317)
[2024-12-17 03:03:07,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:07,279][root][INFO] - Training Epoch: 2/2, step 5162/7134 completed (loss: 0.030498646199703217, acc: 0.9918962717056274)
[2024-12-17 03:03:07,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:07,605][root][INFO] - Training Epoch: 2/2, step 5163/7134 completed (loss: 0.028099583461880684, acc: 0.9915013909339905)
[2024-12-17 03:03:07,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:07,943][root][INFO] - Training Epoch: 2/2, step 5164/7134 completed (loss: 0.025945372879505157, acc: 0.9932773113250732)
[2024-12-17 03:03:08,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:08,312][root][INFO] - Training Epoch: 2/2, step 5165/7134 completed (loss: 0.049760278314352036, acc: 0.9864457845687866)
[2024-12-17 03:03:08,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:08,650][root][INFO] - Training Epoch: 2/2, step 5166/7134 completed (loss: 0.017818329855799675, acc: 0.9954338073730469)
[2024-12-17 03:03:08,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:08,981][root][INFO] - Training Epoch: 2/2, step 5167/7134 completed (loss: 0.07481700927019119, acc: 0.9775640964508057)
[2024-12-17 03:03:09,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:09,309][root][INFO] - Training Epoch: 2/2, step 5168/7134 completed (loss: 0.04543296620249748, acc: 0.989130437374115)
[2024-12-17 03:03:09,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:09,653][root][INFO] - Training Epoch: 2/2, step 5169/7134 completed (loss: 0.07188796252012253, acc: 0.9797507524490356)
[2024-12-17 03:03:09,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:10,002][root][INFO] - Training Epoch: 2/2, step 5170/7134 completed (loss: 0.03988996148109436, acc: 0.9867549538612366)
[2024-12-17 03:03:10,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:10,277][root][INFO] - Training Epoch: 2/2, step 5171/7134 completed (loss: 0.041501354426145554, acc: 0.9871794581413269)
[2024-12-17 03:03:10,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:10,619][root][INFO] - Training Epoch: 2/2, step 5172/7134 completed (loss: 0.10300517082214355, acc: 0.9727427363395691)
[2024-12-17 03:03:10,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:10,942][root][INFO] - Training Epoch: 2/2, step 5173/7134 completed (loss: 0.047184351831674576, acc: 0.9858267903327942)
[2024-12-17 03:03:11,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:11,299][root][INFO] - Training Epoch: 2/2, step 5174/7134 completed (loss: 0.021701699122786522, acc: 0.9961685538291931)
[2024-12-17 03:03:11,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:11,661][root][INFO] - Training Epoch: 2/2, step 5175/7134 completed (loss: 0.01600145734846592, acc: 0.9972375631332397)
[2024-12-17 03:03:11,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:12,018][root][INFO] - Training Epoch: 2/2, step 5176/7134 completed (loss: 0.01019768975675106, acc: 1.0)
[2024-12-17 03:03:12,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:12,381][root][INFO] - Training Epoch: 2/2, step 5177/7134 completed (loss: 0.07499679923057556, acc: 0.9808695912361145)
[2024-12-17 03:03:12,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:12,717][root][INFO] - Training Epoch: 2/2, step 5178/7134 completed (loss: 0.11636164039373398, acc: 0.9721254110336304)
[2024-12-17 03:03:12,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:13,056][root][INFO] - Training Epoch: 2/2, step 5179/7134 completed (loss: 0.02524341456592083, acc: 0.9896449446678162)
[2024-12-17 03:03:13,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:13,367][root][INFO] - Training Epoch: 2/2, step 5180/7134 completed (loss: 0.05681093409657478, acc: 0.9868667721748352)
[2024-12-17 03:03:13,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:13,653][root][INFO] - Training Epoch: 2/2, step 5181/7134 completed (loss: 0.07653138786554337, acc: 0.9840425252914429)
[2024-12-17 03:03:13,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:13,982][root][INFO] - Training Epoch: 2/2, step 5182/7134 completed (loss: 0.16230086982250214, acc: 0.9458333253860474)
[2024-12-17 03:03:14,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:14,316][root][INFO] - Training Epoch: 2/2, step 5183/7134 completed (loss: 0.07518637180328369, acc: 0.9884488582611084)
[2024-12-17 03:03:14,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:14,633][root][INFO] - Training Epoch: 2/2, step 5184/7134 completed (loss: 0.04719432443380356, acc: 0.9902200698852539)
[2024-12-17 03:03:14,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:14,965][root][INFO] - Training Epoch: 2/2, step 5185/7134 completed (loss: 0.044515643268823624, acc: 0.9879518151283264)
[2024-12-17 03:03:15,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:15,296][root][INFO] - Training Epoch: 2/2, step 5186/7134 completed (loss: 0.05119453743100166, acc: 0.9837067127227783)
[2024-12-17 03:03:15,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:15,624][root][INFO] - Training Epoch: 2/2, step 5187/7134 completed (loss: 0.02350158430635929, acc: 0.9923809766769409)
[2024-12-17 03:03:15,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:15,987][root][INFO] - Training Epoch: 2/2, step 5188/7134 completed (loss: 0.19337394833564758, acc: 0.9581817984580994)
[2024-12-17 03:03:16,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:16,237][root][INFO] - Training Epoch: 2/2, step 5189/7134 completed (loss: 0.1585470736026764, acc: 0.9668367505073547)
[2024-12-17 03:03:16,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:16,513][root][INFO] - Training Epoch: 2/2, step 5190/7134 completed (loss: 0.14858588576316833, acc: 0.95961993932724)
[2024-12-17 03:03:16,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:16,885][root][INFO] - Training Epoch: 2/2, step 5191/7134 completed (loss: 0.14094394445419312, acc: 0.9633967876434326)
[2024-12-17 03:03:17,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:17,245][root][INFO] - Training Epoch: 2/2, step 5192/7134 completed (loss: 0.07373584061861038, acc: 0.9833531379699707)
[2024-12-17 03:03:17,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:17,591][root][INFO] - Training Epoch: 2/2, step 5193/7134 completed (loss: 0.04775185510516167, acc: 0.9822834730148315)
[2024-12-17 03:03:17,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:17,925][root][INFO] - Training Epoch: 2/2, step 5194/7134 completed (loss: 0.11404474824666977, acc: 0.9643564224243164)
[2024-12-17 03:03:18,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:18,233][root][INFO] - Training Epoch: 2/2, step 5195/7134 completed (loss: 0.08472239971160889, acc: 0.9780701994895935)
[2024-12-17 03:03:18,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:18,559][root][INFO] - Training Epoch: 2/2, step 5196/7134 completed (loss: 0.08421077579259872, acc: 0.980861246585846)
[2024-12-17 03:03:18,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:18,885][root][INFO] - Training Epoch: 2/2, step 5197/7134 completed (loss: 0.0482478067278862, acc: 0.9855967164039612)
[2024-12-17 03:03:18,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:19,196][root][INFO] - Training Epoch: 2/2, step 5198/7134 completed (loss: 0.057907991111278534, acc: 0.9812889695167542)
[2024-12-17 03:03:19,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:19,570][root][INFO] - Training Epoch: 2/2, step 5199/7134 completed (loss: 0.11824482679367065, acc: 0.9694767594337463)
[2024-12-17 03:03:19,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:19,902][root][INFO] - Training Epoch: 2/2, step 5200/7134 completed (loss: 0.042776528745889664, acc: 0.990176796913147)
[2024-12-17 03:03:20,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:20,261][root][INFO] - Training Epoch: 2/2, step 5201/7134 completed (loss: 0.098758764564991, acc: 0.9758745431900024)
[2024-12-17 03:03:20,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:20,598][root][INFO] - Training Epoch: 2/2, step 5202/7134 completed (loss: 0.09582044929265976, acc: 0.9780219793319702)
[2024-12-17 03:03:20,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:20,959][root][INFO] - Training Epoch: 2/2, step 5203/7134 completed (loss: 0.0817701518535614, acc: 0.9823129177093506)
[2024-12-17 03:03:21,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:21,303][root][INFO] - Training Epoch: 2/2, step 5204/7134 completed (loss: 0.03961263224482536, acc: 0.985567033290863)
[2024-12-17 03:03:21,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:21,576][root][INFO] - Training Epoch: 2/2, step 5205/7134 completed (loss: 0.06743365526199341, acc: 0.9812734127044678)
[2024-12-17 03:03:21,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:21,938][root][INFO] - Training Epoch: 2/2, step 5206/7134 completed (loss: 0.10184315592050552, acc: 0.9759229421615601)
[2024-12-17 03:03:22,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:22,253][root][INFO] - Training Epoch: 2/2, step 5207/7134 completed (loss: 0.06356745958328247, acc: 0.9738430380821228)
[2024-12-17 03:03:22,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:22,647][root][INFO] - Training Epoch: 2/2, step 5208/7134 completed (loss: 0.032251693308353424, acc: 0.9947229623794556)
[2024-12-17 03:03:22,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:22,977][root][INFO] - Training Epoch: 2/2, step 5209/7134 completed (loss: 0.08262471109628677, acc: 0.9738956093788147)
[2024-12-17 03:03:23,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:23,354][root][INFO] - Training Epoch: 2/2, step 5210/7134 completed (loss: 0.05239943414926529, acc: 0.9893190860748291)
[2024-12-17 03:03:23,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:23,713][root][INFO] - Training Epoch: 2/2, step 5211/7134 completed (loss: 0.07219450920820236, acc: 0.9826388955116272)
[2024-12-17 03:03:23,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:23,995][root][INFO] - Training Epoch: 2/2, step 5212/7134 completed (loss: 0.10779214650392532, acc: 0.9590443968772888)
[2024-12-17 03:03:24,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:24,327][root][INFO] - Training Epoch: 2/2, step 5213/7134 completed (loss: 0.0674370527267456, acc: 0.9838129281997681)
[2024-12-17 03:03:24,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:24,644][root][INFO] - Training Epoch: 2/2, step 5214/7134 completed (loss: 0.13318443298339844, acc: 0.9678111672401428)
[2024-12-17 03:03:24,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:25,027][root][INFO] - Training Epoch: 2/2, step 5215/7134 completed (loss: 0.09207511693239212, acc: 0.9795657992362976)
[2024-12-17 03:03:25,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:25,271][root][INFO] - Training Epoch: 2/2, step 5216/7134 completed (loss: 0.0835472047328949, acc: 0.9771863222122192)
[2024-12-17 03:03:25,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:25,575][root][INFO] - Training Epoch: 2/2, step 5217/7134 completed (loss: 0.07138454914093018, acc: 0.9786585569381714)
[2024-12-17 03:03:25,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:25,888][root][INFO] - Training Epoch: 2/2, step 5218/7134 completed (loss: 0.04696549102663994, acc: 0.9820224642753601)
[2024-12-17 03:03:25,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:26,195][root][INFO] - Training Epoch: 2/2, step 5219/7134 completed (loss: 0.06084108725190163, acc: 0.9878934621810913)
[2024-12-17 03:03:26,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:26,469][root][INFO] - Training Epoch: 2/2, step 5220/7134 completed (loss: 0.08153940737247467, acc: 0.9785330891609192)
[2024-12-17 03:03:26,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:26,824][root][INFO] - Training Epoch: 2/2, step 5221/7134 completed (loss: 0.1057734414935112, acc: 0.9781931638717651)
[2024-12-17 03:03:26,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:27,092][root][INFO] - Training Epoch: 2/2, step 5222/7134 completed (loss: 0.04323185235261917, acc: 0.9906542301177979)
[2024-12-17 03:03:27,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:27,431][root][INFO] - Training Epoch: 2/2, step 5223/7134 completed (loss: 0.0418853834271431, acc: 0.9907833933830261)
[2024-12-17 03:03:27,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:27,759][root][INFO] - Training Epoch: 2/2, step 5224/7134 completed (loss: 0.059500355273485184, acc: 0.9859402179718018)
[2024-12-17 03:03:27,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:28,106][root][INFO] - Training Epoch: 2/2, step 5225/7134 completed (loss: 0.11310015618801117, acc: 0.9773828983306885)
[2024-12-17 03:03:28,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:28,447][root][INFO] - Training Epoch: 2/2, step 5226/7134 completed (loss: 0.0668981745839119, acc: 0.9884678721427917)
[2024-12-17 03:03:28,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:28,810][root][INFO] - Training Epoch: 2/2, step 5227/7134 completed (loss: 0.0357733853161335, acc: 0.9935064911842346)
[2024-12-17 03:03:28,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:29,136][root][INFO] - Training Epoch: 2/2, step 5228/7134 completed (loss: 0.051058296114206314, acc: 0.9869186282157898)
[2024-12-17 03:03:29,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:29,477][root][INFO] - Training Epoch: 2/2, step 5229/7134 completed (loss: 0.036214035004377365, acc: 0.98959881067276)
[2024-12-17 03:03:29,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:29,821][root][INFO] - Training Epoch: 2/2, step 5230/7134 completed (loss: 0.0320470929145813, acc: 0.9946091771125793)
[2024-12-17 03:03:29,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:30,183][root][INFO] - Training Epoch: 2/2, step 5231/7134 completed (loss: 0.02633090130984783, acc: 0.9924050569534302)
[2024-12-17 03:03:30,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:30,531][root][INFO] - Training Epoch: 2/2, step 5232/7134 completed (loss: 0.043969374150037766, acc: 0.9865471124649048)
[2024-12-17 03:03:30,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:30,905][root][INFO] - Training Epoch: 2/2, step 5233/7134 completed (loss: 0.03984597697854042, acc: 0.9909909963607788)
[2024-12-17 03:03:31,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:31,274][root][INFO] - Training Epoch: 2/2, step 5234/7134 completed (loss: 0.037767231464385986, acc: 0.9914320707321167)
[2024-12-17 03:03:31,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:31,596][root][INFO] - Training Epoch: 2/2, step 5235/7134 completed (loss: 0.03263704106211662, acc: 0.9915966391563416)
[2024-12-17 03:03:31,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:31,926][root][INFO] - Training Epoch: 2/2, step 5236/7134 completed (loss: 0.009987499564886093, acc: 0.9965277910232544)
[2024-12-17 03:03:32,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:32,278][root][INFO] - Training Epoch: 2/2, step 5237/7134 completed (loss: 0.008424664847552776, acc: 0.9982078671455383)
[2024-12-17 03:03:32,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:32,623][root][INFO] - Training Epoch: 2/2, step 5238/7134 completed (loss: 0.0196138434112072, acc: 0.9929577708244324)
[2024-12-17 03:03:32,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:32,940][root][INFO] - Training Epoch: 2/2, step 5239/7134 completed (loss: 0.03070199117064476, acc: 0.9884169697761536)
[2024-12-17 03:03:33,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:33,278][root][INFO] - Training Epoch: 2/2, step 5240/7134 completed (loss: 0.025005243718624115, acc: 0.9944674968719482)
[2024-12-17 03:03:33,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:33,616][root][INFO] - Training Epoch: 2/2, step 5241/7134 completed (loss: 0.04720277711749077, acc: 0.9890282154083252)
[2024-12-17 03:03:33,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:33,979][root][INFO] - Training Epoch: 2/2, step 5242/7134 completed (loss: 0.031114915385842323, acc: 0.9917355179786682)
[2024-12-17 03:03:34,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:34,304][root][INFO] - Training Epoch: 2/2, step 5243/7134 completed (loss: 0.03402475267648697, acc: 0.9896551966667175)
[2024-12-17 03:03:34,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:34,622][root][INFO] - Training Epoch: 2/2, step 5244/7134 completed (loss: 0.037731703370809555, acc: 0.9903448224067688)
[2024-12-17 03:03:34,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:35,022][root][INFO] - Training Epoch: 2/2, step 5245/7134 completed (loss: 0.029337724670767784, acc: 0.9930192232131958)
[2024-12-17 03:03:35,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:35,346][root][INFO] - Training Epoch: 2/2, step 5246/7134 completed (loss: 0.029711585491895676, acc: 0.9892638325691223)
[2024-12-17 03:03:35,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:35,672][root][INFO] - Training Epoch: 2/2, step 5247/7134 completed (loss: 0.021428469568490982, acc: 0.9962962865829468)
[2024-12-17 03:03:35,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:35,998][root][INFO] - Training Epoch: 2/2, step 5248/7134 completed (loss: 0.06602419167757034, acc: 0.9850187301635742)
[2024-12-17 03:03:36,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:36,329][root][INFO] - Training Epoch: 2/2, step 5249/7134 completed (loss: 0.01272533182054758, acc: 0.9952830076217651)
[2024-12-17 03:03:36,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:36,693][root][INFO] - Training Epoch: 2/2, step 5250/7134 completed (loss: 0.029104935005307198, acc: 0.9924337863922119)
[2024-12-17 03:03:36,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:37,052][root][INFO] - Training Epoch: 2/2, step 5251/7134 completed (loss: 0.03585776686668396, acc: 0.9866666793823242)
[2024-12-17 03:03:37,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:37,365][root][INFO] - Training Epoch: 2/2, step 5252/7134 completed (loss: 0.057144634425640106, acc: 0.9836448431015015)
[2024-12-17 03:03:37,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:37,707][root][INFO] - Training Epoch: 2/2, step 5253/7134 completed (loss: 0.03574705496430397, acc: 0.9869281053543091)
[2024-12-17 03:03:37,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:38,057][root][INFO] - Training Epoch: 2/2, step 5254/7134 completed (loss: 0.05987456813454628, acc: 0.9881154298782349)
[2024-12-17 03:03:38,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:38,405][root][INFO] - Training Epoch: 2/2, step 5255/7134 completed (loss: 0.04660186916589737, acc: 0.9876712560653687)
[2024-12-17 03:03:38,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:38,758][root][INFO] - Training Epoch: 2/2, step 5256/7134 completed (loss: 0.06481446325778961, acc: 0.9876352548599243)
[2024-12-17 03:03:38,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:39,105][root][INFO] - Training Epoch: 2/2, step 5257/7134 completed (loss: 0.08448309451341629, acc: 0.9802131056785583)
[2024-12-17 03:03:39,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:39,462][root][INFO] - Training Epoch: 2/2, step 5258/7134 completed (loss: 0.060785431414842606, acc: 0.9885203838348389)
[2024-12-17 03:03:39,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:39,814][root][INFO] - Training Epoch: 2/2, step 5259/7134 completed (loss: 0.06895969808101654, acc: 0.982594907283783)
[2024-12-17 03:03:39,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:40,185][root][INFO] - Training Epoch: 2/2, step 5260/7134 completed (loss: 0.0379992239177227, acc: 0.9878048896789551)
[2024-12-17 03:03:40,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:40,519][root][INFO] - Training Epoch: 2/2, step 5261/7134 completed (loss: 0.0756857767701149, acc: 0.9769230484962463)
[2024-12-17 03:03:40,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:40,888][root][INFO] - Training Epoch: 2/2, step 5262/7134 completed (loss: 0.03297315537929535, acc: 0.9889655113220215)
[2024-12-17 03:03:40,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:41,215][root][INFO] - Training Epoch: 2/2, step 5263/7134 completed (loss: 0.06730129569768906, acc: 0.9859648942947388)
[2024-12-17 03:03:41,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:41,585][root][INFO] - Training Epoch: 2/2, step 5264/7134 completed (loss: 0.03908666595816612, acc: 0.9878493547439575)
[2024-12-17 03:03:41,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:41,937][root][INFO] - Training Epoch: 2/2, step 5265/7134 completed (loss: 0.06061223894357681, acc: 0.9834815859794617)
[2024-12-17 03:03:42,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:42,263][root][INFO] - Training Epoch: 2/2, step 5266/7134 completed (loss: 0.03104294277727604, acc: 0.9904109835624695)
[2024-12-17 03:03:42,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:42,578][root][INFO] - Training Epoch: 2/2, step 5267/7134 completed (loss: 0.08666937053203583, acc: 0.9735614061355591)
[2024-12-17 03:03:42,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:42,903][root][INFO] - Training Epoch: 2/2, step 5268/7134 completed (loss: 0.05012965574860573, acc: 0.9827255010604858)
[2024-12-17 03:03:42,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:43,238][root][INFO] - Training Epoch: 2/2, step 5269/7134 completed (loss: 0.08335381001234055, acc: 0.980322003364563)
[2024-12-17 03:03:43,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:43,605][root][INFO] - Training Epoch: 2/2, step 5270/7134 completed (loss: 0.04111207276582718, acc: 0.990641713142395)
[2024-12-17 03:03:43,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:43,950][root][INFO] - Training Epoch: 2/2, step 5271/7134 completed (loss: 0.07357119768857956, acc: 0.9841269850730896)
[2024-12-17 03:03:44,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:44,282][root][INFO] - Training Epoch: 2/2, step 5272/7134 completed (loss: 0.05768783763051033, acc: 0.9824047088623047)
[2024-12-17 03:03:44,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:44,626][root][INFO] - Training Epoch: 2/2, step 5273/7134 completed (loss: 0.034822721034288406, acc: 0.9881154298782349)
[2024-12-17 03:03:44,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:44,958][root][INFO] - Training Epoch: 2/2, step 5274/7134 completed (loss: 0.06361275166273117, acc: 0.9895522594451904)
[2024-12-17 03:03:45,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:45,303][root][INFO] - Training Epoch: 2/2, step 5275/7134 completed (loss: 0.03813553601503372, acc: 0.9853747487068176)
[2024-12-17 03:03:45,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:45,626][root][INFO] - Training Epoch: 2/2, step 5276/7134 completed (loss: 0.03219037875533104, acc: 0.9865471124649048)
[2024-12-17 03:03:45,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:45,945][root][INFO] - Training Epoch: 2/2, step 5277/7134 completed (loss: 0.05664196237921715, acc: 0.9783861637115479)
[2024-12-17 03:03:46,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:46,277][root][INFO] - Training Epoch: 2/2, step 5278/7134 completed (loss: 0.08736398071050644, acc: 0.9785932898521423)
[2024-12-17 03:03:46,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:46,615][root][INFO] - Training Epoch: 2/2, step 5279/7134 completed (loss: 0.03100578300654888, acc: 0.9922178983688354)
[2024-12-17 03:03:46,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:46,949][root][INFO] - Training Epoch: 2/2, step 5280/7134 completed (loss: 0.041153550148010254, acc: 0.9900497794151306)
[2024-12-17 03:03:47,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:47,283][root][INFO] - Training Epoch: 2/2, step 5281/7134 completed (loss: 0.050952814519405365, acc: 0.9866888523101807)
[2024-12-17 03:03:47,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:47,605][root][INFO] - Training Epoch: 2/2, step 5282/7134 completed (loss: 0.040758632123470306, acc: 0.9871612191200256)
[2024-12-17 03:03:47,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:47,935][root][INFO] - Training Epoch: 2/2, step 5283/7134 completed (loss: 0.03583921864628792, acc: 0.9931600689888)
[2024-12-17 03:03:48,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:48,269][root][INFO] - Training Epoch: 2/2, step 5284/7134 completed (loss: 0.05886993929743767, acc: 0.9917012453079224)
[2024-12-17 03:03:48,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:48,632][root][INFO] - Training Epoch: 2/2, step 5285/7134 completed (loss: 0.0291096493601799, acc: 0.9940828680992126)
[2024-12-17 03:03:48,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:48,986][root][INFO] - Training Epoch: 2/2, step 5286/7134 completed (loss: 0.05474900081753731, acc: 0.9852941036224365)
[2024-12-17 03:03:49,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:49,335][root][INFO] - Training Epoch: 2/2, step 5287/7134 completed (loss: 0.043392010033130646, acc: 0.9864498376846313)
[2024-12-17 03:03:49,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:49,661][root][INFO] - Training Epoch: 2/2, step 5288/7134 completed (loss: 0.018098030239343643, acc: 0.995398759841919)
[2024-12-17 03:03:49,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:50,021][root][INFO] - Training Epoch: 2/2, step 5289/7134 completed (loss: 0.04478193074464798, acc: 0.9872521162033081)
[2024-12-17 03:03:50,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:50,384][root][INFO] - Training Epoch: 2/2, step 5290/7134 completed (loss: 0.053484153002500534, acc: 0.9873417615890503)
[2024-12-17 03:03:50,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:50,752][root][INFO] - Training Epoch: 2/2, step 5291/7134 completed (loss: 0.02988887019455433, acc: 0.9927272796630859)
[2024-12-17 03:03:50,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:51,108][root][INFO] - Training Epoch: 2/2, step 5292/7134 completed (loss: 0.022516196593642235, acc: 0.9923664331436157)
[2024-12-17 03:03:51,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:51,456][root][INFO] - Training Epoch: 2/2, step 5293/7134 completed (loss: 0.05388600006699562, acc: 0.9810218811035156)
[2024-12-17 03:03:51,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:51,806][root][INFO] - Training Epoch: 2/2, step 5294/7134 completed (loss: 0.03261766582727432, acc: 0.9930264949798584)
[2024-12-17 03:03:51,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:52,124][root][INFO] - Training Epoch: 2/2, step 5295/7134 completed (loss: 0.02401740849018097, acc: 0.9926470518112183)
[2024-12-17 03:03:52,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:52,464][root][INFO] - Training Epoch: 2/2, step 5296/7134 completed (loss: 0.03499729558825493, acc: 0.9916550517082214)
[2024-12-17 03:03:52,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:52,798][root][INFO] - Training Epoch: 2/2, step 5297/7134 completed (loss: 0.03531248867511749, acc: 0.9885057210922241)
[2024-12-17 03:03:52,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:53,194][root][INFO] - Training Epoch: 2/2, step 5298/7134 completed (loss: 0.04437997192144394, acc: 0.9897435903549194)
[2024-12-17 03:03:53,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:53,520][root][INFO] - Training Epoch: 2/2, step 5299/7134 completed (loss: 0.032202936708927155, acc: 0.9935794472694397)
[2024-12-17 03:03:53,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:53,862][root][INFO] - Training Epoch: 2/2, step 5300/7134 completed (loss: 0.03963477909564972, acc: 0.988252580165863)
[2024-12-17 03:03:53,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:54,188][root][INFO] - Training Epoch: 2/2, step 5301/7134 completed (loss: 0.026183713227510452, acc: 0.9911894202232361)
[2024-12-17 03:03:54,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:54,547][root][INFO] - Training Epoch: 2/2, step 5302/7134 completed (loss: 0.08178550750017166, acc: 0.9832826852798462)
[2024-12-17 03:03:54,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:54,899][root][INFO] - Training Epoch: 2/2, step 5303/7134 completed (loss: 0.06085994839668274, acc: 0.9876106381416321)
[2024-12-17 03:03:54,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:55,232][root][INFO] - Training Epoch: 2/2, step 5304/7134 completed (loss: 0.08058784157037735, acc: 0.980033278465271)
[2024-12-17 03:03:55,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:55,562][root][INFO] - Training Epoch: 2/2, step 5305/7134 completed (loss: 0.07900173962116241, acc: 0.9795620441436768)
[2024-12-17 03:03:55,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:55,895][root][INFO] - Training Epoch: 2/2, step 5306/7134 completed (loss: 0.05193952098488808, acc: 0.9861111044883728)
[2024-12-17 03:03:55,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:56,228][root][INFO] - Training Epoch: 2/2, step 5307/7134 completed (loss: 0.08066637068986893, acc: 0.9845678806304932)
[2024-12-17 03:03:56,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:56,570][root][INFO] - Training Epoch: 2/2, step 5308/7134 completed (loss: 0.04805093631148338, acc: 0.9924471378326416)
[2024-12-17 03:03:56,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:56,898][root][INFO] - Training Epoch: 2/2, step 5309/7134 completed (loss: 0.12205661088228226, acc: 0.971377432346344)
[2024-12-17 03:03:56,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:57,244][root][INFO] - Training Epoch: 2/2, step 5310/7134 completed (loss: 0.08537185192108154, acc: 0.9762901067733765)
[2024-12-17 03:03:57,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:57,584][root][INFO] - Training Epoch: 2/2, step 5311/7134 completed (loss: 0.11726690083742142, acc: 0.9759229421615601)
[2024-12-17 03:03:57,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:57,896][root][INFO] - Training Epoch: 2/2, step 5312/7134 completed (loss: 0.039929743856191635, acc: 0.9868667721748352)
[2024-12-17 03:03:58,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:58,255][root][INFO] - Training Epoch: 2/2, step 5313/7134 completed (loss: 0.055746156722307205, acc: 0.9836065769195557)
[2024-12-17 03:03:58,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:58,584][root][INFO] - Training Epoch: 2/2, step 5314/7134 completed (loss: 0.04282265529036522, acc: 0.9860627055168152)
[2024-12-17 03:03:58,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:58,935][root][INFO] - Training Epoch: 2/2, step 5315/7134 completed (loss: 0.02955794520676136, acc: 0.9918166995048523)
[2024-12-17 03:03:59,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:59,268][root][INFO] - Training Epoch: 2/2, step 5316/7134 completed (loss: 0.043512530624866486, acc: 0.9915966391563416)
[2024-12-17 03:03:59,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:59,568][root][INFO] - Training Epoch: 2/2, step 5317/7134 completed (loss: 0.03464397415518761, acc: 0.9874551892280579)
[2024-12-17 03:03:59,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:59,892][root][INFO] - Training Epoch: 2/2, step 5318/7134 completed (loss: 0.019611945375800133, acc: 0.9948186278343201)
[2024-12-17 03:04:00,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:00,224][root][INFO] - Training Epoch: 2/2, step 5319/7134 completed (loss: 0.05590864643454552, acc: 0.985401451587677)
[2024-12-17 03:04:00,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:00,565][root][INFO] - Training Epoch: 2/2, step 5320/7134 completed (loss: 0.039007581770420074, acc: 0.9922360181808472)
[2024-12-17 03:04:00,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:00,903][root][INFO] - Training Epoch: 2/2, step 5321/7134 completed (loss: 0.0313945971429348, acc: 0.9922480583190918)
[2024-12-17 03:04:01,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:01,250][root][INFO] - Training Epoch: 2/2, step 5322/7134 completed (loss: 0.023511050269007683, acc: 0.9924585223197937)
[2024-12-17 03:04:01,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:01,606][root][INFO] - Training Epoch: 2/2, step 5323/7134 completed (loss: 0.038713857531547546, acc: 0.9878787994384766)
[2024-12-17 03:04:01,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:01,956][root][INFO] - Training Epoch: 2/2, step 5324/7134 completed (loss: 0.03989920765161514, acc: 0.9876352548599243)
[2024-12-17 03:04:02,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:02,337][root][INFO] - Training Epoch: 2/2, step 5325/7134 completed (loss: 0.01967858150601387, acc: 0.9965928196907043)
[2024-12-17 03:04:02,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:02,674][root][INFO] - Training Epoch: 2/2, step 5326/7134 completed (loss: 0.03491082787513733, acc: 0.9887096881866455)
[2024-12-17 03:04:02,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:03,000][root][INFO] - Training Epoch: 2/2, step 5327/7134 completed (loss: 0.031801898032426834, acc: 0.9927431344985962)
[2024-12-17 03:04:03,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:03,315][root][INFO] - Training Epoch: 2/2, step 5328/7134 completed (loss: 0.03554964065551758, acc: 0.9926605224609375)
[2024-12-17 03:04:03,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:03,642][root][INFO] - Training Epoch: 2/2, step 5329/7134 completed (loss: 0.04694882780313492, acc: 0.9821717739105225)
[2024-12-17 03:04:03,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:03,972][root][INFO] - Training Epoch: 2/2, step 5330/7134 completed (loss: 0.046414900571107864, acc: 0.9859374761581421)
[2024-12-17 03:04:04,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:04,298][root][INFO] - Training Epoch: 2/2, step 5331/7134 completed (loss: 0.0554102398455143, acc: 0.9877408146858215)
[2024-12-17 03:04:04,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:04,643][root][INFO] - Training Epoch: 2/2, step 5332/7134 completed (loss: 0.04151954874396324, acc: 0.9934959411621094)
[2024-12-17 03:04:04,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:04,983][root][INFO] - Training Epoch: 2/2, step 5333/7134 completed (loss: 0.02058032527565956, acc: 0.9922118186950684)
[2024-12-17 03:04:05,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:05,315][root][INFO] - Training Epoch: 2/2, step 5334/7134 completed (loss: 0.07467419654130936, acc: 0.9846860766410828)
[2024-12-17 03:04:05,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:05,639][root][INFO] - Training Epoch: 2/2, step 5335/7134 completed (loss: 0.05003202706575394, acc: 0.9888178706169128)
[2024-12-17 03:04:05,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:05,981][root][INFO] - Training Epoch: 2/2, step 5336/7134 completed (loss: 0.0442480593919754, acc: 0.9859374761581421)
[2024-12-17 03:04:06,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:06,340][root][INFO] - Training Epoch: 2/2, step 5337/7134 completed (loss: 0.03130500391125679, acc: 0.9866369962692261)
[2024-12-17 03:04:06,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:06,729][root][INFO] - Training Epoch: 2/2, step 5338/7134 completed (loss: 0.019276008009910583, acc: 0.9954338073730469)
[2024-12-17 03:04:06,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:07,053][root][INFO] - Training Epoch: 2/2, step 5339/7134 completed (loss: 0.07036689668893814, acc: 0.9857512712478638)
[2024-12-17 03:04:07,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:07,410][root][INFO] - Training Epoch: 2/2, step 5340/7134 completed (loss: 0.07194531708955765, acc: 0.9774696826934814)
[2024-12-17 03:04:07,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:07,754][root][INFO] - Training Epoch: 2/2, step 5341/7134 completed (loss: 0.026501981541514397, acc: 0.993220329284668)
[2024-12-17 03:04:07,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:08,116][root][INFO] - Training Epoch: 2/2, step 5342/7134 completed (loss: 0.08349950611591339, acc: 0.974700391292572)
[2024-12-17 03:04:08,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:08,467][root][INFO] - Training Epoch: 2/2, step 5343/7134 completed (loss: 0.08028127253055573, acc: 0.9828495979309082)
[2024-12-17 03:04:08,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:08,825][root][INFO] - Training Epoch: 2/2, step 5344/7134 completed (loss: 0.04517335444688797, acc: 0.9915789365768433)
[2024-12-17 03:04:08,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:09,171][root][INFO] - Training Epoch: 2/2, step 5345/7134 completed (loss: 0.046531397849321365, acc: 0.9896551966667175)
[2024-12-17 03:04:09,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:09,517][root][INFO] - Training Epoch: 2/2, step 5346/7134 completed (loss: 0.07402998208999634, acc: 0.9821615815162659)
[2024-12-17 03:04:10,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:10,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:10,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:11,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:11,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:11,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:12,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:12,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:12,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:12,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:13,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:13,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:13,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:14,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:14,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:14,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:14,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:15,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:15,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:15,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:16,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:16,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:16,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:16,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:17,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:17,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:17,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:17,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:18,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:18,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:18,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:19,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:19,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:19,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:20,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:20,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:20,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:20,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:21,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:21,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:21,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:21,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:22,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:22,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:22,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:23,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:23,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:23,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:24,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:24,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:24,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:24,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:25,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:25,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:25,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:25,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:26,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:26,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:26,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:26,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:27,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:27,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:27,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:27,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:28,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:28,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:28,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:28,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:29,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:29,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:29,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:29,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:30,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:30,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:30,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:30,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:31,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:31,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:31,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:32,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:32,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:32,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:32,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:33,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:33,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:33,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:33,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:34,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:34,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:34,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:35,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:35,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:35,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:35,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:36,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:36,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:36,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:36,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:37,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:37,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:37,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:37,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:37,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:38,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:38,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:38,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:39,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:39,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:39,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:39,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:40,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:40,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:40,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:41,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:41,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:41,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:42,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:42,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:42,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:42,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:43,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:43,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:43,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:44,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:44,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:44,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:44,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:45,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:45,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:45,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:45,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:46,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:46,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:46,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:47,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:47,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:47,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:47,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:48,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:48,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:48,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:49,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:49,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:49,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:49,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:50,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:50,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:50,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:50,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:51,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:51,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:51,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:51,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:52,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:52,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:52,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:52,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:53,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:53,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:53,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:54,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:54,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:54,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:54,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:55,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:55,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:55,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:56,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:56,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:56,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:57,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:57,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:57,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:57,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:58,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:58,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:58,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:59,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:59,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:59,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:59,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:59,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:00,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:00,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:00,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:01,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:01,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:01,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:01,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:02,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:02,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:02,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:03,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:03,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:03,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:03,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:04,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:04,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:04,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:04,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:05,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:05,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:05,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:05,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:06,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:06,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:06,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:06,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:07,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:07,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:07,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:08,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:08,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:08,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:08,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:09,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:09,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:09,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:10,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:10,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:10,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:10,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:11,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:11,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:11,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:11,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:12,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:12,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:12,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:12,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:13,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:13,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:13,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:13,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:14,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:14,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:14,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:15,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:15,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:15,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:15,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:16,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:16,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:16,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:17,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:17,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:17,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:18,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:18,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:18,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:19,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:19,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:19,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:20,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:20,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:20,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:21,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:21,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:21,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:21,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:22,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:22,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:22,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:22,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:23,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:23,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:23,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:23,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:24,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:24,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:24,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:25,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:25,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:25,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:26,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:26,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:26,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:26,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:27,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:27,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:27,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:28,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:28,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:29,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:29,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:29,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:29,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:30,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:30,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:30,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:31,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:31,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:32,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:32,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:32,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:33,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:33,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:33,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:34,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:34,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:34,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:34,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:35,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:35,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:35,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:35,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:36,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:36,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:36,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:36,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:37,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:37,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:37,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:37,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:38,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:38,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:38,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:38,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:39,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:39,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:39,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:40,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:40,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:40,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:40,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:41,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:41,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:41,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:42,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:42,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:42,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:43,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:43,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:43,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:44,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:44,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:44,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:44,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:45,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:45,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:45,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:46,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:46,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:47,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:47,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:47,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:48,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:48,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:48,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:48,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:49,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:49,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:49,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:50,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:50,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:50,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:50,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:51,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:51,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:51,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:52,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:52,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:53,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:53,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:54,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:54,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:54,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:55,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:55,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:55,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:56,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:56,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:56,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:56,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:56,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:57,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:57,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:57,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:57,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:58,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:58,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:58,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:59,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:59,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:59,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:59,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:00,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:00,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:00,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:00,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:01,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:01,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:01,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:01,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:02,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:02,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:02,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:03,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:03,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:03,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:03,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:04,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:04,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:04,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:05,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:05,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:05,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:06,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:06,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:06,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:06,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:07,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:07,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:07,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:07,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:08,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:08,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:08,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:09,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:09,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:09,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:09,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:10,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:10,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:10,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:10,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:11,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:11,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:11,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:11,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:12,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:12,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:12,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:12,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:13,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:13,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:13,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:13,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:13,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:14,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:14,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:14,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:15,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:15,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:15,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:16,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:16,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:16,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:16,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:17,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:17,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:17,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:17,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:18,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:18,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:18,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:18,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:19,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:19,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:19,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:19,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:20,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:20,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:20,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:20,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:21,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:21,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:21,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:22,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:22,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:22,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:22,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:23,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:23,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:23,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:23,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:24,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:24,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:24,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:25,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:25,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:25,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:26,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:26,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:26,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:26,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:27,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:27,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:27,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:27,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:28,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:28,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:28,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:29,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:29,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:29,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:30,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:30,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:30,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:31,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:31,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:31,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:32,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:32,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:32,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:33,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:33,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:33,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:33,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:34,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:34,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:34,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:34,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:35,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:35,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:35,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:36,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:36,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:36,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:37,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:37,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:37,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:37,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:37,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:38,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:38,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:38,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:39,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:39,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:39,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:40,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:40,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:40,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:40,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:41,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:41,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:41,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:42,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:42,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:42,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:43,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:43,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:43,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:43,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:44,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:44,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:44,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:44,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:45,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:45,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:45,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:45,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:46,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:46,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:46,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:47,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:47,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:47,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:48,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:48,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:48,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:49,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:49,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:49,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:49,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:50,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:50,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:50,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:51,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:51,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:51,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:51,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:52,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:52,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:52,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:53,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:53,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:53,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:54,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:54,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:54,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:55,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:55,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:55,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:56,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:56,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:56,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:57,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:57,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:57,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:57,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:58,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:58,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:58,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:59,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:59,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:59,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:59,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:00,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:00,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:00,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:00,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:01,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:01,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:01,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:01,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:02,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:02,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:02,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:02,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:03,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:03,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:03,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:04,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:04,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:04,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:04,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:05,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:05,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:05,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:05,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:06,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:06,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:06,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:07,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:07,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:08,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:08,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:09,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:09,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:09,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:10,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:10,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:10,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:11,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:11,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:11,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:12,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:12,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:12,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:12,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:13,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:13,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:13,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:13,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:14,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:14,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:15,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:15,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:15,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:16,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:16,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:16,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:16,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:17,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:17,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:17,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:18,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:18,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:18,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:19,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:19,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:19,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:20,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:20,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:20,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:20,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:21,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:21,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:21,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:22,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:22,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:22,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:23,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:23,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:24,237][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.0738, device='cuda:0') eval_epoch_loss=tensor(0.0712, device='cuda:0') eval_epoch_acc=tensor(0.9817, device='cuda:0')
[2024-12-17 03:07:24,238][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-12-17 03:07:24,239][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 03:07:24,440][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_2_step_5347_loss_0.07123670727014542/model.pt
[2024-12-17 03:07:24,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:24,814][root][INFO] - Training Epoch: 2/2, step 5347/7134 completed (loss: 0.03482351079583168, acc: 0.9920424222946167)
[2024-12-17 03:07:24,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:25,185][root][INFO] - Training Epoch: 2/2, step 5348/7134 completed (loss: 0.05611144006252289, acc: 0.9861496090888977)
[2024-12-17 03:07:25,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:25,544][root][INFO] - Training Epoch: 2/2, step 5349/7134 completed (loss: 0.07879535108804703, acc: 0.9767441749572754)
[2024-12-17 03:07:25,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:25,896][root][INFO] - Training Epoch: 2/2, step 5350/7134 completed (loss: 0.06590326130390167, acc: 0.9788639545440674)
[2024-12-17 03:07:26,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:26,230][root][INFO] - Training Epoch: 2/2, step 5351/7134 completed (loss: 0.05309927836060524, acc: 0.985111653804779)
[2024-12-17 03:07:26,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:26,564][root][INFO] - Training Epoch: 2/2, step 5352/7134 completed (loss: 0.02570268325507641, acc: 0.9909443855285645)
[2024-12-17 03:07:26,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:26,938][root][INFO] - Training Epoch: 2/2, step 5353/7134 completed (loss: 0.015737779438495636, acc: 0.9954904317855835)
[2024-12-17 03:07:27,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:27,304][root][INFO] - Training Epoch: 2/2, step 5354/7134 completed (loss: 0.055166617035865784, acc: 0.9823788404464722)
[2024-12-17 03:07:27,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:27,654][root][INFO] - Training Epoch: 2/2, step 5355/7134 completed (loss: 0.09338492900133133, acc: 0.978723406791687)
[2024-12-17 03:07:27,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:28,010][root][INFO] - Training Epoch: 2/2, step 5356/7134 completed (loss: 0.08213941007852554, acc: 0.975093424320221)
[2024-12-17 03:07:28,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:28,347][root][INFO] - Training Epoch: 2/2, step 5357/7134 completed (loss: 0.04325051233172417, acc: 0.9860627055168152)
[2024-12-17 03:07:28,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:28,709][root][INFO] - Training Epoch: 2/2, step 5358/7134 completed (loss: 0.06711197644472122, acc: 0.9862068891525269)
[2024-12-17 03:07:28,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:29,056][root][INFO] - Training Epoch: 2/2, step 5359/7134 completed (loss: 0.029397539794445038, acc: 0.9906759858131409)
[2024-12-17 03:07:29,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:29,405][root][INFO] - Training Epoch: 2/2, step 5360/7134 completed (loss: 0.012736300937831402, acc: 0.9958791136741638)
[2024-12-17 03:07:29,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:29,774][root][INFO] - Training Epoch: 2/2, step 5361/7134 completed (loss: 0.03897795081138611, acc: 0.9904191493988037)
[2024-12-17 03:07:29,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:30,138][root][INFO] - Training Epoch: 2/2, step 5362/7134 completed (loss: 0.049447063356637955, acc: 0.9865671396255493)
[2024-12-17 03:07:30,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:30,484][root][INFO] - Training Epoch: 2/2, step 5363/7134 completed (loss: 0.07321745902299881, acc: 0.979651153087616)
[2024-12-17 03:07:30,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:30,840][root][INFO] - Training Epoch: 2/2, step 5364/7134 completed (loss: 0.03679198399186134, acc: 0.9883117079734802)
[2024-12-17 03:07:30,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:31,192][root][INFO] - Training Epoch: 2/2, step 5365/7134 completed (loss: 0.022780248895287514, acc: 0.9929453134536743)
[2024-12-17 03:07:31,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:31,516][root][INFO] - Training Epoch: 2/2, step 5366/7134 completed (loss: 0.06085450202226639, acc: 0.9791666865348816)
[2024-12-17 03:07:31,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:31,874][root][INFO] - Training Epoch: 2/2, step 5367/7134 completed (loss: 0.05203423276543617, acc: 0.9874371886253357)
[2024-12-17 03:07:31,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:32,231][root][INFO] - Training Epoch: 2/2, step 5368/7134 completed (loss: 0.04391257464885712, acc: 0.9849498271942139)
[2024-12-17 03:07:32,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:32,558][root][INFO] - Training Epoch: 2/2, step 5369/7134 completed (loss: 0.02657013200223446, acc: 0.9893842935562134)
[2024-12-17 03:07:32,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:32,902][root][INFO] - Training Epoch: 2/2, step 5370/7134 completed (loss: 0.06702607870101929, acc: 0.9827315807342529)
[2024-12-17 03:07:33,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:33,258][root][INFO] - Training Epoch: 2/2, step 5371/7134 completed (loss: 0.10363958030939102, acc: 0.9734219312667847)
[2024-12-17 03:07:33,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:33,613][root][INFO] - Training Epoch: 2/2, step 5372/7134 completed (loss: 0.01541215367615223, acc: 0.9971949458122253)
[2024-12-17 03:07:33,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:33,933][root][INFO] - Training Epoch: 2/2, step 5373/7134 completed (loss: 0.08312752842903137, acc: 0.9748954176902771)
[2024-12-17 03:07:34,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:34,191][root][INFO] - Training Epoch: 2/2, step 5374/7134 completed (loss: 0.07305066287517548, acc: 0.9807074069976807)
[2024-12-17 03:07:34,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:34,527][root][INFO] - Training Epoch: 2/2, step 5375/7134 completed (loss: 0.07322081178426743, acc: 0.975095808506012)
[2024-12-17 03:07:34,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:34,851][root][INFO] - Training Epoch: 2/2, step 5376/7134 completed (loss: 0.032958049327135086, acc: 0.9860627055168152)
[2024-12-17 03:07:34,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:35,212][root][INFO] - Training Epoch: 2/2, step 5377/7134 completed (loss: 0.0633080005645752, acc: 0.9893778562545776)
[2024-12-17 03:07:35,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:35,578][root][INFO] - Training Epoch: 2/2, step 5378/7134 completed (loss: 0.021291572600603104, acc: 0.9987863898277283)
[2024-12-17 03:07:35,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:35,929][root][INFO] - Training Epoch: 2/2, step 5379/7134 completed (loss: 0.0395125113427639, acc: 0.9857327938079834)
[2024-12-17 03:07:36,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:36,259][root][INFO] - Training Epoch: 2/2, step 5380/7134 completed (loss: 0.04686808958649635, acc: 0.9858906269073486)
[2024-12-17 03:07:36,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:36,587][root][INFO] - Training Epoch: 2/2, step 5381/7134 completed (loss: 0.04216733202338219, acc: 0.9832636117935181)
[2024-12-17 03:07:36,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:36,914][root][INFO] - Training Epoch: 2/2, step 5382/7134 completed (loss: 0.018857261165976524, acc: 0.9948805570602417)
[2024-12-17 03:07:37,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:37,276][root][INFO] - Training Epoch: 2/2, step 5383/7134 completed (loss: 0.03160623461008072, acc: 0.9829545617103577)
[2024-12-17 03:07:37,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:37,660][root][INFO] - Training Epoch: 2/2, step 5384/7134 completed (loss: 0.01869659498333931, acc: 0.9928910136222839)
[2024-12-17 03:07:37,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:38,014][root][INFO] - Training Epoch: 2/2, step 5385/7134 completed (loss: 0.05273766443133354, acc: 0.9801849126815796)
[2024-12-17 03:07:38,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:38,359][root][INFO] - Training Epoch: 2/2, step 5386/7134 completed (loss: 0.02504589408636093, acc: 0.9915730357170105)
[2024-12-17 03:07:38,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:38,717][root][INFO] - Training Epoch: 2/2, step 5387/7134 completed (loss: 0.018078329041600227, acc: 0.9961904883384705)
[2024-12-17 03:07:38,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:39,074][root][INFO] - Training Epoch: 2/2, step 5388/7134 completed (loss: 0.027599085122346878, acc: 0.993686854839325)
[2024-12-17 03:07:39,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:39,402][root][INFO] - Training Epoch: 2/2, step 5389/7134 completed (loss: 0.02565486915409565, acc: 0.9840255379676819)
[2024-12-17 03:07:39,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:39,744][root][INFO] - Training Epoch: 2/2, step 5390/7134 completed (loss: 0.041787996888160706, acc: 0.9857369065284729)
[2024-12-17 03:07:39,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:40,054][root][INFO] - Training Epoch: 2/2, step 5391/7134 completed (loss: 0.07931844145059586, acc: 0.9794167876243591)
[2024-12-17 03:07:40,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:40,379][root][INFO] - Training Epoch: 2/2, step 5392/7134 completed (loss: 0.05785590782761574, acc: 0.9740853905677795)
[2024-12-17 03:07:40,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:40,703][root][INFO] - Training Epoch: 2/2, step 5393/7134 completed (loss: 0.029413117095828056, acc: 0.990234375)
[2024-12-17 03:07:40,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:40,999][root][INFO] - Training Epoch: 2/2, step 5394/7134 completed (loss: 0.061825744807720184, acc: 0.9841269850730896)
[2024-12-17 03:07:41,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:41,348][root][INFO] - Training Epoch: 2/2, step 5395/7134 completed (loss: 0.03575659543275833, acc: 0.9909502267837524)
[2024-12-17 03:07:41,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:41,688][root][INFO] - Training Epoch: 2/2, step 5396/7134 completed (loss: 0.04725958779454231, acc: 0.9879699349403381)
[2024-12-17 03:07:41,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:42,021][root][INFO] - Training Epoch: 2/2, step 5397/7134 completed (loss: 0.03192881867289543, acc: 0.989847719669342)
[2024-12-17 03:07:42,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:42,381][root][INFO] - Training Epoch: 2/2, step 5398/7134 completed (loss: 0.06161663308739662, acc: 0.9882006049156189)
[2024-12-17 03:07:42,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:42,738][root][INFO] - Training Epoch: 2/2, step 5399/7134 completed (loss: 0.03079851344227791, acc: 0.9876881241798401)
[2024-12-17 03:07:42,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:43,081][root][INFO] - Training Epoch: 2/2, step 5400/7134 completed (loss: 0.1307036578655243, acc: 0.9717868566513062)
[2024-12-17 03:07:43,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:43,421][root][INFO] - Training Epoch: 2/2, step 5401/7134 completed (loss: 0.030006852000951767, acc: 0.9887640476226807)
[2024-12-17 03:07:43,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:43,762][root][INFO] - Training Epoch: 2/2, step 5402/7134 completed (loss: 0.03720477595925331, acc: 0.9867841601371765)
[2024-12-17 03:07:43,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:44,059][root][INFO] - Training Epoch: 2/2, step 5403/7134 completed (loss: 0.07414242625236511, acc: 0.9869494438171387)
[2024-12-17 03:07:44,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:44,411][root][INFO] - Training Epoch: 2/2, step 5404/7134 completed (loss: 0.1199224591255188, acc: 0.9758388996124268)
[2024-12-17 03:07:44,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:44,773][root][INFO] - Training Epoch: 2/2, step 5405/7134 completed (loss: 0.05503937229514122, acc: 0.9808027744293213)
[2024-12-17 03:07:44,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:45,120][root][INFO] - Training Epoch: 2/2, step 5406/7134 completed (loss: 0.03397563472390175, acc: 0.9902533888816833)
[2024-12-17 03:07:45,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:45,430][root][INFO] - Training Epoch: 2/2, step 5407/7134 completed (loss: 0.04164855554699898, acc: 0.990338146686554)
[2024-12-17 03:07:45,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:45,761][root][INFO] - Training Epoch: 2/2, step 5408/7134 completed (loss: 0.09955612570047379, acc: 0.9828392863273621)
[2024-12-17 03:07:45,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:46,096][root][INFO] - Training Epoch: 2/2, step 5409/7134 completed (loss: 0.11924533545970917, acc: 0.9833585619926453)
[2024-12-17 03:07:46,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:46,433][root][INFO] - Training Epoch: 2/2, step 5410/7134 completed (loss: 0.06510540097951889, acc: 0.9868766665458679)
[2024-12-17 03:07:46,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:46,777][root][INFO] - Training Epoch: 2/2, step 5411/7134 completed (loss: 0.08030018210411072, acc: 0.9782293438911438)
[2024-12-17 03:07:46,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:47,135][root][INFO] - Training Epoch: 2/2, step 5412/7134 completed (loss: 0.11406923085451126, acc: 0.9673076868057251)
[2024-12-17 03:07:47,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:47,513][root][INFO] - Training Epoch: 2/2, step 5413/7134 completed (loss: 0.10910740494728088, acc: 0.9742857217788696)
[2024-12-17 03:07:47,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:47,880][root][INFO] - Training Epoch: 2/2, step 5414/7134 completed (loss: 0.14184893667697906, acc: 0.9652956128120422)
[2024-12-17 03:07:48,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:48,220][root][INFO] - Training Epoch: 2/2, step 5415/7134 completed (loss: 0.08970054239034653, acc: 0.9785100221633911)
[2024-12-17 03:07:48,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:48,588][root][INFO] - Training Epoch: 2/2, step 5416/7134 completed (loss: 0.0691179633140564, acc: 0.9790940880775452)
[2024-12-17 03:07:48,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:48,956][root][INFO] - Training Epoch: 2/2, step 5417/7134 completed (loss: 0.05502072349190712, acc: 0.9837703108787537)
[2024-12-17 03:07:49,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:49,292][root][INFO] - Training Epoch: 2/2, step 5418/7134 completed (loss: 0.05816776677966118, acc: 0.9807976484298706)
[2024-12-17 03:07:49,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:49,636][root][INFO] - Training Epoch: 2/2, step 5419/7134 completed (loss: 0.14545783400535583, acc: 0.9559321999549866)
[2024-12-17 03:07:49,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:49,977][root][INFO] - Training Epoch: 2/2, step 5420/7134 completed (loss: 0.12160895019769669, acc: 0.9650349617004395)
[2024-12-17 03:07:50,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:50,340][root][INFO] - Training Epoch: 2/2, step 5421/7134 completed (loss: 0.12227007001638412, acc: 0.9703587889671326)
[2024-12-17 03:07:50,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:50,700][root][INFO] - Training Epoch: 2/2, step 5422/7134 completed (loss: 0.07060792297124863, acc: 0.9807692170143127)
[2024-12-17 03:07:50,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:50,974][root][INFO] - Training Epoch: 2/2, step 5423/7134 completed (loss: 0.09384993463754654, acc: 0.9648093581199646)
[2024-12-17 03:07:51,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:51,321][root][INFO] - Training Epoch: 2/2, step 5424/7134 completed (loss: 0.051600534468889236, acc: 0.9894366264343262)
[2024-12-17 03:07:51,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:51,615][root][INFO] - Training Epoch: 2/2, step 5425/7134 completed (loss: 0.03159105032682419, acc: 0.9941747784614563)
[2024-12-17 03:07:51,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:51,919][root][INFO] - Training Epoch: 2/2, step 5426/7134 completed (loss: 0.09082850068807602, acc: 0.9879518151283264)
[2024-12-17 03:07:52,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:52,247][root][INFO] - Training Epoch: 2/2, step 5427/7134 completed (loss: 0.03006470762193203, acc: 0.9921011328697205)
[2024-12-17 03:07:52,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:52,570][root][INFO] - Training Epoch: 2/2, step 5428/7134 completed (loss: 0.05548512190580368, acc: 0.9846677780151367)
[2024-12-17 03:07:52,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:52,873][root][INFO] - Training Epoch: 2/2, step 5429/7134 completed (loss: 0.071427121758461, acc: 0.9837545156478882)
[2024-12-17 03:07:52,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:53,207][root][INFO] - Training Epoch: 2/2, step 5430/7134 completed (loss: 0.04385446012020111, acc: 0.9890282154083252)
[2024-12-17 03:07:53,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:53,502][root][INFO] - Training Epoch: 2/2, step 5431/7134 completed (loss: 0.03200163692235947, acc: 0.9905481934547424)
[2024-12-17 03:07:53,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:53,827][root][INFO] - Training Epoch: 2/2, step 5432/7134 completed (loss: 0.016866372898221016, acc: 0.9981167316436768)
[2024-12-17 03:07:53,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:54,106][root][INFO] - Training Epoch: 2/2, step 5433/7134 completed (loss: 0.05103223770856857, acc: 0.991919219493866)
[2024-12-17 03:07:54,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:54,422][root][INFO] - Training Epoch: 2/2, step 5434/7134 completed (loss: 0.037053387612104416, acc: 0.9899396300315857)
[2024-12-17 03:07:54,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:54,716][root][INFO] - Training Epoch: 2/2, step 5435/7134 completed (loss: 0.03401259332895279, acc: 0.991631805896759)
[2024-12-17 03:07:54,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:55,047][root][INFO] - Training Epoch: 2/2, step 5436/7134 completed (loss: 0.0333961546421051, acc: 0.9940652847290039)
[2024-12-17 03:07:55,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:55,376][root][INFO] - Training Epoch: 2/2, step 5437/7134 completed (loss: 0.01809808798134327, acc: 0.9947643876075745)
[2024-12-17 03:07:55,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:55,738][root][INFO] - Training Epoch: 2/2, step 5438/7134 completed (loss: 0.03109600953757763, acc: 0.9922480583190918)
[2024-12-17 03:07:55,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:56,089][root][INFO] - Training Epoch: 2/2, step 5439/7134 completed (loss: 0.04610784351825714, acc: 0.9869186282157898)
[2024-12-17 03:07:56,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:56,447][root][INFO] - Training Epoch: 2/2, step 5440/7134 completed (loss: 0.05043819174170494, acc: 0.9910600185394287)
[2024-12-17 03:07:56,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:56,804][root][INFO] - Training Epoch: 2/2, step 5441/7134 completed (loss: 0.03865249454975128, acc: 0.990208089351654)
[2024-12-17 03:07:56,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:57,153][root][INFO] - Training Epoch: 2/2, step 5442/7134 completed (loss: 0.035681966692209244, acc: 0.9932340979576111)
[2024-12-17 03:07:57,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:57,491][root][INFO] - Training Epoch: 2/2, step 5443/7134 completed (loss: 0.03928956389427185, acc: 0.9872159361839294)
[2024-12-17 03:07:57,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:57,844][root][INFO] - Training Epoch: 2/2, step 5444/7134 completed (loss: 0.022737588733434677, acc: 0.9963503479957581)
[2024-12-17 03:07:57,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:58,182][root][INFO] - Training Epoch: 2/2, step 5445/7134 completed (loss: 0.04221568629145622, acc: 0.9908592104911804)
[2024-12-17 03:07:58,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:58,520][root][INFO] - Training Epoch: 2/2, step 5446/7134 completed (loss: 0.03439746052026749, acc: 0.9929971694946289)
[2024-12-17 03:07:58,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:58,833][root][INFO] - Training Epoch: 2/2, step 5447/7134 completed (loss: 0.028805002570152283, acc: 0.9919484853744507)
[2024-12-17 03:07:58,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:59,198][root][INFO] - Training Epoch: 2/2, step 5448/7134 completed (loss: 0.04560307040810585, acc: 0.9888268113136292)
[2024-12-17 03:07:59,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:59,521][root][INFO] - Training Epoch: 2/2, step 5449/7134 completed (loss: 0.02218964882194996, acc: 0.9947368502616882)
[2024-12-17 03:07:59,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:59,858][root][INFO] - Training Epoch: 2/2, step 5450/7134 completed (loss: 0.03056156262755394, acc: 0.9897040128707886)
[2024-12-17 03:07:59,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:00,186][root][INFO] - Training Epoch: 2/2, step 5451/7134 completed (loss: 0.05063404515385628, acc: 0.9895150661468506)
[2024-12-17 03:08:00,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:00,521][root][INFO] - Training Epoch: 2/2, step 5452/7134 completed (loss: 0.05710186809301376, acc: 0.985788106918335)
[2024-12-17 03:08:00,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:00,887][root][INFO] - Training Epoch: 2/2, step 5453/7134 completed (loss: 0.04105386137962341, acc: 0.9889570474624634)
[2024-12-17 03:08:01,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:01,245][root][INFO] - Training Epoch: 2/2, step 5454/7134 completed (loss: 0.04282206669449806, acc: 0.9908735156059265)
[2024-12-17 03:08:01,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:01,613][root][INFO] - Training Epoch: 2/2, step 5455/7134 completed (loss: 0.12173251807689667, acc: 0.9760100841522217)
[2024-12-17 03:08:01,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:01,967][root][INFO] - Training Epoch: 2/2, step 5456/7134 completed (loss: 0.04498305544257164, acc: 0.982367753982544)
[2024-12-17 03:08:02,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:02,330][root][INFO] - Training Epoch: 2/2, step 5457/7134 completed (loss: 0.06278876960277557, acc: 0.9838926196098328)
[2024-12-17 03:08:02,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:02,683][root][INFO] - Training Epoch: 2/2, step 5458/7134 completed (loss: 0.0521053671836853, acc: 0.9859872460365295)
[2024-12-17 03:08:02,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:03,017][root][INFO] - Training Epoch: 2/2, step 5459/7134 completed (loss: 0.014386530965566635, acc: 0.997019350528717)
[2024-12-17 03:08:03,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:03,344][root][INFO] - Training Epoch: 2/2, step 5460/7134 completed (loss: 0.03225565701723099, acc: 0.9944367408752441)
[2024-12-17 03:08:03,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:03,665][root][INFO] - Training Epoch: 2/2, step 5461/7134 completed (loss: 0.05365435779094696, acc: 0.9845474362373352)
[2024-12-17 03:08:03,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:04,015][root][INFO] - Training Epoch: 2/2, step 5462/7134 completed (loss: 0.017171433195471764, acc: 0.9942775368690491)
[2024-12-17 03:08:04,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:04,344][root][INFO] - Training Epoch: 2/2, step 5463/7134 completed (loss: 0.032606687396764755, acc: 0.9923664331436157)
[2024-12-17 03:08:04,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:04,691][root][INFO] - Training Epoch: 2/2, step 5464/7134 completed (loss: 0.04729050397872925, acc: 0.9854689836502075)
[2024-12-17 03:08:04,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:05,044][root][INFO] - Training Epoch: 2/2, step 5465/7134 completed (loss: 0.05338702350854874, acc: 0.9925261735916138)
[2024-12-17 03:08:05,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:05,402][root][INFO] - Training Epoch: 2/2, step 5466/7134 completed (loss: 0.02687005326151848, acc: 0.994246244430542)
[2024-12-17 03:08:05,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:05,775][root][INFO] - Training Epoch: 2/2, step 5467/7134 completed (loss: 0.03311135247349739, acc: 0.9894366264343262)
[2024-12-17 03:08:05,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:06,130][root][INFO] - Training Epoch: 2/2, step 5468/7134 completed (loss: 0.03403638303279877, acc: 0.9907192587852478)
[2024-12-17 03:08:06,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:06,481][root][INFO] - Training Epoch: 2/2, step 5469/7134 completed (loss: 0.02863345295190811, acc: 0.9963189959526062)
[2024-12-17 03:08:06,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:06,836][root][INFO] - Training Epoch: 2/2, step 5470/7134 completed (loss: 0.01893899030983448, acc: 0.9963855147361755)
[2024-12-17 03:08:06,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:07,183][root][INFO] - Training Epoch: 2/2, step 5471/7134 completed (loss: 0.030615828931331635, acc: 0.9891892075538635)
[2024-12-17 03:08:07,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:07,543][root][INFO] - Training Epoch: 2/2, step 5472/7134 completed (loss: 0.039693549275398254, acc: 0.9912717938423157)
[2024-12-17 03:08:07,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:07,904][root][INFO] - Training Epoch: 2/2, step 5473/7134 completed (loss: 0.02496478706598282, acc: 0.9926380515098572)
[2024-12-17 03:08:08,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:08,253][root][INFO] - Training Epoch: 2/2, step 5474/7134 completed (loss: 0.024543490260839462, acc: 0.9928571581840515)
[2024-12-17 03:08:08,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:08,610][root][INFO] - Training Epoch: 2/2, step 5475/7134 completed (loss: 0.028373707085847855, acc: 0.9928876161575317)
[2024-12-17 03:08:08,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:08,938][root][INFO] - Training Epoch: 2/2, step 5476/7134 completed (loss: 0.014667204581201077, acc: 0.9971056580543518)
[2024-12-17 03:08:09,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:09,303][root][INFO] - Training Epoch: 2/2, step 5477/7134 completed (loss: 0.014693458564579487, acc: 0.9950739145278931)
[2024-12-17 03:08:09,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:09,684][root][INFO] - Training Epoch: 2/2, step 5478/7134 completed (loss: 0.05048961192369461, acc: 0.9845626354217529)
[2024-12-17 03:08:09,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:10,046][root][INFO] - Training Epoch: 2/2, step 5479/7134 completed (loss: 0.05323546379804611, acc: 0.979619562625885)
[2024-12-17 03:08:10,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:10,401][root][INFO] - Training Epoch: 2/2, step 5480/7134 completed (loss: 0.06376031041145325, acc: 0.9815789461135864)
[2024-12-17 03:08:10,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:10,731][root][INFO] - Training Epoch: 2/2, step 5481/7134 completed (loss: 0.038693953305482864, acc: 0.9898989796638489)
[2024-12-17 03:08:10,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:11,357][root][INFO] - Training Epoch: 2/2, step 5482/7134 completed (loss: 0.03548237308859825, acc: 0.987908124923706)
[2024-12-17 03:08:11,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:11,756][root][INFO] - Training Epoch: 2/2, step 5483/7134 completed (loss: 0.03698631003499031, acc: 0.9916434288024902)
[2024-12-17 03:08:11,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:12,113][root][INFO] - Training Epoch: 2/2, step 5484/7134 completed (loss: 0.05384441092610359, acc: 0.9791377186775208)
[2024-12-17 03:08:12,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:12,442][root][INFO] - Training Epoch: 2/2, step 5485/7134 completed (loss: 0.06530643254518509, acc: 0.9818511605262756)
[2024-12-17 03:08:12,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:12,796][root][INFO] - Training Epoch: 2/2, step 5486/7134 completed (loss: 0.06405666470527649, acc: 0.9809688329696655)
[2024-12-17 03:08:12,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:13,120][root][INFO] - Training Epoch: 2/2, step 5487/7134 completed (loss: 0.023625168949365616, acc: 0.9934959411621094)
[2024-12-17 03:08:13,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:13,504][root][INFO] - Training Epoch: 2/2, step 5488/7134 completed (loss: 0.0627441480755806, acc: 0.9750000238418579)
[2024-12-17 03:08:13,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:13,867][root][INFO] - Training Epoch: 2/2, step 5489/7134 completed (loss: 0.0733383372426033, acc: 0.9860681295394897)
[2024-12-17 03:08:13,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:14,132][root][INFO] - Training Epoch: 2/2, step 5490/7134 completed (loss: 0.0187531691044569, acc: 0.9977220892906189)
[2024-12-17 03:08:14,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:14,460][root][INFO] - Training Epoch: 2/2, step 5491/7134 completed (loss: 0.03625858947634697, acc: 0.9912023544311523)
[2024-12-17 03:08:14,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:14,786][root][INFO] - Training Epoch: 2/2, step 5492/7134 completed (loss: 0.04453902691602707, acc: 0.9864636063575745)
[2024-12-17 03:08:14,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:15,109][root][INFO] - Training Epoch: 2/2, step 5493/7134 completed (loss: 0.057456281036138535, acc: 0.9864130616188049)
[2024-12-17 03:08:15,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:15,476][root][INFO] - Training Epoch: 2/2, step 5494/7134 completed (loss: 0.02381015382707119, acc: 0.9900426864624023)
[2024-12-17 03:08:15,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:15,783][root][INFO] - Training Epoch: 2/2, step 5495/7134 completed (loss: 0.029868580400943756, acc: 0.9910394549369812)
[2024-12-17 03:08:15,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:16,094][root][INFO] - Training Epoch: 2/2, step 5496/7134 completed (loss: 0.05246942862868309, acc: 0.9883268475532532)
[2024-12-17 03:08:16,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:16,440][root][INFO] - Training Epoch: 2/2, step 5497/7134 completed (loss: 0.08055666834115982, acc: 0.9765739440917969)
[2024-12-17 03:08:16,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:16,783][root][INFO] - Training Epoch: 2/2, step 5498/7134 completed (loss: 0.03687054291367531, acc: 0.9867374300956726)
[2024-12-17 03:08:16,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:17,109][root][INFO] - Training Epoch: 2/2, step 5499/7134 completed (loss: 0.03914860263466835, acc: 0.9874371886253357)
[2024-12-17 03:08:17,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:17,443][root][INFO] - Training Epoch: 2/2, step 5500/7134 completed (loss: 0.057485438883304596, acc: 0.9863574504852295)
[2024-12-17 03:08:17,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:17,795][root][INFO] - Training Epoch: 2/2, step 5501/7134 completed (loss: 0.027420638129115105, acc: 0.9913580417633057)
[2024-12-17 03:08:17,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:18,147][root][INFO] - Training Epoch: 2/2, step 5502/7134 completed (loss: 0.045031461864709854, acc: 0.9865047335624695)
[2024-12-17 03:08:18,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:18,468][root][INFO] - Training Epoch: 2/2, step 5503/7134 completed (loss: 0.05437525734305382, acc: 0.9880715608596802)
[2024-12-17 03:08:18,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:18,822][root][INFO] - Training Epoch: 2/2, step 5504/7134 completed (loss: 0.040463704615831375, acc: 0.9878934621810913)
[2024-12-17 03:08:18,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:19,154][root][INFO] - Training Epoch: 2/2, step 5505/7134 completed (loss: 0.051254305988550186, acc: 0.980141818523407)
[2024-12-17 03:08:19,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:19,503][root][INFO] - Training Epoch: 2/2, step 5506/7134 completed (loss: 0.057316165417432785, acc: 0.9838523864746094)
[2024-12-17 03:08:19,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:19,842][root][INFO] - Training Epoch: 2/2, step 5507/7134 completed (loss: 0.04991617798805237, acc: 0.9859943985939026)
[2024-12-17 03:08:19,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:20,194][root][INFO] - Training Epoch: 2/2, step 5508/7134 completed (loss: 0.020027123391628265, acc: 0.9953271150588989)
[2024-12-17 03:08:20,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:20,554][root][INFO] - Training Epoch: 2/2, step 5509/7134 completed (loss: 0.043410997837781906, acc: 0.9859648942947388)
[2024-12-17 03:08:20,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:20,906][root][INFO] - Training Epoch: 2/2, step 5510/7134 completed (loss: 0.062116872519254684, acc: 0.980719804763794)
[2024-12-17 03:08:21,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:21,284][root][INFO] - Training Epoch: 2/2, step 5511/7134 completed (loss: 0.05317249149084091, acc: 0.9864253401756287)
[2024-12-17 03:08:21,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:21,629][root][INFO] - Training Epoch: 2/2, step 5512/7134 completed (loss: 0.02822168916463852, acc: 0.992094874382019)
[2024-12-17 03:08:21,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:21,958][root][INFO] - Training Epoch: 2/2, step 5513/7134 completed (loss: 0.04736718907952309, acc: 0.9850543737411499)
[2024-12-17 03:08:22,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:22,314][root][INFO] - Training Epoch: 2/2, step 5514/7134 completed (loss: 0.1544189304113388, acc: 0.961442768573761)
[2024-12-17 03:08:22,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:22,642][root][INFO] - Training Epoch: 2/2, step 5515/7134 completed (loss: 0.05315818265080452, acc: 0.9857346415519714)
[2024-12-17 03:08:22,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:22,954][root][INFO] - Training Epoch: 2/2, step 5516/7134 completed (loss: 0.033985596150159836, acc: 0.9943740963935852)
[2024-12-17 03:08:23,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:23,274][root][INFO] - Training Epoch: 2/2, step 5517/7134 completed (loss: 0.03991346433758736, acc: 0.9893617033958435)
[2024-12-17 03:08:23,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:23,629][root][INFO] - Training Epoch: 2/2, step 5518/7134 completed (loss: 0.04561443254351616, acc: 0.989130437374115)
[2024-12-17 03:08:23,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:23,984][root][INFO] - Training Epoch: 2/2, step 5519/7134 completed (loss: 0.01953098364174366, acc: 0.9944827556610107)
[2024-12-17 03:08:24,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:24,337][root][INFO] - Training Epoch: 2/2, step 5520/7134 completed (loss: 0.027359390631318092, acc: 0.9932050108909607)
[2024-12-17 03:08:24,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:24,693][root][INFO] - Training Epoch: 2/2, step 5521/7134 completed (loss: 0.04193657636642456, acc: 0.9886934757232666)
[2024-12-17 03:08:24,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:25,043][root][INFO] - Training Epoch: 2/2, step 5522/7134 completed (loss: 0.05644163861870766, acc: 0.9816993474960327)
[2024-12-17 03:08:25,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:25,347][root][INFO] - Training Epoch: 2/2, step 5523/7134 completed (loss: 0.05031035840511322, acc: 0.9887640476226807)
[2024-12-17 03:08:25,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:25,668][root][INFO] - Training Epoch: 2/2, step 5524/7134 completed (loss: 0.047305893152952194, acc: 0.9860681295394897)
[2024-12-17 03:08:25,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:26,019][root][INFO] - Training Epoch: 2/2, step 5525/7134 completed (loss: 0.053261853754520416, acc: 0.9824304580688477)
[2024-12-17 03:08:26,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:26,359][root][INFO] - Training Epoch: 2/2, step 5526/7134 completed (loss: 0.05480118840932846, acc: 0.9882179498672485)
[2024-12-17 03:08:26,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:26,710][root][INFO] - Training Epoch: 2/2, step 5527/7134 completed (loss: 0.046802207827568054, acc: 0.9848739504814148)
[2024-12-17 03:08:26,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:27,062][root][INFO] - Training Epoch: 2/2, step 5528/7134 completed (loss: 0.032113321125507355, acc: 0.9917159676551819)
[2024-12-17 03:08:27,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:27,416][root][INFO] - Training Epoch: 2/2, step 5529/7134 completed (loss: 0.06713579595088959, acc: 0.9799054265022278)
[2024-12-17 03:08:27,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:27,768][root][INFO] - Training Epoch: 2/2, step 5530/7134 completed (loss: 0.03501025214791298, acc: 0.992548406124115)
[2024-12-17 03:08:27,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:28,121][root][INFO] - Training Epoch: 2/2, step 5531/7134 completed (loss: 0.06010126322507858, acc: 0.9838107228279114)
[2024-12-17 03:08:28,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:28,489][root][INFO] - Training Epoch: 2/2, step 5532/7134 completed (loss: 0.06440936028957367, acc: 0.9765142202377319)
[2024-12-17 03:08:28,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:28,863][root][INFO] - Training Epoch: 2/2, step 5533/7134 completed (loss: 0.024048715829849243, acc: 0.9931972622871399)
[2024-12-17 03:08:28,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:29,233][root][INFO] - Training Epoch: 2/2, step 5534/7134 completed (loss: 0.05647169426083565, acc: 0.9848130941390991)
[2024-12-17 03:08:29,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:29,593][root][INFO] - Training Epoch: 2/2, step 5535/7134 completed (loss: 0.043792180716991425, acc: 0.9869423508644104)
[2024-12-17 03:08:29,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:29,936][root][INFO] - Training Epoch: 2/2, step 5536/7134 completed (loss: 0.02616417035460472, acc: 0.9918604493141174)
[2024-12-17 03:08:30,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:30,275][root][INFO] - Training Epoch: 2/2, step 5537/7134 completed (loss: 0.044967569410800934, acc: 0.9883313775062561)
[2024-12-17 03:08:30,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:30,632][root][INFO] - Training Epoch: 2/2, step 5538/7134 completed (loss: 0.04660920426249504, acc: 0.9886234402656555)
[2024-12-17 03:08:30,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:31,001][root][INFO] - Training Epoch: 2/2, step 5539/7134 completed (loss: 0.04142351821064949, acc: 0.9864864945411682)
[2024-12-17 03:08:31,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:31,355][root][INFO] - Training Epoch: 2/2, step 5540/7134 completed (loss: 0.052228931337594986, acc: 0.9894737005233765)
[2024-12-17 03:08:31,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:31,734][root][INFO] - Training Epoch: 2/2, step 5541/7134 completed (loss: 0.03504970297217369, acc: 0.9920212626457214)
[2024-12-17 03:08:31,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:32,069][root][INFO] - Training Epoch: 2/2, step 5542/7134 completed (loss: 0.029332907870411873, acc: 0.9900142550468445)
[2024-12-17 03:08:32,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:32,435][root][INFO] - Training Epoch: 2/2, step 5543/7134 completed (loss: 0.0384538434445858, acc: 0.9944567680358887)
[2024-12-17 03:08:32,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:32,795][root][INFO] - Training Epoch: 2/2, step 5544/7134 completed (loss: 0.0324077345430851, acc: 0.9881720542907715)
[2024-12-17 03:08:32,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:33,154][root][INFO] - Training Epoch: 2/2, step 5545/7134 completed (loss: 0.04573715850710869, acc: 0.9868852496147156)
[2024-12-17 03:08:33,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:33,504][root][INFO] - Training Epoch: 2/2, step 5546/7134 completed (loss: 0.051145486533641815, acc: 0.9878183603286743)
[2024-12-17 03:08:33,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:33,870][root][INFO] - Training Epoch: 2/2, step 5547/7134 completed (loss: 0.04158609360456467, acc: 0.9907833933830261)
[2024-12-17 03:08:33,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:34,212][root][INFO] - Training Epoch: 2/2, step 5548/7134 completed (loss: 0.03047540783882141, acc: 0.9918604493141174)
[2024-12-17 03:08:34,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:34,519][root][INFO] - Training Epoch: 2/2, step 5549/7134 completed (loss: 0.042410317808389664, acc: 0.9885714054107666)
[2024-12-17 03:08:34,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:34,869][root][INFO] - Training Epoch: 2/2, step 5550/7134 completed (loss: 0.01674290932714939, acc: 0.9952996373176575)
[2024-12-17 03:08:34,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:35,188][root][INFO] - Training Epoch: 2/2, step 5551/7134 completed (loss: 0.06933756172657013, acc: 0.9783491492271423)
[2024-12-17 03:08:35,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:35,539][root][INFO] - Training Epoch: 2/2, step 5552/7134 completed (loss: 0.030472930520772934, acc: 0.9892984628677368)
[2024-12-17 03:08:35,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:35,888][root][INFO] - Training Epoch: 2/2, step 5553/7134 completed (loss: 0.030066674575209618, acc: 0.9913473129272461)
[2024-12-17 03:08:35,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:36,229][root][INFO] - Training Epoch: 2/2, step 5554/7134 completed (loss: 0.021374933421611786, acc: 0.9938875436782837)
[2024-12-17 03:08:36,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:36,589][root][INFO] - Training Epoch: 2/2, step 5555/7134 completed (loss: 0.047670118510723114, acc: 0.9826202988624573)
[2024-12-17 03:08:36,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:36,911][root][INFO] - Training Epoch: 2/2, step 5556/7134 completed (loss: 0.047078974545001984, acc: 0.9870298504829407)
[2024-12-17 03:08:37,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:37,268][root][INFO] - Training Epoch: 2/2, step 5557/7134 completed (loss: 0.02866775169968605, acc: 0.9957982897758484)
[2024-12-17 03:08:37,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:37,622][root][INFO] - Training Epoch: 2/2, step 5558/7134 completed (loss: 0.018602129071950912, acc: 0.9900621175765991)
[2024-12-17 03:08:37,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:37,970][root][INFO] - Training Epoch: 2/2, step 5559/7134 completed (loss: 0.043721601366996765, acc: 0.9888198971748352)
[2024-12-17 03:08:38,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:38,308][root][INFO] - Training Epoch: 2/2, step 5560/7134 completed (loss: 0.056673675775527954, acc: 0.9857512712478638)
[2024-12-17 03:08:38,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:38,603][root][INFO] - Training Epoch: 2/2, step 5561/7134 completed (loss: 0.061839595437049866, acc: 0.9886578321456909)
[2024-12-17 03:08:38,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:38,950][root][INFO] - Training Epoch: 2/2, step 5562/7134 completed (loss: 0.03591204434633255, acc: 0.9965870380401611)
[2024-12-17 03:08:39,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:39,295][root][INFO] - Training Epoch: 2/2, step 5563/7134 completed (loss: 0.05001049116253853, acc: 0.9894894957542419)
[2024-12-17 03:08:39,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:39,625][root][INFO] - Training Epoch: 2/2, step 5564/7134 completed (loss: 0.03681790828704834, acc: 0.9958158731460571)
[2024-12-17 03:08:39,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:39,980][root][INFO] - Training Epoch: 2/2, step 5565/7134 completed (loss: 0.016949135810136795, acc: 0.9953917264938354)
[2024-12-17 03:08:40,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:40,343][root][INFO] - Training Epoch: 2/2, step 5566/7134 completed (loss: 0.02964571863412857, acc: 0.9931113719940186)
[2024-12-17 03:08:40,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:40,716][root][INFO] - Training Epoch: 2/2, step 5567/7134 completed (loss: 0.02980128861963749, acc: 0.990867555141449)
[2024-12-17 03:08:40,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:41,033][root][INFO] - Training Epoch: 2/2, step 5568/7134 completed (loss: 0.03481468930840492, acc: 0.9909793734550476)
[2024-12-17 03:08:41,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:41,403][root][INFO] - Training Epoch: 2/2, step 5569/7134 completed (loss: 0.014446981251239777, acc: 0.9988584518432617)
[2024-12-17 03:08:41,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:41,750][root][INFO] - Training Epoch: 2/2, step 5570/7134 completed (loss: 0.021599184721708298, acc: 0.992546558380127)
[2024-12-17 03:08:41,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:42,068][root][INFO] - Training Epoch: 2/2, step 5571/7134 completed (loss: 0.04680931195616722, acc: 0.9910846948623657)
[2024-12-17 03:08:42,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:42,400][root][INFO] - Training Epoch: 2/2, step 5572/7134 completed (loss: 0.06237166374921799, acc: 0.9890109896659851)
[2024-12-17 03:08:42,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:42,769][root][INFO] - Training Epoch: 2/2, step 5573/7134 completed (loss: 0.0345035046339035, acc: 0.9941775798797607)
[2024-12-17 03:08:42,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:43,086][root][INFO] - Training Epoch: 2/2, step 5574/7134 completed (loss: 0.015326716005802155, acc: 0.9952380657196045)
[2024-12-17 03:08:43,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:43,434][root][INFO] - Training Epoch: 2/2, step 5575/7134 completed (loss: 0.03826640546321869, acc: 0.9856459498405457)
[2024-12-17 03:08:43,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:43,755][root][INFO] - Training Epoch: 2/2, step 5576/7134 completed (loss: 0.047463081777095795, acc: 0.982807993888855)
[2024-12-17 03:08:43,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:44,091][root][INFO] - Training Epoch: 2/2, step 5577/7134 completed (loss: 0.04629199206829071, acc: 0.9895287752151489)
[2024-12-17 03:08:44,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:44,442][root][INFO] - Training Epoch: 2/2, step 5578/7134 completed (loss: 0.02000468410551548, acc: 0.9928264021873474)
[2024-12-17 03:08:44,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:44,793][root][INFO] - Training Epoch: 2/2, step 5579/7134 completed (loss: 0.030784472823143005, acc: 0.9889349937438965)
[2024-12-17 03:08:44,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:45,122][root][INFO] - Training Epoch: 2/2, step 5580/7134 completed (loss: 0.01962442137300968, acc: 0.9931787252426147)
[2024-12-17 03:08:45,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:45,477][root][INFO] - Training Epoch: 2/2, step 5581/7134 completed (loss: 0.026858152821660042, acc: 0.9920212626457214)
[2024-12-17 03:08:45,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:45,842][root][INFO] - Training Epoch: 2/2, step 5582/7134 completed (loss: 0.019554173573851585, acc: 0.9908735156059265)
[2024-12-17 03:08:45,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:46,217][root][INFO] - Training Epoch: 2/2, step 5583/7134 completed (loss: 0.022118911147117615, acc: 0.997481107711792)
[2024-12-17 03:08:46,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:46,551][root][INFO] - Training Epoch: 2/2, step 5584/7134 completed (loss: 0.02237982675433159, acc: 0.9911242723464966)
[2024-12-17 03:08:46,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:46,920][root][INFO] - Training Epoch: 2/2, step 5585/7134 completed (loss: 0.048362847417593, acc: 0.9878787994384766)
[2024-12-17 03:08:47,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:47,236][root][INFO] - Training Epoch: 2/2, step 5586/7134 completed (loss: 0.026410752907395363, acc: 0.9911190271377563)
[2024-12-17 03:08:47,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:47,588][root][INFO] - Training Epoch: 2/2, step 5587/7134 completed (loss: 0.02549818344414234, acc: 0.9930651783943176)
[2024-12-17 03:08:47,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:47,943][root][INFO] - Training Epoch: 2/2, step 5588/7134 completed (loss: 0.012106504291296005, acc: 0.9954614043235779)
[2024-12-17 03:08:48,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:48,277][root][INFO] - Training Epoch: 2/2, step 5589/7134 completed (loss: 0.02779667265713215, acc: 0.9968454241752625)
[2024-12-17 03:08:48,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:48,604][root][INFO] - Training Epoch: 2/2, step 5590/7134 completed (loss: 0.035452328622341156, acc: 0.9901408553123474)
[2024-12-17 03:08:48,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:48,931][root][INFO] - Training Epoch: 2/2, step 5591/7134 completed (loss: 0.016541702672839165, acc: 0.9947643876075745)
[2024-12-17 03:08:49,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:49,258][root][INFO] - Training Epoch: 2/2, step 5592/7134 completed (loss: 0.02770325168967247, acc: 0.9903978109359741)
[2024-12-17 03:08:49,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:49,616][root][INFO] - Training Epoch: 2/2, step 5593/7134 completed (loss: 0.02204802818596363, acc: 0.9935232996940613)
[2024-12-17 03:08:49,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:49,961][root][INFO] - Training Epoch: 2/2, step 5594/7134 completed (loss: 0.017118608579039574, acc: 0.9959568977355957)
[2024-12-17 03:08:50,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:50,301][root][INFO] - Training Epoch: 2/2, step 5595/7134 completed (loss: 0.033088237047195435, acc: 0.9906166195869446)
[2024-12-17 03:08:50,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:50,633][root][INFO] - Training Epoch: 2/2, step 5596/7134 completed (loss: 0.01946699246764183, acc: 0.9905914068222046)
[2024-12-17 03:08:50,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:50,972][root][INFO] - Training Epoch: 2/2, step 5597/7134 completed (loss: 0.04869014397263527, acc: 0.9876033067703247)
[2024-12-17 03:08:51,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:51,301][root][INFO] - Training Epoch: 2/2, step 5598/7134 completed (loss: 0.03334634006023407, acc: 0.99301677942276)
[2024-12-17 03:08:51,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:51,648][root][INFO] - Training Epoch: 2/2, step 5599/7134 completed (loss: 0.0775490328669548, acc: 0.9877049326896667)
[2024-12-17 03:08:51,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:52,006][root][INFO] - Training Epoch: 2/2, step 5600/7134 completed (loss: 0.02653929777443409, acc: 0.9942693114280701)
[2024-12-17 03:08:52,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:52,319][root][INFO] - Training Epoch: 2/2, step 5601/7134 completed (loss: 0.05874992161989212, acc: 0.9843478202819824)
[2024-12-17 03:08:52,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:52,650][root][INFO] - Training Epoch: 2/2, step 5602/7134 completed (loss: 0.05304919555783272, acc: 0.9822866320610046)
[2024-12-17 03:08:52,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:52,957][root][INFO] - Training Epoch: 2/2, step 5603/7134 completed (loss: 0.011764615774154663, acc: 0.9950900077819824)
[2024-12-17 03:08:53,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:53,270][root][INFO] - Training Epoch: 2/2, step 5604/7134 completed (loss: 0.08031269162893295, acc: 0.9742765426635742)
[2024-12-17 03:08:53,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:53,612][root][INFO] - Training Epoch: 2/2, step 5605/7134 completed (loss: 0.03400273621082306, acc: 0.9881154298782349)
[2024-12-17 03:08:53,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:53,933][root][INFO] - Training Epoch: 2/2, step 5606/7134 completed (loss: 0.048795558512210846, acc: 0.9914529919624329)
[2024-12-17 03:08:54,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:54,258][root][INFO] - Training Epoch: 2/2, step 5607/7134 completed (loss: 0.01709684729576111, acc: 0.9969924688339233)
[2024-12-17 03:08:54,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:54,577][root][INFO] - Training Epoch: 2/2, step 5608/7134 completed (loss: 0.03331999480724335, acc: 0.9901477694511414)
[2024-12-17 03:08:54,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:54,895][root][INFO] - Training Epoch: 2/2, step 5609/7134 completed (loss: 0.030634351074695587, acc: 0.9895651936531067)
[2024-12-17 03:08:55,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:55,183][root][INFO] - Training Epoch: 2/2, step 5610/7134 completed (loss: 0.035331886261701584, acc: 0.9919517040252686)
[2024-12-17 03:08:55,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:55,551][root][INFO] - Training Epoch: 2/2, step 5611/7134 completed (loss: 0.04756433889269829, acc: 0.982594907283783)
[2024-12-17 03:08:55,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:55,898][root][INFO] - Training Epoch: 2/2, step 5612/7134 completed (loss: 0.039556194096803665, acc: 0.9861963391304016)
[2024-12-17 03:08:56,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:56,220][root][INFO] - Training Epoch: 2/2, step 5613/7134 completed (loss: 0.04059939458966255, acc: 0.991055428981781)
[2024-12-17 03:08:56,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:56,551][root][INFO] - Training Epoch: 2/2, step 5614/7134 completed (loss: 0.05402447655797005, acc: 0.9842857122421265)
[2024-12-17 03:08:56,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:56,897][root][INFO] - Training Epoch: 2/2, step 5615/7134 completed (loss: 0.045815110206604004, acc: 0.982758641242981)
[2024-12-17 03:08:57,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:57,224][root][INFO] - Training Epoch: 2/2, step 5616/7134 completed (loss: 0.032747168093919754, acc: 0.9881129264831543)
[2024-12-17 03:08:57,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:57,542][root][INFO] - Training Epoch: 2/2, step 5617/7134 completed (loss: 0.0102330157533288, acc: 0.9983766078948975)
[2024-12-17 03:08:57,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:57,880][root][INFO] - Training Epoch: 2/2, step 5618/7134 completed (loss: 0.05791467800736427, acc: 0.9788618087768555)
[2024-12-17 03:08:57,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:58,189][root][INFO] - Training Epoch: 2/2, step 5619/7134 completed (loss: 0.06127701327204704, acc: 0.9776875972747803)
[2024-12-17 03:08:58,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:58,513][root][INFO] - Training Epoch: 2/2, step 5620/7134 completed (loss: 0.04120553284883499, acc: 0.9831775426864624)
[2024-12-17 03:08:58,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:58,885][root][INFO] - Training Epoch: 2/2, step 5621/7134 completed (loss: 0.024582618847489357, acc: 0.9936467409133911)
[2024-12-17 03:08:59,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:59,234][root][INFO] - Training Epoch: 2/2, step 5622/7134 completed (loss: 0.06588281691074371, acc: 0.9904631972312927)
[2024-12-17 03:08:59,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:59,540][root][INFO] - Training Epoch: 2/2, step 5623/7134 completed (loss: 0.04367708042263985, acc: 0.9860627055168152)
[2024-12-17 03:08:59,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:59,880][root][INFO] - Training Epoch: 2/2, step 5624/7134 completed (loss: 0.05158894136548042, acc: 0.9918166995048523)
[2024-12-17 03:08:59,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:00,191][root][INFO] - Training Epoch: 2/2, step 5625/7134 completed (loss: 0.005968982819467783, acc: 1.0)
[2024-12-17 03:09:00,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:00,544][root][INFO] - Training Epoch: 2/2, step 5626/7134 completed (loss: 0.028691722080111504, acc: 0.9949238300323486)
[2024-12-17 03:09:00,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:00,896][root][INFO] - Training Epoch: 2/2, step 5627/7134 completed (loss: 0.12582339346408844, acc: 0.9703153967857361)
[2024-12-17 03:09:01,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:01,264][root][INFO] - Training Epoch: 2/2, step 5628/7134 completed (loss: 0.04864207282662392, acc: 0.9781420826911926)
[2024-12-17 03:09:01,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:01,606][root][INFO] - Training Epoch: 2/2, step 5629/7134 completed (loss: 0.0623384490609169, acc: 0.982425332069397)
[2024-12-17 03:09:01,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:01,939][root][INFO] - Training Epoch: 2/2, step 5630/7134 completed (loss: 0.049475863575935364, acc: 0.9815195202827454)
[2024-12-17 03:09:02,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:02,265][root][INFO] - Training Epoch: 2/2, step 5631/7134 completed (loss: 0.0799962505698204, acc: 0.9684908986091614)
[2024-12-17 03:09:02,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:02,604][root][INFO] - Training Epoch: 2/2, step 5632/7134 completed (loss: 0.043934792280197144, acc: 0.9854809641838074)
[2024-12-17 03:09:02,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:02,930][root][INFO] - Training Epoch: 2/2, step 5633/7134 completed (loss: 0.0670221671462059, acc: 0.9820846915245056)
[2024-12-17 03:09:03,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:03,260][root][INFO] - Training Epoch: 2/2, step 5634/7134 completed (loss: 0.04478238895535469, acc: 0.9895287752151489)
[2024-12-17 03:09:03,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:03,607][root][INFO] - Training Epoch: 2/2, step 5635/7134 completed (loss: 0.02641179785132408, acc: 0.9949324131011963)
[2024-12-17 03:09:03,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:03,960][root][INFO] - Training Epoch: 2/2, step 5636/7134 completed (loss: 0.034557923674583435, acc: 0.9888178706169128)
[2024-12-17 03:09:04,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:04,285][root][INFO] - Training Epoch: 2/2, step 5637/7134 completed (loss: 0.04657277092337608, acc: 0.9865092635154724)
[2024-12-17 03:09:04,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:04,588][root][INFO] - Training Epoch: 2/2, step 5638/7134 completed (loss: 0.05671285465359688, acc: 0.986328125)
[2024-12-17 03:09:04,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:04,941][root][INFO] - Training Epoch: 2/2, step 5639/7134 completed (loss: 0.03321995586156845, acc: 0.9871794581413269)
[2024-12-17 03:09:05,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:05,277][root][INFO] - Training Epoch: 2/2, step 5640/7134 completed (loss: 0.049402523785829544, acc: 0.9821138381958008)
[2024-12-17 03:09:05,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:05,564][root][INFO] - Training Epoch: 2/2, step 5641/7134 completed (loss: 0.06438343226909637, acc: 0.9873737096786499)
[2024-12-17 03:09:05,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:05,885][root][INFO] - Training Epoch: 2/2, step 5642/7134 completed (loss: 0.07159778475761414, acc: 0.9803030490875244)
[2024-12-17 03:09:06,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:06,203][root][INFO] - Training Epoch: 2/2, step 5643/7134 completed (loss: 0.05368434265255928, acc: 0.991150438785553)
[2024-12-17 03:09:06,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:06,541][root][INFO] - Training Epoch: 2/2, step 5644/7134 completed (loss: 0.05874697118997574, acc: 0.9857723712921143)
[2024-12-17 03:09:06,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:06,868][root][INFO] - Training Epoch: 2/2, step 5645/7134 completed (loss: 0.04236915335059166, acc: 0.9867452383041382)
[2024-12-17 03:09:06,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:07,188][root][INFO] - Training Epoch: 2/2, step 5646/7134 completed (loss: 0.05610523745417595, acc: 0.9808917045593262)
[2024-12-17 03:09:07,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:07,531][root][INFO] - Training Epoch: 2/2, step 5647/7134 completed (loss: 0.04101603105664253, acc: 0.9906976819038391)
[2024-12-17 03:09:07,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:07,875][root][INFO] - Training Epoch: 2/2, step 5648/7134 completed (loss: 0.11407960206270218, acc: 0.9776119589805603)
[2024-12-17 03:09:07,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:08,196][root][INFO] - Training Epoch: 2/2, step 5649/7134 completed (loss: 0.07427246123552322, acc: 0.9801223278045654)
[2024-12-17 03:09:08,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:08,534][root][INFO] - Training Epoch: 2/2, step 5650/7134 completed (loss: 0.02944447286427021, acc: 0.9879931211471558)
[2024-12-17 03:09:08,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:08,874][root][INFO] - Training Epoch: 2/2, step 5651/7134 completed (loss: 0.02467663399875164, acc: 0.9955621361732483)
[2024-12-17 03:09:09,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:09,245][root][INFO] - Training Epoch: 2/2, step 5652/7134 completed (loss: 0.03809262812137604, acc: 0.9871794581413269)
[2024-12-17 03:09:09,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:09,547][root][INFO] - Training Epoch: 2/2, step 5653/7134 completed (loss: 0.08994832634925842, acc: 0.9739583134651184)
[2024-12-17 03:09:09,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:09,872][root][INFO] - Training Epoch: 2/2, step 5654/7134 completed (loss: 0.03225189447402954, acc: 0.9924924969673157)
[2024-12-17 03:09:09,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:10,208][root][INFO] - Training Epoch: 2/2, step 5655/7134 completed (loss: 0.044385019689798355, acc: 0.9812925457954407)
[2024-12-17 03:09:10,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:10,528][root][INFO] - Training Epoch: 2/2, step 5656/7134 completed (loss: 0.02568557672202587, acc: 0.9904761910438538)
[2024-12-17 03:09:10,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:10,857][root][INFO] - Training Epoch: 2/2, step 5657/7134 completed (loss: 0.04492520913481712, acc: 0.9941434860229492)
[2024-12-17 03:09:10,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:11,212][root][INFO] - Training Epoch: 2/2, step 5658/7134 completed (loss: 0.06388595700263977, acc: 0.9779005646705627)
[2024-12-17 03:09:11,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:11,543][root][INFO] - Training Epoch: 2/2, step 5659/7134 completed (loss: 0.042501550167798996, acc: 0.9900709390640259)
[2024-12-17 03:09:11,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:11,876][root][INFO] - Training Epoch: 2/2, step 5660/7134 completed (loss: 0.02835649624466896, acc: 0.9933884143829346)
[2024-12-17 03:09:11,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:12,233][root][INFO] - Training Epoch: 2/2, step 5661/7134 completed (loss: 0.014568439684808254, acc: 0.9981752038002014)
[2024-12-17 03:09:12,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:12,579][root][INFO] - Training Epoch: 2/2, step 5662/7134 completed (loss: 0.022216688841581345, acc: 0.9935897588729858)
[2024-12-17 03:09:12,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:12,908][root][INFO] - Training Epoch: 2/2, step 5663/7134 completed (loss: 0.019413894042372704, acc: 0.9938367009162903)
[2024-12-17 03:09:13,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:13,237][root][INFO] - Training Epoch: 2/2, step 5664/7134 completed (loss: 0.08304435759782791, acc: 0.9836552739143372)
[2024-12-17 03:09:13,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:13,597][root][INFO] - Training Epoch: 2/2, step 5665/7134 completed (loss: 0.026908161118626595, acc: 0.9900142550468445)
[2024-12-17 03:09:13,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:13,958][root][INFO] - Training Epoch: 2/2, step 5666/7134 completed (loss: 0.0182512030005455, acc: 0.9958620667457581)
[2024-12-17 03:09:14,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:14,286][root][INFO] - Training Epoch: 2/2, step 5667/7134 completed (loss: 0.04342446103692055, acc: 0.9909090995788574)
[2024-12-17 03:09:14,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:14,615][root][INFO] - Training Epoch: 2/2, step 5668/7134 completed (loss: 0.044973235577344894, acc: 0.985049843788147)
[2024-12-17 03:09:14,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:14,939][root][INFO] - Training Epoch: 2/2, step 5669/7134 completed (loss: 0.024456435814499855, acc: 0.9912023544311523)
[2024-12-17 03:09:15,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:15,267][root][INFO] - Training Epoch: 2/2, step 5670/7134 completed (loss: 0.01351828221231699, acc: 0.996666669845581)
[2024-12-17 03:09:15,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:15,636][root][INFO] - Training Epoch: 2/2, step 5671/7134 completed (loss: 0.014945827424526215, acc: 0.9963099360466003)
[2024-12-17 03:09:15,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:15,996][root][INFO] - Training Epoch: 2/2, step 5672/7134 completed (loss: 0.02093987725675106, acc: 0.9952681660652161)
[2024-12-17 03:09:16,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:16,318][root][INFO] - Training Epoch: 2/2, step 5673/7134 completed (loss: 0.013556310907006264, acc: 0.9970458149909973)
[2024-12-17 03:09:16,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:16,691][root][INFO] - Training Epoch: 2/2, step 5674/7134 completed (loss: 0.01955847255885601, acc: 0.9969419240951538)
[2024-12-17 03:09:16,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:17,033][root][INFO] - Training Epoch: 2/2, step 5675/7134 completed (loss: 0.040003594011068344, acc: 0.9883913993835449)
[2024-12-17 03:09:17,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:17,378][root][INFO] - Training Epoch: 2/2, step 5676/7134 completed (loss: 0.09107378870248795, acc: 0.9807692170143127)
[2024-12-17 03:09:17,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:17,718][root][INFO] - Training Epoch: 2/2, step 5677/7134 completed (loss: 0.05220650136470795, acc: 0.9857954382896423)
[2024-12-17 03:09:17,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:18,046][root][INFO] - Training Epoch: 2/2, step 5678/7134 completed (loss: 0.03139346092939377, acc: 0.9911764860153198)
[2024-12-17 03:09:18,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:18,406][root][INFO] - Training Epoch: 2/2, step 5679/7134 completed (loss: 0.05841348320245743, acc: 0.9795022010803223)
[2024-12-17 03:09:18,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:18,750][root][INFO] - Training Epoch: 2/2, step 5680/7134 completed (loss: 0.08239808678627014, acc: 0.9731743931770325)
[2024-12-17 03:09:18,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:19,094][root][INFO] - Training Epoch: 2/2, step 5681/7134 completed (loss: 0.059382759034633636, acc: 0.9849170446395874)
[2024-12-17 03:09:19,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:19,429][root][INFO] - Training Epoch: 2/2, step 5682/7134 completed (loss: 0.03535626456141472, acc: 0.9884560108184814)
[2024-12-17 03:09:19,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:19,769][root][INFO] - Training Epoch: 2/2, step 5683/7134 completed (loss: 0.07368024438619614, acc: 0.9795022010803223)
[2024-12-17 03:09:19,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:20,134][root][INFO] - Training Epoch: 2/2, step 5684/7134 completed (loss: 0.07942185550928116, acc: 0.9814502596855164)
[2024-12-17 03:09:20,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:20,466][root][INFO] - Training Epoch: 2/2, step 5685/7134 completed (loss: 0.05550127103924751, acc: 0.9852941036224365)
[2024-12-17 03:09:20,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:20,803][root][INFO] - Training Epoch: 2/2, step 5686/7134 completed (loss: 0.06681053340435028, acc: 0.9796954393386841)
[2024-12-17 03:09:20,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:21,107][root][INFO] - Training Epoch: 2/2, step 5687/7134 completed (loss: 0.06279513239860535, acc: 0.9835164546966553)
[2024-12-17 03:09:21,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:21,468][root][INFO] - Training Epoch: 2/2, step 5688/7134 completed (loss: 0.06516838073730469, acc: 0.9839786291122437)
[2024-12-17 03:09:21,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:21,819][root][INFO] - Training Epoch: 2/2, step 5689/7134 completed (loss: 0.08278506249189377, acc: 0.9802131056785583)
[2024-12-17 03:09:21,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:22,191][root][INFO] - Training Epoch: 2/2, step 5690/7134 completed (loss: 0.04903431609272957, acc: 0.9917452931404114)
[2024-12-17 03:09:22,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:22,513][root][INFO] - Training Epoch: 2/2, step 5691/7134 completed (loss: 0.07122955471277237, acc: 0.9776397347450256)
[2024-12-17 03:09:22,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:22,877][root][INFO] - Training Epoch: 2/2, step 5692/7134 completed (loss: 0.07681242376565933, acc: 0.9825737476348877)
[2024-12-17 03:09:22,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:23,204][root][INFO] - Training Epoch: 2/2, step 5693/7134 completed (loss: 0.02890501357614994, acc: 0.9940029978752136)
[2024-12-17 03:09:23,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:23,523][root][INFO] - Training Epoch: 2/2, step 5694/7134 completed (loss: 0.040236879140138626, acc: 0.9913169145584106)
[2024-12-17 03:09:23,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:23,878][root][INFO] - Training Epoch: 2/2, step 5695/7134 completed (loss: 0.023958845064044, acc: 0.9914039969444275)
[2024-12-17 03:09:24,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:24,236][root][INFO] - Training Epoch: 2/2, step 5696/7134 completed (loss: 0.05453230068087578, acc: 0.9870588183403015)
[2024-12-17 03:09:24,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:24,590][root][INFO] - Training Epoch: 2/2, step 5697/7134 completed (loss: 0.0794784426689148, acc: 0.9858956336975098)
[2024-12-17 03:09:24,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:24,941][root][INFO] - Training Epoch: 2/2, step 5698/7134 completed (loss: 0.05757004767656326, acc: 0.9877551198005676)
[2024-12-17 03:09:25,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:25,305][root][INFO] - Training Epoch: 2/2, step 5699/7134 completed (loss: 0.052700478583574295, acc: 0.9859872460365295)
[2024-12-17 03:09:25,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:25,657][root][INFO] - Training Epoch: 2/2, step 5700/7134 completed (loss: 0.021611999720335007, acc: 0.9929078221321106)
[2024-12-17 03:09:25,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:26,034][root][INFO] - Training Epoch: 2/2, step 5701/7134 completed (loss: 0.052485182881355286, acc: 0.9949937462806702)
[2024-12-17 03:09:26,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:26,382][root][INFO] - Training Epoch: 2/2, step 5702/7134 completed (loss: 0.035971540957689285, acc: 0.9945873022079468)
[2024-12-17 03:09:26,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:26,725][root][INFO] - Training Epoch: 2/2, step 5703/7134 completed (loss: 0.02095974050462246, acc: 0.9915611743927002)
[2024-12-17 03:09:26,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:27,047][root][INFO] - Training Epoch: 2/2, step 5704/7134 completed (loss: 0.05354713276028633, acc: 0.9828816056251526)
[2024-12-17 03:09:27,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:27,275][root][INFO] - Training Epoch: 2/2, step 5705/7134 completed (loss: 0.020186882466077805, acc: 0.9964285492897034)
[2024-12-17 03:09:27,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:27,657][root][INFO] - Training Epoch: 2/2, step 5706/7134 completed (loss: 0.0325569249689579, acc: 0.9921700358390808)
[2024-12-17 03:09:27,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:27,981][root][INFO] - Training Epoch: 2/2, step 5707/7134 completed (loss: 0.045816585421562195, acc: 0.98591548204422)
[2024-12-17 03:09:28,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:28,308][root][INFO] - Training Epoch: 2/2, step 5708/7134 completed (loss: 0.022094542160630226, acc: 0.9940740466117859)
[2024-12-17 03:09:28,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:28,652][root][INFO] - Training Epoch: 2/2, step 5709/7134 completed (loss: 0.05900304391980171, acc: 0.9808481335639954)
[2024-12-17 03:09:28,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:29,005][root][INFO] - Training Epoch: 2/2, step 5710/7134 completed (loss: 0.05180517956614494, acc: 0.9860050678253174)
[2024-12-17 03:09:29,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:29,335][root][INFO] - Training Epoch: 2/2, step 5711/7134 completed (loss: 0.0508686788380146, acc: 0.9882199168205261)
[2024-12-17 03:09:29,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:29,674][root][INFO] - Training Epoch: 2/2, step 5712/7134 completed (loss: 0.05280498415231705, acc: 0.9879999756813049)
[2024-12-17 03:09:29,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:30,046][root][INFO] - Training Epoch: 2/2, step 5713/7134 completed (loss: 0.023308349773287773, acc: 0.9911054372787476)
[2024-12-17 03:09:30,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:30,404][root][INFO] - Training Epoch: 2/2, step 5714/7134 completed (loss: 0.028811000287532806, acc: 0.993773341178894)
[2024-12-17 03:09:30,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:30,726][root][INFO] - Training Epoch: 2/2, step 5715/7134 completed (loss: 0.06843677163124084, acc: 0.9869646430015564)
[2024-12-17 03:09:30,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:31,044][root][INFO] - Training Epoch: 2/2, step 5716/7134 completed (loss: 0.12340651452541351, acc: 0.980461835861206)
[2024-12-17 03:09:31,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:31,366][root][INFO] - Training Epoch: 2/2, step 5717/7134 completed (loss: 0.10175223648548126, acc: 0.9782270789146423)
[2024-12-17 03:09:31,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:31,682][root][INFO] - Training Epoch: 2/2, step 5718/7134 completed (loss: 0.06678958237171173, acc: 0.9826498627662659)
[2024-12-17 03:09:31,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:32,007][root][INFO] - Training Epoch: 2/2, step 5719/7134 completed (loss: 0.03572799265384674, acc: 0.9910045266151428)
[2024-12-17 03:09:32,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:32,326][root][INFO] - Training Epoch: 2/2, step 5720/7134 completed (loss: 0.043499283492565155, acc: 0.9861830472946167)
[2024-12-17 03:09:32,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:32,651][root][INFO] - Training Epoch: 2/2, step 5721/7134 completed (loss: 0.04876327887177467, acc: 0.9868420958518982)
[2024-12-17 03:09:32,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:32,933][root][INFO] - Training Epoch: 2/2, step 5722/7134 completed (loss: 0.04011515900492668, acc: 0.9889135360717773)
[2024-12-17 03:09:33,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:33,274][root][INFO] - Training Epoch: 2/2, step 5723/7134 completed (loss: 0.05007890611886978, acc: 0.9833585619926453)
[2024-12-17 03:09:33,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:33,587][root][INFO] - Training Epoch: 2/2, step 5724/7134 completed (loss: 0.03265135735273361, acc: 0.9872000217437744)
[2024-12-17 03:09:33,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:33,930][root][INFO] - Training Epoch: 2/2, step 5725/7134 completed (loss: 0.023390570655465126, acc: 0.9928571581840515)
[2024-12-17 03:09:34,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:34,255][root][INFO] - Training Epoch: 2/2, step 5726/7134 completed (loss: 0.060374047607183456, acc: 0.9877675771713257)
[2024-12-17 03:09:34,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:34,599][root][INFO] - Training Epoch: 2/2, step 5727/7134 completed (loss: 0.02058003470301628, acc: 0.9959893226623535)
[2024-12-17 03:09:34,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:34,902][root][INFO] - Training Epoch: 2/2, step 5728/7134 completed (loss: 0.014011180959641933, acc: 0.9982455968856812)
[2024-12-17 03:09:34,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:35,208][root][INFO] - Training Epoch: 2/2, step 5729/7134 completed (loss: 0.021319719031453133, acc: 0.9933333396911621)
[2024-12-17 03:09:35,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:35,523][root][INFO] - Training Epoch: 2/2, step 5730/7134 completed (loss: 0.08185983449220657, acc: 0.9858585596084595)
[2024-12-17 03:09:35,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:35,869][root][INFO] - Training Epoch: 2/2, step 5731/7134 completed (loss: 0.0537223294377327, acc: 0.9784052968025208)
[2024-12-17 03:09:35,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:36,181][root][INFO] - Training Epoch: 2/2, step 5732/7134 completed (loss: 0.17062713205814362, acc: 0.9611650705337524)
[2024-12-17 03:09:36,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:36,503][root][INFO] - Training Epoch: 2/2, step 5733/7134 completed (loss: 0.047104157507419586, acc: 0.9872495532035828)
[2024-12-17 03:09:36,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:36,826][root][INFO] - Training Epoch: 2/2, step 5734/7134 completed (loss: 0.021517129614949226, acc: 0.9950000047683716)
[2024-12-17 03:09:36,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:37,145][root][INFO] - Training Epoch: 2/2, step 5735/7134 completed (loss: 0.05342467874288559, acc: 0.9820788502693176)
[2024-12-17 03:09:37,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:37,509][root][INFO] - Training Epoch: 2/2, step 5736/7134 completed (loss: 0.04742271453142166, acc: 0.9819548726081848)
[2024-12-17 03:09:37,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:37,841][root][INFO] - Training Epoch: 2/2, step 5737/7134 completed (loss: 0.044397756457328796, acc: 0.9879153966903687)
[2024-12-17 03:09:37,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:38,196][root][INFO] - Training Epoch: 2/2, step 5738/7134 completed (loss: 0.03386309742927551, acc: 0.9891172647476196)
[2024-12-17 03:09:38,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:38,533][root][INFO] - Training Epoch: 2/2, step 5739/7134 completed (loss: 0.060790758579969406, acc: 0.9810526371002197)
[2024-12-17 03:09:38,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:38,860][root][INFO] - Training Epoch: 2/2, step 5740/7134 completed (loss: 0.04190339148044586, acc: 0.9859334826469421)
[2024-12-17 03:09:38,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:39,195][root][INFO] - Training Epoch: 2/2, step 5741/7134 completed (loss: 0.03386060148477554, acc: 0.9922978281974792)
[2024-12-17 03:09:39,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:39,524][root][INFO] - Training Epoch: 2/2, step 5742/7134 completed (loss: 0.03128683567047119, acc: 0.9921156167984009)
[2024-12-17 03:09:39,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:39,880][root][INFO] - Training Epoch: 2/2, step 5743/7134 completed (loss: 0.03219035640358925, acc: 0.9901960492134094)
[2024-12-17 03:09:40,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:40,193][root][INFO] - Training Epoch: 2/2, step 5744/7134 completed (loss: 0.011993137188255787, acc: 0.9979079365730286)
[2024-12-17 03:09:40,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:40,554][root][INFO] - Training Epoch: 2/2, step 5745/7134 completed (loss: 0.02818859927356243, acc: 0.9922279715538025)
[2024-12-17 03:09:40,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:40,868][root][INFO] - Training Epoch: 2/2, step 5746/7134 completed (loss: 0.062254562973976135, acc: 0.9852941036224365)
[2024-12-17 03:09:40,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:41,198][root][INFO] - Training Epoch: 2/2, step 5747/7134 completed (loss: 0.03133293613791466, acc: 0.990304708480835)
[2024-12-17 03:09:41,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:41,547][root][INFO] - Training Epoch: 2/2, step 5748/7134 completed (loss: 0.036358609795570374, acc: 0.9908592104911804)
[2024-12-17 03:09:41,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:41,898][root][INFO] - Training Epoch: 2/2, step 5749/7134 completed (loss: 0.03631037473678589, acc: 0.9921466112136841)
[2024-12-17 03:09:41,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:42,234][root][INFO] - Training Epoch: 2/2, step 5750/7134 completed (loss: 0.0427694097161293, acc: 0.9863861203193665)
[2024-12-17 03:09:42,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:42,568][root][INFO] - Training Epoch: 2/2, step 5751/7134 completed (loss: 0.05175551027059555, acc: 0.9845956563949585)
[2024-12-17 03:09:42,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:42,903][root][INFO] - Training Epoch: 2/2, step 5752/7134 completed (loss: 0.048799753189086914, acc: 0.988399088382721)
[2024-12-17 03:09:42,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:43,223][root][INFO] - Training Epoch: 2/2, step 5753/7134 completed (loss: 0.06671292334794998, acc: 0.987500011920929)
[2024-12-17 03:09:43,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:43,596][root][INFO] - Training Epoch: 2/2, step 5754/7134 completed (loss: 0.0664539635181427, acc: 0.9834395051002502)
[2024-12-17 03:09:43,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:43,926][root][INFO] - Training Epoch: 2/2, step 5755/7134 completed (loss: 0.03473222628235817, acc: 0.9897511005401611)
[2024-12-17 03:09:44,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:44,251][root][INFO] - Training Epoch: 2/2, step 5756/7134 completed (loss: 0.0623481459915638, acc: 0.9840425252914429)
[2024-12-17 03:09:44,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:44,608][root][INFO] - Training Epoch: 2/2, step 5757/7134 completed (loss: 0.029012765735387802, acc: 0.9885057210922241)
[2024-12-17 03:09:44,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:44,918][root][INFO] - Training Epoch: 2/2, step 5758/7134 completed (loss: 0.04954887926578522, acc: 0.9779411554336548)
[2024-12-17 03:09:45,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:45,210][root][INFO] - Training Epoch: 2/2, step 5759/7134 completed (loss: 0.0539771132171154, acc: 0.9784366488456726)
[2024-12-17 03:09:45,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:45,550][root][INFO] - Training Epoch: 2/2, step 5760/7134 completed (loss: 0.03596910089254379, acc: 0.9923664331436157)
[2024-12-17 03:09:45,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:45,906][root][INFO] - Training Epoch: 2/2, step 5761/7134 completed (loss: 0.04156762734055519, acc: 0.9853479862213135)
[2024-12-17 03:09:45,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:46,226][root][INFO] - Training Epoch: 2/2, step 5762/7134 completed (loss: 0.04735693335533142, acc: 0.989051103591919)
[2024-12-17 03:09:46,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:46,568][root][INFO] - Training Epoch: 2/2, step 5763/7134 completed (loss: 0.06297296285629272, acc: 0.9849435091018677)
[2024-12-17 03:09:46,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:46,873][root][INFO] - Training Epoch: 2/2, step 5764/7134 completed (loss: 0.03145493566989899, acc: 0.9897435903549194)
[2024-12-17 03:09:46,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:47,207][root][INFO] - Training Epoch: 2/2, step 5765/7134 completed (loss: 0.01818428933620453, acc: 0.994397759437561)
[2024-12-17 03:09:47,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:47,536][root][INFO] - Training Epoch: 2/2, step 5766/7134 completed (loss: 0.029132427647709846, acc: 0.9955157041549683)
[2024-12-17 03:09:47,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:47,859][root][INFO] - Training Epoch: 2/2, step 5767/7134 completed (loss: 0.00839435774832964, acc: 0.9972183704376221)
[2024-12-17 03:09:47,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:48,201][root][INFO] - Training Epoch: 2/2, step 5768/7134 completed (loss: 0.019121699035167694, acc: 0.9955089688301086)
[2024-12-17 03:09:48,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:48,555][root][INFO] - Training Epoch: 2/2, step 5769/7134 completed (loss: 0.007348239421844482, acc: 1.0)
[2024-12-17 03:09:48,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:48,913][root][INFO] - Training Epoch: 2/2, step 5770/7134 completed (loss: 0.045002274215221405, acc: 0.990208089351654)
[2024-12-17 03:09:48,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:49,243][root][INFO] - Training Epoch: 2/2, step 5771/7134 completed (loss: 0.06077737733721733, acc: 0.9932065010070801)
[2024-12-17 03:09:49,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:49,589][root][INFO] - Training Epoch: 2/2, step 5772/7134 completed (loss: 0.026470525190234184, acc: 0.9930434823036194)
[2024-12-17 03:09:49,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:49,938][root][INFO] - Training Epoch: 2/2, step 5773/7134 completed (loss: 0.02438383735716343, acc: 0.9916387796401978)
[2024-12-17 03:09:50,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:50,282][root][INFO] - Training Epoch: 2/2, step 5774/7134 completed (loss: 0.01825733296573162, acc: 0.997032642364502)
[2024-12-17 03:09:50,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:50,599][root][INFO] - Training Epoch: 2/2, step 5775/7134 completed (loss: 0.017574038356542587, acc: 0.9950576424598694)
[2024-12-17 03:09:50,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:50,930][root][INFO] - Training Epoch: 2/2, step 5776/7134 completed (loss: 0.04608446732163429, acc: 0.9915730357170105)
[2024-12-17 03:09:51,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:51,283][root][INFO] - Training Epoch: 2/2, step 5777/7134 completed (loss: 0.06884895265102386, acc: 0.9839109182357788)
[2024-12-17 03:09:51,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:51,633][root][INFO] - Training Epoch: 2/2, step 5778/7134 completed (loss: 0.09904611110687256, acc: 0.9743589758872986)
[2024-12-17 03:09:51,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:51,983][root][INFO] - Training Epoch: 2/2, step 5779/7134 completed (loss: 0.042547497898340225, acc: 0.993122398853302)
[2024-12-17 03:09:52,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:52,345][root][INFO] - Training Epoch: 2/2, step 5780/7134 completed (loss: 0.0392075851559639, acc: 0.9916467666625977)
[2024-12-17 03:09:52,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:52,687][root][INFO] - Training Epoch: 2/2, step 5781/7134 completed (loss: 0.04522990062832832, acc: 0.9875690340995789)
[2024-12-17 03:09:52,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:53,042][root][INFO] - Training Epoch: 2/2, step 5782/7134 completed (loss: 0.01759191043674946, acc: 0.9961140155792236)
[2024-12-17 03:09:53,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:53,397][root][INFO] - Training Epoch: 2/2, step 5783/7134 completed (loss: 0.037241846323013306, acc: 0.9946879148483276)
[2024-12-17 03:09:53,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:53,735][root][INFO] - Training Epoch: 2/2, step 5784/7134 completed (loss: 0.037555206567049026, acc: 0.9905787110328674)
[2024-12-17 03:09:53,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:54,065][root][INFO] - Training Epoch: 2/2, step 5785/7134 completed (loss: 0.05433105304837227, acc: 0.9811320900917053)
[2024-12-17 03:09:54,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:54,379][root][INFO] - Training Epoch: 2/2, step 5786/7134 completed (loss: 0.03872036933898926, acc: 0.9877049326896667)
[2024-12-17 03:09:54,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:54,724][root][INFO] - Training Epoch: 2/2, step 5787/7134 completed (loss: 0.029266860336065292, acc: 0.9925373196601868)
[2024-12-17 03:09:54,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:55,033][root][INFO] - Training Epoch: 2/2, step 5788/7134 completed (loss: 0.013131167739629745, acc: 0.9969230890274048)
[2024-12-17 03:09:55,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:55,383][root][INFO] - Training Epoch: 2/2, step 5789/7134 completed (loss: 0.028633184731006622, acc: 0.9925558567047119)
[2024-12-17 03:09:55,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:55,724][root][INFO] - Training Epoch: 2/2, step 5790/7134 completed (loss: 0.03163249045610428, acc: 0.9903846383094788)
[2024-12-17 03:09:55,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:56,059][root][INFO] - Training Epoch: 2/2, step 5791/7134 completed (loss: 0.054868828505277634, acc: 0.9793814420700073)
[2024-12-17 03:09:56,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:56,401][root][INFO] - Training Epoch: 2/2, step 5792/7134 completed (loss: 0.05098102241754532, acc: 0.9830220937728882)
[2024-12-17 03:09:56,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:56,726][root][INFO] - Training Epoch: 2/2, step 5793/7134 completed (loss: 0.07389752566814423, acc: 0.9795597195625305)
[2024-12-17 03:09:56,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:57,047][root][INFO] - Training Epoch: 2/2, step 5794/7134 completed (loss: 0.049106333404779434, acc: 0.9848484992980957)
[2024-12-17 03:09:57,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:57,375][root][INFO] - Training Epoch: 2/2, step 5795/7134 completed (loss: 0.10341639816761017, acc: 0.9768907427787781)
[2024-12-17 03:09:57,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:57,701][root][INFO] - Training Epoch: 2/2, step 5796/7134 completed (loss: 0.04208927974104881, acc: 0.9830795526504517)
[2024-12-17 03:09:57,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:58,024][root][INFO] - Training Epoch: 2/2, step 5797/7134 completed (loss: 0.03634890913963318, acc: 0.9872000217437744)
[2024-12-17 03:09:58,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:58,343][root][INFO] - Training Epoch: 2/2, step 5798/7134 completed (loss: 0.16595762968063354, acc: 0.9617391228675842)
[2024-12-17 03:09:58,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:58,657][root][INFO] - Training Epoch: 2/2, step 5799/7134 completed (loss: 0.06855963915586472, acc: 0.9743589758872986)
[2024-12-17 03:09:58,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:58,980][root][INFO] - Training Epoch: 2/2, step 5800/7134 completed (loss: 0.0637066513299942, acc: 0.9797794222831726)
[2024-12-17 03:09:59,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:59,313][root][INFO] - Training Epoch: 2/2, step 5801/7134 completed (loss: 0.060366880148649216, acc: 0.9786585569381714)
[2024-12-17 03:09:59,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:59,641][root][INFO] - Training Epoch: 2/2, step 5802/7134 completed (loss: 0.029576515778899193, acc: 0.9926062822341919)
[2024-12-17 03:09:59,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:59,997][root][INFO] - Training Epoch: 2/2, step 5803/7134 completed (loss: 0.02662316896021366, acc: 0.9936224222183228)
[2024-12-17 03:10:00,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:00,333][root][INFO] - Training Epoch: 2/2, step 5804/7134 completed (loss: 0.1065039113163948, acc: 0.97428959608078)
[2024-12-17 03:10:00,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:00,671][root][INFO] - Training Epoch: 2/2, step 5805/7134 completed (loss: 0.05370074510574341, acc: 0.9856114983558655)
[2024-12-17 03:10:00,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:01,014][root][INFO] - Training Epoch: 2/2, step 5806/7134 completed (loss: 0.05277225747704506, acc: 0.9849726557731628)
[2024-12-17 03:10:01,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:01,351][root][INFO] - Training Epoch: 2/2, step 5807/7134 completed (loss: 0.08118969947099686, acc: 0.9818456768989563)
[2024-12-17 03:10:01,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:01,715][root][INFO] - Training Epoch: 2/2, step 5808/7134 completed (loss: 0.020475812256336212, acc: 0.9957805871963501)
[2024-12-17 03:10:01,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:02,034][root][INFO] - Training Epoch: 2/2, step 5809/7134 completed (loss: 0.056084394454956055, acc: 0.984649121761322)
[2024-12-17 03:10:02,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:02,372][root][INFO] - Training Epoch: 2/2, step 5810/7134 completed (loss: 0.048175521194934845, acc: 0.9878296256065369)
[2024-12-17 03:10:02,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:02,643][root][INFO] - Training Epoch: 2/2, step 5811/7134 completed (loss: 0.03838096931576729, acc: 0.983132541179657)
[2024-12-17 03:10:02,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:02,969][root][INFO] - Training Epoch: 2/2, step 5812/7134 completed (loss: 0.012699445709586143, acc: 0.9983498454093933)
[2024-12-17 03:10:03,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:03,288][root][INFO] - Training Epoch: 2/2, step 5813/7134 completed (loss: 0.01838943362236023, acc: 0.994339644908905)
[2024-12-17 03:10:03,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:03,677][root][INFO] - Training Epoch: 2/2, step 5814/7134 completed (loss: 0.023730387911200523, acc: 0.9915397763252258)
[2024-12-17 03:10:03,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:04,009][root][INFO] - Training Epoch: 2/2, step 5815/7134 completed (loss: 0.03785843029618263, acc: 0.9868173003196716)
[2024-12-17 03:10:04,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:04,358][root][INFO] - Training Epoch: 2/2, step 5816/7134 completed (loss: 0.009810961782932281, acc: 0.9975062608718872)
[2024-12-17 03:10:04,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:04,682][root][INFO] - Training Epoch: 2/2, step 5817/7134 completed (loss: 0.07574228942394257, acc: 0.98740553855896)
[2024-12-17 03:10:04,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:05,020][root][INFO] - Training Epoch: 2/2, step 5818/7134 completed (loss: 0.037649184465408325, acc: 0.9881481528282166)
[2024-12-17 03:10:05,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:05,336][root][INFO] - Training Epoch: 2/2, step 5819/7134 completed (loss: 0.023152515292167664, acc: 0.9913793206214905)
[2024-12-17 03:10:05,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:05,641][root][INFO] - Training Epoch: 2/2, step 5820/7134 completed (loss: 0.05426615849137306, acc: 0.9876033067703247)
[2024-12-17 03:10:05,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:05,962][root][INFO] - Training Epoch: 2/2, step 5821/7134 completed (loss: 0.014528467319905758, acc: 0.9969183206558228)
[2024-12-17 03:10:06,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:06,298][root][INFO] - Training Epoch: 2/2, step 5822/7134 completed (loss: 0.025447756052017212, acc: 0.9951612949371338)
[2024-12-17 03:10:06,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:06,625][root][INFO] - Training Epoch: 2/2, step 5823/7134 completed (loss: 0.0326458215713501, acc: 0.9906687140464783)
[2024-12-17 03:10:06,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:06,972][root][INFO] - Training Epoch: 2/2, step 5824/7134 completed (loss: 0.024814553558826447, acc: 0.9953343868255615)
[2024-12-17 03:10:07,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:07,311][root][INFO] - Training Epoch: 2/2, step 5825/7134 completed (loss: 0.041228458285331726, acc: 0.9896193742752075)
[2024-12-17 03:10:07,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:07,642][root][INFO] - Training Epoch: 2/2, step 5826/7134 completed (loss: 0.008614870719611645, acc: 0.9982269406318665)
[2024-12-17 03:10:07,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:07,955][root][INFO] - Training Epoch: 2/2, step 5827/7134 completed (loss: 0.02334650419652462, acc: 0.9942307472229004)
[2024-12-17 03:10:08,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:08,286][root][INFO] - Training Epoch: 2/2, step 5828/7134 completed (loss: 0.04891917482018471, acc: 0.9866270422935486)
[2024-12-17 03:10:08,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:08,625][root][INFO] - Training Epoch: 2/2, step 5829/7134 completed (loss: 0.023152152076363564, acc: 0.992094874382019)
[2024-12-17 03:10:08,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:08,932][root][INFO] - Training Epoch: 2/2, step 5830/7134 completed (loss: 0.03418469429016113, acc: 0.9905481934547424)
[2024-12-17 03:10:09,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:09,248][root][INFO] - Training Epoch: 2/2, step 5831/7134 completed (loss: 0.018262134864926338, acc: 0.9953488111495972)
[2024-12-17 03:10:09,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:09,583][root][INFO] - Training Epoch: 2/2, step 5832/7134 completed (loss: 0.05719561129808426, acc: 0.9847972989082336)
[2024-12-17 03:10:09,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:09,891][root][INFO] - Training Epoch: 2/2, step 5833/7134 completed (loss: 0.019364820793271065, acc: 0.9946236610412598)
[2024-12-17 03:10:10,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:10,227][root][INFO] - Training Epoch: 2/2, step 5834/7134 completed (loss: 0.028344638645648956, acc: 0.9958333373069763)
[2024-12-17 03:10:10,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:10,562][root][INFO] - Training Epoch: 2/2, step 5835/7134 completed (loss: 0.01587839238345623, acc: 0.9985548853874207)
[2024-12-17 03:10:10,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:10,906][root][INFO] - Training Epoch: 2/2, step 5836/7134 completed (loss: 0.05050616338849068, acc: 0.9899135231971741)
[2024-12-17 03:10:11,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:11,235][root][INFO] - Training Epoch: 2/2, step 5837/7134 completed (loss: 0.06965029984712601, acc: 0.9932432174682617)
[2024-12-17 03:10:11,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:11,577][root][INFO] - Training Epoch: 2/2, step 5838/7134 completed (loss: 0.04464339092373848, acc: 0.9917627573013306)
[2024-12-17 03:10:11,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:11,907][root][INFO] - Training Epoch: 2/2, step 5839/7134 completed (loss: 0.02676454186439514, acc: 0.9928571581840515)
[2024-12-17 03:10:12,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:12,230][root][INFO] - Training Epoch: 2/2, step 5840/7134 completed (loss: 0.012770290486514568, acc: 0.996820330619812)
[2024-12-17 03:10:12,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:12,563][root][INFO] - Training Epoch: 2/2, step 5841/7134 completed (loss: 0.05127421021461487, acc: 0.9888357520103455)
[2024-12-17 03:10:12,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:12,888][root][INFO] - Training Epoch: 2/2, step 5842/7134 completed (loss: 0.028210962191224098, acc: 0.9927536249160767)
[2024-12-17 03:10:13,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:13,237][root][INFO] - Training Epoch: 2/2, step 5843/7134 completed (loss: 0.044438015669584274, acc: 0.9892904758453369)
[2024-12-17 03:10:13,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:13,576][root][INFO] - Training Epoch: 2/2, step 5844/7134 completed (loss: 0.02557176537811756, acc: 0.9943100810050964)
[2024-12-17 03:10:13,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:13,904][root][INFO] - Training Epoch: 2/2, step 5845/7134 completed (loss: 0.02771316096186638, acc: 0.9928774833679199)
[2024-12-17 03:10:14,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:14,244][root][INFO] - Training Epoch: 2/2, step 5846/7134 completed (loss: 0.042585939168930054, acc: 0.9876881241798401)
[2024-12-17 03:10:14,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:14,587][root][INFO] - Training Epoch: 2/2, step 5847/7134 completed (loss: 0.02201060950756073, acc: 0.9945054650306702)
[2024-12-17 03:10:14,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:14,908][root][INFO] - Training Epoch: 2/2, step 5848/7134 completed (loss: 0.03744357079267502, acc: 0.9895833134651184)
[2024-12-17 03:10:15,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:15,224][root][INFO] - Training Epoch: 2/2, step 5849/7134 completed (loss: 0.04315168410539627, acc: 0.9882006049156189)
[2024-12-17 03:10:15,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:15,546][root][INFO] - Training Epoch: 2/2, step 5850/7134 completed (loss: 0.025951068848371506, acc: 0.9938931465148926)
[2024-12-17 03:10:15,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:15,859][root][INFO] - Training Epoch: 2/2, step 5851/7134 completed (loss: 0.0341610386967659, acc: 0.9884868264198303)
[2024-12-17 03:10:15,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:16,187][root][INFO] - Training Epoch: 2/2, step 5852/7134 completed (loss: 0.017632922157645226, acc: 0.9941605925559998)
[2024-12-17 03:10:16,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:16,528][root][INFO] - Training Epoch: 2/2, step 5853/7134 completed (loss: 0.04791499301791191, acc: 0.9864681959152222)
[2024-12-17 03:10:16,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:16,848][root][INFO] - Training Epoch: 2/2, step 5854/7134 completed (loss: 0.03199227899312973, acc: 0.9858406782150269)
[2024-12-17 03:10:16,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:17,166][root][INFO] - Training Epoch: 2/2, step 5855/7134 completed (loss: 0.03782119229435921, acc: 0.9879102110862732)
[2024-12-17 03:10:17,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:17,502][root][INFO] - Training Epoch: 2/2, step 5856/7134 completed (loss: 0.055540282279253006, acc: 0.9833837151527405)
[2024-12-17 03:10:17,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:17,862][root][INFO] - Training Epoch: 2/2, step 5857/7134 completed (loss: 0.033936478197574615, acc: 0.9936808943748474)
[2024-12-17 03:10:17,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:18,175][root][INFO] - Training Epoch: 2/2, step 5858/7134 completed (loss: 0.02248038724064827, acc: 0.9926062822341919)
[2024-12-17 03:10:18,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:18,501][root][INFO] - Training Epoch: 2/2, step 5859/7134 completed (loss: 0.03841385245323181, acc: 0.98828125)
[2024-12-17 03:10:18,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:18,820][root][INFO] - Training Epoch: 2/2, step 5860/7134 completed (loss: 0.042812030762434006, acc: 0.9779614210128784)
[2024-12-17 03:10:18,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:19,138][root][INFO] - Training Epoch: 2/2, step 5861/7134 completed (loss: 0.03263192996382713, acc: 0.9898580312728882)
[2024-12-17 03:10:19,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:19,477][root][INFO] - Training Epoch: 2/2, step 5862/7134 completed (loss: 0.0429091639816761, acc: 0.9871244430541992)
[2024-12-17 03:10:19,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:19,748][root][INFO] - Training Epoch: 2/2, step 5863/7134 completed (loss: 0.04051603749394417, acc: 0.9898989796638489)
[2024-12-17 03:10:19,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:20,082][root][INFO] - Training Epoch: 2/2, step 5864/7134 completed (loss: 0.06523312628269196, acc: 0.9880239367485046)
[2024-12-17 03:10:20,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:20,402][root][INFO] - Training Epoch: 2/2, step 5865/7134 completed (loss: 0.09332740306854248, acc: 0.9825396537780762)
[2024-12-17 03:10:20,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:20,763][root][INFO] - Training Epoch: 2/2, step 5866/7134 completed (loss: 0.024511808529496193, acc: 0.9933862686157227)
[2024-12-17 03:10:20,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:21,098][root][INFO] - Training Epoch: 2/2, step 5867/7134 completed (loss: 0.033293332904577255, acc: 0.9900826215744019)
[2024-12-17 03:10:21,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:21,435][root][INFO] - Training Epoch: 2/2, step 5868/7134 completed (loss: 0.04660731926560402, acc: 0.9879310131072998)
[2024-12-17 03:10:21,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:21,756][root][INFO] - Training Epoch: 2/2, step 5869/7134 completed (loss: 0.08123232424259186, acc: 0.9865671396255493)
[2024-12-17 03:10:21,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:22,091][root][INFO] - Training Epoch: 2/2, step 5870/7134 completed (loss: 0.0429392084479332, acc: 0.9958158731460571)
[2024-12-17 03:10:22,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:22,396][root][INFO] - Training Epoch: 2/2, step 5871/7134 completed (loss: 0.013979618437588215, acc: 0.993630588054657)
[2024-12-17 03:10:22,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:22,720][root][INFO] - Training Epoch: 2/2, step 5872/7134 completed (loss: 0.04264013096690178, acc: 0.9893454909324646)
[2024-12-17 03:10:22,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:23,116][root][INFO] - Training Epoch: 2/2, step 5873/7134 completed (loss: 0.03425966948270798, acc: 0.9893333315849304)
[2024-12-17 03:10:23,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:23,403][root][INFO] - Training Epoch: 2/2, step 5874/7134 completed (loss: 0.015562166459858418, acc: 0.9959839582443237)
[2024-12-17 03:10:23,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:23,738][root][INFO] - Training Epoch: 2/2, step 5875/7134 completed (loss: 0.03507443517446518, acc: 0.9840707778930664)
[2024-12-17 03:10:23,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:24,086][root][INFO] - Training Epoch: 2/2, step 5876/7134 completed (loss: 0.01284212525933981, acc: 0.9951456189155579)
[2024-12-17 03:10:24,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:24,416][root][INFO] - Training Epoch: 2/2, step 5877/7134 completed (loss: 0.051947981119155884, acc: 0.989847719669342)
[2024-12-17 03:10:24,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:24,755][root][INFO] - Training Epoch: 2/2, step 5878/7134 completed (loss: 0.04332296922802925, acc: 0.9890350699424744)
[2024-12-17 03:10:24,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:25,070][root][INFO] - Training Epoch: 2/2, step 5879/7134 completed (loss: 0.017133168876171112, acc: 0.9974619150161743)
[2024-12-17 03:10:25,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:25,328][root][INFO] - Training Epoch: 2/2, step 5880/7134 completed (loss: 0.01788390427827835, acc: 0.995555579662323)
[2024-12-17 03:10:25,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:25,649][root][INFO] - Training Epoch: 2/2, step 5881/7134 completed (loss: 0.02322559617459774, acc: 0.9884836673736572)
[2024-12-17 03:10:25,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:25,887][root][INFO] - Training Epoch: 2/2, step 5882/7134 completed (loss: 0.022318320348858833, acc: 0.9929412007331848)
[2024-12-17 03:10:25,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:26,147][root][INFO] - Training Epoch: 2/2, step 5883/7134 completed (loss: 0.04793184623122215, acc: 0.9906367063522339)
[2024-12-17 03:10:26,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:26,482][root][INFO] - Training Epoch: 2/2, step 5884/7134 completed (loss: 0.07734422385692596, acc: 0.9781022071838379)
[2024-12-17 03:10:26,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:26,797][root][INFO] - Training Epoch: 2/2, step 5885/7134 completed (loss: 0.08575265854597092, acc: 0.9864130616188049)
[2024-12-17 03:10:26,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:27,101][root][INFO] - Training Epoch: 2/2, step 5886/7134 completed (loss: 0.02579539641737938, acc: 0.9885714054107666)
[2024-12-17 03:10:27,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:27,422][root][INFO] - Training Epoch: 2/2, step 5887/7134 completed (loss: 0.049026623368263245, acc: 0.9893842935562134)
[2024-12-17 03:10:27,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:27,756][root][INFO] - Training Epoch: 2/2, step 5888/7134 completed (loss: 0.08393492549657822, acc: 0.9831081032752991)
[2024-12-17 03:10:27,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:27,997][root][INFO] - Training Epoch: 2/2, step 5889/7134 completed (loss: 0.006669905502349138, acc: 1.0)
[2024-12-17 03:10:28,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:28,346][root][INFO] - Training Epoch: 2/2, step 5890/7134 completed (loss: 0.03688934072852135, acc: 0.9860140085220337)
[2024-12-17 03:10:28,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:28,680][root][INFO] - Training Epoch: 2/2, step 5891/7134 completed (loss: 0.04805116727948189, acc: 0.988950252532959)
[2024-12-17 03:10:28,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:29,036][root][INFO] - Training Epoch: 2/2, step 5892/7134 completed (loss: 0.07456184178590775, acc: 0.9868804812431335)
[2024-12-17 03:10:29,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:29,363][root][INFO] - Training Epoch: 2/2, step 5893/7134 completed (loss: 0.04455247148871422, acc: 0.9905511736869812)
[2024-12-17 03:10:29,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:29,641][root][INFO] - Training Epoch: 2/2, step 5894/7134 completed (loss: 0.010177035816013813, acc: 1.0)
[2024-12-17 03:10:29,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:29,964][root][INFO] - Training Epoch: 2/2, step 5895/7134 completed (loss: 0.015384683385491371, acc: 0.9952380657196045)
[2024-12-17 03:10:30,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:30,294][root][INFO] - Training Epoch: 2/2, step 5896/7134 completed (loss: 0.055122010409832, acc: 0.9846938848495483)
[2024-12-17 03:10:30,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:30,641][root][INFO] - Training Epoch: 2/2, step 5897/7134 completed (loss: 0.021480882540345192, acc: 0.9958677887916565)
[2024-12-17 03:10:30,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:30,961][root][INFO] - Training Epoch: 2/2, step 5898/7134 completed (loss: 0.015717480331659317, acc: 0.993534505367279)
[2024-12-17 03:10:31,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:31,192][root][INFO] - Training Epoch: 2/2, step 5899/7134 completed (loss: 0.02731567993760109, acc: 0.9940476417541504)
[2024-12-17 03:10:31,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:31,495][root][INFO] - Training Epoch: 2/2, step 5900/7134 completed (loss: 0.03308709338307381, acc: 0.9821428656578064)
[2024-12-17 03:10:31,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:31,829][root][INFO] - Training Epoch: 2/2, step 5901/7134 completed (loss: 0.0536649189889431, acc: 0.987500011920929)
[2024-12-17 03:10:31,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:32,173][root][INFO] - Training Epoch: 2/2, step 5902/7134 completed (loss: 0.09028910845518112, acc: 0.9664948582649231)
[2024-12-17 03:10:32,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:32,510][root][INFO] - Training Epoch: 2/2, step 5903/7134 completed (loss: 0.0566733293235302, acc: 0.9835766553878784)
[2024-12-17 03:10:32,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:32,863][root][INFO] - Training Epoch: 2/2, step 5904/7134 completed (loss: 0.04686411842703819, acc: 0.9890710115432739)
[2024-12-17 03:10:32,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:33,180][root][INFO] - Training Epoch: 2/2, step 5905/7134 completed (loss: 0.04231490194797516, acc: 0.9888734221458435)
[2024-12-17 03:10:33,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:33,541][root][INFO] - Training Epoch: 2/2, step 5906/7134 completed (loss: 0.05131852999329567, acc: 0.9877150058746338)
[2024-12-17 03:10:33,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:33,919][root][INFO] - Training Epoch: 2/2, step 5907/7134 completed (loss: 0.05108876898884773, acc: 0.983182430267334)
[2024-12-17 03:10:34,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:34,296][root][INFO] - Training Epoch: 2/2, step 5908/7134 completed (loss: 0.02854372188448906, acc: 0.9910485744476318)
[2024-12-17 03:10:34,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:34,771][root][INFO] - Training Epoch: 2/2, step 5909/7134 completed (loss: 0.054204974323511124, acc: 0.9855907559394836)
[2024-12-17 03:10:34,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:35,161][root][INFO] - Training Epoch: 2/2, step 5910/7134 completed (loss: 0.0544271320104599, acc: 0.9750346541404724)
[2024-12-17 03:10:35,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:35,495][root][INFO] - Training Epoch: 2/2, step 5911/7134 completed (loss: 0.05225459858775139, acc: 0.9884297251701355)
[2024-12-17 03:10:35,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:35,806][root][INFO] - Training Epoch: 2/2, step 5912/7134 completed (loss: 0.03815136477351189, acc: 0.9873417615890503)
[2024-12-17 03:10:35,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:36,173][root][INFO] - Training Epoch: 2/2, step 5913/7134 completed (loss: 0.12079230695962906, acc: 0.9714673757553101)
[2024-12-17 03:10:36,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:36,485][root][INFO] - Training Epoch: 2/2, step 5914/7134 completed (loss: 0.0353352390229702, acc: 0.9919742941856384)
[2024-12-17 03:10:36,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:36,846][root][INFO] - Training Epoch: 2/2, step 5915/7134 completed (loss: 0.050924938172101974, acc: 0.987596869468689)
[2024-12-17 03:10:36,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:37,211][root][INFO] - Training Epoch: 2/2, step 5916/7134 completed (loss: 0.035462215542793274, acc: 0.9908257126808167)
[2024-12-17 03:10:37,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:37,510][root][INFO] - Training Epoch: 2/2, step 5917/7134 completed (loss: 0.033957287669181824, acc: 0.9896013736724854)
[2024-12-17 03:10:37,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:37,874][root][INFO] - Training Epoch: 2/2, step 5918/7134 completed (loss: 0.10372669249773026, acc: 0.9796807169914246)
[2024-12-17 03:10:37,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:38,206][root][INFO] - Training Epoch: 2/2, step 5919/7134 completed (loss: 0.03565245494246483, acc: 0.9924012422561646)
[2024-12-17 03:10:38,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:38,536][root][INFO] - Training Epoch: 2/2, step 5920/7134 completed (loss: 0.033089492470026016, acc: 0.9900166392326355)
[2024-12-17 03:10:38,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:38,863][root][INFO] - Training Epoch: 2/2, step 5921/7134 completed (loss: 0.06555576622486115, acc: 0.9832985401153564)
[2024-12-17 03:10:38,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:39,208][root][INFO] - Training Epoch: 2/2, step 5922/7134 completed (loss: 0.19346103072166443, acc: 0.9609929323196411)
[2024-12-17 03:10:39,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:39,568][root][INFO] - Training Epoch: 2/2, step 5923/7134 completed (loss: 0.12167667597532272, acc: 0.9751098155975342)
[2024-12-17 03:10:39,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:39,891][root][INFO] - Training Epoch: 2/2, step 5924/7134 completed (loss: 0.05458839237689972, acc: 0.9809069037437439)
[2024-12-17 03:10:39,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:40,159][root][INFO] - Training Epoch: 2/2, step 5925/7134 completed (loss: 0.21244056522846222, acc: 0.9530791640281677)
[2024-12-17 03:10:40,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:40,482][root][INFO] - Training Epoch: 2/2, step 5926/7134 completed (loss: 0.0915408805012703, acc: 0.971666693687439)
[2024-12-17 03:10:40,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:40,802][root][INFO] - Training Epoch: 2/2, step 5927/7134 completed (loss: 0.07891516387462616, acc: 0.9866369962692261)
[2024-12-17 03:10:40,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:41,076][root][INFO] - Training Epoch: 2/2, step 5928/7134 completed (loss: 0.22321350872516632, acc: 0.9452054500579834)
[2024-12-17 03:10:41,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:41,427][root][INFO] - Training Epoch: 2/2, step 5929/7134 completed (loss: 0.06256935000419617, acc: 0.9813432693481445)
[2024-12-17 03:10:41,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:41,728][root][INFO] - Training Epoch: 2/2, step 5930/7134 completed (loss: 0.10020618140697479, acc: 0.9710467457771301)
[2024-12-17 03:10:41,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:42,046][root][INFO] - Training Epoch: 2/2, step 5931/7134 completed (loss: 0.04987383633852005, acc: 0.9848812222480774)
[2024-12-17 03:10:42,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:42,368][root][INFO] - Training Epoch: 2/2, step 5932/7134 completed (loss: 0.09209726005792618, acc: 0.9685184955596924)
[2024-12-17 03:10:42,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:42,650][root][INFO] - Training Epoch: 2/2, step 5933/7134 completed (loss: 0.1259843111038208, acc: 0.9643605947494507)
[2024-12-17 03:10:42,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:42,982][root][INFO] - Training Epoch: 2/2, step 5934/7134 completed (loss: 0.051294755190610886, acc: 0.9875665903091431)
[2024-12-17 03:10:43,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:43,301][root][INFO] - Training Epoch: 2/2, step 5935/7134 completed (loss: 0.03267120197415352, acc: 0.9941747784614563)
[2024-12-17 03:10:43,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:43,613][root][INFO] - Training Epoch: 2/2, step 5936/7134 completed (loss: 0.07791274040937424, acc: 0.9800918698310852)
[2024-12-17 03:10:43,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:43,946][root][INFO] - Training Epoch: 2/2, step 5937/7134 completed (loss: 0.026914428919553757, acc: 0.9920254945755005)
[2024-12-17 03:10:44,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:44,267][root][INFO] - Training Epoch: 2/2, step 5938/7134 completed (loss: 0.09373993426561356, acc: 0.9694072604179382)
[2024-12-17 03:10:44,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:44,544][root][INFO] - Training Epoch: 2/2, step 5939/7134 completed (loss: 0.12707637250423431, acc: 0.970588207244873)
[2024-12-17 03:10:44,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:44,905][root][INFO] - Training Epoch: 2/2, step 5940/7134 completed (loss: 0.07191760838031769, acc: 0.975218653678894)
[2024-12-17 03:10:45,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:45,194][root][INFO] - Training Epoch: 2/2, step 5941/7134 completed (loss: 0.050605785101652145, acc: 0.9906250238418579)
[2024-12-17 03:10:45,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:45,522][root][INFO] - Training Epoch: 2/2, step 5942/7134 completed (loss: 0.011817033402621746, acc: 0.9980879426002502)
[2024-12-17 03:10:45,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:45,846][root][INFO] - Training Epoch: 2/2, step 5943/7134 completed (loss: 0.017875911667943, acc: 0.995708167552948)
[2024-12-17 03:10:45,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:46,203][root][INFO] - Training Epoch: 2/2, step 5944/7134 completed (loss: 0.051842059940099716, acc: 0.9803664684295654)
[2024-12-17 03:10:46,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:46,567][root][INFO] - Training Epoch: 2/2, step 5945/7134 completed (loss: 0.02875014767050743, acc: 0.9954954981803894)
[2024-12-17 03:10:46,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:46,893][root][INFO] - Training Epoch: 2/2, step 5946/7134 completed (loss: 0.035952772945165634, acc: 0.9873188138008118)
[2024-12-17 03:10:47,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:47,243][root][INFO] - Training Epoch: 2/2, step 5947/7134 completed (loss: 0.03171977400779724, acc: 0.9888476133346558)
[2024-12-17 03:10:47,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:47,585][root][INFO] - Training Epoch: 2/2, step 5948/7134 completed (loss: 0.08179725706577301, acc: 0.9819999933242798)
[2024-12-17 03:10:47,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:47,935][root][INFO] - Training Epoch: 2/2, step 5949/7134 completed (loss: 0.019931070506572723, acc: 0.9937264919281006)
[2024-12-17 03:10:48,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:48,258][root][INFO] - Training Epoch: 2/2, step 5950/7134 completed (loss: 0.10731151700019836, acc: 0.9691211581230164)
[2024-12-17 03:10:48,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:48,590][root][INFO] - Training Epoch: 2/2, step 5951/7134 completed (loss: 0.05864288657903671, acc: 0.9842180609703064)
[2024-12-17 03:10:48,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:48,957][root][INFO] - Training Epoch: 2/2, step 5952/7134 completed (loss: 0.1806698739528656, acc: 0.9593750238418579)
[2024-12-17 03:10:49,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:49,299][root][INFO] - Training Epoch: 2/2, step 5953/7134 completed (loss: 0.06598933041095734, acc: 0.9752066135406494)
[2024-12-17 03:10:49,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:49,618][root][INFO] - Training Epoch: 2/2, step 5954/7134 completed (loss: 0.024801988154649734, acc: 0.9974619150161743)
[2024-12-17 03:10:49,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:49,852][root][INFO] - Training Epoch: 2/2, step 5955/7134 completed (loss: 0.019758891314268112, acc: 0.9952380657196045)
[2024-12-17 03:10:49,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:50,181][root][INFO] - Training Epoch: 2/2, step 5956/7134 completed (loss: 0.06814007461071014, acc: 0.9784313440322876)
[2024-12-17 03:10:50,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:50,496][root][INFO] - Training Epoch: 2/2, step 5957/7134 completed (loss: 0.061987631022930145, acc: 0.9850075244903564)
[2024-12-17 03:10:50,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:50,840][root][INFO] - Training Epoch: 2/2, step 5958/7134 completed (loss: 0.040830936282873154, acc: 0.9852349162101746)
[2024-12-17 03:10:50,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:51,191][root][INFO] - Training Epoch: 2/2, step 5959/7134 completed (loss: 0.05814581736922264, acc: 0.9879840016365051)
[2024-12-17 03:10:51,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:51,541][root][INFO] - Training Epoch: 2/2, step 5960/7134 completed (loss: 0.01461764145642519, acc: 0.9971910119056702)
[2024-12-17 03:10:51,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:51,826][root][INFO] - Training Epoch: 2/2, step 5961/7134 completed (loss: 0.05087634548544884, acc: 0.9856557250022888)
[2024-12-17 03:10:51,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:52,166][root][INFO] - Training Epoch: 2/2, step 5962/7134 completed (loss: 0.025677651166915894, acc: 0.9934959411621094)
[2024-12-17 03:10:52,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:52,508][root][INFO] - Training Epoch: 2/2, step 5963/7134 completed (loss: 0.025546127930283546, acc: 0.9902234673500061)
[2024-12-17 03:10:52,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:52,831][root][INFO] - Training Epoch: 2/2, step 5964/7134 completed (loss: 0.023833904415369034, acc: 0.9944547414779663)
[2024-12-17 03:10:52,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:53,165][root][INFO] - Training Epoch: 2/2, step 5965/7134 completed (loss: 0.05939276143908501, acc: 0.9910045266151428)
[2024-12-17 03:10:53,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:53,507][root][INFO] - Training Epoch: 2/2, step 5966/7134 completed (loss: 0.05027852579951286, acc: 0.9819694757461548)
[2024-12-17 03:10:53,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:53,846][root][INFO] - Training Epoch: 2/2, step 5967/7134 completed (loss: 0.03504755347967148, acc: 0.9850746393203735)
[2024-12-17 03:10:53,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:54,171][root][INFO] - Training Epoch: 2/2, step 5968/7134 completed (loss: 0.044163260608911514, acc: 0.9863013625144958)
[2024-12-17 03:10:54,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:54,491][root][INFO] - Training Epoch: 2/2, step 5969/7134 completed (loss: 0.05580201745033264, acc: 0.9845201373100281)
[2024-12-17 03:10:54,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:54,815][root][INFO] - Training Epoch: 2/2, step 5970/7134 completed (loss: 0.07967142760753632, acc: 0.9836065769195557)
[2024-12-17 03:10:54,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:55,159][root][INFO] - Training Epoch: 2/2, step 5971/7134 completed (loss: 0.021716102957725525, acc: 0.9912280440330505)
[2024-12-17 03:10:55,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:55,502][root][INFO] - Training Epoch: 2/2, step 5972/7134 completed (loss: 0.0845571756362915, acc: 0.9838472604751587)
[2024-12-17 03:10:55,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:55,876][root][INFO] - Training Epoch: 2/2, step 5973/7134 completed (loss: 0.0965651124715805, acc: 0.971222996711731)
[2024-12-17 03:10:55,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:56,240][root][INFO] - Training Epoch: 2/2, step 5974/7134 completed (loss: 0.022117458283901215, acc: 0.9948006868362427)
[2024-12-17 03:10:56,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:56,553][root][INFO] - Training Epoch: 2/2, step 5975/7134 completed (loss: 0.02146420069038868, acc: 0.9955752491950989)
[2024-12-17 03:10:56,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:56,902][root][INFO] - Training Epoch: 2/2, step 5976/7134 completed (loss: 0.032444920390844345, acc: 0.9892638325691223)
[2024-12-17 03:10:57,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:57,259][root][INFO] - Training Epoch: 2/2, step 5977/7134 completed (loss: 0.030617594718933105, acc: 0.9925650358200073)
[2024-12-17 03:10:57,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:57,608][root][INFO] - Training Epoch: 2/2, step 5978/7134 completed (loss: 0.043637748807668686, acc: 0.9919871687889099)
[2024-12-17 03:10:57,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:57,905][root][INFO] - Training Epoch: 2/2, step 5979/7134 completed (loss: 0.0431162528693676, acc: 0.9851852059364319)
[2024-12-17 03:10:58,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:58,263][root][INFO] - Training Epoch: 2/2, step 5980/7134 completed (loss: 0.03848247602581978, acc: 0.98591548204422)
[2024-12-17 03:10:58,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:58,627][root][INFO] - Training Epoch: 2/2, step 5981/7134 completed (loss: 0.05252057686448097, acc: 0.9861271381378174)
[2024-12-17 03:10:58,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:58,948][root][INFO] - Training Epoch: 2/2, step 5982/7134 completed (loss: 0.029845453798770905, acc: 0.9920477271080017)
[2024-12-17 03:10:59,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:59,284][root][INFO] - Training Epoch: 2/2, step 5983/7134 completed (loss: 0.06691309809684753, acc: 0.980555534362793)
[2024-12-17 03:10:59,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:59,626][root][INFO] - Training Epoch: 2/2, step 5984/7134 completed (loss: 0.028376774862408638, acc: 0.9929078221321106)
[2024-12-17 03:10:59,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:59,984][root][INFO] - Training Epoch: 2/2, step 5985/7134 completed (loss: 0.029362371191382408, acc: 0.9937421679496765)
[2024-12-17 03:11:00,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:00,354][root][INFO] - Training Epoch: 2/2, step 5986/7134 completed (loss: 0.0612109936773777, acc: 0.987261176109314)
[2024-12-17 03:11:00,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:00,713][root][INFO] - Training Epoch: 2/2, step 5987/7134 completed (loss: 0.05803338810801506, acc: 0.9813519716262817)
[2024-12-17 03:11:00,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:01,054][root][INFO] - Training Epoch: 2/2, step 5988/7134 completed (loss: 0.02532719075679779, acc: 0.9946666955947876)
[2024-12-17 03:11:01,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:01,409][root][INFO] - Training Epoch: 2/2, step 5989/7134 completed (loss: 0.04877949506044388, acc: 0.9870848655700684)
[2024-12-17 03:11:01,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:01,782][root][INFO] - Training Epoch: 2/2, step 5990/7134 completed (loss: 0.042510926723480225, acc: 0.9849315285682678)
[2024-12-17 03:11:01,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:02,005][root][INFO] - Training Epoch: 2/2, step 5991/7134 completed (loss: 0.09883759170770645, acc: 0.9748603105545044)
[2024-12-17 03:11:02,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:02,387][root][INFO] - Training Epoch: 2/2, step 5992/7134 completed (loss: 0.049718353897333145, acc: 0.9860627055168152)
[2024-12-17 03:11:02,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:02,719][root][INFO] - Training Epoch: 2/2, step 5993/7134 completed (loss: 0.03283701092004776, acc: 0.9902912378311157)
[2024-12-17 03:11:02,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:03,064][root][INFO] - Training Epoch: 2/2, step 5994/7134 completed (loss: 0.01280149631202221, acc: 0.9980988502502441)
[2024-12-17 03:11:03,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:03,424][root][INFO] - Training Epoch: 2/2, step 5995/7134 completed (loss: 0.03682561218738556, acc: 0.9943661689758301)
[2024-12-17 03:11:03,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:03,774][root][INFO] - Training Epoch: 2/2, step 5996/7134 completed (loss: 0.07403437048196793, acc: 0.9796556830406189)
[2024-12-17 03:11:03,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:04,128][root][INFO] - Training Epoch: 2/2, step 5997/7134 completed (loss: 0.03447525575757027, acc: 0.9906542301177979)
[2024-12-17 03:11:04,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:04,488][root][INFO] - Training Epoch: 2/2, step 5998/7134 completed (loss: 0.03223065286874771, acc: 0.9887780547142029)
[2024-12-17 03:11:04,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:04,822][root][INFO] - Training Epoch: 2/2, step 5999/7134 completed (loss: 0.039674703031778336, acc: 0.9913259148597717)
[2024-12-17 03:11:04,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:05,134][root][INFO] - Training Epoch: 2/2, step 6000/7134 completed (loss: 0.04199134185910225, acc: 0.9883527159690857)
[2024-12-17 03:11:05,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:05,485][root][INFO] - Training Epoch: 2/2, step 6001/7134 completed (loss: 0.025424323976039886, acc: 0.9936061501502991)
[2024-12-17 03:11:05,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:05,812][root][INFO] - Training Epoch: 2/2, step 6002/7134 completed (loss: 0.06786589324474335, acc: 0.9785575270652771)
[2024-12-17 03:11:05,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:06,190][root][INFO] - Training Epoch: 2/2, step 6003/7134 completed (loss: 0.04163911193609238, acc: 0.9838472604751587)
[2024-12-17 03:11:06,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:06,528][root][INFO] - Training Epoch: 2/2, step 6004/7134 completed (loss: 0.032030023634433746, acc: 0.9888734221458435)
[2024-12-17 03:11:06,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:06,848][root][INFO] - Training Epoch: 2/2, step 6005/7134 completed (loss: 0.04295376315712929, acc: 0.9893454909324646)
[2024-12-17 03:11:06,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:07,178][root][INFO] - Training Epoch: 2/2, step 6006/7134 completed (loss: 0.0517788790166378, acc: 0.9864603281021118)
[2024-12-17 03:11:07,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:07,536][root][INFO] - Training Epoch: 2/2, step 6007/7134 completed (loss: 0.032569896429777145, acc: 0.9916527271270752)
[2024-12-17 03:11:07,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:07,895][root][INFO] - Training Epoch: 2/2, step 6008/7134 completed (loss: 0.039047107100486755, acc: 0.9910979270935059)
[2024-12-17 03:11:08,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:08,224][root][INFO] - Training Epoch: 2/2, step 6009/7134 completed (loss: 0.052045952528715134, acc: 0.9875776171684265)
[2024-12-17 03:11:08,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:08,576][root][INFO] - Training Epoch: 2/2, step 6010/7134 completed (loss: 0.06403522193431854, acc: 0.9837398529052734)
[2024-12-17 03:11:08,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:08,934][root][INFO] - Training Epoch: 2/2, step 6011/7134 completed (loss: 0.05488607659935951, acc: 0.9831606149673462)
[2024-12-17 03:11:09,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:09,276][root][INFO] - Training Epoch: 2/2, step 6012/7134 completed (loss: 0.05364786833524704, acc: 0.9805970191955566)
[2024-12-17 03:11:09,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:09,638][root][INFO] - Training Epoch: 2/2, step 6013/7134 completed (loss: 0.05369872227311134, acc: 0.9826202988624573)
[2024-12-17 03:11:09,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:09,966][root][INFO] - Training Epoch: 2/2, step 6014/7134 completed (loss: 0.02727224864065647, acc: 0.9872958064079285)
[2024-12-17 03:11:10,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:10,316][root][INFO] - Training Epoch: 2/2, step 6015/7134 completed (loss: 0.07352902740240097, acc: 0.9793388247489929)
[2024-12-17 03:11:10,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:10,636][root][INFO] - Training Epoch: 2/2, step 6016/7134 completed (loss: 0.018160665407776833, acc: 0.9928315281867981)
[2024-12-17 03:11:10,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:10,852][root][INFO] - Training Epoch: 2/2, step 6017/7134 completed (loss: 0.06796238571405411, acc: 0.9851484894752502)
[2024-12-17 03:11:10,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:11,126][root][INFO] - Training Epoch: 2/2, step 6018/7134 completed (loss: 0.012912265956401825, acc: 1.0)
[2024-12-17 03:11:11,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:11,358][root][INFO] - Training Epoch: 2/2, step 6019/7134 completed (loss: 0.03819815814495087, acc: 0.9913793206214905)
[2024-12-17 03:11:11,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:11,646][root][INFO] - Training Epoch: 2/2, step 6020/7134 completed (loss: 0.006790798157453537, acc: 1.0)
[2024-12-17 03:11:11,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:11,920][root][INFO] - Training Epoch: 2/2, step 6021/7134 completed (loss: 0.010095267556607723, acc: 1.0)
[2024-12-17 03:11:12,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:12,221][root][INFO] - Training Epoch: 2/2, step 6022/7134 completed (loss: 0.04150417447090149, acc: 0.9852398633956909)
[2024-12-17 03:11:12,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:12,498][root][INFO] - Training Epoch: 2/2, step 6023/7134 completed (loss: 0.023059289902448654, acc: 0.9972899556159973)
[2024-12-17 03:11:12,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:12,752][root][INFO] - Training Epoch: 2/2, step 6024/7134 completed (loss: 0.017719218507409096, acc: 0.9953488111495972)
[2024-12-17 03:11:12,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:13,060][root][INFO] - Training Epoch: 2/2, step 6025/7134 completed (loss: 0.009692855179309845, acc: 0.9979079365730286)
[2024-12-17 03:11:13,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:13,277][root][INFO] - Training Epoch: 2/2, step 6026/7134 completed (loss: 0.019537191838026047, acc: 0.9942857027053833)
[2024-12-17 03:11:13,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:13,547][root][INFO] - Training Epoch: 2/2, step 6027/7134 completed (loss: 0.03145204111933708, acc: 0.9974293112754822)
[2024-12-17 03:11:13,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:13,805][root][INFO] - Training Epoch: 2/2, step 6028/7134 completed (loss: 0.007409009616822004, acc: 1.0)
[2024-12-17 03:11:13,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:14,083][root][INFO] - Training Epoch: 2/2, step 6029/7134 completed (loss: 0.05504196509718895, acc: 0.9891696572303772)
[2024-12-17 03:11:14,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:14,357][root][INFO] - Training Epoch: 2/2, step 6030/7134 completed (loss: 0.04922502487897873, acc: 0.992337167263031)
[2024-12-17 03:11:14,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:14,671][root][INFO] - Training Epoch: 2/2, step 6031/7134 completed (loss: 0.023915397003293037, acc: 0.9941520690917969)
[2024-12-17 03:11:14,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:14,948][root][INFO] - Training Epoch: 2/2, step 6032/7134 completed (loss: 0.027366003021597862, acc: 0.9924050569534302)
[2024-12-17 03:11:15,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:15,235][root][INFO] - Training Epoch: 2/2, step 6033/7134 completed (loss: 0.06567157059907913, acc: 0.9754098653793335)
[2024-12-17 03:11:15,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:15,455][root][INFO] - Training Epoch: 2/2, step 6034/7134 completed (loss: 0.055676210671663284, acc: 0.9877049326896667)
[2024-12-17 03:11:15,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:15,835][root][INFO] - Training Epoch: 2/2, step 6035/7134 completed (loss: 0.08244934678077698, acc: 0.9789473414421082)
[2024-12-17 03:11:15,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:16,211][root][INFO] - Training Epoch: 2/2, step 6036/7134 completed (loss: 0.07812301069498062, acc: 0.9720279574394226)
[2024-12-17 03:11:16,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:16,556][root][INFO] - Training Epoch: 2/2, step 6037/7134 completed (loss: 0.04200148582458496, acc: 0.9847457408905029)
[2024-12-17 03:11:16,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:16,929][root][INFO] - Training Epoch: 2/2, step 6038/7134 completed (loss: 0.03851846978068352, acc: 0.9876957535743713)
[2024-12-17 03:11:17,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:17,289][root][INFO] - Training Epoch: 2/2, step 6039/7134 completed (loss: 0.04250847548246384, acc: 0.9869513511657715)
[2024-12-17 03:11:17,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:17,653][root][INFO] - Training Epoch: 2/2, step 6040/7134 completed (loss: 0.0636104941368103, acc: 0.9844074845314026)
[2024-12-17 03:11:17,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:17,983][root][INFO] - Training Epoch: 2/2, step 6041/7134 completed (loss: 0.046521302312612534, acc: 0.9855832457542419)
[2024-12-17 03:11:18,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:18,338][root][INFO] - Training Epoch: 2/2, step 6042/7134 completed (loss: 0.02742961049079895, acc: 0.9919999837875366)
[2024-12-17 03:11:18,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:18,689][root][INFO] - Training Epoch: 2/2, step 6043/7134 completed (loss: 0.05284740403294563, acc: 0.9904076457023621)
[2024-12-17 03:11:18,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:19,047][root][INFO] - Training Epoch: 2/2, step 6044/7134 completed (loss: 0.06064493581652641, acc: 0.980246901512146)
[2024-12-17 03:11:19,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:19,384][root][INFO] - Training Epoch: 2/2, step 6045/7134 completed (loss: 0.03477732837200165, acc: 0.9869822263717651)
[2024-12-17 03:11:19,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:19,738][root][INFO] - Training Epoch: 2/2, step 6046/7134 completed (loss: 0.05938424542546272, acc: 0.9809358716011047)
[2024-12-17 03:11:19,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:20,111][root][INFO] - Training Epoch: 2/2, step 6047/7134 completed (loss: 0.11806399375200272, acc: 0.9780775904655457)
[2024-12-17 03:11:20,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:20,457][root][INFO] - Training Epoch: 2/2, step 6048/7134 completed (loss: 0.0873270183801651, acc: 0.9779559373855591)
[2024-12-17 03:11:20,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:20,768][root][INFO] - Training Epoch: 2/2, step 6049/7134 completed (loss: 0.02426323853433132, acc: 0.9931740760803223)
[2024-12-17 03:11:20,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:21,089][root][INFO] - Training Epoch: 2/2, step 6050/7134 completed (loss: 0.0812995433807373, acc: 0.9822161197662354)
[2024-12-17 03:11:21,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:21,455][root][INFO] - Training Epoch: 2/2, step 6051/7134 completed (loss: 0.1085851714015007, acc: 0.9675036668777466)
[2024-12-17 03:11:21,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:21,819][root][INFO] - Training Epoch: 2/2, step 6052/7134 completed (loss: 0.08898365497589111, acc: 0.971742570400238)
[2024-12-17 03:11:21,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:22,185][root][INFO] - Training Epoch: 2/2, step 6053/7134 completed (loss: 0.05062984302639961, acc: 0.984649121761322)
[2024-12-17 03:11:22,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:22,538][root][INFO] - Training Epoch: 2/2, step 6054/7134 completed (loss: 0.05164606124162674, acc: 0.9830917716026306)
[2024-12-17 03:11:22,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:22,871][root][INFO] - Training Epoch: 2/2, step 6055/7134 completed (loss: 0.04313221201300621, acc: 0.9889415502548218)
[2024-12-17 03:11:22,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:23,173][root][INFO] - Training Epoch: 2/2, step 6056/7134 completed (loss: 0.06270015239715576, acc: 0.9769585132598877)
[2024-12-17 03:11:23,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:23,469][root][INFO] - Training Epoch: 2/2, step 6057/7134 completed (loss: 0.029729997739195824, acc: 0.9901315569877625)
[2024-12-17 03:11:23,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:23,753][root][INFO] - Training Epoch: 2/2, step 6058/7134 completed (loss: 0.014302524738013744, acc: 0.9954954981803894)
[2024-12-17 03:11:23,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:24,032][root][INFO] - Training Epoch: 2/2, step 6059/7134 completed (loss: 0.022089987993240356, acc: 0.9929328560829163)
[2024-12-17 03:11:24,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:24,382][root][INFO] - Training Epoch: 2/2, step 6060/7134 completed (loss: 0.03376268222928047, acc: 0.9864661693572998)
[2024-12-17 03:11:24,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:24,700][root][INFO] - Training Epoch: 2/2, step 6061/7134 completed (loss: 0.07139360159635544, acc: 0.9845916628837585)
[2024-12-17 03:11:24,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:25,047][root][INFO] - Training Epoch: 2/2, step 6062/7134 completed (loss: 0.06819401681423187, acc: 0.9793281555175781)
[2024-12-17 03:11:25,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:25,368][root][INFO] - Training Epoch: 2/2, step 6063/7134 completed (loss: 0.0965457633137703, acc: 0.9801084995269775)
[2024-12-17 03:11:25,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:25,714][root][INFO] - Training Epoch: 2/2, step 6064/7134 completed (loss: 0.04332443326711655, acc: 0.9855282306671143)
[2024-12-17 03:11:25,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:26,074][root][INFO] - Training Epoch: 2/2, step 6065/7134 completed (loss: 0.05800457298755646, acc: 0.9854192137718201)
[2024-12-17 03:11:26,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:26,409][root][INFO] - Training Epoch: 2/2, step 6066/7134 completed (loss: 0.07813285291194916, acc: 0.9818781018257141)
[2024-12-17 03:11:26,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:26,739][root][INFO] - Training Epoch: 2/2, step 6067/7134 completed (loss: 0.07367096096277237, acc: 0.9841269850730896)
[2024-12-17 03:11:26,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:27,160][root][INFO] - Training Epoch: 2/2, step 6068/7134 completed (loss: 0.10861793160438538, acc: 0.9674593210220337)
[2024-12-17 03:11:27,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:27,499][root][INFO] - Training Epoch: 2/2, step 6069/7134 completed (loss: 0.07480867207050323, acc: 0.9810218811035156)
[2024-12-17 03:11:27,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:27,863][root][INFO] - Training Epoch: 2/2, step 6070/7134 completed (loss: 0.07911746948957443, acc: 0.974700391292572)
[2024-12-17 03:11:27,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:28,194][root][INFO] - Training Epoch: 2/2, step 6071/7134 completed (loss: 0.05465579032897949, acc: 0.9865410327911377)
[2024-12-17 03:11:28,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:28,454][root][INFO] - Training Epoch: 2/2, step 6072/7134 completed (loss: 0.10441065579652786, acc: 0.9684873819351196)
[2024-12-17 03:11:28,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:28,784][root][INFO] - Training Epoch: 2/2, step 6073/7134 completed (loss: 0.08315937966108322, acc: 0.9790209531784058)
[2024-12-17 03:11:28,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:29,114][root][INFO] - Training Epoch: 2/2, step 6074/7134 completed (loss: 0.09325235337018967, acc: 0.979411780834198)
[2024-12-17 03:11:29,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:29,467][root][INFO] - Training Epoch: 2/2, step 6075/7134 completed (loss: 0.0599784217774868, acc: 0.9856114983558655)
[2024-12-17 03:11:29,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:29,803][root][INFO] - Training Epoch: 2/2, step 6076/7134 completed (loss: 0.1236492469906807, acc: 0.9755747318267822)
[2024-12-17 03:11:29,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:30,134][root][INFO] - Training Epoch: 2/2, step 6077/7134 completed (loss: 0.05208543315529823, acc: 0.9808306694030762)
[2024-12-17 03:11:30,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:30,467][root][INFO] - Training Epoch: 2/2, step 6078/7134 completed (loss: 0.08468339592218399, acc: 0.9760563373565674)
[2024-12-17 03:11:30,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:30,826][root][INFO] - Training Epoch: 2/2, step 6079/7134 completed (loss: 0.02895629219710827, acc: 0.9908758997917175)
[2024-12-17 03:11:30,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:31,145][root][INFO] - Training Epoch: 2/2, step 6080/7134 completed (loss: 0.045224063098430634, acc: 0.985855758190155)
[2024-12-17 03:11:31,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:31,482][root][INFO] - Training Epoch: 2/2, step 6081/7134 completed (loss: 0.04371031001210213, acc: 0.981679379940033)
[2024-12-17 03:11:31,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:31,805][root][INFO] - Training Epoch: 2/2, step 6082/7134 completed (loss: 0.03870757669210434, acc: 0.993630588054657)
[2024-12-17 03:11:31,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:32,163][root][INFO] - Training Epoch: 2/2, step 6083/7134 completed (loss: 0.020404573529958725, acc: 0.9938575029373169)
[2024-12-17 03:11:32,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:32,478][root][INFO] - Training Epoch: 2/2, step 6084/7134 completed (loss: 0.07457657903432846, acc: 0.9842767119407654)
[2024-12-17 03:11:32,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:32,834][root][INFO] - Training Epoch: 2/2, step 6085/7134 completed (loss: 0.048031724989414215, acc: 0.9838998317718506)
[2024-12-17 03:11:32,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:33,210][root][INFO] - Training Epoch: 2/2, step 6086/7134 completed (loss: 0.04121794179081917, acc: 0.9887640476226807)
[2024-12-17 03:11:33,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:33,576][root][INFO] - Training Epoch: 2/2, step 6087/7134 completed (loss: 0.08137275278568268, acc: 0.9761006236076355)
[2024-12-17 03:11:33,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:33,900][root][INFO] - Training Epoch: 2/2, step 6088/7134 completed (loss: 0.03721875697374344, acc: 0.9879356622695923)
[2024-12-17 03:11:34,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:34,269][root][INFO] - Training Epoch: 2/2, step 6089/7134 completed (loss: 0.047104671597480774, acc: 0.9834482669830322)
[2024-12-17 03:11:34,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:34,620][root][INFO] - Training Epoch: 2/2, step 6090/7134 completed (loss: 0.03149506077170372, acc: 0.9903978109359741)
[2024-12-17 03:11:34,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:34,941][root][INFO] - Training Epoch: 2/2, step 6091/7134 completed (loss: 0.06219037249684334, acc: 0.9856687784194946)
[2024-12-17 03:11:35,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:35,259][root][INFO] - Training Epoch: 2/2, step 6092/7134 completed (loss: 0.036626070737838745, acc: 0.9936507940292358)
[2024-12-17 03:11:35,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:35,583][root][INFO] - Training Epoch: 2/2, step 6093/7134 completed (loss: 0.05262339487671852, acc: 0.9814471006393433)
[2024-12-17 03:11:35,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:35,906][root][INFO] - Training Epoch: 2/2, step 6094/7134 completed (loss: 0.037547070533037186, acc: 0.9901960492134094)
[2024-12-17 03:11:36,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:36,210][root][INFO] - Training Epoch: 2/2, step 6095/7134 completed (loss: 0.02982817031443119, acc: 0.9913793206214905)
[2024-12-17 03:11:36,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:36,571][root][INFO] - Training Epoch: 2/2, step 6096/7134 completed (loss: 0.05814534053206444, acc: 0.9856801629066467)
[2024-12-17 03:11:36,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:36,905][root][INFO] - Training Epoch: 2/2, step 6097/7134 completed (loss: 0.04486456513404846, acc: 0.9875346422195435)
[2024-12-17 03:11:37,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:37,240][root][INFO] - Training Epoch: 2/2, step 6098/7134 completed (loss: 0.08275941014289856, acc: 0.9806950092315674)
[2024-12-17 03:11:37,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:37,587][root][INFO] - Training Epoch: 2/2, step 6099/7134 completed (loss: 0.06028320640325546, acc: 0.9862385392189026)
[2024-12-17 03:11:37,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:37,832][root][INFO] - Training Epoch: 2/2, step 6100/7134 completed (loss: 0.08968361467123032, acc: 0.9817073345184326)
[2024-12-17 03:11:37,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:38,137][root][INFO] - Training Epoch: 2/2, step 6101/7134 completed (loss: 0.020630700513720512, acc: 0.9936102032661438)
[2024-12-17 03:11:38,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:38,451][root][INFO] - Training Epoch: 2/2, step 6102/7134 completed (loss: 0.07345893979072571, acc: 0.98591548204422)
[2024-12-17 03:11:38,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:38,789][root][INFO] - Training Epoch: 2/2, step 6103/7134 completed (loss: 0.030405111610889435, acc: 0.9870370626449585)
[2024-12-17 03:11:38,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:39,107][root][INFO] - Training Epoch: 2/2, step 6104/7134 completed (loss: 0.07607799023389816, acc: 0.9777777791023254)
[2024-12-17 03:11:39,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:39,449][root][INFO] - Training Epoch: 2/2, step 6105/7134 completed (loss: 0.08450345695018768, acc: 0.9776785969734192)
[2024-12-17 03:11:39,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:39,718][root][INFO] - Training Epoch: 2/2, step 6106/7134 completed (loss: 0.05846688896417618, acc: 0.9838998317718506)
[2024-12-17 03:11:39,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:40,041][root][INFO] - Training Epoch: 2/2, step 6107/7134 completed (loss: 0.06683170050382614, acc: 0.9852941036224365)
[2024-12-17 03:11:40,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:40,359][root][INFO] - Training Epoch: 2/2, step 6108/7134 completed (loss: 0.05616694688796997, acc: 0.9836065769195557)
[2024-12-17 03:11:40,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:40,660][root][INFO] - Training Epoch: 2/2, step 6109/7134 completed (loss: 0.028734436258673668, acc: 0.9872881174087524)
[2024-12-17 03:11:40,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:40,997][root][INFO] - Training Epoch: 2/2, step 6110/7134 completed (loss: 0.11773631721735, acc: 0.9700854420661926)
[2024-12-17 03:11:41,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:41,313][root][INFO] - Training Epoch: 2/2, step 6111/7134 completed (loss: 0.08340395987033844, acc: 0.9758713245391846)
[2024-12-17 03:11:41,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:41,642][root][INFO] - Training Epoch: 2/2, step 6112/7134 completed (loss: 0.04797477647662163, acc: 0.9849498271942139)
[2024-12-17 03:11:41,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:41,976][root][INFO] - Training Epoch: 2/2, step 6113/7134 completed (loss: 0.028995012864470482, acc: 0.9893778562545776)
[2024-12-17 03:11:42,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:42,293][root][INFO] - Training Epoch: 2/2, step 6114/7134 completed (loss: 0.08682194352149963, acc: 0.9752066135406494)
[2024-12-17 03:11:42,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:42,595][root][INFO] - Training Epoch: 2/2, step 6115/7134 completed (loss: 0.05578728765249252, acc: 0.99042147397995)
[2024-12-17 03:11:42,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:42,861][root][INFO] - Training Epoch: 2/2, step 6116/7134 completed (loss: 0.09068197011947632, acc: 0.9822134375572205)
[2024-12-17 03:11:43,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:43,214][root][INFO] - Training Epoch: 2/2, step 6117/7134 completed (loss: 0.09699694067239761, acc: 0.9754098653793335)
[2024-12-17 03:11:43,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:43,592][root][INFO] - Training Epoch: 2/2, step 6118/7134 completed (loss: 0.10823596268892288, acc: 0.970588207244873)
[2024-12-17 03:11:43,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:43,948][root][INFO] - Training Epoch: 2/2, step 6119/7134 completed (loss: 0.059986911714076996, acc: 0.981992781162262)
[2024-12-17 03:11:44,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:44,292][root][INFO] - Training Epoch: 2/2, step 6120/7134 completed (loss: 0.04655352234840393, acc: 0.989266574382782)
[2024-12-17 03:11:44,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:44,646][root][INFO] - Training Epoch: 2/2, step 6121/7134 completed (loss: 0.08123178035020828, acc: 0.9748201370239258)
[2024-12-17 03:11:44,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:44,995][root][INFO] - Training Epoch: 2/2, step 6122/7134 completed (loss: 0.06342549622058868, acc: 0.9792453050613403)
[2024-12-17 03:11:45,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:45,325][root][INFO] - Training Epoch: 2/2, step 6123/7134 completed (loss: 0.10009034723043442, acc: 0.9771309494972229)
[2024-12-17 03:11:45,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:45,640][root][INFO] - Training Epoch: 2/2, step 6124/7134 completed (loss: 0.028442349284887314, acc: 0.9923076629638672)
[2024-12-17 03:11:45,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:46,003][root][INFO] - Training Epoch: 2/2, step 6125/7134 completed (loss: 0.14716961979866028, acc: 0.9759036302566528)
[2024-12-17 03:11:46,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:46,332][root][INFO] - Training Epoch: 2/2, step 6126/7134 completed (loss: 0.07966702431440353, acc: 0.9811912178993225)
[2024-12-17 03:11:46,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:46,600][root][INFO] - Training Epoch: 2/2, step 6127/7134 completed (loss: 0.0314505361020565, acc: 0.9857142567634583)
[2024-12-17 03:11:46,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:46,922][root][INFO] - Training Epoch: 2/2, step 6128/7134 completed (loss: 0.03584582731127739, acc: 0.9898785352706909)
[2024-12-17 03:11:47,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:47,261][root][INFO] - Training Epoch: 2/2, step 6129/7134 completed (loss: 0.07651732116937637, acc: 0.9760900139808655)
[2024-12-17 03:11:47,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:47,579][root][INFO] - Training Epoch: 2/2, step 6130/7134 completed (loss: 0.03112424537539482, acc: 0.9874551892280579)
[2024-12-17 03:11:47,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:47,948][root][INFO] - Training Epoch: 2/2, step 6131/7134 completed (loss: 0.059396013617515564, acc: 0.9856287240982056)
[2024-12-17 03:11:48,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:48,280][root][INFO] - Training Epoch: 2/2, step 6132/7134 completed (loss: 0.049405939877033234, acc: 0.989062488079071)
[2024-12-17 03:11:48,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:48,652][root][INFO] - Training Epoch: 2/2, step 6133/7134 completed (loss: 0.04937132075428963, acc: 0.9890776872634888)
[2024-12-17 03:11:48,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:48,967][root][INFO] - Training Epoch: 2/2, step 6134/7134 completed (loss: 0.09197080135345459, acc: 0.9739663004875183)
[2024-12-17 03:11:49,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:49,318][root][INFO] - Training Epoch: 2/2, step 6135/7134 completed (loss: 0.02362692542374134, acc: 0.9947735071182251)
[2024-12-17 03:11:49,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:49,646][root][INFO] - Training Epoch: 2/2, step 6136/7134 completed (loss: 0.06361924111843109, acc: 0.9873949289321899)
[2024-12-17 03:11:49,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:49,961][root][INFO] - Training Epoch: 2/2, step 6137/7134 completed (loss: 0.09507030993700027, acc: 0.9828392863273621)
[2024-12-17 03:11:50,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:50,277][root][INFO] - Training Epoch: 2/2, step 6138/7134 completed (loss: 0.06791768223047256, acc: 0.9831029176712036)
[2024-12-17 03:11:50,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:50,587][root][INFO] - Training Epoch: 2/2, step 6139/7134 completed (loss: 0.08545425534248352, acc: 0.9740740656852722)
[2024-12-17 03:11:50,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:50,962][root][INFO] - Training Epoch: 2/2, step 6140/7134 completed (loss: 0.040836501866579056, acc: 0.9911660552024841)
[2024-12-17 03:11:51,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:51,202][root][INFO] - Training Epoch: 2/2, step 6141/7134 completed (loss: 0.08100870996713638, acc: 0.9908257126808167)
[2024-12-17 03:11:51,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:51,537][root][INFO] - Training Epoch: 2/2, step 6142/7134 completed (loss: 0.03921417519450188, acc: 0.9856114983558655)
[2024-12-17 03:11:51,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:51,881][root][INFO] - Training Epoch: 2/2, step 6143/7134 completed (loss: 0.03196500986814499, acc: 0.9932432174682617)
[2024-12-17 03:11:51,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:52,199][root][INFO] - Training Epoch: 2/2, step 6144/7134 completed (loss: 0.0354691818356514, acc: 0.9865546226501465)
[2024-12-17 03:11:52,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:52,553][root][INFO] - Training Epoch: 2/2, step 6145/7134 completed (loss: 0.0934768095612526, acc: 0.9788639545440674)
[2024-12-17 03:11:52,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:52,865][root][INFO] - Training Epoch: 2/2, step 6146/7134 completed (loss: 0.08191988617181778, acc: 0.9773755669593811)
[2024-12-17 03:11:52,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:53,183][root][INFO] - Training Epoch: 2/2, step 6147/7134 completed (loss: 0.05852257087826729, acc: 0.9861111044883728)
[2024-12-17 03:11:53,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:53,538][root][INFO] - Training Epoch: 2/2, step 6148/7134 completed (loss: 0.058713361620903015, acc: 0.9832496047019958)
[2024-12-17 03:11:53,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:53,864][root][INFO] - Training Epoch: 2/2, step 6149/7134 completed (loss: 0.050670355558395386, acc: 0.9823151230812073)
[2024-12-17 03:11:53,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:54,195][root][INFO] - Training Epoch: 2/2, step 6150/7134 completed (loss: 0.051081642508506775, acc: 0.9894737005233765)
[2024-12-17 03:11:54,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:54,494][root][INFO] - Training Epoch: 2/2, step 6151/7134 completed (loss: 0.0248983483761549, acc: 0.9905808568000793)
[2024-12-17 03:11:54,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:54,830][root][INFO] - Training Epoch: 2/2, step 6152/7134 completed (loss: 0.04563210904598236, acc: 0.9849170446395874)
[2024-12-17 03:11:54,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:55,181][root][INFO] - Training Epoch: 2/2, step 6153/7134 completed (loss: 0.026813076809048653, acc: 0.9942113161087036)
[2024-12-17 03:11:55,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:55,535][root][INFO] - Training Epoch: 2/2, step 6154/7134 completed (loss: 0.045399684458971024, acc: 0.9860529899597168)
[2024-12-17 03:11:55,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:55,880][root][INFO] - Training Epoch: 2/2, step 6155/7134 completed (loss: 0.06241462379693985, acc: 0.9821958541870117)
[2024-12-17 03:11:55,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:56,188][root][INFO] - Training Epoch: 2/2, step 6156/7134 completed (loss: 0.04949798434972763, acc: 0.9873217344284058)
[2024-12-17 03:11:56,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:56,528][root][INFO] - Training Epoch: 2/2, step 6157/7134 completed (loss: 0.04158473014831543, acc: 0.9843260049819946)
[2024-12-17 03:11:56,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:56,867][root][INFO] - Training Epoch: 2/2, step 6158/7134 completed (loss: 0.07359645515680313, acc: 0.9891501069068909)
[2024-12-17 03:11:56,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:57,225][root][INFO] - Training Epoch: 2/2, step 6159/7134 completed (loss: 0.07791204750537872, acc: 0.9746682643890381)
[2024-12-17 03:11:57,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:57,560][root][INFO] - Training Epoch: 2/2, step 6160/7134 completed (loss: 0.07692517340183258, acc: 0.9848484992980957)
[2024-12-17 03:11:57,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:57,916][root][INFO] - Training Epoch: 2/2, step 6161/7134 completed (loss: 0.078029565513134, acc: 0.982425332069397)
[2024-12-17 03:11:58,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:58,263][root][INFO] - Training Epoch: 2/2, step 6162/7134 completed (loss: 0.0668654665350914, acc: 0.9869067072868347)
[2024-12-17 03:11:58,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:58,592][root][INFO] - Training Epoch: 2/2, step 6163/7134 completed (loss: 0.08476904779672623, acc: 0.9821428656578064)
[2024-12-17 03:11:58,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:58,945][root][INFO] - Training Epoch: 2/2, step 6164/7134 completed (loss: 0.1118888407945633, acc: 0.9674220681190491)
[2024-12-17 03:11:59,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:59,251][root][INFO] - Training Epoch: 2/2, step 6165/7134 completed (loss: 0.07112705707550049, acc: 0.9797047972679138)
[2024-12-17 03:11:59,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:59,572][root][INFO] - Training Epoch: 2/2, step 6166/7134 completed (loss: 0.03632711246609688, acc: 0.9841827750205994)
[2024-12-17 03:11:59,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:59,894][root][INFO] - Training Epoch: 2/2, step 6167/7134 completed (loss: 0.037634026259183884, acc: 0.9915134310722351)
[2024-12-17 03:11:59,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:00,242][root][INFO] - Training Epoch: 2/2, step 6168/7134 completed (loss: 0.04421146586537361, acc: 0.9832689762115479)
[2024-12-17 03:12:00,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:00,555][root][INFO] - Training Epoch: 2/2, step 6169/7134 completed (loss: 0.060968734323978424, acc: 0.9883381724357605)
[2024-12-17 03:12:00,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:00,864][root][INFO] - Training Epoch: 2/2, step 6170/7134 completed (loss: 0.040299542248249054, acc: 0.9886578321456909)
[2024-12-17 03:12:00,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:01,199][root][INFO] - Training Epoch: 2/2, step 6171/7134 completed (loss: 0.01835043355822563, acc: 0.9921156167984009)
[2024-12-17 03:12:01,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:01,498][root][INFO] - Training Epoch: 2/2, step 6172/7134 completed (loss: 0.039745964109897614, acc: 0.9839679598808289)
[2024-12-17 03:12:01,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:01,815][root][INFO] - Training Epoch: 2/2, step 6173/7134 completed (loss: 0.017117958515882492, acc: 0.9926362037658691)
[2024-12-17 03:12:01,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:02,147][root][INFO] - Training Epoch: 2/2, step 6174/7134 completed (loss: 0.025320539250969887, acc: 0.9941349029541016)
[2024-12-17 03:12:02,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:02,489][root][INFO] - Training Epoch: 2/2, step 6175/7134 completed (loss: 0.047987863421440125, acc: 0.9866864085197449)
[2024-12-17 03:12:02,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:02,802][root][INFO] - Training Epoch: 2/2, step 6176/7134 completed (loss: 0.038878876715898514, acc: 0.9913169145584106)
[2024-12-17 03:12:02,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:03,135][root][INFO] - Training Epoch: 2/2, step 6177/7134 completed (loss: 0.031791944056749344, acc: 0.9936061501502991)
[2024-12-17 03:12:03,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:03,471][root][INFO] - Training Epoch: 2/2, step 6178/7134 completed (loss: 0.02244039624929428, acc: 0.99262535572052)
[2024-12-17 03:12:03,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:03,798][root][INFO] - Training Epoch: 2/2, step 6179/7134 completed (loss: 0.049883242696523666, acc: 0.9860248565673828)
[2024-12-17 03:12:03,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:04,084][root][INFO] - Training Epoch: 2/2, step 6180/7134 completed (loss: 0.13760560750961304, acc: 0.9458598494529724)
[2024-12-17 03:12:04,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:04,396][root][INFO] - Training Epoch: 2/2, step 6181/7134 completed (loss: 0.23934073746204376, acc: 0.9380165338516235)
[2024-12-17 03:12:04,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:04,728][root][INFO] - Training Epoch: 2/2, step 6182/7134 completed (loss: 0.059732455760240555, acc: 0.9777365326881409)
[2024-12-17 03:12:04,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:05,064][root][INFO] - Training Epoch: 2/2, step 6183/7134 completed (loss: 0.07514812052249908, acc: 0.9816232919692993)
[2024-12-17 03:12:05,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:05,383][root][INFO] - Training Epoch: 2/2, step 6184/7134 completed (loss: 0.12585356831550598, acc: 0.9657257795333862)
[2024-12-17 03:12:05,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:05,710][root][INFO] - Training Epoch: 2/2, step 6185/7134 completed (loss: 0.04856152459979057, acc: 0.9852941036224365)
[2024-12-17 03:12:05,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:06,030][root][INFO] - Training Epoch: 2/2, step 6186/7134 completed (loss: 0.04260196164250374, acc: 0.9860140085220337)
[2024-12-17 03:12:06,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:06,390][root][INFO] - Training Epoch: 2/2, step 6187/7134 completed (loss: 0.030314018949866295, acc: 0.9933862686157227)
[2024-12-17 03:12:06,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:06,737][root][INFO] - Training Epoch: 2/2, step 6188/7134 completed (loss: 0.08635561913251877, acc: 0.9816642999649048)
[2024-12-17 03:12:06,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:07,098][root][INFO] - Training Epoch: 2/2, step 6189/7134 completed (loss: 0.1303219050168991, acc: 0.9653679728507996)
[2024-12-17 03:12:07,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:07,426][root][INFO] - Training Epoch: 2/2, step 6190/7134 completed (loss: 0.13137485086917877, acc: 0.9684385657310486)
[2024-12-17 03:12:07,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:07,780][root][INFO] - Training Epoch: 2/2, step 6191/7134 completed (loss: 0.09126093238592148, acc: 0.9772727489471436)
[2024-12-17 03:12:07,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:08,160][root][INFO] - Training Epoch: 2/2, step 6192/7134 completed (loss: 0.04095933586359024, acc: 0.9871382713317871)
[2024-12-17 03:12:08,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:08,512][root][INFO] - Training Epoch: 2/2, step 6193/7134 completed (loss: 0.0934891402721405, acc: 0.9738406538963318)
[2024-12-17 03:12:08,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:08,854][root][INFO] - Training Epoch: 2/2, step 6194/7134 completed (loss: 0.05826758220791817, acc: 0.9785992503166199)
[2024-12-17 03:12:08,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:09,169][root][INFO] - Training Epoch: 2/2, step 6195/7134 completed (loss: 0.06026385724544525, acc: 0.9856459498405457)
[2024-12-17 03:12:09,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:09,520][root][INFO] - Training Epoch: 2/2, step 6196/7134 completed (loss: 0.04694490507245064, acc: 0.9807162284851074)
[2024-12-17 03:12:09,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:09,869][root][INFO] - Training Epoch: 2/2, step 6197/7134 completed (loss: 0.13295958936214447, acc: 0.9696551561355591)
[2024-12-17 03:12:09,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:10,208][root][INFO] - Training Epoch: 2/2, step 6198/7134 completed (loss: 0.06831026822328568, acc: 0.9854771494865417)
[2024-12-17 03:12:10,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:10,563][root][INFO] - Training Epoch: 2/2, step 6199/7134 completed (loss: 0.07152030616998672, acc: 0.9802784323692322)
[2024-12-17 03:12:10,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:10,909][root][INFO] - Training Epoch: 2/2, step 6200/7134 completed (loss: 0.041893571615219116, acc: 0.9914634227752686)
[2024-12-17 03:12:11,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:11,271][root][INFO] - Training Epoch: 2/2, step 6201/7134 completed (loss: 0.04917578399181366, acc: 0.9843924045562744)
[2024-12-17 03:12:11,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:11,584][root][INFO] - Training Epoch: 2/2, step 6202/7134 completed (loss: 0.04668116569519043, acc: 0.9848155975341797)
[2024-12-17 03:12:11,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:11,945][root][INFO] - Training Epoch: 2/2, step 6203/7134 completed (loss: 0.0609167255461216, acc: 0.983418345451355)
[2024-12-17 03:12:12,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:12,285][root][INFO] - Training Epoch: 2/2, step 6204/7134 completed (loss: 0.038896940648555756, acc: 0.9862475395202637)
[2024-12-17 03:12:12,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:12,613][root][INFO] - Training Epoch: 2/2, step 6205/7134 completed (loss: 0.04209978133440018, acc: 0.9863481521606445)
[2024-12-17 03:12:12,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:12,924][root][INFO] - Training Epoch: 2/2, step 6206/7134 completed (loss: 0.04301004856824875, acc: 0.9855282306671143)
[2024-12-17 03:12:13,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:13,281][root][INFO] - Training Epoch: 2/2, step 6207/7134 completed (loss: 0.1913650929927826, acc: 0.9559412598609924)
[2024-12-17 03:12:13,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:13,621][root][INFO] - Training Epoch: 2/2, step 6208/7134 completed (loss: 0.05566903576254845, acc: 0.9814814925193787)
[2024-12-17 03:12:13,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:13,971][root][INFO] - Training Epoch: 2/2, step 6209/7134 completed (loss: 0.06296132504940033, acc: 0.9754204154014587)
[2024-12-17 03:12:14,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:14,350][root][INFO] - Training Epoch: 2/2, step 6210/7134 completed (loss: 0.07193128764629364, acc: 0.9780219793319702)
[2024-12-17 03:12:14,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:14,706][root][INFO] - Training Epoch: 2/2, step 6211/7134 completed (loss: 0.07840018719434738, acc: 0.9797022938728333)
[2024-12-17 03:12:14,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:15,027][root][INFO] - Training Epoch: 2/2, step 6212/7134 completed (loss: 0.03208569064736366, acc: 0.9947368502616882)
[2024-12-17 03:12:15,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:15,353][root][INFO] - Training Epoch: 2/2, step 6213/7134 completed (loss: 0.02570831961929798, acc: 0.9896050095558167)
[2024-12-17 03:12:15,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:15,715][root][INFO] - Training Epoch: 2/2, step 6214/7134 completed (loss: 0.04651367664337158, acc: 0.9871630072593689)
[2024-12-17 03:12:15,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:16,074][root][INFO] - Training Epoch: 2/2, step 6215/7134 completed (loss: 0.07281412184238434, acc: 0.9804147481918335)
[2024-12-17 03:12:16,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:16,343][root][INFO] - Training Epoch: 2/2, step 6216/7134 completed (loss: 0.04500705748796463, acc: 0.9893617033958435)
[2024-12-17 03:12:16,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:16,692][root][INFO] - Training Epoch: 2/2, step 6217/7134 completed (loss: 0.03732267767190933, acc: 0.9879194498062134)
[2024-12-17 03:12:16,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:17,058][root][INFO] - Training Epoch: 2/2, step 6218/7134 completed (loss: 0.06859610974788666, acc: 0.9817073345184326)
[2024-12-17 03:12:17,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:17,404][root][INFO] - Training Epoch: 2/2, step 6219/7134 completed (loss: 0.04049612954258919, acc: 0.9901546835899353)
[2024-12-17 03:12:17,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:17,723][root][INFO] - Training Epoch: 2/2, step 6220/7134 completed (loss: 0.05448541045188904, acc: 0.9833333492279053)
[2024-12-17 03:12:17,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:18,072][root][INFO] - Training Epoch: 2/2, step 6221/7134 completed (loss: 0.022759737446904182, acc: 0.9929824471473694)
[2024-12-17 03:12:18,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:18,411][root][INFO] - Training Epoch: 2/2, step 6222/7134 completed (loss: 0.05494380742311478, acc: 0.9877049326896667)
[2024-12-17 03:12:18,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:18,759][root][INFO] - Training Epoch: 2/2, step 6223/7134 completed (loss: 0.06906861811876297, acc: 0.9853479862213135)
[2024-12-17 03:12:18,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:19,095][root][INFO] - Training Epoch: 2/2, step 6224/7134 completed (loss: 0.017171012237668037, acc: 0.9956458806991577)
[2024-12-17 03:12:19,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:19,450][root][INFO] - Training Epoch: 2/2, step 6225/7134 completed (loss: 0.039492350071668625, acc: 0.9859693646430969)
[2024-12-17 03:12:19,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:19,775][root][INFO] - Training Epoch: 2/2, step 6226/7134 completed (loss: 0.05855709686875343, acc: 0.9829620122909546)
[2024-12-17 03:12:19,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:20,121][root][INFO] - Training Epoch: 2/2, step 6227/7134 completed (loss: 0.024427048861980438, acc: 0.9906291961669922)
[2024-12-17 03:12:20,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:20,472][root][INFO] - Training Epoch: 2/2, step 6228/7134 completed (loss: 0.040681205689907074, acc: 0.9852579832077026)
[2024-12-17 03:12:20,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:20,824][root][INFO] - Training Epoch: 2/2, step 6229/7134 completed (loss: 0.09379657357931137, acc: 0.9791183471679688)
[2024-12-17 03:12:20,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:21,183][root][INFO] - Training Epoch: 2/2, step 6230/7134 completed (loss: 0.03631214052438736, acc: 0.9887780547142029)
[2024-12-17 03:12:21,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:21,498][root][INFO] - Training Epoch: 2/2, step 6231/7134 completed (loss: 0.02833823673427105, acc: 0.9896640777587891)
[2024-12-17 03:12:21,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:21,863][root][INFO] - Training Epoch: 2/2, step 6232/7134 completed (loss: 0.051667556166648865, acc: 0.9861111044883728)
[2024-12-17 03:12:21,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:22,212][root][INFO] - Training Epoch: 2/2, step 6233/7134 completed (loss: 0.021264739334583282, acc: 0.9932975769042969)
[2024-12-17 03:12:22,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:22,569][root][INFO] - Training Epoch: 2/2, step 6234/7134 completed (loss: 0.08522411435842514, acc: 0.9826202988624573)
[2024-12-17 03:12:22,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:22,894][root][INFO] - Training Epoch: 2/2, step 6235/7134 completed (loss: 0.032222550362348557, acc: 0.9908735156059265)
[2024-12-17 03:12:23,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:23,243][root][INFO] - Training Epoch: 2/2, step 6236/7134 completed (loss: 0.052707068622112274, acc: 0.9822646379470825)
[2024-12-17 03:12:23,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:23,582][root][INFO] - Training Epoch: 2/2, step 6237/7134 completed (loss: 0.0450579933822155, acc: 0.9877675771713257)
[2024-12-17 03:12:23,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:23,899][root][INFO] - Training Epoch: 2/2, step 6238/7134 completed (loss: 0.013096753507852554, acc: 0.9951534867286682)
[2024-12-17 03:12:24,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:24,254][root][INFO] - Training Epoch: 2/2, step 6239/7134 completed (loss: 0.03964861482381821, acc: 0.9904420375823975)
[2024-12-17 03:12:24,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:24,597][root][INFO] - Training Epoch: 2/2, step 6240/7134 completed (loss: 0.012226924300193787, acc: 0.995768666267395)
[2024-12-17 03:12:24,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:24,953][root][INFO] - Training Epoch: 2/2, step 6241/7134 completed (loss: 0.013174018822610378, acc: 0.996835470199585)
[2024-12-17 03:12:25,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:25,285][root][INFO] - Training Epoch: 2/2, step 6242/7134 completed (loss: 0.018943535163998604, acc: 0.9931972622871399)
[2024-12-17 03:12:25,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:25,613][root][INFO] - Training Epoch: 2/2, step 6243/7134 completed (loss: 0.014574561268091202, acc: 0.9968152642250061)
[2024-12-17 03:12:25,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:25,938][root][INFO] - Training Epoch: 2/2, step 6244/7134 completed (loss: 0.02088293433189392, acc: 0.9958847761154175)
[2024-12-17 03:12:26,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:26,268][root][INFO] - Training Epoch: 2/2, step 6245/7134 completed (loss: 0.031670942902565, acc: 0.9904240965843201)
[2024-12-17 03:12:26,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:26,616][root][INFO] - Training Epoch: 2/2, step 6246/7134 completed (loss: 0.027768874540925026, acc: 0.9894598126411438)
[2024-12-17 03:12:26,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:26,982][root][INFO] - Training Epoch: 2/2, step 6247/7134 completed (loss: 0.0481274239718914, acc: 0.9807229042053223)
[2024-12-17 03:12:27,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:27,331][root][INFO] - Training Epoch: 2/2, step 6248/7134 completed (loss: 0.06072290241718292, acc: 0.9813084006309509)
[2024-12-17 03:12:27,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:27,645][root][INFO] - Training Epoch: 2/2, step 6249/7134 completed (loss: 0.008763842284679413, acc: 0.99842768907547)
[2024-12-17 03:12:27,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:27,970][root][INFO] - Training Epoch: 2/2, step 6250/7134 completed (loss: 0.005596846342086792, acc: 0.9982993006706238)
[2024-12-17 03:12:28,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:28,306][root][INFO] - Training Epoch: 2/2, step 6251/7134 completed (loss: 0.015544535592198372, acc: 0.9938650131225586)
[2024-12-17 03:12:28,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:28,654][root][INFO] - Training Epoch: 2/2, step 6252/7134 completed (loss: 0.01731070503592491, acc: 0.9951456189155579)
[2024-12-17 03:12:28,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:28,982][root][INFO] - Training Epoch: 2/2, step 6253/7134 completed (loss: 0.02138073928654194, acc: 0.9948275685310364)
[2024-12-17 03:12:29,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:29,302][root][INFO] - Training Epoch: 2/2, step 6254/7134 completed (loss: 0.023984482511878014, acc: 0.9930796027183533)
[2024-12-17 03:12:29,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:29,647][root][INFO] - Training Epoch: 2/2, step 6255/7134 completed (loss: 0.02422463521361351, acc: 0.9918699264526367)
[2024-12-17 03:12:29,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:29,987][root][INFO] - Training Epoch: 2/2, step 6256/7134 completed (loss: 0.02304440177977085, acc: 0.9929078221321106)
[2024-12-17 03:12:30,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:30,324][root][INFO] - Training Epoch: 2/2, step 6257/7134 completed (loss: 0.030126206576824188, acc: 0.9913669228553772)
[2024-12-17 03:12:30,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:30,649][root][INFO] - Training Epoch: 2/2, step 6258/7134 completed (loss: 0.013160406611859798, acc: 0.9968000054359436)
[2024-12-17 03:12:30,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:31,003][root][INFO] - Training Epoch: 2/2, step 6259/7134 completed (loss: 0.017124516889452934, acc: 0.9939939975738525)
[2024-12-17 03:12:31,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:31,327][root][INFO] - Training Epoch: 2/2, step 6260/7134 completed (loss: 0.018611403182148933, acc: 0.994966447353363)
[2024-12-17 03:12:31,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:31,686][root][INFO] - Training Epoch: 2/2, step 6261/7134 completed (loss: 0.02803635224699974, acc: 0.9923780560493469)
[2024-12-17 03:12:31,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:32,011][root][INFO] - Training Epoch: 2/2, step 6262/7134 completed (loss: 0.008765690959990025, acc: 0.9985652565956116)
[2024-12-17 03:12:32,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:32,330][root][INFO] - Training Epoch: 2/2, step 6263/7134 completed (loss: 0.010182459838688374, acc: 0.9985358715057373)
[2024-12-17 03:12:32,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:32,661][root][INFO] - Training Epoch: 2/2, step 6264/7134 completed (loss: 0.011946350336074829, acc: 0.9967159032821655)
[2024-12-17 03:12:32,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:33,008][root][INFO] - Training Epoch: 2/2, step 6265/7134 completed (loss: 0.018341992050409317, acc: 0.9955621361732483)
[2024-12-17 03:12:33,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:33,330][root][INFO] - Training Epoch: 2/2, step 6266/7134 completed (loss: 0.007631843909621239, acc: 0.998251736164093)
[2024-12-17 03:12:33,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:33,662][root][INFO] - Training Epoch: 2/2, step 6267/7134 completed (loss: 0.0173202995210886, acc: 0.9967426657676697)
[2024-12-17 03:12:33,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:34,010][root][INFO] - Training Epoch: 2/2, step 6268/7134 completed (loss: 0.03188537806272507, acc: 0.9940476417541504)
[2024-12-17 03:12:34,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:34,340][root][INFO] - Training Epoch: 2/2, step 6269/7134 completed (loss: 0.019944099709391594, acc: 0.9957355856895447)
[2024-12-17 03:12:34,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:34,684][root][INFO] - Training Epoch: 2/2, step 6270/7134 completed (loss: 0.009077166207134724, acc: 0.9969325065612793)
[2024-12-17 03:12:34,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:35,023][root][INFO] - Training Epoch: 2/2, step 6271/7134 completed (loss: 0.0349138118326664, acc: 0.9946523904800415)
[2024-12-17 03:12:35,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:35,389][root][INFO] - Training Epoch: 2/2, step 6272/7134 completed (loss: 0.0032645328901708126, acc: 1.0)
[2024-12-17 03:12:35,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:35,747][root][INFO] - Training Epoch: 2/2, step 6273/7134 completed (loss: 0.013097872957587242, acc: 0.99726402759552)
[2024-12-17 03:12:35,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:36,080][root][INFO] - Training Epoch: 2/2, step 6274/7134 completed (loss: 0.01510340441018343, acc: 0.9985734820365906)
[2024-12-17 03:12:36,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:36,411][root][INFO] - Training Epoch: 2/2, step 6275/7134 completed (loss: 0.03108924813568592, acc: 0.9939117431640625)
[2024-12-17 03:12:36,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:36,710][root][INFO] - Training Epoch: 2/2, step 6276/7134 completed (loss: 0.02385766990482807, acc: 0.9929947257041931)
[2024-12-17 03:12:36,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:37,008][root][INFO] - Training Epoch: 2/2, step 6277/7134 completed (loss: 0.06249528005719185, acc: 0.9841628670692444)
[2024-12-17 03:12:37,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:37,335][root][INFO] - Training Epoch: 2/2, step 6278/7134 completed (loss: 0.005984643008559942, acc: 0.9967105388641357)
[2024-12-17 03:12:37,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:37,672][root][INFO] - Training Epoch: 2/2, step 6279/7134 completed (loss: 0.008306956849992275, acc: 0.9982876777648926)
[2024-12-17 03:12:37,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:37,998][root][INFO] - Training Epoch: 2/2, step 6280/7134 completed (loss: 0.02391476184129715, acc: 0.9930192232131958)
[2024-12-17 03:12:38,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:38,322][root][INFO] - Training Epoch: 2/2, step 6281/7134 completed (loss: 0.016718905419111252, acc: 0.9965338110923767)
[2024-12-17 03:12:38,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:38,662][root][INFO] - Training Epoch: 2/2, step 6282/7134 completed (loss: 0.011933165602385998, acc: 0.9952830076217651)
[2024-12-17 03:12:38,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:38,996][root][INFO] - Training Epoch: 2/2, step 6283/7134 completed (loss: 0.04013357684016228, acc: 0.9890829920768738)
[2024-12-17 03:12:39,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:39,314][root][INFO] - Training Epoch: 2/2, step 6284/7134 completed (loss: 0.06804952025413513, acc: 0.9781181812286377)
[2024-12-17 03:12:39,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:39,617][root][INFO] - Training Epoch: 2/2, step 6285/7134 completed (loss: 0.01712280511856079, acc: 0.9947506785392761)
[2024-12-17 03:12:39,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:39,943][root][INFO] - Training Epoch: 2/2, step 6286/7134 completed (loss: 0.03211003169417381, acc: 0.9950658082962036)
[2024-12-17 03:12:40,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:40,283][root][INFO] - Training Epoch: 2/2, step 6287/7134 completed (loss: 0.0455627366900444, acc: 0.9852941036224365)
[2024-12-17 03:12:40,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:40,611][root][INFO] - Training Epoch: 2/2, step 6288/7134 completed (loss: 0.011929869651794434, acc: 0.9967319965362549)
[2024-12-17 03:12:40,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:40,912][root][INFO] - Training Epoch: 2/2, step 6289/7134 completed (loss: 0.027096951380372047, acc: 0.9909909963607788)
[2024-12-17 03:12:41,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:41,248][root][INFO] - Training Epoch: 2/2, step 6290/7134 completed (loss: 0.017753781750798225, acc: 0.9936000108718872)
[2024-12-17 03:12:41,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:41,553][root][INFO] - Training Epoch: 2/2, step 6291/7134 completed (loss: 0.008143693208694458, acc: 0.9981818199157715)
[2024-12-17 03:12:41,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:41,841][root][INFO] - Training Epoch: 2/2, step 6292/7134 completed (loss: 0.03436989709734917, acc: 0.9931662678718567)
[2024-12-17 03:12:41,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:42,181][root][INFO] - Training Epoch: 2/2, step 6293/7134 completed (loss: 0.05537891015410423, acc: 0.9863481521606445)
[2024-12-17 03:12:42,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:42,560][root][INFO] - Training Epoch: 2/2, step 6294/7134 completed (loss: 0.03066880628466606, acc: 0.9886547923088074)
[2024-12-17 03:12:42,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:42,931][root][INFO] - Training Epoch: 2/2, step 6295/7134 completed (loss: 0.022649915888905525, acc: 0.9909583926200867)
[2024-12-17 03:12:43,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:43,214][root][INFO] - Training Epoch: 2/2, step 6296/7134 completed (loss: 0.05539846792817116, acc: 0.9842519760131836)
[2024-12-17 03:12:43,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:43,543][root][INFO] - Training Epoch: 2/2, step 6297/7134 completed (loss: 0.025914164260029793, acc: 0.9918032884597778)
[2024-12-17 03:12:43,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:43,879][root][INFO] - Training Epoch: 2/2, step 6298/7134 completed (loss: 0.044579003006219864, acc: 0.9862542748451233)
[2024-12-17 03:12:44,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:44,222][root][INFO] - Training Epoch: 2/2, step 6299/7134 completed (loss: 0.07718075066804886, acc: 0.9776358008384705)
[2024-12-17 03:12:44,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:44,564][root][INFO] - Training Epoch: 2/2, step 6300/7134 completed (loss: 0.04923358932137489, acc: 0.9849246144294739)
[2024-12-17 03:12:44,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:44,935][root][INFO] - Training Epoch: 2/2, step 6301/7134 completed (loss: 0.01523964200168848, acc: 0.9977011680603027)
[2024-12-17 03:12:45,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:45,287][root][INFO] - Training Epoch: 2/2, step 6302/7134 completed (loss: 0.012924786657094955, acc: 0.9986187815666199)
[2024-12-17 03:12:45,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:45,671][root][INFO] - Training Epoch: 2/2, step 6303/7134 completed (loss: 0.01541527733206749, acc: 0.9968051314353943)
[2024-12-17 03:12:45,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:46,027][root][INFO] - Training Epoch: 2/2, step 6304/7134 completed (loss: 0.023075615987181664, acc: 0.9932432174682617)
[2024-12-17 03:12:46,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:46,382][root][INFO] - Training Epoch: 2/2, step 6305/7134 completed (loss: 0.02100476436316967, acc: 0.9950900077819824)
[2024-12-17 03:12:46,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:46,745][root][INFO] - Training Epoch: 2/2, step 6306/7134 completed (loss: 0.03819945827126503, acc: 0.989195704460144)
[2024-12-17 03:12:46,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:47,102][root][INFO] - Training Epoch: 2/2, step 6307/7134 completed (loss: 0.0633733943104744, acc: 0.9894179701805115)
[2024-12-17 03:12:47,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:47,462][root][INFO] - Training Epoch: 2/2, step 6308/7134 completed (loss: 0.02374015748500824, acc: 0.9938575029373169)
[2024-12-17 03:12:47,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:47,789][root][INFO] - Training Epoch: 2/2, step 6309/7134 completed (loss: 0.025659378618001938, acc: 0.9936000108718872)
[2024-12-17 03:12:47,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:48,105][root][INFO] - Training Epoch: 2/2, step 6310/7134 completed (loss: 0.06005052849650383, acc: 0.9802197813987732)
[2024-12-17 03:12:48,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:48,455][root][INFO] - Training Epoch: 2/2, step 6311/7134 completed (loss: 0.03473782539367676, acc: 0.9852398633956909)
[2024-12-17 03:12:48,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:48,778][root][INFO] - Training Epoch: 2/2, step 6312/7134 completed (loss: 0.04929940402507782, acc: 0.9921383857727051)
[2024-12-17 03:12:48,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:49,125][root][INFO] - Training Epoch: 2/2, step 6313/7134 completed (loss: 0.022406237199902534, acc: 0.9926380515098572)
[2024-12-17 03:12:49,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:49,499][root][INFO] - Training Epoch: 2/2, step 6314/7134 completed (loss: 0.02349594049155712, acc: 0.9924337863922119)
[2024-12-17 03:12:49,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:49,841][root][INFO] - Training Epoch: 2/2, step 6315/7134 completed (loss: 0.06307437270879745, acc: 0.9868852496147156)
[2024-12-17 03:12:49,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:50,187][root][INFO] - Training Epoch: 2/2, step 6316/7134 completed (loss: 0.03892991691827774, acc: 0.9918962717056274)
[2024-12-17 03:12:50,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:50,515][root][INFO] - Training Epoch: 2/2, step 6317/7134 completed (loss: 0.013358429074287415, acc: 0.9967690110206604)
[2024-12-17 03:12:50,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:50,841][root][INFO] - Training Epoch: 2/2, step 6318/7134 completed (loss: 0.01773366518318653, acc: 0.995230495929718)
[2024-12-17 03:12:50,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:51,207][root][INFO] - Training Epoch: 2/2, step 6319/7134 completed (loss: 0.014241039752960205, acc: 0.9948559403419495)
[2024-12-17 03:12:51,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:51,581][root][INFO] - Training Epoch: 2/2, step 6320/7134 completed (loss: 0.025287561118602753, acc: 0.9921011328697205)
[2024-12-17 03:12:51,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:51,933][root][INFO] - Training Epoch: 2/2, step 6321/7134 completed (loss: 0.0201792661100626, acc: 0.9921875)
[2024-12-17 03:12:52,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:52,295][root][INFO] - Training Epoch: 2/2, step 6322/7134 completed (loss: 0.041249360889196396, acc: 0.992732584476471)
[2024-12-17 03:12:52,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:52,661][root][INFO] - Training Epoch: 2/2, step 6323/7134 completed (loss: 0.02872414141893387, acc: 0.9909909963607788)
[2024-12-17 03:12:52,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:53,008][root][INFO] - Training Epoch: 2/2, step 6324/7134 completed (loss: 0.021685045212507248, acc: 0.9960052967071533)
[2024-12-17 03:12:53,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:53,328][root][INFO] - Training Epoch: 2/2, step 6325/7134 completed (loss: 0.04492541402578354, acc: 0.994339644908905)
[2024-12-17 03:12:53,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:53,675][root][INFO] - Training Epoch: 2/2, step 6326/7134 completed (loss: 0.04172343760728836, acc: 0.9855538010597229)
[2024-12-17 03:12:53,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:54,020][root][INFO] - Training Epoch: 2/2, step 6327/7134 completed (loss: 0.034698035567998886, acc: 0.9947229623794556)
[2024-12-17 03:12:54,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:54,355][root][INFO] - Training Epoch: 2/2, step 6328/7134 completed (loss: 0.03237204626202583, acc: 0.9952152967453003)
[2024-12-17 03:12:54,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:54,697][root][INFO] - Training Epoch: 2/2, step 6329/7134 completed (loss: 0.035254087299108505, acc: 0.9878787994384766)
[2024-12-17 03:12:54,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:55,024][root][INFO] - Training Epoch: 2/2, step 6330/7134 completed (loss: 0.04352249950170517, acc: 0.9925558567047119)
[2024-12-17 03:12:55,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:55,356][root][INFO] - Training Epoch: 2/2, step 6331/7134 completed (loss: 0.01907050609588623, acc: 0.9929328560829163)
[2024-12-17 03:12:55,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:55,704][root][INFO] - Training Epoch: 2/2, step 6332/7134 completed (loss: 0.11104622483253479, acc: 0.9814126491546631)
[2024-12-17 03:12:55,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:56,031][root][INFO] - Training Epoch: 2/2, step 6333/7134 completed (loss: 0.045855578035116196, acc: 0.9841269850730896)
[2024-12-17 03:12:56,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:56,313][root][INFO] - Training Epoch: 2/2, step 6334/7134 completed (loss: 0.023554038256406784, acc: 0.9905303120613098)
[2024-12-17 03:12:56,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:56,640][root][INFO] - Training Epoch: 2/2, step 6335/7134 completed (loss: 0.018596556037664413, acc: 0.9932885766029358)
[2024-12-17 03:12:56,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:56,961][root][INFO] - Training Epoch: 2/2, step 6336/7134 completed (loss: 0.0323253832757473, acc: 0.9931192398071289)
[2024-12-17 03:12:57,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:57,300][root][INFO] - Training Epoch: 2/2, step 6337/7134 completed (loss: 0.013807293958961964, acc: 0.9963503479957581)
[2024-12-17 03:12:57,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:57,643][root][INFO] - Training Epoch: 2/2, step 6338/7134 completed (loss: 0.0444459393620491, acc: 0.9826224446296692)
[2024-12-17 03:12:57,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:57,968][root][INFO] - Training Epoch: 2/2, step 6339/7134 completed (loss: 0.049345310777425766, acc: 0.9844290614128113)
[2024-12-17 03:12:58,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:58,299][root][INFO] - Training Epoch: 2/2, step 6340/7134 completed (loss: 0.01842484250664711, acc: 0.9941349029541016)
[2024-12-17 03:12:58,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:58,622][root][INFO] - Training Epoch: 2/2, step 6341/7134 completed (loss: 0.02307555079460144, acc: 0.992409884929657)
[2024-12-17 03:12:58,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:58,990][root][INFO] - Training Epoch: 2/2, step 6342/7134 completed (loss: 0.035275302827358246, acc: 0.9892328381538391)
[2024-12-17 03:12:59,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:59,342][root][INFO] - Training Epoch: 2/2, step 6343/7134 completed (loss: 0.046379122883081436, acc: 0.9879518151283264)
[2024-12-17 03:12:59,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:59,708][root][INFO] - Training Epoch: 2/2, step 6344/7134 completed (loss: 0.028086768463253975, acc: 0.9931600689888)
[2024-12-17 03:12:59,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:00,055][root][INFO] - Training Epoch: 2/2, step 6345/7134 completed (loss: 0.04388631507754326, acc: 0.9890710115432739)
[2024-12-17 03:13:00,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:00,388][root][INFO] - Training Epoch: 2/2, step 6346/7134 completed (loss: 0.08577860891819, acc: 0.9798761606216431)
[2024-12-17 03:13:00,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:00,682][root][INFO] - Training Epoch: 2/2, step 6347/7134 completed (loss: 0.0363142304122448, acc: 0.9891774654388428)
[2024-12-17 03:13:00,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:01,023][root][INFO] - Training Epoch: 2/2, step 6348/7134 completed (loss: 0.08654683083295822, acc: 0.9826388955116272)
[2024-12-17 03:13:01,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:01,358][root][INFO] - Training Epoch: 2/2, step 6349/7134 completed (loss: 0.034302037209272385, acc: 0.9854280352592468)
[2024-12-17 03:13:01,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:01,715][root][INFO] - Training Epoch: 2/2, step 6350/7134 completed (loss: 0.05257830396294594, acc: 0.9836734533309937)
[2024-12-17 03:13:01,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:02,069][root][INFO] - Training Epoch: 2/2, step 6351/7134 completed (loss: 0.044895462691783905, acc: 0.9880596995353699)
[2024-12-17 03:13:02,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:02,411][root][INFO] - Training Epoch: 2/2, step 6352/7134 completed (loss: 0.1443401575088501, acc: 0.96879643201828)
[2024-12-17 03:13:02,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:02,785][root][INFO] - Training Epoch: 2/2, step 6353/7134 completed (loss: 0.040346406400203705, acc: 0.9897511005401611)
[2024-12-17 03:13:02,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:03,131][root][INFO] - Training Epoch: 2/2, step 6354/7134 completed (loss: 0.029763242229819298, acc: 0.9930747747421265)
[2024-12-17 03:13:03,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:03,464][root][INFO] - Training Epoch: 2/2, step 6355/7134 completed (loss: 0.023609980940818787, acc: 0.9951456189155579)
[2024-12-17 03:13:03,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:03,792][root][INFO] - Training Epoch: 2/2, step 6356/7134 completed (loss: 0.03482532501220703, acc: 0.9910314083099365)
[2024-12-17 03:13:03,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:04,133][root][INFO] - Training Epoch: 2/2, step 6357/7134 completed (loss: 0.01738317497074604, acc: 0.9944444298744202)
[2024-12-17 03:13:04,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:04,496][root][INFO] - Training Epoch: 2/2, step 6358/7134 completed (loss: 0.03673023730516434, acc: 0.9901408553123474)
[2024-12-17 03:13:04,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:04,822][root][INFO] - Training Epoch: 2/2, step 6359/7134 completed (loss: 0.06248754635453224, acc: 0.9873949289321899)
[2024-12-17 03:13:04,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:05,162][root][INFO] - Training Epoch: 2/2, step 6360/7134 completed (loss: 0.024851597845554352, acc: 0.9904458522796631)
[2024-12-17 03:13:05,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:05,513][root][INFO] - Training Epoch: 2/2, step 6361/7134 completed (loss: 0.0423063226044178, acc: 0.9908758997917175)
[2024-12-17 03:13:05,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:05,872][root][INFO] - Training Epoch: 2/2, step 6362/7134 completed (loss: 0.048099178820848465, acc: 0.9847561120986938)
[2024-12-17 03:13:05,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:06,213][root][INFO] - Training Epoch: 2/2, step 6363/7134 completed (loss: 0.0417657271027565, acc: 0.9882698059082031)
[2024-12-17 03:13:06,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:06,550][root][INFO] - Training Epoch: 2/2, step 6364/7134 completed (loss: 0.020585449412465096, acc: 0.9942775368690491)
[2024-12-17 03:13:06,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:06,876][root][INFO] - Training Epoch: 2/2, step 6365/7134 completed (loss: 0.05112899839878082, acc: 0.9878048896789551)
[2024-12-17 03:13:06,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:07,218][root][INFO] - Training Epoch: 2/2, step 6366/7134 completed (loss: 0.03531922027468681, acc: 0.9881109595298767)
[2024-12-17 03:13:07,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:07,539][root][INFO] - Training Epoch: 2/2, step 6367/7134 completed (loss: 0.046650949865579605, acc: 0.9867674708366394)
[2024-12-17 03:13:07,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:07,880][root][INFO] - Training Epoch: 2/2, step 6368/7134 completed (loss: 0.06655818969011307, acc: 0.9872881174087524)
[2024-12-17 03:13:08,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:08,238][root][INFO] - Training Epoch: 2/2, step 6369/7134 completed (loss: 0.049218107014894485, acc: 0.9921156167984009)
[2024-12-17 03:13:08,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:08,605][root][INFO] - Training Epoch: 2/2, step 6370/7134 completed (loss: 0.14278514683246613, acc: 0.9683377146720886)
[2024-12-17 03:13:08,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:08,941][root][INFO] - Training Epoch: 2/2, step 6371/7134 completed (loss: 0.058105308562517166, acc: 0.9764543175697327)
[2024-12-17 03:13:09,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:09,266][root][INFO] - Training Epoch: 2/2, step 6372/7134 completed (loss: 0.11615871638059616, acc: 0.9692898392677307)
[2024-12-17 03:13:09,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:09,567][root][INFO] - Training Epoch: 2/2, step 6373/7134 completed (loss: 0.04351821169257164, acc: 0.9890710115432739)
[2024-12-17 03:13:09,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:09,918][root][INFO] - Training Epoch: 2/2, step 6374/7134 completed (loss: 0.022580578923225403, acc: 0.9917012453079224)
[2024-12-17 03:13:10,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:10,277][root][INFO] - Training Epoch: 2/2, step 6375/7134 completed (loss: 0.05653756484389305, acc: 0.9833119511604309)
[2024-12-17 03:13:10,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:10,595][root][INFO] - Training Epoch: 2/2, step 6376/7134 completed (loss: 0.013586011715233326, acc: 0.9963099360466003)
[2024-12-17 03:13:10,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:10,904][root][INFO] - Training Epoch: 2/2, step 6377/7134 completed (loss: 0.03802509605884552, acc: 0.9926739931106567)
[2024-12-17 03:13:11,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:11,274][root][INFO] - Training Epoch: 2/2, step 6378/7134 completed (loss: 0.05320705473423004, acc: 0.986066460609436)
[2024-12-17 03:13:11,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:11,590][root][INFO] - Training Epoch: 2/2, step 6379/7134 completed (loss: 0.043803248554468155, acc: 0.9911167621612549)
[2024-12-17 03:13:11,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:11,959][root][INFO] - Training Epoch: 2/2, step 6380/7134 completed (loss: 0.07720258831977844, acc: 0.9895209670066833)
[2024-12-17 03:13:12,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:12,296][root][INFO] - Training Epoch: 2/2, step 6381/7134 completed (loss: 0.027584780007600784, acc: 0.9938931465148926)
[2024-12-17 03:13:12,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:12,653][root][INFO] - Training Epoch: 2/2, step 6382/7134 completed (loss: 0.016635531559586525, acc: 0.9934297204017639)
[2024-12-17 03:13:12,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:13,001][root][INFO] - Training Epoch: 2/2, step 6383/7134 completed (loss: 0.06464844942092896, acc: 0.9905020594596863)
[2024-12-17 03:13:13,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:13,359][root][INFO] - Training Epoch: 2/2, step 6384/7134 completed (loss: 0.035054221749305725, acc: 0.9910314083099365)
[2024-12-17 03:13:13,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:13,710][root][INFO] - Training Epoch: 2/2, step 6385/7134 completed (loss: 0.09138213098049164, acc: 0.9868263602256775)
[2024-12-17 03:13:13,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:14,082][root][INFO] - Training Epoch: 2/2, step 6386/7134 completed (loss: 0.021598920226097107, acc: 0.9951159954071045)
[2024-12-17 03:13:14,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:14,437][root][INFO] - Training Epoch: 2/2, step 6387/7134 completed (loss: 0.05042454972863197, acc: 0.9887096881866455)
[2024-12-17 03:13:14,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:14,773][root][INFO] - Training Epoch: 2/2, step 6388/7134 completed (loss: 0.04697113111615181, acc: 0.9865269660949707)
[2024-12-17 03:13:14,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:15,138][root][INFO] - Training Epoch: 2/2, step 6389/7134 completed (loss: 0.06624329090118408, acc: 0.9877899885177612)
[2024-12-17 03:13:15,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:15,525][root][INFO] - Training Epoch: 2/2, step 6390/7134 completed (loss: 0.05644184350967407, acc: 0.98886638879776)
[2024-12-17 03:13:15,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:15,873][root][INFO] - Training Epoch: 2/2, step 6391/7134 completed (loss: 0.07549621164798737, acc: 0.9782330393791199)
[2024-12-17 03:13:16,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:16,235][root][INFO] - Training Epoch: 2/2, step 6392/7134 completed (loss: 0.07871958613395691, acc: 0.9825640916824341)
[2024-12-17 03:13:16,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:16,598][root][INFO] - Training Epoch: 2/2, step 6393/7134 completed (loss: 0.04552214965224266, acc: 0.9840728044509888)
[2024-12-17 03:13:16,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:16,955][root][INFO] - Training Epoch: 2/2, step 6394/7134 completed (loss: 0.07904484122991562, acc: 0.977746844291687)
[2024-12-17 03:13:17,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:17,322][root][INFO] - Training Epoch: 2/2, step 6395/7134 completed (loss: 0.04610191658139229, acc: 0.9913899302482605)
[2024-12-17 03:13:17,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:17,671][root][INFO] - Training Epoch: 2/2, step 6396/7134 completed (loss: 0.06927848607301712, acc: 0.9908257126808167)
[2024-12-17 03:13:17,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:18,038][root][INFO] - Training Epoch: 2/2, step 6397/7134 completed (loss: 0.036506395787000656, acc: 0.9925558567047119)
[2024-12-17 03:13:18,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:18,394][root][INFO] - Training Epoch: 2/2, step 6398/7134 completed (loss: 0.035573240369558334, acc: 0.9901546835899353)
[2024-12-17 03:13:18,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:18,764][root][INFO] - Training Epoch: 2/2, step 6399/7134 completed (loss: 0.048476871103048325, acc: 0.9862155318260193)
[2024-12-17 03:13:18,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:19,107][root][INFO] - Training Epoch: 2/2, step 6400/7134 completed (loss: 0.02954757958650589, acc: 0.994301974773407)
[2024-12-17 03:13:19,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:19,479][root][INFO] - Training Epoch: 2/2, step 6401/7134 completed (loss: 0.05671670287847519, acc: 0.9858849048614502)
[2024-12-17 03:13:19,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:19,835][root][INFO] - Training Epoch: 2/2, step 6402/7134 completed (loss: 0.051780372858047485, acc: 0.9931895732879639)
[2024-12-17 03:13:19,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:20,159][root][INFO] - Training Epoch: 2/2, step 6403/7134 completed (loss: 0.03646067902445793, acc: 0.9885203838348389)
[2024-12-17 03:13:20,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:20,502][root][INFO] - Training Epoch: 2/2, step 6404/7134 completed (loss: 0.02523980848491192, acc: 0.9944367408752441)
[2024-12-17 03:13:20,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:20,926][root][INFO] - Training Epoch: 2/2, step 6405/7134 completed (loss: 0.022927390411496162, acc: 0.9946236610412598)
[2024-12-17 03:13:21,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:21,295][root][INFO] - Training Epoch: 2/2, step 6406/7134 completed (loss: 0.04587653651833534, acc: 0.9885975122451782)
[2024-12-17 03:13:21,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:21,674][root][INFO] - Training Epoch: 2/2, step 6407/7134 completed (loss: 0.024175791069865227, acc: 0.9947437644004822)
[2024-12-17 03:13:21,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:22,011][root][INFO] - Training Epoch: 2/2, step 6408/7134 completed (loss: 0.05252361297607422, acc: 0.9896602630615234)
[2024-12-17 03:13:22,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:22,353][root][INFO] - Training Epoch: 2/2, step 6409/7134 completed (loss: 0.03600795567035675, acc: 0.9947368502616882)
[2024-12-17 03:13:22,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:22,689][root][INFO] - Training Epoch: 2/2, step 6410/7134 completed (loss: 0.03237967565655708, acc: 0.9889705777168274)
[2024-12-17 03:13:22,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:23,006][root][INFO] - Training Epoch: 2/2, step 6411/7134 completed (loss: 0.04922882467508316, acc: 0.9865996837615967)
[2024-12-17 03:13:23,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:23,338][root][INFO] - Training Epoch: 2/2, step 6412/7134 completed (loss: 0.020653875544667244, acc: 0.9919999837875366)
[2024-12-17 03:13:23,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:23,702][root][INFO] - Training Epoch: 2/2, step 6413/7134 completed (loss: 0.04041852802038193, acc: 0.9880136847496033)
[2024-12-17 03:13:23,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:24,021][root][INFO] - Training Epoch: 2/2, step 6414/7134 completed (loss: 0.015441649593412876, acc: 0.9939576983451843)
[2024-12-17 03:13:24,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:24,362][root][INFO] - Training Epoch: 2/2, step 6415/7134 completed (loss: 0.024969523772597313, acc: 0.9935815334320068)
[2024-12-17 03:13:24,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:24,699][root][INFO] - Training Epoch: 2/2, step 6416/7134 completed (loss: 0.05040574073791504, acc: 0.9829221963882446)
[2024-12-17 03:13:24,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:25,050][root][INFO] - Training Epoch: 2/2, step 6417/7134 completed (loss: 0.10501217842102051, acc: 0.982425332069397)
[2024-12-17 03:13:25,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:25,404][root][INFO] - Training Epoch: 2/2, step 6418/7134 completed (loss: 0.15307103097438812, acc: 0.9676966071128845)
[2024-12-17 03:13:25,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:25,735][root][INFO] - Training Epoch: 2/2, step 6419/7134 completed (loss: 0.08988165855407715, acc: 0.9820554852485657)
[2024-12-17 03:13:25,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:26,083][root][INFO] - Training Epoch: 2/2, step 6420/7134 completed (loss: 0.0461006723344326, acc: 0.9855907559394836)
[2024-12-17 03:13:26,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:26,412][root][INFO] - Training Epoch: 2/2, step 6421/7134 completed (loss: 0.03846244513988495, acc: 0.9910846948623657)
[2024-12-17 03:13:26,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:26,759][root][INFO] - Training Epoch: 2/2, step 6422/7134 completed (loss: 0.051943179219961166, acc: 0.9835841059684753)
[2024-12-17 03:13:26,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:27,096][root][INFO] - Training Epoch: 2/2, step 6423/7134 completed (loss: 0.09397968649864197, acc: 0.9838709831237793)
[2024-12-17 03:13:27,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:27,454][root][INFO] - Training Epoch: 2/2, step 6424/7134 completed (loss: 0.04833497852087021, acc: 0.9873896837234497)
[2024-12-17 03:13:27,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:27,816][root][INFO] - Training Epoch: 2/2, step 6425/7134 completed (loss: 0.05798875913023949, acc: 0.9869621992111206)
[2024-12-17 03:13:27,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:28,183][root][INFO] - Training Epoch: 2/2, step 6426/7134 completed (loss: 0.06956250220537186, acc: 0.9788918495178223)
[2024-12-17 03:13:28,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:28,528][root][INFO] - Training Epoch: 2/2, step 6427/7134 completed (loss: 0.05533097684383392, acc: 0.9857954382896423)
[2024-12-17 03:13:28,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:28,887][root][INFO] - Training Epoch: 2/2, step 6428/7134 completed (loss: 0.03845168650150299, acc: 0.9916201233863831)
[2024-12-17 03:13:29,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:29,245][root][INFO] - Training Epoch: 2/2, step 6429/7134 completed (loss: 0.02242099866271019, acc: 0.9939393997192383)
[2024-12-17 03:13:29,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:29,607][root][INFO] - Training Epoch: 2/2, step 6430/7134 completed (loss: 0.057320788502693176, acc: 0.9884892106056213)
[2024-12-17 03:13:29,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:29,945][root][INFO] - Training Epoch: 2/2, step 6431/7134 completed (loss: 0.07437220215797424, acc: 0.9802631735801697)
[2024-12-17 03:13:30,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:30,270][root][INFO] - Training Epoch: 2/2, step 6432/7134 completed (loss: 0.1823432743549347, acc: 0.9579124450683594)
[2024-12-17 03:13:30,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:30,615][root][INFO] - Training Epoch: 2/2, step 6433/7134 completed (loss: 0.04919128865003586, acc: 0.9863387942314148)
[2024-12-17 03:13:30,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:30,937][root][INFO] - Training Epoch: 2/2, step 6434/7134 completed (loss: 0.019526029005646706, acc: 0.9933422207832336)
[2024-12-17 03:13:31,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:31,272][root][INFO] - Training Epoch: 2/2, step 6435/7134 completed (loss: 0.04863810911774635, acc: 0.9861351847648621)
[2024-12-17 03:13:31,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:31,634][root][INFO] - Training Epoch: 2/2, step 6436/7134 completed (loss: 0.014011639170348644, acc: 0.9984543919563293)
[2024-12-17 03:13:31,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:31,987][root][INFO] - Training Epoch: 2/2, step 6437/7134 completed (loss: 0.03929133713245392, acc: 0.9900000095367432)
[2024-12-17 03:13:32,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:32,352][root][INFO] - Training Epoch: 2/2, step 6438/7134 completed (loss: 0.04237813130021095, acc: 0.990111231803894)
[2024-12-17 03:13:32,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:32,680][root][INFO] - Training Epoch: 2/2, step 6439/7134 completed (loss: 0.04868196323513985, acc: 0.982677161693573)
[2024-12-17 03:13:32,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:33,069][root][INFO] - Training Epoch: 2/2, step 6440/7134 completed (loss: 0.029327884316444397, acc: 0.9892473220825195)
[2024-12-17 03:13:33,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:33,428][root][INFO] - Training Epoch: 2/2, step 6441/7134 completed (loss: 0.022195307537913322, acc: 0.9926144480705261)
[2024-12-17 03:13:33,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:33,831][root][INFO] - Training Epoch: 2/2, step 6442/7134 completed (loss: 0.03407992050051689, acc: 0.9931895732879639)
[2024-12-17 03:13:33,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:34,184][root][INFO] - Training Epoch: 2/2, step 6443/7134 completed (loss: 0.02130996808409691, acc: 0.9950494766235352)
[2024-12-17 03:13:34,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:34,548][root][INFO] - Training Epoch: 2/2, step 6444/7134 completed (loss: 0.035591792315244675, acc: 0.9902234673500061)
[2024-12-17 03:13:34,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:34,902][root][INFO] - Training Epoch: 2/2, step 6445/7134 completed (loss: 0.0562901496887207, acc: 0.9864364862442017)
[2024-12-17 03:13:35,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:35,260][root][INFO] - Training Epoch: 2/2, step 6446/7134 completed (loss: 0.02879416011273861, acc: 0.9940405488014221)
[2024-12-17 03:13:35,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:35,640][root][INFO] - Training Epoch: 2/2, step 6447/7134 completed (loss: 0.045712050050497055, acc: 0.9884925484657288)
[2024-12-17 03:13:35,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:35,984][root][INFO] - Training Epoch: 2/2, step 6448/7134 completed (loss: 0.09825799614191055, acc: 0.9750778675079346)
[2024-12-17 03:13:36,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:36,335][root][INFO] - Training Epoch: 2/2, step 6449/7134 completed (loss: 0.03744445741176605, acc: 0.9884058237075806)
[2024-12-17 03:13:36,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:36,704][root][INFO] - Training Epoch: 2/2, step 6450/7134 completed (loss: 0.028673041611909866, acc: 0.992559552192688)
[2024-12-17 03:13:36,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:37,151][root][INFO] - Training Epoch: 2/2, step 6451/7134 completed (loss: 0.05272434651851654, acc: 0.9862879514694214)
[2024-12-17 03:13:37,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:37,507][root][INFO] - Training Epoch: 2/2, step 6452/7134 completed (loss: 0.01798049733042717, acc: 0.9921962022781372)
[2024-12-17 03:13:37,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:37,859][root][INFO] - Training Epoch: 2/2, step 6453/7134 completed (loss: 0.023708146065473557, acc: 0.9946236610412598)
[2024-12-17 03:13:37,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:38,245][root][INFO] - Training Epoch: 2/2, step 6454/7134 completed (loss: 0.03791293129324913, acc: 0.9929328560829163)
[2024-12-17 03:13:38,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:38,596][root][INFO] - Training Epoch: 2/2, step 6455/7134 completed (loss: 0.016769489273428917, acc: 0.9966044425964355)
[2024-12-17 03:13:38,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:38,938][root][INFO] - Training Epoch: 2/2, step 6456/7134 completed (loss: 0.03636576235294342, acc: 0.9923312664031982)
[2024-12-17 03:13:39,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:39,281][root][INFO] - Training Epoch: 2/2, step 6457/7134 completed (loss: 0.012123611755669117, acc: 0.9955947399139404)
[2024-12-17 03:13:39,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:39,595][root][INFO] - Training Epoch: 2/2, step 6458/7134 completed (loss: 0.035957347601652145, acc: 0.9865546226501465)
[2024-12-17 03:13:39,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:39,944][root][INFO] - Training Epoch: 2/2, step 6459/7134 completed (loss: 0.008335600607097149, acc: 0.997245192527771)
[2024-12-17 03:13:40,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:40,320][root][INFO] - Training Epoch: 2/2, step 6460/7134 completed (loss: 0.01174162793904543, acc: 0.996458113193512)
[2024-12-17 03:13:40,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:40,666][root][INFO] - Training Epoch: 2/2, step 6461/7134 completed (loss: 0.01950320415198803, acc: 0.9921156167984009)
[2024-12-17 03:13:40,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:41,003][root][INFO] - Training Epoch: 2/2, step 6462/7134 completed (loss: 0.02233240194618702, acc: 0.9901599287986755)
[2024-12-17 03:13:41,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:41,381][root][INFO] - Training Epoch: 2/2, step 6463/7134 completed (loss: 0.03547029569745064, acc: 0.9874715209007263)
[2024-12-17 03:13:41,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:41,727][root][INFO] - Training Epoch: 2/2, step 6464/7134 completed (loss: 0.031075280159711838, acc: 0.9882965087890625)
[2024-12-17 03:13:41,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:42,072][root][INFO] - Training Epoch: 2/2, step 6465/7134 completed (loss: 0.018979769200086594, acc: 0.9961439371109009)
[2024-12-17 03:13:42,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:42,406][root][INFO] - Training Epoch: 2/2, step 6466/7134 completed (loss: 0.030592041090130806, acc: 0.9907529950141907)
[2024-12-17 03:13:42,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:42,757][root][INFO] - Training Epoch: 2/2, step 6467/7134 completed (loss: 0.04496706649661064, acc: 0.9832060933113098)
[2024-12-17 03:13:42,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:43,117][root][INFO] - Training Epoch: 2/2, step 6468/7134 completed (loss: 0.06529362499713898, acc: 0.9831144213676453)
[2024-12-17 03:13:43,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:43,491][root][INFO] - Training Epoch: 2/2, step 6469/7134 completed (loss: 0.07009830325841904, acc: 0.9817296266555786)
[2024-12-17 03:13:43,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:43,794][root][INFO] - Training Epoch: 2/2, step 6470/7134 completed (loss: 0.05659590661525726, acc: 0.9853300452232361)
[2024-12-17 03:13:43,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:44,154][root][INFO] - Training Epoch: 2/2, step 6471/7134 completed (loss: 0.016662996262311935, acc: 0.9967426657676697)
[2024-12-17 03:13:44,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:44,533][root][INFO] - Training Epoch: 2/2, step 6472/7134 completed (loss: 0.07448488473892212, acc: 0.9810874462127686)
[2024-12-17 03:13:44,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:44,900][root][INFO] - Training Epoch: 2/2, step 6473/7134 completed (loss: 0.014390760101377964, acc: 0.9986594915390015)
[2024-12-17 03:13:44,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:45,228][root][INFO] - Training Epoch: 2/2, step 6474/7134 completed (loss: 0.023409487679600716, acc: 0.9932705163955688)
[2024-12-17 03:13:45,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:45,544][root][INFO] - Training Epoch: 2/2, step 6475/7134 completed (loss: 0.059846583753824234, acc: 0.9866666793823242)
[2024-12-17 03:13:45,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:45,826][root][INFO] - Training Epoch: 2/2, step 6476/7134 completed (loss: 0.05139674246311188, acc: 0.9834983348846436)
[2024-12-17 03:13:45,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:46,139][root][INFO] - Training Epoch: 2/2, step 6477/7134 completed (loss: 0.020043259486556053, acc: 0.9936440587043762)
[2024-12-17 03:13:46,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:46,473][root][INFO] - Training Epoch: 2/2, step 6478/7134 completed (loss: 0.02449345588684082, acc: 0.9870848655700684)
[2024-12-17 03:13:46,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:46,814][root][INFO] - Training Epoch: 2/2, step 6479/7134 completed (loss: 0.04193275794386864, acc: 0.9899497628211975)
[2024-12-17 03:13:46,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:47,139][root][INFO] - Training Epoch: 2/2, step 6480/7134 completed (loss: 0.0833611786365509, acc: 0.9793814420700073)
[2024-12-17 03:13:47,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:47,469][root][INFO] - Training Epoch: 2/2, step 6481/7134 completed (loss: 0.014123499393463135, acc: 0.9982993006706238)
[2024-12-17 03:13:47,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:47,816][root][INFO] - Training Epoch: 2/2, step 6482/7134 completed (loss: 0.01459001936018467, acc: 0.9950000047683716)
[2024-12-17 03:13:47,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:48,146][root][INFO] - Training Epoch: 2/2, step 6483/7134 completed (loss: 0.09907753020524979, acc: 0.9783393740653992)
[2024-12-17 03:13:48,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:48,476][root][INFO] - Training Epoch: 2/2, step 6484/7134 completed (loss: 0.06259068101644516, acc: 0.9882698059082031)
[2024-12-17 03:13:48,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:48,845][root][INFO] - Training Epoch: 2/2, step 6485/7134 completed (loss: 0.01916046068072319, acc: 0.9960474371910095)
[2024-12-17 03:13:48,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:49,182][root][INFO] - Training Epoch: 2/2, step 6486/7134 completed (loss: 0.14069868624210358, acc: 0.9763636589050293)
[2024-12-17 03:13:49,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:49,465][root][INFO] - Training Epoch: 2/2, step 6487/7134 completed (loss: 0.14633341133594513, acc: 0.9655870199203491)
[2024-12-17 03:13:49,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:49,801][root][INFO] - Training Epoch: 2/2, step 6488/7134 completed (loss: 0.07721232622861862, acc: 0.9798792600631714)
[2024-12-17 03:13:49,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:50,126][root][INFO] - Training Epoch: 2/2, step 6489/7134 completed (loss: 0.11008147895336151, acc: 0.9757462739944458)
[2024-12-17 03:13:50,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:50,463][root][INFO] - Training Epoch: 2/2, step 6490/7134 completed (loss: 0.06663420796394348, acc: 0.9811320900917053)
[2024-12-17 03:13:50,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:50,822][root][INFO] - Training Epoch: 2/2, step 6491/7134 completed (loss: 0.09783405065536499, acc: 0.9838056564331055)
[2024-12-17 03:13:50,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:51,161][root][INFO] - Training Epoch: 2/2, step 6492/7134 completed (loss: 0.0327434279024601, acc: 0.9870634078979492)
[2024-12-17 03:13:51,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:51,529][root][INFO] - Training Epoch: 2/2, step 6493/7134 completed (loss: 0.06626664102077484, acc: 0.9860050678253174)
[2024-12-17 03:13:51,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:51,841][root][INFO] - Training Epoch: 2/2, step 6494/7134 completed (loss: 0.03281180560588837, acc: 0.9870848655700684)
[2024-12-17 03:13:51,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:52,186][root][INFO] - Training Epoch: 2/2, step 6495/7134 completed (loss: 0.06557435542345047, acc: 0.9831697344779968)
[2024-12-17 03:13:52,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:52,548][root][INFO] - Training Epoch: 2/2, step 6496/7134 completed (loss: 0.04722569137811661, acc: 0.988664984703064)
[2024-12-17 03:13:52,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:52,894][root][INFO] - Training Epoch: 2/2, step 6497/7134 completed (loss: 0.11007029563188553, acc: 0.9688957929611206)
[2024-12-17 03:13:53,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:53,266][root][INFO] - Training Epoch: 2/2, step 6498/7134 completed (loss: 0.02838004007935524, acc: 0.995121955871582)
[2024-12-17 03:13:53,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:53,617][root][INFO] - Training Epoch: 2/2, step 6499/7134 completed (loss: 0.03895633667707443, acc: 0.993773341178894)
[2024-12-17 03:13:53,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:53,985][root][INFO] - Training Epoch: 2/2, step 6500/7134 completed (loss: 0.0825260803103447, acc: 0.9845938086509705)
[2024-12-17 03:13:54,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:54,327][root][INFO] - Training Epoch: 2/2, step 6501/7134 completed (loss: 0.13545092940330505, acc: 0.9629155993461609)
[2024-12-17 03:13:54,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:54,759][root][INFO] - Training Epoch: 2/2, step 6502/7134 completed (loss: 0.03810322657227516, acc: 0.9904988408088684)
[2024-12-17 03:13:54,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:55,082][root][INFO] - Training Epoch: 2/2, step 6503/7134 completed (loss: 0.05019323155283928, acc: 0.9853372573852539)
[2024-12-17 03:13:55,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:55,392][root][INFO] - Training Epoch: 2/2, step 6504/7134 completed (loss: 0.06039102002978325, acc: 0.9873617887496948)
[2024-12-17 03:13:55,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:55,744][root][INFO] - Training Epoch: 2/2, step 6505/7134 completed (loss: 0.10866345465183258, acc: 0.9724637866020203)
[2024-12-17 03:13:55,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:56,116][root][INFO] - Training Epoch: 2/2, step 6506/7134 completed (loss: 0.09676762670278549, acc: 0.9793702363967896)
[2024-12-17 03:13:56,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:56,469][root][INFO] - Training Epoch: 2/2, step 6507/7134 completed (loss: 0.11640377342700958, acc: 0.974281370639801)
[2024-12-17 03:13:56,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:56,838][root][INFO] - Training Epoch: 2/2, step 6508/7134 completed (loss: 0.06546355783939362, acc: 0.9823943376541138)
[2024-12-17 03:13:56,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:57,197][root][INFO] - Training Epoch: 2/2, step 6509/7134 completed (loss: 0.046043939888477325, acc: 0.9889258146286011)
[2024-12-17 03:13:57,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:57,590][root][INFO] - Training Epoch: 2/2, step 6510/7134 completed (loss: 0.051389455795288086, acc: 0.9873149991035461)
[2024-12-17 03:13:57,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:57,936][root][INFO] - Training Epoch: 2/2, step 6511/7134 completed (loss: 0.056548669934272766, acc: 0.9864661693572998)
[2024-12-17 03:13:58,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:58,185][root][INFO] - Training Epoch: 2/2, step 6512/7134 completed (loss: 0.03174520283937454, acc: 0.9923954606056213)
[2024-12-17 03:13:58,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:58,513][root][INFO] - Training Epoch: 2/2, step 6513/7134 completed (loss: 0.04274575039744377, acc: 0.9861111044883728)
[2024-12-17 03:13:58,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:58,837][root][INFO] - Training Epoch: 2/2, step 6514/7134 completed (loss: 0.04752684757113457, acc: 0.9857954382896423)
[2024-12-17 03:13:58,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:59,209][root][INFO] - Training Epoch: 2/2, step 6515/7134 completed (loss: 0.04684816300868988, acc: 0.9860405921936035)
[2024-12-17 03:13:59,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:59,571][root][INFO] - Training Epoch: 2/2, step 6516/7134 completed (loss: 0.09324684739112854, acc: 0.9761273264884949)
[2024-12-17 03:13:59,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:59,920][root][INFO] - Training Epoch: 2/2, step 6517/7134 completed (loss: 0.03205995261669159, acc: 0.9868420958518982)
[2024-12-17 03:14:00,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:00,272][root][INFO] - Training Epoch: 2/2, step 6518/7134 completed (loss: 0.017796354368329048, acc: 0.9958620667457581)
[2024-12-17 03:14:00,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:00,615][root][INFO] - Training Epoch: 2/2, step 6519/7134 completed (loss: 0.04505641385912895, acc: 0.9946808218955994)
[2024-12-17 03:14:00,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:00,937][root][INFO] - Training Epoch: 2/2, step 6520/7134 completed (loss: 0.04465413838624954, acc: 0.9906687140464783)
[2024-12-17 03:14:01,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:01,262][root][INFO] - Training Epoch: 2/2, step 6521/7134 completed (loss: 0.03178166598081589, acc: 0.9895833134651184)
[2024-12-17 03:14:01,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:01,581][root][INFO] - Training Epoch: 2/2, step 6522/7134 completed (loss: 0.049789633601903915, acc: 0.9828473329544067)
[2024-12-17 03:14:01,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:01,898][root][INFO] - Training Epoch: 2/2, step 6523/7134 completed (loss: 0.12101594358682632, acc: 0.967332124710083)
[2024-12-17 03:14:02,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:02,259][root][INFO] - Training Epoch: 2/2, step 6524/7134 completed (loss: 0.06120477244257927, acc: 0.9820051193237305)
[2024-12-17 03:14:02,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:02,598][root][INFO] - Training Epoch: 2/2, step 6525/7134 completed (loss: 0.019483206793665886, acc: 0.9919678568840027)
[2024-12-17 03:14:02,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:02,958][root][INFO] - Training Epoch: 2/2, step 6526/7134 completed (loss: 0.07003293186426163, acc: 0.980793833732605)
[2024-12-17 03:14:03,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:03,291][root][INFO] - Training Epoch: 2/2, step 6527/7134 completed (loss: 0.035402268171310425, acc: 0.9910979270935059)
[2024-12-17 03:14:03,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:03,607][root][INFO] - Training Epoch: 2/2, step 6528/7134 completed (loss: 0.06826388835906982, acc: 0.9891696572303772)
[2024-12-17 03:14:03,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:03,919][root][INFO] - Training Epoch: 2/2, step 6529/7134 completed (loss: 0.0758599266409874, acc: 0.9849624037742615)
[2024-12-17 03:14:04,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:04,258][root][INFO] - Training Epoch: 2/2, step 6530/7134 completed (loss: 0.03926124423742294, acc: 0.9857346415519714)
[2024-12-17 03:14:04,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:04,592][root][INFO] - Training Epoch: 2/2, step 6531/7134 completed (loss: 0.039828233420848846, acc: 0.9855491518974304)
[2024-12-17 03:14:04,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:04,942][root][INFO] - Training Epoch: 2/2, step 6532/7134 completed (loss: 0.053637322038412094, acc: 0.9799749851226807)
[2024-12-17 03:14:05,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:05,284][root][INFO] - Training Epoch: 2/2, step 6533/7134 completed (loss: 0.021035682410001755, acc: 0.9955223798751831)
[2024-12-17 03:14:05,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:05,600][root][INFO] - Training Epoch: 2/2, step 6534/7134 completed (loss: 0.06751958280801773, acc: 0.9906166195869446)
[2024-12-17 03:14:05,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:05,917][root][INFO] - Training Epoch: 2/2, step 6535/7134 completed (loss: 0.016948102042078972, acc: 0.9953161478042603)
[2024-12-17 03:14:06,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:06,239][root][INFO] - Training Epoch: 2/2, step 6536/7134 completed (loss: 0.057323653250932693, acc: 0.9821428656578064)
[2024-12-17 03:14:06,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:06,549][root][INFO] - Training Epoch: 2/2, step 6537/7134 completed (loss: 0.06506791710853577, acc: 0.9778761267662048)
[2024-12-17 03:14:06,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:06,873][root][INFO] - Training Epoch: 2/2, step 6538/7134 completed (loss: 0.07225193083286285, acc: 0.9840142130851746)
[2024-12-17 03:14:06,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:07,122][root][INFO] - Training Epoch: 2/2, step 6539/7134 completed (loss: 0.016967205330729485, acc: 0.9969879388809204)
[2024-12-17 03:14:07,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:07,419][root][INFO] - Training Epoch: 2/2, step 6540/7134 completed (loss: 0.2740945518016815, acc: 0.937158465385437)
[2024-12-17 03:14:07,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:07,788][root][INFO] - Training Epoch: 2/2, step 6541/7134 completed (loss: 0.07563862949609756, acc: 0.9828431606292725)
[2024-12-17 03:14:07,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:08,149][root][INFO] - Training Epoch: 2/2, step 6542/7134 completed (loss: 0.05425740405917168, acc: 0.9847457408905029)
[2024-12-17 03:14:08,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:08,490][root][INFO] - Training Epoch: 2/2, step 6543/7134 completed (loss: 0.023531043902039528, acc: 0.9895178079605103)
[2024-12-17 03:14:08,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:08,836][root][INFO] - Training Epoch: 2/2, step 6544/7134 completed (loss: 0.05785086005926132, acc: 0.9880715608596802)
[2024-12-17 03:14:08,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:09,161][root][INFO] - Training Epoch: 2/2, step 6545/7134 completed (loss: 0.034026674926280975, acc: 0.9925650358200073)
[2024-12-17 03:14:09,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:09,467][root][INFO] - Training Epoch: 2/2, step 6546/7134 completed (loss: 0.055346615612506866, acc: 0.990227997303009)
[2024-12-17 03:14:09,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:09,795][root][INFO] - Training Epoch: 2/2, step 6547/7134 completed (loss: 0.11839289218187332, acc: 0.9744463562965393)
[2024-12-17 03:14:09,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:10,060][root][INFO] - Training Epoch: 2/2, step 6548/7134 completed (loss: 0.04076312854886055, acc: 0.988095223903656)
[2024-12-17 03:14:10,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:10,388][root][INFO] - Training Epoch: 2/2, step 6549/7134 completed (loss: 0.07649081945419312, acc: 0.984466016292572)
[2024-12-17 03:14:10,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:10,708][root][INFO] - Training Epoch: 2/2, step 6550/7134 completed (loss: 0.0897424966096878, acc: 0.9815384745597839)
[2024-12-17 03:14:10,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:11,062][root][INFO] - Training Epoch: 2/2, step 6551/7134 completed (loss: 0.026669437065720558, acc: 0.9943052530288696)
[2024-12-17 03:14:11,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:11,429][root][INFO] - Training Epoch: 2/2, step 6552/7134 completed (loss: 0.04333087429404259, acc: 0.9910358786582947)
[2024-12-17 03:14:11,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:11,790][root][INFO] - Training Epoch: 2/2, step 6553/7134 completed (loss: 0.03949843719601631, acc: 0.9898219108581543)
[2024-12-17 03:14:11,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:12,161][root][INFO] - Training Epoch: 2/2, step 6554/7134 completed (loss: 0.04130417853593826, acc: 0.9924324154853821)
[2024-12-17 03:14:12,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:12,547][root][INFO] - Training Epoch: 2/2, step 6555/7134 completed (loss: 0.08216127753257751, acc: 0.9808853268623352)
[2024-12-17 03:14:12,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:12,886][root][INFO] - Training Epoch: 2/2, step 6556/7134 completed (loss: 0.05258636921644211, acc: 0.9873684048652649)
[2024-12-17 03:14:13,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:13,261][root][INFO] - Training Epoch: 2/2, step 6557/7134 completed (loss: 0.03811396658420563, acc: 0.9889112710952759)
[2024-12-17 03:14:13,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:13,642][root][INFO] - Training Epoch: 2/2, step 6558/7134 completed (loss: 0.07265444099903107, acc: 0.9858695864677429)
[2024-12-17 03:14:13,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:13,987][root][INFO] - Training Epoch: 2/2, step 6559/7134 completed (loss: 0.03975392132997513, acc: 0.9902912378311157)
[2024-12-17 03:14:14,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:14,428][root][INFO] - Training Epoch: 2/2, step 6560/7134 completed (loss: 0.03548811003565788, acc: 0.9916765689849854)
[2024-12-17 03:14:14,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:14,770][root][INFO] - Training Epoch: 2/2, step 6561/7134 completed (loss: 0.03470640629529953, acc: 0.9894737005233765)
[2024-12-17 03:14:14,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:15,115][root][INFO] - Training Epoch: 2/2, step 6562/7134 completed (loss: 0.043692681938409805, acc: 0.9820627570152283)
[2024-12-17 03:14:15,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:15,481][root][INFO] - Training Epoch: 2/2, step 6563/7134 completed (loss: 0.054613061249256134, acc: 0.9860302805900574)
[2024-12-17 03:14:15,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:15,840][root][INFO] - Training Epoch: 2/2, step 6564/7134 completed (loss: 0.060728877782821655, acc: 0.9824561476707458)
[2024-12-17 03:14:15,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:16,211][root][INFO] - Training Epoch: 2/2, step 6565/7134 completed (loss: 0.046355534344911575, acc: 0.9894291758537292)
[2024-12-17 03:14:16,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:16,600][root][INFO] - Training Epoch: 2/2, step 6566/7134 completed (loss: 0.03937236964702606, acc: 0.9886040091514587)
[2024-12-17 03:14:16,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:16,997][root][INFO] - Training Epoch: 2/2, step 6567/7134 completed (loss: 0.026643743738532066, acc: 0.9898682832717896)
[2024-12-17 03:14:17,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:17,367][root][INFO] - Training Epoch: 2/2, step 6568/7134 completed (loss: 0.03241025656461716, acc: 0.9924337863922119)
[2024-12-17 03:14:17,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:17,735][root][INFO] - Training Epoch: 2/2, step 6569/7134 completed (loss: 0.017880400642752647, acc: 0.9923076629638672)
[2024-12-17 03:14:17,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:18,109][root][INFO] - Training Epoch: 2/2, step 6570/7134 completed (loss: 0.02918877825140953, acc: 0.9918699264526367)
[2024-12-17 03:14:18,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:18,423][root][INFO] - Training Epoch: 2/2, step 6571/7134 completed (loss: 0.02032184787094593, acc: 0.9947643876075745)
[2024-12-17 03:14:18,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:18,771][root][INFO] - Training Epoch: 2/2, step 6572/7134 completed (loss: 0.05397377535700798, acc: 0.9855875968933105)
[2024-12-17 03:14:18,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:19,137][root][INFO] - Training Epoch: 2/2, step 6573/7134 completed (loss: 0.02297099120914936, acc: 0.9920993447303772)
[2024-12-17 03:14:19,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:19,512][root][INFO] - Training Epoch: 2/2, step 6574/7134 completed (loss: 0.018676409497857094, acc: 0.9928425550460815)
[2024-12-17 03:14:19,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:19,904][root][INFO] - Training Epoch: 2/2, step 6575/7134 completed (loss: 0.03871278837323189, acc: 0.9878453016281128)
[2024-12-17 03:14:19,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:20,259][root][INFO] - Training Epoch: 2/2, step 6576/7134 completed (loss: 0.016666481271386147, acc: 0.9947478771209717)
[2024-12-17 03:14:20,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:20,622][root][INFO] - Training Epoch: 2/2, step 6577/7134 completed (loss: 0.047273363918066025, acc: 0.9859943985939026)
[2024-12-17 03:14:20,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:21,182][root][INFO] - Training Epoch: 2/2, step 6578/7134 completed (loss: 0.03780140355229378, acc: 0.9875444769859314)
[2024-12-17 03:14:21,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:21,521][root][INFO] - Training Epoch: 2/2, step 6579/7134 completed (loss: 0.030396491289138794, acc: 0.9891107082366943)
[2024-12-17 03:14:21,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:21,898][root][INFO] - Training Epoch: 2/2, step 6580/7134 completed (loss: 0.02529536746442318, acc: 0.9905882477760315)
[2024-12-17 03:14:22,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:22,255][root][INFO] - Training Epoch: 2/2, step 6581/7134 completed (loss: 0.03727266564965248, acc: 0.9876998662948608)
[2024-12-17 03:14:22,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:22,568][root][INFO] - Training Epoch: 2/2, step 6582/7134 completed (loss: 0.06610047817230225, acc: 0.9798561334609985)
[2024-12-17 03:14:22,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:22,929][root][INFO] - Training Epoch: 2/2, step 6583/7134 completed (loss: 0.0201686043292284, acc: 0.9931350350379944)
[2024-12-17 03:14:23,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:23,290][root][INFO] - Training Epoch: 2/2, step 6584/7134 completed (loss: 0.046524155884981155, acc: 0.9853121042251587)
[2024-12-17 03:14:23,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:23,657][root][INFO] - Training Epoch: 2/2, step 6585/7134 completed (loss: 0.04443485662341118, acc: 0.9819079041481018)
[2024-12-17 03:14:23,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:24,019][root][INFO] - Training Epoch: 2/2, step 6586/7134 completed (loss: 0.03583512455224991, acc: 0.9948186278343201)
[2024-12-17 03:14:24,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:24,372][root][INFO] - Training Epoch: 2/2, step 6587/7134 completed (loss: 0.09368808567523956, acc: 0.9823113083839417)
[2024-12-17 03:14:24,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:24,705][root][INFO] - Training Epoch: 2/2, step 6588/7134 completed (loss: 0.046516913920640945, acc: 0.9911949634552002)
[2024-12-17 03:14:24,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:25,050][root][INFO] - Training Epoch: 2/2, step 6589/7134 completed (loss: 0.0404176339507103, acc: 0.9861687421798706)
[2024-12-17 03:14:25,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:25,414][root][INFO] - Training Epoch: 2/2, step 6590/7134 completed (loss: 0.05230696499347687, acc: 0.9848661422729492)
[2024-12-17 03:14:25,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:25,781][root][INFO] - Training Epoch: 2/2, step 6591/7134 completed (loss: 0.037036146968603134, acc: 0.9888476133346558)
[2024-12-17 03:14:25,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:26,140][root][INFO] - Training Epoch: 2/2, step 6592/7134 completed (loss: 0.06764708459377289, acc: 0.9818388223648071)
[2024-12-17 03:14:26,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:26,493][root][INFO] - Training Epoch: 2/2, step 6593/7134 completed (loss: 0.04855954647064209, acc: 0.9863013625144958)
[2024-12-17 03:14:26,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:26,874][root][INFO] - Training Epoch: 2/2, step 6594/7134 completed (loss: 0.02815774641931057, acc: 0.9941314458847046)
[2024-12-17 03:14:26,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:27,218][root][INFO] - Training Epoch: 2/2, step 6595/7134 completed (loss: 0.05569420009851456, acc: 0.9851632118225098)
[2024-12-17 03:14:27,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:27,543][root][INFO] - Training Epoch: 2/2, step 6596/7134 completed (loss: 0.04093848168849945, acc: 0.9893778562545776)
[2024-12-17 03:14:27,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:27,898][root][INFO] - Training Epoch: 2/2, step 6597/7134 completed (loss: 0.037616901099681854, acc: 0.9870283007621765)
[2024-12-17 03:14:28,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:28,249][root][INFO] - Training Epoch: 2/2, step 6598/7134 completed (loss: 0.04548034816980362, acc: 0.9892617464065552)
[2024-12-17 03:14:28,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:28,620][root][INFO] - Training Epoch: 2/2, step 6599/7134 completed (loss: 0.04841576889157295, acc: 0.9855072498321533)
[2024-12-17 03:14:28,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:28,948][root][INFO] - Training Epoch: 2/2, step 6600/7134 completed (loss: 0.04504326358437538, acc: 0.9857369065284729)
[2024-12-17 03:14:29,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:29,317][root][INFO] - Training Epoch: 2/2, step 6601/7134 completed (loss: 0.06506302207708359, acc: 0.98591548204422)
[2024-12-17 03:14:29,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:29,676][root][INFO] - Training Epoch: 2/2, step 6602/7134 completed (loss: 0.031884752213954926, acc: 0.9879662990570068)
[2024-12-17 03:14:29,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:30,036][root][INFO] - Training Epoch: 2/2, step 6603/7134 completed (loss: 0.0341079942882061, acc: 0.9887797832489014)
[2024-12-17 03:14:30,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:30,331][root][INFO] - Training Epoch: 2/2, step 6604/7134 completed (loss: 0.05056369677186012, acc: 0.9885057210922241)
[2024-12-17 03:14:30,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:30,655][root][INFO] - Training Epoch: 2/2, step 6605/7134 completed (loss: 0.08611024916172028, acc: 0.9723374843597412)
[2024-12-17 03:14:30,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:31,013][root][INFO] - Training Epoch: 2/2, step 6606/7134 completed (loss: 0.037957482039928436, acc: 0.9886363744735718)
[2024-12-17 03:14:31,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:31,373][root][INFO] - Training Epoch: 2/2, step 6607/7134 completed (loss: 0.09216146916151047, acc: 0.9840425252914429)
[2024-12-17 03:14:31,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:31,733][root][INFO] - Training Epoch: 2/2, step 6608/7134 completed (loss: 0.03816681727766991, acc: 0.9920318722724915)
[2024-12-17 03:14:31,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:32,082][root][INFO] - Training Epoch: 2/2, step 6609/7134 completed (loss: 0.05811568722128868, acc: 0.97555011510849)
[2024-12-17 03:14:32,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:32,409][root][INFO] - Training Epoch: 2/2, step 6610/7134 completed (loss: 0.07414770871400833, acc: 0.9838274717330933)
[2024-12-17 03:14:32,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:32,724][root][INFO] - Training Epoch: 2/2, step 6611/7134 completed (loss: 0.0938231572508812, acc: 0.9723076820373535)
[2024-12-17 03:14:32,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:33,099][root][INFO] - Training Epoch: 2/2, step 6612/7134 completed (loss: 0.07884114235639572, acc: 0.9824970960617065)
[2024-12-17 03:14:33,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:33,499][root][INFO] - Training Epoch: 2/2, step 6613/7134 completed (loss: 0.04022159054875374, acc: 0.988095223903656)
[2024-12-17 03:14:33,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:33,858][root][INFO] - Training Epoch: 2/2, step 6614/7134 completed (loss: 0.06539268046617508, acc: 0.9878987669944763)
[2024-12-17 03:14:33,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:34,210][root][INFO] - Training Epoch: 2/2, step 6615/7134 completed (loss: 0.04226948320865631, acc: 0.987270176410675)
[2024-12-17 03:14:34,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:34,577][root][INFO] - Training Epoch: 2/2, step 6616/7134 completed (loss: 0.04064098000526428, acc: 0.9882628917694092)
[2024-12-17 03:14:34,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:34,932][root][INFO] - Training Epoch: 2/2, step 6617/7134 completed (loss: 0.04116301238536835, acc: 0.9884726405143738)
[2024-12-17 03:14:35,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:35,261][root][INFO] - Training Epoch: 2/2, step 6618/7134 completed (loss: 0.028125034645199776, acc: 0.9955423474311829)
[2024-12-17 03:14:35,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:35,632][root][INFO] - Training Epoch: 2/2, step 6619/7134 completed (loss: 0.03546716645359993, acc: 0.9887892603874207)
[2024-12-17 03:14:35,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:35,994][root][INFO] - Training Epoch: 2/2, step 6620/7134 completed (loss: 0.07355167716741562, acc: 0.9807427525520325)
[2024-12-17 03:14:36,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:36,339][root][INFO] - Training Epoch: 2/2, step 6621/7134 completed (loss: 0.04920005053281784, acc: 0.9849711060523987)
[2024-12-17 03:14:36,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:36,700][root][INFO] - Training Epoch: 2/2, step 6622/7134 completed (loss: 0.05743740126490593, acc: 0.9836065769195557)
[2024-12-17 03:14:36,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:37,050][root][INFO] - Training Epoch: 2/2, step 6623/7134 completed (loss: 0.023346496745944023, acc: 0.9899371266365051)
[2024-12-17 03:14:37,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:37,398][root][INFO] - Training Epoch: 2/2, step 6624/7134 completed (loss: 0.029450299218297005, acc: 0.9908854365348816)
[2024-12-17 03:14:37,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:37,759][root][INFO] - Training Epoch: 2/2, step 6625/7134 completed (loss: 0.029476184397935867, acc: 0.9876203536987305)
[2024-12-17 03:14:37,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:38,124][root][INFO] - Training Epoch: 2/2, step 6626/7134 completed (loss: 0.01910567469894886, acc: 0.9975757598876953)
[2024-12-17 03:14:38,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:38,496][root][INFO] - Training Epoch: 2/2, step 6627/7134 completed (loss: 0.035257019102573395, acc: 0.9891892075538635)
[2024-12-17 03:14:38,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:38,856][root][INFO] - Training Epoch: 2/2, step 6628/7134 completed (loss: 0.04682102054357529, acc: 0.9881656765937805)
[2024-12-17 03:14:38,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:39,162][root][INFO] - Training Epoch: 2/2, step 6629/7134 completed (loss: 0.06324413418769836, acc: 0.9858793616294861)
[2024-12-17 03:14:39,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:39,551][root][INFO] - Training Epoch: 2/2, step 6630/7134 completed (loss: 0.06819381564855576, acc: 0.9843924045562744)
[2024-12-17 03:14:39,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:39,900][root][INFO] - Training Epoch: 2/2, step 6631/7134 completed (loss: 0.04743601009249687, acc: 0.9882044792175293)
[2024-12-17 03:14:40,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:40,310][root][INFO] - Training Epoch: 2/2, step 6632/7134 completed (loss: 0.03743250295519829, acc: 0.9898762702941895)
[2024-12-17 03:14:40,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:40,653][root][INFO] - Training Epoch: 2/2, step 6633/7134 completed (loss: 0.04686114192008972, acc: 0.9890244007110596)
[2024-12-17 03:14:40,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:40,983][root][INFO] - Training Epoch: 2/2, step 6634/7134 completed (loss: 0.039926040917634964, acc: 0.989266574382782)
[2024-12-17 03:14:41,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:41,289][root][INFO] - Training Epoch: 2/2, step 6635/7134 completed (loss: 0.11844558268785477, acc: 0.9757032990455627)
[2024-12-17 03:14:41,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:41,650][root][INFO] - Training Epoch: 2/2, step 6636/7134 completed (loss: 0.06061556190252304, acc: 0.982876718044281)
[2024-12-17 03:14:41,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:41,990][root][INFO] - Training Epoch: 2/2, step 6637/7134 completed (loss: 0.03197958320379257, acc: 0.9927219748497009)
[2024-12-17 03:14:42,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:42,335][root][INFO] - Training Epoch: 2/2, step 6638/7134 completed (loss: 0.019111748784780502, acc: 0.9936467409133911)
[2024-12-17 03:14:42,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:42,697][root][INFO] - Training Epoch: 2/2, step 6639/7134 completed (loss: 0.027167722582817078, acc: 0.995529055595398)
[2024-12-17 03:14:42,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:43,067][root][INFO] - Training Epoch: 2/2, step 6640/7134 completed (loss: 0.030883759260177612, acc: 0.9908116459846497)
[2024-12-17 03:14:43,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:43,426][root][INFO] - Training Epoch: 2/2, step 6641/7134 completed (loss: 0.08202790468931198, acc: 0.9777256846427917)
[2024-12-17 03:14:43,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:43,776][root][INFO] - Training Epoch: 2/2, step 6642/7134 completed (loss: 0.03212887793779373, acc: 0.9939758777618408)
[2024-12-17 03:14:43,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:44,148][root][INFO] - Training Epoch: 2/2, step 6643/7134 completed (loss: 0.04522775486111641, acc: 0.9854689836502075)
[2024-12-17 03:14:44,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:44,513][root][INFO] - Training Epoch: 2/2, step 6644/7134 completed (loss: 0.05706510692834854, acc: 0.9847406148910522)
[2024-12-17 03:14:44,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:44,861][root][INFO] - Training Epoch: 2/2, step 6645/7134 completed (loss: 0.03342029079794884, acc: 0.9877150058746338)
[2024-12-17 03:14:44,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:45,236][root][INFO] - Training Epoch: 2/2, step 6646/7134 completed (loss: 0.04490835592150688, acc: 0.9878854751586914)
[2024-12-17 03:14:45,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:45,580][root][INFO] - Training Epoch: 2/2, step 6647/7134 completed (loss: 0.022778039798140526, acc: 0.9959239363670349)
[2024-12-17 03:14:45,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:45,938][root][INFO] - Training Epoch: 2/2, step 6648/7134 completed (loss: 0.09424963593482971, acc: 0.9711999893188477)
[2024-12-17 03:14:46,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:46,308][root][INFO] - Training Epoch: 2/2, step 6649/7134 completed (loss: 0.055344440042972565, acc: 0.9834710955619812)
[2024-12-17 03:14:46,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:46,694][root][INFO] - Training Epoch: 2/2, step 6650/7134 completed (loss: 0.019719043746590614, acc: 0.9933035969734192)
[2024-12-17 03:14:46,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:47,073][root][INFO] - Training Epoch: 2/2, step 6651/7134 completed (loss: 0.021542999893426895, acc: 0.9972714781761169)
[2024-12-17 03:14:47,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:47,430][root][INFO] - Training Epoch: 2/2, step 6652/7134 completed (loss: 0.03918365389108658, acc: 0.987922728061676)
[2024-12-17 03:14:47,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:47,800][root][INFO] - Training Epoch: 2/2, step 6653/7134 completed (loss: 0.05612657964229584, acc: 0.9868565201759338)
[2024-12-17 03:14:47,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:48,139][root][INFO] - Training Epoch: 2/2, step 6654/7134 completed (loss: 0.07342582941055298, acc: 0.9782945513725281)
[2024-12-17 03:14:48,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:48,472][root][INFO] - Training Epoch: 2/2, step 6655/7134 completed (loss: 0.04741373658180237, acc: 0.9900744557380676)
[2024-12-17 03:14:48,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:48,801][root][INFO] - Training Epoch: 2/2, step 6656/7134 completed (loss: 0.05079474672675133, acc: 0.983460545539856)
[2024-12-17 03:14:48,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:49,155][root][INFO] - Training Epoch: 2/2, step 6657/7134 completed (loss: 0.06471776962280273, acc: 0.9783197641372681)
[2024-12-17 03:14:49,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:49,533][root][INFO] - Training Epoch: 2/2, step 6658/7134 completed (loss: 0.028917910531163216, acc: 0.9922580718994141)
[2024-12-17 03:14:49,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:49,918][root][INFO] - Training Epoch: 2/2, step 6659/7134 completed (loss: 0.04168844223022461, acc: 0.9869791865348816)
[2024-12-17 03:14:50,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:50,275][root][INFO] - Training Epoch: 2/2, step 6660/7134 completed (loss: 0.04407279193401337, acc: 0.9900793433189392)
[2024-12-17 03:14:50,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:50,653][root][INFO] - Training Epoch: 2/2, step 6661/7134 completed (loss: 0.04094497859477997, acc: 0.9876237511634827)
[2024-12-17 03:14:50,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:50,984][root][INFO] - Training Epoch: 2/2, step 6662/7134 completed (loss: 0.06884252279996872, acc: 0.9785407781600952)
[2024-12-17 03:14:51,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:51,341][root][INFO] - Training Epoch: 2/2, step 6663/7134 completed (loss: 0.04332389310002327, acc: 0.9901639223098755)
[2024-12-17 03:14:51,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:51,664][root][INFO] - Training Epoch: 2/2, step 6664/7134 completed (loss: 0.07421788573265076, acc: 0.9649446606636047)
[2024-12-17 03:14:51,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:51,982][root][INFO] - Training Epoch: 2/2, step 6665/7134 completed (loss: 0.08203092962503433, acc: 0.9659090638160706)
[2024-12-17 03:14:52,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:52,341][root][INFO] - Training Epoch: 2/2, step 6666/7134 completed (loss: 0.031185615807771683, acc: 0.989847719669342)
[2024-12-17 03:14:52,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:52,677][root][INFO] - Training Epoch: 2/2, step 6667/7134 completed (loss: 0.044010963290929794, acc: 0.9893993139266968)
[2024-12-17 03:14:52,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:52,990][root][INFO] - Training Epoch: 2/2, step 6668/7134 completed (loss: 0.014841252006590366, acc: 0.9948006868362427)
[2024-12-17 03:14:53,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:53,299][root][INFO] - Training Epoch: 2/2, step 6669/7134 completed (loss: 0.034548453986644745, acc: 0.9916107654571533)
[2024-12-17 03:14:53,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:53,603][root][INFO] - Training Epoch: 2/2, step 6670/7134 completed (loss: 0.014945341274142265, acc: 0.9966555237770081)
[2024-12-17 03:14:53,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:53,941][root][INFO] - Training Epoch: 2/2, step 6671/7134 completed (loss: 0.012010304257273674, acc: 0.9970674514770508)
[2024-12-17 03:14:54,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:54,281][root][INFO] - Training Epoch: 2/2, step 6672/7134 completed (loss: 0.02137828804552555, acc: 0.9906191229820251)
[2024-12-17 03:14:54,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:54,628][root][INFO] - Training Epoch: 2/2, step 6673/7134 completed (loss: 0.02621804177761078, acc: 0.9911894202232361)
[2024-12-17 03:14:54,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:54,943][root][INFO] - Training Epoch: 2/2, step 6674/7134 completed (loss: 0.014344059862196445, acc: 0.9980657696723938)
[2024-12-17 03:14:55,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:55,267][root][INFO] - Training Epoch: 2/2, step 6675/7134 completed (loss: 0.025952011346817017, acc: 0.990123450756073)
[2024-12-17 03:14:55,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:55,602][root][INFO] - Training Epoch: 2/2, step 6676/7134 completed (loss: 0.03249615803360939, acc: 0.9928401112556458)
[2024-12-17 03:14:55,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:55,900][root][INFO] - Training Epoch: 2/2, step 6677/7134 completed (loss: 0.08798074722290039, acc: 0.9809160232543945)
[2024-12-17 03:14:55,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:56,223][root][INFO] - Training Epoch: 2/2, step 6678/7134 completed (loss: 0.020978638902306557, acc: 0.9946428537368774)
[2024-12-17 03:14:56,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:56,514][root][INFO] - Training Epoch: 2/2, step 6679/7134 completed (loss: 0.02434711717069149, acc: 0.9934498071670532)
[2024-12-17 03:14:56,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:56,805][root][INFO] - Training Epoch: 2/2, step 6680/7134 completed (loss: 0.01906677335500717, acc: 0.9918919205665588)
[2024-12-17 03:14:56,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:57,139][root][INFO] - Training Epoch: 2/2, step 6681/7134 completed (loss: 0.023595433682203293, acc: 0.9896050095558167)
[2024-12-17 03:14:57,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:57,460][root][INFO] - Training Epoch: 2/2, step 6682/7134 completed (loss: 0.05065714195370674, acc: 0.9953271150588989)
[2024-12-17 03:14:57,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:57,745][root][INFO] - Training Epoch: 2/2, step 6683/7134 completed (loss: 0.02291405014693737, acc: 0.9890109896659851)
[2024-12-17 03:14:57,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:58,071][root][INFO] - Training Epoch: 2/2, step 6684/7134 completed (loss: 0.04459778219461441, acc: 0.9910714030265808)
[2024-12-17 03:14:58,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:58,389][root][INFO] - Training Epoch: 2/2, step 6685/7134 completed (loss: 0.027894137427210808, acc: 0.9904580116271973)
[2024-12-17 03:14:58,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:58,718][root][INFO] - Training Epoch: 2/2, step 6686/7134 completed (loss: 0.08209924399852753, acc: 0.9876033067703247)
[2024-12-17 03:14:58,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:59,004][root][INFO] - Training Epoch: 2/2, step 6687/7134 completed (loss: 0.04573381319642067, acc: 0.9845678806304932)
[2024-12-17 03:14:59,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:59,372][root][INFO] - Training Epoch: 2/2, step 6688/7134 completed (loss: 0.08423862606287003, acc: 0.9793814420700073)
[2024-12-17 03:14:59,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:59,704][root][INFO] - Training Epoch: 2/2, step 6689/7134 completed (loss: 0.054479170590639114, acc: 0.9881188273429871)
[2024-12-17 03:14:59,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:00,009][root][INFO] - Training Epoch: 2/2, step 6690/7134 completed (loss: 0.11795254796743393, acc: 0.9636803865432739)
[2024-12-17 03:15:00,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:00,338][root][INFO] - Training Epoch: 2/2, step 6691/7134 completed (loss: 0.04250265285372734, acc: 0.9901800155639648)
[2024-12-17 03:15:00,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:00,615][root][INFO] - Training Epoch: 2/2, step 6692/7134 completed (loss: 0.04003044217824936, acc: 0.9936440587043762)
[2024-12-17 03:15:00,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:00,929][root][INFO] - Training Epoch: 2/2, step 6693/7134 completed (loss: 0.04003313183784485, acc: 0.9884488582611084)
[2024-12-17 03:15:01,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:01,264][root][INFO] - Training Epoch: 2/2, step 6694/7134 completed (loss: 0.08179377764463425, acc: 0.9755351543426514)
[2024-12-17 03:15:01,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:01,597][root][INFO] - Training Epoch: 2/2, step 6695/7134 completed (loss: 0.04680219292640686, acc: 0.9890561103820801)
[2024-12-17 03:15:01,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:01,932][root][INFO] - Training Epoch: 2/2, step 6696/7134 completed (loss: 0.049960386008024216, acc: 0.9845201373100281)
[2024-12-17 03:15:02,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:02,263][root][INFO] - Training Epoch: 2/2, step 6697/7134 completed (loss: 0.07007842510938644, acc: 0.9836065769195557)
[2024-12-17 03:15:02,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:02,587][root][INFO] - Training Epoch: 2/2, step 6698/7134 completed (loss: 0.03410204499959946, acc: 0.9896142482757568)
[2024-12-17 03:15:02,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:02,916][root][INFO] - Training Epoch: 2/2, step 6699/7134 completed (loss: 0.0411887988448143, acc: 0.9886105060577393)
[2024-12-17 03:15:03,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:03,251][root][INFO] - Training Epoch: 2/2, step 6700/7134 completed (loss: 0.09599865227937698, acc: 0.9779411554336548)
[2024-12-17 03:15:03,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:03,563][root][INFO] - Training Epoch: 2/2, step 6701/7134 completed (loss: 0.135407492518425, acc: 0.966269850730896)
[2024-12-17 03:15:03,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:03,871][root][INFO] - Training Epoch: 2/2, step 6702/7134 completed (loss: 0.058304332196712494, acc: 0.9764243364334106)
[2024-12-17 03:15:03,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:04,190][root][INFO] - Training Epoch: 2/2, step 6703/7134 completed (loss: 0.09548800438642502, acc: 0.9835526347160339)
[2024-12-17 03:15:04,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:04,526][root][INFO] - Training Epoch: 2/2, step 6704/7134 completed (loss: 0.12792403995990753, acc: 0.9676584601402283)
[2024-12-17 03:15:04,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:04,866][root][INFO] - Training Epoch: 2/2, step 6705/7134 completed (loss: 0.06565075367689133, acc: 0.981794536113739)
[2024-12-17 03:15:04,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:05,153][root][INFO] - Training Epoch: 2/2, step 6706/7134 completed (loss: 0.034164443612098694, acc: 0.9855371713638306)
[2024-12-17 03:15:05,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:05,476][root][INFO] - Training Epoch: 2/2, step 6707/7134 completed (loss: 0.07600206136703491, acc: 0.976331353187561)
[2024-12-17 03:15:05,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:05,826][root][INFO] - Training Epoch: 2/2, step 6708/7134 completed (loss: 0.054552026093006134, acc: 0.9834983348846436)
[2024-12-17 03:15:05,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:06,163][root][INFO] - Training Epoch: 2/2, step 6709/7134 completed (loss: 0.06354299932718277, acc: 0.976047933101654)
[2024-12-17 03:15:06,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:06,492][root][INFO] - Training Epoch: 2/2, step 6710/7134 completed (loss: 0.10024887323379517, acc: 0.9817184805870056)
[2024-12-17 03:15:06,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:06,850][root][INFO] - Training Epoch: 2/2, step 6711/7134 completed (loss: 0.03537158668041229, acc: 0.9888888597488403)
[2024-12-17 03:15:06,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:07,173][root][INFO] - Training Epoch: 2/2, step 6712/7134 completed (loss: 0.0463583841919899, acc: 0.9803328514099121)
[2024-12-17 03:15:07,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:07,599][root][INFO] - Training Epoch: 2/2, step 6713/7134 completed (loss: 0.058812275528907776, acc: 0.986975371837616)
[2024-12-17 03:15:07,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:07,940][root][INFO] - Training Epoch: 2/2, step 6714/7134 completed (loss: 0.03711162507534027, acc: 0.9836552739143372)
[2024-12-17 03:15:08,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:08,267][root][INFO] - Training Epoch: 2/2, step 6715/7134 completed (loss: 0.08074906468391418, acc: 0.9748822450637817)
[2024-12-17 03:15:08,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:08,597][root][INFO] - Training Epoch: 2/2, step 6716/7134 completed (loss: 0.026402683928608894, acc: 0.9910179376602173)
[2024-12-17 03:15:08,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:08,920][root][INFO] - Training Epoch: 2/2, step 6717/7134 completed (loss: 0.032959263771772385, acc: 0.990338146686554)
[2024-12-17 03:15:09,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:09,242][root][INFO] - Training Epoch: 2/2, step 6718/7134 completed (loss: 0.07588918507099152, acc: 0.9803030490875244)
[2024-12-17 03:15:09,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:09,566][root][INFO] - Training Epoch: 2/2, step 6719/7134 completed (loss: 0.043456289917230606, acc: 0.9869281053543091)
[2024-12-17 03:15:09,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:09,899][root][INFO] - Training Epoch: 2/2, step 6720/7134 completed (loss: 0.07545022666454315, acc: 0.9818435907363892)
[2024-12-17 03:15:09,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:10,203][root][INFO] - Training Epoch: 2/2, step 6721/7134 completed (loss: 0.07421278953552246, acc: 0.9843993782997131)
[2024-12-17 03:15:10,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:10,461][root][INFO] - Training Epoch: 2/2, step 6722/7134 completed (loss: 0.10319744050502777, acc: 0.9771528840065002)
[2024-12-17 03:15:10,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:10,808][root][INFO] - Training Epoch: 2/2, step 6723/7134 completed (loss: 0.03863086923956871, acc: 0.9888888597488403)
[2024-12-17 03:15:10,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:11,132][root][INFO] - Training Epoch: 2/2, step 6724/7134 completed (loss: 0.049122050404548645, acc: 0.9868228435516357)
[2024-12-17 03:15:11,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:11,426][root][INFO] - Training Epoch: 2/2, step 6725/7134 completed (loss: 0.041001707315444946, acc: 0.9846416115760803)
[2024-12-17 03:15:11,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:11,745][root][INFO] - Training Epoch: 2/2, step 6726/7134 completed (loss: 0.09299911558628082, acc: 0.977911651134491)
[2024-12-17 03:15:11,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:12,060][root][INFO] - Training Epoch: 2/2, step 6727/7134 completed (loss: 0.06729525327682495, acc: 0.9823943376541138)
[2024-12-17 03:15:12,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:12,402][root][INFO] - Training Epoch: 2/2, step 6728/7134 completed (loss: 0.07416198402643204, acc: 0.9861751198768616)
[2024-12-17 03:15:12,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:12,753][root][INFO] - Training Epoch: 2/2, step 6729/7134 completed (loss: 0.029698288068175316, acc: 0.9932065010070801)
[2024-12-17 03:15:12,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:13,111][root][INFO] - Training Epoch: 2/2, step 6730/7134 completed (loss: 0.047853149473667145, acc: 0.9890109896659851)
[2024-12-17 03:15:13,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:13,464][root][INFO] - Training Epoch: 2/2, step 6731/7134 completed (loss: 0.03825471177697182, acc: 0.9864253401756287)
[2024-12-17 03:15:13,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:13,787][root][INFO] - Training Epoch: 2/2, step 6732/7134 completed (loss: 0.048563119024038315, acc: 0.9889937043190002)
[2024-12-17 03:15:13,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:14,108][root][INFO] - Training Epoch: 2/2, step 6733/7134 completed (loss: 0.05982796102762222, acc: 0.9829221963882446)
[2024-12-17 03:15:14,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:14,428][root][INFO] - Training Epoch: 2/2, step 6734/7134 completed (loss: 0.07378366589546204, acc: 0.9813084006309509)
[2024-12-17 03:15:14,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:14,749][root][INFO] - Training Epoch: 2/2, step 6735/7134 completed (loss: 0.06740755587816238, acc: 0.9861751198768616)
[2024-12-17 03:15:14,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:15,114][root][INFO] - Training Epoch: 2/2, step 6736/7134 completed (loss: 0.07067123800516129, acc: 0.9818941354751587)
[2024-12-17 03:15:15,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:15,456][root][INFO] - Training Epoch: 2/2, step 6737/7134 completed (loss: 0.059211812913417816, acc: 0.9854133129119873)
[2024-12-17 03:15:15,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:15,777][root][INFO] - Training Epoch: 2/2, step 6738/7134 completed (loss: 0.06630165874958038, acc: 0.983208954334259)
[2024-12-17 03:15:15,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:16,050][root][INFO] - Training Epoch: 2/2, step 6739/7134 completed (loss: 0.03772741183638573, acc: 0.9889705777168274)
[2024-12-17 03:15:16,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:16,382][root][INFO] - Training Epoch: 2/2, step 6740/7134 completed (loss: 0.060147207230329514, acc: 0.9898132681846619)
[2024-12-17 03:15:16,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:16,716][root][INFO] - Training Epoch: 2/2, step 6741/7134 completed (loss: 0.027705246582627296, acc: 0.9912917017936707)
[2024-12-17 03:15:16,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:17,028][root][INFO] - Training Epoch: 2/2, step 6742/7134 completed (loss: 0.0143121974542737, acc: 0.9942280054092407)
[2024-12-17 03:15:17,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:17,398][root][INFO] - Training Epoch: 2/2, step 6743/7134 completed (loss: 0.018550943583250046, acc: 0.9945504069328308)
[2024-12-17 03:15:17,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:17,752][root][INFO] - Training Epoch: 2/2, step 6744/7134 completed (loss: 0.03845495358109474, acc: 0.9839743375778198)
[2024-12-17 03:15:17,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:18,093][root][INFO] - Training Epoch: 2/2, step 6745/7134 completed (loss: 0.010722820647060871, acc: 0.9972489476203918)
[2024-12-17 03:15:18,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:18,406][root][INFO] - Training Epoch: 2/2, step 6746/7134 completed (loss: 0.02193603292107582, acc: 0.9964726567268372)
[2024-12-17 03:15:18,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:18,763][root][INFO] - Training Epoch: 2/2, step 6747/7134 completed (loss: 0.030159125104546547, acc: 0.9937888383865356)
[2024-12-17 03:15:18,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:19,149][root][INFO] - Training Epoch: 2/2, step 6748/7134 completed (loss: 0.023990197107195854, acc: 0.9977452158927917)
[2024-12-17 03:15:19,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:19,530][root][INFO] - Training Epoch: 2/2, step 6749/7134 completed (loss: 0.02758661098778248, acc: 0.9912853837013245)
[2024-12-17 03:15:19,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:19,900][root][INFO] - Training Epoch: 2/2, step 6750/7134 completed (loss: 0.019425468519330025, acc: 0.9965397715568542)
[2024-12-17 03:15:20,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:20,278][root][INFO] - Training Epoch: 2/2, step 6751/7134 completed (loss: 0.01736368238925934, acc: 0.9954338073730469)
[2024-12-17 03:15:20,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:20,614][root][INFO] - Training Epoch: 2/2, step 6752/7134 completed (loss: 0.009763678535819054, acc: 1.0)
[2024-12-17 03:15:20,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:20,974][root][INFO] - Training Epoch: 2/2, step 6753/7134 completed (loss: 0.019511641934514046, acc: 0.9954128265380859)
[2024-12-17 03:15:21,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:21,308][root][INFO] - Training Epoch: 2/2, step 6754/7134 completed (loss: 0.009875169955193996, acc: 0.9987951517105103)
[2024-12-17 03:15:21,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:21,663][root][INFO] - Training Epoch: 2/2, step 6755/7134 completed (loss: 0.019732287153601646, acc: 0.9926108121871948)
[2024-12-17 03:15:21,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:22,007][root][INFO] - Training Epoch: 2/2, step 6756/7134 completed (loss: 0.006758403033018112, acc: 0.9986594915390015)
[2024-12-17 03:15:22,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:22,328][root][INFO] - Training Epoch: 2/2, step 6757/7134 completed (loss: 0.03238000348210335, acc: 0.9893292784690857)
[2024-12-17 03:15:22,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:22,670][root][INFO] - Training Epoch: 2/2, step 6758/7134 completed (loss: 0.016838453710079193, acc: 0.9948253631591797)
[2024-12-17 03:15:22,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:23,036][root][INFO] - Training Epoch: 2/2, step 6759/7134 completed (loss: 0.028152819722890854, acc: 0.9921700358390808)
[2024-12-17 03:15:23,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:23,390][root][INFO] - Training Epoch: 2/2, step 6760/7134 completed (loss: 0.027732471004128456, acc: 0.990813672542572)
[2024-12-17 03:15:23,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:23,733][root][INFO] - Training Epoch: 2/2, step 6761/7134 completed (loss: 0.04234480857849121, acc: 0.9891566038131714)
[2024-12-17 03:15:23,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:24,089][root][INFO] - Training Epoch: 2/2, step 6762/7134 completed (loss: 0.049824535846710205, acc: 0.9852941036224365)
[2024-12-17 03:15:24,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:24,445][root][INFO] - Training Epoch: 2/2, step 6763/7134 completed (loss: 0.01795579493045807, acc: 0.9962359070777893)
[2024-12-17 03:15:24,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:24,767][root][INFO] - Training Epoch: 2/2, step 6764/7134 completed (loss: 0.02561676874756813, acc: 0.9899425506591797)
[2024-12-17 03:15:24,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:25,146][root][INFO] - Training Epoch: 2/2, step 6765/7134 completed (loss: 0.023228032514452934, acc: 0.9906790852546692)
[2024-12-17 03:15:25,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:25,467][root][INFO] - Training Epoch: 2/2, step 6766/7134 completed (loss: 0.020234020426869392, acc: 0.9958620667457581)
[2024-12-17 03:15:25,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:25,716][root][INFO] - Training Epoch: 2/2, step 6767/7134 completed (loss: 0.036192674189805984, acc: 0.9909909963607788)
[2024-12-17 03:15:25,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:26,069][root][INFO] - Training Epoch: 2/2, step 6768/7134 completed (loss: 0.016880791634321213, acc: 0.9961977005004883)
[2024-12-17 03:15:26,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:26,394][root][INFO] - Training Epoch: 2/2, step 6769/7134 completed (loss: 0.023044392466545105, acc: 0.9907407164573669)
[2024-12-17 03:15:26,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:26,744][root][INFO] - Training Epoch: 2/2, step 6770/7134 completed (loss: 0.05596492066979408, acc: 0.9838926196098328)
[2024-12-17 03:15:26,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:27,094][root][INFO] - Training Epoch: 2/2, step 6771/7134 completed (loss: 0.03122761659324169, acc: 0.9905362725257874)
[2024-12-17 03:15:27,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:27,437][root][INFO] - Training Epoch: 2/2, step 6772/7134 completed (loss: 0.11858490109443665, acc: 0.9803921580314636)
[2024-12-17 03:15:27,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:27,753][root][INFO] - Training Epoch: 2/2, step 6773/7134 completed (loss: 0.045472681522369385, acc: 0.9841772317886353)
[2024-12-17 03:15:27,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:28,095][root][INFO] - Training Epoch: 2/2, step 6774/7134 completed (loss: 0.059885066002607346, acc: 0.9824841022491455)
[2024-12-17 03:15:28,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:28,417][root][INFO] - Training Epoch: 2/2, step 6775/7134 completed (loss: 0.024364611133933067, acc: 0.9905481934547424)
[2024-12-17 03:15:28,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:28,746][root][INFO] - Training Epoch: 2/2, step 6776/7134 completed (loss: 0.056062646210193634, acc: 0.9851064085960388)
[2024-12-17 03:15:28,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:29,081][root][INFO] - Training Epoch: 2/2, step 6777/7134 completed (loss: 0.041425950825214386, acc: 0.9892617464065552)
[2024-12-17 03:15:29,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:29,436][root][INFO] - Training Epoch: 2/2, step 6778/7134 completed (loss: 0.06335562467575073, acc: 0.9866270422935486)
[2024-12-17 03:15:29,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:29,771][root][INFO] - Training Epoch: 2/2, step 6779/7134 completed (loss: 0.03366381302475929, acc: 0.9850746393203735)
[2024-12-17 03:15:29,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:30,115][root][INFO] - Training Epoch: 2/2, step 6780/7134 completed (loss: 0.02513078600168228, acc: 0.9925261735916138)
[2024-12-17 03:15:30,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:30,466][root][INFO] - Training Epoch: 2/2, step 6781/7134 completed (loss: 0.034849148243665695, acc: 0.992514967918396)
[2024-12-17 03:15:30,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:30,804][root][INFO] - Training Epoch: 2/2, step 6782/7134 completed (loss: 0.03219740092754364, acc: 0.9895833134651184)
[2024-12-17 03:15:30,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:31,083][root][INFO] - Training Epoch: 2/2, step 6783/7134 completed (loss: 0.057327721267938614, acc: 0.9904030561447144)
[2024-12-17 03:15:31,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:31,418][root][INFO] - Training Epoch: 2/2, step 6784/7134 completed (loss: 0.03614705055952072, acc: 0.9900166392326355)
[2024-12-17 03:15:31,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:31,751][root][INFO] - Training Epoch: 2/2, step 6785/7134 completed (loss: 0.01694495975971222, acc: 0.9952830076217651)
[2024-12-17 03:15:31,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:32,111][root][INFO] - Training Epoch: 2/2, step 6786/7134 completed (loss: 0.013264943845570087, acc: 0.9956834316253662)
[2024-12-17 03:15:32,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:32,463][root][INFO] - Training Epoch: 2/2, step 6787/7134 completed (loss: 0.03976661339402199, acc: 0.9881578683853149)
[2024-12-17 03:15:32,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:32,789][root][INFO] - Training Epoch: 2/2, step 6788/7134 completed (loss: 0.059851791709661484, acc: 0.980215847492218)
[2024-12-17 03:15:32,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:33,111][root][INFO] - Training Epoch: 2/2, step 6789/7134 completed (loss: 0.027803009375929832, acc: 0.9902724027633667)
[2024-12-17 03:15:33,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:33,457][root][INFO] - Training Epoch: 2/2, step 6790/7134 completed (loss: 0.07296847552061081, acc: 0.9856321811676025)
[2024-12-17 03:15:33,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:33,784][root][INFO] - Training Epoch: 2/2, step 6791/7134 completed (loss: 0.031529881060123444, acc: 0.9897785186767578)
[2024-12-17 03:15:33,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:34,126][root][INFO] - Training Epoch: 2/2, step 6792/7134 completed (loss: 0.027257906273007393, acc: 0.9926605224609375)
[2024-12-17 03:15:34,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:34,480][root][INFO] - Training Epoch: 2/2, step 6793/7134 completed (loss: 0.028092490509152412, acc: 0.9957805871963501)
[2024-12-17 03:15:34,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:34,813][root][INFO] - Training Epoch: 2/2, step 6794/7134 completed (loss: 0.05259980261325836, acc: 0.9901477694511414)
[2024-12-17 03:15:34,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:35,158][root][INFO] - Training Epoch: 2/2, step 6795/7134 completed (loss: 0.020393356680870056, acc: 0.9935064911842346)
[2024-12-17 03:15:35,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:35,492][root][INFO] - Training Epoch: 2/2, step 6796/7134 completed (loss: 0.025660855695605278, acc: 0.992668628692627)
[2024-12-17 03:15:35,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:35,840][root][INFO] - Training Epoch: 2/2, step 6797/7134 completed (loss: 0.045612893998622894, acc: 0.9810771346092224)
[2024-12-17 03:15:35,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:36,169][root][INFO] - Training Epoch: 2/2, step 6798/7134 completed (loss: 0.04238647595047951, acc: 0.9889807105064392)
[2024-12-17 03:15:36,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:36,499][root][INFO] - Training Epoch: 2/2, step 6799/7134 completed (loss: 0.03297819569706917, acc: 0.99452805519104)
[2024-12-17 03:15:36,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:36,818][root][INFO] - Training Epoch: 2/2, step 6800/7134 completed (loss: 0.032809387892484665, acc: 0.9875690340995789)
[2024-12-17 03:15:36,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:37,175][root][INFO] - Training Epoch: 2/2, step 6801/7134 completed (loss: 0.03510389104485512, acc: 0.9889763593673706)
[2024-12-17 03:15:37,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:37,497][root][INFO] - Training Epoch: 2/2, step 6802/7134 completed (loss: 0.019420132040977478, acc: 0.9956076145172119)
[2024-12-17 03:15:37,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:37,840][root][INFO] - Training Epoch: 2/2, step 6803/7134 completed (loss: 0.02036602422595024, acc: 0.9911949634552002)
[2024-12-17 03:15:37,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:38,164][root][INFO] - Training Epoch: 2/2, step 6804/7134 completed (loss: 0.04876893013715744, acc: 0.9937499761581421)
[2024-12-17 03:15:38,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:38,519][root][INFO] - Training Epoch: 2/2, step 6805/7134 completed (loss: 0.05664239078760147, acc: 0.9807692170143127)
[2024-12-17 03:15:38,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:38,869][root][INFO] - Training Epoch: 2/2, step 6806/7134 completed (loss: 0.06202665716409683, acc: 0.9898734092712402)
[2024-12-17 03:15:38,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:39,237][root][INFO] - Training Epoch: 2/2, step 6807/7134 completed (loss: 0.025416506454348564, acc: 0.9913793206214905)
[2024-12-17 03:15:39,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:39,570][root][INFO] - Training Epoch: 2/2, step 6808/7134 completed (loss: 0.04119863361120224, acc: 0.9872408509254456)
[2024-12-17 03:15:39,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:39,921][root][INFO] - Training Epoch: 2/2, step 6809/7134 completed (loss: 0.035038337111473083, acc: 0.9918699264526367)
[2024-12-17 03:15:40,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:40,245][root][INFO] - Training Epoch: 2/2, step 6810/7134 completed (loss: 0.015008271671831608, acc: 0.99210524559021)
[2024-12-17 03:15:40,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:40,607][root][INFO] - Training Epoch: 2/2, step 6811/7134 completed (loss: 0.06718684732913971, acc: 0.9816513657569885)
[2024-12-17 03:15:40,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:40,933][root][INFO] - Training Epoch: 2/2, step 6812/7134 completed (loss: 0.03573745861649513, acc: 0.9886547923088074)
[2024-12-17 03:15:41,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:41,270][root][INFO] - Training Epoch: 2/2, step 6813/7134 completed (loss: 0.011416316032409668, acc: 0.9985915422439575)
[2024-12-17 03:15:41,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:41,606][root][INFO] - Training Epoch: 2/2, step 6814/7134 completed (loss: 0.020919200032949448, acc: 0.9919354915618896)
[2024-12-17 03:15:41,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:41,948][root][INFO] - Training Epoch: 2/2, step 6815/7134 completed (loss: 0.021695692092180252, acc: 0.9894875288009644)
[2024-12-17 03:15:42,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:42,283][root][INFO] - Training Epoch: 2/2, step 6816/7134 completed (loss: 0.030000055208802223, acc: 0.9933110475540161)
[2024-12-17 03:15:42,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:42,644][root][INFO] - Training Epoch: 2/2, step 6817/7134 completed (loss: 0.057633403688669205, acc: 0.988034188747406)
[2024-12-17 03:15:42,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:42,985][root][INFO] - Training Epoch: 2/2, step 6818/7134 completed (loss: 0.02021467685699463, acc: 0.9940029978752136)
[2024-12-17 03:15:43,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:43,327][root][INFO] - Training Epoch: 2/2, step 6819/7134 completed (loss: 0.053531065583229065, acc: 0.9892086386680603)
[2024-12-17 03:15:43,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:43,654][root][INFO] - Training Epoch: 2/2, step 6820/7134 completed (loss: 0.028567275032401085, acc: 0.9927927851676941)
[2024-12-17 03:15:43,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:43,925][root][INFO] - Training Epoch: 2/2, step 6821/7134 completed (loss: 0.03433592990040779, acc: 0.9878787994384766)
[2024-12-17 03:15:44,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:44,263][root][INFO] - Training Epoch: 2/2, step 6822/7134 completed (loss: 0.057802390307188034, acc: 0.9773123860359192)
[2024-12-17 03:15:44,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:44,601][root][INFO] - Training Epoch: 2/2, step 6823/7134 completed (loss: 0.04075668752193451, acc: 0.9856938719749451)
[2024-12-17 03:15:44,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:44,904][root][INFO] - Training Epoch: 2/2, step 6824/7134 completed (loss: 0.07408436387777328, acc: 0.9798387289047241)
[2024-12-17 03:15:45,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:45,217][root][INFO] - Training Epoch: 2/2, step 6825/7134 completed (loss: 0.02436189353466034, acc: 0.9902439117431641)
[2024-12-17 03:15:45,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:45,525][root][INFO] - Training Epoch: 2/2, step 6826/7134 completed (loss: 0.0529024712741375, acc: 0.9882155060768127)
[2024-12-17 03:15:45,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:45,869][root][INFO] - Training Epoch: 2/2, step 6827/7134 completed (loss: 0.10120178759098053, acc: 0.9755154848098755)
[2024-12-17 03:15:46,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:46,234][root][INFO] - Training Epoch: 2/2, step 6828/7134 completed (loss: 0.06995729357004166, acc: 0.970802903175354)
[2024-12-17 03:15:46,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:46,576][root][INFO] - Training Epoch: 2/2, step 6829/7134 completed (loss: 0.06233607977628708, acc: 0.9821958541870117)
[2024-12-17 03:15:46,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:46,893][root][INFO] - Training Epoch: 2/2, step 6830/7134 completed (loss: 0.04466082155704498, acc: 0.9901153445243835)
[2024-12-17 03:15:46,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:47,226][root][INFO] - Training Epoch: 2/2, step 6831/7134 completed (loss: 0.039918456226587296, acc: 0.9892473220825195)
[2024-12-17 03:15:47,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:47,556][root][INFO] - Training Epoch: 2/2, step 6832/7134 completed (loss: 0.03553440421819687, acc: 0.9944547414779663)
[2024-12-17 03:15:47,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:47,882][root][INFO] - Training Epoch: 2/2, step 6833/7134 completed (loss: 0.04810725897550583, acc: 0.9839228391647339)
[2024-12-17 03:15:47,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:48,159][root][INFO] - Training Epoch: 2/2, step 6834/7134 completed (loss: 0.058360982686281204, acc: 0.9795570969581604)
[2024-12-17 03:15:48,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:48,475][root][INFO] - Training Epoch: 2/2, step 6835/7134 completed (loss: 0.050364233553409576, acc: 0.9788960814476013)
[2024-12-17 03:15:48,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:48,797][root][INFO] - Training Epoch: 2/2, step 6836/7134 completed (loss: 0.05383830890059471, acc: 0.9849246144294739)
[2024-12-17 03:15:48,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:49,158][root][INFO] - Training Epoch: 2/2, step 6837/7134 completed (loss: 0.041382238268852234, acc: 0.9889570474624634)
[2024-12-17 03:15:49,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:49,478][root][INFO] - Training Epoch: 2/2, step 6838/7134 completed (loss: 0.07937046140432358, acc: 0.9814814925193787)
[2024-12-17 03:15:49,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:49,785][root][INFO] - Training Epoch: 2/2, step 6839/7134 completed (loss: 0.1183207556605339, acc: 0.9702970385551453)
[2024-12-17 03:15:49,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:50,134][root][INFO] - Training Epoch: 2/2, step 6840/7134 completed (loss: 0.07886242866516113, acc: 0.9799426794052124)
[2024-12-17 03:15:50,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:50,459][root][INFO] - Training Epoch: 2/2, step 6841/7134 completed (loss: 0.050101496279239655, acc: 0.9826839566230774)
[2024-12-17 03:15:50,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:50,822][root][INFO] - Training Epoch: 2/2, step 6842/7134 completed (loss: 0.031353291124105453, acc: 0.9899749159812927)
[2024-12-17 03:15:50,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:51,182][root][INFO] - Training Epoch: 2/2, step 6843/7134 completed (loss: 0.054238032549619675, acc: 0.9815043210983276)
[2024-12-17 03:15:51,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:51,510][root][INFO] - Training Epoch: 2/2, step 6844/7134 completed (loss: 0.031155627220869064, acc: 0.9861830472946167)
[2024-12-17 03:15:51,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:51,866][root][INFO] - Training Epoch: 2/2, step 6845/7134 completed (loss: 0.024006756022572517, acc: 0.9965986609458923)
[2024-12-17 03:15:51,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:52,190][root][INFO] - Training Epoch: 2/2, step 6846/7134 completed (loss: 0.036967165768146515, acc: 0.9914039969444275)
[2024-12-17 03:15:52,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:52,528][root][INFO] - Training Epoch: 2/2, step 6847/7134 completed (loss: 0.06704080104827881, acc: 0.9803030490875244)
[2024-12-17 03:15:52,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:52,841][root][INFO] - Training Epoch: 2/2, step 6848/7134 completed (loss: 0.020816778764128685, acc: 0.9945945739746094)
[2024-12-17 03:15:52,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:53,178][root][INFO] - Training Epoch: 2/2, step 6849/7134 completed (loss: 0.03574543446302414, acc: 0.9914089441299438)
[2024-12-17 03:15:53,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:53,505][root][INFO] - Training Epoch: 2/2, step 6850/7134 completed (loss: 0.07381867617368698, acc: 0.9794050455093384)
[2024-12-17 03:15:53,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:53,848][root][INFO] - Training Epoch: 2/2, step 6851/7134 completed (loss: 0.06499404460191727, acc: 0.9802538752555847)
[2024-12-17 03:15:53,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:54,192][root][INFO] - Training Epoch: 2/2, step 6852/7134 completed (loss: 0.028763337060809135, acc: 0.9912587404251099)
[2024-12-17 03:15:54,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:54,567][root][INFO] - Training Epoch: 2/2, step 6853/7134 completed (loss: 0.046234358102083206, acc: 0.9875518679618835)
[2024-12-17 03:15:54,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:54,840][root][INFO] - Training Epoch: 2/2, step 6854/7134 completed (loss: 0.06080428510904312, acc: 0.9869847893714905)
[2024-12-17 03:15:54,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:55,153][root][INFO] - Training Epoch: 2/2, step 6855/7134 completed (loss: 0.025955382734537125, acc: 0.9952830076217651)
[2024-12-17 03:15:55,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:55,489][root][INFO] - Training Epoch: 2/2, step 6856/7134 completed (loss: 0.008449769578874111, acc: 0.9985693693161011)
[2024-12-17 03:15:55,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:55,842][root][INFO] - Training Epoch: 2/2, step 6857/7134 completed (loss: 0.03144987300038338, acc: 0.9956011772155762)
[2024-12-17 03:15:55,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:56,106][root][INFO] - Training Epoch: 2/2, step 6858/7134 completed (loss: 0.0046762144193053246, acc: 1.0)
[2024-12-17 03:15:56,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:56,467][root][INFO] - Training Epoch: 2/2, step 6859/7134 completed (loss: 0.016698220744729042, acc: 0.99615877866745)
[2024-12-17 03:15:56,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:56,801][root][INFO] - Training Epoch: 2/2, step 6860/7134 completed (loss: 0.016612472012639046, acc: 0.9982269406318665)
[2024-12-17 03:15:56,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:57,110][root][INFO] - Training Epoch: 2/2, step 6861/7134 completed (loss: 0.013436674140393734, acc: 0.9982699155807495)
[2024-12-17 03:15:57,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:57,468][root][INFO] - Training Epoch: 2/2, step 6862/7134 completed (loss: 0.033925317227840424, acc: 0.9923809766769409)
[2024-12-17 03:15:57,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:57,797][root][INFO] - Training Epoch: 2/2, step 6863/7134 completed (loss: 0.024989791214466095, acc: 0.994350254535675)
[2024-12-17 03:15:57,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:58,158][root][INFO] - Training Epoch: 2/2, step 6864/7134 completed (loss: 0.019303690642118454, acc: 0.9916805028915405)
[2024-12-17 03:15:58,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:58,491][root][INFO] - Training Epoch: 2/2, step 6865/7134 completed (loss: 0.04549875110387802, acc: 0.9876288771629333)
[2024-12-17 03:15:58,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:58,811][root][INFO] - Training Epoch: 2/2, step 6866/7134 completed (loss: 0.007177417632192373, acc: 0.9984802603721619)
[2024-12-17 03:15:58,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:59,144][root][INFO] - Training Epoch: 2/2, step 6867/7134 completed (loss: 0.009747005067765713, acc: 0.9944444298744202)
[2024-12-17 03:15:59,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:59,399][root][INFO] - Training Epoch: 2/2, step 6868/7134 completed (loss: 0.004199448972940445, acc: 1.0)
[2024-12-17 03:15:59,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:59,681][root][INFO] - Training Epoch: 2/2, step 6869/7134 completed (loss: 0.012857085093855858, acc: 0.9957173466682434)
[2024-12-17 03:15:59,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:00,041][root][INFO] - Training Epoch: 2/2, step 6870/7134 completed (loss: 0.021007265895605087, acc: 0.9951140284538269)
[2024-12-17 03:16:00,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:00,396][root][INFO] - Training Epoch: 2/2, step 6871/7134 completed (loss: 0.0036126018967479467, acc: 1.0)
[2024-12-17 03:16:00,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:00,723][root][INFO] - Training Epoch: 2/2, step 6872/7134 completed (loss: 0.010248592123389244, acc: 0.9986149668693542)
[2024-12-17 03:16:00,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:01,073][root][INFO] - Training Epoch: 2/2, step 6873/7134 completed (loss: 0.00440734950825572, acc: 1.0)
[2024-12-17 03:16:01,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:01,414][root][INFO] - Training Epoch: 2/2, step 6874/7134 completed (loss: 0.014903723262250423, acc: 0.9964538812637329)
[2024-12-17 03:16:01,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:01,750][root][INFO] - Training Epoch: 2/2, step 6875/7134 completed (loss: 0.014564921148121357, acc: 0.9953632354736328)
[2024-12-17 03:16:01,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:02,068][root][INFO] - Training Epoch: 2/2, step 6876/7134 completed (loss: 0.03324193134903908, acc: 0.9932318329811096)
[2024-12-17 03:16:02,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:02,422][root][INFO] - Training Epoch: 2/2, step 6877/7134 completed (loss: 0.023553799837827682, acc: 0.9957864880561829)
[2024-12-17 03:16:02,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:02,771][root][INFO] - Training Epoch: 2/2, step 6878/7134 completed (loss: 0.014038598164916039, acc: 0.995502233505249)
[2024-12-17 03:16:02,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:03,044][root][INFO] - Training Epoch: 2/2, step 6879/7134 completed (loss: 0.023012926802039146, acc: 0.991631805896759)
[2024-12-17 03:16:03,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:03,410][root][INFO] - Training Epoch: 2/2, step 6880/7134 completed (loss: 0.017469702288508415, acc: 0.9941792488098145)
[2024-12-17 03:16:03,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:03,764][root][INFO] - Training Epoch: 2/2, step 6881/7134 completed (loss: 0.06351558119058609, acc: 0.9878493547439575)
[2024-12-17 03:16:03,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:04,064][root][INFO] - Training Epoch: 2/2, step 6882/7134 completed (loss: 0.046702444553375244, acc: 0.981203019618988)
[2024-12-17 03:16:04,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:04,384][root][INFO] - Training Epoch: 2/2, step 6883/7134 completed (loss: 0.019519653171300888, acc: 0.9933993220329285)
[2024-12-17 03:16:04,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:04,733][root][INFO] - Training Epoch: 2/2, step 6884/7134 completed (loss: 0.0676376149058342, acc: 0.989924430847168)
[2024-12-17 03:16:04,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:05,036][root][INFO] - Training Epoch: 2/2, step 6885/7134 completed (loss: 0.04015519842505455, acc: 0.9888392686843872)
[2024-12-17 03:16:05,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:05,362][root][INFO] - Training Epoch: 2/2, step 6886/7134 completed (loss: 0.023992503061890602, acc: 0.9904912710189819)
[2024-12-17 03:16:05,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:05,672][root][INFO] - Training Epoch: 2/2, step 6887/7134 completed (loss: 0.03641972318291664, acc: 0.987679660320282)
[2024-12-17 03:16:05,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:06,024][root][INFO] - Training Epoch: 2/2, step 6888/7134 completed (loss: 0.02934788167476654, acc: 0.9933554530143738)
[2024-12-17 03:16:06,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:06,373][root][INFO] - Training Epoch: 2/2, step 6889/7134 completed (loss: 0.015749048441648483, acc: 0.9969372153282166)
[2024-12-17 03:16:06,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:06,725][root][INFO] - Training Epoch: 2/2, step 6890/7134 completed (loss: 0.030075425282120705, acc: 0.9920739531517029)
[2024-12-17 03:16:06,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:07,051][root][INFO] - Training Epoch: 2/2, step 6891/7134 completed (loss: 0.03422722592949867, acc: 0.9911110997200012)
[2024-12-17 03:16:07,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:07,401][root][INFO] - Training Epoch: 2/2, step 6892/7134 completed (loss: 0.03124665468931198, acc: 0.98828125)
[2024-12-17 03:16:07,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:07,748][root][INFO] - Training Epoch: 2/2, step 6893/7134 completed (loss: 0.05668104812502861, acc: 0.9719626307487488)
[2024-12-17 03:16:07,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:08,102][root][INFO] - Training Epoch: 2/2, step 6894/7134 completed (loss: 0.07110713422298431, acc: 0.9828947186470032)
[2024-12-17 03:16:08,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:08,456][root][INFO] - Training Epoch: 2/2, step 6895/7134 completed (loss: 0.0472630076110363, acc: 0.9832134246826172)
[2024-12-17 03:16:08,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:08,762][root][INFO] - Training Epoch: 2/2, step 6896/7134 completed (loss: 0.02527545392513275, acc: 0.9942029118537903)
[2024-12-17 03:16:08,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:09,112][root][INFO] - Training Epoch: 2/2, step 6897/7134 completed (loss: 0.023221813142299652, acc: 0.9950920343399048)
[2024-12-17 03:16:09,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:09,449][root][INFO] - Training Epoch: 2/2, step 6898/7134 completed (loss: 0.024368776008486748, acc: 0.9931318759918213)
[2024-12-17 03:16:09,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:09,808][root][INFO] - Training Epoch: 2/2, step 6899/7134 completed (loss: 0.03232429176568985, acc: 0.9899497628211975)
[2024-12-17 03:16:09,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:10,161][root][INFO] - Training Epoch: 2/2, step 6900/7134 completed (loss: 0.030719341710209846, acc: 0.987270176410675)
[2024-12-17 03:16:10,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:10,516][root][INFO] - Training Epoch: 2/2, step 6901/7134 completed (loss: 0.032337386161088943, acc: 0.9867899417877197)
[2024-12-17 03:16:10,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:10,885][root][INFO] - Training Epoch: 2/2, step 6902/7134 completed (loss: 0.038352321833372116, acc: 0.9889042973518372)
[2024-12-17 03:16:10,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:11,234][root][INFO] - Training Epoch: 2/2, step 6903/7134 completed (loss: 0.024224668741226196, acc: 0.9923954606056213)
[2024-12-17 03:16:11,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:11,591][root][INFO] - Training Epoch: 2/2, step 6904/7134 completed (loss: 0.015844063833355904, acc: 0.9937810897827148)
[2024-12-17 03:16:11,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:11,952][root][INFO] - Training Epoch: 2/2, step 6905/7134 completed (loss: 0.027776962146162987, acc: 0.9897698163986206)
[2024-12-17 03:16:12,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:12,321][root][INFO] - Training Epoch: 2/2, step 6906/7134 completed (loss: 0.03225657716393471, acc: 0.9964072108268738)
[2024-12-17 03:16:12,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:12,679][root][INFO] - Training Epoch: 2/2, step 6907/7134 completed (loss: 0.0355985127389431, acc: 0.9913151264190674)
[2024-12-17 03:16:12,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:13,028][root][INFO] - Training Epoch: 2/2, step 6908/7134 completed (loss: 0.04869913309812546, acc: 0.9870466589927673)
[2024-12-17 03:16:13,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:13,377][root][INFO] - Training Epoch: 2/2, step 6909/7134 completed (loss: 0.026042724028229713, acc: 0.9934210777282715)
[2024-12-17 03:16:13,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:13,723][root][INFO] - Training Epoch: 2/2, step 6910/7134 completed (loss: 0.014043589122593403, acc: 0.9961783289909363)
[2024-12-17 03:16:13,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:14,028][root][INFO] - Training Epoch: 2/2, step 6911/7134 completed (loss: 0.05351722612977028, acc: 0.9854651093482971)
[2024-12-17 03:16:14,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:14,384][root][INFO] - Training Epoch: 2/2, step 6912/7134 completed (loss: 0.0351116769015789, acc: 0.9937577843666077)
[2024-12-17 03:16:14,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:14,796][root][INFO] - Training Epoch: 2/2, step 6913/7134 completed (loss: 0.0441557839512825, acc: 0.986601710319519)
[2024-12-17 03:16:14,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:15,115][root][INFO] - Training Epoch: 2/2, step 6914/7134 completed (loss: 0.09925469011068344, acc: 0.9764309525489807)
[2024-12-17 03:16:15,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:15,466][root][INFO] - Training Epoch: 2/2, step 6915/7134 completed (loss: 0.020942362025380135, acc: 0.9922279715538025)
[2024-12-17 03:16:15,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:15,828][root][INFO] - Training Epoch: 2/2, step 6916/7134 completed (loss: 0.038625266402959824, acc: 0.9901840686798096)
[2024-12-17 03:16:15,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:16,200][root][INFO] - Training Epoch: 2/2, step 6917/7134 completed (loss: 0.05331982672214508, acc: 0.9861111044883728)
[2024-12-17 03:16:16,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:16,532][root][INFO] - Training Epoch: 2/2, step 6918/7134 completed (loss: 0.02375325746834278, acc: 0.9918032884597778)
[2024-12-17 03:16:16,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:16,881][root][INFO] - Training Epoch: 2/2, step 6919/7134 completed (loss: 0.053765881806612015, acc: 0.9884659647941589)
[2024-12-17 03:16:16,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:17,202][root][INFO] - Training Epoch: 2/2, step 6920/7134 completed (loss: 0.0268174409866333, acc: 0.9914529919624329)
[2024-12-17 03:16:17,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:17,564][root][INFO] - Training Epoch: 2/2, step 6921/7134 completed (loss: 0.07314849644899368, acc: 0.986143171787262)
[2024-12-17 03:16:17,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:17,866][root][INFO] - Training Epoch: 2/2, step 6922/7134 completed (loss: 0.06400205940008163, acc: 0.9828392863273621)
[2024-12-17 03:16:17,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:18,223][root][INFO] - Training Epoch: 2/2, step 6923/7134 completed (loss: 0.04911717399954796, acc: 0.9902724027633667)
[2024-12-17 03:16:18,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:18,574][root][INFO] - Training Epoch: 2/2, step 6924/7134 completed (loss: 0.03049907647073269, acc: 0.9918256402015686)
[2024-12-17 03:16:18,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:18,915][root][INFO] - Training Epoch: 2/2, step 6925/7134 completed (loss: 0.02680039592087269, acc: 0.9921875)
[2024-12-17 03:16:19,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:19,254][root][INFO] - Training Epoch: 2/2, step 6926/7134 completed (loss: 0.03666764870285988, acc: 0.9891501069068909)
[2024-12-17 03:16:19,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:19,615][root][INFO] - Training Epoch: 2/2, step 6927/7134 completed (loss: 0.05753424018621445, acc: 0.9820144176483154)
[2024-12-17 03:16:19,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:19,924][root][INFO] - Training Epoch: 2/2, step 6928/7134 completed (loss: 0.05541956052184105, acc: 0.9902152419090271)
[2024-12-17 03:16:20,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:20,315][root][INFO] - Training Epoch: 2/2, step 6929/7134 completed (loss: 0.058612413704395294, acc: 0.9901130199432373)
[2024-12-17 03:16:20,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:20,681][root][INFO] - Training Epoch: 2/2, step 6930/7134 completed (loss: 0.06984928250312805, acc: 0.9875930547714233)
[2024-12-17 03:16:20,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:21,052][root][INFO] - Training Epoch: 2/2, step 6931/7134 completed (loss: 0.03611728921532631, acc: 0.9890244007110596)
[2024-12-17 03:16:21,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:21,376][root][INFO] - Training Epoch: 2/2, step 6932/7134 completed (loss: 0.058303698897361755, acc: 0.9867647290229797)
[2024-12-17 03:16:21,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:21,716][root][INFO] - Training Epoch: 2/2, step 6933/7134 completed (loss: 0.0858754813671112, acc: 0.9805951118469238)
[2024-12-17 03:16:21,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:22,026][root][INFO] - Training Epoch: 2/2, step 6934/7134 completed (loss: 0.06122040003538132, acc: 0.9823434948921204)
[2024-12-17 03:16:22,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:22,390][root][INFO] - Training Epoch: 2/2, step 6935/7134 completed (loss: 0.061982136219739914, acc: 0.9842932224273682)
[2024-12-17 03:16:22,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:22,753][root][INFO] - Training Epoch: 2/2, step 6936/7134 completed (loss: 0.0339042954146862, acc: 0.9919999837875366)
[2024-12-17 03:16:22,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:23,089][root][INFO] - Training Epoch: 2/2, step 6937/7134 completed (loss: 0.08981440961360931, acc: 0.9754816293716431)
[2024-12-17 03:16:23,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:23,463][root][INFO] - Training Epoch: 2/2, step 6938/7134 completed (loss: 0.1014375314116478, acc: 0.9703124761581421)
[2024-12-17 03:16:23,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:23,837][root][INFO] - Training Epoch: 2/2, step 6939/7134 completed (loss: 0.08027445524930954, acc: 0.9833101630210876)
[2024-12-17 03:16:23,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:24,159][root][INFO] - Training Epoch: 2/2, step 6940/7134 completed (loss: 0.11919370293617249, acc: 0.9691780805587769)
[2024-12-17 03:16:24,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:24,440][root][INFO] - Training Epoch: 2/2, step 6941/7134 completed (loss: 0.032600801438093185, acc: 0.9895833134651184)
[2024-12-17 03:16:24,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:24,763][root][INFO] - Training Epoch: 2/2, step 6942/7134 completed (loss: 0.06105287745594978, acc: 0.9780821800231934)
[2024-12-17 03:16:24,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:25,041][root][INFO] - Training Epoch: 2/2, step 6943/7134 completed (loss: 0.03746078163385391, acc: 0.991631805896759)
[2024-12-17 03:16:25,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:25,366][root][INFO] - Training Epoch: 2/2, step 6944/7134 completed (loss: 0.04932742565870285, acc: 0.9920381903648376)
[2024-12-17 03:16:25,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:25,652][root][INFO] - Training Epoch: 2/2, step 6945/7134 completed (loss: 0.09350655972957611, acc: 0.9808027744293213)
[2024-12-17 03:16:25,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:25,921][root][INFO] - Training Epoch: 2/2, step 6946/7134 completed (loss: 0.03882346302270889, acc: 0.9856733679771423)
[2024-12-17 03:16:26,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:26,242][root][INFO] - Training Epoch: 2/2, step 6947/7134 completed (loss: 0.056254178285598755, acc: 0.989130437374115)
[2024-12-17 03:16:26,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:26,579][root][INFO] - Training Epoch: 2/2, step 6948/7134 completed (loss: 0.0786794051527977, acc: 0.981574535369873)
[2024-12-17 03:16:26,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:26,895][root][INFO] - Training Epoch: 2/2, step 6949/7134 completed (loss: 0.082548126578331, acc: 0.9807692170143127)
[2024-12-17 03:16:26,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:27,154][root][INFO] - Training Epoch: 2/2, step 6950/7134 completed (loss: 0.04058285430073738, acc: 0.9923469424247742)
[2024-12-17 03:16:27,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:27,490][root][INFO] - Training Epoch: 2/2, step 6951/7134 completed (loss: 0.03535020351409912, acc: 0.989830493927002)
[2024-12-17 03:16:27,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:27,768][root][INFO] - Training Epoch: 2/2, step 6952/7134 completed (loss: 0.02165001630783081, acc: 0.9929906725883484)
[2024-12-17 03:16:27,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:28,093][root][INFO] - Training Epoch: 2/2, step 6953/7134 completed (loss: 0.020629575476050377, acc: 0.9934425950050354)
[2024-12-17 03:16:28,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:28,420][root][INFO] - Training Epoch: 2/2, step 6954/7134 completed (loss: 0.08070901781320572, acc: 0.9850746393203735)
[2024-12-17 03:16:28,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:28,721][root][INFO] - Training Epoch: 2/2, step 6955/7134 completed (loss: 0.05618099495768547, acc: 0.9756097793579102)
[2024-12-17 03:16:28,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:29,056][root][INFO] - Training Epoch: 2/2, step 6956/7134 completed (loss: 0.034892287105321884, acc: 0.9875665903091431)
[2024-12-17 03:16:29,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:29,377][root][INFO] - Training Epoch: 2/2, step 6957/7134 completed (loss: 0.023555805906653404, acc: 0.9921721816062927)
[2024-12-17 03:16:29,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:29,688][root][INFO] - Training Epoch: 2/2, step 6958/7134 completed (loss: 0.06246960163116455, acc: 0.9844054579734802)
[2024-12-17 03:16:29,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:30,005][root][INFO] - Training Epoch: 2/2, step 6959/7134 completed (loss: 0.03544953837990761, acc: 0.9911308288574219)
[2024-12-17 03:16:30,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:30,333][root][INFO] - Training Epoch: 2/2, step 6960/7134 completed (loss: 0.042192790657281876, acc: 0.9869918823242188)
[2024-12-17 03:16:30,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:30,653][root][INFO] - Training Epoch: 2/2, step 6961/7134 completed (loss: 0.05591153725981712, acc: 0.9939393997192383)
[2024-12-17 03:16:30,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:30,977][root][INFO] - Training Epoch: 2/2, step 6962/7134 completed (loss: 0.04389636591076851, acc: 0.9930434823036194)
[2024-12-17 03:16:31,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:31,307][root][INFO] - Training Epoch: 2/2, step 6963/7134 completed (loss: 0.01849237084388733, acc: 0.9949495196342468)
[2024-12-17 03:16:31,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:31,639][root][INFO] - Training Epoch: 2/2, step 6964/7134 completed (loss: 0.02232435531914234, acc: 0.9909747242927551)
[2024-12-17 03:16:31,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:31,977][root][INFO] - Training Epoch: 2/2, step 6965/7134 completed (loss: 0.03205431252717972, acc: 0.9908424615859985)
[2024-12-17 03:16:32,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:32,269][root][INFO] - Training Epoch: 2/2, step 6966/7134 completed (loss: 0.04257475957274437, acc: 0.9825436472892761)
[2024-12-17 03:16:32,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:32,596][root][INFO] - Training Epoch: 2/2, step 6967/7134 completed (loss: 0.019452083855867386, acc: 0.9924585223197937)
[2024-12-17 03:16:32,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:32,913][root][INFO] - Training Epoch: 2/2, step 6968/7134 completed (loss: 0.044051989912986755, acc: 0.9879310131072998)
[2024-12-17 03:16:33,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:33,234][root][INFO] - Training Epoch: 2/2, step 6969/7134 completed (loss: 0.07133997976779938, acc: 0.9792099595069885)
[2024-12-17 03:16:33,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:33,563][root][INFO] - Training Epoch: 2/2, step 6970/7134 completed (loss: 0.09504413604736328, acc: 0.9789473414421082)
[2024-12-17 03:16:33,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:33,899][root][INFO] - Training Epoch: 2/2, step 6971/7134 completed (loss: 0.0735815018415451, acc: 0.984455943107605)
[2024-12-17 03:16:34,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:34,230][root][INFO] - Training Epoch: 2/2, step 6972/7134 completed (loss: 0.026098914444446564, acc: 0.9893048405647278)
[2024-12-17 03:16:34,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:34,551][root][INFO] - Training Epoch: 2/2, step 6973/7134 completed (loss: 0.034420739859342575, acc: 0.9911894202232361)
[2024-12-17 03:16:34,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:34,877][root][INFO] - Training Epoch: 2/2, step 6974/7134 completed (loss: 0.0485343374311924, acc: 0.9879310131072998)
[2024-12-17 03:16:35,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:35,201][root][INFO] - Training Epoch: 2/2, step 6975/7134 completed (loss: 0.05347944051027298, acc: 0.989154040813446)
[2024-12-17 03:16:35,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:35,527][root][INFO] - Training Epoch: 2/2, step 6976/7134 completed (loss: 0.05766058340668678, acc: 0.9809358716011047)
[2024-12-17 03:16:35,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:35,856][root][INFO] - Training Epoch: 2/2, step 6977/7134 completed (loss: 0.04262986406683922, acc: 0.9830827116966248)
[2024-12-17 03:16:35,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:36,191][root][INFO] - Training Epoch: 2/2, step 6978/7134 completed (loss: 0.04605542868375778, acc: 0.9837398529052734)
[2024-12-17 03:16:36,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:36,542][root][INFO] - Training Epoch: 2/2, step 6979/7134 completed (loss: 0.06091177836060524, acc: 0.9832317233085632)
[2024-12-17 03:16:36,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:36,901][root][INFO] - Training Epoch: 2/2, step 6980/7134 completed (loss: 0.1039789542555809, acc: 0.9735848903656006)
[2024-12-17 03:16:36,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:37,265][root][INFO] - Training Epoch: 2/2, step 6981/7134 completed (loss: 0.10392783582210541, acc: 0.9706258177757263)
[2024-12-17 03:16:37,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:37,635][root][INFO] - Training Epoch: 2/2, step 6982/7134 completed (loss: 0.10893672704696655, acc: 0.9780755043029785)
[2024-12-17 03:16:37,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:38,005][root][INFO] - Training Epoch: 2/2, step 6983/7134 completed (loss: 0.12358563393354416, acc: 0.9777448177337646)
[2024-12-17 03:16:38,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:38,362][root][INFO] - Training Epoch: 2/2, step 6984/7134 completed (loss: 0.055828362703323364, acc: 0.9882100820541382)
[2024-12-17 03:16:38,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:38,742][root][INFO] - Training Epoch: 2/2, step 6985/7134 completed (loss: 0.13566501438617706, acc: 0.9723076820373535)
[2024-12-17 03:16:38,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:39,083][root][INFO] - Training Epoch: 2/2, step 6986/7134 completed (loss: 0.04964391514658928, acc: 0.9836552739143372)
[2024-12-17 03:16:39,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:39,462][root][INFO] - Training Epoch: 2/2, step 6987/7134 completed (loss: 0.07095255702733994, acc: 0.9808080792427063)
[2024-12-17 03:16:39,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:39,727][root][INFO] - Training Epoch: 2/2, step 6988/7134 completed (loss: 0.04034152626991272, acc: 0.9920477271080017)
[2024-12-17 03:16:39,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:40,014][root][INFO] - Training Epoch: 2/2, step 6989/7134 completed (loss: 0.09762129932641983, acc: 0.9672726988792419)
[2024-12-17 03:16:40,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:40,324][root][INFO] - Training Epoch: 2/2, step 6990/7134 completed (loss: 0.030875610187649727, acc: 0.9910714030265808)
[2024-12-17 03:16:40,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:40,609][root][INFO] - Training Epoch: 2/2, step 6991/7134 completed (loss: 0.060124728828668594, acc: 0.9824561476707458)
[2024-12-17 03:16:40,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:40,921][root][INFO] - Training Epoch: 2/2, step 6992/7134 completed (loss: 0.05890196934342384, acc: 0.9789473414421082)
[2024-12-17 03:16:41,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:41,276][root][INFO] - Training Epoch: 2/2, step 6993/7134 completed (loss: 0.11951887607574463, acc: 0.9773755669593811)
[2024-12-17 03:16:41,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:41,662][root][INFO] - Training Epoch: 2/2, step 6994/7134 completed (loss: 0.14873316884040833, acc: 0.9695023894309998)
[2024-12-17 03:16:41,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:42,016][root][INFO] - Training Epoch: 2/2, step 6995/7134 completed (loss: 0.03736291825771332, acc: 0.9908376932144165)
[2024-12-17 03:16:42,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:42,339][root][INFO] - Training Epoch: 2/2, step 6996/7134 completed (loss: 0.04355812817811966, acc: 0.9902597665786743)
[2024-12-17 03:16:42,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:42,660][root][INFO] - Training Epoch: 2/2, step 6997/7134 completed (loss: 0.05284043028950691, acc: 0.985981285572052)
[2024-12-17 03:16:42,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:42,906][root][INFO] - Training Epoch: 2/2, step 6998/7134 completed (loss: 0.0918598622083664, acc: 0.968137264251709)
[2024-12-17 03:16:43,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:43,269][root][INFO] - Training Epoch: 2/2, step 6999/7134 completed (loss: 0.054310936480760574, acc: 0.98562091588974)
[2024-12-17 03:16:43,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:43,515][root][INFO] - Training Epoch: 2/2, step 7000/7134 completed (loss: 0.03858104348182678, acc: 0.991525411605835)
[2024-12-17 03:16:43,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:43,859][root][INFO] - Training Epoch: 2/2, step 7001/7134 completed (loss: 0.12598055601119995, acc: 0.974397599697113)
[2024-12-17 03:16:43,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:44,211][root][INFO] - Training Epoch: 2/2, step 7002/7134 completed (loss: 0.019151775166392326, acc: 0.9959431886672974)
[2024-12-17 03:16:44,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:44,561][root][INFO] - Training Epoch: 2/2, step 7003/7134 completed (loss: 0.03096027299761772, acc: 0.9901424050331116)
[2024-12-17 03:16:44,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:44,927][root][INFO] - Training Epoch: 2/2, step 7004/7134 completed (loss: 0.09469057619571686, acc: 0.9790025949478149)
[2024-12-17 03:16:45,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:45,291][root][INFO] - Training Epoch: 2/2, step 7005/7134 completed (loss: 0.08597861975431442, acc: 0.9743589758872986)
[2024-12-17 03:16:45,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:45,656][root][INFO] - Training Epoch: 2/2, step 7006/7134 completed (loss: 0.05612581968307495, acc: 0.9822161197662354)
[2024-12-17 03:16:45,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:46,008][root][INFO] - Training Epoch: 2/2, step 7007/7134 completed (loss: 0.0588839016854763, acc: 0.9880239367485046)
[2024-12-17 03:16:46,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:46,343][root][INFO] - Training Epoch: 2/2, step 7008/7134 completed (loss: 0.057295337319374084, acc: 0.9839704036712646)
[2024-12-17 03:16:46,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:46,709][root][INFO] - Training Epoch: 2/2, step 7009/7134 completed (loss: 0.04971940070390701, acc: 0.9837962985038757)
[2024-12-17 03:16:46,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:47,031][root][INFO] - Training Epoch: 2/2, step 7010/7134 completed (loss: 0.02540171891450882, acc: 0.990755021572113)
[2024-12-17 03:16:47,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:47,388][root][INFO] - Training Epoch: 2/2, step 7011/7134 completed (loss: 0.04669695720076561, acc: 0.9867788553237915)
[2024-12-17 03:16:47,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:47,702][root][INFO] - Training Epoch: 2/2, step 7012/7134 completed (loss: 0.061440881341695786, acc: 0.9825072884559631)
[2024-12-17 03:16:47,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:48,056][root][INFO] - Training Epoch: 2/2, step 7013/7134 completed (loss: 0.01788041554391384, acc: 0.9956772327423096)
[2024-12-17 03:16:48,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:48,383][root][INFO] - Training Epoch: 2/2, step 7014/7134 completed (loss: 0.0331823006272316, acc: 0.990338146686554)
[2024-12-17 03:16:48,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:48,685][root][INFO] - Training Epoch: 2/2, step 7015/7134 completed (loss: 0.0464031882584095, acc: 0.9785330891609192)
[2024-12-17 03:16:48,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:49,051][root][INFO] - Training Epoch: 2/2, step 7016/7134 completed (loss: 0.05248428136110306, acc: 0.9797688126564026)
[2024-12-17 03:16:49,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:49,328][root][INFO] - Training Epoch: 2/2, step 7017/7134 completed (loss: 0.05349574238061905, acc: 0.9813277721405029)
[2024-12-17 03:16:49,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:49,669][root][INFO] - Training Epoch: 2/2, step 7018/7134 completed (loss: 0.061610862612724304, acc: 0.9891473054885864)
[2024-12-17 03:16:49,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:49,983][root][INFO] - Training Epoch: 2/2, step 7019/7134 completed (loss: 0.12152936309576035, acc: 0.9722222089767456)
[2024-12-17 03:16:50,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:50,306][root][INFO] - Training Epoch: 2/2, step 7020/7134 completed (loss: 0.03443121537566185, acc: 0.9929478168487549)
[2024-12-17 03:16:50,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:50,701][root][INFO] - Training Epoch: 2/2, step 7021/7134 completed (loss: 0.03117295540869236, acc: 0.991482138633728)
[2024-12-17 03:16:50,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:50,976][root][INFO] - Training Epoch: 2/2, step 7022/7134 completed (loss: 0.1008988469839096, acc: 0.9783950448036194)
[2024-12-17 03:16:51,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:51,280][root][INFO] - Training Epoch: 2/2, step 7023/7134 completed (loss: 0.07799267023801804, acc: 0.9761336445808411)
[2024-12-17 03:16:51,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:51,554][root][INFO] - Training Epoch: 2/2, step 7024/7134 completed (loss: 0.04786157235503197, acc: 0.9904458522796631)
[2024-12-17 03:16:51,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:51,854][root][INFO] - Training Epoch: 2/2, step 7025/7134 completed (loss: 0.1370004415512085, acc: 0.9632183909416199)
[2024-12-17 03:16:51,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:52,126][root][INFO] - Training Epoch: 2/2, step 7026/7134 completed (loss: 0.09985457360744476, acc: 0.9768339991569519)
[2024-12-17 03:16:52,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:52,389][root][INFO] - Training Epoch: 2/2, step 7027/7134 completed (loss: 0.04327435418963432, acc: 0.9878048896789551)
[2024-12-17 03:16:52,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:52,683][root][INFO] - Training Epoch: 2/2, step 7028/7134 completed (loss: 0.01700522005558014, acc: 0.9951573610305786)
[2024-12-17 03:16:52,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:52,963][root][INFO] - Training Epoch: 2/2, step 7029/7134 completed (loss: 0.028754420578479767, acc: 0.9930394291877747)
[2024-12-17 03:16:53,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:53,238][root][INFO] - Training Epoch: 2/2, step 7030/7134 completed (loss: 0.08481473475694656, acc: 0.9763033390045166)
[2024-12-17 03:16:53,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:53,545][root][INFO] - Training Epoch: 2/2, step 7031/7134 completed (loss: 0.07979871332645416, acc: 0.9720812439918518)
[2024-12-17 03:16:53,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:53,819][root][INFO] - Training Epoch: 2/2, step 7032/7134 completed (loss: 0.05851465091109276, acc: 0.9783197641372681)
[2024-12-17 03:16:53,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:54,079][root][INFO] - Training Epoch: 2/2, step 7033/7134 completed (loss: 0.07279694080352783, acc: 0.9765396118164062)
[2024-12-17 03:16:54,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:54,363][root][INFO] - Training Epoch: 2/2, step 7034/7134 completed (loss: 0.08753614127635956, acc: 0.971731424331665)
[2024-12-17 03:16:54,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:54,657][root][INFO] - Training Epoch: 2/2, step 7035/7134 completed (loss: 0.10630838572978973, acc: 0.9682539701461792)
[2024-12-17 03:16:54,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:54,890][root][INFO] - Training Epoch: 2/2, step 7036/7134 completed (loss: 0.04673534259200096, acc: 0.9794238805770874)
[2024-12-17 03:16:54,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:55,115][root][INFO] - Training Epoch: 2/2, step 7037/7134 completed (loss: 0.036205921322107315, acc: 0.98828125)
[2024-12-17 03:16:55,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:55,396][root][INFO] - Training Epoch: 2/2, step 7038/7134 completed (loss: 0.1047421246767044, acc: 0.9788918495178223)
[2024-12-17 03:16:55,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:55,689][root][INFO] - Training Epoch: 2/2, step 7039/7134 completed (loss: 0.03650986775755882, acc: 0.990338146686554)
[2024-12-17 03:16:55,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:55,962][root][INFO] - Training Epoch: 2/2, step 7040/7134 completed (loss: 0.12513121962547302, acc: 0.959770143032074)
[2024-12-17 03:16:56,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:56,232][root][INFO] - Training Epoch: 2/2, step 7041/7134 completed (loss: 0.11195199936628342, acc: 0.9685534834861755)
[2024-12-17 03:16:56,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:56,510][root][INFO] - Training Epoch: 2/2, step 7042/7134 completed (loss: 0.06702259182929993, acc: 0.9784615635871887)
[2024-12-17 03:16:56,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:56,768][root][INFO] - Training Epoch: 2/2, step 7043/7134 completed (loss: 0.09882324934005737, acc: 0.9733333587646484)
[2024-12-17 03:16:56,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:57,033][root][INFO] - Training Epoch: 2/2, step 7044/7134 completed (loss: 0.09975860267877579, acc: 0.9724770784378052)
[2024-12-17 03:16:57,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:57,348][root][INFO] - Training Epoch: 2/2, step 7045/7134 completed (loss: 0.04272151738405228, acc: 0.9846938848495483)
[2024-12-17 03:16:57,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:57,705][root][INFO] - Training Epoch: 2/2, step 7046/7134 completed (loss: 0.10051949322223663, acc: 0.9767759442329407)
[2024-12-17 03:16:57,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:58,049][root][INFO] - Training Epoch: 2/2, step 7047/7134 completed (loss: 0.09598882496356964, acc: 0.9797618985176086)
[2024-12-17 03:16:58,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:58,402][root][INFO] - Training Epoch: 2/2, step 7048/7134 completed (loss: 0.0158542487770319, acc: 0.9952996373176575)
[2024-12-17 03:16:58,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:58,719][root][INFO] - Training Epoch: 2/2, step 7049/7134 completed (loss: 0.04178783670067787, acc: 0.990641713142395)
[2024-12-17 03:16:58,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:59,050][root][INFO] - Training Epoch: 2/2, step 7050/7134 completed (loss: 0.05412337929010391, acc: 0.9857512712478638)
[2024-12-17 03:16:59,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:59,400][root][INFO] - Training Epoch: 2/2, step 7051/7134 completed (loss: 0.07158183306455612, acc: 0.983565092086792)
[2024-12-17 03:16:59,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:59,755][root][INFO] - Training Epoch: 2/2, step 7052/7134 completed (loss: 0.039835717529058456, acc: 0.9906790852546692)
[2024-12-17 03:16:59,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:00,112][root][INFO] - Training Epoch: 2/2, step 7053/7134 completed (loss: 0.01307241152971983, acc: 0.9975639581680298)
[2024-12-17 03:17:00,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:00,462][root][INFO] - Training Epoch: 2/2, step 7054/7134 completed (loss: 0.05288896709680557, acc: 0.9841772317886353)
[2024-12-17 03:17:00,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:00,797][root][INFO] - Training Epoch: 2/2, step 7055/7134 completed (loss: 0.037965551018714905, acc: 0.9897959232330322)
[2024-12-17 03:17:00,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:01,173][root][INFO] - Training Epoch: 2/2, step 7056/7134 completed (loss: 0.04992785304784775, acc: 0.989195704460144)
[2024-12-17 03:17:01,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:01,553][root][INFO] - Training Epoch: 2/2, step 7057/7134 completed (loss: 0.1270028054714203, acc: 0.9767123460769653)
[2024-12-17 03:17:01,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:01,901][root][INFO] - Training Epoch: 2/2, step 7058/7134 completed (loss: 0.05818566307425499, acc: 0.9881889820098877)
[2024-12-17 03:17:01,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:02,241][root][INFO] - Training Epoch: 2/2, step 7059/7134 completed (loss: 0.02153349295258522, acc: 0.9916201233863831)
[2024-12-17 03:17:02,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:02,561][root][INFO] - Training Epoch: 2/2, step 7060/7134 completed (loss: 0.08808042854070663, acc: 0.977419376373291)
[2024-12-17 03:17:02,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:02,901][root][INFO] - Training Epoch: 2/2, step 7061/7134 completed (loss: 0.04906459152698517, acc: 0.9856770634651184)
[2024-12-17 03:17:02,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:03,224][root][INFO] - Training Epoch: 2/2, step 7062/7134 completed (loss: 0.11006879806518555, acc: 0.9800000190734863)
[2024-12-17 03:17:03,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:03,563][root][INFO] - Training Epoch: 2/2, step 7063/7134 completed (loss: 0.08389927446842194, acc: 0.98562091588974)
[2024-12-17 03:17:03,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:03,930][root][INFO] - Training Epoch: 2/2, step 7064/7134 completed (loss: 0.03563738986849785, acc: 0.9910979270935059)
[2024-12-17 03:17:04,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:04,284][root][INFO] - Training Epoch: 2/2, step 7065/7134 completed (loss: 0.02714802324771881, acc: 0.9907299876213074)
[2024-12-17 03:17:04,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:04,642][root][INFO] - Training Epoch: 2/2, step 7066/7134 completed (loss: 0.04853157699108124, acc: 0.9916765689849854)
[2024-12-17 03:17:04,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:04,986][root][INFO] - Training Epoch: 2/2, step 7067/7134 completed (loss: 0.03628513589501381, acc: 0.9898089170455933)
[2024-12-17 03:17:05,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:05,350][root][INFO] - Training Epoch: 2/2, step 7068/7134 completed (loss: 0.026639342308044434, acc: 0.9903498291969299)
[2024-12-17 03:17:05,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:05,729][root][INFO] - Training Epoch: 2/2, step 7069/7134 completed (loss: 0.03928747773170471, acc: 0.990138053894043)
[2024-12-17 03:17:05,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:06,076][root][INFO] - Training Epoch: 2/2, step 7070/7134 completed (loss: 0.041635047644376755, acc: 0.9903978109359741)
[2024-12-17 03:17:06,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:06,427][root][INFO] - Training Epoch: 2/2, step 7071/7134 completed (loss: 0.047540903091430664, acc: 0.9906014800071716)
[2024-12-17 03:17:06,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:06,781][root][INFO] - Training Epoch: 2/2, step 7072/7134 completed (loss: 0.025032151490449905, acc: 0.9927272796630859)
[2024-12-17 03:17:06,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:07,160][root][INFO] - Training Epoch: 2/2, step 7073/7134 completed (loss: 0.039226241409778595, acc: 0.9886234402656555)
[2024-12-17 03:17:07,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:07,479][root][INFO] - Training Epoch: 2/2, step 7074/7134 completed (loss: 0.0499393492937088, acc: 0.9885277152061462)
[2024-12-17 03:17:07,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:07,822][root][INFO] - Training Epoch: 2/2, step 7075/7134 completed (loss: 0.044871848076581955, acc: 0.9865471124649048)
[2024-12-17 03:17:07,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:08,138][root][INFO] - Training Epoch: 2/2, step 7076/7134 completed (loss: 0.0464845709502697, acc: 0.9886040091514587)
[2024-12-17 03:17:08,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:08,447][root][INFO] - Training Epoch: 2/2, step 7077/7134 completed (loss: 0.06226552650332451, acc: 0.9836065769195557)
[2024-12-17 03:17:08,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:08,766][root][INFO] - Training Epoch: 2/2, step 7078/7134 completed (loss: 0.0469859316945076, acc: 0.9823718070983887)
[2024-12-17 03:17:08,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:09,080][root][INFO] - Training Epoch: 2/2, step 7079/7134 completed (loss: 0.04847065731883049, acc: 0.9852216839790344)
[2024-12-17 03:17:09,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:09,392][root][INFO] - Training Epoch: 2/2, step 7080/7134 completed (loss: 0.04205921292304993, acc: 0.985049843788147)
[2024-12-17 03:17:09,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:09,738][root][INFO] - Training Epoch: 2/2, step 7081/7134 completed (loss: 0.03947407007217407, acc: 0.9887797832489014)
[2024-12-17 03:17:09,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:10,066][root][INFO] - Training Epoch: 2/2, step 7082/7134 completed (loss: 0.04936498403549194, acc: 0.987075924873352)
[2024-12-17 03:17:10,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:10,393][root][INFO] - Training Epoch: 2/2, step 7083/7134 completed (loss: 0.04995264858007431, acc: 0.9832776188850403)
[2024-12-17 03:17:10,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:10,735][root][INFO] - Training Epoch: 2/2, step 7084/7134 completed (loss: 0.03298558294773102, acc: 0.9898403286933899)
[2024-12-17 03:17:10,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:11,079][root][INFO] - Training Epoch: 2/2, step 7085/7134 completed (loss: 0.06126353144645691, acc: 0.9891975522041321)
[2024-12-17 03:17:11,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:11,427][root][INFO] - Training Epoch: 2/2, step 7086/7134 completed (loss: 0.03829960152506828, acc: 0.9917920827865601)
[2024-12-17 03:17:11,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:11,746][root][INFO] - Training Epoch: 2/2, step 7087/7134 completed (loss: 0.05174243450164795, acc: 0.9852125644683838)
[2024-12-17 03:17:11,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:12,075][root][INFO] - Training Epoch: 2/2, step 7088/7134 completed (loss: 0.07169012725353241, acc: 0.9850993156433105)
[2024-12-17 03:17:12,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:12,398][root][INFO] - Training Epoch: 2/2, step 7089/7134 completed (loss: 0.11378589272499084, acc: 0.977707028388977)
[2024-12-17 03:17:12,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:12,745][root][INFO] - Training Epoch: 2/2, step 7090/7134 completed (loss: 0.03916357830166817, acc: 0.9905149340629578)
[2024-12-17 03:17:12,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:13,076][root][INFO] - Training Epoch: 2/2, step 7091/7134 completed (loss: 0.011648583225905895, acc: 0.9958217144012451)
[2024-12-17 03:17:13,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:13,415][root][INFO] - Training Epoch: 2/2, step 7092/7134 completed (loss: 0.03885921090841293, acc: 0.9862778782844543)
[2024-12-17 03:17:13,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:13,712][root][INFO] - Training Epoch: 2/2, step 7093/7134 completed (loss: 0.05672943964600563, acc: 0.9861111044883728)
[2024-12-17 03:17:13,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:14,035][root][INFO] - Training Epoch: 2/2, step 7094/7134 completed (loss: 0.018327971920371056, acc: 0.9953917264938354)
[2024-12-17 03:17:14,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:14,365][root][INFO] - Training Epoch: 2/2, step 7095/7134 completed (loss: 0.04298783838748932, acc: 0.9917355179786682)
[2024-12-17 03:17:14,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:14,684][root][INFO] - Training Epoch: 2/2, step 7096/7134 completed (loss: 0.05464579537510872, acc: 0.9815126061439514)
[2024-12-17 03:17:14,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:15,020][root][INFO] - Training Epoch: 2/2, step 7097/7134 completed (loss: 0.08167315274477005, acc: 0.9798271059989929)
[2024-12-17 03:17:15,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:15,348][root][INFO] - Training Epoch: 2/2, step 7098/7134 completed (loss: 0.02827870287001133, acc: 0.9887640476226807)
[2024-12-17 03:17:15,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:15,640][root][INFO] - Training Epoch: 2/2, step 7099/7134 completed (loss: 0.060995567589998245, acc: 0.9863247871398926)
[2024-12-17 03:17:15,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:15,981][root][INFO] - Training Epoch: 2/2, step 7100/7134 completed (loss: 0.082628034055233, acc: 0.9767441749572754)
[2024-12-17 03:17:16,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:16,262][root][INFO] - Training Epoch: 2/2, step 7101/7134 completed (loss: 0.07471095770597458, acc: 0.9821109175682068)
[2024-12-17 03:17:16,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:16,605][root][INFO] - Training Epoch: 2/2, step 7102/7134 completed (loss: 0.020312149077653885, acc: 0.9941860437393188)
[2024-12-17 03:17:16,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:16,889][root][INFO] - Training Epoch: 2/2, step 7103/7134 completed (loss: 0.04371777921915054, acc: 0.9919354915618896)
[2024-12-17 03:17:17,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:17,212][root][INFO] - Training Epoch: 2/2, step 7104/7134 completed (loss: 0.020467601716518402, acc: 0.9958847761154175)
[2024-12-17 03:17:17,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:17,543][root][INFO] - Training Epoch: 2/2, step 7105/7134 completed (loss: 0.03453777730464935, acc: 0.9883333444595337)
[2024-12-17 03:17:17,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:17,862][root][INFO] - Training Epoch: 2/2, step 7106/7134 completed (loss: 0.020451782271265984, acc: 0.9966611266136169)
[2024-12-17 03:17:17,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:18,193][root][INFO] - Training Epoch: 2/2, step 7107/7134 completed (loss: 0.024339092895388603, acc: 0.9937888383865356)
[2024-12-17 03:17:18,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:18,515][root][INFO] - Training Epoch: 2/2, step 7108/7134 completed (loss: 0.03336835652589798, acc: 0.9916666746139526)
[2024-12-17 03:17:18,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:18,814][root][INFO] - Training Epoch: 2/2, step 7109/7134 completed (loss: 0.06308478116989136, acc: 0.9774859547615051)
[2024-12-17 03:17:18,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:19,145][root][INFO] - Training Epoch: 2/2, step 7110/7134 completed (loss: 0.039438098669052124, acc: 0.988135576248169)
[2024-12-17 03:17:19,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:19,421][root][INFO] - Training Epoch: 2/2, step 7111/7134 completed (loss: 0.06895476579666138, acc: 0.9800443649291992)
[2024-12-17 03:17:19,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:19,749][root][INFO] - Training Epoch: 2/2, step 7112/7134 completed (loss: 0.04195573553442955, acc: 0.9814814925193787)
[2024-12-17 03:17:19,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:20,104][root][INFO] - Training Epoch: 2/2, step 7113/7134 completed (loss: 0.10368764400482178, acc: 0.9668769836425781)
[2024-12-17 03:17:20,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:20,425][root][INFO] - Training Epoch: 2/2, step 7114/7134 completed (loss: 0.027458667755126953, acc: 0.9961758852005005)
[2024-12-17 03:17:20,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:20,741][root][INFO] - Training Epoch: 2/2, step 7115/7134 completed (loss: 0.039610978215932846, acc: 0.9858906269073486)
[2024-12-17 03:17:20,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:21,067][root][INFO] - Training Epoch: 2/2, step 7116/7134 completed (loss: 0.03214505314826965, acc: 0.9912126660346985)
[2024-12-17 03:17:21,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:21,383][root][INFO] - Training Epoch: 2/2, step 7117/7134 completed (loss: 0.028033707290887833, acc: 0.9933333396911621)
[2024-12-17 03:17:21,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:21,730][root][INFO] - Training Epoch: 2/2, step 7118/7134 completed (loss: 0.037756696343421936, acc: 0.9898256063461304)
[2024-12-17 03:17:21,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:22,055][root][INFO] - Training Epoch: 2/2, step 7119/7134 completed (loss: 0.018383968621492386, acc: 0.9918166995048523)
[2024-12-17 03:17:22,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:22,356][root][INFO] - Training Epoch: 2/2, step 7120/7134 completed (loss: 0.04173468053340912, acc: 0.985981285572052)
[2024-12-17 03:17:22,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:22,671][root][INFO] - Training Epoch: 2/2, step 7121/7134 completed (loss: 0.024314623326063156, acc: 0.9911971688270569)
[2024-12-17 03:17:22,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:22,952][root][INFO] - Training Epoch: 2/2, step 7122/7134 completed (loss: 0.026118852198123932, acc: 0.9919785857200623)
[2024-12-17 03:17:23,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:23,244][root][INFO] - Training Epoch: 2/2, step 7123/7134 completed (loss: 0.05287718400359154, acc: 0.9878048896789551)
[2024-12-17 03:17:23,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:23,604][root][INFO] - Training Epoch: 2/2, step 7124/7134 completed (loss: 0.019476501271128654, acc: 0.9962476491928101)
[2024-12-17 03:17:23,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:23,887][root][INFO] - Training Epoch: 2/2, step 7125/7134 completed (loss: 0.02449243701994419, acc: 0.9917080998420715)
[2024-12-17 03:17:24,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:24,217][root][INFO] - Training Epoch: 2/2, step 7126/7134 completed (loss: 0.10151797533035278, acc: 0.9747048616409302)
[2024-12-17 03:17:24,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:24,523][root][INFO] - Training Epoch: 2/2, step 7127/7134 completed (loss: 0.018631160259246826, acc: 0.9968152642250061)
[2024-12-17 03:17:24,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:24,852][root][INFO] - Training Epoch: 2/2, step 7128/7134 completed (loss: 0.035788457840681076, acc: 0.9869918823242188)
[2024-12-17 03:17:24,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:25,181][root][INFO] - Training Epoch: 2/2, step 7129/7134 completed (loss: 0.08284523338079453, acc: 0.9753915071487427)
[2024-12-17 03:17:26,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:26,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:26,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:26,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:27,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:27,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:27,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:27,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:28,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:28,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:28,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:28,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:29,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:29,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:29,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:29,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:30,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:30,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:30,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:31,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:31,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:31,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:32,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:32,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:32,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:32,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:33,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:33,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:33,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:33,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:34,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:34,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:34,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:35,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:35,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:35,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:36,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:36,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:36,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:36,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:37,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:37,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:37,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:37,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:38,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:38,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:38,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:39,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:39,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:39,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:40,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:40,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:40,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:40,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:41,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:41,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:41,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:42,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:42,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:42,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:42,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:43,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:43,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:43,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:43,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:44,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:44,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:44,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:44,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:45,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:45,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:45,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:45,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:46,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:46,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:46,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:46,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:47,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:47,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:47,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:48,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:48,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:48,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:49,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:49,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:49,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:50,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:50,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:50,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:50,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:51,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:51,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:51,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:52,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:52,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:52,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:52,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:53,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:53,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:53,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:54,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:54,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:54,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:54,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:55,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:55,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:55,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:55,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:56,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:56,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:56,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:57,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:57,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:57,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:57,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:58,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:58,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:58,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:59,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:59,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:59,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:00,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:00,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:00,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:00,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:01,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:01,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:01,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:01,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:02,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:02,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:02,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:03,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:03,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:03,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:04,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:04,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:04,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:04,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:05,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:05,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:05,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:06,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:06,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:06,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:06,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:07,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:07,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:07,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:08,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:08,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:08,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:08,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:08,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:09,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:09,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:09,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:09,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:10,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:10,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:10,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:10,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:11,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:11,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:11,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:12,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:12,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:12,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:12,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:13,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:13,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:13,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:13,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:14,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:14,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:14,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:15,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:15,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:15,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:15,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:16,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:16,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:16,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:16,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:17,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:17,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:17,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:17,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:18,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:18,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:18,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:19,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:19,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:19,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:19,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:19,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:20,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:20,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:20,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:20,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:21,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:21,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:21,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:21,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:22,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:22,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:22,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:22,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:23,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:23,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:23,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:24,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:24,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:24,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:25,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:25,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:25,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:25,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:25,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:26,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:26,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:26,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:27,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:27,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:27,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:27,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:28,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:28,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:28,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:29,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:29,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:29,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:29,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:30,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:30,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:30,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:31,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:31,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:31,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:31,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:32,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:32,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:32,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:32,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:33,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:33,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:33,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:34,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:34,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:35,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:35,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:35,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:36,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:36,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:36,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:37,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:37,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:37,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:38,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:38,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:38,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:38,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:39,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:39,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:39,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:40,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:40,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:40,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:40,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:41,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:41,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:41,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:42,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:42,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:42,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:43,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:43,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:43,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:43,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:44,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:44,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:44,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:45,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:45,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:45,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:46,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:46,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:46,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:47,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:47,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:47,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:48,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:48,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:48,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:48,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:49,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:49,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:50,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:50,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:50,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:50,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:51,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:51,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:51,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:51,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:52,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:52,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:52,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:52,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:53,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:53,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:53,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:53,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:54,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:54,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:54,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:55,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:55,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:55,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:56,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:56,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:56,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:57,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:57,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:57,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:57,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:58,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:58,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:58,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:59,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:59,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:59,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:00,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:00,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:00,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:01,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:01,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:01,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:01,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:02,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:02,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:02,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:03,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:03,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:03,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:04,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:04,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:04,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:05,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:05,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:05,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:05,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:06,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:06,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:06,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:06,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:07,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:07,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:07,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:08,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:08,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:09,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:09,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:09,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:10,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:10,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:11,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:11,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:11,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:12,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:12,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:12,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:12,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:13,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:13,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:13,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:13,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:14,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:14,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:14,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:14,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:15,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:15,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:15,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:16,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:16,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:16,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:16,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:17,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:17,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:17,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:17,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:18,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:18,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:18,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:18,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:19,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:19,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:19,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:20,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:20,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:20,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:20,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:21,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:21,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:21,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:22,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:22,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:22,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:22,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:23,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:23,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:23,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:23,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:24,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:24,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:24,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:25,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:25,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:25,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:25,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:26,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:26,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:26,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:26,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:27,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:27,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:27,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:28,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:28,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:28,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:28,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:29,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:29,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:29,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:29,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:30,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:30,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:30,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:30,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:31,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:31,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:31,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:32,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:32,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:32,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:33,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:33,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:33,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:33,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:34,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:34,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:34,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:35,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:35,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:35,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:35,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:36,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:36,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:36,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:36,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:37,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:37,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:37,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:38,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:38,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:38,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:38,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:39,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:39,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:39,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:39,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:40,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:40,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:40,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:40,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:41,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:41,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:41,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:42,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:42,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:42,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:43,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:43,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:43,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:43,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:44,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:44,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:44,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:45,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:45,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:45,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:46,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:46,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:46,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:46,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:47,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:47,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:47,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:47,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:48,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:48,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:48,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:49,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:49,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:49,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:50,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:50,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:50,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:50,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:50,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:51,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:51,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:51,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:52,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:52,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:52,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:52,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:53,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:53,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:53,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:54,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:54,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:54,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:54,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:54,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:55,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:55,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:55,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:55,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:56,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:56,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:56,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:57,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:57,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:57,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:57,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:58,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:58,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:58,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:58,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:59,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:59,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:59,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:59,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:00,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:00,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:00,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:01,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:01,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:01,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:01,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:02,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:02,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:03,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:03,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:03,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:04,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:04,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:04,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:04,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:05,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:05,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:05,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:06,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:06,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:06,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:06,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:07,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:07,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:07,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:07,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:08,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:08,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:08,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:09,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:09,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:09,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:09,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:10,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:10,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:11,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:11,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:11,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:11,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:12,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:12,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:12,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:13,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:13,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:13,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:14,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:14,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:14,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:14,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:14,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:15,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:15,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:15,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:16,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:16,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:16,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:17,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:17,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:17,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:17,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:18,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:18,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:18,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:18,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:19,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:19,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:19,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:19,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:20,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:20,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:20,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:20,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:21,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:21,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:21,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:22,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:22,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:22,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:23,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:23,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:24,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:24,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:25,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:25,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:25,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:26,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:26,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:27,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:27,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:27,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:28,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:28,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:28,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:29,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:29,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:29,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:29,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:30,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:30,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:30,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:31,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:31,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:31,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:32,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:32,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:32,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:32,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:33,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:33,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:33,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:33,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:34,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:34,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:34,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:35,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:35,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:35,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:35,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:36,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:36,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:36,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:36,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:36,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:37,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:37,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:37,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:38,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:38,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:38,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:39,371][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.0688, device='cuda:0') eval_epoch_loss=tensor(0.0665, device='cuda:0') eval_epoch_acc=tensor(0.9830, device='cuda:0')
[2024-12-17 03:20:39,373][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-12-17 03:20:39,374][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 03:20:39,558][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_2_step_7130_loss_0.06649578362703323/model.pt
[2024-12-17 03:20:39,562][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 0.06649578362703323
[2024-12-17 03:20:39,563][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.9830231666564941
[2024-12-17 03:20:39,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:39,913][root][INFO] - Training Epoch: 2/2, step 7130/7134 completed (loss: 0.12223614007234573, acc: 0.9607142806053162)
[2024-12-17 03:20:40,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:40,227][root][INFO] - Training Epoch: 2/2, step 7131/7134 completed (loss: 0.022714275866746902, acc: 0.9907192587852478)
[2024-12-17 03:20:40,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:40,474][root][INFO] - Training Epoch: 2/2, step 7132/7134 completed (loss: 0.03372768685221672, acc: 0.9932659864425659)
[2024-12-17 03:20:40,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:40,765][root][INFO] - Training Epoch: 2/2, step 7133/7134 completed (loss: 0.009978924877941608, acc: 0.9981516003608704)
[2024-12-17 03:20:41,266][slam_llm.utils.train_utils][INFO] - Epoch 2: train_perplexity=1.0581, train_epoch_loss=0.0565, epoch time 3194.6390174366534s
[2024-12-17 03:20:41,267][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 12 GB
[2024-12-17 03:20:41,267][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 30 GB
[2024-12-17 03:20:41,267][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 12 GB
[2024-12-17 03:20:41,267][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 11
[2024-12-17 03:20:41,267][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-12-17 03:20:41,269][root][INFO] - Key: avg_train_prep, Value: 1.2699863910675049
[2024-12-17 03:20:41,270][root][INFO] - Key: avg_train_loss, Value: 0.22489677369594574
[2024-12-17 03:20:41,270][root][INFO] - Key: avg_train_acc, Value: 0.9446514248847961
[2024-12-17 03:20:41,271][root][INFO] - Key: avg_eval_prep, Value: 1.0979809761047363
[2024-12-17 03:20:41,271][root][INFO] - Key: avg_eval_loss, Value: 0.09282878041267395
[2024-12-17 03:20:41,271][root][INFO] - Key: avg_eval_acc, Value: 0.9764499664306641
[2024-12-17 03:20:41,271][root][INFO] - Key: avg_epoch_time, Value: 3208.288035660982
[2024-12-17 03:20:41,271][root][INFO] - Key: avg_checkpoint_time, Value: 0.22416806127876043
