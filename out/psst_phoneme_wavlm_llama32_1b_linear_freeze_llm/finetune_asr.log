[2024-11-29 02:53:03,541][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 10, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': False, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': True}
[2024-11-29 02:53:03,541][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-11-29 02:53:03,542][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-11-29 02:53:03,542][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'psst_phoneme_wavlm_llama32_1b_linear_freeze_llm', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-11-29_02-53-02.txt', 'log_interval': 5}
[2024-11-29 02:53:27,452][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-11-29 02:53:32,918][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-11-29 02:53:32,920][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-11-29 02:53:32,922][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-11-29 02:53:32,923][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-11-29 02:53:40,334][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-29 02:53:40,336][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-11-29 02:53:40,337][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-29 02:53:40,338][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 0.0 Million params

[2024-11-29 02:53:40,439][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-11-29 02:53:40,439][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-11-29 02:53:40,440][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-11-29 02:53:40,442][slam_llm.utils.train_utils][INFO] - --> asr has 14.68416 Million params

[2024-11-29 02:53:42,412][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-11-29 02:53:44,383][root][INFO] - --> Training Set Length = 2298
[2024-11-29 02:53:44,391][root][INFO] - --> Validation Set Length = 341
[2024-11-29 02:53:44,392][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-29 02:53:44,393][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-29 02:53:46,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:48,263][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-11-29 02:53:49,250][root][INFO] - Training Epoch: 1/10, step 0/574 completed (loss: 8.480217933654785, acc: 0.0)
[2024-11-29 02:53:49,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:49,774][root][INFO] - Training Epoch: 1/10, step 1/574 completed (loss: 8.3673095703125, acc: 0.0)
[2024-11-29 02:53:49,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:50,064][root][INFO] - Training Epoch: 1/10, step 2/574 completed (loss: 7.651307582855225, acc: 0.027027027681469917)
[2024-11-29 02:53:50,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:50,363][root][INFO] - Training Epoch: 1/10, step 3/574 completed (loss: 8.27139949798584, acc: 0.05263157933950424)
[2024-11-29 02:53:50,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:50,616][root][INFO] - Training Epoch: 1/10, step 4/574 completed (loss: 7.12307071685791, acc: 0.054054055362939835)
[2024-11-29 02:53:50,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:50,930][root][INFO] - Training Epoch: 1/10, step 5/574 completed (loss: 7.729887962341309, acc: 0.0)
[2024-11-29 02:53:51,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:51,212][root][INFO] - Training Epoch: 1/10, step 6/574 completed (loss: 7.776432514190674, acc: 0.020408162847161293)
[2024-11-29 02:53:51,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:51,449][root][INFO] - Training Epoch: 1/10, step 7/574 completed (loss: 7.532177448272705, acc: 0.0)
[2024-11-29 02:53:51,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:51,735][root][INFO] - Training Epoch: 1/10, step 8/574 completed (loss: 9.473755836486816, acc: 0.0)
[2024-11-29 02:53:51,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:52,004][root][INFO] - Training Epoch: 1/10, step 9/574 completed (loss: 7.289339542388916, acc: 0.03846153989434242)
[2024-11-29 02:53:52,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:52,274][root][INFO] - Training Epoch: 1/10, step 10/574 completed (loss: 8.491701126098633, acc: 0.03703703731298447)
[2024-11-29 02:53:52,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:52,569][root][INFO] - Training Epoch: 1/10, step 11/574 completed (loss: 7.002791881561279, acc: 0.0)
[2024-11-29 02:53:52,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:52,829][root][INFO] - Training Epoch: 1/10, step 12/574 completed (loss: 7.808872222900391, acc: 0.0)
[2024-11-29 02:53:52,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:53,087][root][INFO] - Training Epoch: 1/10, step 13/574 completed (loss: 7.0610246658325195, acc: 0.0)
[2024-11-29 02:53:53,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:53,397][root][INFO] - Training Epoch: 1/10, step 14/574 completed (loss: 7.365792274475098, acc: 0.0)
[2024-11-29 02:53:53,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:53,667][root][INFO] - Training Epoch: 1/10, step 15/574 completed (loss: 6.289956092834473, acc: 0.06122449040412903)
[2024-11-29 02:53:53,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:53,977][root][INFO] - Training Epoch: 1/10, step 16/574 completed (loss: 9.410804748535156, acc: 0.0)
[2024-11-29 02:53:54,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:54,249][root][INFO] - Training Epoch: 1/10, step 17/574 completed (loss: 8.404153823852539, acc: 0.0)
[2024-11-29 02:53:54,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:54,497][root][INFO] - Training Epoch: 1/10, step 18/574 completed (loss: 6.719508647918701, acc: 0.0833333358168602)
[2024-11-29 02:53:54,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:54,766][root][INFO] - Training Epoch: 1/10, step 19/574 completed (loss: 8.373422622680664, acc: 0.05263157933950424)
[2024-11-29 02:53:54,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:55,044][root][INFO] - Training Epoch: 1/10, step 20/574 completed (loss: 7.943757057189941, acc: 0.0)
[2024-11-29 02:53:55,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:55,325][root][INFO] - Training Epoch: 1/10, step 21/574 completed (loss: 7.280201435089111, acc: 0.0)
[2024-11-29 02:53:55,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:55,620][root][INFO] - Training Epoch: 1/10, step 22/574 completed (loss: 7.747892379760742, acc: 0.03999999910593033)
[2024-11-29 02:53:55,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:55,900][root][INFO] - Training Epoch: 1/10, step 23/574 completed (loss: 8.52219295501709, acc: 0.0476190485060215)
[2024-11-29 02:53:56,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:56,164][root][INFO] - Training Epoch: 1/10, step 24/574 completed (loss: 8.618715286254883, acc: 0.0)
[2024-11-29 02:53:56,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:56,383][root][INFO] - Training Epoch: 1/10, step 25/574 completed (loss: 6.346898078918457, acc: 0.01886792480945587)
[2024-11-29 02:53:56,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:56,670][root][INFO] - Training Epoch: 1/10, step 26/574 completed (loss: 5.965940475463867, acc: 0.08219178020954132)
[2024-11-29 02:53:57,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:57,916][root][INFO] - Training Epoch: 1/10, step 27/574 completed (loss: 4.5753936767578125, acc: 0.22529643774032593)
[2024-11-29 02:53:58,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:58,203][root][INFO] - Training Epoch: 1/10, step 28/574 completed (loss: 6.667969226837158, acc: 0.06976744532585144)
[2024-11-29 02:53:58,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:58,512][root][INFO] - Training Epoch: 1/10, step 29/574 completed (loss: 5.599632263183594, acc: 0.15662650763988495)
[2024-11-29 02:53:58,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:58,782][root][INFO] - Training Epoch: 1/10, step 30/574 completed (loss: 5.304330348968506, acc: 0.1358024626970291)
[2024-11-29 02:53:58,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:59,034][root][INFO] - Training Epoch: 1/10, step 31/574 completed (loss: 7.87670373916626, acc: 0.0)
[2024-11-29 02:53:59,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:59,290][root][INFO] - Training Epoch: 1/10, step 32/574 completed (loss: 7.5405049324035645, acc: 0.0)
[2024-11-29 02:53:59,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:59,561][root][INFO] - Training Epoch: 1/10, step 33/574 completed (loss: 8.043198585510254, acc: 0.0)
[2024-11-29 02:53:59,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:59,840][root][INFO] - Training Epoch: 1/10, step 34/574 completed (loss: 5.237917900085449, acc: 0.1428571492433548)
[2024-11-29 02:53:59,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:00,116][root][INFO] - Training Epoch: 1/10, step 35/574 completed (loss: 5.551674842834473, acc: 0.1803278625011444)
[2024-11-29 02:54:00,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:00,333][root][INFO] - Training Epoch: 1/10, step 36/574 completed (loss: 5.39389181137085, acc: 0.190476194024086)
[2024-11-29 02:54:00,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:00,576][root][INFO] - Training Epoch: 1/10, step 37/574 completed (loss: 6.530097007751465, acc: 0.033898305147886276)
[2024-11-29 02:54:00,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:00,932][root][INFO] - Training Epoch: 1/10, step 38/574 completed (loss: 5.640740394592285, acc: 0.12643678486347198)
[2024-11-29 02:54:01,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:01,241][root][INFO] - Training Epoch: 1/10, step 39/574 completed (loss: 8.078022956848145, acc: 0.0)
[2024-11-29 02:54:01,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:01,538][root][INFO] - Training Epoch: 1/10, step 40/574 completed (loss: 7.151127338409424, acc: 0.03846153989434242)
[2024-11-29 02:54:01,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:01,888][root][INFO] - Training Epoch: 1/10, step 41/574 completed (loss: 5.128255367279053, acc: 0.18918919563293457)
[2024-11-29 02:54:02,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:02,232][root][INFO] - Training Epoch: 1/10, step 42/574 completed (loss: 5.595872402191162, acc: 0.1538461595773697)
[2024-11-29 02:54:02,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:02,700][root][INFO] - Training Epoch: 1/10, step 43/574 completed (loss: 5.5895233154296875, acc: 0.17171716690063477)
[2024-11-29 02:54:02,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:03,051][root][INFO] - Training Epoch: 1/10, step 44/574 completed (loss: 4.814455032348633, acc: 0.23711340129375458)
[2024-11-29 02:54:03,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:03,386][root][INFO] - Training Epoch: 1/10, step 45/574 completed (loss: 5.388923645019531, acc: 0.13235294818878174)
[2024-11-29 02:54:03,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:03,615][root][INFO] - Training Epoch: 1/10, step 46/574 completed (loss: 7.832555770874023, acc: 0.0)
[2024-11-29 02:54:03,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:03,845][root][INFO] - Training Epoch: 1/10, step 47/574 completed (loss: 6.955371379852295, acc: 0.03703703731298447)
[2024-11-29 02:54:03,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:04,113][root][INFO] - Training Epoch: 1/10, step 48/574 completed (loss: 7.653075695037842, acc: 0.0)
[2024-11-29 02:54:04,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:04,381][root][INFO] - Training Epoch: 1/10, step 49/574 completed (loss: 6.425346374511719, acc: 0.0)
[2024-11-29 02:54:04,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:04,645][root][INFO] - Training Epoch: 1/10, step 50/574 completed (loss: 5.683309555053711, acc: 0.15789473056793213)
[2024-11-29 02:54:04,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:04,878][root][INFO] - Training Epoch: 1/10, step 51/574 completed (loss: 5.828924655914307, acc: 0.0793650820851326)
[2024-11-29 02:54:04,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:05,106][root][INFO] - Training Epoch: 1/10, step 52/574 completed (loss: 5.992965221405029, acc: 0.11267605423927307)
[2024-11-29 02:54:05,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:05,480][root][INFO] - Training Epoch: 1/10, step 53/574 completed (loss: 4.949980735778809, acc: 0.23333333432674408)
[2024-11-29 02:54:05,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:05,704][root][INFO] - Training Epoch: 1/10, step 54/574 completed (loss: 7.197372913360596, acc: 0.0)
[2024-11-29 02:54:05,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:06,034][root][INFO] - Training Epoch: 1/10, step 55/574 completed (loss: 7.540493488311768, acc: 0.0)
[2024-11-29 02:54:07,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:08,787][root][INFO] - Training Epoch: 1/10, step 56/574 completed (loss: 3.332617998123169, acc: 0.36518770456314087)
[2024-11-29 02:54:09,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:09,942][root][INFO] - Training Epoch: 1/10, step 57/574 completed (loss: 3.7769641876220703, acc: 0.27450981736183167)
[2024-11-29 02:54:10,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:10,617][root][INFO] - Training Epoch: 1/10, step 58/574 completed (loss: 4.455029010772705, acc: 0.23295454680919647)
[2024-11-29 02:54:10,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:11,106][root][INFO] - Training Epoch: 1/10, step 59/574 completed (loss: 4.679698944091797, acc: 0.2132352888584137)
[2024-11-29 02:54:11,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:11,575][root][INFO] - Training Epoch: 1/10, step 60/574 completed (loss: 4.427807331085205, acc: 0.2246376872062683)
[2024-11-29 02:54:11,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:11,914][root][INFO] - Training Epoch: 1/10, step 61/574 completed (loss: 4.660669803619385, acc: 0.26249998807907104)
[2024-11-29 02:54:12,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:12,126][root][INFO] - Training Epoch: 1/10, step 62/574 completed (loss: 6.478281021118164, acc: 0.0)
[2024-11-29 02:54:12,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:12,409][root][INFO] - Training Epoch: 1/10, step 63/574 completed (loss: 6.685723781585693, acc: 0.0555555559694767)
[2024-11-29 02:54:12,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:12,666][root][INFO] - Training Epoch: 1/10, step 64/574 completed (loss: 4.505694389343262, acc: 0.25)
[2024-11-29 02:54:12,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:12,888][root][INFO] - Training Epoch: 1/10, step 65/574 completed (loss: 5.746148586273193, acc: 0.2068965584039688)
[2024-11-29 02:54:13,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:13,152][root][INFO] - Training Epoch: 1/10, step 66/574 completed (loss: 5.3744096755981445, acc: 0.1785714328289032)
[2024-11-29 02:54:13,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:13,402][root][INFO] - Training Epoch: 1/10, step 67/574 completed (loss: 5.814859867095947, acc: 0.01666666753590107)
[2024-11-29 02:54:13,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:13,637][root][INFO] - Training Epoch: 1/10, step 68/574 completed (loss: 7.117074012756348, acc: 0.0)
[2024-11-29 02:54:13,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:13,864][root][INFO] - Training Epoch: 1/10, step 69/574 completed (loss: 6.324346542358398, acc: 0.02777777798473835)
[2024-11-29 02:54:14,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:14,123][root][INFO] - Training Epoch: 1/10, step 70/574 completed (loss: 6.925064563751221, acc: 0.0)
[2024-11-29 02:54:14,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:14,380][root][INFO] - Training Epoch: 1/10, step 71/574 completed (loss: 4.505711555480957, acc: 0.22794117033481598)
[2024-11-29 02:54:14,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:14,614][root][INFO] - Training Epoch: 1/10, step 72/574 completed (loss: 4.389969348907471, acc: 0.1825396865606308)
[2024-11-29 02:54:14,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:14,869][root][INFO] - Training Epoch: 1/10, step 73/574 completed (loss: 4.4659552574157715, acc: 0.22051282227039337)
[2024-11-29 02:54:14,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:15,080][root][INFO] - Training Epoch: 1/10, step 74/574 completed (loss: 5.570042610168457, acc: 0.0714285746216774)
[2024-11-29 02:54:15,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:15,395][root][INFO] - Training Epoch: 1/10, step 75/574 completed (loss: 4.988980293273926, acc: 0.11940298229455948)
[2024-11-29 02:54:15,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:15,740][root][INFO] - Training Epoch: 1/10, step 76/574 completed (loss: 4.009467124938965, acc: 0.24087591469287872)
[2024-11-29 02:54:15,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:16,021][root][INFO] - Training Epoch: 1/10, step 77/574 completed (loss: 7.45653772354126, acc: 0.0)
[2024-11-29 02:54:16,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:16,287][root][INFO] - Training Epoch: 1/10, step 78/574 completed (loss: 6.606799602508545, acc: 0.0833333358168602)
[2024-11-29 02:54:16,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:16,521][root][INFO] - Training Epoch: 1/10, step 79/574 completed (loss: 6.287886619567871, acc: 0.0)
[2024-11-29 02:54:16,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:16,769][root][INFO] - Training Epoch: 1/10, step 80/574 completed (loss: 6.415318012237549, acc: 0.0)
[2024-11-29 02:54:16,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:17,015][root][INFO] - Training Epoch: 1/10, step 81/574 completed (loss: 5.763155460357666, acc: 0.01923076994717121)
[2024-11-29 02:54:17,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:17,252][root][INFO] - Training Epoch: 1/10, step 82/574 completed (loss: 5.865850448608398, acc: 0.07692307978868484)
[2024-11-29 02:54:17,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:17,463][root][INFO] - Training Epoch: 1/10, step 83/574 completed (loss: 5.626232624053955, acc: 0.09375)
[2024-11-29 02:54:17,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:17,741][root][INFO] - Training Epoch: 1/10, step 84/574 completed (loss: 5.406120300292969, acc: 0.10144927352666855)
[2024-11-29 02:54:17,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:17,989][root][INFO] - Training Epoch: 1/10, step 85/574 completed (loss: 5.498164653778076, acc: 0.07999999821186066)
[2024-11-29 02:54:18,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:18,233][root][INFO] - Training Epoch: 1/10, step 86/574 completed (loss: 6.8531951904296875, acc: 0.043478261679410934)
[2024-11-29 02:54:18,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:18,644][root][INFO] - Training Epoch: 1/10, step 87/574 completed (loss: 5.524606704711914, acc: 0.10000000149011612)
[2024-11-29 02:54:18,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:18,887][root][INFO] - Training Epoch: 1/10, step 88/574 completed (loss: 4.599839687347412, acc: 0.19417475163936615)
[2024-11-29 02:54:19,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:19,898][root][INFO] - Training Epoch: 1/10, step 89/574 completed (loss: 4.350423812866211, acc: 0.24757280945777893)
[2024-11-29 02:54:20,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:20,637][root][INFO] - Training Epoch: 1/10, step 90/574 completed (loss: 4.552916526794434, acc: 0.17741934955120087)
[2024-11-29 02:54:20,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:21,335][root][INFO] - Training Epoch: 1/10, step 91/574 completed (loss: 3.9968149662017822, acc: 0.3017241358757019)
[2024-11-29 02:54:21,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:21,996][root][INFO] - Training Epoch: 1/10, step 92/574 completed (loss: 4.431870460510254, acc: 0.27368420362472534)
[2024-11-29 02:54:22,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:22,925][root][INFO] - Training Epoch: 1/10, step 93/574 completed (loss: 4.482795238494873, acc: 0.15841583907604218)
[2024-11-29 02:54:23,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:23,190][root][INFO] - Training Epoch: 1/10, step 94/574 completed (loss: 5.146185874938965, acc: 0.09677419066429138)
[2024-11-29 02:54:23,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:23,511][root][INFO] - Training Epoch: 1/10, step 95/574 completed (loss: 5.023542881011963, acc: 0.17391304671764374)
[2024-11-29 02:54:23,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:23,819][root][INFO] - Training Epoch: 1/10, step 96/574 completed (loss: 4.7046003341674805, acc: 0.10084033757448196)
[2024-11-29 02:54:24,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:24,131][root][INFO] - Training Epoch: 1/10, step 97/574 completed (loss: 4.847246170043945, acc: 0.13461539149284363)
[2024-11-29 02:54:24,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:24,432][root][INFO] - Training Epoch: 1/10, step 98/574 completed (loss: 4.58410120010376, acc: 0.16788321733474731)
[2024-11-29 02:54:24,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:24,665][root][INFO] - Training Epoch: 1/10, step 99/574 completed (loss: 5.9424967765808105, acc: 0.0746268630027771)
[2024-11-29 02:54:24,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:24,946][root][INFO] - Training Epoch: 1/10, step 100/574 completed (loss: 6.330531120300293, acc: 0.0)
[2024-11-29 02:54:25,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:25,234][root][INFO] - Training Epoch: 1/10, step 101/574 completed (loss: 6.955407619476318, acc: 0.0)
[2024-11-29 02:54:25,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:25,529][root][INFO] - Training Epoch: 1/10, step 102/574 completed (loss: 5.511464595794678, acc: 0.08695652335882187)
[2024-11-29 02:54:25,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:25,773][root][INFO] - Training Epoch: 1/10, step 103/574 completed (loss: 5.225788593292236, acc: 0.11363636702299118)
[2024-11-29 02:54:25,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:26,058][root][INFO] - Training Epoch: 1/10, step 104/574 completed (loss: 5.22371244430542, acc: 0.08620689809322357)
[2024-11-29 02:54:26,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:26,347][root][INFO] - Training Epoch: 1/10, step 105/574 completed (loss: 5.362639904022217, acc: 0.04651162773370743)
[2024-11-29 02:54:26,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:26,628][root][INFO] - Training Epoch: 1/10, step 106/574 completed (loss: 5.669594764709473, acc: 0.03999999910593033)
[2024-11-29 02:54:26,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:26,881][root][INFO] - Training Epoch: 1/10, step 107/574 completed (loss: 5.982316493988037, acc: 0.11764705926179886)
[2024-11-29 02:54:27,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:27,192][root][INFO] - Training Epoch: 1/10, step 108/574 completed (loss: 5.4698486328125, acc: 0.03846153989434242)
[2024-11-29 02:54:27,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:27,476][root][INFO] - Training Epoch: 1/10, step 109/574 completed (loss: 5.567897796630859, acc: 0.02380952425301075)
[2024-11-29 02:54:27,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:27,769][root][INFO] - Training Epoch: 1/10, step 110/574 completed (loss: 5.142724990844727, acc: 0.1538461595773697)
[2024-11-29 02:54:27,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:28,111][root][INFO] - Training Epoch: 1/10, step 111/574 completed (loss: 5.127829074859619, acc: 0.07017543911933899)
[2024-11-29 02:54:28,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:28,397][root][INFO] - Training Epoch: 1/10, step 112/574 completed (loss: 5.046823978424072, acc: 0.15789473056793213)
[2024-11-29 02:54:28,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:28,662][root][INFO] - Training Epoch: 1/10, step 113/574 completed (loss: 5.386013507843018, acc: 0.05128205195069313)
[2024-11-29 02:54:28,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:28,954][root][INFO] - Training Epoch: 1/10, step 114/574 completed (loss: 5.229341983795166, acc: 0.06122449040412903)
[2024-11-29 02:54:29,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:29,226][root][INFO] - Training Epoch: 1/10, step 115/574 completed (loss: 5.230062484741211, acc: 0.04545454680919647)
[2024-11-29 02:54:29,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:29,563][root][INFO] - Training Epoch: 1/10, step 116/574 completed (loss: 4.472043991088867, acc: 0.190476194024086)
[2024-11-29 02:54:29,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:29,861][root][INFO] - Training Epoch: 1/10, step 117/574 completed (loss: 4.09957218170166, acc: 0.22764228284358978)
[2024-11-29 02:54:30,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:30,144][root][INFO] - Training Epoch: 1/10, step 118/574 completed (loss: 4.537240505218506, acc: 0.14516128599643707)
[2024-11-29 02:54:30,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:30,913][root][INFO] - Training Epoch: 1/10, step 119/574 completed (loss: 3.7564849853515625, acc: 0.26996198296546936)
[2024-11-29 02:54:31,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:31,149][root][INFO] - Training Epoch: 1/10, step 120/574 completed (loss: 4.504758358001709, acc: 0.1733333319425583)
[2024-11-29 02:54:31,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:31,489][root][INFO] - Training Epoch: 1/10, step 121/574 completed (loss: 4.921169757843018, acc: 0.13461539149284363)
[2024-11-29 02:54:31,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:31,674][root][INFO] - Training Epoch: 1/10, step 122/574 completed (loss: 6.0601725578308105, acc: 0.0416666679084301)
[2024-11-29 02:54:31,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:31,866][root][INFO] - Training Epoch: 1/10, step 123/574 completed (loss: 5.3332200050354, acc: 0.05263157933950424)
[2024-11-29 02:54:31,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:32,147][root][INFO] - Training Epoch: 1/10, step 124/574 completed (loss: 4.042468547821045, acc: 0.19018404185771942)
[2024-11-29 02:54:32,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:32,470][root][INFO] - Training Epoch: 1/10, step 125/574 completed (loss: 3.3040707111358643, acc: 0.3402777910232544)
[2024-11-29 02:54:32,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:32,672][root][INFO] - Training Epoch: 1/10, step 126/574 completed (loss: 4.115434646606445, acc: 0.20000000298023224)
[2024-11-29 02:54:32,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:32,919][root][INFO] - Training Epoch: 1/10, step 127/574 completed (loss: 3.826885461807251, acc: 0.1785714328289032)
[2024-11-29 02:54:33,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:33,219][root][INFO] - Training Epoch: 1/10, step 128/574 completed (loss: 3.8811984062194824, acc: 0.20512820780277252)
[2024-11-29 02:54:33,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:33,578][root][INFO] - Training Epoch: 1/10, step 129/574 completed (loss: 3.481748342514038, acc: 0.2720588147640228)
[2024-11-29 02:54:33,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:33,842][root][INFO] - Training Epoch: 1/10, step 130/574 completed (loss: 5.5683674812316895, acc: 0.03846153989434242)
[2024-11-29 02:54:33,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:34,106][root][INFO] - Training Epoch: 1/10, step 131/574 completed (loss: 5.382214546203613, acc: 0.0)
[2024-11-29 02:54:34,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:34,359][root][INFO] - Training Epoch: 1/10, step 132/574 completed (loss: 5.3557820320129395, acc: 0.03125)
[2024-11-29 02:54:34,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:34,615][root][INFO] - Training Epoch: 1/10, step 133/574 completed (loss: 4.444965362548828, acc: 0.17391304671764374)
[2024-11-29 02:54:34,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:34,877][root][INFO] - Training Epoch: 1/10, step 134/574 completed (loss: 4.865129470825195, acc: 0.1428571492433548)
[2024-11-29 02:54:34,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:35,116][root][INFO] - Training Epoch: 1/10, step 135/574 completed (loss: 4.636239051818848, acc: 0.19230769574642181)
[2024-11-29 02:54:35,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:35,357][root][INFO] - Training Epoch: 1/10, step 136/574 completed (loss: 4.599565029144287, acc: 0.095238097012043)
[2024-11-29 02:54:35,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:35,628][root][INFO] - Training Epoch: 1/10, step 137/574 completed (loss: 4.631126403808594, acc: 0.06666667014360428)
[2024-11-29 02:54:35,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:35,877][root][INFO] - Training Epoch: 1/10, step 138/574 completed (loss: 4.290093421936035, acc: 0.21739129722118378)
[2024-11-29 02:54:36,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:36,147][root][INFO] - Training Epoch: 1/10, step 139/574 completed (loss: 5.206350326538086, acc: 0.1428571492433548)
[2024-11-29 02:54:36,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:36,379][root][INFO] - Training Epoch: 1/10, step 140/574 completed (loss: 4.76992130279541, acc: 0.11538461595773697)
[2024-11-29 02:54:36,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:36,596][root][INFO] - Training Epoch: 1/10, step 141/574 completed (loss: 4.42776346206665, acc: 0.09677419066429138)
[2024-11-29 02:54:36,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:36,870][root][INFO] - Training Epoch: 1/10, step 142/574 completed (loss: 3.9873769283294678, acc: 0.3243243098258972)
[2024-11-29 02:54:37,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:37,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:38,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:38,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:38,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:39,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:39,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:39,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:39,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:40,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:40,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:40,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:41,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:41,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:41,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:42,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:42,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:42,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:42,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:43,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:43,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:43,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:44,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:44,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:44,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:44,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:45,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:45,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:45,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:46,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:46,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:46,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:46,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:47,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:47,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:47,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:47,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:48,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:48,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:48,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:48,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:49,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:49,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:49,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:50,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:50,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:50,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:51,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:51,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:51,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:51,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:52,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:52,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:52,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:52,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:53,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:53,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:53,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:54,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:54,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:54,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:55,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:55,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:56,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:56,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:56,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:56,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:57,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:57,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:58,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:58,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:58,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:58,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:59,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:59,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:59,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:00,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:00,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:00,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:01,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:01,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:01,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:02,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:02,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:02,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:03,472][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(100.1549, device='cuda:0') eval_epoch_loss=tensor(4.6067, device='cuda:0') eval_epoch_acc=tensor(0.1516, device='cuda:0')
[2024-11-29 02:55:03,474][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 02:55:03,474][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 02:55:03,650][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_1_step_143_loss_4.606718063354492/model.pt
[2024-11-29 02:55:03,652][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 4.606718063354492
[2024-11-29 02:55:03,653][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.15156494081020355
[2024-11-29 02:55:03,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:04,175][root][INFO] - Training Epoch: 1/10, step 143/574 completed (loss: 3.3588039875030518, acc: 0.35087719559669495)
[2024-11-29 02:55:04,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:04,464][root][INFO] - Training Epoch: 1/10, step 144/574 completed (loss: 3.345055341720581, acc: 0.3731343150138855)
[2024-11-29 02:55:04,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:04,756][root][INFO] - Training Epoch: 1/10, step 145/574 completed (loss: 3.958343505859375, acc: 0.19387754797935486)
[2024-11-29 02:55:04,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:05,166][root][INFO] - Training Epoch: 1/10, step 146/574 completed (loss: 3.88747239112854, acc: 0.24468085169792175)
[2024-11-29 02:55:05,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:05,442][root][INFO] - Training Epoch: 1/10, step 147/574 completed (loss: 3.821546792984009, acc: 0.2857142984867096)
[2024-11-29 02:55:05,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:05,723][root][INFO] - Training Epoch: 1/10, step 148/574 completed (loss: 5.109114646911621, acc: 0.0714285746216774)
[2024-11-29 02:55:05,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:05,991][root][INFO] - Training Epoch: 1/10, step 149/574 completed (loss: 5.1822710037231445, acc: 0.08695652335882187)
[2024-11-29 02:55:06,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:06,273][root][INFO] - Training Epoch: 1/10, step 150/574 completed (loss: 4.54325532913208, acc: 0.1034482792019844)
[2024-11-29 02:55:06,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:06,561][root][INFO] - Training Epoch: 1/10, step 151/574 completed (loss: 4.30723237991333, acc: 0.260869562625885)
[2024-11-29 02:55:06,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:06,827][root][INFO] - Training Epoch: 1/10, step 152/574 completed (loss: 3.999688148498535, acc: 0.22033898532390594)
[2024-11-29 02:55:06,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:07,100][root][INFO] - Training Epoch: 1/10, step 153/574 completed (loss: 4.541356563568115, acc: 0.17543859779834747)
[2024-11-29 02:55:07,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:07,372][root][INFO] - Training Epoch: 1/10, step 154/574 completed (loss: 4.3835368156433105, acc: 0.20270270109176636)
[2024-11-29 02:55:07,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:07,646][root][INFO] - Training Epoch: 1/10, step 155/574 completed (loss: 4.725152015686035, acc: 0.25)
[2024-11-29 02:55:07,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:07,921][root][INFO] - Training Epoch: 1/10, step 156/574 completed (loss: 4.704996585845947, acc: 0.21739129722118378)
[2024-11-29 02:55:08,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:08,163][root][INFO] - Training Epoch: 1/10, step 157/574 completed (loss: 4.9181976318359375, acc: 0.21052631735801697)
[2024-11-29 02:55:08,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:09,844][root][INFO] - Training Epoch: 1/10, step 158/574 completed (loss: 4.830097675323486, acc: 0.1756756752729416)
[2024-11-29 02:55:09,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:10,055][root][INFO] - Training Epoch: 1/10, step 159/574 completed (loss: 4.442155838012695, acc: 0.14814814925193787)
[2024-11-29 02:55:10,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:10,400][root][INFO] - Training Epoch: 1/10, step 160/574 completed (loss: 4.973902702331543, acc: 0.1627907007932663)
[2024-11-29 02:55:10,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:10,987][root][INFO] - Training Epoch: 1/10, step 161/574 completed (loss: 4.430109977722168, acc: 0.20000000298023224)
[2024-11-29 02:55:11,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:11,461][root][INFO] - Training Epoch: 1/10, step 162/574 completed (loss: 4.447115898132324, acc: 0.24719101190567017)
[2024-11-29 02:55:11,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:11,763][root][INFO] - Training Epoch: 1/10, step 163/574 completed (loss: 4.4093828201293945, acc: 0.15909090638160706)
[2024-11-29 02:55:11,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:12,030][root][INFO] - Training Epoch: 1/10, step 164/574 completed (loss: 4.894322395324707, acc: 0.0476190485060215)
[2024-11-29 02:55:12,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:12,253][root][INFO] - Training Epoch: 1/10, step 165/574 completed (loss: 4.427256107330322, acc: 0.03448275849223137)
[2024-11-29 02:55:12,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:12,545][root][INFO] - Training Epoch: 1/10, step 166/574 completed (loss: 3.1321380138397217, acc: 0.3877550959587097)
[2024-11-29 02:55:12,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:12,821][root][INFO] - Training Epoch: 1/10, step 167/574 completed (loss: 3.9004485607147217, acc: 0.20000000298023224)
[2024-11-29 02:55:12,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:13,163][root][INFO] - Training Epoch: 1/10, step 168/574 completed (loss: 3.7525722980499268, acc: 0.3194444477558136)
[2024-11-29 02:55:13,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:13,444][root][INFO] - Training Epoch: 1/10, step 169/574 completed (loss: 3.8426804542541504, acc: 0.2647058963775635)
[2024-11-29 02:55:13,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:14,449][root][INFO] - Training Epoch: 1/10, step 170/574 completed (loss: 4.160364627838135, acc: 0.25342464447021484)
[2024-11-29 02:55:14,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:14,753][root][INFO] - Training Epoch: 1/10, step 171/574 completed (loss: 4.252321243286133, acc: 0.1666666716337204)
[2024-11-29 02:55:14,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:15,001][root][INFO] - Training Epoch: 1/10, step 172/574 completed (loss: 4.416166305541992, acc: 0.14814814925193787)
[2024-11-29 02:55:15,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:15,289][root][INFO] - Training Epoch: 1/10, step 173/574 completed (loss: 4.247000217437744, acc: 0.2142857164144516)
[2024-11-29 02:55:15,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:15,807][root][INFO] - Training Epoch: 1/10, step 174/574 completed (loss: 3.1234235763549805, acc: 0.39823007583618164)
[2024-11-29 02:55:15,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:16,051][root][INFO] - Training Epoch: 1/10, step 175/574 completed (loss: 4.185263156890869, acc: 0.15942029654979706)
[2024-11-29 02:55:16,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:16,382][root][INFO] - Training Epoch: 1/10, step 176/574 completed (loss: 3.9839937686920166, acc: 0.1818181872367859)
[2024-11-29 02:55:16,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:17,304][root][INFO] - Training Epoch: 1/10, step 177/574 completed (loss: 4.031612396240234, acc: 0.23664122819900513)
[2024-11-29 02:55:17,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:17,890][root][INFO] - Training Epoch: 1/10, step 178/574 completed (loss: 4.215446949005127, acc: 0.17037037014961243)
[2024-11-29 02:55:18,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:18,141][root][INFO] - Training Epoch: 1/10, step 179/574 completed (loss: 4.06559419631958, acc: 0.1803278625011444)
[2024-11-29 02:55:18,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:18,415][root][INFO] - Training Epoch: 1/10, step 180/574 completed (loss: 4.746326923370361, acc: 0.1666666716337204)
[2024-11-29 02:55:18,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:18,681][root][INFO] - Training Epoch: 1/10, step 181/574 completed (loss: 4.383328437805176, acc: 0.20000000298023224)
[2024-11-29 02:55:18,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:18,936][root][INFO] - Training Epoch: 1/10, step 182/574 completed (loss: 4.902483940124512, acc: 0.1428571492433548)
[2024-11-29 02:55:19,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:19,218][root][INFO] - Training Epoch: 1/10, step 183/574 completed (loss: 4.1538543701171875, acc: 0.13414634764194489)
[2024-11-29 02:55:19,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:19,517][root][INFO] - Training Epoch: 1/10, step 184/574 completed (loss: 3.7106826305389404, acc: 0.24773414433002472)
[2024-11-29 02:55:19,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:19,784][root][INFO] - Training Epoch: 1/10, step 185/574 completed (loss: 3.751366376876831, acc: 0.20749279856681824)
[2024-11-29 02:55:19,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:20,238][root][INFO] - Training Epoch: 1/10, step 186/574 completed (loss: 3.8156185150146484, acc: 0.20000000298023224)
[2024-11-29 02:55:20,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:20,685][root][INFO] - Training Epoch: 1/10, step 187/574 completed (loss: 3.54310941696167, acc: 0.25328329205513)
[2024-11-29 02:55:20,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:21,052][root][INFO] - Training Epoch: 1/10, step 188/574 completed (loss: 3.50502610206604, acc: 0.2633451819419861)
[2024-11-29 02:55:21,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:21,310][root][INFO] - Training Epoch: 1/10, step 189/574 completed (loss: 4.3866167068481445, acc: 0.11999999731779099)
[2024-11-29 02:55:21,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:21,869][root][INFO] - Training Epoch: 1/10, step 190/574 completed (loss: 3.879371404647827, acc: 0.27906978130340576)
[2024-11-29 02:55:22,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:22,646][root][INFO] - Training Epoch: 1/10, step 191/574 completed (loss: 3.9687469005584717, acc: 0.261904776096344)
[2024-11-29 02:55:22,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:23,487][root][INFO] - Training Epoch: 1/10, step 192/574 completed (loss: 3.707543134689331, acc: 0.31060606241226196)
[2024-11-29 02:55:23,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:24,159][root][INFO] - Training Epoch: 1/10, step 193/574 completed (loss: 3.5646979808807373, acc: 0.34117648005485535)
[2024-11-29 02:55:24,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:25,137][root][INFO] - Training Epoch: 1/10, step 194/574 completed (loss: 3.3579165935516357, acc: 0.29012346267700195)
[2024-11-29 02:55:25,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:25,985][root][INFO] - Training Epoch: 1/10, step 195/574 completed (loss: 3.9983248710632324, acc: 0.24193547666072845)
[2024-11-29 02:55:26,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:26,183][root][INFO] - Training Epoch: 1/10, step 196/574 completed (loss: 3.5759522914886475, acc: 0.25)
[2024-11-29 02:55:26,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:26,460][root][INFO] - Training Epoch: 1/10, step 197/574 completed (loss: 4.361815452575684, acc: 0.125)
[2024-11-29 02:55:26,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:26,752][root][INFO] - Training Epoch: 1/10, step 198/574 completed (loss: 4.410869598388672, acc: 0.14705882966518402)
[2024-11-29 02:55:26,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:27,072][root][INFO] - Training Epoch: 1/10, step 199/574 completed (loss: 3.7071340084075928, acc: 0.2647058963775635)
[2024-11-29 02:55:27,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:27,382][root][INFO] - Training Epoch: 1/10, step 200/574 completed (loss: 3.608405590057373, acc: 0.2288135588169098)
[2024-11-29 02:55:27,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:27,659][root][INFO] - Training Epoch: 1/10, step 201/574 completed (loss: 3.7957847118377686, acc: 0.26865673065185547)
[2024-11-29 02:55:27,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:27,934][root][INFO] - Training Epoch: 1/10, step 202/574 completed (loss: 4.132232189178467, acc: 0.18446601927280426)
[2024-11-29 02:55:28,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:28,152][root][INFO] - Training Epoch: 1/10, step 203/574 completed (loss: 3.7094967365264893, acc: 0.30158731341362)
[2024-11-29 02:55:28,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:28,367][root][INFO] - Training Epoch: 1/10, step 204/574 completed (loss: 3.727372407913208, acc: 0.17582418024539948)
[2024-11-29 02:55:28,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:28,615][root][INFO] - Training Epoch: 1/10, step 205/574 completed (loss: 3.6371843814849854, acc: 0.219730943441391)
[2024-11-29 02:55:28,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:28,972][root][INFO] - Training Epoch: 1/10, step 206/574 completed (loss: 3.475353240966797, acc: 0.32283464074134827)
[2024-11-29 02:55:29,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:29,212][root][INFO] - Training Epoch: 1/10, step 207/574 completed (loss: 3.567552328109741, acc: 0.27586206793785095)
[2024-11-29 02:55:29,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:29,479][root][INFO] - Training Epoch: 1/10, step 208/574 completed (loss: 3.1120221614837646, acc: 0.3550724685192108)
[2024-11-29 02:55:29,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:29,763][root][INFO] - Training Epoch: 1/10, step 209/574 completed (loss: 3.639946222305298, acc: 0.2529182732105255)
[2024-11-29 02:55:29,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:30,008][root][INFO] - Training Epoch: 1/10, step 210/574 completed (loss: 3.9116175174713135, acc: 0.18478260934352875)
[2024-11-29 02:55:30,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:30,228][root][INFO] - Training Epoch: 1/10, step 211/574 completed (loss: 3.343289852142334, acc: 0.30434781312942505)
[2024-11-29 02:55:30,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:30,445][root][INFO] - Training Epoch: 1/10, step 212/574 completed (loss: 3.8648438453674316, acc: 0.1785714328289032)
[2024-11-29 02:55:30,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:30,688][root][INFO] - Training Epoch: 1/10, step 213/574 completed (loss: 3.8169052600860596, acc: 0.21276596188545227)
[2024-11-29 02:55:30,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:31,359][root][INFO] - Training Epoch: 1/10, step 214/574 completed (loss: 3.795708656311035, acc: 0.20769231021404266)
[2024-11-29 02:55:31,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:31,619][root][INFO] - Training Epoch: 1/10, step 215/574 completed (loss: 4.13264274597168, acc: 0.06756756454706192)
[2024-11-29 02:55:31,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:31,864][root][INFO] - Training Epoch: 1/10, step 216/574 completed (loss: 3.880786180496216, acc: 0.1744185984134674)
[2024-11-29 02:55:32,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:32,340][root][INFO] - Training Epoch: 1/10, step 217/574 completed (loss: 3.967393398284912, acc: 0.18918919563293457)
[2024-11-29 02:55:32,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:32,656][root][INFO] - Training Epoch: 1/10, step 218/574 completed (loss: 3.648988962173462, acc: 0.2222222238779068)
[2024-11-29 02:55:32,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:32,866][root][INFO] - Training Epoch: 1/10, step 219/574 completed (loss: 4.063109397888184, acc: 0.21212121844291687)
[2024-11-29 02:55:32,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:33,080][root][INFO] - Training Epoch: 1/10, step 220/574 completed (loss: 3.293104648590088, acc: 0.29629629850387573)
[2024-11-29 02:55:33,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:33,320][root][INFO] - Training Epoch: 1/10, step 221/574 completed (loss: 3.6050803661346436, acc: 0.23999999463558197)
[2024-11-29 02:55:33,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:33,581][root][INFO] - Training Epoch: 1/10, step 222/574 completed (loss: 3.830287456512451, acc: 0.1538461595773697)
[2024-11-29 02:55:33,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:34,267][root][INFO] - Training Epoch: 1/10, step 223/574 completed (loss: 3.3941397666931152, acc: 0.3478260934352875)
[2024-11-29 02:55:34,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:34,759][root][INFO] - Training Epoch: 1/10, step 224/574 completed (loss: 3.408621072769165, acc: 0.3238636255264282)
[2024-11-29 02:55:34,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:35,129][root][INFO] - Training Epoch: 1/10, step 225/574 completed (loss: 3.570648431777954, acc: 0.23404255509376526)
[2024-11-29 02:55:35,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:35,407][root][INFO] - Training Epoch: 1/10, step 226/574 completed (loss: 3.985421895980835, acc: 0.3207547068595886)
[2024-11-29 02:55:35,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:35,666][root][INFO] - Training Epoch: 1/10, step 227/574 completed (loss: 3.5936126708984375, acc: 0.2666666805744171)
[2024-11-29 02:55:35,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:35,922][root][INFO] - Training Epoch: 1/10, step 228/574 completed (loss: 3.163935899734497, acc: 0.39534884691238403)
[2024-11-29 02:55:36,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:36,182][root][INFO] - Training Epoch: 1/10, step 229/574 completed (loss: 4.09730339050293, acc: 0.20000000298023224)
[2024-11-29 02:55:36,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:36,499][root][INFO] - Training Epoch: 1/10, step 230/574 completed (loss: 4.198202610015869, acc: 0.13684210181236267)
[2024-11-29 02:55:36,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:36,819][root][INFO] - Training Epoch: 1/10, step 231/574 completed (loss: 3.870504379272461, acc: 0.24444444477558136)
[2024-11-29 02:55:37,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:37,197][root][INFO] - Training Epoch: 1/10, step 232/574 completed (loss: 3.071035146713257, acc: 0.3611111044883728)
[2024-11-29 02:55:37,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:37,673][root][INFO] - Training Epoch: 1/10, step 233/574 completed (loss: 3.39585018157959, acc: 0.35321101546287537)
[2024-11-29 02:55:37,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:38,067][root][INFO] - Training Epoch: 1/10, step 234/574 completed (loss: 3.369281768798828, acc: 0.3384615480899811)
[2024-11-29 02:55:38,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:38,327][root][INFO] - Training Epoch: 1/10, step 235/574 completed (loss: 4.045759677886963, acc: 0.10526315867900848)
[2024-11-29 02:55:38,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:38,612][root][INFO] - Training Epoch: 1/10, step 236/574 completed (loss: 3.3199260234832764, acc: 0.2916666567325592)
[2024-11-29 02:55:38,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:38,923][root][INFO] - Training Epoch: 1/10, step 237/574 completed (loss: 3.959130048751831, acc: 0.22727273404598236)
[2024-11-29 02:55:39,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:39,238][root][INFO] - Training Epoch: 1/10, step 238/574 completed (loss: 3.329624891281128, acc: 0.3333333432674408)
[2024-11-29 02:55:39,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:39,531][root][INFO] - Training Epoch: 1/10, step 239/574 completed (loss: 3.220836639404297, acc: 0.34285715222358704)
[2024-11-29 02:55:39,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:39,787][root][INFO] - Training Epoch: 1/10, step 240/574 completed (loss: 3.3094537258148193, acc: 0.3181818127632141)
[2024-11-29 02:55:39,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:40,018][root][INFO] - Training Epoch: 1/10, step 241/574 completed (loss: 3.4105031490325928, acc: 0.25)
[2024-11-29 02:55:40,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:40,569][root][INFO] - Training Epoch: 1/10, step 242/574 completed (loss: 3.8850905895233154, acc: 0.27419355511665344)
[2024-11-29 02:55:40,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:41,054][root][INFO] - Training Epoch: 1/10, step 243/574 completed (loss: 3.5651209354400635, acc: 0.2954545319080353)
[2024-11-29 02:55:41,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:41,279][root][INFO] - Training Epoch: 1/10, step 244/574 completed (loss: 3.9323222637176514, acc: 0.190476194024086)
[2024-11-29 02:55:41,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:41,516][root][INFO] - Training Epoch: 1/10, step 245/574 completed (loss: 3.957205295562744, acc: 0.3076923191547394)
[2024-11-29 02:55:41,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:41,789][root][INFO] - Training Epoch: 1/10, step 246/574 completed (loss: 4.476607799530029, acc: 0.19354838132858276)
[2024-11-29 02:55:41,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:41,998][root][INFO] - Training Epoch: 1/10, step 247/574 completed (loss: 2.9824254512786865, acc: 0.30000001192092896)
[2024-11-29 02:55:42,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:42,305][root][INFO] - Training Epoch: 1/10, step 248/574 completed (loss: 3.8830666542053223, acc: 0.2432432472705841)
[2024-11-29 02:55:42,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:42,632][root][INFO] - Training Epoch: 1/10, step 249/574 completed (loss: 3.9463438987731934, acc: 0.21621622145175934)
[2024-11-29 02:55:42,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:42,910][root][INFO] - Training Epoch: 1/10, step 250/574 completed (loss: 3.9664690494537354, acc: 0.2702702581882477)
[2024-11-29 02:55:43,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:43,167][root][INFO] - Training Epoch: 1/10, step 251/574 completed (loss: 4.379661560058594, acc: 0.10294117778539658)
[2024-11-29 02:55:43,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:43,418][root][INFO] - Training Epoch: 1/10, step 252/574 completed (loss: 3.2737984657287598, acc: 0.31707316637039185)
[2024-11-29 02:55:43,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:43,699][root][INFO] - Training Epoch: 1/10, step 253/574 completed (loss: 4.088860988616943, acc: 0.23999999463558197)
[2024-11-29 02:55:43,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:43,997][root][INFO] - Training Epoch: 1/10, step 254/574 completed (loss: 3.306488037109375, acc: 0.3199999928474426)
[2024-11-29 02:55:44,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:44,301][root][INFO] - Training Epoch: 1/10, step 255/574 completed (loss: 4.178542137145996, acc: 0.22580644488334656)
[2024-11-29 02:55:44,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:44,553][root][INFO] - Training Epoch: 1/10, step 256/574 completed (loss: 4.084155559539795, acc: 0.08771929889917374)
[2024-11-29 02:55:44,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:44,846][root][INFO] - Training Epoch: 1/10, step 257/574 completed (loss: 3.690091848373413, acc: 0.20000000298023224)
[2024-11-29 02:55:45,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:45,155][root][INFO] - Training Epoch: 1/10, step 258/574 completed (loss: 3.810814619064331, acc: 0.22368420660495758)
[2024-11-29 02:55:45,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:45,668][root][INFO] - Training Epoch: 1/10, step 259/574 completed (loss: 3.5973029136657715, acc: 0.27358490228652954)
[2024-11-29 02:55:45,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:46,178][root][INFO] - Training Epoch: 1/10, step 260/574 completed (loss: 3.7909018993377686, acc: 0.2750000059604645)
[2024-11-29 02:55:46,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:46,381][root][INFO] - Training Epoch: 1/10, step 261/574 completed (loss: 3.6100759506225586, acc: 0.1944444477558136)
[2024-11-29 02:55:46,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:46,634][root][INFO] - Training Epoch: 1/10, step 262/574 completed (loss: 3.573084592819214, acc: 0.25806450843811035)
[2024-11-29 02:55:46,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:46,941][root][INFO] - Training Epoch: 1/10, step 263/574 completed (loss: 3.3027100563049316, acc: 0.2800000011920929)
[2024-11-29 02:55:47,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:47,170][root][INFO] - Training Epoch: 1/10, step 264/574 completed (loss: 3.529179334640503, acc: 0.2291666716337204)
[2024-11-29 02:55:47,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:47,984][root][INFO] - Training Epoch: 1/10, step 265/574 completed (loss: 3.489636182785034, acc: 0.3199999928474426)
[2024-11-29 02:55:48,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:48,236][root][INFO] - Training Epoch: 1/10, step 266/574 completed (loss: 3.3188529014587402, acc: 0.2808988690376282)
[2024-11-29 02:55:48,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:48,519][root][INFO] - Training Epoch: 1/10, step 267/574 completed (loss: 3.9037256240844727, acc: 0.28378379344940186)
[2024-11-29 02:55:48,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:48,903][root][INFO] - Training Epoch: 1/10, step 268/574 completed (loss: 3.3531012535095215, acc: 0.3103448152542114)
[2024-11-29 02:55:49,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:49,147][root][INFO] - Training Epoch: 1/10, step 269/574 completed (loss: 3.8051161766052246, acc: 0.1818181872367859)
[2024-11-29 02:55:49,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:49,386][root][INFO] - Training Epoch: 1/10, step 270/574 completed (loss: 2.649371385574341, acc: 0.3181818127632141)
[2024-11-29 02:55:49,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:49,640][root][INFO] - Training Epoch: 1/10, step 271/574 completed (loss: 2.9863762855529785, acc: 0.28125)
[2024-11-29 02:55:49,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:49,911][root][INFO] - Training Epoch: 1/10, step 272/574 completed (loss: 3.206261157989502, acc: 0.30000001192092896)
[2024-11-29 02:55:50,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:50,257][root][INFO] - Training Epoch: 1/10, step 273/574 completed (loss: 3.0503249168395996, acc: 0.3333333432674408)
[2024-11-29 02:55:50,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:50,469][root][INFO] - Training Epoch: 1/10, step 274/574 completed (loss: 3.5814931392669678, acc: 0.25)
[2024-11-29 02:55:50,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:50,776][root][INFO] - Training Epoch: 1/10, step 275/574 completed (loss: 3.0173964500427246, acc: 0.4333333373069763)
[2024-11-29 02:55:50,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:51,064][root][INFO] - Training Epoch: 1/10, step 276/574 completed (loss: 3.8920609951019287, acc: 0.24137930572032928)
[2024-11-29 02:55:51,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:51,319][root][INFO] - Training Epoch: 1/10, step 277/574 completed (loss: 3.338390827178955, acc: 0.20000000298023224)
[2024-11-29 02:55:51,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:51,582][root][INFO] - Training Epoch: 1/10, step 278/574 completed (loss: 3.5593936443328857, acc: 0.1489361673593521)
[2024-11-29 02:55:51,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:51,814][root][INFO] - Training Epoch: 1/10, step 279/574 completed (loss: 3.5290586948394775, acc: 0.25)
[2024-11-29 02:55:51,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:52,047][root][INFO] - Training Epoch: 1/10, step 280/574 completed (loss: 2.6143898963928223, acc: 0.4318181872367859)
[2024-11-29 02:55:52,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:52,402][root][INFO] - Training Epoch: 1/10, step 281/574 completed (loss: 3.60186767578125, acc: 0.2530120611190796)
[2024-11-29 02:55:52,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:52,670][root][INFO] - Training Epoch: 1/10, step 282/574 completed (loss: 3.235421895980835, acc: 0.28703704476356506)
[2024-11-29 02:55:52,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:52,909][root][INFO] - Training Epoch: 1/10, step 283/574 completed (loss: 3.8393561840057373, acc: 0.2368421107530594)
[2024-11-29 02:55:53,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:53,141][root][INFO] - Training Epoch: 1/10, step 284/574 completed (loss: 3.0460219383239746, acc: 0.29411765933036804)
[2024-11-29 02:55:53,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:53,413][root][INFO] - Training Epoch: 1/10, step 285/574 completed (loss: 3.143472194671631, acc: 0.2750000059604645)
[2024-11-29 02:55:54,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:54,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:54,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:54,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:55,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:55,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:55,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:56,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:56,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:56,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:56,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:57,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:57,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:57,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:58,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:58,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:58,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:59,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:59,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:59,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:59,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:00,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:00,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:00,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:00,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:01,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:01,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:01,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:01,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:02,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:02,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:02,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:03,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:03,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:03,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:03,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:04,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:04,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:04,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:05,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:05,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:05,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:05,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:06,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:06,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:06,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:06,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:07,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:07,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:07,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:08,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:08,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:08,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:09,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:09,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:09,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:09,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:10,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:10,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:10,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:10,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:11,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:11,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:11,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:12,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:12,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:12,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:12,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:13,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:13,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:13,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:14,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:14,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:14,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:15,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:15,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:15,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:15,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:16,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:16,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:16,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:17,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:17,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:17,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:18,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:18,640][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(34.1518, device='cuda:0') eval_epoch_loss=tensor(3.5308, device='cuda:0') eval_epoch_acc=tensor(0.2500, device='cuda:0')
[2024-11-29 02:56:18,641][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 02:56:18,641][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 02:56:18,898][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_1_step_286_loss_3.5308141708374023/model.pt
[2024-11-29 02:56:18,901][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 3.5308141708374023
[2024-11-29 02:56:18,901][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.24997760355472565
[2024-11-29 02:56:19,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:19,212][root][INFO] - Training Epoch: 1/10, step 286/574 completed (loss: 3.290513753890991, acc: 0.25)
[2024-11-29 02:56:19,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:19,500][root][INFO] - Training Epoch: 1/10, step 287/574 completed (loss: 3.686511754989624, acc: 0.18400000035762787)
[2024-11-29 02:56:19,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:19,779][root][INFO] - Training Epoch: 1/10, step 288/574 completed (loss: 3.469571590423584, acc: 0.2857142984867096)
[2024-11-29 02:56:19,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:20,094][root][INFO] - Training Epoch: 1/10, step 289/574 completed (loss: 3.4509148597717285, acc: 0.23602484166622162)
[2024-11-29 02:56:20,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:20,386][root][INFO] - Training Epoch: 1/10, step 290/574 completed (loss: 3.516225576400757, acc: 0.24742268025875092)
[2024-11-29 02:56:20,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:20,664][root][INFO] - Training Epoch: 1/10, step 291/574 completed (loss: 3.9001450538635254, acc: 0.3181818127632141)
[2024-11-29 02:56:20,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:20,898][root][INFO] - Training Epoch: 1/10, step 292/574 completed (loss: 3.198385715484619, acc: 0.380952388048172)
[2024-11-29 02:56:21,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:21,157][root][INFO] - Training Epoch: 1/10, step 293/574 completed (loss: 3.4506967067718506, acc: 0.36206895112991333)
[2024-11-29 02:56:21,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:21,569][root][INFO] - Training Epoch: 1/10, step 294/574 completed (loss: 2.6281023025512695, acc: 0.4545454680919647)
[2024-11-29 02:56:21,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:22,070][root][INFO] - Training Epoch: 1/10, step 295/574 completed (loss: 2.9718117713928223, acc: 0.39175257086753845)
[2024-11-29 02:56:22,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:22,344][root][INFO] - Training Epoch: 1/10, step 296/574 completed (loss: 3.2431106567382812, acc: 0.2931034564971924)
[2024-11-29 02:56:22,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:22,581][root][INFO] - Training Epoch: 1/10, step 297/574 completed (loss: 3.1598613262176514, acc: 0.3333333432674408)
[2024-11-29 02:56:22,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:22,802][root][INFO] - Training Epoch: 1/10, step 298/574 completed (loss: 3.6846096515655518, acc: 0.2368421107530594)
[2024-11-29 02:56:22,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:23,023][root][INFO] - Training Epoch: 1/10, step 299/574 completed (loss: 3.6126208305358887, acc: 0.2142857164144516)
[2024-11-29 02:56:23,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:23,299][root][INFO] - Training Epoch: 1/10, step 300/574 completed (loss: 3.025721788406372, acc: 0.25)
[2024-11-29 02:56:23,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:23,572][root][INFO] - Training Epoch: 1/10, step 301/574 completed (loss: 3.531843662261963, acc: 0.22641509771347046)
[2024-11-29 02:56:23,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:23,808][root][INFO] - Training Epoch: 1/10, step 302/574 completed (loss: 3.121936321258545, acc: 0.30188679695129395)
[2024-11-29 02:56:23,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:24,071][root][INFO] - Training Epoch: 1/10, step 303/574 completed (loss: 3.136340856552124, acc: 0.29411765933036804)
[2024-11-29 02:56:24,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:24,368][root][INFO] - Training Epoch: 1/10, step 304/574 completed (loss: 3.3168773651123047, acc: 0.3125)
[2024-11-29 02:56:24,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:24,666][root][INFO] - Training Epoch: 1/10, step 305/574 completed (loss: 3.3674116134643555, acc: 0.32786884903907776)
[2024-11-29 02:56:24,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:24,924][root][INFO] - Training Epoch: 1/10, step 306/574 completed (loss: 3.089632272720337, acc: 0.4000000059604645)
[2024-11-29 02:56:25,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:25,186][root][INFO] - Training Epoch: 1/10, step 307/574 completed (loss: 3.9607908725738525, acc: 0.21052631735801697)
[2024-11-29 02:56:25,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:25,478][root][INFO] - Training Epoch: 1/10, step 308/574 completed (loss: 3.534527540206909, acc: 0.18840579688549042)
[2024-11-29 02:56:25,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:25,842][root][INFO] - Training Epoch: 1/10, step 309/574 completed (loss: 3.244685649871826, acc: 0.3472222089767456)
[2024-11-29 02:56:25,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:26,067][root][INFO] - Training Epoch: 1/10, step 310/574 completed (loss: 3.3164048194885254, acc: 0.3132530152797699)
[2024-11-29 02:56:26,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:26,374][root][INFO] - Training Epoch: 1/10, step 311/574 completed (loss: 3.5349888801574707, acc: 0.25641027092933655)
[2024-11-29 02:56:26,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:26,679][root][INFO] - Training Epoch: 1/10, step 312/574 completed (loss: 3.6348650455474854, acc: 0.2142857164144516)
[2024-11-29 02:56:26,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:26,903][root][INFO] - Training Epoch: 1/10, step 313/574 completed (loss: 3.5767745971679688, acc: 0.1666666716337204)
[2024-11-29 02:56:27,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:27,147][root][INFO] - Training Epoch: 1/10, step 314/574 completed (loss: 3.2977800369262695, acc: 0.2916666567325592)
[2024-11-29 02:56:27,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:27,390][root][INFO] - Training Epoch: 1/10, step 315/574 completed (loss: 3.570448875427246, acc: 0.22580644488334656)
[2024-11-29 02:56:27,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:27,667][root][INFO] - Training Epoch: 1/10, step 316/574 completed (loss: 3.6891372203826904, acc: 0.29032257199287415)
[2024-11-29 02:56:27,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:28,021][root][INFO] - Training Epoch: 1/10, step 317/574 completed (loss: 3.279449701309204, acc: 0.2985074520111084)
[2024-11-29 02:56:28,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:28,345][root][INFO] - Training Epoch: 1/10, step 318/574 completed (loss: 2.89656400680542, acc: 0.35576921701431274)
[2024-11-29 02:56:28,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:28,648][root][INFO] - Training Epoch: 1/10, step 319/574 completed (loss: 3.8363518714904785, acc: 0.13333334028720856)
[2024-11-29 02:56:28,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:28,949][root][INFO] - Training Epoch: 1/10, step 320/574 completed (loss: 3.629629135131836, acc: 0.14516128599643707)
[2024-11-29 02:56:29,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:29,253][root][INFO] - Training Epoch: 1/10, step 321/574 completed (loss: 3.3035573959350586, acc: 0.2199999988079071)
[2024-11-29 02:56:29,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:29,513][root][INFO] - Training Epoch: 1/10, step 322/574 completed (loss: 3.8121156692504883, acc: 0.07407407462596893)
[2024-11-29 02:56:29,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:29,698][root][INFO] - Training Epoch: 1/10, step 323/574 completed (loss: 4.136711597442627, acc: 0.02857142873108387)
[2024-11-29 02:56:29,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:29,967][root][INFO] - Training Epoch: 1/10, step 324/574 completed (loss: 3.821490526199341, acc: 0.25641027092933655)
[2024-11-29 02:56:30,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:30,291][root][INFO] - Training Epoch: 1/10, step 325/574 completed (loss: 3.5934360027313232, acc: 0.2195121943950653)
[2024-11-29 02:56:30,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:30,515][root][INFO] - Training Epoch: 1/10, step 326/574 completed (loss: 3.2263567447662354, acc: 0.34210526943206787)
[2024-11-29 02:56:30,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:30,748][root][INFO] - Training Epoch: 1/10, step 327/574 completed (loss: 3.975954055786133, acc: 0.2631579041481018)
[2024-11-29 02:56:30,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:31,000][root][INFO] - Training Epoch: 1/10, step 328/574 completed (loss: 3.63655424118042, acc: 0.2857142984867096)
[2024-11-29 02:56:31,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:31,231][root][INFO] - Training Epoch: 1/10, step 329/574 completed (loss: 3.122453212738037, acc: 0.2222222238779068)
[2024-11-29 02:56:31,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:31,453][root][INFO] - Training Epoch: 1/10, step 330/574 completed (loss: 2.827613115310669, acc: 0.4375)
[2024-11-29 02:56:31,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:31,681][root][INFO] - Training Epoch: 1/10, step 331/574 completed (loss: 3.3955559730529785, acc: 0.32258063554763794)
[2024-11-29 02:56:31,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:31,989][root][INFO] - Training Epoch: 1/10, step 332/574 completed (loss: 2.709777355194092, acc: 0.42105263471603394)
[2024-11-29 02:56:32,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:32,250][root][INFO] - Training Epoch: 1/10, step 333/574 completed (loss: 3.300584077835083, acc: 0.1875)
[2024-11-29 02:56:32,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:32,520][root][INFO] - Training Epoch: 1/10, step 334/574 completed (loss: 3.2385668754577637, acc: 0.2666666805744171)
[2024-11-29 02:56:32,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:32,738][root][INFO] - Training Epoch: 1/10, step 335/574 completed (loss: 2.9727914333343506, acc: 0.31578946113586426)
[2024-11-29 02:56:32,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:32,981][root][INFO] - Training Epoch: 1/10, step 336/574 completed (loss: 3.024624824523926, acc: 0.20000000298023224)
[2024-11-29 02:56:33,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:33,261][root][INFO] - Training Epoch: 1/10, step 337/574 completed (loss: 3.4698030948638916, acc: 0.27586206793785095)
[2024-11-29 02:56:33,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:33,536][root][INFO] - Training Epoch: 1/10, step 338/574 completed (loss: 3.588247537612915, acc: 0.26595744490623474)
[2024-11-29 02:56:33,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:33,764][root][INFO] - Training Epoch: 1/10, step 339/574 completed (loss: 3.6612560749053955, acc: 0.22891566157341003)
[2024-11-29 02:56:33,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:34,013][root][INFO] - Training Epoch: 1/10, step 340/574 completed (loss: 2.9936702251434326, acc: 0.3913043439388275)
[2024-11-29 02:56:34,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:34,274][root][INFO] - Training Epoch: 1/10, step 341/574 completed (loss: 3.9423530101776123, acc: 0.1538461595773697)
[2024-11-29 02:56:34,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:34,533][root][INFO] - Training Epoch: 1/10, step 342/574 completed (loss: 3.9545600414276123, acc: 0.1927710771560669)
[2024-11-29 02:56:34,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:34,849][root][INFO] - Training Epoch: 1/10, step 343/574 completed (loss: 3.7306599617004395, acc: 0.16981132328510284)
[2024-11-29 02:56:35,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:35,138][root][INFO] - Training Epoch: 1/10, step 344/574 completed (loss: 3.5543131828308105, acc: 0.2151898741722107)
[2024-11-29 02:56:35,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:35,376][root][INFO] - Training Epoch: 1/10, step 345/574 completed (loss: 3.155308485031128, acc: 0.29411765933036804)
[2024-11-29 02:56:35,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:35,695][root][INFO] - Training Epoch: 1/10, step 346/574 completed (loss: 3.5864994525909424, acc: 0.20895522832870483)
[2024-11-29 02:56:35,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:35,956][root][INFO] - Training Epoch: 1/10, step 347/574 completed (loss: 3.272817611694336, acc: 0.30000001192092896)
[2024-11-29 02:56:36,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:36,269][root][INFO] - Training Epoch: 1/10, step 348/574 completed (loss: 3.3129684925079346, acc: 0.20000000298023224)
[2024-11-29 02:56:36,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:36,637][root][INFO] - Training Epoch: 1/10, step 349/574 completed (loss: 3.518855571746826, acc: 0.3333333432674408)
[2024-11-29 02:56:36,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:36,859][root][INFO] - Training Epoch: 1/10, step 350/574 completed (loss: 3.247964859008789, acc: 0.302325576543808)
[2024-11-29 02:56:37,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:37,138][root][INFO] - Training Epoch: 1/10, step 351/574 completed (loss: 3.5409631729125977, acc: 0.25641027092933655)
[2024-11-29 02:56:37,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:37,430][root][INFO] - Training Epoch: 1/10, step 352/574 completed (loss: 3.5761141777038574, acc: 0.2888889014720917)
[2024-11-29 02:56:37,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:37,686][root][INFO] - Training Epoch: 1/10, step 353/574 completed (loss: 2.9737741947174072, acc: 0.3913043439388275)
[2024-11-29 02:56:37,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:37,956][root][INFO] - Training Epoch: 1/10, step 354/574 completed (loss: 3.4792706966400146, acc: 0.3076923191547394)
[2024-11-29 02:56:38,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:38,239][root][INFO] - Training Epoch: 1/10, step 355/574 completed (loss: 3.459242820739746, acc: 0.21978022158145905)
[2024-11-29 02:56:38,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:38,722][root][INFO] - Training Epoch: 1/10, step 356/574 completed (loss: 3.1264991760253906, acc: 0.35652172565460205)
[2024-11-29 02:56:38,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:39,028][root][INFO] - Training Epoch: 1/10, step 357/574 completed (loss: 3.4871323108673096, acc: 0.239130437374115)
[2024-11-29 02:56:39,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:39,374][root][INFO] - Training Epoch: 1/10, step 358/574 completed (loss: 3.2342824935913086, acc: 0.3265306055545807)
[2024-11-29 02:56:39,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:39,681][root][INFO] - Training Epoch: 1/10, step 359/574 completed (loss: 3.1706440448760986, acc: 0.2916666567325592)
[2024-11-29 02:56:39,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:39,988][root][INFO] - Training Epoch: 1/10, step 360/574 completed (loss: 3.168083429336548, acc: 0.23076923191547394)
[2024-11-29 02:56:40,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:40,243][root][INFO] - Training Epoch: 1/10, step 361/574 completed (loss: 3.4576170444488525, acc: 0.2926829159259796)
[2024-11-29 02:56:40,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:40,488][root][INFO] - Training Epoch: 1/10, step 362/574 completed (loss: 3.0622494220733643, acc: 0.2888889014720917)
[2024-11-29 02:56:40,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:40,785][root][INFO] - Training Epoch: 1/10, step 363/574 completed (loss: 3.3225443363189697, acc: 0.25)
[2024-11-29 02:56:40,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:41,042][root][INFO] - Training Epoch: 1/10, step 364/574 completed (loss: 3.439502716064453, acc: 0.17073170840740204)
[2024-11-29 02:56:41,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:41,243][root][INFO] - Training Epoch: 1/10, step 365/574 completed (loss: 3.2874958515167236, acc: 0.21212121844291687)
[2024-11-29 02:56:41,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:41,454][root][INFO] - Training Epoch: 1/10, step 366/574 completed (loss: 2.412555694580078, acc: 0.4166666567325592)
[2024-11-29 02:56:41,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:41,735][root][INFO] - Training Epoch: 1/10, step 367/574 completed (loss: 2.7243478298187256, acc: 0.43478259444236755)
[2024-11-29 02:56:41,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:41,978][root][INFO] - Training Epoch: 1/10, step 368/574 completed (loss: 3.0341503620147705, acc: 0.2142857164144516)
[2024-11-29 02:56:42,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:42,172][root][INFO] - Training Epoch: 1/10, step 369/574 completed (loss: 2.9485745429992676, acc: 0.375)
[2024-11-29 02:56:42,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:42,733][root][INFO] - Training Epoch: 1/10, step 370/574 completed (loss: 3.689518928527832, acc: 0.2666666805744171)
[2024-11-29 02:56:43,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:43,544][root][INFO] - Training Epoch: 1/10, step 371/574 completed (loss: 2.9148964881896973, acc: 0.4245283007621765)
[2024-11-29 02:56:43,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:43,789][root][INFO] - Training Epoch: 1/10, step 372/574 completed (loss: 2.8924143314361572, acc: 0.3333333432674408)
[2024-11-29 02:56:43,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:44,062][root][INFO] - Training Epoch: 1/10, step 373/574 completed (loss: 3.4586544036865234, acc: 0.3214285671710968)
[2024-11-29 02:56:44,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:44,380][root][INFO] - Training Epoch: 1/10, step 374/574 completed (loss: 2.4535655975341797, acc: 0.48571428656578064)
[2024-11-29 02:56:44,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:44,640][root][INFO] - Training Epoch: 1/10, step 375/574 completed (loss: 3.298722743988037, acc: 0.23999999463558197)
[2024-11-29 02:56:44,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:44,861][root][INFO] - Training Epoch: 1/10, step 376/574 completed (loss: 2.6062111854553223, acc: 0.3478260934352875)
[2024-11-29 02:56:44,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:45,159][root][INFO] - Training Epoch: 1/10, step 377/574 completed (loss: 3.5265884399414062, acc: 0.3125)
[2024-11-29 02:56:45,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:45,469][root][INFO] - Training Epoch: 1/10, step 378/574 completed (loss: 2.900921583175659, acc: 0.34736841917037964)
[2024-11-29 02:56:45,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:46,015][root][INFO] - Training Epoch: 1/10, step 379/574 completed (loss: 2.8741681575775146, acc: 0.3652694523334503)
[2024-11-29 02:56:46,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:46,339][root][INFO] - Training Epoch: 1/10, step 380/574 completed (loss: 2.720672369003296, acc: 0.4436090290546417)
[2024-11-29 02:56:46,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:47,347][root][INFO] - Training Epoch: 1/10, step 381/574 completed (loss: 3.0629849433898926, acc: 0.4010695219039917)
[2024-11-29 02:56:47,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:47,821][root][INFO] - Training Epoch: 1/10, step 382/574 completed (loss: 2.6942031383514404, acc: 0.3963963985443115)
[2024-11-29 02:56:47,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:48,023][root][INFO] - Training Epoch: 1/10, step 383/574 completed (loss: 3.319636106491089, acc: 0.2857142984867096)
[2024-11-29 02:56:48,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:48,249][root][INFO] - Training Epoch: 1/10, step 384/574 completed (loss: 2.563323736190796, acc: 0.2857142984867096)
[2024-11-29 02:56:48,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:48,521][root][INFO] - Training Epoch: 1/10, step 385/574 completed (loss: 3.347306489944458, acc: 0.375)
[2024-11-29 02:56:48,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:48,779][root][INFO] - Training Epoch: 1/10, step 386/574 completed (loss: 3.080197334289551, acc: 0.3333333432674408)
[2024-11-29 02:56:48,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:49,062][root][INFO] - Training Epoch: 1/10, step 387/574 completed (loss: 3.036769151687622, acc: 0.34210526943206787)
[2024-11-29 02:56:49,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:49,366][root][INFO] - Training Epoch: 1/10, step 388/574 completed (loss: 3.0670928955078125, acc: 0.3636363744735718)
[2024-11-29 02:56:49,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:49,662][root][INFO] - Training Epoch: 1/10, step 389/574 completed (loss: 2.5654802322387695, acc: 0.4000000059604645)
[2024-11-29 02:56:49,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:49,949][root][INFO] - Training Epoch: 1/10, step 390/574 completed (loss: 2.607490301132202, acc: 0.4285714328289032)
[2024-11-29 02:56:50,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:50,219][root][INFO] - Training Epoch: 1/10, step 391/574 completed (loss: 3.058880567550659, acc: 0.3333333432674408)
[2024-11-29 02:56:50,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:50,498][root][INFO] - Training Epoch: 1/10, step 392/574 completed (loss: 3.3842391967773438, acc: 0.26213592290878296)
[2024-11-29 02:56:50,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:50,967][root][INFO] - Training Epoch: 1/10, step 393/574 completed (loss: 3.1698663234710693, acc: 0.3382352888584137)
[2024-11-29 02:56:51,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:51,283][root][INFO] - Training Epoch: 1/10, step 394/574 completed (loss: 3.2732768058776855, acc: 0.2933333218097687)
[2024-11-29 02:56:51,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:51,621][root][INFO] - Training Epoch: 1/10, step 395/574 completed (loss: 3.105318069458008, acc: 0.2847222089767456)
[2024-11-29 02:56:51,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:51,886][root][INFO] - Training Epoch: 1/10, step 396/574 completed (loss: 3.4837143421173096, acc: 0.27906978130340576)
[2024-11-29 02:56:52,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:52,177][root][INFO] - Training Epoch: 1/10, step 397/574 completed (loss: 3.0534675121307373, acc: 0.4166666567325592)
[2024-11-29 02:56:52,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:52,490][root][INFO] - Training Epoch: 1/10, step 398/574 completed (loss: 2.9017419815063477, acc: 0.25581395626068115)
[2024-11-29 02:56:52,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:52,807][root][INFO] - Training Epoch: 1/10, step 399/574 completed (loss: 3.0139923095703125, acc: 0.4000000059604645)
[2024-11-29 02:56:53,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:53,311][root][INFO] - Training Epoch: 1/10, step 400/574 completed (loss: 3.056269884109497, acc: 0.3529411852359772)
[2024-11-29 02:56:53,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:53,524][root][INFO] - Training Epoch: 1/10, step 401/574 completed (loss: 2.892364263534546, acc: 0.4000000059604645)
[2024-11-29 02:56:53,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:53,739][root][INFO] - Training Epoch: 1/10, step 402/574 completed (loss: 3.2092583179473877, acc: 0.3030303120613098)
[2024-11-29 02:56:53,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:54,006][root][INFO] - Training Epoch: 1/10, step 403/574 completed (loss: 2.6860220432281494, acc: 0.3333333432674408)
[2024-11-29 02:56:54,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:54,321][root][INFO] - Training Epoch: 1/10, step 404/574 completed (loss: 3.054943561553955, acc: 0.29032257199287415)
[2024-11-29 02:56:54,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:54,614][root][INFO] - Training Epoch: 1/10, step 405/574 completed (loss: 2.433138847351074, acc: 0.48148149251937866)
[2024-11-29 02:56:54,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:54,860][root][INFO] - Training Epoch: 1/10, step 406/574 completed (loss: 2.234327554702759, acc: 0.47999998927116394)
[2024-11-29 02:56:55,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:55,140][root][INFO] - Training Epoch: 1/10, step 407/574 completed (loss: 2.6700632572174072, acc: 0.4444444477558136)
[2024-11-29 02:56:55,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:55,427][root][INFO] - Training Epoch: 1/10, step 408/574 completed (loss: 2.471789836883545, acc: 0.4444444477558136)
[2024-11-29 02:56:55,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:55,654][root][INFO] - Training Epoch: 1/10, step 409/574 completed (loss: 1.995617151260376, acc: 0.5)
[2024-11-29 02:56:55,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:55,916][root][INFO] - Training Epoch: 1/10, step 410/574 completed (loss: 3.008434772491455, acc: 0.48275861144065857)
[2024-11-29 02:56:56,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:56,148][root][INFO] - Training Epoch: 1/10, step 411/574 completed (loss: 3.189540147781372, acc: 0.2857142984867096)
[2024-11-29 02:56:56,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:56,398][root][INFO] - Training Epoch: 1/10, step 412/574 completed (loss: 2.6032965183258057, acc: 0.36666667461395264)
[2024-11-29 02:56:56,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:56,632][root][INFO] - Training Epoch: 1/10, step 413/574 completed (loss: 2.9037656784057617, acc: 0.27272728085517883)
[2024-11-29 02:56:56,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:56,836][root][INFO] - Training Epoch: 1/10, step 414/574 completed (loss: 2.8404531478881836, acc: 0.40909090638160706)
[2024-11-29 02:56:56,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:57,113][root][INFO] - Training Epoch: 1/10, step 415/574 completed (loss: 2.892758846282959, acc: 0.3137255012989044)
[2024-11-29 02:56:57,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:57,339][root][INFO] - Training Epoch: 1/10, step 416/574 completed (loss: 3.0404253005981445, acc: 0.38461539149284363)
[2024-11-29 02:56:57,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:57,555][root][INFO] - Training Epoch: 1/10, step 417/574 completed (loss: 3.033442497253418, acc: 0.3888888955116272)
[2024-11-29 02:56:57,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:57,831][root][INFO] - Training Epoch: 1/10, step 418/574 completed (loss: 3.43402361869812, acc: 0.32499998807907104)
[2024-11-29 02:56:57,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:58,073][root][INFO] - Training Epoch: 1/10, step 419/574 completed (loss: 2.786670446395874, acc: 0.30000001192092896)
[2024-11-29 02:56:58,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:58,307][root][INFO] - Training Epoch: 1/10, step 420/574 completed (loss: 2.5650219917297363, acc: 0.380952388048172)
[2024-11-29 02:56:58,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:58,536][root][INFO] - Training Epoch: 1/10, step 421/574 completed (loss: 2.613473653793335, acc: 0.4333333373069763)
[2024-11-29 02:56:58,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:58,755][root][INFO] - Training Epoch: 1/10, step 422/574 completed (loss: 2.8486368656158447, acc: 0.28125)
[2024-11-29 02:56:58,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:58,999][root][INFO] - Training Epoch: 1/10, step 423/574 completed (loss: 3.557857036590576, acc: 0.3055555522441864)
[2024-11-29 02:56:59,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:59,221][root][INFO] - Training Epoch: 1/10, step 424/574 completed (loss: 3.007128953933716, acc: 0.29629629850387573)
[2024-11-29 02:56:59,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:59,442][root][INFO] - Training Epoch: 1/10, step 425/574 completed (loss: 2.832853078842163, acc: 0.39393940567970276)
[2024-11-29 02:56:59,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:59,685][root][INFO] - Training Epoch: 1/10, step 426/574 completed (loss: 1.9224514961242676, acc: 0.5652173757553101)
[2024-11-29 02:56:59,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:59,909][root][INFO] - Training Epoch: 1/10, step 427/574 completed (loss: 2.414208173751831, acc: 0.4324324429035187)
[2024-11-29 02:57:00,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:00,121][root][INFO] - Training Epoch: 1/10, step 428/574 completed (loss: 2.314112424850464, acc: 0.5185185074806213)
[2024-11-29 02:57:00,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:01,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:01,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:01,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:01,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:02,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:02,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:02,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:03,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:03,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:03,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:04,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:04,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:04,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:04,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:05,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:05,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:05,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:06,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:06,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:06,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:06,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:07,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:07,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:07,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:07,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:08,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:08,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:08,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:08,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:09,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:09,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:09,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:09,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:10,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:10,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:10,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:10,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:11,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:11,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:11,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:12,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:12,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:12,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:12,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:13,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:13,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:13,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:13,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:14,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:14,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:14,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:15,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:15,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:15,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:15,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:16,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:16,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:16,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:16,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:17,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:17,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:17,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:18,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:18,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:18,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:19,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:19,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:19,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:20,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:20,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:20,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:21,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:21,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:21,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:22,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:22,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:22,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:22,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:22,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:23,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:23,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:23,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:24,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:24,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:24,984][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(20.2020, device='cuda:0') eval_epoch_loss=tensor(3.0058, device='cuda:0') eval_epoch_acc=tensor(0.3147, device='cuda:0')
[2024-11-29 02:57:24,986][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 02:57:24,986][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 02:57:25,301][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_1_step_429_loss_3.005781888961792/model.pt
[2024-11-29 02:57:25,305][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 3.005781888961792
[2024-11-29 02:57:25,306][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.31467700004577637
[2024-11-29 02:57:25,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:25,545][root][INFO] - Training Epoch: 1/10, step 429/574 completed (loss: 2.406045436859131, acc: 0.43478259444236755)
[2024-11-29 02:57:25,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:25,820][root][INFO] - Training Epoch: 1/10, step 430/574 completed (loss: 2.4882924556732178, acc: 0.40740740299224854)
[2024-11-29 02:57:25,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:26,060][root][INFO] - Training Epoch: 1/10, step 431/574 completed (loss: 2.2592709064483643, acc: 0.40740740299224854)
[2024-11-29 02:57:26,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:26,275][root][INFO] - Training Epoch: 1/10, step 432/574 completed (loss: 2.853691816329956, acc: 0.43478259444236755)
[2024-11-29 02:57:26,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:26,542][root][INFO] - Training Epoch: 1/10, step 433/574 completed (loss: 2.709561347961426, acc: 0.3888888955116272)
[2024-11-29 02:57:26,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:26,764][root][INFO] - Training Epoch: 1/10, step 434/574 completed (loss: 1.9523799419403076, acc: 0.5199999809265137)
[2024-11-29 02:57:26,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:27,033][root][INFO] - Training Epoch: 1/10, step 435/574 completed (loss: 2.0350897312164307, acc: 0.5151515007019043)
[2024-11-29 02:57:27,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:27,298][root][INFO] - Training Epoch: 1/10, step 436/574 completed (loss: 2.565760850906372, acc: 0.4166666567325592)
[2024-11-29 02:57:27,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:27,549][root][INFO] - Training Epoch: 1/10, step 437/574 completed (loss: 2.2528505325317383, acc: 0.5909090638160706)
[2024-11-29 02:57:27,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:27,748][root][INFO] - Training Epoch: 1/10, step 438/574 completed (loss: 1.7613705396652222, acc: 0.6666666865348816)
[2024-11-29 02:57:27,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:27,983][root][INFO] - Training Epoch: 1/10, step 439/574 completed (loss: 2.874650716781616, acc: 0.3076923191547394)
[2024-11-29 02:57:28,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:28,413][root][INFO] - Training Epoch: 1/10, step 440/574 completed (loss: 2.855587959289551, acc: 0.3181818127632141)
[2024-11-29 02:57:28,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:29,079][root][INFO] - Training Epoch: 1/10, step 441/574 completed (loss: 3.5852081775665283, acc: 0.2879999876022339)
[2024-11-29 02:57:29,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:29,437][root][INFO] - Training Epoch: 1/10, step 442/574 completed (loss: 3.1651413440704346, acc: 0.30645161867141724)
[2024-11-29 02:57:29,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:30,001][root][INFO] - Training Epoch: 1/10, step 443/574 completed (loss: 3.3715131282806396, acc: 0.28358209133148193)
[2024-11-29 02:57:30,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:30,220][root][INFO] - Training Epoch: 1/10, step 444/574 completed (loss: 3.138145923614502, acc: 0.3396226465702057)
[2024-11-29 02:57:30,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:30,563][root][INFO] - Training Epoch: 1/10, step 445/574 completed (loss: 3.2513837814331055, acc: 0.3636363744735718)
[2024-11-29 02:57:30,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:30,777][root][INFO] - Training Epoch: 1/10, step 446/574 completed (loss: 2.5534331798553467, acc: 0.30434781312942505)
[2024-11-29 02:57:30,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:30,997][root][INFO] - Training Epoch: 1/10, step 447/574 completed (loss: 2.6634347438812256, acc: 0.42307692766189575)
[2024-11-29 02:57:31,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:31,219][root][INFO] - Training Epoch: 1/10, step 448/574 completed (loss: 2.76839017868042, acc: 0.3214285671710968)
[2024-11-29 02:57:31,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:31,455][root][INFO] - Training Epoch: 1/10, step 449/574 completed (loss: 3.7551109790802, acc: 0.2238806039094925)
[2024-11-29 02:57:31,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:31,695][root][INFO] - Training Epoch: 1/10, step 450/574 completed (loss: 2.9840054512023926, acc: 0.3333333432674408)
[2024-11-29 02:57:31,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:31,917][root][INFO] - Training Epoch: 1/10, step 451/574 completed (loss: 3.303377866744995, acc: 0.28260868787765503)
[2024-11-29 02:57:32,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:32,169][root][INFO] - Training Epoch: 1/10, step 452/574 completed (loss: 3.3662543296813965, acc: 0.23076923191547394)
[2024-11-29 02:57:32,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:32,406][root][INFO] - Training Epoch: 1/10, step 453/574 completed (loss: 3.299696207046509, acc: 0.2763157784938812)
[2024-11-29 02:57:32,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:32,653][root][INFO] - Training Epoch: 1/10, step 454/574 completed (loss: 2.742074489593506, acc: 0.40816327929496765)
[2024-11-29 02:57:32,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:32,866][root][INFO] - Training Epoch: 1/10, step 455/574 completed (loss: 3.1106154918670654, acc: 0.24242424964904785)
[2024-11-29 02:57:32,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:33,094][root][INFO] - Training Epoch: 1/10, step 456/574 completed (loss: 2.880317211151123, acc: 0.30927833914756775)
[2024-11-29 02:57:33,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:33,330][root][INFO] - Training Epoch: 1/10, step 457/574 completed (loss: 2.864523410797119, acc: 0.2857142984867096)
[2024-11-29 02:57:33,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:33,643][root][INFO] - Training Epoch: 1/10, step 458/574 completed (loss: 2.9917988777160645, acc: 0.33139535784721375)
[2024-11-29 02:57:33,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:33,883][root][INFO] - Training Epoch: 1/10, step 459/574 completed (loss: 3.0029408931732178, acc: 0.3035714328289032)
[2024-11-29 02:57:34,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:34,145][root][INFO] - Training Epoch: 1/10, step 460/574 completed (loss: 3.0243940353393555, acc: 0.2839506268501282)
[2024-11-29 02:57:34,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:34,336][root][INFO] - Training Epoch: 1/10, step 461/574 completed (loss: 2.0118250846862793, acc: 0.5277777910232544)
[2024-11-29 02:57:34,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:34,540][root][INFO] - Training Epoch: 1/10, step 462/574 completed (loss: 2.7637553215026855, acc: 0.28125)
[2024-11-29 02:57:34,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:34,773][root][INFO] - Training Epoch: 1/10, step 463/574 completed (loss: 2.3692526817321777, acc: 0.3461538553237915)
[2024-11-29 02:57:34,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:34,993][root][INFO] - Training Epoch: 1/10, step 464/574 completed (loss: 2.7670514583587646, acc: 0.32608696818351746)
[2024-11-29 02:57:35,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:35,246][root][INFO] - Training Epoch: 1/10, step 465/574 completed (loss: 3.2741851806640625, acc: 0.3095238208770752)
[2024-11-29 02:57:35,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:35,481][root][INFO] - Training Epoch: 1/10, step 466/574 completed (loss: 3.1693618297576904, acc: 0.21686747670173645)
[2024-11-29 02:57:35,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:35,762][root][INFO] - Training Epoch: 1/10, step 467/574 completed (loss: 2.8088197708129883, acc: 0.38738739490509033)
[2024-11-29 02:57:35,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:35,996][root][INFO] - Training Epoch: 1/10, step 468/574 completed (loss: 3.085340738296509, acc: 0.33980581164360046)
[2024-11-29 02:57:36,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:36,238][root][INFO] - Training Epoch: 1/10, step 469/574 completed (loss: 2.964855670928955, acc: 0.3414634168148041)
[2024-11-29 02:57:36,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:36,458][root][INFO] - Training Epoch: 1/10, step 470/574 completed (loss: 1.8225822448730469, acc: 0.5833333134651184)
[2024-11-29 02:57:36,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:36,691][root][INFO] - Training Epoch: 1/10, step 471/574 completed (loss: 2.8267579078674316, acc: 0.25)
[2024-11-29 02:57:36,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:37,053][root][INFO] - Training Epoch: 1/10, step 472/574 completed (loss: 2.6544599533081055, acc: 0.37254902720451355)
[2024-11-29 02:57:37,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:37,313][root][INFO] - Training Epoch: 1/10, step 473/574 completed (loss: 3.030183792114258, acc: 0.28820961713790894)
[2024-11-29 02:57:37,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:37,531][root][INFO] - Training Epoch: 1/10, step 474/574 completed (loss: 3.151792526245117, acc: 0.2395833283662796)
[2024-11-29 02:57:37,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:37,774][root][INFO] - Training Epoch: 1/10, step 475/574 completed (loss: 2.891040563583374, acc: 0.30674847960472107)
[2024-11-29 02:57:37,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:38,052][root][INFO] - Training Epoch: 1/10, step 476/574 completed (loss: 3.165339469909668, acc: 0.28057554364204407)
[2024-11-29 02:57:38,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:38,327][root][INFO] - Training Epoch: 1/10, step 477/574 completed (loss: 3.0348260402679443, acc: 0.3668341636657715)
[2024-11-29 02:57:38,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:38,547][root][INFO] - Training Epoch: 1/10, step 478/574 completed (loss: 2.704508066177368, acc: 0.4166666567325592)
[2024-11-29 02:57:38,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:38,824][root][INFO] - Training Epoch: 1/10, step 479/574 completed (loss: 2.5254979133605957, acc: 0.4545454680919647)
[2024-11-29 02:57:38,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:39,106][root][INFO] - Training Epoch: 1/10, step 480/574 completed (loss: 2.409151315689087, acc: 0.37037035822868347)
[2024-11-29 02:57:39,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:39,356][root][INFO] - Training Epoch: 1/10, step 481/574 completed (loss: 2.5720608234405518, acc: 0.4000000059604645)
[2024-11-29 02:57:39,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:39,643][root][INFO] - Training Epoch: 1/10, step 482/574 completed (loss: 2.6062874794006348, acc: 0.3499999940395355)
[2024-11-29 02:57:39,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:40,016][root][INFO] - Training Epoch: 1/10, step 483/574 completed (loss: 2.7366204261779785, acc: 0.3965517282485962)
[2024-11-29 02:57:40,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:40,299][root][INFO] - Training Epoch: 1/10, step 484/574 completed (loss: 2.5144028663635254, acc: 0.4838709533214569)
[2024-11-29 02:57:40,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:40,532][root][INFO] - Training Epoch: 1/10, step 485/574 completed (loss: 1.7520545721054077, acc: 0.5789473652839661)
[2024-11-29 02:57:40,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:40,735][root][INFO] - Training Epoch: 1/10, step 486/574 completed (loss: 2.830174207687378, acc: 0.3333333432674408)
[2024-11-29 02:57:40,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:40,935][root][INFO] - Training Epoch: 1/10, step 487/574 completed (loss: 2.4596614837646484, acc: 0.3333333432674408)
[2024-11-29 02:57:41,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:41,148][root][INFO] - Training Epoch: 1/10, step 488/574 completed (loss: 2.3823375701904297, acc: 0.5454545617103577)
[2024-11-29 02:57:41,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:41,445][root][INFO] - Training Epoch: 1/10, step 489/574 completed (loss: 2.572324514389038, acc: 0.3076923191547394)
[2024-11-29 02:57:41,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:41,735][root][INFO] - Training Epoch: 1/10, step 490/574 completed (loss: 2.075330972671509, acc: 0.5)
[2024-11-29 02:57:41,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:41,993][root][INFO] - Training Epoch: 1/10, step 491/574 completed (loss: 2.037972927093506, acc: 0.6896551847457886)
[2024-11-29 02:57:42,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:42,208][root][INFO] - Training Epoch: 1/10, step 492/574 completed (loss: 2.895582675933838, acc: 0.3333333432674408)
[2024-11-29 02:57:42,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:42,378][root][INFO] - Training Epoch: 1/10, step 493/574 completed (loss: 1.8294321298599243, acc: 0.6206896305084229)
[2024-11-29 02:57:42,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:42,598][root][INFO] - Training Epoch: 1/10, step 494/574 completed (loss: 1.9714384078979492, acc: 0.4736842215061188)
[2024-11-29 02:57:42,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:42,833][root][INFO] - Training Epoch: 1/10, step 495/574 completed (loss: 3.1337990760803223, acc: 0.2631579041481018)
[2024-11-29 02:57:43,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:43,161][root][INFO] - Training Epoch: 1/10, step 496/574 completed (loss: 2.706728219985962, acc: 0.3482142984867096)
[2024-11-29 02:57:43,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:43,465][root][INFO] - Training Epoch: 1/10, step 497/574 completed (loss: 2.4750514030456543, acc: 0.3820224702358246)
[2024-11-29 02:57:43,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:43,709][root][INFO] - Training Epoch: 1/10, step 498/574 completed (loss: 2.706679344177246, acc: 0.3932584226131439)
[2024-11-29 02:57:43,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:43,995][root][INFO] - Training Epoch: 1/10, step 499/574 completed (loss: 2.9802489280700684, acc: 0.326241135597229)
[2024-11-29 02:57:44,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:44,280][root][INFO] - Training Epoch: 1/10, step 500/574 completed (loss: 2.9794583320617676, acc: 0.32608696818351746)
[2024-11-29 02:57:44,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:44,543][root][INFO] - Training Epoch: 1/10, step 501/574 completed (loss: 1.9098963737487793, acc: 0.5199999809265137)
[2024-11-29 02:57:44,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:44,803][root][INFO] - Training Epoch: 1/10, step 502/574 completed (loss: 2.077040910720825, acc: 0.5)
[2024-11-29 02:57:44,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:45,068][root][INFO] - Training Epoch: 1/10, step 503/574 completed (loss: 2.475606679916382, acc: 0.4444444477558136)
[2024-11-29 02:57:45,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:45,346][root][INFO] - Training Epoch: 1/10, step 504/574 completed (loss: 2.1857688426971436, acc: 0.48148149251937866)
[2024-11-29 02:57:45,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:45,602][root][INFO] - Training Epoch: 1/10, step 505/574 completed (loss: 2.414654493331909, acc: 0.49056604504585266)
[2024-11-29 02:57:45,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:45,812][root][INFO] - Training Epoch: 1/10, step 506/574 completed (loss: 3.005725145339966, acc: 0.24137930572032928)
[2024-11-29 02:57:46,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:46,360][root][INFO] - Training Epoch: 1/10, step 507/574 completed (loss: 2.8900933265686035, acc: 0.3963963985443115)
[2024-11-29 02:57:46,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:46,728][root][INFO] - Training Epoch: 1/10, step 508/574 completed (loss: 3.151796340942383, acc: 0.3661971688270569)
[2024-11-29 02:57:46,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:46,971][root][INFO] - Training Epoch: 1/10, step 509/574 completed (loss: 1.1032377481460571, acc: 0.550000011920929)
[2024-11-29 02:57:47,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:47,196][root][INFO] - Training Epoch: 1/10, step 510/574 completed (loss: 2.16802716255188, acc: 0.4333333373069763)
[2024-11-29 02:57:47,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:47,482][root][INFO] - Training Epoch: 1/10, step 511/574 completed (loss: 2.067666530609131, acc: 0.5384615659713745)
[2024-11-29 02:57:48,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:50,116][root][INFO] - Training Epoch: 1/10, step 512/574 completed (loss: 3.1486310958862305, acc: 0.3142857253551483)
[2024-11-29 02:57:50,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:50,803][root][INFO] - Training Epoch: 1/10, step 513/574 completed (loss: 3.0320188999176025, acc: 0.3888888955116272)
[2024-11-29 02:57:50,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:50,999][root][INFO] - Training Epoch: 1/10, step 514/574 completed (loss: 2.1182377338409424, acc: 0.4642857015132904)
[2024-11-29 02:57:51,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:51,264][root][INFO] - Training Epoch: 1/10, step 515/574 completed (loss: 2.5602846145629883, acc: 0.38333332538604736)
[2024-11-29 02:57:51,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:51,944][root][INFO] - Training Epoch: 1/10, step 516/574 completed (loss: 2.8215184211730957, acc: 0.4722222089767456)
[2024-11-29 02:57:52,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:52,229][root][INFO] - Training Epoch: 1/10, step 517/574 completed (loss: 1.9366443157196045, acc: 0.692307710647583)
[2024-11-29 02:57:52,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:52,532][root][INFO] - Training Epoch: 1/10, step 518/574 completed (loss: 3.090940475463867, acc: 0.29032257199287415)
[2024-11-29 02:57:52,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:52,756][root][INFO] - Training Epoch: 1/10, step 519/574 completed (loss: 1.8117320537567139, acc: 0.5)
[2024-11-29 02:57:52,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:53,018][root][INFO] - Training Epoch: 1/10, step 520/574 completed (loss: 2.3858485221862793, acc: 0.29629629850387573)
[2024-11-29 02:57:53,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:53,960][root][INFO] - Training Epoch: 1/10, step 521/574 completed (loss: 2.7120227813720703, acc: 0.4067796468734741)
[2024-11-29 02:57:54,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:54,216][root][INFO] - Training Epoch: 1/10, step 522/574 completed (loss: 2.4556944370269775, acc: 0.4552238881587982)
[2024-11-29 02:57:54,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:54,499][root][INFO] - Training Epoch: 1/10, step 523/574 completed (loss: 2.642796754837036, acc: 0.37956205010414124)
[2024-11-29 02:57:54,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:55,028][root][INFO] - Training Epoch: 1/10, step 524/574 completed (loss: 2.560812473297119, acc: 0.4399999976158142)
[2024-11-29 02:57:55,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:55,231][root][INFO] - Training Epoch: 1/10, step 525/574 completed (loss: 2.7698113918304443, acc: 0.2777777910232544)
[2024-11-29 02:57:55,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:55,470][root][INFO] - Training Epoch: 1/10, step 526/574 completed (loss: 2.2617766857147217, acc: 0.4615384638309479)
[2024-11-29 02:57:55,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:55,678][root][INFO] - Training Epoch: 1/10, step 527/574 completed (loss: 2.65539813041687, acc: 0.380952388048172)
[2024-11-29 02:57:55,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:55,905][root][INFO] - Training Epoch: 1/10, step 528/574 completed (loss: 3.4039576053619385, acc: 0.21311475336551666)
[2024-11-29 02:57:56,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:56,096][root][INFO] - Training Epoch: 1/10, step 529/574 completed (loss: 2.5018978118896484, acc: 0.4067796468734741)
[2024-11-29 02:57:56,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:56,320][root][INFO] - Training Epoch: 1/10, step 530/574 completed (loss: 3.5387022495269775, acc: 0.25581395626068115)
[2024-11-29 02:57:56,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:56,595][root][INFO] - Training Epoch: 1/10, step 531/574 completed (loss: 2.7660892009735107, acc: 0.2954545319080353)
[2024-11-29 02:57:56,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:56,885][root][INFO] - Training Epoch: 1/10, step 532/574 completed (loss: 3.178316831588745, acc: 0.24528302252292633)
[2024-11-29 02:57:57,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:57,195][root][INFO] - Training Epoch: 1/10, step 533/574 completed (loss: 2.8635175228118896, acc: 0.3636363744735718)
[2024-11-29 02:57:57,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:57,440][root][INFO] - Training Epoch: 1/10, step 534/574 completed (loss: 2.0437800884246826, acc: 0.47999998927116394)
[2024-11-29 02:57:57,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:57,650][root][INFO] - Training Epoch: 1/10, step 535/574 completed (loss: 2.1936960220336914, acc: 0.4000000059604645)
[2024-11-29 02:57:57,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:57,855][root][INFO] - Training Epoch: 1/10, step 536/574 completed (loss: 1.435896635055542, acc: 0.6363636255264282)
[2024-11-29 02:57:58,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:58,185][root][INFO] - Training Epoch: 1/10, step 537/574 completed (loss: 2.4198904037475586, acc: 0.4000000059604645)
[2024-11-29 02:57:58,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:58,436][root][INFO] - Training Epoch: 1/10, step 538/574 completed (loss: 2.4611775875091553, acc: 0.40625)
[2024-11-29 02:57:58,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:58,743][root][INFO] - Training Epoch: 1/10, step 539/574 completed (loss: 2.1380937099456787, acc: 0.5)
[2024-11-29 02:57:58,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:58,967][root][INFO] - Training Epoch: 1/10, step 540/574 completed (loss: 2.5106277465820312, acc: 0.4545454680919647)
[2024-11-29 02:57:59,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:59,246][root][INFO] - Training Epoch: 1/10, step 541/574 completed (loss: 1.4842298030853271, acc: 0.5625)
[2024-11-29 02:57:59,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:59,487][root][INFO] - Training Epoch: 1/10, step 542/574 completed (loss: 1.8849530220031738, acc: 0.5161290168762207)
[2024-11-29 02:57:59,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:59,749][root][INFO] - Training Epoch: 1/10, step 543/574 completed (loss: 0.7290449738502502, acc: 0.8695651888847351)
[2024-11-29 02:57:59,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:59,963][root][INFO] - Training Epoch: 1/10, step 544/574 completed (loss: 1.9499588012695312, acc: 0.4000000059604645)
[2024-11-29 02:58:00,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:00,193][root][INFO] - Training Epoch: 1/10, step 545/574 completed (loss: 2.249009847640991, acc: 0.5609756112098694)
[2024-11-29 02:58:00,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:00,464][root][INFO] - Training Epoch: 1/10, step 546/574 completed (loss: 1.254163384437561, acc: 0.6571428775787354)
[2024-11-29 02:58:00,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:00,751][root][INFO] - Training Epoch: 1/10, step 547/574 completed (loss: 2.274034023284912, acc: 0.5789473652839661)
[2024-11-29 02:58:00,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:01,045][root][INFO] - Training Epoch: 1/10, step 548/574 completed (loss: 2.193490982055664, acc: 0.5806451439857483)
[2024-11-29 02:58:01,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:01,299][root][INFO] - Training Epoch: 1/10, step 549/574 completed (loss: 1.3480035066604614, acc: 0.6399999856948853)
[2024-11-29 02:58:01,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:01,561][root][INFO] - Training Epoch: 1/10, step 550/574 completed (loss: 1.9655250310897827, acc: 0.5151515007019043)
[2024-11-29 02:58:01,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:01,840][root][INFO] - Training Epoch: 1/10, step 551/574 completed (loss: 2.121208667755127, acc: 0.4749999940395355)
[2024-11-29 02:58:01,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:02,080][root][INFO] - Training Epoch: 1/10, step 552/574 completed (loss: 2.327244281768799, acc: 0.4571428596973419)
[2024-11-29 02:58:02,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:02,329][root][INFO] - Training Epoch: 1/10, step 553/574 completed (loss: 3.2473583221435547, acc: 0.24817518889904022)
[2024-11-29 02:58:02,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:02,648][root][INFO] - Training Epoch: 1/10, step 554/574 completed (loss: 2.6799488067626953, acc: 0.38620689511299133)
[2024-11-29 02:58:02,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:02,953][root][INFO] - Training Epoch: 1/10, step 555/574 completed (loss: 3.1932098865509033, acc: 0.2142857164144516)
[2024-11-29 02:58:03,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:03,266][root][INFO] - Training Epoch: 1/10, step 556/574 completed (loss: 3.3755340576171875, acc: 0.18543046712875366)
[2024-11-29 02:58:03,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:03,524][root][INFO] - Training Epoch: 1/10, step 557/574 completed (loss: 3.0594840049743652, acc: 0.3076923191547394)
[2024-11-29 02:58:03,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:03,752][root][INFO] - Training Epoch: 1/10, step 558/574 completed (loss: 1.8058576583862305, acc: 0.5600000023841858)
[2024-11-29 02:58:03,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:04,022][root][INFO] - Training Epoch: 1/10, step 559/574 completed (loss: 1.9811066389083862, acc: 0.42307692766189575)
[2024-11-29 02:58:04,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:04,229][root][INFO] - Training Epoch: 1/10, step 560/574 completed (loss: 1.4321104288101196, acc: 0.692307710647583)
[2024-11-29 02:58:04,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:04,434][root][INFO] - Training Epoch: 1/10, step 561/574 completed (loss: 2.658104419708252, acc: 0.43589743971824646)
[2024-11-29 02:58:04,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:04,698][root][INFO] - Training Epoch: 1/10, step 562/574 completed (loss: 2.231610059738159, acc: 0.46666666865348816)
[2024-11-29 02:58:04,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:05,000][root][INFO] - Training Epoch: 1/10, step 563/574 completed (loss: 2.9989230632781982, acc: 0.3636363744735718)
[2024-11-29 02:58:05,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:05,240][root][INFO] - Training Epoch: 1/10, step 564/574 completed (loss: 2.1298716068267822, acc: 0.4583333432674408)
[2024-11-29 02:58:05,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:05,496][root][INFO] - Training Epoch: 1/10, step 565/574 completed (loss: 2.685408592224121, acc: 0.3965517282485962)
[2024-11-29 02:58:05,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:05,732][root][INFO] - Training Epoch: 1/10, step 566/574 completed (loss: 2.62862229347229, acc: 0.3333333432674408)
[2024-11-29 02:58:05,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:05,940][root][INFO] - Training Epoch: 1/10, step 567/574 completed (loss: 1.730043888092041, acc: 0.5526315569877625)
[2024-11-29 02:58:06,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:06,151][root][INFO] - Training Epoch: 1/10, step 568/574 completed (loss: 1.611171007156372, acc: 0.4444444477558136)
[2024-11-29 02:58:06,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:06,452][root][INFO] - Training Epoch: 1/10, step 569/574 completed (loss: 2.8832664489746094, acc: 0.33155080676078796)
[2024-11-29 02:58:06,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:06,636][root][INFO] - Training Epoch: 1/10, step 570/574 completed (loss: 1.9120861291885376, acc: 0.5806451439857483)
[2024-11-29 02:58:06,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:06,916][root][INFO] - Training Epoch: 1/10, step 571/574 completed (loss: 3.001146078109741, acc: 0.34188035130500793)
[2024-11-29 02:58:07,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:07,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:08,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:08,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:08,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:09,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:09,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:09,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:09,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:10,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:10,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:10,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:11,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:11,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:11,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:11,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:12,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:12,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:12,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:12,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:13,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:13,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:13,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:13,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:14,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:14,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:14,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:14,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:15,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:15,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:15,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:15,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:16,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:16,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:16,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:16,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:17,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:17,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:17,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:17,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:18,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:18,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:18,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:18,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:19,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:19,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:19,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:20,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:20,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:20,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:21,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:21,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:21,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:21,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:22,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:22,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:22,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:23,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:23,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:23,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:23,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:24,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:24,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:24,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:25,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:25,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:25,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:26,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:26,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:26,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:27,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:27,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:27,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:27,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:27,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:28,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:28,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:28,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:29,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:29,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:29,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:29,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:30,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:30,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:30,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:31,242][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(10.0367, device='cuda:0') eval_epoch_loss=tensor(2.3062, device='cuda:0') eval_epoch_acc=tensor(0.4391, device='cuda:0')
[2024-11-29 02:58:31,243][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 02:58:31,243][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 02:58:31,463][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_1_step_572_loss_2.3062450885772705/model.pt
[2024-11-29 02:58:31,465][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 2.3062450885772705
[2024-11-29 02:58:31,466][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.4391210377216339
[2024-11-29 02:58:31,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:31,685][root][INFO] - Training Epoch: 1/10, step 572/574 completed (loss: 3.2589311599731445, acc: 0.23469388484954834)
[2024-11-29 02:58:31,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:31,934][root][INFO] - Training Epoch: 1/10, step 573/574 completed (loss: 3.082095146179199, acc: 0.2641509473323822)
[2024-11-29 02:58:32,448][slam_llm.utils.train_utils][INFO] - Epoch 1: train_perplexity=46.7409, train_epoch_loss=3.8446, epoch time 288.04743190295994s
[2024-11-29 02:58:32,448][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 11 GB
[2024-11-29 02:58:32,448][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 16 GB
[2024-11-29 02:58:32,449][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 11 GB
[2024-11-29 02:58:32,449][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 2
[2024-11-29 02:58:32,449][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 02:58:33,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:33,152][root][INFO] - Training Epoch: 2/10, step 0/574 completed (loss: 2.005455255508423, acc: 0.29629629850387573)
[2024-11-29 02:58:33,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:33,366][root][INFO] - Training Epoch: 2/10, step 1/574 completed (loss: 1.7641165256500244, acc: 0.5600000023841858)
[2024-11-29 02:58:33,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:33,591][root][INFO] - Training Epoch: 2/10, step 2/574 completed (loss: 2.151362419128418, acc: 0.4324324429035187)
[2024-11-29 02:58:33,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:33,840][root][INFO] - Training Epoch: 2/10, step 3/574 completed (loss: 2.4484915733337402, acc: 0.31578946113586426)
[2024-11-29 02:58:33,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:34,074][root][INFO] - Training Epoch: 2/10, step 4/574 completed (loss: 2.041308879852295, acc: 0.4864864945411682)
[2024-11-29 02:58:34,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:34,323][root][INFO] - Training Epoch: 2/10, step 5/574 completed (loss: 2.109149932861328, acc: 0.4285714328289032)
[2024-11-29 02:58:34,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:34,570][root][INFO] - Training Epoch: 2/10, step 6/574 completed (loss: 2.1952266693115234, acc: 0.3877550959587097)
[2024-11-29 02:58:34,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:34,805][root][INFO] - Training Epoch: 2/10, step 7/574 completed (loss: 1.3541899919509888, acc: 0.6666666865348816)
[2024-11-29 02:58:34,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:35,037][root][INFO] - Training Epoch: 2/10, step 8/574 completed (loss: 0.8909200429916382, acc: 0.7272727489471436)
[2024-11-29 02:58:35,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:35,267][root][INFO] - Training Epoch: 2/10, step 9/574 completed (loss: 0.6610001921653748, acc: 0.807692289352417)
[2024-11-29 02:58:35,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:35,500][root][INFO] - Training Epoch: 2/10, step 10/574 completed (loss: 1.0387483835220337, acc: 0.7407407164573669)
[2024-11-29 02:58:35,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:35,736][root][INFO] - Training Epoch: 2/10, step 11/574 completed (loss: 2.1955642700195312, acc: 0.5384615659713745)
[2024-11-29 02:58:35,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:35,977][root][INFO] - Training Epoch: 2/10, step 12/574 completed (loss: 1.8088507652282715, acc: 0.5454545617103577)
[2024-11-29 02:58:36,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:36,215][root][INFO] - Training Epoch: 2/10, step 13/574 completed (loss: 1.638365387916565, acc: 0.52173912525177)
[2024-11-29 02:58:36,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:36,453][root][INFO] - Training Epoch: 2/10, step 14/574 completed (loss: 2.24155330657959, acc: 0.47058823704719543)
[2024-11-29 02:58:36,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:36,694][root][INFO] - Training Epoch: 2/10, step 15/574 completed (loss: 1.698135256767273, acc: 0.6326530575752258)
[2024-11-29 02:58:36,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:36,933][root][INFO] - Training Epoch: 2/10, step 16/574 completed (loss: 1.2456655502319336, acc: 0.5789473652839661)
[2024-11-29 02:58:37,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:37,154][root][INFO] - Training Epoch: 2/10, step 17/574 completed (loss: 1.745358943939209, acc: 0.5833333134651184)
[2024-11-29 02:58:37,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:37,381][root][INFO] - Training Epoch: 2/10, step 18/574 completed (loss: 2.688518762588501, acc: 0.3611111044883728)
[2024-11-29 02:58:37,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:37,618][root][INFO] - Training Epoch: 2/10, step 19/574 completed (loss: 0.9528266787528992, acc: 0.7368420958518982)
[2024-11-29 02:58:37,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:37,851][root][INFO] - Training Epoch: 2/10, step 20/574 completed (loss: 1.9756783246994019, acc: 0.4615384638309479)
[2024-11-29 02:58:37,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:38,089][root][INFO] - Training Epoch: 2/10, step 21/574 completed (loss: 1.5649480819702148, acc: 0.6206896305084229)
[2024-11-29 02:58:38,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:38,318][root][INFO] - Training Epoch: 2/10, step 22/574 completed (loss: 2.1393396854400635, acc: 0.4000000059604645)
[2024-11-29 02:58:38,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:38,525][root][INFO] - Training Epoch: 2/10, step 23/574 completed (loss: 1.0781928300857544, acc: 0.8095238208770752)
[2024-11-29 02:58:38,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:38,742][root][INFO] - Training Epoch: 2/10, step 24/574 completed (loss: 1.606557011604309, acc: 0.75)
[2024-11-29 02:58:38,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:38,969][root][INFO] - Training Epoch: 2/10, step 25/574 completed (loss: 2.6287286281585693, acc: 0.37735849618911743)
[2024-11-29 02:58:39,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:39,198][root][INFO] - Training Epoch: 2/10, step 26/574 completed (loss: 2.5515708923339844, acc: 0.3835616409778595)
[2024-11-29 02:58:39,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:40,351][root][INFO] - Training Epoch: 2/10, step 27/574 completed (loss: 3.089470863342285, acc: 0.2964426875114441)
[2024-11-29 02:58:40,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:40,524][root][INFO] - Training Epoch: 2/10, step 28/574 completed (loss: 2.5422723293304443, acc: 0.39534884691238403)
[2024-11-29 02:58:40,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:40,769][root][INFO] - Training Epoch: 2/10, step 29/574 completed (loss: 2.30322003364563, acc: 0.4337349534034729)
[2024-11-29 02:58:40,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:41,000][root][INFO] - Training Epoch: 2/10, step 30/574 completed (loss: 2.834104061126709, acc: 0.3333333432674408)
[2024-11-29 02:58:41,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:41,239][root][INFO] - Training Epoch: 2/10, step 31/574 completed (loss: 2.212369441986084, acc: 0.5)
[2024-11-29 02:58:41,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:41,439][root][INFO] - Training Epoch: 2/10, step 32/574 completed (loss: 1.4937820434570312, acc: 0.5555555820465088)
[2024-11-29 02:58:41,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:41,668][root][INFO] - Training Epoch: 2/10, step 33/574 completed (loss: 1.7560535669326782, acc: 0.6086956262588501)
[2024-11-29 02:58:41,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:41,914][root][INFO] - Training Epoch: 2/10, step 34/574 completed (loss: 2.3417632579803467, acc: 0.5126050710678101)
[2024-11-29 02:58:42,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:42,142][root][INFO] - Training Epoch: 2/10, step 35/574 completed (loss: 2.0171070098876953, acc: 0.5573770403862)
[2024-11-29 02:58:42,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:42,382][root][INFO] - Training Epoch: 2/10, step 36/574 completed (loss: 1.9963574409484863, acc: 0.5079365372657776)
[2024-11-29 02:58:42,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:42,633][root][INFO] - Training Epoch: 2/10, step 37/574 completed (loss: 2.3876700401306152, acc: 0.4067796468734741)
[2024-11-29 02:58:42,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:42,917][root][INFO] - Training Epoch: 2/10, step 38/574 completed (loss: 2.156301975250244, acc: 0.517241358757019)
[2024-11-29 02:58:43,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:43,152][root][INFO] - Training Epoch: 2/10, step 39/574 completed (loss: 1.6714448928833008, acc: 0.6190476417541504)
[2024-11-29 02:58:43,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:43,384][root][INFO] - Training Epoch: 2/10, step 40/574 completed (loss: 1.7329496145248413, acc: 0.42307692766189575)
[2024-11-29 02:58:43,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:43,664][root][INFO] - Training Epoch: 2/10, step 41/574 completed (loss: 2.5050854682922363, acc: 0.5)
[2024-11-29 02:58:43,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:43,891][root][INFO] - Training Epoch: 2/10, step 42/574 completed (loss: 2.544281005859375, acc: 0.38461539149284363)
[2024-11-29 02:58:44,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:44,220][root][INFO] - Training Epoch: 2/10, step 43/574 completed (loss: 2.7979280948638916, acc: 0.4040403962135315)
[2024-11-29 02:58:44,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:44,532][root][INFO] - Training Epoch: 2/10, step 44/574 completed (loss: 2.2753043174743652, acc: 0.5154638886451721)
[2024-11-29 02:58:44,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:44,821][root][INFO] - Training Epoch: 2/10, step 45/574 completed (loss: 2.6327407360076904, acc: 0.3897058963775635)
[2024-11-29 02:58:44,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:45,002][root][INFO] - Training Epoch: 2/10, step 46/574 completed (loss: 1.5296311378479004, acc: 0.6538461446762085)
[2024-11-29 02:58:45,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:45,208][root][INFO] - Training Epoch: 2/10, step 47/574 completed (loss: 1.6589288711547852, acc: 0.5925925970077515)
[2024-11-29 02:58:45,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:45,435][root][INFO] - Training Epoch: 2/10, step 48/574 completed (loss: 1.2032277584075928, acc: 0.6428571343421936)
[2024-11-29 02:58:45,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:45,678][root][INFO] - Training Epoch: 2/10, step 49/574 completed (loss: 1.804039478302002, acc: 0.5555555820465088)
[2024-11-29 02:58:45,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:45,925][root][INFO] - Training Epoch: 2/10, step 50/574 completed (loss: 2.328742027282715, acc: 0.42105263471603394)
[2024-11-29 02:58:46,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:46,169][root][INFO] - Training Epoch: 2/10, step 51/574 completed (loss: 2.646195888519287, acc: 0.4126984179019928)
[2024-11-29 02:58:46,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:46,415][root][INFO] - Training Epoch: 2/10, step 52/574 completed (loss: 2.9019317626953125, acc: 0.3239436745643616)
[2024-11-29 02:58:46,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:46,815][root][INFO] - Training Epoch: 2/10, step 53/574 completed (loss: 3.0695383548736572, acc: 0.3266666531562805)
[2024-11-29 02:58:46,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:47,006][root][INFO] - Training Epoch: 2/10, step 54/574 completed (loss: 2.316105842590332, acc: 0.5135135054588318)
[2024-11-29 02:58:47,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:47,225][root][INFO] - Training Epoch: 2/10, step 55/574 completed (loss: 0.9771300554275513, acc: 0.7307692170143127)
[2024-11-29 02:58:48,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:49,765][root][INFO] - Training Epoch: 2/10, step 56/574 completed (loss: 2.4834983348846436, acc: 0.457337886095047)
[2024-11-29 02:58:50,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:50,906][root][INFO] - Training Epoch: 2/10, step 57/574 completed (loss: 2.997260093688965, acc: 0.363834410905838)
[2024-11-29 02:58:51,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:51,436][root][INFO] - Training Epoch: 2/10, step 58/574 completed (loss: 2.597783088684082, acc: 0.4375)
[2024-11-29 02:58:51,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:51,909][root][INFO] - Training Epoch: 2/10, step 59/574 completed (loss: 2.563734531402588, acc: 0.4485294222831726)
[2024-11-29 02:58:52,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:52,372][root][INFO] - Training Epoch: 2/10, step 60/574 completed (loss: 2.6517534255981445, acc: 0.3840579688549042)
[2024-11-29 02:58:52,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:52,687][root][INFO] - Training Epoch: 2/10, step 61/574 completed (loss: 2.32381010055542, acc: 0.48750001192092896)
[2024-11-29 02:58:52,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:52,925][root][INFO] - Training Epoch: 2/10, step 62/574 completed (loss: 1.1956923007965088, acc: 0.7647058963775635)
[2024-11-29 02:58:53,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:53,172][root][INFO] - Training Epoch: 2/10, step 63/574 completed (loss: 1.7172702550888062, acc: 0.5)
[2024-11-29 02:58:53,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:53,426][root][INFO] - Training Epoch: 2/10, step 64/574 completed (loss: 1.6991512775421143, acc: 0.5625)
[2024-11-29 02:58:53,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:53,658][root][INFO] - Training Epoch: 2/10, step 65/574 completed (loss: 1.3519002199172974, acc: 0.6896551847457886)
[2024-11-29 02:58:53,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:53,905][root][INFO] - Training Epoch: 2/10, step 66/574 completed (loss: 2.0586085319519043, acc: 0.5178571343421936)
[2024-11-29 02:58:54,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:54,153][root][INFO] - Training Epoch: 2/10, step 67/574 completed (loss: 2.3609557151794434, acc: 0.38333332538604736)
[2024-11-29 02:58:54,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:54,375][root][INFO] - Training Epoch: 2/10, step 68/574 completed (loss: 1.2668970823287964, acc: 0.6800000071525574)
[2024-11-29 02:58:54,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:54,599][root][INFO] - Training Epoch: 2/10, step 69/574 completed (loss: 1.6832345724105835, acc: 0.5)
[2024-11-29 02:58:54,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:54,832][root][INFO] - Training Epoch: 2/10, step 70/574 completed (loss: 2.5107736587524414, acc: 0.42424243688583374)
[2024-11-29 02:58:54,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:55,089][root][INFO] - Training Epoch: 2/10, step 71/574 completed (loss: 2.7902421951293945, acc: 0.3970588147640228)
[2024-11-29 02:58:55,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:55,328][root][INFO] - Training Epoch: 2/10, step 72/574 completed (loss: 2.3454365730285645, acc: 0.3968254029750824)
[2024-11-29 02:58:55,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:55,581][root][INFO] - Training Epoch: 2/10, step 73/574 completed (loss: 2.774210214614868, acc: 0.35384616255760193)
[2024-11-29 02:58:55,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:55,817][root][INFO] - Training Epoch: 2/10, step 74/574 completed (loss: 2.8313910961151123, acc: 0.3469387888908386)
[2024-11-29 02:58:55,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:56,044][root][INFO] - Training Epoch: 2/10, step 75/574 completed (loss: 2.814652442932129, acc: 0.26865673065185547)
[2024-11-29 02:58:56,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:56,335][root][INFO] - Training Epoch: 2/10, step 76/574 completed (loss: 2.7960472106933594, acc: 0.3467153310775757)
[2024-11-29 02:58:56,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:56,537][root][INFO] - Training Epoch: 2/10, step 77/574 completed (loss: 0.9985733032226562, acc: 0.8095238208770752)
[2024-11-29 02:58:56,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:56,752][root][INFO] - Training Epoch: 2/10, step 78/574 completed (loss: 1.1836349964141846, acc: 0.7083333134651184)
[2024-11-29 02:58:56,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:56,949][root][INFO] - Training Epoch: 2/10, step 79/574 completed (loss: 1.4337924718856812, acc: 0.6060606241226196)
[2024-11-29 02:58:57,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:57,180][root][INFO] - Training Epoch: 2/10, step 80/574 completed (loss: 1.5246195793151855, acc: 0.6153846383094788)
[2024-11-29 02:58:57,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:57,408][root][INFO] - Training Epoch: 2/10, step 81/574 completed (loss: 2.2271597385406494, acc: 0.5)
[2024-11-29 02:58:57,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:57,635][root][INFO] - Training Epoch: 2/10, step 82/574 completed (loss: 2.3015875816345215, acc: 0.5384615659713745)
[2024-11-29 02:58:57,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:57,858][root][INFO] - Training Epoch: 2/10, step 83/574 completed (loss: 0.8233263492584229, acc: 0.84375)
[2024-11-29 02:58:57,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:58,112][root][INFO] - Training Epoch: 2/10, step 84/574 completed (loss: 1.7003384828567505, acc: 0.5652173757553101)
[2024-11-29 02:58:58,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:58,347][root][INFO] - Training Epoch: 2/10, step 85/574 completed (loss: 1.8359897136688232, acc: 0.5600000023841858)
[2024-11-29 02:58:58,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:58,585][root][INFO] - Training Epoch: 2/10, step 86/574 completed (loss: 1.0136514902114868, acc: 0.782608687877655)
[2024-11-29 02:58:58,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:58,969][root][INFO] - Training Epoch: 2/10, step 87/574 completed (loss: 2.6837782859802246, acc: 0.3799999952316284)
[2024-11-29 02:58:59,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:59,188][root][INFO] - Training Epoch: 2/10, step 88/574 completed (loss: 2.243025779724121, acc: 0.4563106894493103)
[2024-11-29 02:58:59,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:00,176][root][INFO] - Training Epoch: 2/10, step 89/574 completed (loss: 2.3754796981811523, acc: 0.45145630836486816)
[2024-11-29 02:59:00,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:00,870][root][INFO] - Training Epoch: 2/10, step 90/574 completed (loss: 2.7504584789276123, acc: 0.35483869910240173)
[2024-11-29 02:59:01,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:01,552][root][INFO] - Training Epoch: 2/10, step 91/574 completed (loss: 2.468313217163086, acc: 0.4784482717514038)
[2024-11-29 02:59:01,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:02,180][root][INFO] - Training Epoch: 2/10, step 92/574 completed (loss: 2.0282933712005615, acc: 0.4842105209827423)
[2024-11-29 02:59:02,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:03,041][root][INFO] - Training Epoch: 2/10, step 93/574 completed (loss: 3.203397035598755, acc: 0.2970297038555145)
[2024-11-29 02:59:03,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:03,215][root][INFO] - Training Epoch: 2/10, step 94/574 completed (loss: 2.3819806575775146, acc: 0.3709677457809448)
[2024-11-29 02:59:03,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:03,426][root][INFO] - Training Epoch: 2/10, step 95/574 completed (loss: 2.5661709308624268, acc: 0.3913043439388275)
[2024-11-29 02:59:03,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:03,663][root][INFO] - Training Epoch: 2/10, step 96/574 completed (loss: 3.09519362449646, acc: 0.21848739683628082)
[2024-11-29 02:59:03,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:03,909][root][INFO] - Training Epoch: 2/10, step 97/574 completed (loss: 2.8963961601257324, acc: 0.2788461446762085)
[2024-11-29 02:59:04,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:04,185][root][INFO] - Training Epoch: 2/10, step 98/574 completed (loss: 2.800586223602295, acc: 0.29927006363868713)
[2024-11-29 02:59:04,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:04,428][root][INFO] - Training Epoch: 2/10, step 99/574 completed (loss: 2.991976022720337, acc: 0.28358209133148193)
[2024-11-29 02:59:04,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:04,667][root][INFO] - Training Epoch: 2/10, step 100/574 completed (loss: 2.0749294757843018, acc: 0.5)
[2024-11-29 02:59:04,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:04,879][root][INFO] - Training Epoch: 2/10, step 101/574 completed (loss: 0.797080934047699, acc: 0.7727272510528564)
[2024-11-29 02:59:04,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:05,079][root][INFO] - Training Epoch: 2/10, step 102/574 completed (loss: 1.040493130683899, acc: 0.6086956262588501)
[2024-11-29 02:59:05,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:05,279][root][INFO] - Training Epoch: 2/10, step 103/574 completed (loss: 1.2695677280426025, acc: 0.7272727489471436)
[2024-11-29 02:59:05,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:05,562][root][INFO] - Training Epoch: 2/10, step 104/574 completed (loss: 1.945285439491272, acc: 0.5)
[2024-11-29 02:59:05,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:05,829][root][INFO] - Training Epoch: 2/10, step 105/574 completed (loss: 1.4949250221252441, acc: 0.5581395626068115)
[2024-11-29 02:59:05,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:06,089][root][INFO] - Training Epoch: 2/10, step 106/574 completed (loss: 1.2523635625839233, acc: 0.7599999904632568)
[2024-11-29 02:59:06,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:06,336][root][INFO] - Training Epoch: 2/10, step 107/574 completed (loss: 0.7256956696510315, acc: 0.8823529481887817)
[2024-11-29 02:59:06,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:06,590][root][INFO] - Training Epoch: 2/10, step 108/574 completed (loss: 0.6938832998275757, acc: 0.807692289352417)
[2024-11-29 02:59:06,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:06,853][root][INFO] - Training Epoch: 2/10, step 109/574 completed (loss: 1.681212067604065, acc: 0.5952380895614624)
[2024-11-29 02:59:06,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:07,048][root][INFO] - Training Epoch: 2/10, step 110/574 completed (loss: 2.0808370113372803, acc: 0.5230769515037537)
[2024-11-29 02:59:07,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:07,344][root][INFO] - Training Epoch: 2/10, step 111/574 completed (loss: 2.2788455486297607, acc: 0.5263158082962036)
[2024-11-29 02:59:07,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:07,564][root][INFO] - Training Epoch: 2/10, step 112/574 completed (loss: 2.1473140716552734, acc: 0.45614033937454224)
[2024-11-29 02:59:07,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:07,798][root][INFO] - Training Epoch: 2/10, step 113/574 completed (loss: 2.0056557655334473, acc: 0.43589743971824646)
[2024-11-29 02:59:07,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:08,055][root][INFO] - Training Epoch: 2/10, step 114/574 completed (loss: 1.2895939350128174, acc: 0.5918367505073547)
[2024-11-29 02:59:08,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:08,324][root][INFO] - Training Epoch: 2/10, step 115/574 completed (loss: 1.400459885597229, acc: 0.6363636255264282)
[2024-11-29 02:59:08,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:08,559][root][INFO] - Training Epoch: 2/10, step 116/574 completed (loss: 2.2824370861053467, acc: 0.460317462682724)
[2024-11-29 02:59:08,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:08,815][root][INFO] - Training Epoch: 2/10, step 117/574 completed (loss: 2.561763048171997, acc: 0.43089431524276733)
[2024-11-29 02:59:08,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:09,025][root][INFO] - Training Epoch: 2/10, step 118/574 completed (loss: 1.976388692855835, acc: 0.5322580933570862)
[2024-11-29 02:59:09,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:09,813][root][INFO] - Training Epoch: 2/10, step 119/574 completed (loss: 2.5540106296539307, acc: 0.39923954010009766)
[2024-11-29 02:59:09,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:10,054][root][INFO] - Training Epoch: 2/10, step 120/574 completed (loss: 2.1317992210388184, acc: 0.47999998927116394)
[2024-11-29 02:59:10,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:10,349][root][INFO] - Training Epoch: 2/10, step 121/574 completed (loss: 1.8643288612365723, acc: 0.6153846383094788)
[2024-11-29 02:59:10,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:10,535][root][INFO] - Training Epoch: 2/10, step 122/574 completed (loss: 1.119658350944519, acc: 0.7916666865348816)
[2024-11-29 02:59:10,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:10,752][root][INFO] - Training Epoch: 2/10, step 123/574 completed (loss: 1.4257768392562866, acc: 0.6842105388641357)
[2024-11-29 02:59:10,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:10,983][root][INFO] - Training Epoch: 2/10, step 124/574 completed (loss: 2.777132272720337, acc: 0.3987730145454407)
[2024-11-29 02:59:11,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:11,224][root][INFO] - Training Epoch: 2/10, step 125/574 completed (loss: 2.4681243896484375, acc: 0.4375)
[2024-11-29 02:59:11,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:11,473][root][INFO] - Training Epoch: 2/10, step 126/574 completed (loss: 2.6885812282562256, acc: 0.3583333194255829)
[2024-11-29 02:59:11,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:11,711][root][INFO] - Training Epoch: 2/10, step 127/574 completed (loss: 2.6685245037078857, acc: 0.3571428656578064)
[2024-11-29 02:59:11,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:11,928][root][INFO] - Training Epoch: 2/10, step 128/574 completed (loss: 2.5658621788024902, acc: 0.41025641560554504)
[2024-11-29 02:59:12,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:12,230][root][INFO] - Training Epoch: 2/10, step 129/574 completed (loss: 2.5188121795654297, acc: 0.41911765933036804)
[2024-11-29 02:59:12,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:12,470][root][INFO] - Training Epoch: 2/10, step 130/574 completed (loss: 2.2801625728607178, acc: 0.42307692766189575)
[2024-11-29 02:59:12,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:12,738][root][INFO] - Training Epoch: 2/10, step 131/574 completed (loss: 1.430651068687439, acc: 0.5652173757553101)
[2024-11-29 02:59:12,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:13,001][root][INFO] - Training Epoch: 2/10, step 132/574 completed (loss: 2.83864164352417, acc: 0.3125)
[2024-11-29 02:59:13,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:13,240][root][INFO] - Training Epoch: 2/10, step 133/574 completed (loss: 2.066956043243408, acc: 0.5652173757553101)
[2024-11-29 02:59:13,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:13,482][root][INFO] - Training Epoch: 2/10, step 134/574 completed (loss: 2.088146209716797, acc: 0.5142857432365417)
[2024-11-29 02:59:13,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:13,704][root][INFO] - Training Epoch: 2/10, step 135/574 completed (loss: 2.2366204261779785, acc: 0.38461539149284363)
[2024-11-29 02:59:13,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:13,894][root][INFO] - Training Epoch: 2/10, step 136/574 completed (loss: 2.361936569213867, acc: 0.380952388048172)
[2024-11-29 02:59:13,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:14,118][root][INFO] - Training Epoch: 2/10, step 137/574 completed (loss: 2.3119595050811768, acc: 0.5)
[2024-11-29 02:59:14,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:14,319][root][INFO] - Training Epoch: 2/10, step 138/574 completed (loss: 1.4524247646331787, acc: 0.6521739363670349)
[2024-11-29 02:59:14,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:14,538][root][INFO] - Training Epoch: 2/10, step 139/574 completed (loss: 2.8310911655426025, acc: 0.3333333432674408)
[2024-11-29 02:59:14,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:14,775][root][INFO] - Training Epoch: 2/10, step 140/574 completed (loss: 2.295950174331665, acc: 0.42307692766189575)
[2024-11-29 02:59:15,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:15,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:16,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:16,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:16,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:17,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:17,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:17,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:17,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:18,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:18,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:18,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:19,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:19,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:19,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:20,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:20,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:20,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:20,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:21,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:21,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:21,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:22,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:22,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:22,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:22,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:23,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:23,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:23,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:23,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:24,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:24,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:24,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:24,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:25,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:25,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:25,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:25,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:26,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:26,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:26,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:26,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:27,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:27,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:27,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:27,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:28,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:28,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:28,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:29,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:29,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:29,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:30,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:30,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:30,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:30,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:31,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:31,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:31,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:32,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:32,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:32,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:33,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:33,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:33,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:33,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:34,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:34,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:34,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:35,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:35,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:35,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:35,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:36,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:36,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:36,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:36,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:37,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:37,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:37,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:38,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:38,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:38,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:39,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:39,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:39,803][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.6242, device='cuda:0') eval_epoch_loss=tensor(1.8907, device='cuda:0') eval_epoch_acc=tensor(0.5275, device='cuda:0')
[2024-11-29 02:59:39,806][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 02:59:39,806][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 02:59:40,092][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_2_step_141_loss_1.8907277584075928/model.pt
[2024-11-29 02:59:40,096][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 1.8907277584075928
[2024-11-29 02:59:40,097][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.5275046825408936
[2024-11-29 02:59:40,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:40,302][root][INFO] - Training Epoch: 2/10, step 141/574 completed (loss: 2.4159884452819824, acc: 0.35483869910240173)
[2024-11-29 02:59:40,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:40,536][root][INFO] - Training Epoch: 2/10, step 142/574 completed (loss: 1.7238554954528809, acc: 0.5135135054588318)
[2024-11-29 02:59:40,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:40,993][root][INFO] - Training Epoch: 2/10, step 143/574 completed (loss: 2.016916275024414, acc: 0.5350877046585083)
[2024-11-29 02:59:41,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:41,219][root][INFO] - Training Epoch: 2/10, step 144/574 completed (loss: 1.89308500289917, acc: 0.5970149040222168)
[2024-11-29 02:59:41,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:41,451][root][INFO] - Training Epoch: 2/10, step 145/574 completed (loss: 2.1726322174072266, acc: 0.4285714328289032)
[2024-11-29 02:59:41,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:41,805][root][INFO] - Training Epoch: 2/10, step 146/574 completed (loss: 2.058420419692993, acc: 0.4680851101875305)
[2024-11-29 02:59:41,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:42,007][root][INFO] - Training Epoch: 2/10, step 147/574 completed (loss: 2.000199317932129, acc: 0.5714285969734192)
[2024-11-29 02:59:42,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:42,249][root][INFO] - Training Epoch: 2/10, step 148/574 completed (loss: 1.9175598621368408, acc: 0.5357142686843872)
[2024-11-29 02:59:42,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:42,484][root][INFO] - Training Epoch: 2/10, step 149/574 completed (loss: 1.4146127700805664, acc: 0.6521739363670349)
[2024-11-29 02:59:42,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:42,716][root][INFO] - Training Epoch: 2/10, step 150/574 completed (loss: 2.03127384185791, acc: 0.517241358757019)
[2024-11-29 02:59:42,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:42,951][root][INFO] - Training Epoch: 2/10, step 151/574 completed (loss: 2.229865074157715, acc: 0.52173912525177)
[2024-11-29 02:59:43,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:43,198][root][INFO] - Training Epoch: 2/10, step 152/574 completed (loss: 1.4954851865768433, acc: 0.6440678238868713)
[2024-11-29 02:59:43,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:43,429][root][INFO] - Training Epoch: 2/10, step 153/574 completed (loss: 2.624929666519165, acc: 0.4035087823867798)
[2024-11-29 02:59:43,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:43,665][root][INFO] - Training Epoch: 2/10, step 154/574 completed (loss: 2.013988971710205, acc: 0.5270270109176636)
[2024-11-29 02:59:43,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:43,894][root][INFO] - Training Epoch: 2/10, step 155/574 completed (loss: 1.347919225692749, acc: 0.7857142686843872)
[2024-11-29 02:59:43,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:44,123][root][INFO] - Training Epoch: 2/10, step 156/574 completed (loss: 1.4635640382766724, acc: 0.6521739363670349)
[2024-11-29 02:59:44,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:44,361][root][INFO] - Training Epoch: 2/10, step 157/574 completed (loss: 3.727825403213501, acc: 0.21052631735801697)
[2024-11-29 02:59:45,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:46,012][root][INFO] - Training Epoch: 2/10, step 158/574 completed (loss: 3.1953933238983154, acc: 0.3243243098258972)
[2024-11-29 02:59:46,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:46,198][root][INFO] - Training Epoch: 2/10, step 159/574 completed (loss: 2.817115545272827, acc: 0.35185185074806213)
[2024-11-29 02:59:46,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:46,504][root][INFO] - Training Epoch: 2/10, step 160/574 completed (loss: 3.2557148933410645, acc: 0.2906976640224457)
[2024-11-29 02:59:46,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:47,023][root][INFO] - Training Epoch: 2/10, step 161/574 completed (loss: 3.1550092697143555, acc: 0.34117648005485535)
[2024-11-29 02:59:47,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:47,493][root][INFO] - Training Epoch: 2/10, step 162/574 completed (loss: 3.1289587020874023, acc: 0.2808988690376282)
[2024-11-29 02:59:47,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:47,694][root][INFO] - Training Epoch: 2/10, step 163/574 completed (loss: 1.812252163887024, acc: 0.5227272510528564)
[2024-11-29 02:59:47,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:47,889][root][INFO] - Training Epoch: 2/10, step 164/574 completed (loss: 1.9208567142486572, acc: 0.5714285969734192)
[2024-11-29 02:59:47,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:48,064][root][INFO] - Training Epoch: 2/10, step 165/574 completed (loss: 2.7880637645721436, acc: 0.3448275923728943)
[2024-11-29 02:59:48,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:48,269][root][INFO] - Training Epoch: 2/10, step 166/574 completed (loss: 1.3162614107131958, acc: 0.6734693646430969)
[2024-11-29 02:59:48,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:48,443][root][INFO] - Training Epoch: 2/10, step 167/574 completed (loss: 1.2519422769546509, acc: 0.6399999856948853)
[2024-11-29 02:59:48,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:48,747][root][INFO] - Training Epoch: 2/10, step 168/574 completed (loss: 1.5836912393569946, acc: 0.6111111044883728)
[2024-11-29 02:59:48,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:49,030][root][INFO] - Training Epoch: 2/10, step 169/574 completed (loss: 2.0072999000549316, acc: 0.4803921580314636)
[2024-11-29 02:59:49,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:50,022][root][INFO] - Training Epoch: 2/10, step 170/574 completed (loss: 2.8512051105499268, acc: 0.3493150770664215)
[2024-11-29 02:59:50,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:50,209][root][INFO] - Training Epoch: 2/10, step 171/574 completed (loss: 1.2578331232070923, acc: 0.625)
[2024-11-29 02:59:50,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:50,402][root][INFO] - Training Epoch: 2/10, step 172/574 completed (loss: 2.0017025470733643, acc: 0.48148149251937866)
[2024-11-29 02:59:50,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:50,615][root][INFO] - Training Epoch: 2/10, step 173/574 completed (loss: 1.7339932918548584, acc: 0.5714285969734192)
[2024-11-29 02:59:50,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:51,081][root][INFO] - Training Epoch: 2/10, step 174/574 completed (loss: 2.2104079723358154, acc: 0.5044247508049011)
[2024-11-29 02:59:51,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:51,294][root][INFO] - Training Epoch: 2/10, step 175/574 completed (loss: 2.3138842582702637, acc: 0.4202898442745209)
[2024-11-29 02:59:51,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:51,523][root][INFO] - Training Epoch: 2/10, step 176/574 completed (loss: 2.166961669921875, acc: 0.4318181872367859)
[2024-11-29 02:59:51,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:52,385][root][INFO] - Training Epoch: 2/10, step 177/574 completed (loss: 2.621394395828247, acc: 0.32824426889419556)
[2024-11-29 02:59:52,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:52,961][root][INFO] - Training Epoch: 2/10, step 178/574 completed (loss: 2.38205623626709, acc: 0.4000000059604645)
[2024-11-29 02:59:53,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:53,190][root][INFO] - Training Epoch: 2/10, step 179/574 completed (loss: 1.7351937294006348, acc: 0.6229507923126221)
[2024-11-29 02:59:53,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:53,443][root][INFO] - Training Epoch: 2/10, step 180/574 completed (loss: 0.3891880214214325, acc: 0.9166666865348816)
[2024-11-29 02:59:53,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:53,725][root][INFO] - Training Epoch: 2/10, step 181/574 completed (loss: 0.5398594737052917, acc: 0.8799999952316284)
[2024-11-29 02:59:53,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:54,025][root][INFO] - Training Epoch: 2/10, step 182/574 completed (loss: 1.1719343662261963, acc: 0.7142857313156128)
[2024-11-29 02:59:54,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:54,253][root][INFO] - Training Epoch: 2/10, step 183/574 completed (loss: 1.7355058193206787, acc: 0.5365853905677795)
[2024-11-29 02:59:54,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:54,501][root][INFO] - Training Epoch: 2/10, step 184/574 completed (loss: 2.4991891384124756, acc: 0.395770400762558)
[2024-11-29 02:59:54,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:54,779][root][INFO] - Training Epoch: 2/10, step 185/574 completed (loss: 2.5361201763153076, acc: 0.3717579245567322)
[2024-11-29 02:59:54,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:55,197][root][INFO] - Training Epoch: 2/10, step 186/574 completed (loss: 2.5865530967712402, acc: 0.35624998807907104)
[2024-11-29 02:59:55,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:55,624][root][INFO] - Training Epoch: 2/10, step 187/574 completed (loss: 2.6095962524414062, acc: 0.39024388790130615)
[2024-11-29 02:59:55,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:55,932][root][INFO] - Training Epoch: 2/10, step 188/574 completed (loss: 2.2299091815948486, acc: 0.4590747356414795)
[2024-11-29 02:59:56,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:56,171][root][INFO] - Training Epoch: 2/10, step 189/574 completed (loss: 1.9381554126739502, acc: 0.6000000238418579)
[2024-11-29 02:59:56,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:56,660][root][INFO] - Training Epoch: 2/10, step 190/574 completed (loss: 2.397677421569824, acc: 0.44186046719551086)
[2024-11-29 02:59:56,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:57,366][root][INFO] - Training Epoch: 2/10, step 191/574 completed (loss: 2.8489558696746826, acc: 0.341269850730896)
[2024-11-29 02:59:57,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:58,173][root][INFO] - Training Epoch: 2/10, step 192/574 completed (loss: 2.56703519821167, acc: 0.3787878751754761)
[2024-11-29 02:59:58,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:58,817][root][INFO] - Training Epoch: 2/10, step 193/574 completed (loss: 1.937300682067871, acc: 0.5058823823928833)
[2024-11-29 02:59:59,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:59,779][root][INFO] - Training Epoch: 2/10, step 194/574 completed (loss: 2.260589122772217, acc: 0.4753086566925049)
[2024-11-29 03:00:00,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:00,629][root][INFO] - Training Epoch: 2/10, step 195/574 completed (loss: 1.7976198196411133, acc: 0.5161290168762207)
[2024-11-29 03:00:00,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:00,835][root][INFO] - Training Epoch: 2/10, step 196/574 completed (loss: 0.8670883774757385, acc: 0.7142857313156128)
[2024-11-29 03:00:00,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:01,092][root][INFO] - Training Epoch: 2/10, step 197/574 completed (loss: 2.427905321121216, acc: 0.5)
[2024-11-29 03:00:01,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:01,335][root][INFO] - Training Epoch: 2/10, step 198/574 completed (loss: 2.0148558616638184, acc: 0.529411792755127)
[2024-11-29 03:00:01,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:01,601][root][INFO] - Training Epoch: 2/10, step 199/574 completed (loss: 2.0142242908477783, acc: 0.5588235259056091)
[2024-11-29 03:00:01,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:01,894][root][INFO] - Training Epoch: 2/10, step 200/574 completed (loss: 1.9258081912994385, acc: 0.5338982939720154)
[2024-11-29 03:00:02,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:02,183][root][INFO] - Training Epoch: 2/10, step 201/574 completed (loss: 2.2563836574554443, acc: 0.48507463932037354)
[2024-11-29 03:00:02,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:02,488][root][INFO] - Training Epoch: 2/10, step 202/574 completed (loss: 2.425191640853882, acc: 0.41747573018074036)
[2024-11-29 03:00:02,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:02,747][root][INFO] - Training Epoch: 2/10, step 203/574 completed (loss: 2.2727818489074707, acc: 0.4761904776096344)
[2024-11-29 03:00:02,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:02,997][root][INFO] - Training Epoch: 2/10, step 204/574 completed (loss: 1.729032278060913, acc: 0.5384615659713745)
[2024-11-29 03:00:03,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:03,305][root][INFO] - Training Epoch: 2/10, step 205/574 completed (loss: 2.100740909576416, acc: 0.46188339591026306)
[2024-11-29 03:00:03,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:03,629][root][INFO] - Training Epoch: 2/10, step 206/574 completed (loss: 2.244788885116577, acc: 0.4921259880065918)
[2024-11-29 03:00:03,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:03,855][root][INFO] - Training Epoch: 2/10, step 207/574 completed (loss: 1.8012717962265015, acc: 0.556034505367279)
[2024-11-29 03:00:03,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:04,091][root][INFO] - Training Epoch: 2/10, step 208/574 completed (loss: 1.8096883296966553, acc: 0.5181159377098083)
[2024-11-29 03:00:04,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:04,357][root][INFO] - Training Epoch: 2/10, step 209/574 completed (loss: 1.9257831573486328, acc: 0.5214007496833801)
[2024-11-29 03:00:04,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:04,600][root][INFO] - Training Epoch: 2/10, step 210/574 completed (loss: 2.1963589191436768, acc: 0.44565218687057495)
[2024-11-29 03:00:04,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:04,868][root][INFO] - Training Epoch: 2/10, step 211/574 completed (loss: 1.222150444984436, acc: 0.695652186870575)
[2024-11-29 03:00:04,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:05,103][root][INFO] - Training Epoch: 2/10, step 212/574 completed (loss: 1.1633776426315308, acc: 0.5714285969734192)
[2024-11-29 03:00:05,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:05,329][root][INFO] - Training Epoch: 2/10, step 213/574 completed (loss: 1.6159374713897705, acc: 0.5744680762290955)
[2024-11-29 03:00:05,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:05,982][root][INFO] - Training Epoch: 2/10, step 214/574 completed (loss: 1.6183807849884033, acc: 0.5538461804389954)
[2024-11-29 03:00:06,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:06,207][root][INFO] - Training Epoch: 2/10, step 215/574 completed (loss: 1.1984010934829712, acc: 0.7162162065505981)
[2024-11-29 03:00:06,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:06,418][root][INFO] - Training Epoch: 2/10, step 216/574 completed (loss: 1.0965704917907715, acc: 0.7325581312179565)
[2024-11-29 03:00:06,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:06,897][root][INFO] - Training Epoch: 2/10, step 217/574 completed (loss: 1.4131163358688354, acc: 0.6486486196517944)
[2024-11-29 03:00:07,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:07,199][root][INFO] - Training Epoch: 2/10, step 218/574 completed (loss: 1.1580597162246704, acc: 0.7222222089767456)
[2024-11-29 03:00:07,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:07,476][root][INFO] - Training Epoch: 2/10, step 219/574 completed (loss: 0.7510818243026733, acc: 0.8787878751754761)
[2024-11-29 03:00:07,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:07,754][root][INFO] - Training Epoch: 2/10, step 220/574 completed (loss: 0.6819777488708496, acc: 0.8148148059844971)
[2024-11-29 03:00:07,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:08,024][root][INFO] - Training Epoch: 2/10, step 221/574 completed (loss: 0.5069050788879395, acc: 0.8399999737739563)
[2024-11-29 03:00:08,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:08,264][root][INFO] - Training Epoch: 2/10, step 222/574 completed (loss: 1.8939906358718872, acc: 0.5961538553237915)
[2024-11-29 03:00:08,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:09,005][root][INFO] - Training Epoch: 2/10, step 223/574 completed (loss: 1.9601439237594604, acc: 0.532608687877655)
[2024-11-29 03:00:09,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:09,460][root][INFO] - Training Epoch: 2/10, step 224/574 completed (loss: 2.1464712619781494, acc: 0.4886363744735718)
[2024-11-29 03:00:09,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:09,811][root][INFO] - Training Epoch: 2/10, step 225/574 completed (loss: 2.2110648155212402, acc: 0.43617022037506104)
[2024-11-29 03:00:09,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:10,049][root][INFO] - Training Epoch: 2/10, step 226/574 completed (loss: 1.6891058683395386, acc: 0.5849056839942932)
[2024-11-29 03:00:10,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:10,266][root][INFO] - Training Epoch: 2/10, step 227/574 completed (loss: 1.2343471050262451, acc: 0.6499999761581421)
[2024-11-29 03:00:10,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:10,468][root][INFO] - Training Epoch: 2/10, step 228/574 completed (loss: 1.6600664854049683, acc: 0.6279069781303406)
[2024-11-29 03:00:10,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:10,658][root][INFO] - Training Epoch: 2/10, step 229/574 completed (loss: 3.0705113410949707, acc: 0.4000000059604645)
[2024-11-29 03:00:10,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:10,935][root][INFO] - Training Epoch: 2/10, step 230/574 completed (loss: 3.5472586154937744, acc: 0.1894736886024475)
[2024-11-29 03:00:11,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:11,155][root][INFO] - Training Epoch: 2/10, step 231/574 completed (loss: 2.6640753746032715, acc: 0.3333333432674408)
[2024-11-29 03:00:11,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:11,489][root][INFO] - Training Epoch: 2/10, step 232/574 completed (loss: 2.437511920928955, acc: 0.41111111640930176)
[2024-11-29 03:00:11,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:11,896][root][INFO] - Training Epoch: 2/10, step 233/574 completed (loss: 2.764464855194092, acc: 0.3899082541465759)
[2024-11-29 03:00:12,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:12,275][root][INFO] - Training Epoch: 2/10, step 234/574 completed (loss: 2.6855475902557373, acc: 0.4076923131942749)
[2024-11-29 03:00:12,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:12,493][root][INFO] - Training Epoch: 2/10, step 235/574 completed (loss: 0.6952925324440002, acc: 0.7368420958518982)
[2024-11-29 03:00:12,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:12,725][root][INFO] - Training Epoch: 2/10, step 236/574 completed (loss: 1.2600082159042358, acc: 0.7083333134651184)
[2024-11-29 03:00:12,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:12,974][root][INFO] - Training Epoch: 2/10, step 237/574 completed (loss: 2.199856758117676, acc: 0.40909090638160706)
[2024-11-29 03:00:13,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:13,236][root][INFO] - Training Epoch: 2/10, step 238/574 completed (loss: 2.048057794570923, acc: 0.5185185074806213)
[2024-11-29 03:00:13,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:13,448][root][INFO] - Training Epoch: 2/10, step 239/574 completed (loss: 1.5944987535476685, acc: 0.5714285969734192)
[2024-11-29 03:00:13,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:13,654][root][INFO] - Training Epoch: 2/10, step 240/574 completed (loss: 1.7257587909698486, acc: 0.5909090638160706)
[2024-11-29 03:00:13,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:13,879][root][INFO] - Training Epoch: 2/10, step 241/574 completed (loss: 1.581808090209961, acc: 0.6136363744735718)
[2024-11-29 03:00:14,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:14,387][root][INFO] - Training Epoch: 2/10, step 242/574 completed (loss: 2.4491329193115234, acc: 0.4032258093357086)
[2024-11-29 03:00:14,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:14,822][root][INFO] - Training Epoch: 2/10, step 243/574 completed (loss: 2.1371169090270996, acc: 0.4545454680919647)
[2024-11-29 03:00:14,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:15,059][root][INFO] - Training Epoch: 2/10, step 244/574 completed (loss: 1.061179518699646, acc: 0.7142857313156128)
[2024-11-29 03:00:15,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:15,328][root][INFO] - Training Epoch: 2/10, step 245/574 completed (loss: 1.642722487449646, acc: 0.5769230723381042)
[2024-11-29 03:00:15,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:15,597][root][INFO] - Training Epoch: 2/10, step 246/574 completed (loss: 1.6542019844055176, acc: 0.6451612710952759)
[2024-11-29 03:00:15,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:15,840][root][INFO] - Training Epoch: 2/10, step 247/574 completed (loss: 0.7875899076461792, acc: 0.75)
[2024-11-29 03:00:15,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:16,118][root][INFO] - Training Epoch: 2/10, step 248/574 completed (loss: 1.8445888757705688, acc: 0.6216216087341309)
[2024-11-29 03:00:16,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:16,383][root][INFO] - Training Epoch: 2/10, step 249/574 completed (loss: 1.5456881523132324, acc: 0.7027027010917664)
[2024-11-29 03:00:16,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:16,634][root][INFO] - Training Epoch: 2/10, step 250/574 completed (loss: 1.286801815032959, acc: 0.7027027010917664)
[2024-11-29 03:00:16,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:16,878][root][INFO] - Training Epoch: 2/10, step 251/574 completed (loss: 1.7497769594192505, acc: 0.6029411554336548)
[2024-11-29 03:00:16,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:17,103][root][INFO] - Training Epoch: 2/10, step 252/574 completed (loss: 0.5539682507514954, acc: 0.8048780560493469)
[2024-11-29 03:00:17,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:17,337][root][INFO] - Training Epoch: 2/10, step 253/574 completed (loss: 1.3992323875427246, acc: 0.6000000238418579)
[2024-11-29 03:00:17,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:17,545][root][INFO] - Training Epoch: 2/10, step 254/574 completed (loss: 0.20273107290267944, acc: 0.9599999785423279)
[2024-11-29 03:00:17,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:17,762][root][INFO] - Training Epoch: 2/10, step 255/574 completed (loss: 1.7693182229995728, acc: 0.6129032373428345)
[2024-11-29 03:00:17,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:17,967][root][INFO] - Training Epoch: 2/10, step 256/574 completed (loss: 1.3406184911727905, acc: 0.719298243522644)
[2024-11-29 03:00:18,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:18,223][root][INFO] - Training Epoch: 2/10, step 257/574 completed (loss: 1.5347766876220703, acc: 0.6142857074737549)
[2024-11-29 03:00:18,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:18,486][root][INFO] - Training Epoch: 2/10, step 258/574 completed (loss: 1.432907223701477, acc: 0.6447368264198303)
[2024-11-29 03:00:18,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:18,980][root][INFO] - Training Epoch: 2/10, step 259/574 completed (loss: 1.9887741804122925, acc: 0.5283018946647644)
[2024-11-29 03:00:19,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:19,470][root][INFO] - Training Epoch: 2/10, step 260/574 completed (loss: 1.9027442932128906, acc: 0.5583333373069763)
[2024-11-29 03:00:19,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:19,671][root][INFO] - Training Epoch: 2/10, step 261/574 completed (loss: 1.061696171760559, acc: 0.7222222089767456)
[2024-11-29 03:00:19,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:19,906][root][INFO] - Training Epoch: 2/10, step 262/574 completed (loss: 1.5011447668075562, acc: 0.6129032373428345)
[2024-11-29 03:00:20,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:20,151][root][INFO] - Training Epoch: 2/10, step 263/574 completed (loss: 2.2942957878112793, acc: 0.4533333480358124)
[2024-11-29 03:00:20,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:20,355][root][INFO] - Training Epoch: 2/10, step 264/574 completed (loss: 1.6853336095809937, acc: 0.6041666865348816)
[2024-11-29 03:00:20,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:21,129][root][INFO] - Training Epoch: 2/10, step 265/574 completed (loss: 2.534101963043213, acc: 0.36000001430511475)
[2024-11-29 03:00:21,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:21,345][root][INFO] - Training Epoch: 2/10, step 266/574 completed (loss: 1.8527427911758423, acc: 0.483146071434021)
[2024-11-29 03:00:21,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:21,606][root][INFO] - Training Epoch: 2/10, step 267/574 completed (loss: 2.238677740097046, acc: 0.3918918967247009)
[2024-11-29 03:00:21,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:21,966][root][INFO] - Training Epoch: 2/10, step 268/574 completed (loss: 1.6218528747558594, acc: 0.5517241358757019)
[2024-11-29 03:00:22,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:22,155][root][INFO] - Training Epoch: 2/10, step 269/574 completed (loss: 0.7383736968040466, acc: 0.8181818127632141)
[2024-11-29 03:00:22,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:22,376][root][INFO] - Training Epoch: 2/10, step 270/574 completed (loss: 0.7537292242050171, acc: 0.8181818127632141)
[2024-11-29 03:00:22,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:22,630][root][INFO] - Training Epoch: 2/10, step 271/574 completed (loss: 0.6012877821922302, acc: 0.84375)
[2024-11-29 03:00:22,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:22,877][root][INFO] - Training Epoch: 2/10, step 272/574 completed (loss: 0.6898676753044128, acc: 0.8333333134651184)
[2024-11-29 03:00:23,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:23,161][root][INFO] - Training Epoch: 2/10, step 273/574 completed (loss: 1.5367189645767212, acc: 0.6166666746139526)
[2024-11-29 03:00:23,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:23,437][root][INFO] - Training Epoch: 2/10, step 274/574 completed (loss: 1.0397428274154663, acc: 0.6875)
[2024-11-29 03:00:23,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:23,680][root][INFO] - Training Epoch: 2/10, step 275/574 completed (loss: 1.1592388153076172, acc: 0.7666666507720947)
[2024-11-29 03:00:23,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:23,907][root][INFO] - Training Epoch: 2/10, step 276/574 completed (loss: 0.9395499229431152, acc: 0.7931034564971924)
[2024-11-29 03:00:24,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:24,126][root][INFO] - Training Epoch: 2/10, step 277/574 completed (loss: 0.4810468256473541, acc: 0.8799999952316284)
[2024-11-29 03:00:24,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:24,364][root][INFO] - Training Epoch: 2/10, step 278/574 completed (loss: 1.6664257049560547, acc: 0.5319148898124695)
[2024-11-29 03:00:24,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:24,630][root][INFO] - Training Epoch: 2/10, step 279/574 completed (loss: 1.2726489305496216, acc: 0.6666666865348816)
[2024-11-29 03:00:24,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:24,909][root][INFO] - Training Epoch: 2/10, step 280/574 completed (loss: 0.7601408362388611, acc: 0.7727272510528564)
[2024-11-29 03:00:25,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:25,250][root][INFO] - Training Epoch: 2/10, step 281/574 completed (loss: 1.9208248853683472, acc: 0.5180723071098328)
[2024-11-29 03:00:25,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:25,509][root][INFO] - Training Epoch: 2/10, step 282/574 completed (loss: 1.9343302249908447, acc: 0.5092592835426331)
[2024-11-29 03:00:25,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:25,704][root][INFO] - Training Epoch: 2/10, step 283/574 completed (loss: 1.6312276124954224, acc: 0.5526315569877625)
[2024-11-29 03:00:26,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:26,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:27,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:27,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:27,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:27,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:28,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:28,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:28,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:28,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:29,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:29,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:29,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:30,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:30,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:30,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:30,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:31,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:31,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:31,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:32,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:32,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:32,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:32,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:33,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:33,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:33,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:33,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:34,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:34,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:34,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:35,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:35,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:35,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:35,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:36,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:36,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:36,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:36,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:37,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:37,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:37,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:37,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:38,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:38,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:38,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:38,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:39,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:39,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:39,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:39,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:40,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:40,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:40,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:41,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:41,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:41,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:41,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:42,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:42,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:42,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:43,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:43,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:43,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:44,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:44,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:44,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:44,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:45,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:45,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:45,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:46,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:46,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:46,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:46,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:46,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:47,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:47,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:47,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:47,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:48,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:48,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:48,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:49,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:49,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:50,017][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(4.5013, device='cuda:0') eval_epoch_loss=tensor(1.5044, device='cuda:0') eval_epoch_acc=tensor(0.6248, device='cuda:0')
[2024-11-29 03:00:50,018][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:00:50,018][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:00:50,266][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_2_step_284_loss_1.504357933998108/model.pt
[2024-11-29 03:00:50,273][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 1.504357933998108
[2024-11-29 03:00:50,274][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.6247904896736145
[2024-11-29 03:00:50,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:50,555][root][INFO] - Training Epoch: 2/10, step 284/574 completed (loss: 1.1834440231323242, acc: 0.6764705777168274)
[2024-11-29 03:00:50,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:50,824][root][INFO] - Training Epoch: 2/10, step 285/574 completed (loss: 1.423242449760437, acc: 0.675000011920929)
[2024-11-29 03:00:50,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:51,100][root][INFO] - Training Epoch: 2/10, step 286/574 completed (loss: 1.4601106643676758, acc: 0.625)
[2024-11-29 03:00:51,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:51,363][root][INFO] - Training Epoch: 2/10, step 287/574 completed (loss: 1.732036828994751, acc: 0.5440000295639038)
[2024-11-29 03:00:51,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:51,606][root][INFO] - Training Epoch: 2/10, step 288/574 completed (loss: 1.3880497217178345, acc: 0.6813187003135681)
[2024-11-29 03:00:51,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:51,848][root][INFO] - Training Epoch: 2/10, step 289/574 completed (loss: 1.7057582139968872, acc: 0.5590062141418457)
[2024-11-29 03:00:51,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:52,089][root][INFO] - Training Epoch: 2/10, step 290/574 completed (loss: 2.002443313598633, acc: 0.4484536051750183)
[2024-11-29 03:00:52,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:52,341][root][INFO] - Training Epoch: 2/10, step 291/574 completed (loss: 1.0279842615127563, acc: 0.7272727489471436)
[2024-11-29 03:00:52,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:52,585][root][INFO] - Training Epoch: 2/10, step 292/574 completed (loss: 1.7507963180541992, acc: 0.5952380895614624)
[2024-11-29 03:00:52,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:52,849][root][INFO] - Training Epoch: 2/10, step 293/574 completed (loss: 1.4450596570968628, acc: 0.5862069129943848)
[2024-11-29 03:00:52,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:53,238][root][INFO] - Training Epoch: 2/10, step 294/574 completed (loss: 1.2775471210479736, acc: 0.6909090876579285)
[2024-11-29 03:00:53,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:53,694][root][INFO] - Training Epoch: 2/10, step 295/574 completed (loss: 1.675246238708496, acc: 0.5824742317199707)
[2024-11-29 03:00:53,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:53,845][root][INFO] - Training Epoch: 2/10, step 296/574 completed (loss: 2.0103423595428467, acc: 0.48275861144065857)
[2024-11-29 03:00:53,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:54,072][root][INFO] - Training Epoch: 2/10, step 297/574 completed (loss: 0.6723485589027405, acc: 0.7777777910232544)
[2024-11-29 03:00:54,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:54,315][root][INFO] - Training Epoch: 2/10, step 298/574 completed (loss: 1.7154314517974854, acc: 0.5263158082962036)
[2024-11-29 03:00:54,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:54,556][root][INFO] - Training Epoch: 2/10, step 299/574 completed (loss: 1.3617706298828125, acc: 0.6785714030265808)
[2024-11-29 03:00:54,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:54,813][root][INFO] - Training Epoch: 2/10, step 300/574 completed (loss: 0.6990418434143066, acc: 0.84375)
[2024-11-29 03:00:54,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:55,058][root][INFO] - Training Epoch: 2/10, step 301/574 completed (loss: 1.4117960929870605, acc: 0.6415094137191772)
[2024-11-29 03:00:55,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:55,325][root][INFO] - Training Epoch: 2/10, step 302/574 completed (loss: 0.8719187378883362, acc: 0.7735849022865295)
[2024-11-29 03:00:55,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:55,552][root][INFO] - Training Epoch: 2/10, step 303/574 completed (loss: 0.731579601764679, acc: 0.8235294222831726)
[2024-11-29 03:00:55,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:55,787][root][INFO] - Training Epoch: 2/10, step 304/574 completed (loss: 1.257059931755066, acc: 0.65625)
[2024-11-29 03:00:55,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:55,994][root][INFO] - Training Epoch: 2/10, step 305/574 completed (loss: 1.6244606971740723, acc: 0.6229507923126221)
[2024-11-29 03:00:56,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:56,186][root][INFO] - Training Epoch: 2/10, step 306/574 completed (loss: 0.6386767625808716, acc: 0.8666666746139526)
[2024-11-29 03:00:56,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:56,438][root][INFO] - Training Epoch: 2/10, step 307/574 completed (loss: 0.31397098302841187, acc: 0.9473684430122375)
[2024-11-29 03:00:56,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:56,712][root][INFO] - Training Epoch: 2/10, step 308/574 completed (loss: 1.415950894355774, acc: 0.6521739363670349)
[2024-11-29 03:00:56,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:57,038][root][INFO] - Training Epoch: 2/10, step 309/574 completed (loss: 1.6824039220809937, acc: 0.6388888955116272)
[2024-11-29 03:00:57,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:57,293][root][INFO] - Training Epoch: 2/10, step 310/574 completed (loss: 1.428991436958313, acc: 0.6265060305595398)
[2024-11-29 03:00:57,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:57,546][root][INFO] - Training Epoch: 2/10, step 311/574 completed (loss: 1.5641632080078125, acc: 0.5512820482254028)
[2024-11-29 03:00:57,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:57,801][root][INFO] - Training Epoch: 2/10, step 312/574 completed (loss: 1.3488531112670898, acc: 0.6326530575752258)
[2024-11-29 03:00:57,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:58,043][root][INFO] - Training Epoch: 2/10, step 313/574 completed (loss: 0.7374889850616455, acc: 0.7083333134651184)
[2024-11-29 03:00:58,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:58,287][root][INFO] - Training Epoch: 2/10, step 314/574 completed (loss: 0.9485809803009033, acc: 0.7916666865348816)
[2024-11-29 03:00:58,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:58,540][root][INFO] - Training Epoch: 2/10, step 315/574 completed (loss: 1.3644050359725952, acc: 0.6774193644523621)
[2024-11-29 03:00:58,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:58,810][root][INFO] - Training Epoch: 2/10, step 316/574 completed (loss: 2.2506415843963623, acc: 0.5161290168762207)
[2024-11-29 03:00:58,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:59,072][root][INFO] - Training Epoch: 2/10, step 317/574 completed (loss: 1.0577242374420166, acc: 0.7014925479888916)
[2024-11-29 03:00:59,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:59,357][root][INFO] - Training Epoch: 2/10, step 318/574 completed (loss: 0.9781450033187866, acc: 0.7692307829856873)
[2024-11-29 03:00:59,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:59,601][root][INFO] - Training Epoch: 2/10, step 319/574 completed (loss: 0.8845741152763367, acc: 0.7555555701255798)
[2024-11-29 03:00:59,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:59,852][root][INFO] - Training Epoch: 2/10, step 320/574 completed (loss: 1.0403910875320435, acc: 0.7419354915618896)
[2024-11-29 03:00:59,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:00,122][root][INFO] - Training Epoch: 2/10, step 321/574 completed (loss: 0.4092174470424652, acc: 0.8600000143051147)
[2024-11-29 03:01:00,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:00,357][root][INFO] - Training Epoch: 2/10, step 322/574 completed (loss: 2.581491470336914, acc: 0.40740740299224854)
[2024-11-29 03:01:00,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:00,622][root][INFO] - Training Epoch: 2/10, step 323/574 completed (loss: 3.3347725868225098, acc: 0.2571428716182709)
[2024-11-29 03:01:00,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:00,878][root][INFO] - Training Epoch: 2/10, step 324/574 completed (loss: 2.9956588745117188, acc: 0.3076923191547394)
[2024-11-29 03:01:00,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:01,142][root][INFO] - Training Epoch: 2/10, step 325/574 completed (loss: 2.9971985816955566, acc: 0.3414634168148041)
[2024-11-29 03:01:01,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:01,374][root][INFO] - Training Epoch: 2/10, step 326/574 completed (loss: 2.411302328109741, acc: 0.4736842215061188)
[2024-11-29 03:01:01,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:01,608][root][INFO] - Training Epoch: 2/10, step 327/574 completed (loss: 1.3252497911453247, acc: 0.6315789222717285)
[2024-11-29 03:01:01,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:01,866][root][INFO] - Training Epoch: 2/10, step 328/574 completed (loss: 0.5162736177444458, acc: 0.9285714030265808)
[2024-11-29 03:01:01,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:02,156][root][INFO] - Training Epoch: 2/10, step 329/574 completed (loss: 1.1386505365371704, acc: 0.6296296119689941)
[2024-11-29 03:01:02,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:02,382][root][INFO] - Training Epoch: 2/10, step 330/574 completed (loss: 0.3738384246826172, acc: 0.9375)
[2024-11-29 03:01:02,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:02,621][root][INFO] - Training Epoch: 2/10, step 331/574 completed (loss: 1.2837293148040771, acc: 0.6451612710952759)
[2024-11-29 03:01:02,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:02,885][root][INFO] - Training Epoch: 2/10, step 332/574 completed (loss: 0.889025866985321, acc: 0.7368420958518982)
[2024-11-29 03:01:02,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:03,128][root][INFO] - Training Epoch: 2/10, step 333/574 completed (loss: 1.1989609003067017, acc: 0.6875)
[2024-11-29 03:01:03,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:03,392][root][INFO] - Training Epoch: 2/10, step 334/574 completed (loss: 0.46213823556900024, acc: 0.9333333373069763)
[2024-11-29 03:01:03,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:03,651][root][INFO] - Training Epoch: 2/10, step 335/574 completed (loss: 1.1368216276168823, acc: 0.6315789222717285)
[2024-11-29 03:01:03,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:03,905][root][INFO] - Training Epoch: 2/10, step 336/574 completed (loss: 1.8172736167907715, acc: 0.5400000214576721)
[2024-11-29 03:01:04,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:04,168][root][INFO] - Training Epoch: 2/10, step 337/574 completed (loss: 2.3615691661834717, acc: 0.4252873659133911)
[2024-11-29 03:01:04,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:04,421][root][INFO] - Training Epoch: 2/10, step 338/574 completed (loss: 2.3955934047698975, acc: 0.43617022037506104)
[2024-11-29 03:01:04,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:04,649][root][INFO] - Training Epoch: 2/10, step 339/574 completed (loss: 2.2884373664855957, acc: 0.4457831382751465)
[2024-11-29 03:01:04,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:04,864][root][INFO] - Training Epoch: 2/10, step 340/574 completed (loss: 0.6344375014305115, acc: 0.739130437374115)
[2024-11-29 03:01:04,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:05,088][root][INFO] - Training Epoch: 2/10, step 341/574 completed (loss: 1.7167834043502808, acc: 0.692307710647583)
[2024-11-29 03:01:05,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:05,324][root][INFO] - Training Epoch: 2/10, step 342/574 completed (loss: 1.713142991065979, acc: 0.6024096608161926)
[2024-11-29 03:01:05,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:05,598][root][INFO] - Training Epoch: 2/10, step 343/574 completed (loss: 1.8012813329696655, acc: 0.5471698045730591)
[2024-11-29 03:01:05,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:05,832][root][INFO] - Training Epoch: 2/10, step 344/574 completed (loss: 1.350512146949768, acc: 0.6835442781448364)
[2024-11-29 03:01:05,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:06,079][root][INFO] - Training Epoch: 2/10, step 345/574 completed (loss: 0.934777557849884, acc: 0.7254902124404907)
[2024-11-29 03:01:06,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:06,311][root][INFO] - Training Epoch: 2/10, step 346/574 completed (loss: 1.934970498085022, acc: 0.5820895433425903)
[2024-11-29 03:01:06,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:06,585][root][INFO] - Training Epoch: 2/10, step 347/574 completed (loss: 0.83006352186203, acc: 0.8500000238418579)
[2024-11-29 03:01:06,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:06,827][root][INFO] - Training Epoch: 2/10, step 348/574 completed (loss: 0.7841739058494568, acc: 0.8799999952316284)
[2024-11-29 03:01:06,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:07,132][root][INFO] - Training Epoch: 2/10, step 349/574 completed (loss: 1.4371825456619263, acc: 0.7777777910232544)
[2024-11-29 03:01:07,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:07,392][root][INFO] - Training Epoch: 2/10, step 350/574 completed (loss: 1.6483579874038696, acc: 0.6279069781303406)
[2024-11-29 03:01:07,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:07,639][root][INFO] - Training Epoch: 2/10, step 351/574 completed (loss: 1.3164091110229492, acc: 0.6666666865348816)
[2024-11-29 03:01:07,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:07,912][root][INFO] - Training Epoch: 2/10, step 352/574 completed (loss: 2.648695468902588, acc: 0.31111112236976624)
[2024-11-29 03:01:07,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:08,122][root][INFO] - Training Epoch: 2/10, step 353/574 completed (loss: 0.6022060513496399, acc: 0.8260869383811951)
[2024-11-29 03:01:08,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:08,327][root][INFO] - Training Epoch: 2/10, step 354/574 completed (loss: 1.8073970079421997, acc: 0.38461539149284363)
[2024-11-29 03:01:08,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:08,585][root][INFO] - Training Epoch: 2/10, step 355/574 completed (loss: 2.4009101390838623, acc: 0.4175824224948883)
[2024-11-29 03:01:08,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:09,019][root][INFO] - Training Epoch: 2/10, step 356/574 completed (loss: 1.928581953048706, acc: 0.530434787273407)
[2024-11-29 03:01:09,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:09,290][root][INFO] - Training Epoch: 2/10, step 357/574 completed (loss: 1.6943050622940063, acc: 0.5652173757553101)
[2024-11-29 03:01:09,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:09,550][root][INFO] - Training Epoch: 2/10, step 358/574 completed (loss: 1.5982112884521484, acc: 0.5102040767669678)
[2024-11-29 03:01:09,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:09,776][root][INFO] - Training Epoch: 2/10, step 359/574 completed (loss: 0.22075484693050385, acc: 0.9583333134651184)
[2024-11-29 03:01:09,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:10,003][root][INFO] - Training Epoch: 2/10, step 360/574 completed (loss: 1.1142934560775757, acc: 0.7307692170143127)
[2024-11-29 03:01:10,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:10,237][root][INFO] - Training Epoch: 2/10, step 361/574 completed (loss: 1.8764376640319824, acc: 0.5121951103210449)
[2024-11-29 03:01:10,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:10,490][root][INFO] - Training Epoch: 2/10, step 362/574 completed (loss: 1.0917925834655762, acc: 0.7333333492279053)
[2024-11-29 03:01:10,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:10,750][root][INFO] - Training Epoch: 2/10, step 363/574 completed (loss: 1.415035367012024, acc: 0.6710526347160339)
[2024-11-29 03:01:10,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:10,991][root][INFO] - Training Epoch: 2/10, step 364/574 completed (loss: 1.6348415613174438, acc: 0.6097561120986938)
[2024-11-29 03:01:11,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:11,265][root][INFO] - Training Epoch: 2/10, step 365/574 completed (loss: 0.8175693154335022, acc: 0.7575757503509521)
[2024-11-29 03:01:11,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:11,527][root][INFO] - Training Epoch: 2/10, step 366/574 completed (loss: 0.15244121849536896, acc: 1.0)
[2024-11-29 03:01:11,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:11,763][root][INFO] - Training Epoch: 2/10, step 367/574 completed (loss: 0.5776633024215698, acc: 0.782608687877655)
[2024-11-29 03:01:11,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:11,980][root][INFO] - Training Epoch: 2/10, step 368/574 completed (loss: 0.999913215637207, acc: 0.7142857313156128)
[2024-11-29 03:01:12,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:12,249][root][INFO] - Training Epoch: 2/10, step 369/574 completed (loss: 1.6526353359222412, acc: 0.625)
[2024-11-29 03:01:12,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:12,785][root][INFO] - Training Epoch: 2/10, step 370/574 completed (loss: 2.3318872451782227, acc: 0.4545454680919647)
[2024-11-29 03:01:13,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:13,595][root][INFO] - Training Epoch: 2/10, step 371/574 completed (loss: 1.423596978187561, acc: 0.6415094137191772)
[2024-11-29 03:01:13,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:13,803][root][INFO] - Training Epoch: 2/10, step 372/574 completed (loss: 1.5567574501037598, acc: 0.6222222447395325)
[2024-11-29 03:01:13,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:14,016][root][INFO] - Training Epoch: 2/10, step 373/574 completed (loss: 0.8496953248977661, acc: 0.7857142686843872)
[2024-11-29 03:01:14,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:14,225][root][INFO] - Training Epoch: 2/10, step 374/574 completed (loss: 0.9983848333358765, acc: 0.7714285850524902)
[2024-11-29 03:01:14,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:14,485][root][INFO] - Training Epoch: 2/10, step 375/574 completed (loss: 0.20094597339630127, acc: 0.9599999785423279)
[2024-11-29 03:01:14,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:14,782][root][INFO] - Training Epoch: 2/10, step 376/574 completed (loss: 0.7728754878044128, acc: 0.782608687877655)
[2024-11-29 03:01:14,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:15,026][root][INFO] - Training Epoch: 2/10, step 377/574 completed (loss: 0.974297821521759, acc: 0.75)
[2024-11-29 03:01:15,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:15,260][root][INFO] - Training Epoch: 2/10, step 378/574 completed (loss: 0.6384680271148682, acc: 0.8631578683853149)
[2024-11-29 03:01:15,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:15,766][root][INFO] - Training Epoch: 2/10, step 379/574 completed (loss: 1.2148889303207397, acc: 0.688622772693634)
[2024-11-29 03:01:15,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:16,093][root][INFO] - Training Epoch: 2/10, step 380/574 completed (loss: 1.266413927078247, acc: 0.6766917109489441)
[2024-11-29 03:01:16,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:17,298][root][INFO] - Training Epoch: 2/10, step 381/574 completed (loss: 1.5807682275772095, acc: 0.6096256971359253)
[2024-11-29 03:01:17,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:17,776][root][INFO] - Training Epoch: 2/10, step 382/574 completed (loss: 0.8169044256210327, acc: 0.7837837934494019)
[2024-11-29 03:01:17,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:17,951][root][INFO] - Training Epoch: 2/10, step 383/574 completed (loss: 0.9651016592979431, acc: 0.7142857313156128)
[2024-11-29 03:01:18,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:18,185][root][INFO] - Training Epoch: 2/10, step 384/574 completed (loss: 0.4119042456150055, acc: 0.8928571343421936)
[2024-11-29 03:01:18,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:18,451][root][INFO] - Training Epoch: 2/10, step 385/574 completed (loss: 0.6960307955741882, acc: 0.84375)
[2024-11-29 03:01:18,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:18,706][root][INFO] - Training Epoch: 2/10, step 386/574 completed (loss: 0.4828835725784302, acc: 0.8611111044883728)
[2024-11-29 03:01:18,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:18,962][root][INFO] - Training Epoch: 2/10, step 387/574 completed (loss: 0.3436358571052551, acc: 0.9210526347160339)
[2024-11-29 03:01:19,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:19,209][root][INFO] - Training Epoch: 2/10, step 388/574 completed (loss: 0.3120220899581909, acc: 0.8636363744735718)
[2024-11-29 03:01:19,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:19,484][root][INFO] - Training Epoch: 2/10, step 389/574 completed (loss: 0.352804571390152, acc: 0.8999999761581421)
[2024-11-29 03:01:19,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:19,712][root][INFO] - Training Epoch: 2/10, step 390/574 completed (loss: 1.1848312616348267, acc: 0.6666666865348816)
[2024-11-29 03:01:19,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:19,925][root][INFO] - Training Epoch: 2/10, step 391/574 completed (loss: 1.940232276916504, acc: 0.5925925970077515)
[2024-11-29 03:01:20,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:20,178][root][INFO] - Training Epoch: 2/10, step 392/574 completed (loss: 2.174360513687134, acc: 0.4660194218158722)
[2024-11-29 03:01:20,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:20,642][root][INFO] - Training Epoch: 2/10, step 393/574 completed (loss: 1.8916053771972656, acc: 0.5514705777168274)
[2024-11-29 03:01:20,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:20,924][root][INFO] - Training Epoch: 2/10, step 394/574 completed (loss: 2.2358474731445312, acc: 0.4866666793823242)
[2024-11-29 03:01:21,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:21,216][root][INFO] - Training Epoch: 2/10, step 395/574 completed (loss: 1.72645902633667, acc: 0.5694444179534912)
[2024-11-29 03:01:21,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:21,424][root][INFO] - Training Epoch: 2/10, step 396/574 completed (loss: 1.3101575374603271, acc: 0.7209302186965942)
[2024-11-29 03:01:21,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:21,720][root][INFO] - Training Epoch: 2/10, step 397/574 completed (loss: 0.3065798282623291, acc: 0.9583333134651184)
[2024-11-29 03:01:21,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:22,003][root][INFO] - Training Epoch: 2/10, step 398/574 completed (loss: 1.189942717552185, acc: 0.7209302186965942)
[2024-11-29 03:01:22,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:22,255][root][INFO] - Training Epoch: 2/10, step 399/574 completed (loss: 0.39078930020332336, acc: 0.8399999737739563)
[2024-11-29 03:01:22,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:22,710][root][INFO] - Training Epoch: 2/10, step 400/574 completed (loss: 1.4547648429870605, acc: 0.6029411554336548)
[2024-11-29 03:01:22,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:22,947][root][INFO] - Training Epoch: 2/10, step 401/574 completed (loss: 1.0597710609436035, acc: 0.746666669845581)
[2024-11-29 03:01:23,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:23,187][root][INFO] - Training Epoch: 2/10, step 402/574 completed (loss: 1.521020531654358, acc: 0.6363636255264282)
[2024-11-29 03:01:23,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:23,425][root][INFO] - Training Epoch: 2/10, step 403/574 completed (loss: 1.1904401779174805, acc: 0.6363636255264282)
[2024-11-29 03:01:23,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:23,682][root][INFO] - Training Epoch: 2/10, step 404/574 completed (loss: 1.7362042665481567, acc: 0.5806451439857483)
[2024-11-29 03:01:23,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:23,930][root][INFO] - Training Epoch: 2/10, step 405/574 completed (loss: 0.9474186897277832, acc: 0.7777777910232544)
[2024-11-29 03:01:24,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:24,152][root][INFO] - Training Epoch: 2/10, step 406/574 completed (loss: 0.5673911571502686, acc: 0.8799999952316284)
[2024-11-29 03:01:24,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:24,409][root][INFO] - Training Epoch: 2/10, step 407/574 completed (loss: 0.6782163381576538, acc: 0.8333333134651184)
[2024-11-29 03:01:24,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:24,650][root][INFO] - Training Epoch: 2/10, step 408/574 completed (loss: 0.5479881763458252, acc: 0.8888888955116272)
[2024-11-29 03:01:24,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:24,917][root][INFO] - Training Epoch: 2/10, step 409/574 completed (loss: 0.3776836097240448, acc: 0.8846153616905212)
[2024-11-29 03:01:25,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:25,162][root][INFO] - Training Epoch: 2/10, step 410/574 completed (loss: 1.1295900344848633, acc: 0.7758620977401733)
[2024-11-29 03:01:25,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:25,414][root][INFO] - Training Epoch: 2/10, step 411/574 completed (loss: 1.3374216556549072, acc: 0.7142857313156128)
[2024-11-29 03:01:25,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:25,676][root][INFO] - Training Epoch: 2/10, step 412/574 completed (loss: 0.8472501635551453, acc: 0.7333333492279053)
[2024-11-29 03:01:25,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:25,933][root][INFO] - Training Epoch: 2/10, step 413/574 completed (loss: 1.219961166381836, acc: 0.6969696879386902)
[2024-11-29 03:01:26,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:26,196][root][INFO] - Training Epoch: 2/10, step 414/574 completed (loss: 0.6558492183685303, acc: 0.7727272510528564)
[2024-11-29 03:01:26,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:26,438][root][INFO] - Training Epoch: 2/10, step 415/574 completed (loss: 1.2293007373809814, acc: 0.6274510025978088)
[2024-11-29 03:01:26,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:26,690][root][INFO] - Training Epoch: 2/10, step 416/574 completed (loss: 0.2676859200000763, acc: 0.9615384340286255)
[2024-11-29 03:01:26,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:26,933][root][INFO] - Training Epoch: 2/10, step 417/574 completed (loss: 0.5788418650627136, acc: 0.7222222089767456)
[2024-11-29 03:01:27,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:27,191][root][INFO] - Training Epoch: 2/10, step 418/574 completed (loss: 1.0875874757766724, acc: 0.7749999761581421)
[2024-11-29 03:01:27,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:27,444][root][INFO] - Training Epoch: 2/10, step 419/574 completed (loss: 0.845110297203064, acc: 0.75)
[2024-11-29 03:01:27,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:27,694][root][INFO] - Training Epoch: 2/10, step 420/574 completed (loss: 1.1387900114059448, acc: 0.6190476417541504)
[2024-11-29 03:01:27,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:27,942][root][INFO] - Training Epoch: 2/10, step 421/574 completed (loss: 1.1952154636383057, acc: 0.6666666865348816)
[2024-11-29 03:01:28,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:28,182][root][INFO] - Training Epoch: 2/10, step 422/574 completed (loss: 1.971049427986145, acc: 0.53125)
[2024-11-29 03:01:28,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:28,447][root][INFO] - Training Epoch: 2/10, step 423/574 completed (loss: 1.3740402460098267, acc: 0.6111111044883728)
[2024-11-29 03:01:28,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:28,695][root][INFO] - Training Epoch: 2/10, step 424/574 completed (loss: 1.412506341934204, acc: 0.7037037014961243)
[2024-11-29 03:01:28,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:28,930][root][INFO] - Training Epoch: 2/10, step 425/574 completed (loss: 0.6586124300956726, acc: 0.7575757503509521)
[2024-11-29 03:01:29,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:29,210][root][INFO] - Training Epoch: 2/10, step 426/574 completed (loss: 0.6875703930854797, acc: 0.782608687877655)
[2024-11-29 03:01:29,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:30,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:30,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:30,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:31,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:31,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:31,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:31,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:32,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:32,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:32,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:33,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:33,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:33,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:33,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:34,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:34,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:34,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:35,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:35,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:35,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:35,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:36,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:36,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:36,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:37,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:37,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:37,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:37,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:37,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:38,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:38,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:38,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:38,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:39,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:39,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:39,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:40,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:40,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:40,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:40,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:41,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:41,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:41,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:42,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:42,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:42,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:43,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:43,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:43,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:44,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:44,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:44,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:44,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:44,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:45,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:45,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:45,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:45,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:46,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:46,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:46,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:47,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:47,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:47,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:47,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:48,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:48,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:48,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:49,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:49,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:49,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:49,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:50,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:50,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:50,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:50,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:51,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:51,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:51,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:52,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:52,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:52,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:52,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:53,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:53,731][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(4.3410, device='cuda:0') eval_epoch_loss=tensor(1.4681, device='cuda:0') eval_epoch_acc=tensor(0.6258, device='cuda:0')
[2024-11-29 03:01:53,732][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:01:53,733][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:01:53,978][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_2_step_427_loss_1.4681036472320557/model.pt
[2024-11-29 03:01:53,981][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 1.4681036472320557
[2024-11-29 03:01:53,981][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.6258408427238464
[2024-11-29 03:01:54,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:54,163][root][INFO] - Training Epoch: 2/10, step 427/574 completed (loss: 0.972629964351654, acc: 0.7027027010917664)
[2024-11-29 03:01:54,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:54,400][root][INFO] - Training Epoch: 2/10, step 428/574 completed (loss: 1.0215376615524292, acc: 0.7037037014961243)
[2024-11-29 03:01:54,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:54,624][root][INFO] - Training Epoch: 2/10, step 429/574 completed (loss: 0.3706269860267639, acc: 0.95652174949646)
[2024-11-29 03:01:54,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:54,880][root][INFO] - Training Epoch: 2/10, step 430/574 completed (loss: 0.5866727232933044, acc: 0.8148148059844971)
[2024-11-29 03:01:54,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:55,087][root][INFO] - Training Epoch: 2/10, step 431/574 completed (loss: 0.6290538311004639, acc: 0.8888888955116272)
[2024-11-29 03:01:55,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:55,303][root][INFO] - Training Epoch: 2/10, step 432/574 completed (loss: 0.5514844655990601, acc: 0.8695651888847351)
[2024-11-29 03:01:55,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:55,547][root][INFO] - Training Epoch: 2/10, step 433/574 completed (loss: 0.9565289616584778, acc: 0.7222222089767456)
[2024-11-29 03:01:55,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:55,756][root][INFO] - Training Epoch: 2/10, step 434/574 completed (loss: 0.12117698043584824, acc: 0.9599999785423279)
[2024-11-29 03:01:55,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:55,988][root][INFO] - Training Epoch: 2/10, step 435/574 completed (loss: 0.2468452751636505, acc: 0.9090909361839294)
[2024-11-29 03:01:56,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:56,248][root][INFO] - Training Epoch: 2/10, step 436/574 completed (loss: 1.2299667596817017, acc: 0.6666666865348816)
[2024-11-29 03:01:56,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:56,470][root][INFO] - Training Epoch: 2/10, step 437/574 completed (loss: 1.058413028717041, acc: 0.7727272510528564)
[2024-11-29 03:01:56,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:56,695][root][INFO] - Training Epoch: 2/10, step 438/574 completed (loss: 0.25366678833961487, acc: 0.9523809552192688)
[2024-11-29 03:01:56,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:56,940][root][INFO] - Training Epoch: 2/10, step 439/574 completed (loss: 0.8981022238731384, acc: 0.7179487347602844)
[2024-11-29 03:01:57,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:57,320][root][INFO] - Training Epoch: 2/10, step 440/574 completed (loss: 1.2997009754180908, acc: 0.7121211886405945)
[2024-11-29 03:01:57,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:57,956][root][INFO] - Training Epoch: 2/10, step 441/574 completed (loss: 2.244277238845825, acc: 0.4480000138282776)
[2024-11-29 03:01:58,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:58,260][root][INFO] - Training Epoch: 2/10, step 442/574 completed (loss: 2.035489082336426, acc: 0.4677419364452362)
[2024-11-29 03:01:58,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:58,817][root][INFO] - Training Epoch: 2/10, step 443/574 completed (loss: 1.9942266941070557, acc: 0.5124378204345703)
[2024-11-29 03:01:58,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:59,002][root][INFO] - Training Epoch: 2/10, step 444/574 completed (loss: 1.254087209701538, acc: 0.6792452931404114)
[2024-11-29 03:01:59,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:59,322][root][INFO] - Training Epoch: 2/10, step 445/574 completed (loss: 1.0569453239440918, acc: 0.6818181872367859)
[2024-11-29 03:01:59,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:59,519][root][INFO] - Training Epoch: 2/10, step 446/574 completed (loss: 0.8040024042129517, acc: 0.782608687877655)
[2024-11-29 03:01:59,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:59,738][root][INFO] - Training Epoch: 2/10, step 447/574 completed (loss: 0.9567314386367798, acc: 0.807692289352417)
[2024-11-29 03:01:59,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:59,964][root][INFO] - Training Epoch: 2/10, step 448/574 completed (loss: 0.5416502952575684, acc: 0.8571428656578064)
[2024-11-29 03:02:00,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:00,195][root][INFO] - Training Epoch: 2/10, step 449/574 completed (loss: 1.0618354082107544, acc: 0.7313432693481445)
[2024-11-29 03:02:00,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:00,432][root][INFO] - Training Epoch: 2/10, step 450/574 completed (loss: 0.8401598334312439, acc: 0.8472222089767456)
[2024-11-29 03:02:00,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:00,656][root][INFO] - Training Epoch: 2/10, step 451/574 completed (loss: 0.788804829120636, acc: 0.739130437374115)
[2024-11-29 03:02:00,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:00,885][root][INFO] - Training Epoch: 2/10, step 452/574 completed (loss: 1.0515198707580566, acc: 0.6794871687889099)
[2024-11-29 03:02:00,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:01,104][root][INFO] - Training Epoch: 2/10, step 453/574 completed (loss: 0.9018462300300598, acc: 0.7236841917037964)
[2024-11-29 03:02:01,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:01,328][root][INFO] - Training Epoch: 2/10, step 454/574 completed (loss: 1.2520043849945068, acc: 0.6734693646430969)
[2024-11-29 03:02:01,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:01,563][root][INFO] - Training Epoch: 2/10, step 455/574 completed (loss: 0.9144891500473022, acc: 0.7272727489471436)
[2024-11-29 03:02:01,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:01,805][root][INFO] - Training Epoch: 2/10, step 456/574 completed (loss: 1.7100781202316284, acc: 0.6185566782951355)
[2024-11-29 03:02:01,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:02,052][root][INFO] - Training Epoch: 2/10, step 457/574 completed (loss: 1.3111414909362793, acc: 0.699999988079071)
[2024-11-29 03:02:02,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:02,340][root][INFO] - Training Epoch: 2/10, step 458/574 completed (loss: 1.8423181772232056, acc: 0.5232558250427246)
[2024-11-29 03:02:02,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:02,534][root][INFO] - Training Epoch: 2/10, step 459/574 completed (loss: 1.1612104177474976, acc: 0.6428571343421936)
[2024-11-29 03:02:02,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:02,752][root][INFO] - Training Epoch: 2/10, step 460/574 completed (loss: 1.6443361043930054, acc: 0.5802469253540039)
[2024-11-29 03:02:02,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:02,946][root][INFO] - Training Epoch: 2/10, step 461/574 completed (loss: 1.22978937625885, acc: 0.7222222089767456)
[2024-11-29 03:02:03,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:03,173][root][INFO] - Training Epoch: 2/10, step 462/574 completed (loss: 1.1915361881256104, acc: 0.65625)
[2024-11-29 03:02:03,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:03,414][root][INFO] - Training Epoch: 2/10, step 463/574 completed (loss: 0.7639473676681519, acc: 0.8461538553237915)
[2024-11-29 03:02:03,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:03,638][root][INFO] - Training Epoch: 2/10, step 464/574 completed (loss: 0.8823901414871216, acc: 0.782608687877655)
[2024-11-29 03:02:03,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:03,879][root][INFO] - Training Epoch: 2/10, step 465/574 completed (loss: 1.287983775138855, acc: 0.7142857313156128)
[2024-11-29 03:02:03,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:04,096][root][INFO] - Training Epoch: 2/10, step 466/574 completed (loss: 1.8548493385314941, acc: 0.5180723071098328)
[2024-11-29 03:02:04,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:04,340][root][INFO] - Training Epoch: 2/10, step 467/574 completed (loss: 1.7073967456817627, acc: 0.5945945978164673)
[2024-11-29 03:02:04,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:04,565][root][INFO] - Training Epoch: 2/10, step 468/574 completed (loss: 1.9885743856430054, acc: 0.5436893105506897)
[2024-11-29 03:02:04,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:04,794][root][INFO] - Training Epoch: 2/10, step 469/574 completed (loss: 2.0025827884674072, acc: 0.4878048896789551)
[2024-11-29 03:02:04,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:05,014][root][INFO] - Training Epoch: 2/10, step 470/574 completed (loss: 1.0560212135314941, acc: 0.75)
[2024-11-29 03:02:05,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:05,241][root][INFO] - Training Epoch: 2/10, step 471/574 completed (loss: 1.30069899559021, acc: 0.6428571343421936)
[2024-11-29 03:02:05,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:05,562][root][INFO] - Training Epoch: 2/10, step 472/574 completed (loss: 1.6883597373962402, acc: 0.5)
[2024-11-29 03:02:05,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:05,818][root][INFO] - Training Epoch: 2/10, step 473/574 completed (loss: 1.8863433599472046, acc: 0.4890829622745514)
[2024-11-29 03:02:05,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:06,017][root][INFO] - Training Epoch: 2/10, step 474/574 completed (loss: 1.699435830116272, acc: 0.6041666865348816)
[2024-11-29 03:02:06,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:06,244][root][INFO] - Training Epoch: 2/10, step 475/574 completed (loss: 1.335823893547058, acc: 0.6625766754150391)
[2024-11-29 03:02:06,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:06,479][root][INFO] - Training Epoch: 2/10, step 476/574 completed (loss: 1.2974286079406738, acc: 0.6978417038917542)
[2024-11-29 03:02:06,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:06,743][root][INFO] - Training Epoch: 2/10, step 477/574 completed (loss: 1.7608927488327026, acc: 0.572864294052124)
[2024-11-29 03:02:06,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:06,990][root][INFO] - Training Epoch: 2/10, step 478/574 completed (loss: 1.775211215019226, acc: 0.5833333134651184)
[2024-11-29 03:02:07,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:07,251][root][INFO] - Training Epoch: 2/10, step 479/574 completed (loss: 1.345066785812378, acc: 0.6666666865348816)
[2024-11-29 03:02:07,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:07,490][root][INFO] - Training Epoch: 2/10, step 480/574 completed (loss: 1.002478003501892, acc: 0.7407407164573669)
[2024-11-29 03:02:07,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:07,728][root][INFO] - Training Epoch: 2/10, step 481/574 completed (loss: 2.20408034324646, acc: 0.550000011920929)
[2024-11-29 03:02:07,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:07,939][root][INFO] - Training Epoch: 2/10, step 482/574 completed (loss: 2.056251287460327, acc: 0.6000000238418579)
[2024-11-29 03:02:08,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:08,234][root][INFO] - Training Epoch: 2/10, step 483/574 completed (loss: 1.8977038860321045, acc: 0.5)
[2024-11-29 03:02:08,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:08,443][root][INFO] - Training Epoch: 2/10, step 484/574 completed (loss: 0.6309154629707336, acc: 0.8064516186714172)
[2024-11-29 03:02:08,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:08,639][root][INFO] - Training Epoch: 2/10, step 485/574 completed (loss: 1.036851406097412, acc: 0.6842105388641357)
[2024-11-29 03:02:08,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:08,860][root][INFO] - Training Epoch: 2/10, step 486/574 completed (loss: 2.365501880645752, acc: 0.37037035822868347)
[2024-11-29 03:02:08,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:09,073][root][INFO] - Training Epoch: 2/10, step 487/574 completed (loss: 1.4597899913787842, acc: 0.5714285969734192)
[2024-11-29 03:02:09,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:09,314][root][INFO] - Training Epoch: 2/10, step 488/574 completed (loss: 1.947960615158081, acc: 0.5909090638160706)
[2024-11-29 03:02:09,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:09,565][root][INFO] - Training Epoch: 2/10, step 489/574 completed (loss: 1.97223961353302, acc: 0.5230769515037537)
[2024-11-29 03:02:09,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:09,776][root][INFO] - Training Epoch: 2/10, step 490/574 completed (loss: 0.8785508871078491, acc: 0.7333333492279053)
[2024-11-29 03:02:09,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:09,980][root][INFO] - Training Epoch: 2/10, step 491/574 completed (loss: 1.335528016090393, acc: 0.6896551847457886)
[2024-11-29 03:02:10,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:10,218][root][INFO] - Training Epoch: 2/10, step 492/574 completed (loss: 1.188430905342102, acc: 0.7058823704719543)
[2024-11-29 03:02:10,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:10,461][root][INFO] - Training Epoch: 2/10, step 493/574 completed (loss: 1.1194754838943481, acc: 0.7931034564971924)
[2024-11-29 03:02:10,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:10,682][root][INFO] - Training Epoch: 2/10, step 494/574 completed (loss: 1.075342059135437, acc: 0.7894737124443054)
[2024-11-29 03:02:10,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:10,905][root][INFO] - Training Epoch: 2/10, step 495/574 completed (loss: 1.6701544523239136, acc: 0.5263158082962036)
[2024-11-29 03:02:11,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:11,158][root][INFO] - Training Epoch: 2/10, step 496/574 completed (loss: 1.6163307428359985, acc: 0.5803571343421936)
[2024-11-29 03:02:11,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:11,433][root][INFO] - Training Epoch: 2/10, step 497/574 completed (loss: 1.2587676048278809, acc: 0.6516854166984558)
[2024-11-29 03:02:11,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:11,650][root][INFO] - Training Epoch: 2/10, step 498/574 completed (loss: 1.4879788160324097, acc: 0.5617977380752563)
[2024-11-29 03:02:11,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:11,887][root][INFO] - Training Epoch: 2/10, step 499/574 completed (loss: 1.999169111251831, acc: 0.4822694957256317)
[2024-11-29 03:02:11,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:12,128][root][INFO] - Training Epoch: 2/10, step 500/574 completed (loss: 1.7923893928527832, acc: 0.5760869383811951)
[2024-11-29 03:02:12,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:12,368][root][INFO] - Training Epoch: 2/10, step 501/574 completed (loss: 0.37640807032585144, acc: 0.9200000166893005)
[2024-11-29 03:02:12,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:12,607][root][INFO] - Training Epoch: 2/10, step 502/574 completed (loss: 0.34969550371170044, acc: 0.9615384340286255)
[2024-11-29 03:02:12,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:12,848][root][INFO] - Training Epoch: 2/10, step 503/574 completed (loss: 1.0412689447402954, acc: 0.8148148059844971)
[2024-11-29 03:02:12,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:13,085][root][INFO] - Training Epoch: 2/10, step 504/574 completed (loss: 0.8574947118759155, acc: 0.7407407164573669)
[2024-11-29 03:02:13,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:13,314][root][INFO] - Training Epoch: 2/10, step 505/574 completed (loss: 1.3837758302688599, acc: 0.6792452931404114)
[2024-11-29 03:02:13,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:13,552][root][INFO] - Training Epoch: 2/10, step 506/574 completed (loss: 1.7711436748504639, acc: 0.5862069129943848)
[2024-11-29 03:02:13,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:14,072][root][INFO] - Training Epoch: 2/10, step 507/574 completed (loss: 1.9751871824264526, acc: 0.5315315127372742)
[2024-11-29 03:02:14,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:14,415][root][INFO] - Training Epoch: 2/10, step 508/574 completed (loss: 1.6000959873199463, acc: 0.591549277305603)
[2024-11-29 03:02:14,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:14,601][root][INFO] - Training Epoch: 2/10, step 509/574 completed (loss: 0.5672391653060913, acc: 0.8500000238418579)
[2024-11-29 03:02:14,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:14,801][root][INFO] - Training Epoch: 2/10, step 510/574 completed (loss: 0.5401484966278076, acc: 0.8333333134651184)
[2024-11-29 03:02:14,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:15,017][root][INFO] - Training Epoch: 2/10, step 511/574 completed (loss: 0.9143915772438049, acc: 0.7692307829856873)
[2024-11-29 03:02:16,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:17,625][root][INFO] - Training Epoch: 2/10, step 512/574 completed (loss: 2.393315076828003, acc: 0.44285714626312256)
[2024-11-29 03:02:17,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:18,287][root][INFO] - Training Epoch: 2/10, step 513/574 completed (loss: 1.3993809223175049, acc: 0.6746031641960144)
[2024-11-29 03:02:18,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:18,552][root][INFO] - Training Epoch: 2/10, step 514/574 completed (loss: 1.4410086870193481, acc: 0.75)
[2024-11-29 03:02:18,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:18,761][root][INFO] - Training Epoch: 2/10, step 515/574 completed (loss: 0.5644204616546631, acc: 0.8166666626930237)
[2024-11-29 03:02:18,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:19,353][root][INFO] - Training Epoch: 2/10, step 516/574 completed (loss: 1.3805031776428223, acc: 0.6388888955116272)
[2024-11-29 03:02:19,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:19,618][root][INFO] - Training Epoch: 2/10, step 517/574 completed (loss: 0.23985235393047333, acc: 0.9615384340286255)
[2024-11-29 03:02:19,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:19,869][root][INFO] - Training Epoch: 2/10, step 518/574 completed (loss: 1.4349063634872437, acc: 0.5806451439857483)
[2024-11-29 03:02:19,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:20,075][root][INFO] - Training Epoch: 2/10, step 519/574 completed (loss: 1.0667250156402588, acc: 0.699999988079071)
[2024-11-29 03:02:20,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:20,296][root][INFO] - Training Epoch: 2/10, step 520/574 completed (loss: 1.2492419481277466, acc: 0.6666666865348816)
[2024-11-29 03:02:20,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:21,190][root][INFO] - Training Epoch: 2/10, step 521/574 completed (loss: 1.9278901815414429, acc: 0.5042372941970825)
[2024-11-29 03:02:21,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:21,440][root][INFO] - Training Epoch: 2/10, step 522/574 completed (loss: 1.1351909637451172, acc: 0.6791045069694519)
[2024-11-29 03:02:21,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:21,697][root][INFO] - Training Epoch: 2/10, step 523/574 completed (loss: 1.271350622177124, acc: 0.6788321137428284)
[2024-11-29 03:02:21,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:22,164][root][INFO] - Training Epoch: 2/10, step 524/574 completed (loss: 1.5052980184555054, acc: 0.6299999952316284)
[2024-11-29 03:02:22,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:22,353][root][INFO] - Training Epoch: 2/10, step 525/574 completed (loss: 0.6971567869186401, acc: 0.8148148059844971)
[2024-11-29 03:02:22,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:22,600][root][INFO] - Training Epoch: 2/10, step 526/574 completed (loss: 0.8085415959358215, acc: 0.7692307829856873)
[2024-11-29 03:02:22,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:22,830][root][INFO] - Training Epoch: 2/10, step 527/574 completed (loss: 0.5556358695030212, acc: 1.0)
[2024-11-29 03:02:22,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:23,038][root][INFO] - Training Epoch: 2/10, step 528/574 completed (loss: 2.6934969425201416, acc: 0.3442623019218445)
[2024-11-29 03:02:23,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:23,275][root][INFO] - Training Epoch: 2/10, step 529/574 completed (loss: 1.0170154571533203, acc: 0.6779661178588867)
[2024-11-29 03:02:23,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:23,522][root][INFO] - Training Epoch: 2/10, step 530/574 completed (loss: 3.038914203643799, acc: 0.3720930218696594)
[2024-11-29 03:02:23,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:23,776][root][INFO] - Training Epoch: 2/10, step 531/574 completed (loss: 2.1532716751098633, acc: 0.5227272510528564)
[2024-11-29 03:02:23,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:23,993][root][INFO] - Training Epoch: 2/10, step 532/574 completed (loss: 2.2110841274261475, acc: 0.5094339847564697)
[2024-11-29 03:02:24,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:24,175][root][INFO] - Training Epoch: 2/10, step 533/574 completed (loss: 1.4453057050704956, acc: 0.5909090638160706)
[2024-11-29 03:02:24,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:24,394][root][INFO] - Training Epoch: 2/10, step 534/574 completed (loss: 1.4337012767791748, acc: 0.6800000071525574)
[2024-11-29 03:02:24,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:24,600][root][INFO] - Training Epoch: 2/10, step 535/574 completed (loss: 0.837875247001648, acc: 0.8500000238418579)
[2024-11-29 03:02:24,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:24,771][root][INFO] - Training Epoch: 2/10, step 536/574 completed (loss: 0.6399074196815491, acc: 0.8181818127632141)
[2024-11-29 03:02:24,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:25,067][root][INFO] - Training Epoch: 2/10, step 537/574 completed (loss: 1.2405874729156494, acc: 0.6769230961799622)
[2024-11-29 03:02:25,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:25,284][root][INFO] - Training Epoch: 2/10, step 538/574 completed (loss: 1.2359826564788818, acc: 0.640625)
[2024-11-29 03:02:25,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:25,572][root][INFO] - Training Epoch: 2/10, step 539/574 completed (loss: 0.9917588233947754, acc: 0.78125)
[2024-11-29 03:02:25,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:25,832][root][INFO] - Training Epoch: 2/10, step 540/574 completed (loss: 1.56766939163208, acc: 0.5757575631141663)
[2024-11-29 03:02:25,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:26,058][root][INFO] - Training Epoch: 2/10, step 541/574 completed (loss: 0.8661932945251465, acc: 0.6875)
[2024-11-29 03:02:26,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:26,297][root][INFO] - Training Epoch: 2/10, step 542/574 completed (loss: 0.6510590314865112, acc: 0.8064516186714172)
[2024-11-29 03:02:26,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:26,513][root][INFO] - Training Epoch: 2/10, step 543/574 completed (loss: 0.3951953053474426, acc: 0.9130434989929199)
[2024-11-29 03:02:26,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:26,738][root][INFO] - Training Epoch: 2/10, step 544/574 completed (loss: 0.6019607782363892, acc: 0.8999999761581421)
[2024-11-29 03:02:26,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:26,999][root][INFO] - Training Epoch: 2/10, step 545/574 completed (loss: 0.35332557559013367, acc: 0.9024389982223511)
[2024-11-29 03:02:27,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:27,250][root][INFO] - Training Epoch: 2/10, step 546/574 completed (loss: 0.37255847454071045, acc: 0.8857142925262451)
[2024-11-29 03:02:27,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:27,500][root][INFO] - Training Epoch: 2/10, step 547/574 completed (loss: 0.9154338836669922, acc: 0.7368420958518982)
[2024-11-29 03:02:27,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:27,720][root][INFO] - Training Epoch: 2/10, step 548/574 completed (loss: 1.0069056749343872, acc: 0.7419354915618896)
[2024-11-29 03:02:27,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:27,926][root][INFO] - Training Epoch: 2/10, step 549/574 completed (loss: 0.4710415005683899, acc: 0.8799999952316284)
[2024-11-29 03:02:28,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:28,141][root][INFO] - Training Epoch: 2/10, step 550/574 completed (loss: 0.9700716137886047, acc: 0.7878788113594055)
[2024-11-29 03:02:28,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:28,374][root][INFO] - Training Epoch: 2/10, step 551/574 completed (loss: 0.7087765336036682, acc: 0.7749999761581421)
[2024-11-29 03:02:28,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:28,599][root][INFO] - Training Epoch: 2/10, step 552/574 completed (loss: 0.8513908386230469, acc: 0.7714285850524902)
[2024-11-29 03:02:28,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:28,867][root][INFO] - Training Epoch: 2/10, step 553/574 completed (loss: 1.3205173015594482, acc: 0.6569343209266663)
[2024-11-29 03:02:28,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:29,094][root][INFO] - Training Epoch: 2/10, step 554/574 completed (loss: 1.4026085138320923, acc: 0.634482741355896)
[2024-11-29 03:02:29,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:29,374][root][INFO] - Training Epoch: 2/10, step 555/574 completed (loss: 1.761733055114746, acc: 0.6142857074737549)
[2024-11-29 03:02:29,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:29,627][root][INFO] - Training Epoch: 2/10, step 556/574 completed (loss: 1.2734671831130981, acc: 0.6688741445541382)
[2024-11-29 03:02:29,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:29,856][root][INFO] - Training Epoch: 2/10, step 557/574 completed (loss: 1.1147555112838745, acc: 0.6666666865348816)
[2024-11-29 03:02:29,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:30,030][root][INFO] - Training Epoch: 2/10, step 558/574 completed (loss: 0.7233565449714661, acc: 0.8399999737739563)
[2024-11-29 03:02:30,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:30,212][root][INFO] - Training Epoch: 2/10, step 559/574 completed (loss: 0.9896707534790039, acc: 0.7692307829856873)
[2024-11-29 03:02:30,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:30,407][root][INFO] - Training Epoch: 2/10, step 560/574 completed (loss: 0.3163546919822693, acc: 0.8846153616905212)
[2024-11-29 03:02:30,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:30,639][root][INFO] - Training Epoch: 2/10, step 561/574 completed (loss: 1.2946799993515015, acc: 0.692307710647583)
[2024-11-29 03:02:30,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:30,882][root][INFO] - Training Epoch: 2/10, step 562/574 completed (loss: 1.2688157558441162, acc: 0.6333333253860474)
[2024-11-29 03:02:30,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:31,126][root][INFO] - Training Epoch: 2/10, step 563/574 completed (loss: 1.3548556566238403, acc: 0.6103895902633667)
[2024-11-29 03:02:31,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:31,409][root][INFO] - Training Epoch: 2/10, step 564/574 completed (loss: 1.1259139776229858, acc: 0.6875)
[2024-11-29 03:02:31,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:31,684][root][INFO] - Training Epoch: 2/10, step 565/574 completed (loss: 1.1494989395141602, acc: 0.7413793206214905)
[2024-11-29 03:02:31,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:31,958][root][INFO] - Training Epoch: 2/10, step 566/574 completed (loss: 1.1316964626312256, acc: 0.7976190447807312)
[2024-11-29 03:02:32,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:32,204][root][INFO] - Training Epoch: 2/10, step 567/574 completed (loss: 0.864221453666687, acc: 0.7105262875556946)
[2024-11-29 03:02:32,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:32,445][root][INFO] - Training Epoch: 2/10, step 568/574 completed (loss: 0.47817349433898926, acc: 0.8888888955116272)
[2024-11-29 03:02:32,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:32,726][root][INFO] - Training Epoch: 2/10, step 569/574 completed (loss: 1.5001046657562256, acc: 0.6577540040016174)
[2024-11-29 03:02:33,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:33,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:34,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:34,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:34,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:34,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:35,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:35,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:35,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:35,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:36,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:36,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:36,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:37,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:37,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:37,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:38,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:38,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:38,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:38,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:39,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:39,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:39,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:39,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:40,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:40,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:40,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:41,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:41,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:41,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:41,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:42,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:42,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:42,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:43,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:43,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:43,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:43,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:44,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:44,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:44,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:45,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:45,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:45,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:45,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:46,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:46,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:46,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:47,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:47,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:47,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:47,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:47,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:48,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:48,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:48,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:49,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:49,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:49,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:50,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:50,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:50,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:51,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:51,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:51,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:51,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:51,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:52,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:52,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:52,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:53,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:53,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:53,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:54,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:54,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:54,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:54,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:55,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:55,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:55,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:55,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:56,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:56,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:56,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:57,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:57,839][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(4.0577, device='cuda:0') eval_epoch_loss=tensor(1.4006, device='cuda:0') eval_epoch_acc=tensor(0.6509, device='cuda:0')
[2024-11-29 03:02:57,840][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:02:57,840][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:02:58,100][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_2_step_570_loss_1.4006229639053345/model.pt
[2024-11-29 03:02:58,105][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 1.4006229639053345
[2024-11-29 03:02:58,105][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.6509397029876709
[2024-11-29 03:02:58,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:58,305][root][INFO] - Training Epoch: 2/10, step 570/574 completed (loss: 0.5193632245063782, acc: 0.8548387289047241)
[2024-11-29 03:02:58,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:58,496][root][INFO] - Training Epoch: 2/10, step 571/574 completed (loss: 1.3392198085784912, acc: 0.6666666865348816)
[2024-11-29 03:02:58,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:58,713][root][INFO] - Training Epoch: 2/10, step 572/574 completed (loss: 1.6698930263519287, acc: 0.5867347121238708)
[2024-11-29 03:02:58,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:58,960][root][INFO] - Training Epoch: 2/10, step 573/574 completed (loss: 1.8732666969299316, acc: 0.5408805012702942)
[2024-11-29 03:02:59,432][slam_llm.utils.train_utils][INFO] - Epoch 2: train_perplexity=4.8732, train_epoch_loss=1.5837, epoch time 266.9820512663573s
[2024-11-29 03:02:59,432][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 11 GB
[2024-11-29 03:02:59,432][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-11-29 03:02:59,432][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 11 GB
[2024-11-29 03:02:59,432][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 4
[2024-11-29 03:02:59,433][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:03:00,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:00,153][root][INFO] - Training Epoch: 3/10, step 0/574 completed (loss: 1.448022484779358, acc: 0.6296296119689941)
[2024-11-29 03:03:00,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:00,352][root][INFO] - Training Epoch: 3/10, step 1/574 completed (loss: 0.8501999378204346, acc: 0.800000011920929)
[2024-11-29 03:03:00,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:00,581][root][INFO] - Training Epoch: 3/10, step 2/574 completed (loss: 1.1053555011749268, acc: 0.7027027010917664)
[2024-11-29 03:03:00,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:00,841][root][INFO] - Training Epoch: 3/10, step 3/574 completed (loss: 1.1906851530075073, acc: 0.7105262875556946)
[2024-11-29 03:03:00,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:01,068][root][INFO] - Training Epoch: 3/10, step 4/574 completed (loss: 1.107544183731079, acc: 0.7567567825317383)
[2024-11-29 03:03:01,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:01,297][root][INFO] - Training Epoch: 3/10, step 5/574 completed (loss: 0.6552692651748657, acc: 0.8214285969734192)
[2024-11-29 03:03:01,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:01,522][root][INFO] - Training Epoch: 3/10, step 6/574 completed (loss: 1.5154447555541992, acc: 0.6326530575752258)
[2024-11-29 03:03:01,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:01,767][root][INFO] - Training Epoch: 3/10, step 7/574 completed (loss: 0.8191298246383667, acc: 0.800000011920929)
[2024-11-29 03:03:01,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:02,023][root][INFO] - Training Epoch: 3/10, step 8/574 completed (loss: 0.6860154271125793, acc: 0.8181818127632141)
[2024-11-29 03:03:02,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:02,249][root][INFO] - Training Epoch: 3/10, step 9/574 completed (loss: 0.6635077595710754, acc: 0.807692289352417)
[2024-11-29 03:03:02,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:02,494][root][INFO] - Training Epoch: 3/10, step 10/574 completed (loss: 0.6816913485527039, acc: 0.8148148059844971)
[2024-11-29 03:03:02,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:02,739][root][INFO] - Training Epoch: 3/10, step 11/574 completed (loss: 1.552868127822876, acc: 0.6666666865348816)
[2024-11-29 03:03:02,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:02,993][root][INFO] - Training Epoch: 3/10, step 12/574 completed (loss: 0.8519922494888306, acc: 0.7575757503509521)
[2024-11-29 03:03:03,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:03,212][root][INFO] - Training Epoch: 3/10, step 13/574 completed (loss: 0.8040860891342163, acc: 0.739130437374115)
[2024-11-29 03:03:03,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:03,458][root][INFO] - Training Epoch: 3/10, step 14/574 completed (loss: 0.8446819186210632, acc: 0.7843137383460999)
[2024-11-29 03:03:03,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:03,692][root][INFO] - Training Epoch: 3/10, step 15/574 completed (loss: 1.0447386503219604, acc: 0.7346938848495483)
[2024-11-29 03:03:03,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:03,932][root][INFO] - Training Epoch: 3/10, step 16/574 completed (loss: 0.3211909830570221, acc: 0.8947368264198303)
[2024-11-29 03:03:04,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:04,152][root][INFO] - Training Epoch: 3/10, step 17/574 completed (loss: 1.1005709171295166, acc: 0.7083333134651184)
[2024-11-29 03:03:04,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:04,373][root][INFO] - Training Epoch: 3/10, step 18/574 completed (loss: 1.9310938119888306, acc: 0.5555555820465088)
[2024-11-29 03:03:04,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:04,597][root][INFO] - Training Epoch: 3/10, step 19/574 completed (loss: 0.7086781859397888, acc: 0.7368420958518982)
[2024-11-29 03:03:04,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:04,837][root][INFO] - Training Epoch: 3/10, step 20/574 completed (loss: 0.9862057566642761, acc: 0.8461538553237915)
[2024-11-29 03:03:04,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:05,093][root][INFO] - Training Epoch: 3/10, step 21/574 completed (loss: 1.01317298412323, acc: 0.8275862336158752)
[2024-11-29 03:03:05,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:05,331][root][INFO] - Training Epoch: 3/10, step 22/574 completed (loss: 0.9245593547821045, acc: 0.7599999904632568)
[2024-11-29 03:03:05,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:05,582][root][INFO] - Training Epoch: 3/10, step 23/574 completed (loss: 0.6846408843994141, acc: 0.8095238208770752)
[2024-11-29 03:03:05,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:05,810][root][INFO] - Training Epoch: 3/10, step 24/574 completed (loss: 0.43082401156425476, acc: 0.875)
[2024-11-29 03:03:05,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:06,038][root][INFO] - Training Epoch: 3/10, step 25/574 completed (loss: 1.6277896165847778, acc: 0.5660377144813538)
[2024-11-29 03:03:06,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:06,277][root][INFO] - Training Epoch: 3/10, step 26/574 completed (loss: 1.4694929122924805, acc: 0.6164383292198181)
[2024-11-29 03:03:06,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:07,514][root][INFO] - Training Epoch: 3/10, step 27/574 completed (loss: 2.415327310562134, acc: 0.4466403126716614)
[2024-11-29 03:03:07,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:07,696][root][INFO] - Training Epoch: 3/10, step 28/574 completed (loss: 1.1961969137191772, acc: 0.6744186282157898)
[2024-11-29 03:03:07,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:07,896][root][INFO] - Training Epoch: 3/10, step 29/574 completed (loss: 1.5064209699630737, acc: 0.5662650465965271)
[2024-11-29 03:03:07,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:08,086][root][INFO] - Training Epoch: 3/10, step 30/574 completed (loss: 1.6569918394088745, acc: 0.5925925970077515)
[2024-11-29 03:03:08,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:08,289][root][INFO] - Training Epoch: 3/10, step 31/574 completed (loss: 1.0221483707427979, acc: 0.7857142686843872)
[2024-11-29 03:03:08,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:08,460][root][INFO] - Training Epoch: 3/10, step 32/574 completed (loss: 0.5334637761116028, acc: 0.8888888955116272)
[2024-11-29 03:03:08,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:08,674][root][INFO] - Training Epoch: 3/10, step 33/574 completed (loss: 0.33310380578041077, acc: 0.8695651888847351)
[2024-11-29 03:03:08,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:08,911][root][INFO] - Training Epoch: 3/10, step 34/574 completed (loss: 1.026146650314331, acc: 0.756302535533905)
[2024-11-29 03:03:09,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:09,143][root][INFO] - Training Epoch: 3/10, step 35/574 completed (loss: 1.0714423656463623, acc: 0.7049180269241333)
[2024-11-29 03:03:09,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:09,374][root][INFO] - Training Epoch: 3/10, step 36/574 completed (loss: 1.0543522834777832, acc: 0.7460317611694336)
[2024-11-29 03:03:09,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:09,616][root][INFO] - Training Epoch: 3/10, step 37/574 completed (loss: 1.1785192489624023, acc: 0.6779661178588867)
[2024-11-29 03:03:09,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:09,867][root][INFO] - Training Epoch: 3/10, step 38/574 completed (loss: 0.8732265830039978, acc: 0.7816091775894165)
[2024-11-29 03:03:09,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:10,084][root][INFO] - Training Epoch: 3/10, step 39/574 completed (loss: 0.863465428352356, acc: 0.8571428656578064)
[2024-11-29 03:03:10,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:10,308][root][INFO] - Training Epoch: 3/10, step 40/574 completed (loss: 0.8899297714233398, acc: 0.692307710647583)
[2024-11-29 03:03:10,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:10,584][root][INFO] - Training Epoch: 3/10, step 41/574 completed (loss: 1.1005728244781494, acc: 0.7297297120094299)
[2024-11-29 03:03:10,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:10,817][root][INFO] - Training Epoch: 3/10, step 42/574 completed (loss: 1.5694258213043213, acc: 0.6153846383094788)
[2024-11-29 03:03:10,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:11,156][root][INFO] - Training Epoch: 3/10, step 43/574 completed (loss: 1.343319058418274, acc: 0.6565656661987305)
[2024-11-29 03:03:11,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:11,458][root][INFO] - Training Epoch: 3/10, step 44/574 completed (loss: 1.212031602859497, acc: 0.7113401889801025)
[2024-11-29 03:03:11,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:11,746][root][INFO] - Training Epoch: 3/10, step 45/574 completed (loss: 1.378154993057251, acc: 0.6838235259056091)
[2024-11-29 03:03:11,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:11,933][root][INFO] - Training Epoch: 3/10, step 46/574 completed (loss: 0.7396179437637329, acc: 0.807692289352417)
[2024-11-29 03:03:12,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:12,148][root][INFO] - Training Epoch: 3/10, step 47/574 completed (loss: 0.4650252163410187, acc: 0.8888888955116272)
[2024-11-29 03:03:12,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:12,399][root][INFO] - Training Epoch: 3/10, step 48/574 completed (loss: 0.5347656607627869, acc: 0.9285714030265808)
[2024-11-29 03:03:12,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:12,620][root][INFO] - Training Epoch: 3/10, step 49/574 completed (loss: 0.5949965715408325, acc: 0.8333333134651184)
[2024-11-29 03:03:12,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:12,862][root][INFO] - Training Epoch: 3/10, step 50/574 completed (loss: 1.3599390983581543, acc: 0.719298243522644)
[2024-11-29 03:03:12,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:13,094][root][INFO] - Training Epoch: 3/10, step 51/574 completed (loss: 1.9011386632919312, acc: 0.523809552192688)
[2024-11-29 03:03:13,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:13,332][root][INFO] - Training Epoch: 3/10, step 52/574 completed (loss: 1.8184292316436768, acc: 0.5352112650871277)
[2024-11-29 03:03:13,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:13,742][root][INFO] - Training Epoch: 3/10, step 53/574 completed (loss: 2.4091360569000244, acc: 0.3933333456516266)
[2024-11-29 03:03:13,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:13,940][root][INFO] - Training Epoch: 3/10, step 54/574 completed (loss: 1.8747239112854004, acc: 0.6486486196517944)
[2024-11-29 03:03:14,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:14,138][root][INFO] - Training Epoch: 3/10, step 55/574 completed (loss: 0.23086656630039215, acc: 0.9230769276618958)
[2024-11-29 03:03:15,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:16,668][root][INFO] - Training Epoch: 3/10, step 56/574 completed (loss: 2.090088129043579, acc: 0.457337886095047)
[2024-11-29 03:03:17,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:17,816][root][INFO] - Training Epoch: 3/10, step 57/574 completed (loss: 2.2716875076293945, acc: 0.4422658085823059)
[2024-11-29 03:03:17,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:18,347][root][INFO] - Training Epoch: 3/10, step 58/574 completed (loss: 1.567812442779541, acc: 0.5852272510528564)
[2024-11-29 03:03:18,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:18,821][root][INFO] - Training Epoch: 3/10, step 59/574 completed (loss: 1.2788196802139282, acc: 0.6691176295280457)
[2024-11-29 03:03:18,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:19,284][root][INFO] - Training Epoch: 3/10, step 60/574 completed (loss: 1.4048962593078613, acc: 0.6086956262588501)
[2024-11-29 03:03:19,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:19,598][root][INFO] - Training Epoch: 3/10, step 61/574 completed (loss: 1.6095479726791382, acc: 0.6000000238418579)
[2024-11-29 03:03:19,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:19,786][root][INFO] - Training Epoch: 3/10, step 62/574 completed (loss: 0.8602843284606934, acc: 0.7352941036224365)
[2024-11-29 03:03:19,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:20,007][root][INFO] - Training Epoch: 3/10, step 63/574 completed (loss: 0.5772268772125244, acc: 0.8333333134651184)
[2024-11-29 03:03:20,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:20,247][root][INFO] - Training Epoch: 3/10, step 64/574 completed (loss: 0.7532784938812256, acc: 0.765625)
[2024-11-29 03:03:20,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:20,463][root][INFO] - Training Epoch: 3/10, step 65/574 completed (loss: 0.6299771070480347, acc: 0.8620689511299133)
[2024-11-29 03:03:20,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:20,702][root][INFO] - Training Epoch: 3/10, step 66/574 completed (loss: 1.5816818475723267, acc: 0.6428571343421936)
[2024-11-29 03:03:20,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:20,942][root][INFO] - Training Epoch: 3/10, step 67/574 completed (loss: 1.2246571779251099, acc: 0.7333333492279053)
[2024-11-29 03:03:21,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:21,172][root][INFO] - Training Epoch: 3/10, step 68/574 completed (loss: 0.4321001172065735, acc: 0.9200000166893005)
[2024-11-29 03:03:21,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:21,390][root][INFO] - Training Epoch: 3/10, step 69/574 completed (loss: 1.4511340856552124, acc: 0.6388888955116272)
[2024-11-29 03:03:21,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:21,630][root][INFO] - Training Epoch: 3/10, step 70/574 completed (loss: 1.6708126068115234, acc: 0.5757575631141663)
[2024-11-29 03:03:21,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:21,878][root][INFO] - Training Epoch: 3/10, step 71/574 completed (loss: 2.0208940505981445, acc: 0.5147058963775635)
[2024-11-29 03:03:21,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:22,096][root][INFO] - Training Epoch: 3/10, step 72/574 completed (loss: 1.6432383060455322, acc: 0.5634920597076416)
[2024-11-29 03:03:22,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:22,304][root][INFO] - Training Epoch: 3/10, step 73/574 completed (loss: 2.3045496940612793, acc: 0.44102564454078674)
[2024-11-29 03:03:22,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:22,490][root][INFO] - Training Epoch: 3/10, step 74/574 completed (loss: 2.0617542266845703, acc: 0.4897959232330322)
[2024-11-29 03:03:22,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:22,676][root][INFO] - Training Epoch: 3/10, step 75/574 completed (loss: 1.9315032958984375, acc: 0.5)
[2024-11-29 03:03:22,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:22,960][root][INFO] - Training Epoch: 3/10, step 76/574 completed (loss: 2.258230209350586, acc: 0.4197080433368683)
[2024-11-29 03:03:23,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:23,142][root][INFO] - Training Epoch: 3/10, step 77/574 completed (loss: 0.1876891404390335, acc: 0.9523809552192688)
[2024-11-29 03:03:23,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:23,358][root][INFO] - Training Epoch: 3/10, step 78/574 completed (loss: 0.44392886757850647, acc: 0.9166666865348816)
[2024-11-29 03:03:23,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:23,586][root][INFO] - Training Epoch: 3/10, step 79/574 completed (loss: 0.6758816242218018, acc: 0.7575757503509521)
[2024-11-29 03:03:23,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:23,818][root][INFO] - Training Epoch: 3/10, step 80/574 completed (loss: 0.422414094209671, acc: 0.8846153616905212)
[2024-11-29 03:03:23,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:24,055][root][INFO] - Training Epoch: 3/10, step 81/574 completed (loss: 1.3269836902618408, acc: 0.6730769276618958)
[2024-11-29 03:03:24,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:24,289][root][INFO] - Training Epoch: 3/10, step 82/574 completed (loss: 1.6033121347427368, acc: 0.6153846383094788)
[2024-11-29 03:03:24,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:24,526][root][INFO] - Training Epoch: 3/10, step 83/574 completed (loss: 0.3516632914543152, acc: 0.90625)
[2024-11-29 03:03:24,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:24,775][root][INFO] - Training Epoch: 3/10, step 84/574 completed (loss: 1.0091874599456787, acc: 0.6811594367027283)
[2024-11-29 03:03:24,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:25,007][root][INFO] - Training Epoch: 3/10, step 85/574 completed (loss: 1.180026888847351, acc: 0.6399999856948853)
[2024-11-29 03:03:25,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:25,235][root][INFO] - Training Epoch: 3/10, step 86/574 completed (loss: 0.47947102785110474, acc: 0.8695651888847351)
[2024-11-29 03:03:25,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:25,607][root][INFO] - Training Epoch: 3/10, step 87/574 completed (loss: 1.6849989891052246, acc: 0.6800000071525574)
[2024-11-29 03:03:25,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:25,825][root][INFO] - Training Epoch: 3/10, step 88/574 completed (loss: 1.6448731422424316, acc: 0.6019417643547058)
[2024-11-29 03:03:26,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:26,827][root][INFO] - Training Epoch: 3/10, step 89/574 completed (loss: 1.493975281715393, acc: 0.6262136101722717)
[2024-11-29 03:03:27,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:27,524][root][INFO] - Training Epoch: 3/10, step 90/574 completed (loss: 1.993333101272583, acc: 0.4784946143627167)
[2024-11-29 03:03:27,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:28,207][root][INFO] - Training Epoch: 3/10, step 91/574 completed (loss: 1.734928846359253, acc: 0.5818965435028076)
[2024-11-29 03:03:28,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:28,840][root][INFO] - Training Epoch: 3/10, step 92/574 completed (loss: 1.4505846500396729, acc: 0.6631578803062439)
[2024-11-29 03:03:29,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:29,699][root][INFO] - Training Epoch: 3/10, step 93/574 completed (loss: 2.3099966049194336, acc: 0.39603960514068604)
[2024-11-29 03:03:29,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:29,880][root][INFO] - Training Epoch: 3/10, step 94/574 completed (loss: 1.7080035209655762, acc: 0.4516128897666931)
[2024-11-29 03:03:29,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:30,077][root][INFO] - Training Epoch: 3/10, step 95/574 completed (loss: 1.4294953346252441, acc: 0.5942028760910034)
[2024-11-29 03:03:30,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:30,316][root][INFO] - Training Epoch: 3/10, step 96/574 completed (loss: 2.082930326461792, acc: 0.38655462861061096)
[2024-11-29 03:03:30,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:30,535][root][INFO] - Training Epoch: 3/10, step 97/574 completed (loss: 2.1771066188812256, acc: 0.36538460850715637)
[2024-11-29 03:03:30,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:30,814][root][INFO] - Training Epoch: 3/10, step 98/574 completed (loss: 2.208604335784912, acc: 0.40875911712646484)
[2024-11-29 03:03:30,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:31,020][root][INFO] - Training Epoch: 3/10, step 99/574 completed (loss: 2.3138606548309326, acc: 0.41791045665740967)
[2024-11-29 03:03:31,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:31,250][root][INFO] - Training Epoch: 3/10, step 100/574 completed (loss: 0.9399933815002441, acc: 0.699999988079071)
[2024-11-29 03:03:31,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:31,482][root][INFO] - Training Epoch: 3/10, step 101/574 completed (loss: 0.13561193645000458, acc: 0.9545454382896423)
[2024-11-29 03:03:31,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:31,713][root][INFO] - Training Epoch: 3/10, step 102/574 completed (loss: 0.2542570233345032, acc: 0.95652174949646)
[2024-11-29 03:03:31,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:31,940][root][INFO] - Training Epoch: 3/10, step 103/574 completed (loss: 0.35322171449661255, acc: 0.9318181872367859)
[2024-11-29 03:03:32,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:32,173][root][INFO] - Training Epoch: 3/10, step 104/574 completed (loss: 1.2406326532363892, acc: 0.6724137663841248)
[2024-11-29 03:03:32,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:32,393][root][INFO] - Training Epoch: 3/10, step 105/574 completed (loss: 0.7152251601219177, acc: 0.7209302186965942)
[2024-11-29 03:03:32,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:32,615][root][INFO] - Training Epoch: 3/10, step 106/574 completed (loss: 0.7054761648178101, acc: 0.800000011920929)
[2024-11-29 03:03:32,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:32,837][root][INFO] - Training Epoch: 3/10, step 107/574 completed (loss: 0.09663419425487518, acc: 1.0)
[2024-11-29 03:03:32,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:33,031][root][INFO] - Training Epoch: 3/10, step 108/574 completed (loss: 0.24422433972358704, acc: 0.9615384340286255)
[2024-11-29 03:03:33,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:33,236][root][INFO] - Training Epoch: 3/10, step 109/574 completed (loss: 0.45866549015045166, acc: 0.8809523582458496)
[2024-11-29 03:03:33,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:33,468][root][INFO] - Training Epoch: 3/10, step 110/574 completed (loss: 0.6827906370162964, acc: 0.8153846263885498)
[2024-11-29 03:03:33,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:33,765][root][INFO] - Training Epoch: 3/10, step 111/574 completed (loss: 1.087207555770874, acc: 0.6842105388641357)
[2024-11-29 03:03:33,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:34,001][root][INFO] - Training Epoch: 3/10, step 112/574 completed (loss: 1.463503360748291, acc: 0.5789473652839661)
[2024-11-29 03:03:34,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:34,201][root][INFO] - Training Epoch: 3/10, step 113/574 completed (loss: 1.0831494331359863, acc: 0.6666666865348816)
[2024-11-29 03:03:34,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:34,451][root][INFO] - Training Epoch: 3/10, step 114/574 completed (loss: 0.5215259194374084, acc: 0.795918345451355)
[2024-11-29 03:03:34,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:34,648][root][INFO] - Training Epoch: 3/10, step 115/574 completed (loss: 0.6218681931495667, acc: 0.8181818127632141)
[2024-11-29 03:03:34,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:34,893][root][INFO] - Training Epoch: 3/10, step 116/574 completed (loss: 1.3602830171585083, acc: 0.6666666865348816)
[2024-11-29 03:03:34,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:35,115][root][INFO] - Training Epoch: 3/10, step 117/574 completed (loss: 1.3684778213500977, acc: 0.6585366129875183)
[2024-11-29 03:03:35,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:35,325][root][INFO] - Training Epoch: 3/10, step 118/574 completed (loss: 0.8866649866104126, acc: 0.7419354915618896)
[2024-11-29 03:03:35,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:36,082][root][INFO] - Training Epoch: 3/10, step 119/574 completed (loss: 1.8175474405288696, acc: 0.5589353442192078)
[2024-11-29 03:03:36,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:36,294][root][INFO] - Training Epoch: 3/10, step 120/574 completed (loss: 0.9815428853034973, acc: 0.746666669845581)
[2024-11-29 03:03:36,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:36,592][root][INFO] - Training Epoch: 3/10, step 121/574 completed (loss: 1.2913224697113037, acc: 0.7115384340286255)
[2024-11-29 03:03:36,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:36,801][root][INFO] - Training Epoch: 3/10, step 122/574 completed (loss: 0.7404031753540039, acc: 0.7916666865348816)
[2024-11-29 03:03:36,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:37,029][root][INFO] - Training Epoch: 3/10, step 123/574 completed (loss: 1.634993314743042, acc: 0.6842105388641357)
[2024-11-29 03:03:37,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:37,275][root][INFO] - Training Epoch: 3/10, step 124/574 completed (loss: 2.1699929237365723, acc: 0.4601227045059204)
[2024-11-29 03:03:37,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:37,542][root][INFO] - Training Epoch: 3/10, step 125/574 completed (loss: 1.9262375831604004, acc: 0.5)
[2024-11-29 03:03:37,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:37,742][root][INFO] - Training Epoch: 3/10, step 126/574 completed (loss: 1.9731422662734985, acc: 0.4749999940395355)
[2024-11-29 03:03:37,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:37,966][root][INFO] - Training Epoch: 3/10, step 127/574 completed (loss: 2.0866410732269287, acc: 0.4821428656578064)
[2024-11-29 03:03:38,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:38,194][root][INFO] - Training Epoch: 3/10, step 128/574 completed (loss: 1.816633701324463, acc: 0.5179487466812134)
[2024-11-29 03:03:38,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:38,494][root][INFO] - Training Epoch: 3/10, step 129/574 completed (loss: 2.0231857299804688, acc: 0.4779411852359772)
[2024-11-29 03:03:38,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:38,683][root][INFO] - Training Epoch: 3/10, step 130/574 completed (loss: 1.7171168327331543, acc: 0.5384615659713745)
[2024-11-29 03:03:38,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:38,893][root][INFO] - Training Epoch: 3/10, step 131/574 completed (loss: 1.3416898250579834, acc: 0.6521739363670349)
[2024-11-29 03:03:38,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:39,096][root][INFO] - Training Epoch: 3/10, step 132/574 completed (loss: 2.5299971103668213, acc: 0.375)
[2024-11-29 03:03:39,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:39,308][root][INFO] - Training Epoch: 3/10, step 133/574 completed (loss: 1.4810824394226074, acc: 0.6086956262588501)
[2024-11-29 03:03:39,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:39,549][root][INFO] - Training Epoch: 3/10, step 134/574 completed (loss: 1.3741941452026367, acc: 0.6857143044471741)
[2024-11-29 03:03:39,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:39,802][root][INFO] - Training Epoch: 3/10, step 135/574 completed (loss: 1.19102144241333, acc: 0.6538461446762085)
[2024-11-29 03:03:39,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:40,069][root][INFO] - Training Epoch: 3/10, step 136/574 completed (loss: 1.5442054271697998, acc: 0.6666666865348816)
[2024-11-29 03:03:40,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:40,318][root][INFO] - Training Epoch: 3/10, step 137/574 completed (loss: 1.6985323429107666, acc: 0.6000000238418579)
[2024-11-29 03:03:40,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:40,562][root][INFO] - Training Epoch: 3/10, step 138/574 completed (loss: 0.8466564416885376, acc: 0.739130437374115)
[2024-11-29 03:03:41,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:41,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:41,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:42,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:42,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:42,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:43,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:43,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:43,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:43,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:44,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:44,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:44,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:44,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:45,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:45,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:45,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:45,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:46,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:46,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:46,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:46,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:47,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:47,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:47,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:47,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:48,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:48,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:48,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:48,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:49,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:49,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:49,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:49,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:49,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:50,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:50,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:50,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:50,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:51,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:51,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:51,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:51,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:52,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:52,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:52,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:53,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:53,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:53,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:53,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:54,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:54,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:54,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:55,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:55,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:55,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:55,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:56,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:56,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:56,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:56,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:57,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:57,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:57,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:58,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:58,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:58,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:58,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:59,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:59,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:59,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:00,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:00,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:00,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:00,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:01,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:01,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:01,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:01,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:01,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:02,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:02,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:02,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:03,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:03,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:04,081][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.4141, device='cuda:0') eval_epoch_loss=tensor(1.2279, device='cuda:0') eval_epoch_acc=tensor(0.6854, device='cuda:0')
[2024-11-29 03:04:04,082][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:04:04,082][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:04:04,321][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_3_step_139_loss_1.2279013395309448/model.pt
[2024-11-29 03:04:04,326][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.2279013395309448
[2024-11-29 03:04:04,327][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.6854275465011597
[2024-11-29 03:04:04,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:04,610][root][INFO] - Training Epoch: 3/10, step 139/574 completed (loss: 1.238072395324707, acc: 0.7142857313156128)
[2024-11-29 03:04:04,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:04,839][root][INFO] - Training Epoch: 3/10, step 140/574 completed (loss: 1.0227055549621582, acc: 0.7692307829856873)
[2024-11-29 03:04:04,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:05,075][root][INFO] - Training Epoch: 3/10, step 141/574 completed (loss: 1.4239509105682373, acc: 0.6129032373428345)
[2024-11-29 03:04:05,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:05,329][root][INFO] - Training Epoch: 3/10, step 142/574 completed (loss: 1.122312307357788, acc: 0.6486486196517944)
[2024-11-29 03:04:05,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:05,797][root][INFO] - Training Epoch: 3/10, step 143/574 completed (loss: 1.4065428972244263, acc: 0.6666666865348816)
[2024-11-29 03:04:05,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:06,024][root][INFO] - Training Epoch: 3/10, step 144/574 completed (loss: 1.4452346563339233, acc: 0.6567164063453674)
[2024-11-29 03:04:06,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:06,252][root][INFO] - Training Epoch: 3/10, step 145/574 completed (loss: 1.4184986352920532, acc: 0.5714285969734192)
[2024-11-29 03:04:06,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:06,603][root][INFO] - Training Epoch: 3/10, step 146/574 completed (loss: 1.55250084400177, acc: 0.521276593208313)
[2024-11-29 03:04:06,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:06,838][root][INFO] - Training Epoch: 3/10, step 147/574 completed (loss: 1.262465238571167, acc: 0.6857143044471741)
[2024-11-29 03:04:06,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:07,076][root][INFO] - Training Epoch: 3/10, step 148/574 completed (loss: 1.1454784870147705, acc: 0.6428571343421936)
[2024-11-29 03:04:07,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:07,352][root][INFO] - Training Epoch: 3/10, step 149/574 completed (loss: 1.186600685119629, acc: 0.6521739363670349)
[2024-11-29 03:04:07,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:07,585][root][INFO] - Training Epoch: 3/10, step 150/574 completed (loss: 1.205410122871399, acc: 0.6551724076271057)
[2024-11-29 03:04:07,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:07,813][root][INFO] - Training Epoch: 3/10, step 151/574 completed (loss: 1.2446906566619873, acc: 0.760869562625885)
[2024-11-29 03:04:07,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:08,053][root][INFO] - Training Epoch: 3/10, step 152/574 completed (loss: 1.1294186115264893, acc: 0.7118644118309021)
[2024-11-29 03:04:08,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:08,245][root][INFO] - Training Epoch: 3/10, step 153/574 completed (loss: 1.8688223361968994, acc: 0.5438596606254578)
[2024-11-29 03:04:08,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:08,504][root][INFO] - Training Epoch: 3/10, step 154/574 completed (loss: 1.0769191980361938, acc: 0.7297297120094299)
[2024-11-29 03:04:08,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:08,763][root][INFO] - Training Epoch: 3/10, step 155/574 completed (loss: 0.6269952058792114, acc: 0.8571428656578064)
[2024-11-29 03:04:08,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:09,037][root][INFO] - Training Epoch: 3/10, step 156/574 completed (loss: 0.7034808993339539, acc: 0.8260869383811951)
[2024-11-29 03:04:09,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:09,281][root][INFO] - Training Epoch: 3/10, step 157/574 completed (loss: 3.285482406616211, acc: 0.21052631735801697)
[2024-11-29 03:04:10,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:10,944][root][INFO] - Training Epoch: 3/10, step 158/574 completed (loss: 2.256892681121826, acc: 0.47297295928001404)
[2024-11-29 03:04:11,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:11,132][root][INFO] - Training Epoch: 3/10, step 159/574 completed (loss: 2.232344627380371, acc: 0.40740740299224854)
[2024-11-29 03:04:11,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:11,435][root][INFO] - Training Epoch: 3/10, step 160/574 completed (loss: 2.530503273010254, acc: 0.44186046719551086)
[2024-11-29 03:04:11,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:11,936][root][INFO] - Training Epoch: 3/10, step 161/574 completed (loss: 2.511955738067627, acc: 0.364705890417099)
[2024-11-29 03:04:12,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:12,408][root][INFO] - Training Epoch: 3/10, step 162/574 completed (loss: 2.3548593521118164, acc: 0.4157303273677826)
[2024-11-29 03:04:12,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:12,613][root][INFO] - Training Epoch: 3/10, step 163/574 completed (loss: 0.9760360717773438, acc: 0.75)
[2024-11-29 03:04:12,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:12,820][root][INFO] - Training Epoch: 3/10, step 164/574 completed (loss: 1.0808417797088623, acc: 0.761904776096344)
[2024-11-29 03:04:12,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:13,076][root][INFO] - Training Epoch: 3/10, step 165/574 completed (loss: 1.7380292415618896, acc: 0.6206896305084229)
[2024-11-29 03:04:13,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:13,341][root][INFO] - Training Epoch: 3/10, step 166/574 completed (loss: 0.6619194746017456, acc: 0.7755101919174194)
[2024-11-29 03:04:13,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:13,587][root][INFO] - Training Epoch: 3/10, step 167/574 completed (loss: 0.5760969519615173, acc: 0.8399999737739563)
[2024-11-29 03:04:13,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:13,881][root][INFO] - Training Epoch: 3/10, step 168/574 completed (loss: 0.9823269248008728, acc: 0.75)
[2024-11-29 03:04:13,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:14,103][root][INFO] - Training Epoch: 3/10, step 169/574 completed (loss: 1.6748638153076172, acc: 0.6176470518112183)
[2024-11-29 03:04:14,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:15,013][root][INFO] - Training Epoch: 3/10, step 170/574 completed (loss: 2.0698776245117188, acc: 0.5136986374855042)
[2024-11-29 03:04:15,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:15,250][root][INFO] - Training Epoch: 3/10, step 171/574 completed (loss: 0.5099514126777649, acc: 0.875)
[2024-11-29 03:04:15,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:15,476][root][INFO] - Training Epoch: 3/10, step 172/574 completed (loss: 1.198722004890442, acc: 0.7407407164573669)
[2024-11-29 03:04:15,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:15,751][root][INFO] - Training Epoch: 3/10, step 173/574 completed (loss: 1.3153690099716187, acc: 0.6785714030265808)
[2024-11-29 03:04:15,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:16,206][root][INFO] - Training Epoch: 3/10, step 174/574 completed (loss: 1.6881840229034424, acc: 0.6017699241638184)
[2024-11-29 03:04:16,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:16,390][root][INFO] - Training Epoch: 3/10, step 175/574 completed (loss: 1.577717661857605, acc: 0.6231883764266968)
[2024-11-29 03:04:16,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:16,617][root][INFO] - Training Epoch: 3/10, step 176/574 completed (loss: 1.2698951959609985, acc: 0.6818181872367859)
[2024-11-29 03:04:16,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:17,508][root][INFO] - Training Epoch: 3/10, step 177/574 completed (loss: 2.050180196762085, acc: 0.47328245639801025)
[2024-11-29 03:04:17,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:18,085][root][INFO] - Training Epoch: 3/10, step 178/574 completed (loss: 1.7669404745101929, acc: 0.5333333611488342)
[2024-11-29 03:04:18,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:18,325][root][INFO] - Training Epoch: 3/10, step 179/574 completed (loss: 1.1151647567749023, acc: 0.7213114500045776)
[2024-11-29 03:04:18,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:18,543][root][INFO] - Training Epoch: 3/10, step 180/574 completed (loss: 0.14274415373802185, acc: 0.9166666865348816)
[2024-11-29 03:04:18,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:18,750][root][INFO] - Training Epoch: 3/10, step 181/574 completed (loss: 0.18561610579490662, acc: 0.9599999785423279)
[2024-11-29 03:04:18,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:18,970][root][INFO] - Training Epoch: 3/10, step 182/574 completed (loss: 0.28006961941719055, acc: 0.9285714030265808)
[2024-11-29 03:04:19,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:19,201][root][INFO] - Training Epoch: 3/10, step 183/574 completed (loss: 0.8386794328689575, acc: 0.7682926654815674)
[2024-11-29 03:04:19,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:19,432][root][INFO] - Training Epoch: 3/10, step 184/574 completed (loss: 1.4977413415908813, acc: 0.652567982673645)
[2024-11-29 03:04:19,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:19,660][root][INFO] - Training Epoch: 3/10, step 185/574 completed (loss: 1.5502656698226929, acc: 0.619596540927887)
[2024-11-29 03:04:19,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:20,055][root][INFO] - Training Epoch: 3/10, step 186/574 completed (loss: 1.5551807880401611, acc: 0.6156250238418579)
[2024-11-29 03:04:20,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:20,488][root][INFO] - Training Epoch: 3/10, step 187/574 completed (loss: 1.759280800819397, acc: 0.5590994358062744)
[2024-11-29 03:04:20,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:20,791][root][INFO] - Training Epoch: 3/10, step 188/574 completed (loss: 1.441821813583374, acc: 0.6192170977592468)
[2024-11-29 03:04:20,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:21,001][root][INFO] - Training Epoch: 3/10, step 189/574 completed (loss: 1.0453609228134155, acc: 0.7599999904632568)
[2024-11-29 03:04:21,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:21,479][root][INFO] - Training Epoch: 3/10, step 190/574 completed (loss: 1.590547800064087, acc: 0.5465116500854492)
[2024-11-29 03:04:21,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:22,180][root][INFO] - Training Epoch: 3/10, step 191/574 completed (loss: 2.0878570079803467, acc: 0.4920634925365448)
[2024-11-29 03:04:22,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:22,989][root][INFO] - Training Epoch: 3/10, step 192/574 completed (loss: 1.9305816888809204, acc: 0.5)
[2024-11-29 03:04:23,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:23,634][root][INFO] - Training Epoch: 3/10, step 193/574 completed (loss: 1.360285758972168, acc: 0.5882353186607361)
[2024-11-29 03:04:23,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:24,604][root][INFO] - Training Epoch: 3/10, step 194/574 completed (loss: 1.7371999025344849, acc: 0.5123456716537476)
[2024-11-29 03:04:24,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:25,449][root][INFO] - Training Epoch: 3/10, step 195/574 completed (loss: 1.0860828161239624, acc: 0.6612903475761414)
[2024-11-29 03:04:25,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:25,607][root][INFO] - Training Epoch: 3/10, step 196/574 completed (loss: 0.30697450041770935, acc: 0.9285714030265808)
[2024-11-29 03:04:25,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:25,846][root][INFO] - Training Epoch: 3/10, step 197/574 completed (loss: 1.5870593786239624, acc: 0.6499999761581421)
[2024-11-29 03:04:25,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:26,086][root][INFO] - Training Epoch: 3/10, step 198/574 completed (loss: 1.2987568378448486, acc: 0.6323529481887817)
[2024-11-29 03:04:26,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:26,328][root][INFO] - Training Epoch: 3/10, step 199/574 completed (loss: 1.5988030433654785, acc: 0.6397058963775635)
[2024-11-29 03:04:26,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:26,562][root][INFO] - Training Epoch: 3/10, step 200/574 completed (loss: 1.4142721891403198, acc: 0.6271186470985413)
[2024-11-29 03:04:26,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:26,807][root][INFO] - Training Epoch: 3/10, step 201/574 completed (loss: 1.4868873357772827, acc: 0.641791045665741)
[2024-11-29 03:04:26,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:27,054][root][INFO] - Training Epoch: 3/10, step 202/574 completed (loss: 1.511007308959961, acc: 0.6407766938209534)
[2024-11-29 03:04:27,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:27,292][root][INFO] - Training Epoch: 3/10, step 203/574 completed (loss: 1.2905479669570923, acc: 0.6349206566810608)
[2024-11-29 03:04:27,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:27,535][root][INFO] - Training Epoch: 3/10, step 204/574 completed (loss: 0.8221296668052673, acc: 0.8021978139877319)
[2024-11-29 03:04:27,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:27,790][root][INFO] - Training Epoch: 3/10, step 205/574 completed (loss: 1.3161208629608154, acc: 0.6233183741569519)
[2024-11-29 03:04:27,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:28,096][root][INFO] - Training Epoch: 3/10, step 206/574 completed (loss: 1.503785252571106, acc: 0.6181102395057678)
[2024-11-29 03:04:28,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:28,309][root][INFO] - Training Epoch: 3/10, step 207/574 completed (loss: 1.1199674606323242, acc: 0.7112069129943848)
[2024-11-29 03:04:28,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:28,570][root][INFO] - Training Epoch: 3/10, step 208/574 completed (loss: 1.0137635469436646, acc: 0.739130437374115)
[2024-11-29 03:04:28,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:28,828][root][INFO] - Training Epoch: 3/10, step 209/574 completed (loss: 1.1153451204299927, acc: 0.6926069855690002)
[2024-11-29 03:04:28,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:29,045][root][INFO] - Training Epoch: 3/10, step 210/574 completed (loss: 1.3336502313613892, acc: 0.6739130616188049)
[2024-11-29 03:04:29,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:29,242][root][INFO] - Training Epoch: 3/10, step 211/574 completed (loss: 0.7855983972549438, acc: 0.739130437374115)
[2024-11-29 03:04:29,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:29,447][root][INFO] - Training Epoch: 3/10, step 212/574 completed (loss: 0.6927548050880432, acc: 0.8571428656578064)
[2024-11-29 03:04:29,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:29,683][root][INFO] - Training Epoch: 3/10, step 213/574 completed (loss: 0.8813008069992065, acc: 0.8085106611251831)
[2024-11-29 03:04:29,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:30,324][root][INFO] - Training Epoch: 3/10, step 214/574 completed (loss: 0.7129350900650024, acc: 0.8230769038200378)
[2024-11-29 03:04:30,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:30,547][root][INFO] - Training Epoch: 3/10, step 215/574 completed (loss: 0.520682692527771, acc: 0.8918918967247009)
[2024-11-29 03:04:30,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:30,759][root][INFO] - Training Epoch: 3/10, step 216/574 completed (loss: 0.371837317943573, acc: 0.895348846912384)
[2024-11-29 03:04:30,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:31,210][root][INFO] - Training Epoch: 3/10, step 217/574 completed (loss: 0.5805633664131165, acc: 0.8288288116455078)
[2024-11-29 03:04:31,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:31,503][root][INFO] - Training Epoch: 3/10, step 218/574 completed (loss: 0.5180804133415222, acc: 0.8666666746139526)
[2024-11-29 03:04:31,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:31,695][root][INFO] - Training Epoch: 3/10, step 219/574 completed (loss: 0.4141680598258972, acc: 0.8787878751754761)
[2024-11-29 03:04:31,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:31,909][root][INFO] - Training Epoch: 3/10, step 220/574 completed (loss: 0.2654488682746887, acc: 0.9259259104728699)
[2024-11-29 03:04:32,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:32,135][root][INFO] - Training Epoch: 3/10, step 221/574 completed (loss: 0.38147684931755066, acc: 0.8799999952316284)
[2024-11-29 03:04:32,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:32,386][root][INFO] - Training Epoch: 3/10, step 222/574 completed (loss: 1.4264887571334839, acc: 0.6730769276618958)
[2024-11-29 03:04:32,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:33,061][root][INFO] - Training Epoch: 3/10, step 223/574 completed (loss: 1.0911263227462769, acc: 0.6902173757553101)
[2024-11-29 03:04:33,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:33,513][root][INFO] - Training Epoch: 3/10, step 224/574 completed (loss: 1.2149215936660767, acc: 0.6931818127632141)
[2024-11-29 03:04:33,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:33,859][root][INFO] - Training Epoch: 3/10, step 225/574 completed (loss: 1.48403000831604, acc: 0.6170212626457214)
[2024-11-29 03:04:33,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:34,095][root][INFO] - Training Epoch: 3/10, step 226/574 completed (loss: 1.1121320724487305, acc: 0.7169811129570007)
[2024-11-29 03:04:34,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:34,319][root][INFO] - Training Epoch: 3/10, step 227/574 completed (loss: 0.6600387096405029, acc: 0.7833333611488342)
[2024-11-29 03:04:34,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:34,520][root][INFO] - Training Epoch: 3/10, step 228/574 completed (loss: 1.1175330877304077, acc: 0.7674418687820435)
[2024-11-29 03:04:34,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:34,761][root][INFO] - Training Epoch: 3/10, step 229/574 completed (loss: 2.5967462062835693, acc: 0.4333333373069763)
[2024-11-29 03:04:34,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:35,017][root][INFO] - Training Epoch: 3/10, step 230/574 completed (loss: 3.048424005508423, acc: 0.35789474844932556)
[2024-11-29 03:04:35,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:35,216][root][INFO] - Training Epoch: 3/10, step 231/574 completed (loss: 2.3633506298065186, acc: 0.42222222685813904)
[2024-11-29 03:04:35,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:35,543][root][INFO] - Training Epoch: 3/10, step 232/574 completed (loss: 2.216495990753174, acc: 0.4833333194255829)
[2024-11-29 03:04:35,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:35,948][root][INFO] - Training Epoch: 3/10, step 233/574 completed (loss: 2.5710465908050537, acc: 0.39908257126808167)
[2024-11-29 03:04:36,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:36,330][root][INFO] - Training Epoch: 3/10, step 234/574 completed (loss: 2.403688907623291, acc: 0.446153849363327)
[2024-11-29 03:04:36,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:36,515][root][INFO] - Training Epoch: 3/10, step 235/574 completed (loss: 0.5122202038764954, acc: 0.8421052694320679)
[2024-11-29 03:04:36,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:36,724][root][INFO] - Training Epoch: 3/10, step 236/574 completed (loss: 0.7401180267333984, acc: 0.7916666865348816)
[2024-11-29 03:04:36,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:36,964][root][INFO] - Training Epoch: 3/10, step 237/574 completed (loss: 1.7623015642166138, acc: 0.5)
[2024-11-29 03:04:37,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:37,195][root][INFO] - Training Epoch: 3/10, step 238/574 completed (loss: 1.3653199672698975, acc: 0.6296296119689941)
[2024-11-29 03:04:37,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:37,397][root][INFO] - Training Epoch: 3/10, step 239/574 completed (loss: 0.9794310331344604, acc: 0.7428571581840515)
[2024-11-29 03:04:37,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:37,637][root][INFO] - Training Epoch: 3/10, step 240/574 completed (loss: 1.7685844898223877, acc: 0.6136363744735718)
[2024-11-29 03:04:37,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:37,851][root][INFO] - Training Epoch: 3/10, step 241/574 completed (loss: 1.1330188512802124, acc: 0.75)
[2024-11-29 03:04:37,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:38,346][root][INFO] - Training Epoch: 3/10, step 242/574 completed (loss: 2.0294952392578125, acc: 0.4193548262119293)
[2024-11-29 03:04:38,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:38,782][root][INFO] - Training Epoch: 3/10, step 243/574 completed (loss: 1.7507542371749878, acc: 0.47727271914482117)
[2024-11-29 03:04:38,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:38,964][root][INFO] - Training Epoch: 3/10, step 244/574 completed (loss: 0.31710848212242126, acc: 0.9523809552192688)
[2024-11-29 03:04:39,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:39,178][root][INFO] - Training Epoch: 3/10, step 245/574 completed (loss: 1.3433880805969238, acc: 0.692307710647583)
[2024-11-29 03:04:39,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:39,388][root][INFO] - Training Epoch: 3/10, step 246/574 completed (loss: 0.7624488472938538, acc: 0.8064516186714172)
[2024-11-29 03:04:39,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:39,622][root][INFO] - Training Epoch: 3/10, step 247/574 completed (loss: 1.128364086151123, acc: 0.6499999761581421)
[2024-11-29 03:04:39,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:39,892][root][INFO] - Training Epoch: 3/10, step 248/574 completed (loss: 0.924142599105835, acc: 0.7027027010917664)
[2024-11-29 03:04:39,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:40,103][root][INFO] - Training Epoch: 3/10, step 249/574 completed (loss: 0.8748548626899719, acc: 0.7297297120094299)
[2024-11-29 03:04:40,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:40,325][root][INFO] - Training Epoch: 3/10, step 250/574 completed (loss: 0.45599648356437683, acc: 0.8648648858070374)
[2024-11-29 03:04:40,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:40,549][root][INFO] - Training Epoch: 3/10, step 251/574 completed (loss: 0.8113528490066528, acc: 0.8529411554336548)
[2024-11-29 03:04:40,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:40,793][root][INFO] - Training Epoch: 3/10, step 252/574 completed (loss: 0.24935424327850342, acc: 0.9512194991111755)
[2024-11-29 03:04:40,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:41,030][root][INFO] - Training Epoch: 3/10, step 253/574 completed (loss: 0.29127833247184753, acc: 0.9599999785423279)
[2024-11-29 03:04:41,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:41,258][root][INFO] - Training Epoch: 3/10, step 254/574 completed (loss: 0.06935982406139374, acc: 1.0)
[2024-11-29 03:04:41,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:41,493][root][INFO] - Training Epoch: 3/10, step 255/574 completed (loss: 0.3140490651130676, acc: 0.9354838728904724)
[2024-11-29 03:04:41,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:41,722][root][INFO] - Training Epoch: 3/10, step 256/574 completed (loss: 0.6425914168357849, acc: 0.859649121761322)
[2024-11-29 03:04:41,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:41,952][root][INFO] - Training Epoch: 3/10, step 257/574 completed (loss: 0.7350694537162781, acc: 0.8142856955528259)
[2024-11-29 03:04:42,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:42,192][root][INFO] - Training Epoch: 3/10, step 258/574 completed (loss: 0.8113362193107605, acc: 0.8157894611358643)
[2024-11-29 03:04:42,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:42,665][root][INFO] - Training Epoch: 3/10, step 259/574 completed (loss: 1.2127540111541748, acc: 0.698113203048706)
[2024-11-29 03:04:42,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:43,154][root][INFO] - Training Epoch: 3/10, step 260/574 completed (loss: 1.0237265825271606, acc: 0.7166666388511658)
[2024-11-29 03:04:43,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:43,333][root][INFO] - Training Epoch: 3/10, step 261/574 completed (loss: 0.6487300395965576, acc: 0.8055555820465088)
[2024-11-29 03:04:43,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:43,531][root][INFO] - Training Epoch: 3/10, step 262/574 completed (loss: 0.9028381109237671, acc: 0.8064516186714172)
[2024-11-29 03:04:43,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:43,782][root][INFO] - Training Epoch: 3/10, step 263/574 completed (loss: 1.9713566303253174, acc: 0.6133333444595337)
[2024-11-29 03:04:43,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:44,021][root][INFO] - Training Epoch: 3/10, step 264/574 completed (loss: 1.4632855653762817, acc: 0.5833333134651184)
[2024-11-29 03:04:44,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:44,823][root][INFO] - Training Epoch: 3/10, step 265/574 completed (loss: 1.878633737564087, acc: 0.5360000133514404)
[2024-11-29 03:04:44,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:45,039][root][INFO] - Training Epoch: 3/10, step 266/574 completed (loss: 1.5410922765731812, acc: 0.584269642829895)
[2024-11-29 03:04:45,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:45,286][root][INFO] - Training Epoch: 3/10, step 267/574 completed (loss: 1.7379121780395508, acc: 0.4864864945411682)
[2024-11-29 03:04:45,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:45,645][root][INFO] - Training Epoch: 3/10, step 268/574 completed (loss: 1.3383208513259888, acc: 0.6379310488700867)
[2024-11-29 03:04:45,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:45,872][root][INFO] - Training Epoch: 3/10, step 269/574 completed (loss: 0.4874221682548523, acc: 0.9090909361839294)
[2024-11-29 03:04:45,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:46,085][root][INFO] - Training Epoch: 3/10, step 270/574 completed (loss: 0.2692815661430359, acc: 0.9090909361839294)
[2024-11-29 03:04:46,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:46,259][root][INFO] - Training Epoch: 3/10, step 271/574 completed (loss: 0.31311705708503723, acc: 0.875)
[2024-11-29 03:04:46,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:46,452][root][INFO] - Training Epoch: 3/10, step 272/574 completed (loss: 0.30843591690063477, acc: 0.9333333373069763)
[2024-11-29 03:04:46,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:46,729][root][INFO] - Training Epoch: 3/10, step 273/574 completed (loss: 1.0415325164794922, acc: 0.699999988079071)
[2024-11-29 03:04:46,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:46,930][root][INFO] - Training Epoch: 3/10, step 274/574 completed (loss: 0.43518170714378357, acc: 0.875)
[2024-11-29 03:04:47,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:47,181][root][INFO] - Training Epoch: 3/10, step 275/574 completed (loss: 0.5291496515274048, acc: 0.8333333134651184)
[2024-11-29 03:04:47,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:47,420][root][INFO] - Training Epoch: 3/10, step 276/574 completed (loss: 0.49696603417396545, acc: 0.8965517282485962)
[2024-11-29 03:04:47,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:47,668][root][INFO] - Training Epoch: 3/10, step 277/574 completed (loss: 0.3030608296394348, acc: 0.9599999785423279)
[2024-11-29 03:04:47,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:47,882][root][INFO] - Training Epoch: 3/10, step 278/574 completed (loss: 1.3985199928283691, acc: 0.6170212626457214)
[2024-11-29 03:04:48,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:48,138][root][INFO] - Training Epoch: 3/10, step 279/574 completed (loss: 0.7130618691444397, acc: 0.8125)
[2024-11-29 03:04:48,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:48,357][root][INFO] - Training Epoch: 3/10, step 280/574 completed (loss: 0.7241019606590271, acc: 0.7954545617103577)
[2024-11-29 03:04:48,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:48,693][root][INFO] - Training Epoch: 3/10, step 281/574 completed (loss: 1.5230560302734375, acc: 0.5903614163398743)
[2024-11-29 03:04:49,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:49,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:50,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:50,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:50,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:51,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:51,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:51,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:51,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:52,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:52,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:52,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:53,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:53,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:53,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:54,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:54,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:54,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:55,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:55,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:55,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:55,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:56,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:56,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:56,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:56,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:57,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:57,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:57,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:58,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:58,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:58,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:59,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:59,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:59,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:00,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:00,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:00,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:00,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:01,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:01,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:01,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:01,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:02,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:02,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:02,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:03,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:03,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:03,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:03,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:04,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:04,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:04,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:04,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:05,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:05,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:05,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:06,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:06,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:06,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:06,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:07,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:07,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:08,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:08,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:08,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:08,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:09,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:09,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:10,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:10,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:10,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:10,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:11,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:11,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:11,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:11,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:11,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:12,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:12,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:12,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:13,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:13,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:13,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:13,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:14,487][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.1525, device='cuda:0') eval_epoch_loss=tensor(1.1482, device='cuda:0') eval_epoch_acc=tensor(0.7031, device='cuda:0')
[2024-11-29 03:05:14,488][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:05:14,489][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:05:14,701][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_3_step_282_loss_1.1482107639312744/model.pt
[2024-11-29 03:05:14,703][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.1482107639312744
[2024-11-29 03:05:14,704][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.7031111121177673
[2024-11-29 03:05:14,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:14,982][root][INFO] - Training Epoch: 3/10, step 282/574 completed (loss: 1.397717833518982, acc: 0.6018518805503845)
[2024-11-29 03:05:15,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:15,225][root][INFO] - Training Epoch: 3/10, step 283/574 completed (loss: 0.6061891913414001, acc: 0.8421052694320679)
[2024-11-29 03:05:15,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:15,453][root][INFO] - Training Epoch: 3/10, step 284/574 completed (loss: 0.43761664628982544, acc: 0.8529411554336548)
[2024-11-29 03:05:15,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:15,673][root][INFO] - Training Epoch: 3/10, step 285/574 completed (loss: 0.7750089764595032, acc: 0.7749999761581421)
[2024-11-29 03:05:15,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:15,883][root][INFO] - Training Epoch: 3/10, step 286/574 completed (loss: 0.9609103202819824, acc: 0.75)
[2024-11-29 03:05:16,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:16,138][root][INFO] - Training Epoch: 3/10, step 287/574 completed (loss: 1.3280582427978516, acc: 0.6800000071525574)
[2024-11-29 03:05:16,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:16,384][root][INFO] - Training Epoch: 3/10, step 288/574 completed (loss: 1.077056884765625, acc: 0.7582417726516724)
[2024-11-29 03:05:16,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:16,642][root][INFO] - Training Epoch: 3/10, step 289/574 completed (loss: 1.1524845361709595, acc: 0.695652186870575)
[2024-11-29 03:05:16,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:16,899][root][INFO] - Training Epoch: 3/10, step 290/574 completed (loss: 1.3122056722640991, acc: 0.6649484634399414)
[2024-11-29 03:05:16,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:17,127][root][INFO] - Training Epoch: 3/10, step 291/574 completed (loss: 0.15106794238090515, acc: 1.0)
[2024-11-29 03:05:17,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:17,379][root][INFO] - Training Epoch: 3/10, step 292/574 completed (loss: 1.1882070302963257, acc: 0.5952380895614624)
[2024-11-29 03:05:17,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:17,671][root][INFO] - Training Epoch: 3/10, step 293/574 completed (loss: 0.7477527260780334, acc: 0.7586206793785095)
[2024-11-29 03:05:17,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:18,065][root][INFO] - Training Epoch: 3/10, step 294/574 completed (loss: 0.8482133150100708, acc: 0.800000011920929)
[2024-11-29 03:05:18,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:18,530][root][INFO] - Training Epoch: 3/10, step 295/574 completed (loss: 1.2925441265106201, acc: 0.6804123520851135)
[2024-11-29 03:05:18,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:18,775][root][INFO] - Training Epoch: 3/10, step 296/574 completed (loss: 1.075824499130249, acc: 0.7931034564971924)
[2024-11-29 03:05:18,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:19,007][root][INFO] - Training Epoch: 3/10, step 297/574 completed (loss: 0.33289799094200134, acc: 0.9259259104728699)
[2024-11-29 03:05:19,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:19,251][root][INFO] - Training Epoch: 3/10, step 298/574 completed (loss: 0.8756000399589539, acc: 0.7631579041481018)
[2024-11-29 03:05:19,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:19,489][root][INFO] - Training Epoch: 3/10, step 299/574 completed (loss: 0.48424026370048523, acc: 0.8571428656578064)
[2024-11-29 03:05:19,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:19,714][root][INFO] - Training Epoch: 3/10, step 300/574 completed (loss: 0.07408426702022552, acc: 0.96875)
[2024-11-29 03:05:19,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:19,983][root][INFO] - Training Epoch: 3/10, step 301/574 completed (loss: 0.5348625779151917, acc: 0.8679245114326477)
[2024-11-29 03:05:20,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:20,236][root][INFO] - Training Epoch: 3/10, step 302/574 completed (loss: 0.274355411529541, acc: 0.8867924809455872)
[2024-11-29 03:05:20,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:20,461][root][INFO] - Training Epoch: 3/10, step 303/574 completed (loss: 0.38572967052459717, acc: 0.8823529481887817)
[2024-11-29 03:05:20,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:20,743][root][INFO] - Training Epoch: 3/10, step 304/574 completed (loss: 0.4642064571380615, acc: 0.8125)
[2024-11-29 03:05:20,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:21,008][root][INFO] - Training Epoch: 3/10, step 305/574 completed (loss: 1.0593230724334717, acc: 0.7868852615356445)
[2024-11-29 03:05:21,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:21,265][root][INFO] - Training Epoch: 3/10, step 306/574 completed (loss: 0.31759652495384216, acc: 0.9333333373069763)
[2024-11-29 03:05:21,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:21,512][root][INFO] - Training Epoch: 3/10, step 307/574 completed (loss: 0.03402893245220184, acc: 1.0)
[2024-11-29 03:05:21,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:21,745][root][INFO] - Training Epoch: 3/10, step 308/574 completed (loss: 0.7412182092666626, acc: 0.782608687877655)
[2024-11-29 03:05:21,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:22,078][root][INFO] - Training Epoch: 3/10, step 309/574 completed (loss: 0.9694953560829163, acc: 0.7361111044883728)
[2024-11-29 03:05:22,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:22,318][root][INFO] - Training Epoch: 3/10, step 310/574 completed (loss: 0.7240036129951477, acc: 0.7710843086242676)
[2024-11-29 03:05:22,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:22,554][root][INFO] - Training Epoch: 3/10, step 311/574 completed (loss: 0.9489210844039917, acc: 0.7307692170143127)
[2024-11-29 03:05:22,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:22,804][root][INFO] - Training Epoch: 3/10, step 312/574 completed (loss: 0.6797862648963928, acc: 0.795918345451355)
[2024-11-29 03:05:22,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:22,986][root][INFO] - Training Epoch: 3/10, step 313/574 completed (loss: 0.107115238904953, acc: 1.0)
[2024-11-29 03:05:23,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:23,220][root][INFO] - Training Epoch: 3/10, step 314/574 completed (loss: 0.3409631550312042, acc: 0.875)
[2024-11-29 03:05:23,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:23,483][root][INFO] - Training Epoch: 3/10, step 315/574 completed (loss: 0.44190943241119385, acc: 0.9032257795333862)
[2024-11-29 03:05:23,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:23,672][root][INFO] - Training Epoch: 3/10, step 316/574 completed (loss: 1.7243516445159912, acc: 0.6129032373428345)
[2024-11-29 03:05:23,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:23,908][root][INFO] - Training Epoch: 3/10, step 317/574 completed (loss: 0.5561888813972473, acc: 0.8805969953536987)
[2024-11-29 03:05:24,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:24,170][root][INFO] - Training Epoch: 3/10, step 318/574 completed (loss: 0.3872087597846985, acc: 0.9134615659713745)
[2024-11-29 03:05:24,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:24,441][root][INFO] - Training Epoch: 3/10, step 319/574 completed (loss: 0.4630490243434906, acc: 0.8666666746139526)
[2024-11-29 03:05:24,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:24,681][root][INFO] - Training Epoch: 3/10, step 320/574 completed (loss: 0.24109046161174774, acc: 0.9354838728904724)
[2024-11-29 03:05:24,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:24,913][root][INFO] - Training Epoch: 3/10, step 321/574 completed (loss: 0.06952259689569473, acc: 0.9800000190734863)
[2024-11-29 03:05:25,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:25,145][root][INFO] - Training Epoch: 3/10, step 322/574 completed (loss: 1.477941632270813, acc: 0.5925925970077515)
[2024-11-29 03:05:25,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:25,390][root][INFO] - Training Epoch: 3/10, step 323/574 completed (loss: 2.46732234954834, acc: 0.4000000059604645)
[2024-11-29 03:05:25,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:25,630][root][INFO] - Training Epoch: 3/10, step 324/574 completed (loss: 2.4001073837280273, acc: 0.41025641560554504)
[2024-11-29 03:05:25,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:25,895][root][INFO] - Training Epoch: 3/10, step 325/574 completed (loss: 2.806938409805298, acc: 0.39024388790130615)
[2024-11-29 03:05:25,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:26,085][root][INFO] - Training Epoch: 3/10, step 326/574 completed (loss: 2.24013614654541, acc: 0.3947368562221527)
[2024-11-29 03:05:26,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:26,245][root][INFO] - Training Epoch: 3/10, step 327/574 completed (loss: 0.5594861507415771, acc: 0.8947368264198303)
[2024-11-29 03:05:26,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:26,441][root][INFO] - Training Epoch: 3/10, step 328/574 completed (loss: 0.25746747851371765, acc: 0.9642857313156128)
[2024-11-29 03:05:26,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:26,656][root][INFO] - Training Epoch: 3/10, step 329/574 completed (loss: 0.17010925710201263, acc: 0.9629629850387573)
[2024-11-29 03:05:26,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:26,895][root][INFO] - Training Epoch: 3/10, step 330/574 completed (loss: 0.06673235446214676, acc: 1.0)
[2024-11-29 03:05:27,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:27,152][root][INFO] - Training Epoch: 3/10, step 331/574 completed (loss: 0.715995192527771, acc: 0.774193525314331)
[2024-11-29 03:05:27,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:27,423][root][INFO] - Training Epoch: 3/10, step 332/574 completed (loss: 0.3608684837818146, acc: 0.9298245906829834)
[2024-11-29 03:05:27,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:27,643][root][INFO] - Training Epoch: 3/10, step 333/574 completed (loss: 0.5606063008308411, acc: 0.8125)
[2024-11-29 03:05:27,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:27,871][root][INFO] - Training Epoch: 3/10, step 334/574 completed (loss: 0.2110067903995514, acc: 0.9333333373069763)
[2024-11-29 03:05:27,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:28,089][root][INFO] - Training Epoch: 3/10, step 335/574 completed (loss: 0.6176784634590149, acc: 0.7894737124443054)
[2024-11-29 03:05:28,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:28,328][root][INFO] - Training Epoch: 3/10, step 336/574 completed (loss: 1.583939790725708, acc: 0.5199999809265137)
[2024-11-29 03:05:28,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:28,587][root][INFO] - Training Epoch: 3/10, step 337/574 completed (loss: 1.7989609241485596, acc: 0.5517241358757019)
[2024-11-29 03:05:28,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:28,820][root][INFO] - Training Epoch: 3/10, step 338/574 completed (loss: 1.7339831590652466, acc: 0.5744680762290955)
[2024-11-29 03:05:28,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:29,042][root][INFO] - Training Epoch: 3/10, step 339/574 completed (loss: 1.7837501764297485, acc: 0.5542168617248535)
[2024-11-29 03:05:29,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:29,261][root][INFO] - Training Epoch: 3/10, step 340/574 completed (loss: 0.07129034399986267, acc: 1.0)
[2024-11-29 03:05:29,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:29,488][root][INFO] - Training Epoch: 3/10, step 341/574 completed (loss: 1.0790950059890747, acc: 0.8205128312110901)
[2024-11-29 03:05:29,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:29,723][root][INFO] - Training Epoch: 3/10, step 342/574 completed (loss: 0.879326343536377, acc: 0.7951807379722595)
[2024-11-29 03:05:29,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:29,960][root][INFO] - Training Epoch: 3/10, step 343/574 completed (loss: 1.5155140161514282, acc: 0.5849056839942932)
[2024-11-29 03:05:30,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:30,187][root][INFO] - Training Epoch: 3/10, step 344/574 completed (loss: 0.5246762037277222, acc: 0.8227847814559937)
[2024-11-29 03:05:30,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:30,432][root][INFO] - Training Epoch: 3/10, step 345/574 completed (loss: 0.39286041259765625, acc: 0.9019607901573181)
[2024-11-29 03:05:30,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:30,678][root][INFO] - Training Epoch: 3/10, step 346/574 completed (loss: 1.1675927639007568, acc: 0.746268630027771)
[2024-11-29 03:05:30,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:30,904][root][INFO] - Training Epoch: 3/10, step 347/574 completed (loss: 0.08536440134048462, acc: 1.0)
[2024-11-29 03:05:31,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:31,132][root][INFO] - Training Epoch: 3/10, step 348/574 completed (loss: 0.49833840131759644, acc: 0.8399999737739563)
[2024-11-29 03:05:31,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:31,441][root][INFO] - Training Epoch: 3/10, step 349/574 completed (loss: 1.1895561218261719, acc: 0.75)
[2024-11-29 03:05:31,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:31,654][root][INFO] - Training Epoch: 3/10, step 350/574 completed (loss: 1.4206782579421997, acc: 0.6279069781303406)
[2024-11-29 03:05:31,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:31,885][root][INFO] - Training Epoch: 3/10, step 351/574 completed (loss: 0.7705596685409546, acc: 0.7692307829856873)
[2024-11-29 03:05:31,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:32,152][root][INFO] - Training Epoch: 3/10, step 352/574 completed (loss: 1.834506869316101, acc: 0.42222222685813904)
[2024-11-29 03:05:32,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:32,325][root][INFO] - Training Epoch: 3/10, step 353/574 completed (loss: 0.12381593883037567, acc: 1.0)
[2024-11-29 03:05:32,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:32,564][root][INFO] - Training Epoch: 3/10, step 354/574 completed (loss: 0.9539300203323364, acc: 0.7307692170143127)
[2024-11-29 03:05:32,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:32,816][root][INFO] - Training Epoch: 3/10, step 355/574 completed (loss: 1.654905080795288, acc: 0.5714285969734192)
[2024-11-29 03:05:32,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:33,255][root][INFO] - Training Epoch: 3/10, step 356/574 completed (loss: 1.222893238067627, acc: 0.6695652008056641)
[2024-11-29 03:05:33,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:33,481][root][INFO] - Training Epoch: 3/10, step 357/574 completed (loss: 1.0054818391799927, acc: 0.717391312122345)
[2024-11-29 03:05:33,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:33,678][root][INFO] - Training Epoch: 3/10, step 358/574 completed (loss: 0.9774323105812073, acc: 0.7755101919174194)
[2024-11-29 03:05:33,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:33,887][root][INFO] - Training Epoch: 3/10, step 359/574 completed (loss: 0.10531321913003922, acc: 0.9583333134651184)
[2024-11-29 03:05:33,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:34,094][root][INFO] - Training Epoch: 3/10, step 360/574 completed (loss: 0.5017572045326233, acc: 0.8461538553237915)
[2024-11-29 03:05:34,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:34,338][root][INFO] - Training Epoch: 3/10, step 361/574 completed (loss: 1.4234163761138916, acc: 0.5365853905677795)
[2024-11-29 03:05:34,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:34,554][root][INFO] - Training Epoch: 3/10, step 362/574 completed (loss: 0.8264384865760803, acc: 0.7555555701255798)
[2024-11-29 03:05:34,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:34,777][root][INFO] - Training Epoch: 3/10, step 363/574 completed (loss: 0.7660768032073975, acc: 0.7763158082962036)
[2024-11-29 03:05:34,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:35,021][root][INFO] - Training Epoch: 3/10, step 364/574 completed (loss: 0.4243229329586029, acc: 0.9268292784690857)
[2024-11-29 03:05:35,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:35,261][root][INFO] - Training Epoch: 3/10, step 365/574 completed (loss: 0.2726152837276459, acc: 0.8787878751754761)
[2024-11-29 03:05:35,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:35,522][root][INFO] - Training Epoch: 3/10, step 366/574 completed (loss: 0.06516147404909134, acc: 1.0)
[2024-11-29 03:05:35,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:35,701][root][INFO] - Training Epoch: 3/10, step 367/574 completed (loss: 0.09962469339370728, acc: 1.0)
[2024-11-29 03:05:35,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:35,953][root][INFO] - Training Epoch: 3/10, step 368/574 completed (loss: 0.3435628116130829, acc: 0.9285714030265808)
[2024-11-29 03:05:36,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:36,222][root][INFO] - Training Epoch: 3/10, step 369/574 completed (loss: 1.4552218914031982, acc: 0.59375)
[2024-11-29 03:05:36,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:36,743][root][INFO] - Training Epoch: 3/10, step 370/574 completed (loss: 1.3750159740447998, acc: 0.6424242258071899)
[2024-11-29 03:05:37,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:37,527][root][INFO] - Training Epoch: 3/10, step 371/574 completed (loss: 0.7014831900596619, acc: 0.8301886916160583)
[2024-11-29 03:05:37,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:37,779][root][INFO] - Training Epoch: 3/10, step 372/574 completed (loss: 0.8460297584533691, acc: 0.8111110925674438)
[2024-11-29 03:05:37,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:38,057][root][INFO] - Training Epoch: 3/10, step 373/574 completed (loss: 0.3806909918785095, acc: 0.875)
[2024-11-29 03:05:38,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:38,314][root][INFO] - Training Epoch: 3/10, step 374/574 completed (loss: 0.5331024527549744, acc: 0.7714285850524902)
[2024-11-29 03:05:38,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:38,519][root][INFO] - Training Epoch: 3/10, step 375/574 completed (loss: 0.17426195740699768, acc: 0.9200000166893005)
[2024-11-29 03:05:38,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:38,756][root][INFO] - Training Epoch: 3/10, step 376/574 completed (loss: 0.2292114496231079, acc: 0.9130434989929199)
[2024-11-29 03:05:38,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:39,007][root][INFO] - Training Epoch: 3/10, step 377/574 completed (loss: 0.45242857933044434, acc: 0.8541666865348816)
[2024-11-29 03:05:39,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:39,227][root][INFO] - Training Epoch: 3/10, step 378/574 completed (loss: 0.1984592229127884, acc: 0.9368420839309692)
[2024-11-29 03:05:39,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:39,708][root][INFO] - Training Epoch: 3/10, step 379/574 completed (loss: 0.5862102508544922, acc: 0.8622754216194153)
[2024-11-29 03:05:39,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:40,013][root][INFO] - Training Epoch: 3/10, step 380/574 completed (loss: 0.6122506260871887, acc: 0.8421052694320679)
[2024-11-29 03:05:40,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:41,013][root][INFO] - Training Epoch: 3/10, step 381/574 completed (loss: 1.0626431703567505, acc: 0.7486631274223328)
[2024-11-29 03:05:41,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:41,489][root][INFO] - Training Epoch: 3/10, step 382/574 completed (loss: 0.3567623794078827, acc: 0.9009009003639221)
[2024-11-29 03:05:41,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:41,660][root][INFO] - Training Epoch: 3/10, step 383/574 completed (loss: 0.3758081793785095, acc: 0.9285714030265808)
[2024-11-29 03:05:41,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:41,902][root][INFO] - Training Epoch: 3/10, step 384/574 completed (loss: 0.17853721976280212, acc: 0.9642857313156128)
[2024-11-29 03:05:42,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:42,125][root][INFO] - Training Epoch: 3/10, step 385/574 completed (loss: 0.5802843570709229, acc: 0.875)
[2024-11-29 03:05:42,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:42,376][root][INFO] - Training Epoch: 3/10, step 386/574 completed (loss: 0.1418827474117279, acc: 0.9166666865348816)
[2024-11-29 03:05:42,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:42,630][root][INFO] - Training Epoch: 3/10, step 387/574 completed (loss: 0.1041225865483284, acc: 1.0)
[2024-11-29 03:05:42,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:42,889][root][INFO] - Training Epoch: 3/10, step 388/574 completed (loss: 0.09461910277605057, acc: 0.9545454382896423)
[2024-11-29 03:05:42,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:43,124][root][INFO] - Training Epoch: 3/10, step 389/574 completed (loss: 0.09437563270330429, acc: 1.0)
[2024-11-29 03:05:43,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:43,379][root][INFO] - Training Epoch: 3/10, step 390/574 completed (loss: 0.7100696563720703, acc: 0.8095238208770752)
[2024-11-29 03:05:43,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:43,606][root][INFO] - Training Epoch: 3/10, step 391/574 completed (loss: 1.3104463815689087, acc: 0.6481481194496155)
[2024-11-29 03:05:43,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:43,906][root][INFO] - Training Epoch: 3/10, step 392/574 completed (loss: 1.4343174695968628, acc: 0.6213592290878296)
[2024-11-29 03:05:44,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:44,359][root][INFO] - Training Epoch: 3/10, step 393/574 completed (loss: 1.2737213373184204, acc: 0.7279411554336548)
[2024-11-29 03:05:44,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:44,622][root][INFO] - Training Epoch: 3/10, step 394/574 completed (loss: 1.5710763931274414, acc: 0.6333333253860474)
[2024-11-29 03:05:44,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:44,908][root][INFO] - Training Epoch: 3/10, step 395/574 completed (loss: 1.173008680343628, acc: 0.6805555820465088)
[2024-11-29 03:05:44,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:45,099][root][INFO] - Training Epoch: 3/10, step 396/574 completed (loss: 0.5585126876831055, acc: 0.9069767594337463)
[2024-11-29 03:05:45,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:45,294][root][INFO] - Training Epoch: 3/10, step 397/574 completed (loss: 0.24247229099273682, acc: 0.9166666865348816)
[2024-11-29 03:05:45,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:45,491][root][INFO] - Training Epoch: 3/10, step 398/574 completed (loss: 0.7756027579307556, acc: 0.7906976938247681)
[2024-11-29 03:05:45,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:45,698][root][INFO] - Training Epoch: 3/10, step 399/574 completed (loss: 0.28538110852241516, acc: 0.9599999785423279)
[2024-11-29 03:05:45,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:46,145][root][INFO] - Training Epoch: 3/10, step 400/574 completed (loss: 0.660073459148407, acc: 0.8088235259056091)
[2024-11-29 03:05:46,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:46,343][root][INFO] - Training Epoch: 3/10, step 401/574 completed (loss: 0.7146251797676086, acc: 0.8399999737739563)
[2024-11-29 03:05:46,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:46,574][root][INFO] - Training Epoch: 3/10, step 402/574 completed (loss: 0.8685283064842224, acc: 0.7272727489471436)
[2024-11-29 03:05:46,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:46,811][root][INFO] - Training Epoch: 3/10, step 403/574 completed (loss: 0.4246637225151062, acc: 0.8484848737716675)
[2024-11-29 03:05:46,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:47,057][root][INFO] - Training Epoch: 3/10, step 404/574 completed (loss: 1.2090309858322144, acc: 0.6451612710952759)
[2024-11-29 03:05:47,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:47,294][root][INFO] - Training Epoch: 3/10, step 405/574 completed (loss: 0.5652502775192261, acc: 0.8888888955116272)
[2024-11-29 03:05:47,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:47,530][root][INFO] - Training Epoch: 3/10, step 406/574 completed (loss: 0.3907642364501953, acc: 0.8799999952316284)
[2024-11-29 03:05:47,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:47,778][root][INFO] - Training Epoch: 3/10, step 407/574 completed (loss: 0.4315224289894104, acc: 0.8888888955116272)
[2024-11-29 03:05:47,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:47,993][root][INFO] - Training Epoch: 3/10, step 408/574 completed (loss: 0.3679914176464081, acc: 0.9259259104728699)
[2024-11-29 03:05:48,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:48,231][root][INFO] - Training Epoch: 3/10, step 409/574 completed (loss: 0.09905833750963211, acc: 1.0)
[2024-11-29 03:05:48,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:48,473][root][INFO] - Training Epoch: 3/10, step 410/574 completed (loss: 0.4032627046108246, acc: 0.8965517282485962)
[2024-11-29 03:05:48,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:48,693][root][INFO] - Training Epoch: 3/10, step 411/574 completed (loss: 0.3015157878398895, acc: 0.9642857313156128)
[2024-11-29 03:05:48,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:48,923][root][INFO] - Training Epoch: 3/10, step 412/574 completed (loss: 0.30593618750572205, acc: 0.9666666388511658)
[2024-11-29 03:05:49,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:49,163][root][INFO] - Training Epoch: 3/10, step 413/574 completed (loss: 0.3670576810836792, acc: 0.9090909361839294)
[2024-11-29 03:05:49,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:49,386][root][INFO] - Training Epoch: 3/10, step 414/574 completed (loss: 0.14192871749401093, acc: 1.0)
[2024-11-29 03:05:49,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:49,629][root][INFO] - Training Epoch: 3/10, step 415/574 completed (loss: 0.6038522124290466, acc: 0.8039215803146362)
[2024-11-29 03:05:49,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:49,866][root][INFO] - Training Epoch: 3/10, step 416/574 completed (loss: 0.27077516913414, acc: 0.9230769276618958)
[2024-11-29 03:05:49,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:50,098][root][INFO] - Training Epoch: 3/10, step 417/574 completed (loss: 0.46070802211761475, acc: 0.8888888955116272)
[2024-11-29 03:05:50,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:50,366][root][INFO] - Training Epoch: 3/10, step 418/574 completed (loss: 0.6750867366790771, acc: 0.8500000238418579)
[2024-11-29 03:05:50,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:50,602][root][INFO] - Training Epoch: 3/10, step 419/574 completed (loss: 0.36713212728500366, acc: 0.949999988079071)
[2024-11-29 03:05:50,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:50,803][root][INFO] - Training Epoch: 3/10, step 420/574 completed (loss: 0.3606390357017517, acc: 0.9047619104385376)
[2024-11-29 03:05:50,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:51,015][root][INFO] - Training Epoch: 3/10, step 421/574 completed (loss: 0.6158649325370789, acc: 0.800000011920929)
[2024-11-29 03:05:51,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:51,250][root][INFO] - Training Epoch: 3/10, step 422/574 completed (loss: 0.8192574977874756, acc: 0.78125)
[2024-11-29 03:05:51,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:51,461][root][INFO] - Training Epoch: 3/10, step 423/574 completed (loss: 0.9521445035934448, acc: 0.6666666865348816)
[2024-11-29 03:05:51,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:51,700][root][INFO] - Training Epoch: 3/10, step 424/574 completed (loss: 0.43136537075042725, acc: 0.9259259104728699)
[2024-11-29 03:05:52,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:52,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:52,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:53,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:53,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:53,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:53,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:54,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:54,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:54,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:55,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:55,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:55,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:55,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:56,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:56,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:56,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:57,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:57,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:57,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:57,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:57,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:58,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:58,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:58,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:58,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:59,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:59,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:59,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:59,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:00,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:00,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:00,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:00,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:01,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:01,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:01,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:02,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:02,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:02,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:02,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:02,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:03,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:03,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:03,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:04,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:04,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:04,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:05,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:05,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:05,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:06,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:06,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:06,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:06,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:07,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:07,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:07,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:07,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:08,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:08,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:08,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:09,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:09,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:09,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:09,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:10,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:10,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:10,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:11,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:11,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:11,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:11,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:12,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:12,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:12,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:12,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:12,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:13,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:13,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:13,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:13,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:14,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:14,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:14,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:15,304][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.0851, device='cuda:0') eval_epoch_loss=tensor(1.1266, device='cuda:0') eval_epoch_acc=tensor(0.7176, device='cuda:0')
[2024-11-29 03:06:15,305][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:06:15,306][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:06:15,484][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_3_step_425_loss_1.1265701055526733/model.pt
[2024-11-29 03:06:15,492][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.1265701055526733
[2024-11-29 03:06:15,493][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.7175796031951904
[2024-11-29 03:06:15,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:15,739][root][INFO] - Training Epoch: 3/10, step 425/574 completed (loss: 0.4562464654445648, acc: 0.9090909361839294)
[2024-11-29 03:06:15,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:15,973][root][INFO] - Training Epoch: 3/10, step 426/574 completed (loss: 0.3923151195049286, acc: 0.8695651888847351)
[2024-11-29 03:06:16,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:16,222][root][INFO] - Training Epoch: 3/10, step 427/574 completed (loss: 0.5295672416687012, acc: 0.7837837934494019)
[2024-11-29 03:06:16,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:16,453][root][INFO] - Training Epoch: 3/10, step 428/574 completed (loss: 0.31419864296913147, acc: 0.9259259104728699)
[2024-11-29 03:06:16,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:16,692][root][INFO] - Training Epoch: 3/10, step 429/574 completed (loss: 0.24291029572486877, acc: 0.95652174949646)
[2024-11-29 03:06:16,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:16,898][root][INFO] - Training Epoch: 3/10, step 430/574 completed (loss: 0.03824351727962494, acc: 1.0)
[2024-11-29 03:06:16,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:17,093][root][INFO] - Training Epoch: 3/10, step 431/574 completed (loss: 0.07836998254060745, acc: 1.0)
[2024-11-29 03:06:17,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:17,273][root][INFO] - Training Epoch: 3/10, step 432/574 completed (loss: 0.11834179610013962, acc: 0.95652174949646)
[2024-11-29 03:06:17,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:17,542][root][INFO] - Training Epoch: 3/10, step 433/574 completed (loss: 0.33027589321136475, acc: 0.8611111044883728)
[2024-11-29 03:06:17,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:17,791][root][INFO] - Training Epoch: 3/10, step 434/574 completed (loss: 0.020155837759375572, acc: 1.0)
[2024-11-29 03:06:17,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:18,031][root][INFO] - Training Epoch: 3/10, step 435/574 completed (loss: 0.07625006884336472, acc: 0.9696969985961914)
[2024-11-29 03:06:18,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:18,286][root][INFO] - Training Epoch: 3/10, step 436/574 completed (loss: 0.4691578447818756, acc: 0.9166666865348816)
[2024-11-29 03:06:18,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:18,540][root][INFO] - Training Epoch: 3/10, step 437/574 completed (loss: 0.3076958656311035, acc: 0.8863636255264282)
[2024-11-29 03:06:18,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:18,774][root][INFO] - Training Epoch: 3/10, step 438/574 completed (loss: 0.041017044335603714, acc: 1.0)
[2024-11-29 03:06:18,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:19,016][root][INFO] - Training Epoch: 3/10, step 439/574 completed (loss: 0.4908961355686188, acc: 0.8461538553237915)
[2024-11-29 03:06:19,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:19,396][root][INFO] - Training Epoch: 3/10, step 440/574 completed (loss: 0.9264084100723267, acc: 0.7727272510528564)
[2024-11-29 03:06:19,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:20,023][root][INFO] - Training Epoch: 3/10, step 441/574 completed (loss: 1.4701671600341797, acc: 0.6000000238418579)
[2024-11-29 03:06:20,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:20,328][root][INFO] - Training Epoch: 3/10, step 442/574 completed (loss: 1.4236211776733398, acc: 0.6048387289047241)
[2024-11-29 03:06:20,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:20,888][root][INFO] - Training Epoch: 3/10, step 443/574 completed (loss: 1.1171694993972778, acc: 0.7064676880836487)
[2024-11-29 03:06:20,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:21,125][root][INFO] - Training Epoch: 3/10, step 444/574 completed (loss: 0.5904943346977234, acc: 0.7924528121948242)
[2024-11-29 03:06:21,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:21,446][root][INFO] - Training Epoch: 3/10, step 445/574 completed (loss: 0.43622463941574097, acc: 0.8636363744735718)
[2024-11-29 03:06:21,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:21,627][root][INFO] - Training Epoch: 3/10, step 446/574 completed (loss: 0.9833738803863525, acc: 0.782608687877655)
[2024-11-29 03:06:21,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:21,844][root][INFO] - Training Epoch: 3/10, step 447/574 completed (loss: 1.022658348083496, acc: 0.807692289352417)
[2024-11-29 03:06:21,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:22,064][root][INFO] - Training Epoch: 3/10, step 448/574 completed (loss: 0.36430901288986206, acc: 0.8928571343421936)
[2024-11-29 03:06:22,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:22,312][root][INFO] - Training Epoch: 3/10, step 449/574 completed (loss: 0.3399225175380707, acc: 0.9253731369972229)
[2024-11-29 03:06:22,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:22,537][root][INFO] - Training Epoch: 3/10, step 450/574 completed (loss: 0.5368065237998962, acc: 0.8888888955116272)
[2024-11-29 03:06:22,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:22,824][root][INFO] - Training Epoch: 3/10, step 451/574 completed (loss: 0.3832350969314575, acc: 0.9021739363670349)
[2024-11-29 03:06:22,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:23,068][root][INFO] - Training Epoch: 3/10, step 452/574 completed (loss: 0.4607071876525879, acc: 0.8461538553237915)
[2024-11-29 03:06:23,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:23,304][root][INFO] - Training Epoch: 3/10, step 453/574 completed (loss: 0.741603672504425, acc: 0.8421052694320679)
[2024-11-29 03:06:23,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:23,513][root][INFO] - Training Epoch: 3/10, step 454/574 completed (loss: 0.44784724712371826, acc: 0.8979591727256775)
[2024-11-29 03:06:23,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:23,731][root][INFO] - Training Epoch: 3/10, step 455/574 completed (loss: 0.36802396178245544, acc: 0.8787878751754761)
[2024-11-29 03:06:23,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:23,944][root][INFO] - Training Epoch: 3/10, step 456/574 completed (loss: 1.2370761632919312, acc: 0.6288659572601318)
[2024-11-29 03:06:24,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:24,182][root][INFO] - Training Epoch: 3/10, step 457/574 completed (loss: 0.5695552825927734, acc: 0.8142856955528259)
[2024-11-29 03:06:24,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:24,479][root][INFO] - Training Epoch: 3/10, step 458/574 completed (loss: 1.4245142936706543, acc: 0.680232584476471)
[2024-11-29 03:06:24,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:24,704][root][INFO] - Training Epoch: 3/10, step 459/574 completed (loss: 0.5339048504829407, acc: 0.875)
[2024-11-29 03:06:24,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:24,933][root][INFO] - Training Epoch: 3/10, step 460/574 completed (loss: 0.9998608827590942, acc: 0.7407407164573669)
[2024-11-29 03:06:25,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:25,174][root][INFO] - Training Epoch: 3/10, step 461/574 completed (loss: 0.8648923635482788, acc: 0.7222222089767456)
[2024-11-29 03:06:25,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:25,430][root][INFO] - Training Epoch: 3/10, step 462/574 completed (loss: 0.5326665639877319, acc: 0.84375)
[2024-11-29 03:06:25,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:25,699][root][INFO] - Training Epoch: 3/10, step 463/574 completed (loss: 0.5214178562164307, acc: 0.8846153616905212)
[2024-11-29 03:06:25,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:25,922][root][INFO] - Training Epoch: 3/10, step 464/574 completed (loss: 0.7866775393486023, acc: 0.8478260636329651)
[2024-11-29 03:06:26,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:26,179][root][INFO] - Training Epoch: 3/10, step 465/574 completed (loss: 0.7198306918144226, acc: 0.8214285969734192)
[2024-11-29 03:06:26,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:26,431][root][INFO] - Training Epoch: 3/10, step 466/574 completed (loss: 1.2740792036056519, acc: 0.6626505851745605)
[2024-11-29 03:06:26,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:26,724][root][INFO] - Training Epoch: 3/10, step 467/574 completed (loss: 0.8827749490737915, acc: 0.7567567825317383)
[2024-11-29 03:06:26,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:26,996][root][INFO] - Training Epoch: 3/10, step 468/574 completed (loss: 1.3700977563858032, acc: 0.6796116232872009)
[2024-11-29 03:06:27,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:27,238][root][INFO] - Training Epoch: 3/10, step 469/574 completed (loss: 1.6655675172805786, acc: 0.5934959053993225)
[2024-11-29 03:06:27,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:27,444][root][INFO] - Training Epoch: 3/10, step 470/574 completed (loss: 0.3653346598148346, acc: 0.875)
[2024-11-29 03:06:27,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:27,658][root][INFO] - Training Epoch: 3/10, step 471/574 completed (loss: 0.7827776074409485, acc: 0.7857142686843872)
[2024-11-29 03:06:27,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:27,981][root][INFO] - Training Epoch: 3/10, step 472/574 completed (loss: 1.1444061994552612, acc: 0.656862735748291)
[2024-11-29 03:06:28,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:28,246][root][INFO] - Training Epoch: 3/10, step 473/574 completed (loss: 1.3950324058532715, acc: 0.6419214010238647)
[2024-11-29 03:06:28,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:28,515][root][INFO] - Training Epoch: 3/10, step 474/574 completed (loss: 1.2033039331436157, acc: 0.6875)
[2024-11-29 03:06:28,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:28,739][root][INFO] - Training Epoch: 3/10, step 475/574 completed (loss: 0.7911649346351624, acc: 0.7668711543083191)
[2024-11-29 03:06:28,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:28,975][root][INFO] - Training Epoch: 3/10, step 476/574 completed (loss: 0.8382745981216431, acc: 0.7625899314880371)
[2024-11-29 03:06:29,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:29,244][root][INFO] - Training Epoch: 3/10, step 477/574 completed (loss: 1.2744182348251343, acc: 0.6633166074752808)
[2024-11-29 03:06:29,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:29,498][root][INFO] - Training Epoch: 3/10, step 478/574 completed (loss: 1.0074981451034546, acc: 0.75)
[2024-11-29 03:06:29,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:29,726][root][INFO] - Training Epoch: 3/10, step 479/574 completed (loss: 0.7434001564979553, acc: 0.7878788113594055)
[2024-11-29 03:06:29,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:29,933][root][INFO] - Training Epoch: 3/10, step 480/574 completed (loss: 0.5652088522911072, acc: 0.8518518805503845)
[2024-11-29 03:06:30,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:30,185][root][INFO] - Training Epoch: 3/10, step 481/574 completed (loss: 0.9854151010513306, acc: 0.699999988079071)
[2024-11-29 03:06:30,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:30,427][root][INFO] - Training Epoch: 3/10, step 482/574 completed (loss: 1.4754666090011597, acc: 0.6499999761581421)
[2024-11-29 03:06:30,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:30,709][root][INFO] - Training Epoch: 3/10, step 483/574 completed (loss: 1.410681962966919, acc: 0.6034482717514038)
[2024-11-29 03:06:30,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:30,955][root][INFO] - Training Epoch: 3/10, step 484/574 completed (loss: 0.27704644203186035, acc: 0.8709677457809448)
[2024-11-29 03:06:31,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:31,196][root][INFO] - Training Epoch: 3/10, step 485/574 completed (loss: 0.3323463499546051, acc: 0.8947368264198303)
[2024-11-29 03:06:31,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:31,449][root][INFO] - Training Epoch: 3/10, step 486/574 completed (loss: 1.7179551124572754, acc: 0.5185185074806213)
[2024-11-29 03:06:31,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:31,675][root][INFO] - Training Epoch: 3/10, step 487/574 completed (loss: 0.9469476342201233, acc: 0.6666666865348816)
[2024-11-29 03:06:31,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:31,942][root][INFO] - Training Epoch: 3/10, step 488/574 completed (loss: 1.5256614685058594, acc: 0.7727272510528564)
[2024-11-29 03:06:32,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:32,172][root][INFO] - Training Epoch: 3/10, step 489/574 completed (loss: 1.4823861122131348, acc: 0.5692307949066162)
[2024-11-29 03:06:32,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:32,375][root][INFO] - Training Epoch: 3/10, step 490/574 completed (loss: 0.32180139422416687, acc: 0.8999999761581421)
[2024-11-29 03:06:32,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:32,547][root][INFO] - Training Epoch: 3/10, step 491/574 completed (loss: 0.8411719799041748, acc: 0.7931034564971924)
[2024-11-29 03:06:32,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:32,751][root][INFO] - Training Epoch: 3/10, step 492/574 completed (loss: 0.6506091952323914, acc: 0.7843137383460999)
[2024-11-29 03:06:32,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:32,977][root][INFO] - Training Epoch: 3/10, step 493/574 completed (loss: 0.5542317032814026, acc: 0.7931034564971924)
[2024-11-29 03:06:33,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:33,236][root][INFO] - Training Epoch: 3/10, step 494/574 completed (loss: 0.7745785713195801, acc: 0.7894737124443054)
[2024-11-29 03:06:33,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:33,510][root][INFO] - Training Epoch: 3/10, step 495/574 completed (loss: 0.6955491304397583, acc: 0.7894737124443054)
[2024-11-29 03:06:33,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:33,783][root][INFO] - Training Epoch: 3/10, step 496/574 completed (loss: 1.4611729383468628, acc: 0.5982142686843872)
[2024-11-29 03:06:33,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:34,089][root][INFO] - Training Epoch: 3/10, step 497/574 completed (loss: 0.7626065015792847, acc: 0.7528089880943298)
[2024-11-29 03:06:34,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:34,363][root][INFO] - Training Epoch: 3/10, step 498/574 completed (loss: 1.1868270635604858, acc: 0.6516854166984558)
[2024-11-29 03:06:34,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:34,625][root][INFO] - Training Epoch: 3/10, step 499/574 completed (loss: 1.7714685201644897, acc: 0.5248227119445801)
[2024-11-29 03:06:34,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:34,889][root][INFO] - Training Epoch: 3/10, step 500/574 completed (loss: 1.3608810901641846, acc: 0.695652186870575)
[2024-11-29 03:06:34,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:35,111][root][INFO] - Training Epoch: 3/10, step 501/574 completed (loss: 0.12602539360523224, acc: 0.9599999785423279)
[2024-11-29 03:06:35,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:35,364][root][INFO] - Training Epoch: 3/10, step 502/574 completed (loss: 0.0763675644993782, acc: 1.0)
[2024-11-29 03:06:35,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:35,595][root][INFO] - Training Epoch: 3/10, step 503/574 completed (loss: 0.9484142661094666, acc: 0.8148148059844971)
[2024-11-29 03:06:35,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:35,847][root][INFO] - Training Epoch: 3/10, step 504/574 completed (loss: 0.31725943088531494, acc: 0.8888888955116272)
[2024-11-29 03:06:35,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:36,079][root][INFO] - Training Epoch: 3/10, step 505/574 completed (loss: 1.0862947702407837, acc: 0.7547169923782349)
[2024-11-29 03:06:36,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:36,296][root][INFO] - Training Epoch: 3/10, step 506/574 completed (loss: 1.4619616270065308, acc: 0.6206896305084229)
[2024-11-29 03:06:36,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:36,812][root][INFO] - Training Epoch: 3/10, step 507/574 completed (loss: 1.5643937587738037, acc: 0.6036036014556885)
[2024-11-29 03:06:36,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:37,163][root][INFO] - Training Epoch: 3/10, step 508/574 completed (loss: 1.0201877355575562, acc: 0.7323943376541138)
[2024-11-29 03:06:37,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:37,343][root][INFO] - Training Epoch: 3/10, step 509/574 completed (loss: 0.3388638198375702, acc: 0.8999999761581421)
[2024-11-29 03:06:37,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:37,552][root][INFO] - Training Epoch: 3/10, step 510/574 completed (loss: 0.27199041843414307, acc: 0.9333333373069763)
[2024-11-29 03:06:37,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:37,788][root][INFO] - Training Epoch: 3/10, step 511/574 completed (loss: 0.5198259949684143, acc: 0.8846153616905212)
[2024-11-29 03:06:39,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:40,617][root][INFO] - Training Epoch: 3/10, step 512/574 completed (loss: 2.0172207355499268, acc: 0.5)
[2024-11-29 03:06:40,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:41,277][root][INFO] - Training Epoch: 3/10, step 513/574 completed (loss: 0.7773784399032593, acc: 0.7857142686843872)
[2024-11-29 03:06:41,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:41,483][root][INFO] - Training Epoch: 3/10, step 514/574 completed (loss: 1.0358216762542725, acc: 0.7857142686843872)
[2024-11-29 03:06:41,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:41,732][root][INFO] - Training Epoch: 3/10, step 515/574 completed (loss: 0.28236204385757446, acc: 0.8999999761581421)
[2024-11-29 03:06:41,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:42,362][root][INFO] - Training Epoch: 3/10, step 516/574 completed (loss: 0.8523972034454346, acc: 0.7916666865348816)
[2024-11-29 03:06:42,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:42,546][root][INFO] - Training Epoch: 3/10, step 517/574 completed (loss: 0.03295950964093208, acc: 1.0)
[2024-11-29 03:06:42,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:42,743][root][INFO] - Training Epoch: 3/10, step 518/574 completed (loss: 0.4173012673854828, acc: 0.8387096524238586)
[2024-11-29 03:06:42,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:42,964][root][INFO] - Training Epoch: 3/10, step 519/574 completed (loss: 0.30552300810813904, acc: 0.949999988079071)
[2024-11-29 03:06:43,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:43,189][root][INFO] - Training Epoch: 3/10, step 520/574 completed (loss: 0.5674461722373962, acc: 0.8518518805503845)
[2024-11-29 03:06:43,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:44,098][root][INFO] - Training Epoch: 3/10, step 521/574 completed (loss: 1.15184485912323, acc: 0.7203390002250671)
[2024-11-29 03:06:44,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:44,340][root][INFO] - Training Epoch: 3/10, step 522/574 completed (loss: 0.6796984076499939, acc: 0.8208954930305481)
[2024-11-29 03:06:44,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:44,596][root][INFO] - Training Epoch: 3/10, step 523/574 completed (loss: 0.795621931552887, acc: 0.7591241002082825)
[2024-11-29 03:06:44,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:45,063][root][INFO] - Training Epoch: 3/10, step 524/574 completed (loss: 1.0564544200897217, acc: 0.6949999928474426)
[2024-11-29 03:06:45,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:45,257][root][INFO] - Training Epoch: 3/10, step 525/574 completed (loss: 0.125996395945549, acc: 0.9814814925193787)
[2024-11-29 03:06:45,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:45,462][root][INFO] - Training Epoch: 3/10, step 526/574 completed (loss: 0.33803367614746094, acc: 0.9230769276618958)
[2024-11-29 03:06:45,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:45,681][root][INFO] - Training Epoch: 3/10, step 527/574 completed (loss: 0.38049906492233276, acc: 0.9047619104385376)
[2024-11-29 03:06:45,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:45,913][root][INFO] - Training Epoch: 3/10, step 528/574 completed (loss: 2.222219228744507, acc: 0.4098360538482666)
[2024-11-29 03:06:46,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:46,150][root][INFO] - Training Epoch: 3/10, step 529/574 completed (loss: 0.6229864358901978, acc: 0.8135592937469482)
[2024-11-29 03:06:46,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:46,390][root][INFO] - Training Epoch: 3/10, step 530/574 completed (loss: 2.282705068588257, acc: 0.4883720874786377)
[2024-11-29 03:06:46,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:46,624][root][INFO] - Training Epoch: 3/10, step 531/574 completed (loss: 1.8636857271194458, acc: 0.5454545617103577)
[2024-11-29 03:06:46,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:46,860][root][INFO] - Training Epoch: 3/10, step 532/574 completed (loss: 1.9707393646240234, acc: 0.5660377144813538)
[2024-11-29 03:06:46,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:47,095][root][INFO] - Training Epoch: 3/10, step 533/574 completed (loss: 0.9522709250450134, acc: 0.7272727489471436)
[2024-11-29 03:06:47,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:47,322][root][INFO] - Training Epoch: 3/10, step 534/574 completed (loss: 0.9679916501045227, acc: 0.7599999904632568)
[2024-11-29 03:06:47,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:47,547][root][INFO] - Training Epoch: 3/10, step 535/574 completed (loss: 0.48587679862976074, acc: 0.8500000238418579)
[2024-11-29 03:06:47,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:47,771][root][INFO] - Training Epoch: 3/10, step 536/574 completed (loss: 0.3213367164134979, acc: 0.9545454382896423)
[2024-11-29 03:06:47,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:48,074][root][INFO] - Training Epoch: 3/10, step 537/574 completed (loss: 0.8326376080513, acc: 0.7692307829856873)
[2024-11-29 03:06:48,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:48,298][root][INFO] - Training Epoch: 3/10, step 538/574 completed (loss: 0.793526291847229, acc: 0.75)
[2024-11-29 03:06:48,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:48,582][root][INFO] - Training Epoch: 3/10, step 539/574 completed (loss: 0.6747027635574341, acc: 0.84375)
[2024-11-29 03:06:48,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:48,772][root][INFO] - Training Epoch: 3/10, step 540/574 completed (loss: 1.1176416873931885, acc: 0.6969696879386902)
[2024-11-29 03:06:48,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:48,971][root][INFO] - Training Epoch: 3/10, step 541/574 completed (loss: 0.41346606612205505, acc: 0.9375)
[2024-11-29 03:06:49,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:49,177][root][INFO] - Training Epoch: 3/10, step 542/574 completed (loss: 0.4166567027568817, acc: 0.9032257795333862)
[2024-11-29 03:06:49,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:49,406][root][INFO] - Training Epoch: 3/10, step 543/574 completed (loss: 0.08851504325866699, acc: 1.0)
[2024-11-29 03:06:49,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:49,647][root][INFO] - Training Epoch: 3/10, step 544/574 completed (loss: 0.2431301772594452, acc: 0.9333333373069763)
[2024-11-29 03:06:49,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:49,882][root][INFO] - Training Epoch: 3/10, step 545/574 completed (loss: 0.20872832834720612, acc: 0.9756097793579102)
[2024-11-29 03:06:49,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:50,111][root][INFO] - Training Epoch: 3/10, step 546/574 completed (loss: 0.08963961154222488, acc: 1.0)
[2024-11-29 03:06:50,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:50,341][root][INFO] - Training Epoch: 3/10, step 547/574 completed (loss: 0.2334865778684616, acc: 0.9736841917037964)
[2024-11-29 03:06:50,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:50,581][root][INFO] - Training Epoch: 3/10, step 548/574 completed (loss: 0.2161824107170105, acc: 0.9354838728904724)
[2024-11-29 03:06:50,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:50,828][root][INFO] - Training Epoch: 3/10, step 549/574 completed (loss: 0.04770853370428085, acc: 1.0)
[2024-11-29 03:06:50,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:51,064][root][INFO] - Training Epoch: 3/10, step 550/574 completed (loss: 0.47226381301879883, acc: 0.8787878751754761)
[2024-11-29 03:06:51,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:51,274][root][INFO] - Training Epoch: 3/10, step 551/574 completed (loss: 0.34166061878204346, acc: 0.8999999761581421)
[2024-11-29 03:06:51,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:51,494][root][INFO] - Training Epoch: 3/10, step 552/574 completed (loss: 0.2732841372489929, acc: 0.9285714030265808)
[2024-11-29 03:06:51,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:51,732][root][INFO] - Training Epoch: 3/10, step 553/574 completed (loss: 0.9349612593650818, acc: 0.7372262477874756)
[2024-11-29 03:06:51,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:51,974][root][INFO] - Training Epoch: 3/10, step 554/574 completed (loss: 0.8732486963272095, acc: 0.800000011920929)
[2024-11-29 03:06:52,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:52,216][root][INFO] - Training Epoch: 3/10, step 555/574 completed (loss: 1.1653424501419067, acc: 0.699999988079071)
[2024-11-29 03:06:52,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:52,449][root][INFO] - Training Epoch: 3/10, step 556/574 completed (loss: 0.8514219522476196, acc: 0.7947019934654236)
[2024-11-29 03:06:52,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:52,659][root][INFO] - Training Epoch: 3/10, step 557/574 completed (loss: 0.5435073971748352, acc: 0.8290598392486572)
[2024-11-29 03:06:52,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:52,882][root][INFO] - Training Epoch: 3/10, step 558/574 completed (loss: 0.21272006630897522, acc: 0.9599999785423279)
[2024-11-29 03:06:52,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:53,120][root][INFO] - Training Epoch: 3/10, step 559/574 completed (loss: 0.3106856346130371, acc: 0.8846153616905212)
[2024-11-29 03:06:53,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:53,345][root][INFO] - Training Epoch: 3/10, step 560/574 completed (loss: 0.10139299184083939, acc: 1.0)
[2024-11-29 03:06:53,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:53,565][root][INFO] - Training Epoch: 3/10, step 561/574 completed (loss: 0.983877420425415, acc: 0.7692307829856873)
[2024-11-29 03:06:53,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:53,803][root][INFO] - Training Epoch: 3/10, step 562/574 completed (loss: 0.8828897476196289, acc: 0.7333333492279053)
[2024-11-29 03:06:53,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:54,001][root][INFO] - Training Epoch: 3/10, step 563/574 completed (loss: 0.9120761752128601, acc: 0.7662337422370911)
[2024-11-29 03:06:54,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:54,205][root][INFO] - Training Epoch: 3/10, step 564/574 completed (loss: 0.39751335978507996, acc: 0.8541666865348816)
[2024-11-29 03:06:54,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:54,410][root][INFO] - Training Epoch: 3/10, step 565/574 completed (loss: 0.6968748569488525, acc: 0.8448275923728943)
[2024-11-29 03:06:54,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:54,650][root][INFO] - Training Epoch: 3/10, step 566/574 completed (loss: 0.7743226885795593, acc: 0.8333333134651184)
[2024-11-29 03:06:54,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:54,908][root][INFO] - Training Epoch: 3/10, step 567/574 completed (loss: 0.13065272569656372, acc: 1.0)
[2024-11-29 03:06:55,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:55,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:56,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:56,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:56,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:56,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:57,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:57,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:57,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:57,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:58,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:58,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:58,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:58,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:59,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:59,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:59,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:59,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:00,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:00,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:00,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:00,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:01,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:01,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:01,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:01,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:02,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:02,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:02,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:02,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:03,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:03,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:03,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:03,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:04,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:04,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:04,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:04,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:05,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:05,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:05,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:06,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:06,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:06,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:07,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:07,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:07,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:07,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:08,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:08,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:08,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:08,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:08,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:09,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:09,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:09,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:09,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:10,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:10,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:10,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:10,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:11,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:11,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:11,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:12,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:12,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:12,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:13,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:13,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:13,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:14,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:14,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:14,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:14,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:15,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:15,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:15,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:15,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:16,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:16,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:16,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:16,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:17,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:17,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:17,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:18,224][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.9754, device='cuda:0') eval_epoch_loss=tensor(1.0904, device='cuda:0') eval_epoch_acc=tensor(0.7292, device='cuda:0')
[2024-11-29 03:07:18,225][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:07:18,226][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:07:18,440][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_3_step_568_loss_1.0903743505477905/model.pt
[2024-11-29 03:07:18,443][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.0903743505477905
[2024-11-29 03:07:18,443][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.729216992855072
[2024-11-29 03:07:18,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:18,677][root][INFO] - Training Epoch: 3/10, step 568/574 completed (loss: 0.09403911978006363, acc: 0.9629629850387573)
[2024-11-29 03:07:18,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:18,961][root][INFO] - Training Epoch: 3/10, step 569/574 completed (loss: 1.0122320652008057, acc: 0.7326202988624573)
[2024-11-29 03:07:19,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:19,168][root][INFO] - Training Epoch: 3/10, step 570/574 completed (loss: 0.2637525498867035, acc: 0.9193548560142517)
[2024-11-29 03:07:19,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:19,395][root][INFO] - Training Epoch: 3/10, step 571/574 completed (loss: 0.9128954410552979, acc: 0.7948718070983887)
[2024-11-29 03:07:19,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:19,626][root][INFO] - Training Epoch: 3/10, step 572/574 completed (loss: 1.1783257722854614, acc: 0.6887755393981934)
[2024-11-29 03:07:19,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:19,866][root][INFO] - Training Epoch: 3/10, step 573/574 completed (loss: 1.35606050491333, acc: 0.6352201104164124)
[2024-11-29 03:07:20,309][slam_llm.utils.train_utils][INFO] - Epoch 3: train_perplexity=2.6435, train_epoch_loss=0.9721, epoch time 260.87489722669125s
[2024-11-29 03:07:20,309][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 11 GB
[2024-11-29 03:07:20,309][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-11-29 03:07:20,309][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 11 GB
[2024-11-29 03:07:20,309][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 5
[2024-11-29 03:07:20,309][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:07:20,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:21,049][root][INFO] - Training Epoch: 4/10, step 0/574 completed (loss: 0.2525377571582794, acc: 0.9629629850387573)
[2024-11-29 03:07:21,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:21,258][root][INFO] - Training Epoch: 4/10, step 1/574 completed (loss: 0.5391740798950195, acc: 0.8799999952316284)
[2024-11-29 03:07:21,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:21,503][root][INFO] - Training Epoch: 4/10, step 2/574 completed (loss: 0.9581389427185059, acc: 0.7567567825317383)
[2024-11-29 03:07:21,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:21,761][root][INFO] - Training Epoch: 4/10, step 3/574 completed (loss: 0.6538764834403992, acc: 0.8947368264198303)
[2024-11-29 03:07:21,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:21,986][root][INFO] - Training Epoch: 4/10, step 4/574 completed (loss: 0.7105247974395752, acc: 0.7837837934494019)
[2024-11-29 03:07:22,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:22,226][root][INFO] - Training Epoch: 4/10, step 5/574 completed (loss: 0.4358956515789032, acc: 0.8928571343421936)
[2024-11-29 03:07:22,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:22,465][root][INFO] - Training Epoch: 4/10, step 6/574 completed (loss: 1.0992140769958496, acc: 0.7551020383834839)
[2024-11-29 03:07:22,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:22,725][root][INFO] - Training Epoch: 4/10, step 7/574 completed (loss: 0.6573628187179565, acc: 0.7666666507720947)
[2024-11-29 03:07:22,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:22,968][root][INFO] - Training Epoch: 4/10, step 8/574 completed (loss: 0.2508254051208496, acc: 0.9090909361839294)
[2024-11-29 03:07:23,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:23,217][root][INFO] - Training Epoch: 4/10, step 9/574 completed (loss: 0.32572099566459656, acc: 0.9230769276618958)
[2024-11-29 03:07:23,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:23,462][root][INFO] - Training Epoch: 4/10, step 10/574 completed (loss: 0.1409577876329422, acc: 0.9629629850387573)
[2024-11-29 03:07:23,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:23,696][root][INFO] - Training Epoch: 4/10, step 11/574 completed (loss: 0.8570683002471924, acc: 0.8205128312110901)
[2024-11-29 03:07:23,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:23,932][root][INFO] - Training Epoch: 4/10, step 12/574 completed (loss: 0.40734705328941345, acc: 0.8787878751754761)
[2024-11-29 03:07:24,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:24,168][root][INFO] - Training Epoch: 4/10, step 13/574 completed (loss: 0.4454801678657532, acc: 0.8695651888847351)
[2024-11-29 03:07:24,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:24,428][root][INFO] - Training Epoch: 4/10, step 14/574 completed (loss: 0.5759730935096741, acc: 0.8235294222831726)
[2024-11-29 03:07:24,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:24,670][root][INFO] - Training Epoch: 4/10, step 15/574 completed (loss: 0.6979883313179016, acc: 0.795918345451355)
[2024-11-29 03:07:24,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:24,908][root][INFO] - Training Epoch: 4/10, step 16/574 completed (loss: 0.16245399415493011, acc: 0.9473684430122375)
[2024-11-29 03:07:25,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:25,198][root][INFO] - Training Epoch: 4/10, step 17/574 completed (loss: 0.4434947967529297, acc: 0.8333333134651184)
[2024-11-29 03:07:25,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:25,441][root][INFO] - Training Epoch: 4/10, step 18/574 completed (loss: 1.4914228916168213, acc: 0.6666666865348816)
[2024-11-29 03:07:25,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:25,673][root][INFO] - Training Epoch: 4/10, step 19/574 completed (loss: 0.4360836446285248, acc: 0.8947368264198303)
[2024-11-29 03:07:25,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:25,900][root][INFO] - Training Epoch: 4/10, step 20/574 completed (loss: 0.6309388875961304, acc: 0.8461538553237915)
[2024-11-29 03:07:25,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:26,113][root][INFO] - Training Epoch: 4/10, step 21/574 completed (loss: 0.569099485874176, acc: 0.8275862336158752)
[2024-11-29 03:07:26,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:26,302][root][INFO] - Training Epoch: 4/10, step 22/574 completed (loss: 0.4807383716106415, acc: 0.8799999952316284)
[2024-11-29 03:07:26,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:26,510][root][INFO] - Training Epoch: 4/10, step 23/574 completed (loss: 0.22657862305641174, acc: 0.9523809552192688)
[2024-11-29 03:07:26,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:26,749][root][INFO] - Training Epoch: 4/10, step 24/574 completed (loss: 0.4371987581253052, acc: 0.9375)
[2024-11-29 03:07:26,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:26,990][root][INFO] - Training Epoch: 4/10, step 25/574 completed (loss: 1.1052320003509521, acc: 0.698113203048706)
[2024-11-29 03:07:27,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:27,223][root][INFO] - Training Epoch: 4/10, step 26/574 completed (loss: 1.1554604768753052, acc: 0.6849315166473389)
[2024-11-29 03:07:27,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:28,368][root][INFO] - Training Epoch: 4/10, step 27/574 completed (loss: 1.841569185256958, acc: 0.5691699385643005)
[2024-11-29 03:07:28,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:28,546][root][INFO] - Training Epoch: 4/10, step 28/574 completed (loss: 0.7415117621421814, acc: 0.7674418687820435)
[2024-11-29 03:07:28,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:28,744][root][INFO] - Training Epoch: 4/10, step 29/574 completed (loss: 1.0520049333572388, acc: 0.7108433842658997)
[2024-11-29 03:07:28,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:28,962][root][INFO] - Training Epoch: 4/10, step 30/574 completed (loss: 1.233504056930542, acc: 0.7160493731498718)
[2024-11-29 03:07:29,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:29,180][root][INFO] - Training Epoch: 4/10, step 31/574 completed (loss: 0.5836955308914185, acc: 0.8571428656578064)
[2024-11-29 03:07:29,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:29,443][root][INFO] - Training Epoch: 4/10, step 32/574 completed (loss: 0.31638795137405396, acc: 0.9259259104728699)
[2024-11-29 03:07:29,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:29,696][root][INFO] - Training Epoch: 4/10, step 33/574 completed (loss: 0.12748703360557556, acc: 0.95652174949646)
[2024-11-29 03:07:29,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:29,943][root][INFO] - Training Epoch: 4/10, step 34/574 completed (loss: 0.8779976963996887, acc: 0.8067227005958557)
[2024-11-29 03:07:30,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:30,166][root][INFO] - Training Epoch: 4/10, step 35/574 completed (loss: 0.640899121761322, acc: 0.8360655903816223)
[2024-11-29 03:07:30,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:30,424][root][INFO] - Training Epoch: 4/10, step 36/574 completed (loss: 0.8298112154006958, acc: 0.7936508059501648)
[2024-11-29 03:07:30,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:30,649][root][INFO] - Training Epoch: 4/10, step 37/574 completed (loss: 0.6344446539878845, acc: 0.8305084705352783)
[2024-11-29 03:07:30,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:30,910][root][INFO] - Training Epoch: 4/10, step 38/574 completed (loss: 0.5965688824653625, acc: 0.8160919547080994)
[2024-11-29 03:07:31,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:31,139][root][INFO] - Training Epoch: 4/10, step 39/574 completed (loss: 0.6603816151618958, acc: 0.9047619104385376)
[2024-11-29 03:07:31,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:31,410][root][INFO] - Training Epoch: 4/10, step 40/574 completed (loss: 0.3917328119277954, acc: 0.8846153616905212)
[2024-11-29 03:07:31,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:31,682][root][INFO] - Training Epoch: 4/10, step 41/574 completed (loss: 0.7246792912483215, acc: 0.7837837934494019)
[2024-11-29 03:07:31,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:31,921][root][INFO] - Training Epoch: 4/10, step 42/574 completed (loss: 1.1759482622146606, acc: 0.6615384817123413)
[2024-11-29 03:07:32,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:32,238][root][INFO] - Training Epoch: 4/10, step 43/574 completed (loss: 1.0846093893051147, acc: 0.6969696879386902)
[2024-11-29 03:07:32,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:32,540][root][INFO] - Training Epoch: 4/10, step 44/574 completed (loss: 0.8997547030448914, acc: 0.7525773048400879)
[2024-11-29 03:07:32,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:32,829][root][INFO] - Training Epoch: 4/10, step 45/574 completed (loss: 0.9493685364723206, acc: 0.7426470518112183)
[2024-11-29 03:07:32,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:33,085][root][INFO] - Training Epoch: 4/10, step 46/574 completed (loss: 0.40258294343948364, acc: 0.9230769276618958)
[2024-11-29 03:07:33,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:33,335][root][INFO] - Training Epoch: 4/10, step 47/574 completed (loss: 0.19203956425189972, acc: 0.9629629850387573)
[2024-11-29 03:07:33,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:33,577][root][INFO] - Training Epoch: 4/10, step 48/574 completed (loss: 0.15478363633155823, acc: 0.9642857313156128)
[2024-11-29 03:07:33,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:33,787][root][INFO] - Training Epoch: 4/10, step 49/574 completed (loss: 0.19942942261695862, acc: 0.9722222089767456)
[2024-11-29 03:07:33,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:33,976][root][INFO] - Training Epoch: 4/10, step 50/574 completed (loss: 1.0015521049499512, acc: 0.7543859481811523)
[2024-11-29 03:07:34,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:34,215][root][INFO] - Training Epoch: 4/10, step 51/574 completed (loss: 1.2121732234954834, acc: 0.6984127163887024)
[2024-11-29 03:07:34,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:34,472][root][INFO] - Training Epoch: 4/10, step 52/574 completed (loss: 1.1430824995040894, acc: 0.6760563254356384)
[2024-11-29 03:07:34,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:34,861][root][INFO] - Training Epoch: 4/10, step 53/574 completed (loss: 2.054696559906006, acc: 0.4533333480358124)
[2024-11-29 03:07:34,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:35,056][root][INFO] - Training Epoch: 4/10, step 54/574 completed (loss: 1.3944690227508545, acc: 0.7297297120094299)
[2024-11-29 03:07:35,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:35,283][root][INFO] - Training Epoch: 4/10, step 55/574 completed (loss: 0.06825582683086395, acc: 1.0)
[2024-11-29 03:07:36,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:37,782][root][INFO] - Training Epoch: 4/10, step 56/574 completed (loss: 1.7901661396026611, acc: 0.511945366859436)
[2024-11-29 03:07:38,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:38,911][root][INFO] - Training Epoch: 4/10, step 57/574 completed (loss: 1.9083181619644165, acc: 0.5228758454322815)
[2024-11-29 03:07:39,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:39,430][root][INFO] - Training Epoch: 4/10, step 58/574 completed (loss: 1.224907398223877, acc: 0.6590909361839294)
[2024-11-29 03:07:39,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:39,905][root][INFO] - Training Epoch: 4/10, step 59/574 completed (loss: 0.8771788477897644, acc: 0.7720588445663452)
[2024-11-29 03:07:40,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:40,371][root][INFO] - Training Epoch: 4/10, step 60/574 completed (loss: 1.03605318069458, acc: 0.739130437374115)
[2024-11-29 03:07:40,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:40,686][root][INFO] - Training Epoch: 4/10, step 61/574 completed (loss: 1.2363321781158447, acc: 0.612500011920929)
[2024-11-29 03:07:40,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:40,872][root][INFO] - Training Epoch: 4/10, step 62/574 completed (loss: 0.3505491316318512, acc: 0.9117646813392639)
[2024-11-29 03:07:40,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:41,121][root][INFO] - Training Epoch: 4/10, step 63/574 completed (loss: 0.4219971299171448, acc: 0.8611111044883728)
[2024-11-29 03:07:41,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:41,376][root][INFO] - Training Epoch: 4/10, step 64/574 completed (loss: 0.24768386781215668, acc: 0.90625)
[2024-11-29 03:07:41,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:41,617][root][INFO] - Training Epoch: 4/10, step 65/574 completed (loss: 0.22937554121017456, acc: 0.931034505367279)
[2024-11-29 03:07:41,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:41,867][root][INFO] - Training Epoch: 4/10, step 66/574 completed (loss: 1.156134843826294, acc: 0.7142857313156128)
[2024-11-29 03:07:41,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:42,101][root][INFO] - Training Epoch: 4/10, step 67/574 completed (loss: 0.860389769077301, acc: 0.800000011920929)
[2024-11-29 03:07:42,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:42,362][root][INFO] - Training Epoch: 4/10, step 68/574 completed (loss: 0.044554729014635086, acc: 1.0)
[2024-11-29 03:07:42,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:42,612][root][INFO] - Training Epoch: 4/10, step 69/574 completed (loss: 1.0693213939666748, acc: 0.6944444179534912)
[2024-11-29 03:07:42,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:42,869][root][INFO] - Training Epoch: 4/10, step 70/574 completed (loss: 0.8906059265136719, acc: 0.6969696879386902)
[2024-11-29 03:07:42,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:43,117][root][INFO] - Training Epoch: 4/10, step 71/574 completed (loss: 1.6657073497772217, acc: 0.5808823704719543)
[2024-11-29 03:07:43,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:43,357][root][INFO] - Training Epoch: 4/10, step 72/574 completed (loss: 1.2432650327682495, acc: 0.6507936716079712)
[2024-11-29 03:07:43,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:43,653][root][INFO] - Training Epoch: 4/10, step 73/574 completed (loss: 1.9482288360595703, acc: 0.5128205418586731)
[2024-11-29 03:07:43,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:43,910][root][INFO] - Training Epoch: 4/10, step 74/574 completed (loss: 1.5596776008605957, acc: 0.581632673740387)
[2024-11-29 03:07:44,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:44,163][root][INFO] - Training Epoch: 4/10, step 75/574 completed (loss: 1.5333415269851685, acc: 0.5597015023231506)
[2024-11-29 03:07:44,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:44,463][root][INFO] - Training Epoch: 4/10, step 76/574 completed (loss: 1.9533475637435913, acc: 0.5072992444038391)
[2024-11-29 03:07:44,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:44,695][root][INFO] - Training Epoch: 4/10, step 77/574 completed (loss: 0.03839529678225517, acc: 1.0)
[2024-11-29 03:07:44,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:44,917][root][INFO] - Training Epoch: 4/10, step 78/574 completed (loss: 0.2873418629169464, acc: 0.9166666865348816)
[2024-11-29 03:07:45,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:45,136][root][INFO] - Training Epoch: 4/10, step 79/574 completed (loss: 0.23374435305595398, acc: 0.939393937587738)
[2024-11-29 03:07:45,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:45,329][root][INFO] - Training Epoch: 4/10, step 80/574 completed (loss: 0.18208584189414978, acc: 0.9230769276618958)
[2024-11-29 03:07:45,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:45,570][root][INFO] - Training Epoch: 4/10, step 81/574 completed (loss: 0.8209715485572815, acc: 0.8269230723381042)
[2024-11-29 03:07:45,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:45,789][root][INFO] - Training Epoch: 4/10, step 82/574 completed (loss: 0.9654572010040283, acc: 0.75)
[2024-11-29 03:07:45,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:46,033][root][INFO] - Training Epoch: 4/10, step 83/574 completed (loss: 0.23828184604644775, acc: 0.9375)
[2024-11-29 03:07:46,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:46,279][root][INFO] - Training Epoch: 4/10, step 84/574 completed (loss: 0.704264760017395, acc: 0.8405796885490417)
[2024-11-29 03:07:46,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:46,535][root][INFO] - Training Epoch: 4/10, step 85/574 completed (loss: 0.7300864458084106, acc: 0.800000011920929)
[2024-11-29 03:07:46,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:46,762][root][INFO] - Training Epoch: 4/10, step 86/574 completed (loss: 0.07139288634061813, acc: 1.0)
[2024-11-29 03:07:46,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:47,152][root][INFO] - Training Epoch: 4/10, step 87/574 completed (loss: 1.4976366758346558, acc: 0.6600000262260437)
[2024-11-29 03:07:47,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:47,404][root][INFO] - Training Epoch: 4/10, step 88/574 completed (loss: 1.4049904346466064, acc: 0.6504854559898376)
[2024-11-29 03:07:47,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:48,468][root][INFO] - Training Epoch: 4/10, step 89/574 completed (loss: 1.291205644607544, acc: 0.6796116232872009)
[2024-11-29 03:07:48,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:49,169][root][INFO] - Training Epoch: 4/10, step 90/574 completed (loss: 1.8308161497116089, acc: 0.5161290168762207)
[2024-11-29 03:07:49,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:49,849][root][INFO] - Training Epoch: 4/10, step 91/574 completed (loss: 1.4717034101486206, acc: 0.6206896305084229)
[2024-11-29 03:07:50,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:50,480][root][INFO] - Training Epoch: 4/10, step 92/574 completed (loss: 1.1892204284667969, acc: 0.7263157963752747)
[2024-11-29 03:07:50,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:51,347][root][INFO] - Training Epoch: 4/10, step 93/574 completed (loss: 1.9942291975021362, acc: 0.48514851927757263)
[2024-11-29 03:07:51,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:51,635][root][INFO] - Training Epoch: 4/10, step 94/574 completed (loss: 1.4360121488571167, acc: 0.5967742204666138)
[2024-11-29 03:07:51,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:51,878][root][INFO] - Training Epoch: 4/10, step 95/574 completed (loss: 1.0123205184936523, acc: 0.7101449370384216)
[2024-11-29 03:07:51,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:52,144][root][INFO] - Training Epoch: 4/10, step 96/574 completed (loss: 1.6120262145996094, acc: 0.5378151535987854)
[2024-11-29 03:07:52,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:52,404][root][INFO] - Training Epoch: 4/10, step 97/574 completed (loss: 1.8733115196228027, acc: 0.48076921701431274)
[2024-11-29 03:07:52,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:52,686][root][INFO] - Training Epoch: 4/10, step 98/574 completed (loss: 1.900924563407898, acc: 0.47445255517959595)
[2024-11-29 03:07:52,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:52,917][root][INFO] - Training Epoch: 4/10, step 99/574 completed (loss: 1.919406771659851, acc: 0.447761207818985)
[2024-11-29 03:07:52,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:53,092][root][INFO] - Training Epoch: 4/10, step 100/574 completed (loss: 0.27563008666038513, acc: 0.8999999761581421)
[2024-11-29 03:07:53,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:53,335][root][INFO] - Training Epoch: 4/10, step 101/574 completed (loss: 0.04865250736474991, acc: 1.0)
[2024-11-29 03:07:53,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:53,571][root][INFO] - Training Epoch: 4/10, step 102/574 completed (loss: 0.1113826110959053, acc: 1.0)
[2024-11-29 03:07:53,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:53,832][root][INFO] - Training Epoch: 4/10, step 103/574 completed (loss: 0.10093415528535843, acc: 0.9545454382896423)
[2024-11-29 03:07:53,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:54,107][root][INFO] - Training Epoch: 4/10, step 104/574 completed (loss: 0.9601033926010132, acc: 0.7586206793785095)
[2024-11-29 03:07:54,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:54,346][root][INFO] - Training Epoch: 4/10, step 105/574 completed (loss: 0.38485488295555115, acc: 0.8837209343910217)
[2024-11-29 03:07:54,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:54,591][root][INFO] - Training Epoch: 4/10, step 106/574 completed (loss: 0.42467594146728516, acc: 0.9200000166893005)
[2024-11-29 03:07:54,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:54,838][root][INFO] - Training Epoch: 4/10, step 107/574 completed (loss: 0.04848539084196091, acc: 1.0)
[2024-11-29 03:07:54,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:55,068][root][INFO] - Training Epoch: 4/10, step 108/574 completed (loss: 0.04795875400304794, acc: 1.0)
[2024-11-29 03:07:55,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:55,305][root][INFO] - Training Epoch: 4/10, step 109/574 completed (loss: 0.18284466862678528, acc: 0.9285714030265808)
[2024-11-29 03:07:55,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:55,533][root][INFO] - Training Epoch: 4/10, step 110/574 completed (loss: 0.22409102320671082, acc: 0.9384615421295166)
[2024-11-29 03:07:55,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:55,834][root][INFO] - Training Epoch: 4/10, step 111/574 completed (loss: 0.7506913542747498, acc: 0.7719298005104065)
[2024-11-29 03:07:55,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:56,097][root][INFO] - Training Epoch: 4/10, step 112/574 completed (loss: 1.0488810539245605, acc: 0.719298243522644)
[2024-11-29 03:07:56,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:56,341][root][INFO] - Training Epoch: 4/10, step 113/574 completed (loss: 0.5095459222793579, acc: 0.8461538553237915)
[2024-11-29 03:07:56,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:56,607][root][INFO] - Training Epoch: 4/10, step 114/574 completed (loss: 0.44623157382011414, acc: 0.8979591727256775)
[2024-11-29 03:07:56,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:56,855][root][INFO] - Training Epoch: 4/10, step 115/574 completed (loss: 0.1953554004430771, acc: 0.9090909361839294)
[2024-11-29 03:07:56,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:57,107][root][INFO] - Training Epoch: 4/10, step 116/574 completed (loss: 0.6976410746574402, acc: 0.841269850730896)
[2024-11-29 03:07:57,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:57,365][root][INFO] - Training Epoch: 4/10, step 117/574 completed (loss: 0.9508711099624634, acc: 0.7479674816131592)
[2024-11-29 03:07:57,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:57,583][root][INFO] - Training Epoch: 4/10, step 118/574 completed (loss: 0.40391209721565247, acc: 0.8709677457809448)
[2024-11-29 03:07:57,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:58,340][root][INFO] - Training Epoch: 4/10, step 119/574 completed (loss: 1.6316088438034058, acc: 0.5931559205055237)
[2024-11-29 03:07:58,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:58,547][root][INFO] - Training Epoch: 4/10, step 120/574 completed (loss: 0.6076942086219788, acc: 0.8399999737739563)
[2024-11-29 03:07:58,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:58,840][root][INFO] - Training Epoch: 4/10, step 121/574 completed (loss: 0.8200773000717163, acc: 0.7884615659713745)
[2024-11-29 03:07:58,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:59,051][root][INFO] - Training Epoch: 4/10, step 122/574 completed (loss: 0.2528124153614044, acc: 0.9583333134651184)
[2024-11-29 03:07:59,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:59,258][root][INFO] - Training Epoch: 4/10, step 123/574 completed (loss: 0.8391808271408081, acc: 0.7368420958518982)
[2024-11-29 03:07:59,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:59,499][root][INFO] - Training Epoch: 4/10, step 124/574 completed (loss: 1.8314777612686157, acc: 0.546012282371521)
[2024-11-29 03:07:59,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:59,771][root][INFO] - Training Epoch: 4/10, step 125/574 completed (loss: 1.632458209991455, acc: 0.5902777910232544)
[2024-11-29 03:07:59,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:00,068][root][INFO] - Training Epoch: 4/10, step 126/574 completed (loss: 1.5418217182159424, acc: 0.5833333134651184)
[2024-11-29 03:08:00,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:00,325][root][INFO] - Training Epoch: 4/10, step 127/574 completed (loss: 1.7028112411499023, acc: 0.5535714030265808)
[2024-11-29 03:08:00,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:00,542][root][INFO] - Training Epoch: 4/10, step 128/574 completed (loss: 1.543250322341919, acc: 0.6358974575996399)
[2024-11-29 03:08:00,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:00,840][root][INFO] - Training Epoch: 4/10, step 129/574 completed (loss: 1.6478220224380493, acc: 0.5588235259056091)
[2024-11-29 03:08:00,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:01,014][root][INFO] - Training Epoch: 4/10, step 130/574 completed (loss: 0.8860096335411072, acc: 0.692307710647583)
[2024-11-29 03:08:01,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:01,291][root][INFO] - Training Epoch: 4/10, step 131/574 completed (loss: 0.6304194331169128, acc: 0.9130434989929199)
[2024-11-29 03:08:01,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:01,578][root][INFO] - Training Epoch: 4/10, step 132/574 completed (loss: 1.5719916820526123, acc: 0.59375)
[2024-11-29 03:08:01,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:01,808][root][INFO] - Training Epoch: 4/10, step 133/574 completed (loss: 0.8641812801361084, acc: 0.739130437374115)
[2024-11-29 03:08:01,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:02,056][root][INFO] - Training Epoch: 4/10, step 134/574 completed (loss: 0.8548057675361633, acc: 0.8285714387893677)
[2024-11-29 03:08:02,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:02,297][root][INFO] - Training Epoch: 4/10, step 135/574 completed (loss: 0.6989859342575073, acc: 0.807692289352417)
[2024-11-29 03:08:02,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:02,536][root][INFO] - Training Epoch: 4/10, step 136/574 completed (loss: 1.1192221641540527, acc: 0.738095223903656)
[2024-11-29 03:08:03,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:03,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:03,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:04,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:04,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:04,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:04,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:05,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:05,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:05,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:06,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:06,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:06,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:06,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:07,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:07,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:07,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:08,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:08,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:08,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:08,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:08,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:09,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:09,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:09,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:09,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:10,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:10,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:10,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:10,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:11,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:11,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:11,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:12,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:12,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:12,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:12,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:13,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:13,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:13,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:14,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:14,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:14,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:15,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:15,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:15,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:15,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:16,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:16,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:16,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:16,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:17,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:17,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:17,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:18,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:18,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:18,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:18,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:19,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:19,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:19,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:20,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:20,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:20,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:21,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:21,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:21,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:22,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:22,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:22,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:23,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:23,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:23,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:23,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:24,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:24,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:24,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:25,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:25,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:25,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:25,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:26,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:26,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:26,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:26,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:27,435][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.9301, device='cuda:0') eval_epoch_loss=tensor(1.0750, device='cuda:0') eval_epoch_acc=tensor(0.7182, device='cuda:0')
[2024-11-29 03:08:27,436][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:08:27,436][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:08:27,649][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_4_step_137_loss_1.0750385522842407/model.pt
[2024-11-29 03:08:27,654][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 4 is 1.0750385522842407
[2024-11-29 03:08:27,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:27,965][root][INFO] - Training Epoch: 4/10, step 137/574 completed (loss: 1.3578699827194214, acc: 0.6666666865348816)
[2024-11-29 03:08:28,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:28,145][root][INFO] - Training Epoch: 4/10, step 138/574 completed (loss: 0.40388527512550354, acc: 0.8695651888847351)
[2024-11-29 03:08:28,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:28,356][root][INFO] - Training Epoch: 4/10, step 139/574 completed (loss: 0.6406857371330261, acc: 0.7142857313156128)
[2024-11-29 03:08:28,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:28,558][root][INFO] - Training Epoch: 4/10, step 140/574 completed (loss: 0.37639257311820984, acc: 0.8846153616905212)
[2024-11-29 03:08:28,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:28,767][root][INFO] - Training Epoch: 4/10, step 141/574 completed (loss: 0.8723822236061096, acc: 0.8064516186714172)
[2024-11-29 03:08:28,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:29,045][root][INFO] - Training Epoch: 4/10, step 142/574 completed (loss: 0.7364850044250488, acc: 0.7837837934494019)
[2024-11-29 03:08:29,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:29,513][root][INFO] - Training Epoch: 4/10, step 143/574 completed (loss: 1.0774097442626953, acc: 0.7105262875556946)
[2024-11-29 03:08:29,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:29,749][root][INFO] - Training Epoch: 4/10, step 144/574 completed (loss: 1.153905987739563, acc: 0.6940298676490784)
[2024-11-29 03:08:29,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:29,997][root][INFO] - Training Epoch: 4/10, step 145/574 completed (loss: 0.964081346988678, acc: 0.7448979616165161)
[2024-11-29 03:08:30,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:30,355][root][INFO] - Training Epoch: 4/10, step 146/574 completed (loss: 1.3124343156814575, acc: 0.5531914830207825)
[2024-11-29 03:08:30,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:30,551][root][INFO] - Training Epoch: 4/10, step 147/574 completed (loss: 0.8758945465087891, acc: 0.7285714149475098)
[2024-11-29 03:08:30,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:30,760][root][INFO] - Training Epoch: 4/10, step 148/574 completed (loss: 0.6169373393058777, acc: 0.8571428656578064)
[2024-11-29 03:08:30,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:30,943][root][INFO] - Training Epoch: 4/10, step 149/574 completed (loss: 0.7275886535644531, acc: 0.739130437374115)
[2024-11-29 03:08:31,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:31,168][root][INFO] - Training Epoch: 4/10, step 150/574 completed (loss: 1.1473259925842285, acc: 0.6551724076271057)
[2024-11-29 03:08:31,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:31,397][root][INFO] - Training Epoch: 4/10, step 151/574 completed (loss: 1.102268099784851, acc: 0.695652186870575)
[2024-11-29 03:08:31,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:31,622][root][INFO] - Training Epoch: 4/10, step 152/574 completed (loss: 0.9158582091331482, acc: 0.7796609997749329)
[2024-11-29 03:08:31,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:31,831][root][INFO] - Training Epoch: 4/10, step 153/574 completed (loss: 1.2800943851470947, acc: 0.6666666865348816)
[2024-11-29 03:08:31,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:32,107][root][INFO] - Training Epoch: 4/10, step 154/574 completed (loss: 0.8397725820541382, acc: 0.7972972989082336)
[2024-11-29 03:08:32,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:32,358][root][INFO] - Training Epoch: 4/10, step 155/574 completed (loss: 0.23324966430664062, acc: 0.9642857313156128)
[2024-11-29 03:08:32,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:32,570][root][INFO] - Training Epoch: 4/10, step 156/574 completed (loss: 0.4947517216205597, acc: 0.8695651888847351)
[2024-11-29 03:08:32,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:32,809][root][INFO] - Training Epoch: 4/10, step 157/574 completed (loss: 2.8259196281433105, acc: 0.42105263471603394)
[2024-11-29 03:08:33,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:34,475][root][INFO] - Training Epoch: 4/10, step 158/574 completed (loss: 1.692627191543579, acc: 0.5270270109176636)
[2024-11-29 03:08:34,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:34,702][root][INFO] - Training Epoch: 4/10, step 159/574 completed (loss: 2.0523130893707275, acc: 0.40740740299224854)
[2024-11-29 03:08:34,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:35,035][root][INFO] - Training Epoch: 4/10, step 160/574 completed (loss: 2.0017898082733154, acc: 0.5116279125213623)
[2024-11-29 03:08:35,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:35,551][root][INFO] - Training Epoch: 4/10, step 161/574 completed (loss: 2.122178077697754, acc: 0.47058823704719543)
[2024-11-29 03:08:35,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:36,023][root][INFO] - Training Epoch: 4/10, step 162/574 completed (loss: 2.0980749130249023, acc: 0.483146071434021)
[2024-11-29 03:08:36,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:36,225][root][INFO] - Training Epoch: 4/10, step 163/574 completed (loss: 0.8641887903213501, acc: 0.7727272510528564)
[2024-11-29 03:08:36,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:36,422][root][INFO] - Training Epoch: 4/10, step 164/574 completed (loss: 0.6753058433532715, acc: 0.8571428656578064)
[2024-11-29 03:08:36,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:36,633][root][INFO] - Training Epoch: 4/10, step 165/574 completed (loss: 1.5281161069869995, acc: 0.6206896305084229)
[2024-11-29 03:08:36,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:36,859][root][INFO] - Training Epoch: 4/10, step 166/574 completed (loss: 0.3417906165122986, acc: 0.8571428656578064)
[2024-11-29 03:08:36,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:37,061][root][INFO] - Training Epoch: 4/10, step 167/574 completed (loss: 0.23633036017417908, acc: 0.9399999976158142)
[2024-11-29 03:08:37,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:37,379][root][INFO] - Training Epoch: 4/10, step 168/574 completed (loss: 0.6317188143730164, acc: 0.8055555820465088)
[2024-11-29 03:08:37,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:37,609][root][INFO] - Training Epoch: 4/10, step 169/574 completed (loss: 1.299507737159729, acc: 0.6960784196853638)
[2024-11-29 03:08:37,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:38,587][root][INFO] - Training Epoch: 4/10, step 170/574 completed (loss: 1.7102726697921753, acc: 0.6164383292198181)
[2024-11-29 03:08:38,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:38,761][root][INFO] - Training Epoch: 4/10, step 171/574 completed (loss: 0.1361890435218811, acc: 1.0)
[2024-11-29 03:08:38,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:38,987][root][INFO] - Training Epoch: 4/10, step 172/574 completed (loss: 0.9313651919364929, acc: 0.8888888955116272)
[2024-11-29 03:08:39,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:39,252][root][INFO] - Training Epoch: 4/10, step 173/574 completed (loss: 0.6837936043739319, acc: 0.8214285969734192)
[2024-11-29 03:08:39,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:39,716][root][INFO] - Training Epoch: 4/10, step 174/574 completed (loss: 1.4471036195755005, acc: 0.6283186078071594)
[2024-11-29 03:08:39,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:39,912][root][INFO] - Training Epoch: 4/10, step 175/574 completed (loss: 1.3893723487854004, acc: 0.6086956262588501)
[2024-11-29 03:08:39,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:40,128][root][INFO] - Training Epoch: 4/10, step 176/574 completed (loss: 0.7050406336784363, acc: 0.7613636255264282)
[2024-11-29 03:08:40,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:40,978][root][INFO] - Training Epoch: 4/10, step 177/574 completed (loss: 1.7071528434753418, acc: 0.5877862572669983)
[2024-11-29 03:08:41,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:41,552][root][INFO] - Training Epoch: 4/10, step 178/574 completed (loss: 1.44442880153656, acc: 0.6074073910713196)
[2024-11-29 03:08:41,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:41,794][root][INFO] - Training Epoch: 4/10, step 179/574 completed (loss: 0.7547001242637634, acc: 0.8032786846160889)
[2024-11-29 03:08:41,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:42,040][root][INFO] - Training Epoch: 4/10, step 180/574 completed (loss: 0.052654970437288284, acc: 1.0)
[2024-11-29 03:08:42,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:42,314][root][INFO] - Training Epoch: 4/10, step 181/574 completed (loss: 0.0453813299536705, acc: 1.0)
[2024-11-29 03:08:42,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:42,541][root][INFO] - Training Epoch: 4/10, step 182/574 completed (loss: 0.08303222805261612, acc: 1.0)
[2024-11-29 03:08:42,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:42,813][root][INFO] - Training Epoch: 4/10, step 183/574 completed (loss: 0.5490022897720337, acc: 0.8048780560493469)
[2024-11-29 03:08:42,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:43,057][root][INFO] - Training Epoch: 4/10, step 184/574 completed (loss: 1.1009293794631958, acc: 0.7613292932510376)
[2024-11-29 03:08:43,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:43,284][root][INFO] - Training Epoch: 4/10, step 185/574 completed (loss: 1.208713173866272, acc: 0.6858789920806885)
[2024-11-29 03:08:43,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:43,678][root][INFO] - Training Epoch: 4/10, step 186/574 completed (loss: 1.178243637084961, acc: 0.6937500238418579)
[2024-11-29 03:08:43,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:44,105][root][INFO] - Training Epoch: 4/10, step 187/574 completed (loss: 1.3859204053878784, acc: 0.6604127287864685)
[2024-11-29 03:08:44,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:44,414][root][INFO] - Training Epoch: 4/10, step 188/574 completed (loss: 1.1442209482192993, acc: 0.6797152757644653)
[2024-11-29 03:08:44,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:44,614][root][INFO] - Training Epoch: 4/10, step 189/574 completed (loss: 0.5198286771774292, acc: 0.8799999952316284)
[2024-11-29 03:08:44,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:45,084][root][INFO] - Training Epoch: 4/10, step 190/574 completed (loss: 1.1537177562713623, acc: 0.6162790656089783)
[2024-11-29 03:08:45,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:45,779][root][INFO] - Training Epoch: 4/10, step 191/574 completed (loss: 1.7423412799835205, acc: 0.579365074634552)
[2024-11-29 03:08:46,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:46,586][root][INFO] - Training Epoch: 4/10, step 192/574 completed (loss: 1.6164743900299072, acc: 0.5681818127632141)
[2024-11-29 03:08:46,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:47,232][root][INFO] - Training Epoch: 4/10, step 193/574 completed (loss: 0.9788358807563782, acc: 0.7058823704719543)
[2024-11-29 03:08:47,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:48,191][root][INFO] - Training Epoch: 4/10, step 194/574 completed (loss: 1.4300076961517334, acc: 0.6234567761421204)
[2024-11-29 03:08:48,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:49,039][root][INFO] - Training Epoch: 4/10, step 195/574 completed (loss: 0.7803137302398682, acc: 0.7419354915618896)
[2024-11-29 03:08:49,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:49,285][root][INFO] - Training Epoch: 4/10, step 196/574 completed (loss: 0.10994869470596313, acc: 0.9642857313156128)
[2024-11-29 03:08:49,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:49,521][root][INFO] - Training Epoch: 4/10, step 197/574 completed (loss: 1.0224331617355347, acc: 0.75)
[2024-11-29 03:08:49,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:49,772][root][INFO] - Training Epoch: 4/10, step 198/574 completed (loss: 1.0774013996124268, acc: 0.6470588445663452)
[2024-11-29 03:08:49,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:49,999][root][INFO] - Training Epoch: 4/10, step 199/574 completed (loss: 1.3646248579025269, acc: 0.6617646813392639)
[2024-11-29 03:08:50,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:50,239][root][INFO] - Training Epoch: 4/10, step 200/574 completed (loss: 1.312703251838684, acc: 0.6525423526763916)
[2024-11-29 03:08:50,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:50,470][root][INFO] - Training Epoch: 4/10, step 201/574 completed (loss: 1.214903473854065, acc: 0.6865671873092651)
[2024-11-29 03:08:50,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:50,699][root][INFO] - Training Epoch: 4/10, step 202/574 completed (loss: 1.236492395401001, acc: 0.6601941585540771)
[2024-11-29 03:08:50,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:50,925][root][INFO] - Training Epoch: 4/10, step 203/574 completed (loss: 0.9166864156723022, acc: 0.7460317611694336)
[2024-11-29 03:08:51,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:51,163][root][INFO] - Training Epoch: 4/10, step 204/574 completed (loss: 0.4207525849342346, acc: 0.8791208863258362)
[2024-11-29 03:08:51,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:51,445][root][INFO] - Training Epoch: 4/10, step 205/574 completed (loss: 0.7658928632736206, acc: 0.7533632516860962)
[2024-11-29 03:08:51,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:51,743][root][INFO] - Training Epoch: 4/10, step 206/574 completed (loss: 1.1577211618423462, acc: 0.6929134130477905)
[2024-11-29 03:08:51,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:51,963][root][INFO] - Training Epoch: 4/10, step 207/574 completed (loss: 0.7660066485404968, acc: 0.7844827771186829)
[2024-11-29 03:08:52,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:52,200][root][INFO] - Training Epoch: 4/10, step 208/574 completed (loss: 0.7993910312652588, acc: 0.8152173757553101)
[2024-11-29 03:08:52,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:52,455][root][INFO] - Training Epoch: 4/10, step 209/574 completed (loss: 0.858113706111908, acc: 0.7626459002494812)
[2024-11-29 03:08:52,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:52,662][root][INFO] - Training Epoch: 4/10, step 210/574 completed (loss: 0.7976978421211243, acc: 0.79347825050354)
[2024-11-29 03:08:52,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:52,859][root][INFO] - Training Epoch: 4/10, step 211/574 completed (loss: 0.21653328835964203, acc: 1.0)
[2024-11-29 03:08:52,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:53,060][root][INFO] - Training Epoch: 4/10, step 212/574 completed (loss: 0.38631346821784973, acc: 0.8928571343421936)
[2024-11-29 03:08:53,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:53,303][root][INFO] - Training Epoch: 4/10, step 213/574 completed (loss: 0.6946774125099182, acc: 0.8510638475418091)
[2024-11-29 03:08:53,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:53,892][root][INFO] - Training Epoch: 4/10, step 214/574 completed (loss: 0.472631573677063, acc: 0.9230769276618958)
[2024-11-29 03:08:53,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:54,113][root][INFO] - Training Epoch: 4/10, step 215/574 completed (loss: 0.32267794013023376, acc: 0.9189189076423645)
[2024-11-29 03:08:54,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:54,324][root][INFO] - Training Epoch: 4/10, step 216/574 completed (loss: 0.26320090889930725, acc: 0.9186046719551086)
[2024-11-29 03:08:54,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:54,772][root][INFO] - Training Epoch: 4/10, step 217/574 completed (loss: 0.33327460289001465, acc: 0.9099099040031433)
[2024-11-29 03:08:54,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:55,071][root][INFO] - Training Epoch: 4/10, step 218/574 completed (loss: 0.35938242077827454, acc: 0.8999999761581421)
[2024-11-29 03:08:55,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:55,268][root][INFO] - Training Epoch: 4/10, step 219/574 completed (loss: 0.20010586082935333, acc: 0.939393937587738)
[2024-11-29 03:08:55,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:55,481][root][INFO] - Training Epoch: 4/10, step 220/574 completed (loss: 0.16784341633319855, acc: 0.9259259104728699)
[2024-11-29 03:08:55,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:55,708][root][INFO] - Training Epoch: 4/10, step 221/574 completed (loss: 0.09968563914299011, acc: 1.0)
[2024-11-29 03:08:55,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:55,951][root][INFO] - Training Epoch: 4/10, step 222/574 completed (loss: 1.0018978118896484, acc: 0.692307710647583)
[2024-11-29 03:08:56,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:56,611][root][INFO] - Training Epoch: 4/10, step 223/574 completed (loss: 0.9051364660263062, acc: 0.79347825050354)
[2024-11-29 03:08:56,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:57,068][root][INFO] - Training Epoch: 4/10, step 224/574 completed (loss: 0.9096066951751709, acc: 0.7613636255264282)
[2024-11-29 03:08:57,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:57,416][root][INFO] - Training Epoch: 4/10, step 225/574 completed (loss: 1.088686227798462, acc: 0.7234042286872864)
[2024-11-29 03:08:57,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:57,657][root][INFO] - Training Epoch: 4/10, step 226/574 completed (loss: 0.785391628742218, acc: 0.7547169923782349)
[2024-11-29 03:08:57,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:57,923][root][INFO] - Training Epoch: 4/10, step 227/574 completed (loss: 0.34613049030303955, acc: 0.8999999761581421)
[2024-11-29 03:08:58,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:58,189][root][INFO] - Training Epoch: 4/10, step 228/574 completed (loss: 0.8814775347709656, acc: 0.8139534592628479)
[2024-11-29 03:08:58,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:58,429][root][INFO] - Training Epoch: 4/10, step 229/574 completed (loss: 2.206312417984009, acc: 0.4333333373069763)
[2024-11-29 03:08:58,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:58,690][root][INFO] - Training Epoch: 4/10, step 230/574 completed (loss: 2.740713119506836, acc: 0.28421053290367126)
[2024-11-29 03:08:58,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:58,925][root][INFO] - Training Epoch: 4/10, step 231/574 completed (loss: 2.157219171524048, acc: 0.4444444477558136)
[2024-11-29 03:08:59,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:59,275][root][INFO] - Training Epoch: 4/10, step 232/574 completed (loss: 2.099181890487671, acc: 0.46666666865348816)
[2024-11-29 03:08:59,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:59,693][root][INFO] - Training Epoch: 4/10, step 233/574 completed (loss: 2.424509048461914, acc: 0.4128440320491791)
[2024-11-29 03:08:59,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:00,070][root][INFO] - Training Epoch: 4/10, step 234/574 completed (loss: 2.210611581802368, acc: 0.4923076927661896)
[2024-11-29 03:09:00,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:00,263][root][INFO] - Training Epoch: 4/10, step 235/574 completed (loss: 0.45437636971473694, acc: 0.8947368264198303)
[2024-11-29 03:09:00,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:00,516][root][INFO] - Training Epoch: 4/10, step 236/574 completed (loss: 0.3705085217952728, acc: 0.9166666865348816)
[2024-11-29 03:09:00,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:00,776][root][INFO] - Training Epoch: 4/10, step 237/574 completed (loss: 0.5286427736282349, acc: 0.9090909361839294)
[2024-11-29 03:09:00,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:01,017][root][INFO] - Training Epoch: 4/10, step 238/574 completed (loss: 0.8811475038528442, acc: 0.7407407164573669)
[2024-11-29 03:09:01,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:01,233][root][INFO] - Training Epoch: 4/10, step 239/574 completed (loss: 0.7424482107162476, acc: 0.7142857313156128)
[2024-11-29 03:09:01,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:01,470][root][INFO] - Training Epoch: 4/10, step 240/574 completed (loss: 1.4197640419006348, acc: 0.6818181872367859)
[2024-11-29 03:09:01,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:01,720][root][INFO] - Training Epoch: 4/10, step 241/574 completed (loss: 0.7615786194801331, acc: 0.7272727489471436)
[2024-11-29 03:09:01,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:02,225][root][INFO] - Training Epoch: 4/10, step 242/574 completed (loss: 1.7704890966415405, acc: 0.4838709533214569)
[2024-11-29 03:09:02,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:02,664][root][INFO] - Training Epoch: 4/10, step 243/574 completed (loss: 1.269165277481079, acc: 0.6818181872367859)
[2024-11-29 03:09:02,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:02,859][root][INFO] - Training Epoch: 4/10, step 244/574 completed (loss: 0.10088881105184555, acc: 0.9523809552192688)
[2024-11-29 03:09:02,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:03,091][root][INFO] - Training Epoch: 4/10, step 245/574 completed (loss: 0.7896753549575806, acc: 0.7692307829856873)
[2024-11-29 03:09:03,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:03,318][root][INFO] - Training Epoch: 4/10, step 246/574 completed (loss: 0.21742311120033264, acc: 0.9354838728904724)
[2024-11-29 03:09:03,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:03,570][root][INFO] - Training Epoch: 4/10, step 247/574 completed (loss: 0.29221421480178833, acc: 0.8500000238418579)
[2024-11-29 03:09:03,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:03,843][root][INFO] - Training Epoch: 4/10, step 248/574 completed (loss: 0.7624139785766602, acc: 0.837837815284729)
[2024-11-29 03:09:03,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:04,037][root][INFO] - Training Epoch: 4/10, step 249/574 completed (loss: 0.764801561832428, acc: 0.7837837934494019)
[2024-11-29 03:09:04,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:04,269][root][INFO] - Training Epoch: 4/10, step 250/574 completed (loss: 0.3181028366088867, acc: 0.8918918967247009)
[2024-11-29 03:09:04,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:04,492][root][INFO] - Training Epoch: 4/10, step 251/574 completed (loss: 0.4519961476325989, acc: 0.8529411554336548)
[2024-11-29 03:09:04,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:04,735][root][INFO] - Training Epoch: 4/10, step 252/574 completed (loss: 0.15152637660503387, acc: 0.9512194991111755)
[2024-11-29 03:09:04,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:04,960][root][INFO] - Training Epoch: 4/10, step 253/574 completed (loss: 0.09462513029575348, acc: 1.0)
[2024-11-29 03:09:05,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:05,196][root][INFO] - Training Epoch: 4/10, step 254/574 completed (loss: 0.031213317066431046, acc: 1.0)
[2024-11-29 03:09:05,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:05,462][root][INFO] - Training Epoch: 4/10, step 255/574 completed (loss: 0.15594176948070526, acc: 0.9677419066429138)
[2024-11-29 03:09:05,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:05,693][root][INFO] - Training Epoch: 4/10, step 256/574 completed (loss: 0.42061856389045715, acc: 0.9298245906829834)
[2024-11-29 03:09:05,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:05,929][root][INFO] - Training Epoch: 4/10, step 257/574 completed (loss: 0.2448621243238449, acc: 0.9428571462631226)
[2024-11-29 03:09:06,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:06,175][root][INFO] - Training Epoch: 4/10, step 258/574 completed (loss: 0.19539283215999603, acc: 0.9473684430122375)
[2024-11-29 03:09:06,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:06,676][root][INFO] - Training Epoch: 4/10, step 259/574 completed (loss: 0.8504379391670227, acc: 0.7924528121948242)
[2024-11-29 03:09:06,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:07,168][root][INFO] - Training Epoch: 4/10, step 260/574 completed (loss: 0.8181782960891724, acc: 0.7749999761581421)
[2024-11-29 03:09:07,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:07,392][root][INFO] - Training Epoch: 4/10, step 261/574 completed (loss: 0.16772273182868958, acc: 0.9722222089767456)
[2024-11-29 03:09:07,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:07,628][root][INFO] - Training Epoch: 4/10, step 262/574 completed (loss: 0.5971890091896057, acc: 0.8387096524238586)
[2024-11-29 03:09:07,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:07,895][root][INFO] - Training Epoch: 4/10, step 263/574 completed (loss: 1.6110676527023315, acc: 0.653333306312561)
[2024-11-29 03:09:08,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:08,186][root][INFO] - Training Epoch: 4/10, step 264/574 completed (loss: 1.0891927480697632, acc: 0.6458333134651184)
[2024-11-29 03:09:08,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:08,993][root][INFO] - Training Epoch: 4/10, step 265/574 completed (loss: 1.5641603469848633, acc: 0.6320000290870667)
[2024-11-29 03:09:09,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:09,267][root][INFO] - Training Epoch: 4/10, step 266/574 completed (loss: 1.3355164527893066, acc: 0.6629213690757751)
[2024-11-29 03:09:09,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:09,527][root][INFO] - Training Epoch: 4/10, step 267/574 completed (loss: 1.294525384902954, acc: 0.6351351141929626)
[2024-11-29 03:09:09,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:09,901][root][INFO] - Training Epoch: 4/10, step 268/574 completed (loss: 1.0679423809051514, acc: 0.7413793206214905)
[2024-11-29 03:09:09,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:10,086][root][INFO] - Training Epoch: 4/10, step 269/574 completed (loss: 0.0847356840968132, acc: 1.0)
[2024-11-29 03:09:10,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:10,312][root][INFO] - Training Epoch: 4/10, step 270/574 completed (loss: 0.08607613295316696, acc: 1.0)
[2024-11-29 03:09:10,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:10,536][root][INFO] - Training Epoch: 4/10, step 271/574 completed (loss: 0.16620680689811707, acc: 0.9375)
[2024-11-29 03:09:10,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:10,781][root][INFO] - Training Epoch: 4/10, step 272/574 completed (loss: 0.20898981392383575, acc: 0.9666666388511658)
[2024-11-29 03:09:10,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:11,062][root][INFO] - Training Epoch: 4/10, step 273/574 completed (loss: 0.618617057800293, acc: 0.8166666626930237)
[2024-11-29 03:09:11,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:11,324][root][INFO] - Training Epoch: 4/10, step 274/574 completed (loss: 0.22333590686321259, acc: 0.90625)
[2024-11-29 03:09:11,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:11,563][root][INFO] - Training Epoch: 4/10, step 275/574 completed (loss: 0.3050166368484497, acc: 0.8666666746139526)
[2024-11-29 03:09:11,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:11,791][root][INFO] - Training Epoch: 4/10, step 276/574 completed (loss: 0.36299464106559753, acc: 0.931034505367279)
[2024-11-29 03:09:11,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:12,007][root][INFO] - Training Epoch: 4/10, step 277/574 completed (loss: 0.14497888088226318, acc: 0.9599999785423279)
[2024-11-29 03:09:12,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:12,245][root][INFO] - Training Epoch: 4/10, step 278/574 completed (loss: 0.7404133677482605, acc: 0.7234042286872864)
[2024-11-29 03:09:12,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:12,476][root][INFO] - Training Epoch: 4/10, step 279/574 completed (loss: 0.5890224575996399, acc: 0.8125)
[2024-11-29 03:09:13,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:13,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:13,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:13,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:14,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:14,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:14,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:14,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:15,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:15,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:15,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:16,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:16,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:16,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:16,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:17,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:17,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:17,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:18,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:18,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:18,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:18,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:19,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:19,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:19,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:19,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:20,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:20,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:20,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:21,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:21,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:21,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:21,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:22,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:22,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:22,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:22,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:23,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:23,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:23,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:24,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:24,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:24,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:24,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:25,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:25,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:25,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:25,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:26,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:26,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:26,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:26,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:27,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:27,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:27,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:28,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:28,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:28,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:28,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:29,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:29,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:29,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:30,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:30,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:30,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:31,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:31,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:31,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:32,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:32,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:32,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:32,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:33,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:33,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:33,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:34,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:34,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:34,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:34,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:35,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:35,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:35,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:36,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:36,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:36,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:37,219][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.8740, device='cuda:0') eval_epoch_loss=tensor(1.0557, device='cuda:0') eval_epoch_acc=tensor(0.7364, device='cuda:0')
[2024-11-29 03:09:37,220][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:09:37,220][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:09:37,410][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_4_step_280_loss_1.0557137727737427/model.pt
[2024-11-29 03:09:37,413][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 4 is 1.0557137727737427
[2024-11-29 03:09:37,414][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 4 is 0.7363795638084412
[2024-11-29 03:09:37,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:37,675][root][INFO] - Training Epoch: 4/10, step 280/574 completed (loss: 0.18977002799510956, acc: 0.9545454382896423)
[2024-11-29 03:09:37,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:37,992][root][INFO] - Training Epoch: 4/10, step 281/574 completed (loss: 1.3365528583526611, acc: 0.6746987700462341)
[2024-11-29 03:09:38,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:38,269][root][INFO] - Training Epoch: 4/10, step 282/574 completed (loss: 1.1558805704116821, acc: 0.6666666865348816)
[2024-11-29 03:09:38,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:38,539][root][INFO] - Training Epoch: 4/10, step 283/574 completed (loss: 0.16390056908130646, acc: 0.9473684430122375)
[2024-11-29 03:09:38,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:38,781][root][INFO] - Training Epoch: 4/10, step 284/574 completed (loss: 0.34959831833839417, acc: 0.8529411554336548)
[2024-11-29 03:09:38,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:39,005][root][INFO] - Training Epoch: 4/10, step 285/574 completed (loss: 0.4238145351409912, acc: 0.800000011920929)
[2024-11-29 03:09:39,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:39,224][root][INFO] - Training Epoch: 4/10, step 286/574 completed (loss: 0.6991133689880371, acc: 0.8046875)
[2024-11-29 03:09:39,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:39,468][root][INFO] - Training Epoch: 4/10, step 287/574 completed (loss: 0.97310471534729, acc: 0.7599999904632568)
[2024-11-29 03:09:39,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:39,673][root][INFO] - Training Epoch: 4/10, step 288/574 completed (loss: 0.6489975452423096, acc: 0.8241758346557617)
[2024-11-29 03:09:39,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:39,926][root][INFO] - Training Epoch: 4/10, step 289/574 completed (loss: 0.7428897619247437, acc: 0.7950310707092285)
[2024-11-29 03:09:40,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:40,213][root][INFO] - Training Epoch: 4/10, step 290/574 completed (loss: 0.8957314491271973, acc: 0.7731958627700806)
[2024-11-29 03:09:40,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:40,481][root][INFO] - Training Epoch: 4/10, step 291/574 completed (loss: 0.06421632319688797, acc: 1.0)
[2024-11-29 03:09:40,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:40,737][root][INFO] - Training Epoch: 4/10, step 292/574 completed (loss: 0.9048217535018921, acc: 0.738095223903656)
[2024-11-29 03:09:40,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:40,978][root][INFO] - Training Epoch: 4/10, step 293/574 completed (loss: 0.4181182086467743, acc: 0.9137930870056152)
[2024-11-29 03:09:41,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:41,372][root][INFO] - Training Epoch: 4/10, step 294/574 completed (loss: 0.6815937161445618, acc: 0.8545454740524292)
[2024-11-29 03:09:41,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:41,831][root][INFO] - Training Epoch: 4/10, step 295/574 completed (loss: 1.1621596813201904, acc: 0.6907216310501099)
[2024-11-29 03:09:41,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:42,009][root][INFO] - Training Epoch: 4/10, step 296/574 completed (loss: 1.0631455183029175, acc: 0.6896551847457886)
[2024-11-29 03:09:42,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:42,220][root][INFO] - Training Epoch: 4/10, step 297/574 completed (loss: 0.30953726172447205, acc: 0.9259259104728699)
[2024-11-29 03:09:42,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:42,496][root][INFO] - Training Epoch: 4/10, step 298/574 completed (loss: 0.5006426572799683, acc: 0.8421052694320679)
[2024-11-29 03:09:42,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:42,691][root][INFO] - Training Epoch: 4/10, step 299/574 completed (loss: 0.3006497025489807, acc: 0.9464285969734192)
[2024-11-29 03:09:42,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:42,886][root][INFO] - Training Epoch: 4/10, step 300/574 completed (loss: 0.02508874237537384, acc: 1.0)
[2024-11-29 03:09:42,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:43,110][root][INFO] - Training Epoch: 4/10, step 301/574 completed (loss: 0.3179612457752228, acc: 0.9056603908538818)
[2024-11-29 03:09:43,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:43,353][root][INFO] - Training Epoch: 4/10, step 302/574 completed (loss: 0.10225959867238998, acc: 1.0)
[2024-11-29 03:09:43,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:43,584][root][INFO] - Training Epoch: 4/10, step 303/574 completed (loss: 0.1252300888299942, acc: 0.970588207244873)
[2024-11-29 03:09:43,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:43,832][root][INFO] - Training Epoch: 4/10, step 304/574 completed (loss: 0.11051949858665466, acc: 0.96875)
[2024-11-29 03:09:43,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:44,077][root][INFO] - Training Epoch: 4/10, step 305/574 completed (loss: 0.665771484375, acc: 0.8524590134620667)
[2024-11-29 03:09:44,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:44,290][root][INFO] - Training Epoch: 4/10, step 306/574 completed (loss: 0.23099949955940247, acc: 0.9333333373069763)
[2024-11-29 03:09:44,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:44,543][root][INFO] - Training Epoch: 4/10, step 307/574 completed (loss: 0.020556548610329628, acc: 1.0)
[2024-11-29 03:09:44,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:44,809][root][INFO] - Training Epoch: 4/10, step 308/574 completed (loss: 0.37515076994895935, acc: 0.8405796885490417)
[2024-11-29 03:09:44,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:45,142][root][INFO] - Training Epoch: 4/10, step 309/574 completed (loss: 0.37433621287345886, acc: 0.9166666865348816)
[2024-11-29 03:09:45,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:45,388][root][INFO] - Training Epoch: 4/10, step 310/574 completed (loss: 0.34903883934020996, acc: 0.9036144614219666)
[2024-11-29 03:09:45,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:45,609][root][INFO] - Training Epoch: 4/10, step 311/574 completed (loss: 0.48704794049263, acc: 0.8717948794364929)
[2024-11-29 03:09:45,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:45,856][root][INFO] - Training Epoch: 4/10, step 312/574 completed (loss: 0.2900073826313019, acc: 0.8979591727256775)
[2024-11-29 03:09:45,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:46,062][root][INFO] - Training Epoch: 4/10, step 313/574 completed (loss: 0.042873308062553406, acc: 1.0)
[2024-11-29 03:09:46,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:46,281][root][INFO] - Training Epoch: 4/10, step 314/574 completed (loss: 0.030263178050518036, acc: 1.0)
[2024-11-29 03:09:46,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:46,490][root][INFO] - Training Epoch: 4/10, step 315/574 completed (loss: 0.37839531898498535, acc: 0.8709677457809448)
[2024-11-29 03:09:46,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:46,731][root][INFO] - Training Epoch: 4/10, step 316/574 completed (loss: 1.4214586019515991, acc: 0.7419354915618896)
[2024-11-29 03:09:46,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:47,020][root][INFO] - Training Epoch: 4/10, step 317/574 completed (loss: 0.22346632182598114, acc: 0.9402984976768494)
[2024-11-29 03:09:47,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:47,296][root][INFO] - Training Epoch: 4/10, step 318/574 completed (loss: 0.36317145824432373, acc: 0.8846153616905212)
[2024-11-29 03:09:47,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:47,594][root][INFO] - Training Epoch: 4/10, step 319/574 completed (loss: 0.09560678154230118, acc: 0.9777777791023254)
[2024-11-29 03:09:47,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:47,842][root][INFO] - Training Epoch: 4/10, step 320/574 completed (loss: 0.18861790001392365, acc: 0.9354838728904724)
[2024-11-29 03:09:47,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:48,098][root][INFO] - Training Epoch: 4/10, step 321/574 completed (loss: 0.13443151116371155, acc: 0.9599999785423279)
[2024-11-29 03:09:48,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:48,349][root][INFO] - Training Epoch: 4/10, step 322/574 completed (loss: 1.3367525339126587, acc: 0.6296296119689941)
[2024-11-29 03:09:48,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:48,589][root][INFO] - Training Epoch: 4/10, step 323/574 completed (loss: 2.2495484352111816, acc: 0.34285715222358704)
[2024-11-29 03:09:48,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:48,811][root][INFO] - Training Epoch: 4/10, step 324/574 completed (loss: 1.7452402114868164, acc: 0.5128205418586731)
[2024-11-29 03:09:48,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:49,100][root][INFO] - Training Epoch: 4/10, step 325/574 completed (loss: 2.550445079803467, acc: 0.3414634168148041)
[2024-11-29 03:09:49,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:49,340][root][INFO] - Training Epoch: 4/10, step 326/574 completed (loss: 1.8536702394485474, acc: 0.5263158082962036)
[2024-11-29 03:09:49,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:49,588][root][INFO] - Training Epoch: 4/10, step 327/574 completed (loss: 0.4768599569797516, acc: 0.8947368264198303)
[2024-11-29 03:09:49,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:49,819][root][INFO] - Training Epoch: 4/10, step 328/574 completed (loss: 0.2958802282810211, acc: 0.8571428656578064)
[2024-11-29 03:09:49,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:50,107][root][INFO] - Training Epoch: 4/10, step 329/574 completed (loss: 0.3238855302333832, acc: 0.9629629850387573)
[2024-11-29 03:09:50,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:50,316][root][INFO] - Training Epoch: 4/10, step 330/574 completed (loss: 0.09555515646934509, acc: 1.0)
[2024-11-29 03:09:50,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:50,566][root][INFO] - Training Epoch: 4/10, step 331/574 completed (loss: 0.6442323327064514, acc: 0.8548387289047241)
[2024-11-29 03:09:50,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:50,834][root][INFO] - Training Epoch: 4/10, step 332/574 completed (loss: 0.34511539340019226, acc: 0.8947368264198303)
[2024-11-29 03:09:50,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:51,062][root][INFO] - Training Epoch: 4/10, step 333/574 completed (loss: 0.38581517338752747, acc: 0.90625)
[2024-11-29 03:09:51,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:51,344][root][INFO] - Training Epoch: 4/10, step 334/574 completed (loss: 0.2357151210308075, acc: 0.8666666746139526)
[2024-11-29 03:09:51,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:51,572][root][INFO] - Training Epoch: 4/10, step 335/574 completed (loss: 0.2769870162010193, acc: 0.9473684430122375)
[2024-11-29 03:09:51,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:51,796][root][INFO] - Training Epoch: 4/10, step 336/574 completed (loss: 1.2308467626571655, acc: 0.699999988079071)
[2024-11-29 03:09:51,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:52,057][root][INFO] - Training Epoch: 4/10, step 337/574 completed (loss: 1.7375198602676392, acc: 0.5517241358757019)
[2024-11-29 03:09:52,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:52,310][root][INFO] - Training Epoch: 4/10, step 338/574 completed (loss: 1.5916321277618408, acc: 0.5957446694374084)
[2024-11-29 03:09:52,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:52,551][root][INFO] - Training Epoch: 4/10, step 339/574 completed (loss: 1.5145068168640137, acc: 0.6265060305595398)
[2024-11-29 03:09:52,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:52,813][root][INFO] - Training Epoch: 4/10, step 340/574 completed (loss: 0.043956030160188675, acc: 1.0)
[2024-11-29 03:09:52,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:53,083][root][INFO] - Training Epoch: 4/10, step 341/574 completed (loss: 0.6377118825912476, acc: 0.8717948794364929)
[2024-11-29 03:09:53,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:53,336][root][INFO] - Training Epoch: 4/10, step 342/574 completed (loss: 0.6577355265617371, acc: 0.8313252925872803)
[2024-11-29 03:09:53,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:53,610][root][INFO] - Training Epoch: 4/10, step 343/574 completed (loss: 1.0944136381149292, acc: 0.7735849022865295)
[2024-11-29 03:09:53,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:53,861][root][INFO] - Training Epoch: 4/10, step 344/574 completed (loss: 0.3101826012134552, acc: 0.8987341523170471)
[2024-11-29 03:09:53,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:54,110][root][INFO] - Training Epoch: 4/10, step 345/574 completed (loss: 0.1863822042942047, acc: 0.9215686321258545)
[2024-11-29 03:09:54,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:54,361][root][INFO] - Training Epoch: 4/10, step 346/574 completed (loss: 0.7205192446708679, acc: 0.7611940503120422)
[2024-11-29 03:09:54,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:54,598][root][INFO] - Training Epoch: 4/10, step 347/574 completed (loss: 0.13282804191112518, acc: 0.8999999761581421)
[2024-11-29 03:09:54,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:54,824][root][INFO] - Training Epoch: 4/10, step 348/574 completed (loss: 0.24035322666168213, acc: 0.9200000166893005)
[2024-11-29 03:09:54,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:55,121][root][INFO] - Training Epoch: 4/10, step 349/574 completed (loss: 1.0123646259307861, acc: 0.75)
[2024-11-29 03:09:55,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:55,401][root][INFO] - Training Epoch: 4/10, step 350/574 completed (loss: 0.9750635027885437, acc: 0.6976743936538696)
[2024-11-29 03:09:55,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:55,681][root][INFO] - Training Epoch: 4/10, step 351/574 completed (loss: 0.36298415064811707, acc: 0.9230769276618958)
[2024-11-29 03:09:55,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:55,956][root][INFO] - Training Epoch: 4/10, step 352/574 completed (loss: 1.3316798210144043, acc: 0.6222222447395325)
[2024-11-29 03:09:56,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:56,168][root][INFO] - Training Epoch: 4/10, step 353/574 completed (loss: 0.20150741934776306, acc: 0.95652174949646)
[2024-11-29 03:09:56,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:56,457][root][INFO] - Training Epoch: 4/10, step 354/574 completed (loss: 0.49723589420318604, acc: 0.8461538553237915)
[2024-11-29 03:09:56,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:56,706][root][INFO] - Training Epoch: 4/10, step 355/574 completed (loss: 1.3647422790527344, acc: 0.6263736486434937)
[2024-11-29 03:09:56,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:57,123][root][INFO] - Training Epoch: 4/10, step 356/574 completed (loss: 0.9150896668434143, acc: 0.739130437374115)
[2024-11-29 03:09:57,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:57,347][root][INFO] - Training Epoch: 4/10, step 357/574 completed (loss: 0.7640220522880554, acc: 0.739130437374115)
[2024-11-29 03:09:57,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:57,559][root][INFO] - Training Epoch: 4/10, step 358/574 completed (loss: 0.7890688180923462, acc: 0.7755101919174194)
[2024-11-29 03:09:57,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:57,779][root][INFO] - Training Epoch: 4/10, step 359/574 completed (loss: 0.007420905400067568, acc: 1.0)
[2024-11-29 03:09:57,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:57,983][root][INFO] - Training Epoch: 4/10, step 360/574 completed (loss: 0.3419666290283203, acc: 0.9230769276618958)
[2024-11-29 03:09:58,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:58,219][root][INFO] - Training Epoch: 4/10, step 361/574 completed (loss: 0.879949152469635, acc: 0.7560975551605225)
[2024-11-29 03:09:58,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:58,495][root][INFO] - Training Epoch: 4/10, step 362/574 completed (loss: 0.6235952973365784, acc: 0.8444444537162781)
[2024-11-29 03:09:58,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:58,765][root][INFO] - Training Epoch: 4/10, step 363/574 completed (loss: 0.36654967069625854, acc: 0.8815789222717285)
[2024-11-29 03:09:58,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:59,028][root][INFO] - Training Epoch: 4/10, step 364/574 completed (loss: 0.20296710729599, acc: 0.9268292784690857)
[2024-11-29 03:09:59,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:59,269][root][INFO] - Training Epoch: 4/10, step 365/574 completed (loss: 0.10830510407686234, acc: 0.9696969985961914)
[2024-11-29 03:09:59,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:59,507][root][INFO] - Training Epoch: 4/10, step 366/574 completed (loss: 0.0410984605550766, acc: 1.0)
[2024-11-29 03:09:59,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:59,753][root][INFO] - Training Epoch: 4/10, step 367/574 completed (loss: 0.45078912377357483, acc: 0.8260869383811951)
[2024-11-29 03:09:59,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:59,985][root][INFO] - Training Epoch: 4/10, step 368/574 completed (loss: 0.3593449592590332, acc: 0.8571428656578064)
[2024-11-29 03:10:00,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:00,210][root][INFO] - Training Epoch: 4/10, step 369/574 completed (loss: 1.1229908466339111, acc: 0.71875)
[2024-11-29 03:10:00,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:00,718][root][INFO] - Training Epoch: 4/10, step 370/574 completed (loss: 1.5187867879867554, acc: 0.6242424249649048)
[2024-11-29 03:10:01,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:01,514][root][INFO] - Training Epoch: 4/10, step 371/574 completed (loss: 0.828087568283081, acc: 0.7924528121948242)
[2024-11-29 03:10:01,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:01,724][root][INFO] - Training Epoch: 4/10, step 372/574 completed (loss: 0.5320583581924438, acc: 0.8888888955116272)
[2024-11-29 03:10:01,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:01,929][root][INFO] - Training Epoch: 4/10, step 373/574 completed (loss: 0.2756483852863312, acc: 0.9107142686843872)
[2024-11-29 03:10:02,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:02,163][root][INFO] - Training Epoch: 4/10, step 374/574 completed (loss: 0.32225945591926575, acc: 0.9428571462631226)
[2024-11-29 03:10:02,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:02,387][root][INFO] - Training Epoch: 4/10, step 375/574 completed (loss: 0.024367308244109154, acc: 1.0)
[2024-11-29 03:10:02,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:02,597][root][INFO] - Training Epoch: 4/10, step 376/574 completed (loss: 0.02335117943584919, acc: 1.0)
[2024-11-29 03:10:02,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:02,843][root][INFO] - Training Epoch: 4/10, step 377/574 completed (loss: 0.5245677828788757, acc: 0.8333333134651184)
[2024-11-29 03:10:02,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:03,104][root][INFO] - Training Epoch: 4/10, step 378/574 completed (loss: 0.17266589403152466, acc: 0.9263157844543457)
[2024-11-29 03:10:03,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:03,593][root][INFO] - Training Epoch: 4/10, step 379/574 completed (loss: 0.5264577269554138, acc: 0.8443113565444946)
[2024-11-29 03:10:03,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:03,896][root][INFO] - Training Epoch: 4/10, step 380/574 completed (loss: 0.45910823345184326, acc: 0.902255654335022)
[2024-11-29 03:10:04,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:04,857][root][INFO] - Training Epoch: 4/10, step 381/574 completed (loss: 0.8438501954078674, acc: 0.7860962748527527)
[2024-11-29 03:10:04,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:05,332][root][INFO] - Training Epoch: 4/10, step 382/574 completed (loss: 0.28303128480911255, acc: 0.9369369149208069)
[2024-11-29 03:10:05,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:05,518][root][INFO] - Training Epoch: 4/10, step 383/574 completed (loss: 0.5264882445335388, acc: 0.8571428656578064)
[2024-11-29 03:10:05,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:05,736][root][INFO] - Training Epoch: 4/10, step 384/574 completed (loss: 0.21435458958148956, acc: 0.9642857313156128)
[2024-11-29 03:10:05,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:05,946][root][INFO] - Training Epoch: 4/10, step 385/574 completed (loss: 0.25739744305610657, acc: 0.90625)
[2024-11-29 03:10:06,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:06,180][root][INFO] - Training Epoch: 4/10, step 386/574 completed (loss: 0.039733245968818665, acc: 1.0)
[2024-11-29 03:10:06,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:06,417][root][INFO] - Training Epoch: 4/10, step 387/574 completed (loss: 0.0492028184235096, acc: 1.0)
[2024-11-29 03:10:06,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:06,655][root][INFO] - Training Epoch: 4/10, step 388/574 completed (loss: 0.08306708931922913, acc: 0.9545454382896423)
[2024-11-29 03:10:06,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:06,909][root][INFO] - Training Epoch: 4/10, step 389/574 completed (loss: 0.01757091097533703, acc: 1.0)
[2024-11-29 03:10:07,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:07,145][root][INFO] - Training Epoch: 4/10, step 390/574 completed (loss: 0.6744909882545471, acc: 0.761904776096344)
[2024-11-29 03:10:07,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:07,374][root][INFO] - Training Epoch: 4/10, step 391/574 completed (loss: 1.2159172296524048, acc: 0.6666666865348816)
[2024-11-29 03:10:07,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:07,614][root][INFO] - Training Epoch: 4/10, step 392/574 completed (loss: 1.3370778560638428, acc: 0.6990291476249695)
[2024-11-29 03:10:07,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:08,056][root][INFO] - Training Epoch: 4/10, step 393/574 completed (loss: 1.2374905347824097, acc: 0.720588207244873)
[2024-11-29 03:10:08,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:08,320][root][INFO] - Training Epoch: 4/10, step 394/574 completed (loss: 1.455360770225525, acc: 0.6399999856948853)
[2024-11-29 03:10:08,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:08,607][root][INFO] - Training Epoch: 4/10, step 395/574 completed (loss: 0.9026641845703125, acc: 0.7430555820465088)
[2024-11-29 03:10:08,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:08,871][root][INFO] - Training Epoch: 4/10, step 396/574 completed (loss: 0.49904826283454895, acc: 0.8604651093482971)
[2024-11-29 03:10:08,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:09,104][root][INFO] - Training Epoch: 4/10, step 397/574 completed (loss: 0.1888752579689026, acc: 0.9166666865348816)
[2024-11-29 03:10:09,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:09,358][root][INFO] - Training Epoch: 4/10, step 398/574 completed (loss: 0.36647772789001465, acc: 0.9069767594337463)
[2024-11-29 03:10:09,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:09,575][root][INFO] - Training Epoch: 4/10, step 399/574 completed (loss: 0.07810623198747635, acc: 1.0)
[2024-11-29 03:10:09,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:10,024][root][INFO] - Training Epoch: 4/10, step 400/574 completed (loss: 0.5423544049263, acc: 0.8529411554336548)
[2024-11-29 03:10:10,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:10,215][root][INFO] - Training Epoch: 4/10, step 401/574 completed (loss: 0.6598373651504517, acc: 0.8266666531562805)
[2024-11-29 03:10:10,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:10,454][root][INFO] - Training Epoch: 4/10, step 402/574 completed (loss: 0.5914630889892578, acc: 0.8787878751754761)
[2024-11-29 03:10:10,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:10,700][root][INFO] - Training Epoch: 4/10, step 403/574 completed (loss: 0.40368959307670593, acc: 0.8484848737716675)
[2024-11-29 03:10:10,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:10,943][root][INFO] - Training Epoch: 4/10, step 404/574 completed (loss: 0.6971755623817444, acc: 0.8064516186714172)
[2024-11-29 03:10:11,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:11,209][root][INFO] - Training Epoch: 4/10, step 405/574 completed (loss: 0.32925018668174744, acc: 0.9629629850387573)
[2024-11-29 03:10:11,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:11,446][root][INFO] - Training Epoch: 4/10, step 406/574 completed (loss: 0.3049827814102173, acc: 0.9200000166893005)
[2024-11-29 03:10:11,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:11,693][root][INFO] - Training Epoch: 4/10, step 407/574 completed (loss: 0.1058572307229042, acc: 1.0)
[2024-11-29 03:10:11,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:11,934][root][INFO] - Training Epoch: 4/10, step 408/574 completed (loss: 0.15941374003887177, acc: 0.9629629850387573)
[2024-11-29 03:10:12,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:12,191][root][INFO] - Training Epoch: 4/10, step 409/574 completed (loss: 0.0528431162238121, acc: 1.0)
[2024-11-29 03:10:12,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:12,431][root][INFO] - Training Epoch: 4/10, step 410/574 completed (loss: 0.16291971504688263, acc: 0.9655172228813171)
[2024-11-29 03:10:12,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:12,665][root][INFO] - Training Epoch: 4/10, step 411/574 completed (loss: 0.30639567971229553, acc: 0.9285714030265808)
[2024-11-29 03:10:12,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:12,893][root][INFO] - Training Epoch: 4/10, step 412/574 completed (loss: 0.301611065864563, acc: 0.9666666388511658)
[2024-11-29 03:10:12,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:13,131][root][INFO] - Training Epoch: 4/10, step 413/574 completed (loss: 0.19074587523937225, acc: 0.939393937587738)
[2024-11-29 03:10:13,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:13,390][root][INFO] - Training Epoch: 4/10, step 414/574 completed (loss: 0.027893103659152985, acc: 1.0)
[2024-11-29 03:10:13,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:13,636][root][INFO] - Training Epoch: 4/10, step 415/574 completed (loss: 0.45369473099708557, acc: 0.843137264251709)
[2024-11-29 03:10:13,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:13,838][root][INFO] - Training Epoch: 4/10, step 416/574 completed (loss: 0.07984153926372528, acc: 1.0)
[2024-11-29 03:10:13,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:14,086][root][INFO] - Training Epoch: 4/10, step 417/574 completed (loss: 0.20403720438480377, acc: 0.8888888955116272)
[2024-11-29 03:10:14,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:14,332][root][INFO] - Training Epoch: 4/10, step 418/574 completed (loss: 0.2795275151729584, acc: 0.949999988079071)
[2024-11-29 03:10:14,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:14,545][root][INFO] - Training Epoch: 4/10, step 419/574 completed (loss: 0.2184385061264038, acc: 0.949999988079071)
[2024-11-29 03:10:14,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:14,788][root][INFO] - Training Epoch: 4/10, step 420/574 completed (loss: 0.05233423411846161, acc: 1.0)
[2024-11-29 03:10:14,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:15,035][root][INFO] - Training Epoch: 4/10, step 421/574 completed (loss: 0.1712012141942978, acc: 0.9333333373069763)
[2024-11-29 03:10:15,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:15,241][root][INFO] - Training Epoch: 4/10, step 422/574 completed (loss: 0.4635629951953888, acc: 0.84375)
[2024-11-29 03:10:16,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:16,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:16,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:16,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:17,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:17,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:17,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:17,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:18,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:18,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:18,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:19,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:19,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:19,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:19,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:20,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:20,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:20,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:21,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:21,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:21,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:21,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:22,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:22,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:22,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:22,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:23,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:23,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:23,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:23,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:24,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:24,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:24,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:25,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:25,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:25,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:25,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:26,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:26,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:26,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:26,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:26,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:27,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:27,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:27,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:28,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:28,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:28,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:28,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:29,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:29,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:29,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:29,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:30,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:30,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:30,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:31,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:31,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:31,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:31,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:32,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:32,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:32,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:32,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:33,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:33,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:33,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:33,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:34,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:34,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:34,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:35,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:35,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:35,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:35,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:36,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:36,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:36,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:37,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:37,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:37,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:38,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:38,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:38,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:38,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:39,411][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.0887, device='cuda:0') eval_epoch_loss=tensor(1.1278, device='cuda:0') eval_epoch_acc=tensor(0.7388, device='cuda:0')
[2024-11-29 03:10:39,413][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:10:39,413][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:10:39,579][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_4_step_423_loss_1.1277662515640259/model.pt
[2024-11-29 03:10:39,581][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 4 is 0.7387536764144897
[2024-11-29 03:10:39,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:39,861][root][INFO] - Training Epoch: 4/10, step 423/574 completed (loss: 0.5525162220001221, acc: 0.8611111044883728)
[2024-11-29 03:10:40,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:40,150][root][INFO] - Training Epoch: 4/10, step 424/574 completed (loss: 0.30419763922691345, acc: 0.8888888955116272)
[2024-11-29 03:10:40,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:40,399][root][INFO] - Training Epoch: 4/10, step 425/574 completed (loss: 0.28176063299179077, acc: 0.8787878751754761)
[2024-11-29 03:10:40,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:40,630][root][INFO] - Training Epoch: 4/10, step 426/574 completed (loss: 0.02098698914051056, acc: 1.0)
[2024-11-29 03:10:40,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:40,857][root][INFO] - Training Epoch: 4/10, step 427/574 completed (loss: 0.16080166399478912, acc: 0.9729729890823364)
[2024-11-29 03:10:40,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:41,076][root][INFO] - Training Epoch: 4/10, step 428/574 completed (loss: 0.07608389854431152, acc: 0.9629629850387573)
[2024-11-29 03:10:41,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:41,344][root][INFO] - Training Epoch: 4/10, step 429/574 completed (loss: 0.06015075370669365, acc: 0.95652174949646)
[2024-11-29 03:10:41,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:41,593][root][INFO] - Training Epoch: 4/10, step 430/574 completed (loss: 0.01745840162038803, acc: 1.0)
[2024-11-29 03:10:41,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:41,859][root][INFO] - Training Epoch: 4/10, step 431/574 completed (loss: 0.030080612748861313, acc: 1.0)
[2024-11-29 03:10:41,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:42,124][root][INFO] - Training Epoch: 4/10, step 432/574 completed (loss: 0.044424187391996384, acc: 1.0)
[2024-11-29 03:10:42,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:42,391][root][INFO] - Training Epoch: 4/10, step 433/574 completed (loss: 0.16739560663700104, acc: 0.9444444179534912)
[2024-11-29 03:10:42,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:42,633][root][INFO] - Training Epoch: 4/10, step 434/574 completed (loss: 0.022744160145521164, acc: 1.0)
[2024-11-29 03:10:42,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:42,851][root][INFO] - Training Epoch: 4/10, step 435/574 completed (loss: 0.023444127291440964, acc: 1.0)
[2024-11-29 03:10:42,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:43,089][root][INFO] - Training Epoch: 4/10, step 436/574 completed (loss: 0.1670146882534027, acc: 0.9444444179534912)
[2024-11-29 03:10:43,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:43,326][root][INFO] - Training Epoch: 4/10, step 437/574 completed (loss: 0.1814461350440979, acc: 0.9545454382896423)
[2024-11-29 03:10:43,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:43,528][root][INFO] - Training Epoch: 4/10, step 438/574 completed (loss: 0.02263323776423931, acc: 1.0)
[2024-11-29 03:10:43,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:43,763][root][INFO] - Training Epoch: 4/10, step 439/574 completed (loss: 0.20307284593582153, acc: 0.9487179517745972)
[2024-11-29 03:10:43,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:44,159][root][INFO] - Training Epoch: 4/10, step 440/574 completed (loss: 0.6720358729362488, acc: 0.8030303120613098)
[2024-11-29 03:10:44,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:44,802][root][INFO] - Training Epoch: 4/10, step 441/574 completed (loss: 1.2959082126617432, acc: 0.656000018119812)
[2024-11-29 03:10:44,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:45,107][root][INFO] - Training Epoch: 4/10, step 442/574 completed (loss: 1.0570218563079834, acc: 0.6935483813285828)
[2024-11-29 03:10:45,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:45,662][root][INFO] - Training Epoch: 4/10, step 443/574 completed (loss: 0.8757656812667847, acc: 0.7761194109916687)
[2024-11-29 03:10:45,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:45,850][root][INFO] - Training Epoch: 4/10, step 444/574 completed (loss: 0.2902214527130127, acc: 0.8679245114326477)
[2024-11-29 03:10:45,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:46,169][root][INFO] - Training Epoch: 4/10, step 445/574 completed (loss: 0.12084538489580154, acc: 0.9545454382896423)
[2024-11-29 03:10:46,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:46,355][root][INFO] - Training Epoch: 4/10, step 446/574 completed (loss: 0.647210955619812, acc: 0.782608687877655)
[2024-11-29 03:10:46,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:46,561][root][INFO] - Training Epoch: 4/10, step 447/574 completed (loss: 0.5728949308395386, acc: 0.9230769276618958)
[2024-11-29 03:10:46,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:46,773][root][INFO] - Training Epoch: 4/10, step 448/574 completed (loss: 0.13104446232318878, acc: 0.9285714030265808)
[2024-11-29 03:10:46,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:46,950][root][INFO] - Training Epoch: 4/10, step 449/574 completed (loss: 0.2092348337173462, acc: 0.9104477763175964)
[2024-11-29 03:10:47,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:47,153][root][INFO] - Training Epoch: 4/10, step 450/574 completed (loss: 0.20667985081672668, acc: 0.9166666865348816)
[2024-11-29 03:10:47,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:47,359][root][INFO] - Training Epoch: 4/10, step 451/574 completed (loss: 0.21216019988059998, acc: 0.9239130616188049)
[2024-11-29 03:10:47,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:47,583][root][INFO] - Training Epoch: 4/10, step 452/574 completed (loss: 0.3518105149269104, acc: 0.9102563858032227)
[2024-11-29 03:10:47,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:47,805][root][INFO] - Training Epoch: 4/10, step 453/574 completed (loss: 0.5903682708740234, acc: 0.8552631735801697)
[2024-11-29 03:10:47,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:48,043][root][INFO] - Training Epoch: 4/10, step 454/574 completed (loss: 0.27674418687820435, acc: 0.9591836929321289)
[2024-11-29 03:10:48,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:48,276][root][INFO] - Training Epoch: 4/10, step 455/574 completed (loss: 0.0999717265367508, acc: 1.0)
[2024-11-29 03:10:48,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:48,513][root][INFO] - Training Epoch: 4/10, step 456/574 completed (loss: 0.8130761384963989, acc: 0.7938144207000732)
[2024-11-29 03:10:48,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:48,772][root][INFO] - Training Epoch: 4/10, step 457/574 completed (loss: 0.21210575103759766, acc: 0.9714285731315613)
[2024-11-29 03:10:48,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:49,061][root][INFO] - Training Epoch: 4/10, step 458/574 completed (loss: 1.0216439962387085, acc: 0.7616279125213623)
[2024-11-29 03:10:49,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:49,269][root][INFO] - Training Epoch: 4/10, step 459/574 completed (loss: 0.2611609697341919, acc: 0.9642857313156128)
[2024-11-29 03:10:49,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:49,513][root][INFO] - Training Epoch: 4/10, step 460/574 completed (loss: 0.6336183547973633, acc: 0.8148148059844971)
[2024-11-29 03:10:49,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:49,746][root][INFO] - Training Epoch: 4/10, step 461/574 completed (loss: 0.372074156999588, acc: 0.8888888955116272)
[2024-11-29 03:10:49,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:50,025][root][INFO] - Training Epoch: 4/10, step 462/574 completed (loss: 0.19341035187244415, acc: 0.90625)
[2024-11-29 03:10:50,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:50,285][root][INFO] - Training Epoch: 4/10, step 463/574 completed (loss: 0.3697171211242676, acc: 0.9230769276618958)
[2024-11-29 03:10:50,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:50,519][root][INFO] - Training Epoch: 4/10, step 464/574 completed (loss: 0.562337338924408, acc: 0.782608687877655)
[2024-11-29 03:10:50,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:50,755][root][INFO] - Training Epoch: 4/10, step 465/574 completed (loss: 0.5617472529411316, acc: 0.8333333134651184)
[2024-11-29 03:10:50,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:51,023][root][INFO] - Training Epoch: 4/10, step 466/574 completed (loss: 1.0382930040359497, acc: 0.7831325531005859)
[2024-11-29 03:10:51,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:51,320][root][INFO] - Training Epoch: 4/10, step 467/574 completed (loss: 0.4427168071269989, acc: 0.8738738894462585)
[2024-11-29 03:10:51,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:51,585][root][INFO] - Training Epoch: 4/10, step 468/574 completed (loss: 1.0255415439605713, acc: 0.737864077091217)
[2024-11-29 03:10:51,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:51,824][root][INFO] - Training Epoch: 4/10, step 469/574 completed (loss: 1.1482080221176147, acc: 0.7398374080657959)
[2024-11-29 03:10:51,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:52,065][root][INFO] - Training Epoch: 4/10, step 470/574 completed (loss: 0.2519504725933075, acc: 0.9583333134651184)
[2024-11-29 03:10:52,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:52,296][root][INFO] - Training Epoch: 4/10, step 471/574 completed (loss: 0.14757601916790009, acc: 0.9642857313156128)
[2024-11-29 03:10:52,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:52,615][root][INFO] - Training Epoch: 4/10, step 472/574 completed (loss: 0.8609833121299744, acc: 0.7156862616539001)
[2024-11-29 03:10:52,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:52,871][root][INFO] - Training Epoch: 4/10, step 473/574 completed (loss: 1.2590458393096924, acc: 0.6812227368354797)
[2024-11-29 03:10:52,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:53,085][root][INFO] - Training Epoch: 4/10, step 474/574 completed (loss: 1.0398327112197876, acc: 0.7395833134651184)
[2024-11-29 03:10:53,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:53,304][root][INFO] - Training Epoch: 4/10, step 475/574 completed (loss: 0.5695581436157227, acc: 0.8404908180236816)
[2024-11-29 03:10:53,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:53,561][root][INFO] - Training Epoch: 4/10, step 476/574 completed (loss: 0.6124367713928223, acc: 0.8057553768157959)
[2024-11-29 03:10:53,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:53,865][root][INFO] - Training Epoch: 4/10, step 477/574 completed (loss: 1.0106556415557861, acc: 0.7035176157951355)
[2024-11-29 03:10:53,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:54,113][root][INFO] - Training Epoch: 4/10, step 478/574 completed (loss: 0.7265641093254089, acc: 0.7222222089767456)
[2024-11-29 03:10:54,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:54,345][root][INFO] - Training Epoch: 4/10, step 479/574 completed (loss: 0.6319018602371216, acc: 0.8181818127632141)
[2024-11-29 03:10:54,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:54,578][root][INFO] - Training Epoch: 4/10, step 480/574 completed (loss: 0.5637068152427673, acc: 0.8148148059844971)
[2024-11-29 03:10:54,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:54,803][root][INFO] - Training Epoch: 4/10, step 481/574 completed (loss: 0.8130777478218079, acc: 0.75)
[2024-11-29 03:10:54,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:55,047][root][INFO] - Training Epoch: 4/10, step 482/574 completed (loss: 1.0650808811187744, acc: 0.800000011920929)
[2024-11-29 03:10:55,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:55,340][root][INFO] - Training Epoch: 4/10, step 483/574 completed (loss: 0.9941588640213013, acc: 0.7241379022598267)
[2024-11-29 03:10:55,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:55,611][root][INFO] - Training Epoch: 4/10, step 484/574 completed (loss: 0.28658580780029297, acc: 0.9354838728904724)
[2024-11-29 03:10:55,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:55,845][root][INFO] - Training Epoch: 4/10, step 485/574 completed (loss: 0.35346248745918274, acc: 0.8947368264198303)
[2024-11-29 03:10:55,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:56,057][root][INFO] - Training Epoch: 4/10, step 486/574 completed (loss: 1.09371817111969, acc: 0.7407407164573669)
[2024-11-29 03:10:56,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:56,304][root][INFO] - Training Epoch: 4/10, step 487/574 completed (loss: 0.731773853302002, acc: 0.8095238208770752)
[2024-11-29 03:10:56,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:56,578][root][INFO] - Training Epoch: 4/10, step 488/574 completed (loss: 0.9168815612792969, acc: 0.8181818127632141)
[2024-11-29 03:10:56,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:56,847][root][INFO] - Training Epoch: 4/10, step 489/574 completed (loss: 1.1229705810546875, acc: 0.692307710647583)
[2024-11-29 03:10:56,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:57,075][root][INFO] - Training Epoch: 4/10, step 490/574 completed (loss: 0.1686522215604782, acc: 0.9666666388511658)
[2024-11-29 03:10:57,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:57,298][root][INFO] - Training Epoch: 4/10, step 491/574 completed (loss: 0.5733332633972168, acc: 0.8620689511299133)
[2024-11-29 03:10:57,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:57,568][root][INFO] - Training Epoch: 4/10, step 492/574 completed (loss: 0.5753125548362732, acc: 0.8039215803146362)
[2024-11-29 03:10:57,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:57,804][root][INFO] - Training Epoch: 4/10, step 493/574 completed (loss: 0.3478909134864807, acc: 0.931034505367279)
[2024-11-29 03:10:57,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:58,030][root][INFO] - Training Epoch: 4/10, step 494/574 completed (loss: 0.6541752219200134, acc: 0.8421052694320679)
[2024-11-29 03:10:58,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:58,275][root][INFO] - Training Epoch: 4/10, step 495/574 completed (loss: 0.4646788537502289, acc: 0.8421052694320679)
[2024-11-29 03:10:58,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:58,571][root][INFO] - Training Epoch: 4/10, step 496/574 completed (loss: 1.1840976476669312, acc: 0.7142857313156128)
[2024-11-29 03:10:58,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:58,855][root][INFO] - Training Epoch: 4/10, step 497/574 completed (loss: 0.6115350723266602, acc: 0.8314606547355652)
[2024-11-29 03:10:58,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:59,106][root][INFO] - Training Epoch: 4/10, step 498/574 completed (loss: 1.0755584239959717, acc: 0.6516854166984558)
[2024-11-29 03:10:59,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:59,371][root][INFO] - Training Epoch: 4/10, step 499/574 completed (loss: 1.6725560426712036, acc: 0.5531914830207825)
[2024-11-29 03:10:59,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:59,615][root][INFO] - Training Epoch: 4/10, step 500/574 completed (loss: 1.0807794332504272, acc: 0.717391312122345)
[2024-11-29 03:10:59,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:59,844][root][INFO] - Training Epoch: 4/10, step 501/574 completed (loss: 0.0671706423163414, acc: 1.0)
[2024-11-29 03:10:59,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:00,089][root][INFO] - Training Epoch: 4/10, step 502/574 completed (loss: 0.06491909176111221, acc: 0.9615384340286255)
[2024-11-29 03:11:00,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:00,298][root][INFO] - Training Epoch: 4/10, step 503/574 completed (loss: 0.6973741054534912, acc: 0.8518518805503845)
[2024-11-29 03:11:00,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:00,509][root][INFO] - Training Epoch: 4/10, step 504/574 completed (loss: 0.12879154086112976, acc: 0.9629629850387573)
[2024-11-29 03:11:00,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:00,771][root][INFO] - Training Epoch: 4/10, step 505/574 completed (loss: 0.9179316759109497, acc: 0.7924528121948242)
[2024-11-29 03:11:00,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:01,054][root][INFO] - Training Epoch: 4/10, step 506/574 completed (loss: 1.2709401845932007, acc: 0.6551724076271057)
[2024-11-29 03:11:01,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:01,579][root][INFO] - Training Epoch: 4/10, step 507/574 completed (loss: 1.3352916240692139, acc: 0.6756756901741028)
[2024-11-29 03:11:01,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:01,925][root][INFO] - Training Epoch: 4/10, step 508/574 completed (loss: 1.004893183708191, acc: 0.7605633735656738)
[2024-11-29 03:11:02,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:02,096][root][INFO] - Training Epoch: 4/10, step 509/574 completed (loss: 0.16424494981765747, acc: 0.949999988079071)
[2024-11-29 03:11:02,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:02,307][root][INFO] - Training Epoch: 4/10, step 510/574 completed (loss: 0.201499804854393, acc: 0.9333333373069763)
[2024-11-29 03:11:02,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:02,544][root][INFO] - Training Epoch: 4/10, step 511/574 completed (loss: 0.34143540263175964, acc: 0.807692289352417)
[2024-11-29 03:11:03,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:05,052][root][INFO] - Training Epoch: 4/10, step 512/574 completed (loss: 1.803789496421814, acc: 0.550000011920929)
[2024-11-29 03:11:05,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:05,715][root][INFO] - Training Epoch: 4/10, step 513/574 completed (loss: 0.549591064453125, acc: 0.841269850730896)
[2024-11-29 03:11:05,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:05,907][root][INFO] - Training Epoch: 4/10, step 514/574 completed (loss: 0.7048006653785706, acc: 0.8214285969734192)
[2024-11-29 03:11:05,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:06,111][root][INFO] - Training Epoch: 4/10, step 515/574 completed (loss: 0.21983109414577484, acc: 0.8833333253860474)
[2024-11-29 03:11:06,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:06,725][root][INFO] - Training Epoch: 4/10, step 516/574 completed (loss: 0.6768686771392822, acc: 0.8333333134651184)
[2024-11-29 03:11:06,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:06,966][root][INFO] - Training Epoch: 4/10, step 517/574 completed (loss: 0.07208053022623062, acc: 1.0)
[2024-11-29 03:11:07,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:07,235][root][INFO] - Training Epoch: 4/10, step 518/574 completed (loss: 0.19222231209278107, acc: 0.9677419066429138)
[2024-11-29 03:11:07,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:07,470][root][INFO] - Training Epoch: 4/10, step 519/574 completed (loss: 0.16215644776821136, acc: 0.949999988079071)
[2024-11-29 03:11:07,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:07,666][root][INFO] - Training Epoch: 4/10, step 520/574 completed (loss: 0.22307612001895905, acc: 0.9259259104728699)
[2024-11-29 03:11:07,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:08,575][root][INFO] - Training Epoch: 4/10, step 521/574 completed (loss: 1.0341625213623047, acc: 0.7076271176338196)
[2024-11-29 03:11:08,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:08,849][root][INFO] - Training Epoch: 4/10, step 522/574 completed (loss: 0.5127959847450256, acc: 0.8507462739944458)
[2024-11-29 03:11:08,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:09,124][root][INFO] - Training Epoch: 4/10, step 523/574 completed (loss: 0.5707260966300964, acc: 0.8321167826652527)
[2024-11-29 03:11:09,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:09,607][root][INFO] - Training Epoch: 4/10, step 524/574 completed (loss: 0.9454413056373596, acc: 0.7749999761581421)
[2024-11-29 03:11:09,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:09,861][root][INFO] - Training Epoch: 4/10, step 525/574 completed (loss: 0.07914933562278748, acc: 0.9629629850387573)
[2024-11-29 03:11:09,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:10,118][root][INFO] - Training Epoch: 4/10, step 526/574 completed (loss: 0.26730039715766907, acc: 0.942307710647583)
[2024-11-29 03:11:10,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:10,393][root][INFO] - Training Epoch: 4/10, step 527/574 completed (loss: 0.11989118903875351, acc: 1.0)
[2024-11-29 03:11:10,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:10,650][root][INFO] - Training Epoch: 4/10, step 528/574 completed (loss: 1.9250644445419312, acc: 0.49180328845977783)
[2024-11-29 03:11:10,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:10,917][root][INFO] - Training Epoch: 4/10, step 529/574 completed (loss: 0.49444204568862915, acc: 0.8474576473236084)
[2024-11-29 03:11:11,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:11,140][root][INFO] - Training Epoch: 4/10, step 530/574 completed (loss: 1.9030417203903198, acc: 0.5348837375640869)
[2024-11-29 03:11:11,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:11,366][root][INFO] - Training Epoch: 4/10, step 531/574 completed (loss: 1.243401050567627, acc: 0.6363636255264282)
[2024-11-29 03:11:11,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:11,598][root][INFO] - Training Epoch: 4/10, step 532/574 completed (loss: 1.6201750040054321, acc: 0.6415094137191772)
[2024-11-29 03:11:11,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:11,821][root][INFO] - Training Epoch: 4/10, step 533/574 completed (loss: 0.86240553855896, acc: 0.7727272510528564)
[2024-11-29 03:11:11,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:12,055][root][INFO] - Training Epoch: 4/10, step 534/574 completed (loss: 0.7808119058609009, acc: 0.800000011920929)
[2024-11-29 03:11:12,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:12,285][root][INFO] - Training Epoch: 4/10, step 535/574 completed (loss: 0.2728613018989563, acc: 0.949999988079071)
[2024-11-29 03:11:12,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:12,549][root][INFO] - Training Epoch: 4/10, step 536/574 completed (loss: 0.18658976256847382, acc: 0.9545454382896423)
[2024-11-29 03:11:12,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:12,875][root][INFO] - Training Epoch: 4/10, step 537/574 completed (loss: 0.7720868587493896, acc: 0.8307692408561707)
[2024-11-29 03:11:12,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:13,158][root][INFO] - Training Epoch: 4/10, step 538/574 completed (loss: 0.7710976600646973, acc: 0.75)
[2024-11-29 03:11:13,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:13,446][root][INFO] - Training Epoch: 4/10, step 539/574 completed (loss: 0.4968522787094116, acc: 0.875)
[2024-11-29 03:11:13,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:13,677][root][INFO] - Training Epoch: 4/10, step 540/574 completed (loss: 1.1145575046539307, acc: 0.7272727489471436)
[2024-11-29 03:11:13,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:13,934][root][INFO] - Training Epoch: 4/10, step 541/574 completed (loss: 0.3127591907978058, acc: 0.9375)
[2024-11-29 03:11:14,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:14,171][root][INFO] - Training Epoch: 4/10, step 542/574 completed (loss: 0.11126614362001419, acc: 0.9677419066429138)
[2024-11-29 03:11:14,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:14,422][root][INFO] - Training Epoch: 4/10, step 543/574 completed (loss: 0.04340064153075218, acc: 1.0)
[2024-11-29 03:11:14,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:14,690][root][INFO] - Training Epoch: 4/10, step 544/574 completed (loss: 0.3190785050392151, acc: 0.8999999761581421)
[2024-11-29 03:11:14,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:14,934][root][INFO] - Training Epoch: 4/10, step 545/574 completed (loss: 0.10789597779512405, acc: 0.9756097793579102)
[2024-11-29 03:11:15,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:15,189][root][INFO] - Training Epoch: 4/10, step 546/574 completed (loss: 0.05429239571094513, acc: 1.0)
[2024-11-29 03:11:15,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:15,430][root][INFO] - Training Epoch: 4/10, step 547/574 completed (loss: 0.12376835197210312, acc: 0.9736841917037964)
[2024-11-29 03:11:15,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:15,640][root][INFO] - Training Epoch: 4/10, step 548/574 completed (loss: 0.09089593589305878, acc: 0.9677419066429138)
[2024-11-29 03:11:15,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:15,860][root][INFO] - Training Epoch: 4/10, step 549/574 completed (loss: 0.059510793536901474, acc: 0.9599999785423279)
[2024-11-29 03:11:15,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:16,100][root][INFO] - Training Epoch: 4/10, step 550/574 completed (loss: 0.24632801115512848, acc: 0.939393937587738)
[2024-11-29 03:11:16,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:16,308][root][INFO] - Training Epoch: 4/10, step 551/574 completed (loss: 0.26793843507766724, acc: 0.925000011920929)
[2024-11-29 03:11:16,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:16,525][root][INFO] - Training Epoch: 4/10, step 552/574 completed (loss: 0.28543123602867126, acc: 0.9142857193946838)
[2024-11-29 03:11:16,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:16,735][root][INFO] - Training Epoch: 4/10, step 553/574 completed (loss: 1.00090754032135, acc: 0.7299270033836365)
[2024-11-29 03:11:16,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:16,957][root][INFO] - Training Epoch: 4/10, step 554/574 completed (loss: 0.8051999807357788, acc: 0.7655172348022461)
[2024-11-29 03:11:17,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:17,173][root][INFO] - Training Epoch: 4/10, step 555/574 completed (loss: 0.8263173699378967, acc: 0.75)
[2024-11-29 03:11:17,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:17,393][root][INFO] - Training Epoch: 4/10, step 556/574 completed (loss: 0.7039676308631897, acc: 0.7947019934654236)
[2024-11-29 03:11:17,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:17,623][root][INFO] - Training Epoch: 4/10, step 557/574 completed (loss: 0.2863841950893402, acc: 0.8974359035491943)
[2024-11-29 03:11:17,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:17,853][root][INFO] - Training Epoch: 4/10, step 558/574 completed (loss: 0.09658155590295792, acc: 1.0)
[2024-11-29 03:11:17,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:18,080][root][INFO] - Training Epoch: 4/10, step 559/574 completed (loss: 0.14528939127922058, acc: 0.9230769276618958)
[2024-11-29 03:11:18,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:18,311][root][INFO] - Training Epoch: 4/10, step 560/574 completed (loss: 0.19011767208576202, acc: 0.9615384340286255)
[2024-11-29 03:11:18,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:18,519][root][INFO] - Training Epoch: 4/10, step 561/574 completed (loss: 0.42424920201301575, acc: 0.8717948794364929)
[2024-11-29 03:11:18,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:18,764][root][INFO] - Training Epoch: 4/10, step 562/574 completed (loss: 0.6572094559669495, acc: 0.800000011920929)
[2024-11-29 03:11:18,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:19,014][root][INFO] - Training Epoch: 4/10, step 563/574 completed (loss: 0.6847608685493469, acc: 0.8441558480262756)
[2024-11-29 03:11:19,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:19,287][root][INFO] - Training Epoch: 4/10, step 564/574 completed (loss: 0.6023512482643127, acc: 0.7916666865348816)
[2024-11-29 03:11:19,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:19,502][root][INFO] - Training Epoch: 4/10, step 565/574 completed (loss: 0.38421669602394104, acc: 0.9137930870056152)
[2024-11-29 03:11:20,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:20,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:20,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:20,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:21,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:21,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:21,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:22,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:22,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:22,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:22,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:23,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:23,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:23,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:24,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:24,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:24,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:24,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:25,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:25,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:25,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:25,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:26,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:26,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:26,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:27,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:27,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:27,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:27,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:28,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:28,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:28,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:28,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:29,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:29,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:29,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:30,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:30,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:30,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:30,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:31,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:31,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:31,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:32,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:32,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:32,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:32,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:33,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:33,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:33,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:33,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:34,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:34,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:34,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:34,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:35,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:35,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:35,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:35,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:36,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:36,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:36,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:37,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:37,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:37,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:37,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:38,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:38,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:38,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:39,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:39,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:39,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:39,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:40,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:40,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:40,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:40,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:41,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:41,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:41,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:41,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:42,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:42,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:42,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:42,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:43,606][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.1091, device='cuda:0') eval_epoch_loss=tensor(1.1343, device='cuda:0') eval_epoch_acc=tensor(0.7289, device='cuda:0')
[2024-11-29 03:11:43,607][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:11:43,608][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:11:43,818][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_4_step_566_loss_1.1343437433242798/model.pt
[2024-11-29 03:11:43,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:44,000][root][INFO] - Training Epoch: 4/10, step 566/574 completed (loss: 0.5859404802322388, acc: 0.8690476417541504)
[2024-11-29 03:11:44,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:44,199][root][INFO] - Training Epoch: 4/10, step 567/574 completed (loss: 0.11278290301561356, acc: 1.0)
[2024-11-29 03:11:44,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:44,389][root][INFO] - Training Epoch: 4/10, step 568/574 completed (loss: 0.09910667687654495, acc: 0.9629629850387573)
[2024-11-29 03:11:44,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:44,677][root][INFO] - Training Epoch: 4/10, step 569/574 completed (loss: 0.778911828994751, acc: 0.7700534462928772)
[2024-11-29 03:11:44,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:44,877][root][INFO] - Training Epoch: 4/10, step 570/574 completed (loss: 0.23921267688274384, acc: 0.9032257795333862)
[2024-11-29 03:11:44,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:45,100][root][INFO] - Training Epoch: 4/10, step 571/574 completed (loss: 0.7612433433532715, acc: 0.8461538553237915)
[2024-11-29 03:11:45,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:45,319][root][INFO] - Training Epoch: 4/10, step 572/574 completed (loss: 1.1609374284744263, acc: 0.7244898080825806)
[2024-11-29 03:11:45,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:45,560][root][INFO] - Training Epoch: 4/10, step 573/574 completed (loss: 0.9135397672653198, acc: 0.7421383857727051)
[2024-11-29 03:11:45,942][slam_llm.utils.train_utils][INFO] - Epoch 4: train_perplexity=2.0105, train_epoch_loss=0.6984, epoch time 265.6310493424535s
[2024-11-29 03:11:45,942][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 11 GB
[2024-11-29 03:11:45,942][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-11-29 03:11:45,942][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 11 GB
[2024-11-29 03:11:45,942][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 6
[2024-11-29 03:11:45,943][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:11:46,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:46,641][root][INFO] - Training Epoch: 5/10, step 0/574 completed (loss: 0.12225698679685593, acc: 0.9629629850387573)
[2024-11-29 03:11:46,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:46,828][root][INFO] - Training Epoch: 5/10, step 1/574 completed (loss: 0.0743134617805481, acc: 1.0)
[2024-11-29 03:11:46,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:47,022][root][INFO] - Training Epoch: 5/10, step 2/574 completed (loss: 0.6820269823074341, acc: 0.8648648858070374)
[2024-11-29 03:11:47,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:47,232][root][INFO] - Training Epoch: 5/10, step 3/574 completed (loss: 0.4319228231906891, acc: 0.8947368264198303)
[2024-11-29 03:11:47,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:47,442][root][INFO] - Training Epoch: 5/10, step 4/574 completed (loss: 0.29551902413368225, acc: 0.9189189076423645)
[2024-11-29 03:11:47,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:47,668][root][INFO] - Training Epoch: 5/10, step 5/574 completed (loss: 0.22237715125083923, acc: 0.9285714030265808)
[2024-11-29 03:11:47,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:47,922][root][INFO] - Training Epoch: 5/10, step 6/574 completed (loss: 1.0697429180145264, acc: 0.6734693646430969)
[2024-11-29 03:11:48,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:48,123][root][INFO] - Training Epoch: 5/10, step 7/574 completed (loss: 0.39380690455436707, acc: 0.800000011920929)
[2024-11-29 03:11:48,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:48,327][root][INFO] - Training Epoch: 5/10, step 8/574 completed (loss: 0.1022639200091362, acc: 0.9545454382896423)
[2024-11-29 03:11:48,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:48,532][root][INFO] - Training Epoch: 5/10, step 9/574 completed (loss: 0.04108097776770592, acc: 1.0)
[2024-11-29 03:11:48,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:48,717][root][INFO] - Training Epoch: 5/10, step 10/574 completed (loss: 0.09515058249235153, acc: 1.0)
[2024-11-29 03:11:48,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:48,914][root][INFO] - Training Epoch: 5/10, step 11/574 completed (loss: 0.2998189330101013, acc: 0.9487179517745972)
[2024-11-29 03:11:48,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:49,117][root][INFO] - Training Epoch: 5/10, step 12/574 completed (loss: 0.06192690134048462, acc: 0.9696969985961914)
[2024-11-29 03:11:49,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:49,305][root][INFO] - Training Epoch: 5/10, step 13/574 completed (loss: 0.2473451793193817, acc: 0.8695651888847351)
[2024-11-29 03:11:49,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:49,559][root][INFO] - Training Epoch: 5/10, step 14/574 completed (loss: 0.21510900557041168, acc: 0.9411764740943909)
[2024-11-29 03:11:49,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:49,782][root][INFO] - Training Epoch: 5/10, step 15/574 completed (loss: 0.4390830099582672, acc: 0.9387755393981934)
[2024-11-29 03:11:49,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:50,026][root][INFO] - Training Epoch: 5/10, step 16/574 completed (loss: 0.04081100970506668, acc: 1.0)
[2024-11-29 03:11:50,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:50,253][root][INFO] - Training Epoch: 5/10, step 17/574 completed (loss: 0.4785177707672119, acc: 0.8333333134651184)
[2024-11-29 03:11:50,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:50,489][root][INFO] - Training Epoch: 5/10, step 18/574 completed (loss: 1.3363919258117676, acc: 0.6944444179534912)
[2024-11-29 03:11:50,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:50,746][root][INFO] - Training Epoch: 5/10, step 19/574 completed (loss: 0.5201807618141174, acc: 0.8947368264198303)
[2024-11-29 03:11:50,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:50,974][root][INFO] - Training Epoch: 5/10, step 20/574 completed (loss: 0.5080823302268982, acc: 0.8846153616905212)
[2024-11-29 03:11:51,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:51,226][root][INFO] - Training Epoch: 5/10, step 21/574 completed (loss: 0.5474969148635864, acc: 0.8275862336158752)
[2024-11-29 03:11:51,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:51,447][root][INFO] - Training Epoch: 5/10, step 22/574 completed (loss: 0.5041849613189697, acc: 0.800000011920929)
[2024-11-29 03:11:51,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:51,681][root][INFO] - Training Epoch: 5/10, step 23/574 completed (loss: 0.16248635947704315, acc: 0.9523809552192688)
[2024-11-29 03:11:51,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:51,885][root][INFO] - Training Epoch: 5/10, step 24/574 completed (loss: 0.3651055693626404, acc: 0.875)
[2024-11-29 03:11:51,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:52,090][root][INFO] - Training Epoch: 5/10, step 25/574 completed (loss: 1.0409526824951172, acc: 0.7169811129570007)
[2024-11-29 03:11:52,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:52,301][root][INFO] - Training Epoch: 5/10, step 26/574 completed (loss: 1.2980183362960815, acc: 0.7123287916183472)
[2024-11-29 03:11:52,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:53,453][root][INFO] - Training Epoch: 5/10, step 27/574 completed (loss: 1.6851630210876465, acc: 0.5691699385643005)
[2024-11-29 03:11:53,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:53,641][root][INFO] - Training Epoch: 5/10, step 28/574 completed (loss: 0.5985241532325745, acc: 0.8372092843055725)
[2024-11-29 03:11:53,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:53,889][root][INFO] - Training Epoch: 5/10, step 29/574 completed (loss: 0.8455449938774109, acc: 0.759036123752594)
[2024-11-29 03:11:53,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:54,131][root][INFO] - Training Epoch: 5/10, step 30/574 completed (loss: 0.988677442073822, acc: 0.8024691343307495)
[2024-11-29 03:11:54,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:54,352][root][INFO] - Training Epoch: 5/10, step 31/574 completed (loss: 0.5035180449485779, acc: 0.9285714030265808)
[2024-11-29 03:11:54,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:54,568][root][INFO] - Training Epoch: 5/10, step 32/574 completed (loss: 0.4679027199745178, acc: 0.8518518805503845)
[2024-11-29 03:11:54,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:54,812][root][INFO] - Training Epoch: 5/10, step 33/574 completed (loss: 0.19495852291584015, acc: 0.9130434989929199)
[2024-11-29 03:11:54,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:55,075][root][INFO] - Training Epoch: 5/10, step 34/574 completed (loss: 0.8433592319488525, acc: 0.7899159789085388)
[2024-11-29 03:11:55,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:55,330][root][INFO] - Training Epoch: 5/10, step 35/574 completed (loss: 0.500835657119751, acc: 0.8852459192276001)
[2024-11-29 03:11:55,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:55,574][root][INFO] - Training Epoch: 5/10, step 36/574 completed (loss: 0.6891012191772461, acc: 0.8095238208770752)
[2024-11-29 03:11:55,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:55,812][root][INFO] - Training Epoch: 5/10, step 37/574 completed (loss: 0.8346880078315735, acc: 0.8135592937469482)
[2024-11-29 03:11:55,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:56,065][root][INFO] - Training Epoch: 5/10, step 38/574 completed (loss: 0.4981786906719208, acc: 0.8735632300376892)
[2024-11-29 03:11:56,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:56,292][root][INFO] - Training Epoch: 5/10, step 39/574 completed (loss: 0.5888659358024597, acc: 0.8571428656578064)
[2024-11-29 03:11:56,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:56,471][root][INFO] - Training Epoch: 5/10, step 40/574 completed (loss: 0.5889164209365845, acc: 0.9230769276618958)
[2024-11-29 03:11:56,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:56,760][root][INFO] - Training Epoch: 5/10, step 41/574 completed (loss: 0.5214921832084656, acc: 0.8648648858070374)
[2024-11-29 03:11:56,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:57,024][root][INFO] - Training Epoch: 5/10, step 42/574 completed (loss: 0.8449957370758057, acc: 0.7538461685180664)
[2024-11-29 03:11:57,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:57,370][root][INFO] - Training Epoch: 5/10, step 43/574 completed (loss: 0.8506380915641785, acc: 0.747474730014801)
[2024-11-29 03:11:57,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:57,675][root][INFO] - Training Epoch: 5/10, step 44/574 completed (loss: 0.6788963079452515, acc: 0.8556700944900513)
[2024-11-29 03:11:57,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:57,991][root][INFO] - Training Epoch: 5/10, step 45/574 completed (loss: 0.8161345720291138, acc: 0.7941176295280457)
[2024-11-29 03:11:58,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:58,227][root][INFO] - Training Epoch: 5/10, step 46/574 completed (loss: 0.359950989484787, acc: 0.8461538553237915)
[2024-11-29 03:11:58,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:58,501][root][INFO] - Training Epoch: 5/10, step 47/574 completed (loss: 0.05190937593579292, acc: 1.0)
[2024-11-29 03:11:58,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:58,701][root][INFO] - Training Epoch: 5/10, step 48/574 completed (loss: 0.10617411881685257, acc: 0.9642857313156128)
[2024-11-29 03:11:58,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:58,884][root][INFO] - Training Epoch: 5/10, step 49/574 completed (loss: 0.08859296143054962, acc: 0.9722222089767456)
[2024-11-29 03:11:59,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:59,136][root][INFO] - Training Epoch: 5/10, step 50/574 completed (loss: 0.7389010787010193, acc: 0.8245614171028137)
[2024-11-29 03:11:59,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:59,340][root][INFO] - Training Epoch: 5/10, step 51/574 completed (loss: 0.8736082911491394, acc: 0.7936508059501648)
[2024-11-29 03:11:59,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:59,562][root][INFO] - Training Epoch: 5/10, step 52/574 completed (loss: 1.0426907539367676, acc: 0.7323943376541138)
[2024-11-29 03:11:59,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:59,950][root][INFO] - Training Epoch: 5/10, step 53/574 completed (loss: 1.9788329601287842, acc: 0.4933333396911621)
[2024-11-29 03:12:00,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:00,152][root][INFO] - Training Epoch: 5/10, step 54/574 completed (loss: 0.8560454249382019, acc: 0.7837837934494019)
[2024-11-29 03:12:00,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:00,386][root][INFO] - Training Epoch: 5/10, step 55/574 completed (loss: 0.02416922338306904, acc: 1.0)
[2024-11-29 03:12:01,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:02,944][root][INFO] - Training Epoch: 5/10, step 56/574 completed (loss: 1.5742558240890503, acc: 0.5597269535064697)
[2024-11-29 03:12:03,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:04,061][root][INFO] - Training Epoch: 5/10, step 57/574 completed (loss: 1.726455569267273, acc: 0.5490196347236633)
[2024-11-29 03:12:04,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:04,577][root][INFO] - Training Epoch: 5/10, step 58/574 completed (loss: 0.9795684814453125, acc: 0.7215909361839294)
[2024-11-29 03:12:04,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:05,050][root][INFO] - Training Epoch: 5/10, step 59/574 completed (loss: 0.6729438304901123, acc: 0.8235294222831726)
[2024-11-29 03:12:05,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:05,515][root][INFO] - Training Epoch: 5/10, step 60/574 completed (loss: 0.9992358684539795, acc: 0.7463768124580383)
[2024-11-29 03:12:05,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:05,837][root][INFO] - Training Epoch: 5/10, step 61/574 completed (loss: 0.882688045501709, acc: 0.7749999761581421)
[2024-11-29 03:12:05,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:06,081][root][INFO] - Training Epoch: 5/10, step 62/574 completed (loss: 0.3196966052055359, acc: 0.8823529481887817)
[2024-11-29 03:12:06,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:06,379][root][INFO] - Training Epoch: 5/10, step 63/574 completed (loss: 0.37547585368156433, acc: 0.9166666865348816)
[2024-11-29 03:12:06,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:06,641][root][INFO] - Training Epoch: 5/10, step 64/574 completed (loss: 0.21684229373931885, acc: 0.9375)
[2024-11-29 03:12:06,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:06,923][root][INFO] - Training Epoch: 5/10, step 65/574 completed (loss: 0.2859887182712555, acc: 0.8965517282485962)
[2024-11-29 03:12:07,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:07,205][root][INFO] - Training Epoch: 5/10, step 66/574 completed (loss: 0.7822065949440002, acc: 0.75)
[2024-11-29 03:12:07,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:07,463][root][INFO] - Training Epoch: 5/10, step 67/574 completed (loss: 0.708332359790802, acc: 0.7833333611488342)
[2024-11-29 03:12:07,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:07,693][root][INFO] - Training Epoch: 5/10, step 68/574 completed (loss: 0.08208873867988586, acc: 1.0)
[2024-11-29 03:12:07,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:07,892][root][INFO] - Training Epoch: 5/10, step 69/574 completed (loss: 0.7244043350219727, acc: 0.7777777910232544)
[2024-11-29 03:12:08,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:08,146][root][INFO] - Training Epoch: 5/10, step 70/574 completed (loss: 0.6163527965545654, acc: 0.8181818127632141)
[2024-11-29 03:12:08,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:08,438][root][INFO] - Training Epoch: 5/10, step 71/574 completed (loss: 1.4356640577316284, acc: 0.625)
[2024-11-29 03:12:08,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:08,731][root][INFO] - Training Epoch: 5/10, step 72/574 completed (loss: 1.0816890001296997, acc: 0.7063491940498352)
[2024-11-29 03:12:08,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:09,015][root][INFO] - Training Epoch: 5/10, step 73/574 completed (loss: 1.8683496713638306, acc: 0.5384615659713745)
[2024-11-29 03:12:09,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:09,257][root][INFO] - Training Epoch: 5/10, step 74/574 completed (loss: 1.3286982774734497, acc: 0.6428571343421936)
[2024-11-29 03:12:09,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:09,508][root][INFO] - Training Epoch: 5/10, step 75/574 completed (loss: 1.5154942274093628, acc: 0.5447761416435242)
[2024-11-29 03:12:09,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:09,807][root][INFO] - Training Epoch: 5/10, step 76/574 completed (loss: 2.038999557495117, acc: 0.49635037779808044)
[2024-11-29 03:12:09,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:09,989][root][INFO] - Training Epoch: 5/10, step 77/574 completed (loss: 0.036617640405893326, acc: 1.0)
[2024-11-29 03:12:10,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:10,202][root][INFO] - Training Epoch: 5/10, step 78/574 completed (loss: 0.18875287473201752, acc: 0.875)
[2024-11-29 03:12:10,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:10,420][root][INFO] - Training Epoch: 5/10, step 79/574 completed (loss: 0.3412059545516968, acc: 0.9696969985961914)
[2024-11-29 03:12:10,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:10,678][root][INFO] - Training Epoch: 5/10, step 80/574 completed (loss: 0.17338129878044128, acc: 0.9615384340286255)
[2024-11-29 03:12:10,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:10,932][root][INFO] - Training Epoch: 5/10, step 81/574 completed (loss: 0.44381648302078247, acc: 0.8461538553237915)
[2024-11-29 03:12:11,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:11,170][root][INFO] - Training Epoch: 5/10, step 82/574 completed (loss: 0.7603244185447693, acc: 0.8461538553237915)
[2024-11-29 03:12:11,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:11,414][root][INFO] - Training Epoch: 5/10, step 83/574 completed (loss: 0.29377633333206177, acc: 0.90625)
[2024-11-29 03:12:11,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:11,682][root][INFO] - Training Epoch: 5/10, step 84/574 completed (loss: 0.4234079122543335, acc: 0.8840579986572266)
[2024-11-29 03:12:11,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:11,933][root][INFO] - Training Epoch: 5/10, step 85/574 completed (loss: 0.488284707069397, acc: 0.8799999952316284)
[2024-11-29 03:12:12,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:12,195][root][INFO] - Training Epoch: 5/10, step 86/574 completed (loss: 0.258139967918396, acc: 0.9130434989929199)
[2024-11-29 03:12:12,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:12,578][root][INFO] - Training Epoch: 5/10, step 87/574 completed (loss: 1.2267122268676758, acc: 0.7400000095367432)
[2024-11-29 03:12:12,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:12,788][root][INFO] - Training Epoch: 5/10, step 88/574 completed (loss: 1.1392011642456055, acc: 0.7184466123580933)
[2024-11-29 03:12:13,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:13,819][root][INFO] - Training Epoch: 5/10, step 89/574 completed (loss: 1.1939555406570435, acc: 0.708737850189209)
[2024-11-29 03:12:14,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:14,516][root][INFO] - Training Epoch: 5/10, step 90/574 completed (loss: 1.7064266204833984, acc: 0.5537634491920471)
[2024-11-29 03:12:14,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:15,196][root][INFO] - Training Epoch: 5/10, step 91/574 completed (loss: 1.3630270957946777, acc: 0.6206896305084229)
[2024-11-29 03:12:15,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:15,826][root][INFO] - Training Epoch: 5/10, step 92/574 completed (loss: 1.0803804397583008, acc: 0.7263157963752747)
[2024-11-29 03:12:16,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:16,686][root][INFO] - Training Epoch: 5/10, step 93/574 completed (loss: 1.6942381858825684, acc: 0.5346534848213196)
[2024-11-29 03:12:16,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:16,859][root][INFO] - Training Epoch: 5/10, step 94/574 completed (loss: 1.1508725881576538, acc: 0.6129032373428345)
[2024-11-29 03:12:16,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:17,112][root][INFO] - Training Epoch: 5/10, step 95/574 completed (loss: 0.8807103633880615, acc: 0.739130437374115)
[2024-11-29 03:12:17,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:17,370][root][INFO] - Training Epoch: 5/10, step 96/574 completed (loss: 1.5177873373031616, acc: 0.5210084319114685)
[2024-11-29 03:12:17,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:17,650][root][INFO] - Training Epoch: 5/10, step 97/574 completed (loss: 1.5427470207214355, acc: 0.5192307829856873)
[2024-11-29 03:12:17,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:17,934][root][INFO] - Training Epoch: 5/10, step 98/574 completed (loss: 1.801389455795288, acc: 0.525547444820404)
[2024-11-29 03:12:18,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:18,164][root][INFO] - Training Epoch: 5/10, step 99/574 completed (loss: 1.654539942741394, acc: 0.5223880410194397)
[2024-11-29 03:12:18,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:18,401][root][INFO] - Training Epoch: 5/10, step 100/574 completed (loss: 0.3942306637763977, acc: 0.8500000238418579)
[2024-11-29 03:12:18,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:18,662][root][INFO] - Training Epoch: 5/10, step 101/574 completed (loss: 0.047460947185754776, acc: 1.0)
[2024-11-29 03:12:18,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:18,897][root][INFO] - Training Epoch: 5/10, step 102/574 completed (loss: 0.048969417810440063, acc: 1.0)
[2024-11-29 03:12:18,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:19,128][root][INFO] - Training Epoch: 5/10, step 103/574 completed (loss: 0.12578736245632172, acc: 0.9545454382896423)
[2024-11-29 03:12:19,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:19,391][root][INFO] - Training Epoch: 5/10, step 104/574 completed (loss: 0.822891354560852, acc: 0.7413793206214905)
[2024-11-29 03:12:19,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:19,655][root][INFO] - Training Epoch: 5/10, step 105/574 completed (loss: 0.3729351758956909, acc: 0.8837209343910217)
[2024-11-29 03:12:19,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:19,906][root][INFO] - Training Epoch: 5/10, step 106/574 completed (loss: 0.3043356239795685, acc: 0.8799999952316284)
[2024-11-29 03:12:20,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:20,154][root][INFO] - Training Epoch: 5/10, step 107/574 completed (loss: 0.12151729315519333, acc: 0.9411764740943909)
[2024-11-29 03:12:20,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:20,343][root][INFO] - Training Epoch: 5/10, step 108/574 completed (loss: 0.020676126703619957, acc: 1.0)
[2024-11-29 03:12:20,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:20,591][root][INFO] - Training Epoch: 5/10, step 109/574 completed (loss: 0.11046012490987778, acc: 0.976190447807312)
[2024-11-29 03:12:20,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:20,856][root][INFO] - Training Epoch: 5/10, step 110/574 completed (loss: 0.24465928971767426, acc: 0.9384615421295166)
[2024-11-29 03:12:20,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:21,171][root][INFO] - Training Epoch: 5/10, step 111/574 completed (loss: 0.4880025386810303, acc: 0.859649121761322)
[2024-11-29 03:12:21,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:21,457][root][INFO] - Training Epoch: 5/10, step 112/574 completed (loss: 0.7515884041786194, acc: 0.7719298005104065)
[2024-11-29 03:12:21,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:21,669][root][INFO] - Training Epoch: 5/10, step 113/574 completed (loss: 0.4845881760120392, acc: 0.8717948794364929)
[2024-11-29 03:12:21,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:21,957][root][INFO] - Training Epoch: 5/10, step 114/574 completed (loss: 0.2446889728307724, acc: 0.918367326259613)
[2024-11-29 03:12:22,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:22,186][root][INFO] - Training Epoch: 5/10, step 115/574 completed (loss: 0.1173713281750679, acc: 0.9545454382896423)
[2024-11-29 03:12:22,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:22,419][root][INFO] - Training Epoch: 5/10, step 116/574 completed (loss: 0.6288349628448486, acc: 0.841269850730896)
[2024-11-29 03:12:22,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:22,720][root][INFO] - Training Epoch: 5/10, step 117/574 completed (loss: 0.7242231965065002, acc: 0.772357702255249)
[2024-11-29 03:12:22,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:22,963][root][INFO] - Training Epoch: 5/10, step 118/574 completed (loss: 0.30616995692253113, acc: 0.9032257795333862)
[2024-11-29 03:12:23,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:23,673][root][INFO] - Training Epoch: 5/10, step 119/574 completed (loss: 1.3256369829177856, acc: 0.6463878154754639)
[2024-11-29 03:12:23,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:23,923][root][INFO] - Training Epoch: 5/10, step 120/574 completed (loss: 0.5166835188865662, acc: 0.8399999737739563)
[2024-11-29 03:12:24,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:24,224][root][INFO] - Training Epoch: 5/10, step 121/574 completed (loss: 0.37940600514411926, acc: 0.9038461446762085)
[2024-11-29 03:12:24,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:24,491][root][INFO] - Training Epoch: 5/10, step 122/574 completed (loss: 0.18732108175754547, acc: 0.9583333134651184)
[2024-11-29 03:12:24,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:24,721][root][INFO] - Training Epoch: 5/10, step 123/574 completed (loss: 0.5800445675849915, acc: 0.8421052694320679)
[2024-11-29 03:12:24,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:25,000][root][INFO] - Training Epoch: 5/10, step 124/574 completed (loss: 1.5931289196014404, acc: 0.5950919985771179)
[2024-11-29 03:12:25,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:25,265][root][INFO] - Training Epoch: 5/10, step 125/574 completed (loss: 1.4737677574157715, acc: 0.6041666865348816)
[2024-11-29 03:12:25,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:25,486][root][INFO] - Training Epoch: 5/10, step 126/574 completed (loss: 1.26797354221344, acc: 0.6583333611488342)
[2024-11-29 03:12:25,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:25,757][root][INFO] - Training Epoch: 5/10, step 127/574 completed (loss: 1.7082945108413696, acc: 0.5595238208770752)
[2024-11-29 03:12:25,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:26,012][root][INFO] - Training Epoch: 5/10, step 128/574 completed (loss: 1.535615086555481, acc: 0.5948718190193176)
[2024-11-29 03:12:26,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:26,314][root][INFO] - Training Epoch: 5/10, step 129/574 completed (loss: 1.239108681678772, acc: 0.654411792755127)
[2024-11-29 03:12:26,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:26,515][root][INFO] - Training Epoch: 5/10, step 130/574 completed (loss: 0.3473449945449829, acc: 0.9230769276618958)
[2024-11-29 03:12:26,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:26,736][root][INFO] - Training Epoch: 5/10, step 131/574 completed (loss: 0.4512147605419159, acc: 0.782608687877655)
[2024-11-29 03:12:26,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:26,969][root][INFO] - Training Epoch: 5/10, step 132/574 completed (loss: 1.2240233421325684, acc: 0.6875)
[2024-11-29 03:12:27,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:27,219][root][INFO] - Training Epoch: 5/10, step 133/574 completed (loss: 0.3782096803188324, acc: 0.8695651888847351)
[2024-11-29 03:12:27,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:27,475][root][INFO] - Training Epoch: 5/10, step 134/574 completed (loss: 0.7146850228309631, acc: 0.800000011920929)
[2024-11-29 03:12:28,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:28,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:28,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:29,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:29,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:29,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:29,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:30,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:30,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:30,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:31,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:31,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:31,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:31,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:32,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:32,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:32,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:33,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:33,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:33,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:33,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:34,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:34,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:34,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:34,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:35,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:35,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:35,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:35,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:36,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:36,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:36,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:36,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:37,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:37,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:37,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:38,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:38,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:38,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:38,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:39,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:39,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:39,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:39,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:39,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:40,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:40,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:40,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:41,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:41,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:41,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:41,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:42,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:42,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:42,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:43,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:43,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:43,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:43,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:44,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:44,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:44,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:45,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:45,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:45,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:45,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:46,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:46,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:46,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:47,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:47,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:47,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:47,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:48,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:48,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:48,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:48,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:49,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:49,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:49,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:49,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:50,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:50,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:50,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:51,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:51,645][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.0778, device='cuda:0') eval_epoch_loss=tensor(1.1242, device='cuda:0') eval_epoch_acc=tensor(0.7222, device='cuda:0')
[2024-11-29 03:12:51,647][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:12:51,647][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:12:51,844][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_5_step_135_loss_1.1242039203643799/model.pt
[2024-11-29 03:12:51,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:52,134][root][INFO] - Training Epoch: 5/10, step 135/574 completed (loss: 0.353941410779953, acc: 0.8846153616905212)
[2024-11-29 03:12:52,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:52,378][root][INFO] - Training Epoch: 5/10, step 136/574 completed (loss: 0.8188783526420593, acc: 0.761904776096344)
[2024-11-29 03:12:52,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:52,597][root][INFO] - Training Epoch: 5/10, step 137/574 completed (loss: 1.3002281188964844, acc: 0.7333333492279053)
[2024-11-29 03:12:52,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:52,793][root][INFO] - Training Epoch: 5/10, step 138/574 completed (loss: 0.28492599725723267, acc: 0.9130434989929199)
[2024-11-29 03:12:52,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:53,034][root][INFO] - Training Epoch: 5/10, step 139/574 completed (loss: 0.07262784242630005, acc: 1.0)
[2024-11-29 03:12:53,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:53,279][root][INFO] - Training Epoch: 5/10, step 140/574 completed (loss: 0.21724891662597656, acc: 0.9230769276618958)
[2024-11-29 03:12:53,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:53,553][root][INFO] - Training Epoch: 5/10, step 141/574 completed (loss: 0.6156511902809143, acc: 0.8064516186714172)
[2024-11-29 03:12:53,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:53,834][root][INFO] - Training Epoch: 5/10, step 142/574 completed (loss: 0.45702630281448364, acc: 0.8648648858070374)
[2024-11-29 03:12:54,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:54,316][root][INFO] - Training Epoch: 5/10, step 143/574 completed (loss: 0.9428271651268005, acc: 0.6842105388641357)
[2024-11-29 03:12:54,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:54,589][root][INFO] - Training Epoch: 5/10, step 144/574 completed (loss: 0.9616235494613647, acc: 0.7164179086685181)
[2024-11-29 03:12:54,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:54,897][root][INFO] - Training Epoch: 5/10, step 145/574 completed (loss: 0.887127697467804, acc: 0.7244898080825806)
[2024-11-29 03:12:55,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:55,263][root][INFO] - Training Epoch: 5/10, step 146/574 completed (loss: 1.0592130422592163, acc: 0.6382978558540344)
[2024-11-29 03:12:55,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:55,509][root][INFO] - Training Epoch: 5/10, step 147/574 completed (loss: 0.649416983127594, acc: 0.7428571581840515)
[2024-11-29 03:12:55,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:55,738][root][INFO] - Training Epoch: 5/10, step 148/574 completed (loss: 0.39057686924934387, acc: 0.8928571343421936)
[2024-11-29 03:12:55,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:55,938][root][INFO] - Training Epoch: 5/10, step 149/574 completed (loss: 0.3107669949531555, acc: 0.95652174949646)
[2024-11-29 03:12:56,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:56,184][root][INFO] - Training Epoch: 5/10, step 150/574 completed (loss: 0.6860910654067993, acc: 0.7931034564971924)
[2024-11-29 03:12:56,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:56,430][root][INFO] - Training Epoch: 5/10, step 151/574 completed (loss: 0.7139808535575867, acc: 0.804347813129425)
[2024-11-29 03:12:56,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:56,716][root][INFO] - Training Epoch: 5/10, step 152/574 completed (loss: 0.8370056748390198, acc: 0.8305084705352783)
[2024-11-29 03:12:56,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:56,954][root][INFO] - Training Epoch: 5/10, step 153/574 completed (loss: 1.0071340799331665, acc: 0.719298243522644)
[2024-11-29 03:12:57,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:57,206][root][INFO] - Training Epoch: 5/10, step 154/574 completed (loss: 0.7965433597564697, acc: 0.7837837934494019)
[2024-11-29 03:12:57,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:57,450][root][INFO] - Training Epoch: 5/10, step 155/574 completed (loss: 0.09829755872488022, acc: 1.0)
[2024-11-29 03:12:57,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:57,700][root][INFO] - Training Epoch: 5/10, step 156/574 completed (loss: 0.421522855758667, acc: 0.8695651888847351)
[2024-11-29 03:12:57,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:57,979][root][INFO] - Training Epoch: 5/10, step 157/574 completed (loss: 2.637936592102051, acc: 0.3684210479259491)
[2024-11-29 03:12:58,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:59,629][root][INFO] - Training Epoch: 5/10, step 158/574 completed (loss: 1.468737006187439, acc: 0.5810810923576355)
[2024-11-29 03:12:59,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:59,821][root][INFO] - Training Epoch: 5/10, step 159/574 completed (loss: 1.6884849071502686, acc: 0.5)
[2024-11-29 03:12:59,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:00,137][root][INFO] - Training Epoch: 5/10, step 160/574 completed (loss: 1.8377195596694946, acc: 0.5232558250427246)
[2024-11-29 03:13:00,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:00,638][root][INFO] - Training Epoch: 5/10, step 161/574 completed (loss: 1.93942391872406, acc: 0.47058823704719543)
[2024-11-29 03:13:00,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:01,112][root][INFO] - Training Epoch: 5/10, step 162/574 completed (loss: 1.8232605457305908, acc: 0.516853928565979)
[2024-11-29 03:13:01,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:01,308][root][INFO] - Training Epoch: 5/10, step 163/574 completed (loss: 0.4199138581752777, acc: 0.9090909361839294)
[2024-11-29 03:13:01,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:01,502][root][INFO] - Training Epoch: 5/10, step 164/574 completed (loss: 0.6484341621398926, acc: 0.8571428656578064)
[2024-11-29 03:13:01,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:01,675][root][INFO] - Training Epoch: 5/10, step 165/574 completed (loss: 1.4869396686553955, acc: 0.6896551847457886)
[2024-11-29 03:13:01,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:01,958][root][INFO] - Training Epoch: 5/10, step 166/574 completed (loss: 0.16789355874061584, acc: 0.9387755393981934)
[2024-11-29 03:13:02,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:02,231][root][INFO] - Training Epoch: 5/10, step 167/574 completed (loss: 0.2806994915008545, acc: 0.9200000166893005)
[2024-11-29 03:13:02,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:02,546][root][INFO] - Training Epoch: 5/10, step 168/574 completed (loss: 0.4861977994441986, acc: 0.8472222089767456)
[2024-11-29 03:13:02,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:02,798][root][INFO] - Training Epoch: 5/10, step 169/574 completed (loss: 1.221128225326538, acc: 0.7352941036224365)
[2024-11-29 03:13:03,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:03,810][root][INFO] - Training Epoch: 5/10, step 170/574 completed (loss: 1.5465309619903564, acc: 0.6575342416763306)
[2024-11-29 03:13:03,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:04,020][root][INFO] - Training Epoch: 5/10, step 171/574 completed (loss: 0.2430824488401413, acc: 0.9166666865348816)
[2024-11-29 03:13:04,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:04,297][root][INFO] - Training Epoch: 5/10, step 172/574 completed (loss: 1.0748155117034912, acc: 0.6666666865348816)
[2024-11-29 03:13:04,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:04,556][root][INFO] - Training Epoch: 5/10, step 173/574 completed (loss: 0.4216417670249939, acc: 0.8571428656578064)
[2024-11-29 03:13:04,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:05,046][root][INFO] - Training Epoch: 5/10, step 174/574 completed (loss: 1.3733614683151245, acc: 0.6637167930603027)
[2024-11-29 03:13:05,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:05,206][root][INFO] - Training Epoch: 5/10, step 175/574 completed (loss: 1.2290297746658325, acc: 0.6666666865348816)
[2024-11-29 03:13:05,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:05,417][root][INFO] - Training Epoch: 5/10, step 176/574 completed (loss: 0.8331970572471619, acc: 0.7386363744735718)
[2024-11-29 03:13:05,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:06,241][root][INFO] - Training Epoch: 5/10, step 177/574 completed (loss: 1.6698036193847656, acc: 0.580152690410614)
[2024-11-29 03:13:06,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:06,815][root][INFO] - Training Epoch: 5/10, step 178/574 completed (loss: 1.2542976140975952, acc: 0.6814814805984497)
[2024-11-29 03:13:06,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:07,052][root][INFO] - Training Epoch: 5/10, step 179/574 completed (loss: 0.59482342004776, acc: 0.8524590134620667)
[2024-11-29 03:13:07,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:07,282][root][INFO] - Training Epoch: 5/10, step 180/574 completed (loss: 0.03231571242213249, acc: 1.0)
[2024-11-29 03:13:07,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:07,560][root][INFO] - Training Epoch: 5/10, step 181/574 completed (loss: 0.057583097368478775, acc: 1.0)
[2024-11-29 03:13:07,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:07,787][root][INFO] - Training Epoch: 5/10, step 182/574 completed (loss: 0.10507510602474213, acc: 1.0)
[2024-11-29 03:13:07,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:08,039][root][INFO] - Training Epoch: 5/10, step 183/574 completed (loss: 0.3999376595020294, acc: 0.9024389982223511)
[2024-11-29 03:13:08,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:08,317][root][INFO] - Training Epoch: 5/10, step 184/574 completed (loss: 0.9468916058540344, acc: 0.773413896560669)
[2024-11-29 03:13:08,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:08,569][root][INFO] - Training Epoch: 5/10, step 185/574 completed (loss: 1.0619877576828003, acc: 0.7175792455673218)
[2024-11-29 03:13:08,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:08,986][root][INFO] - Training Epoch: 5/10, step 186/574 completed (loss: 0.9951698184013367, acc: 0.7437499761581421)
[2024-11-29 03:13:09,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:09,414][root][INFO] - Training Epoch: 5/10, step 187/574 completed (loss: 1.3527024984359741, acc: 0.6716697812080383)
[2024-11-29 03:13:09,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:09,716][root][INFO] - Training Epoch: 5/10, step 188/574 completed (loss: 0.9595006704330444, acc: 0.725978672504425)
[2024-11-29 03:13:09,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:09,914][root][INFO] - Training Epoch: 5/10, step 189/574 completed (loss: 0.2464052438735962, acc: 0.9599999785423279)
[2024-11-29 03:13:10,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:10,379][root][INFO] - Training Epoch: 5/10, step 190/574 completed (loss: 1.1773940324783325, acc: 0.6744186282157898)
[2024-11-29 03:13:10,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:11,152][root][INFO] - Training Epoch: 5/10, step 191/574 completed (loss: 1.7922066450119019, acc: 0.523809552192688)
[2024-11-29 03:13:11,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:11,962][root][INFO] - Training Epoch: 5/10, step 192/574 completed (loss: 1.6288899183273315, acc: 0.5757575631141663)
[2024-11-29 03:13:12,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:12,608][root][INFO] - Training Epoch: 5/10, step 193/574 completed (loss: 0.8044994473457336, acc: 0.7529411911964417)
[2024-11-29 03:13:12,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:13,565][root][INFO] - Training Epoch: 5/10, step 194/574 completed (loss: 1.310227870941162, acc: 0.654321014881134)
[2024-11-29 03:13:13,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:14,406][root][INFO] - Training Epoch: 5/10, step 195/574 completed (loss: 0.5621299147605896, acc: 0.8064516186714172)
[2024-11-29 03:13:14,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:14,566][root][INFO] - Training Epoch: 5/10, step 196/574 completed (loss: 0.13162143528461456, acc: 0.9642857313156128)
[2024-11-29 03:13:14,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:14,825][root][INFO] - Training Epoch: 5/10, step 197/574 completed (loss: 0.6676052212715149, acc: 0.824999988079071)
[2024-11-29 03:13:14,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:15,079][root][INFO] - Training Epoch: 5/10, step 198/574 completed (loss: 0.7100601196289062, acc: 0.75)
[2024-11-29 03:13:15,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:15,284][root][INFO] - Training Epoch: 5/10, step 199/574 completed (loss: 1.2987674474716187, acc: 0.6838235259056091)
[2024-11-29 03:13:15,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:15,551][root][INFO] - Training Epoch: 5/10, step 200/574 completed (loss: 1.03658127784729, acc: 0.694915235042572)
[2024-11-29 03:13:15,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:15,814][root][INFO] - Training Epoch: 5/10, step 201/574 completed (loss: 0.9530023336410522, acc: 0.7761194109916687)
[2024-11-29 03:13:15,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:16,081][root][INFO] - Training Epoch: 5/10, step 202/574 completed (loss: 1.0760133266448975, acc: 0.7184466123580933)
[2024-11-29 03:13:16,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:16,332][root][INFO] - Training Epoch: 5/10, step 203/574 completed (loss: 0.823933482170105, acc: 0.7936508059501648)
[2024-11-29 03:13:16,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:16,501][root][INFO] - Training Epoch: 5/10, step 204/574 completed (loss: 0.34200701117515564, acc: 0.8791208863258362)
[2024-11-29 03:13:16,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:16,801][root][INFO] - Training Epoch: 5/10, step 205/574 completed (loss: 0.6994088292121887, acc: 0.7802690863609314)
[2024-11-29 03:13:16,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:17,129][root][INFO] - Training Epoch: 5/10, step 206/574 completed (loss: 0.8700215220451355, acc: 0.7598425149917603)
[2024-11-29 03:13:17,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:17,367][root][INFO] - Training Epoch: 5/10, step 207/574 completed (loss: 0.5200402736663818, acc: 0.857758641242981)
[2024-11-29 03:13:17,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:17,662][root][INFO] - Training Epoch: 5/10, step 208/574 completed (loss: 0.677734911441803, acc: 0.8260869383811951)
[2024-11-29 03:13:17,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:17,937][root][INFO] - Training Epoch: 5/10, step 209/574 completed (loss: 0.6442780494689941, acc: 0.8171206116676331)
[2024-11-29 03:13:18,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:18,189][root][INFO] - Training Epoch: 5/10, step 210/574 completed (loss: 0.5619714856147766, acc: 0.8586956262588501)
[2024-11-29 03:13:18,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:18,437][root][INFO] - Training Epoch: 5/10, step 211/574 completed (loss: 0.14010843634605408, acc: 0.95652174949646)
[2024-11-29 03:13:18,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:18,685][root][INFO] - Training Epoch: 5/10, step 212/574 completed (loss: 0.22402653098106384, acc: 0.9285714030265808)
[2024-11-29 03:13:18,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:18,914][root][INFO] - Training Epoch: 5/10, step 213/574 completed (loss: 0.4651283025741577, acc: 0.8723404407501221)
[2024-11-29 03:13:19,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:19,540][root][INFO] - Training Epoch: 5/10, step 214/574 completed (loss: 0.4652160406112671, acc: 0.8769230842590332)
[2024-11-29 03:13:19,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:19,748][root][INFO] - Training Epoch: 5/10, step 215/574 completed (loss: 0.47484347224235535, acc: 0.8648648858070374)
[2024-11-29 03:13:19,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:19,946][root][INFO] - Training Epoch: 5/10, step 216/574 completed (loss: 0.2539862394332886, acc: 0.9418604373931885)
[2024-11-29 03:13:20,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:20,392][root][INFO] - Training Epoch: 5/10, step 217/574 completed (loss: 0.37661218643188477, acc: 0.8828828930854797)
[2024-11-29 03:13:20,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:20,687][root][INFO] - Training Epoch: 5/10, step 218/574 completed (loss: 0.37566524744033813, acc: 0.9222221970558167)
[2024-11-29 03:13:20,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:20,951][root][INFO] - Training Epoch: 5/10, step 219/574 completed (loss: 0.051498908549547195, acc: 1.0)
[2024-11-29 03:13:21,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:21,162][root][INFO] - Training Epoch: 5/10, step 220/574 completed (loss: 0.126486673951149, acc: 0.9259259104728699)
[2024-11-29 03:13:21,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:21,427][root][INFO] - Training Epoch: 5/10, step 221/574 completed (loss: 0.1910271793603897, acc: 0.9200000166893005)
[2024-11-29 03:13:21,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:21,673][root][INFO] - Training Epoch: 5/10, step 222/574 completed (loss: 1.0721373558044434, acc: 0.692307710647583)
[2024-11-29 03:13:21,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:22,373][root][INFO] - Training Epoch: 5/10, step 223/574 completed (loss: 0.5979785323143005, acc: 0.864130437374115)
[2024-11-29 03:13:22,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:22,825][root][INFO] - Training Epoch: 5/10, step 224/574 completed (loss: 0.8762381076812744, acc: 0.7670454382896423)
[2024-11-29 03:13:22,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:23,172][root][INFO] - Training Epoch: 5/10, step 225/574 completed (loss: 0.836531937122345, acc: 0.7765957713127136)
[2024-11-29 03:13:23,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:23,414][root][INFO] - Training Epoch: 5/10, step 226/574 completed (loss: 0.4970768988132477, acc: 0.7735849022865295)
[2024-11-29 03:13:23,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:23,677][root][INFO] - Training Epoch: 5/10, step 227/574 completed (loss: 0.3009810745716095, acc: 0.8999999761581421)
[2024-11-29 03:13:23,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:23,901][root][INFO] - Training Epoch: 5/10, step 228/574 completed (loss: 0.8136322498321533, acc: 0.8139534592628479)
[2024-11-29 03:13:23,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:24,106][root][INFO] - Training Epoch: 5/10, step 229/574 completed (loss: 1.8064101934432983, acc: 0.5333333611488342)
[2024-11-29 03:13:24,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:24,371][root][INFO] - Training Epoch: 5/10, step 230/574 completed (loss: 2.6961207389831543, acc: 0.38947367668151855)
[2024-11-29 03:13:24,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:24,608][root][INFO] - Training Epoch: 5/10, step 231/574 completed (loss: 1.9695885181427002, acc: 0.5222222208976746)
[2024-11-29 03:13:24,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:24,936][root][INFO] - Training Epoch: 5/10, step 232/574 completed (loss: 2.1387789249420166, acc: 0.47777777910232544)
[2024-11-29 03:13:25,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:25,345][root][INFO] - Training Epoch: 5/10, step 233/574 completed (loss: 2.4002060890197754, acc: 0.4403669834136963)
[2024-11-29 03:13:25,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:25,727][root][INFO] - Training Epoch: 5/10, step 234/574 completed (loss: 2.178278923034668, acc: 0.5076923370361328)
[2024-11-29 03:13:25,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:25,960][root][INFO] - Training Epoch: 5/10, step 235/574 completed (loss: 0.4929904341697693, acc: 0.8421052694320679)
[2024-11-29 03:13:26,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:26,204][root][INFO] - Training Epoch: 5/10, step 236/574 completed (loss: 0.29794418811798096, acc: 0.9166666865348816)
[2024-11-29 03:13:26,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:26,449][root][INFO] - Training Epoch: 5/10, step 237/574 completed (loss: 0.9851825833320618, acc: 0.6363636255264282)
[2024-11-29 03:13:26,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:26,688][root][INFO] - Training Epoch: 5/10, step 238/574 completed (loss: 0.8881814479827881, acc: 0.7407407164573669)
[2024-11-29 03:13:26,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:26,930][root][INFO] - Training Epoch: 5/10, step 239/574 completed (loss: 0.5278147459030151, acc: 0.8857142925262451)
[2024-11-29 03:13:27,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:27,206][root][INFO] - Training Epoch: 5/10, step 240/574 completed (loss: 1.225828766822815, acc: 0.5909090638160706)
[2024-11-29 03:13:27,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:27,473][root][INFO] - Training Epoch: 5/10, step 241/574 completed (loss: 0.4472370147705078, acc: 0.8636363744735718)
[2024-11-29 03:13:27,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:27,968][root][INFO] - Training Epoch: 5/10, step 242/574 completed (loss: 1.3148514032363892, acc: 0.5806451439857483)
[2024-11-29 03:13:28,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:28,403][root][INFO] - Training Epoch: 5/10, step 243/574 completed (loss: 0.8133693337440491, acc: 0.7727272510528564)
[2024-11-29 03:13:28,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:28,570][root][INFO] - Training Epoch: 5/10, step 244/574 completed (loss: 0.09405660629272461, acc: 0.9523809552192688)
[2024-11-29 03:13:28,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:28,814][root][INFO] - Training Epoch: 5/10, step 245/574 completed (loss: 0.6658269166946411, acc: 0.8461538553237915)
[2024-11-29 03:13:28,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:29,042][root][INFO] - Training Epoch: 5/10, step 246/574 completed (loss: 0.29304444789886475, acc: 0.9354838728904724)
[2024-11-29 03:13:29,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:29,281][root][INFO] - Training Epoch: 5/10, step 247/574 completed (loss: 0.06040932610630989, acc: 1.0)
[2024-11-29 03:13:29,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:29,526][root][INFO] - Training Epoch: 5/10, step 248/574 completed (loss: 0.31335458159446716, acc: 0.8648648858070374)
[2024-11-29 03:13:29,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:29,747][root][INFO] - Training Epoch: 5/10, step 249/574 completed (loss: 0.4545600414276123, acc: 0.8918918967247009)
[2024-11-29 03:13:29,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:29,990][root][INFO] - Training Epoch: 5/10, step 250/574 completed (loss: 0.1443796455860138, acc: 0.9729729890823364)
[2024-11-29 03:13:30,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:30,267][root][INFO] - Training Epoch: 5/10, step 251/574 completed (loss: 0.35701584815979004, acc: 0.8676470518112183)
[2024-11-29 03:13:30,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:30,507][root][INFO] - Training Epoch: 5/10, step 252/574 completed (loss: 0.11591512709856033, acc: 0.9512194991111755)
[2024-11-29 03:13:30,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:30,744][root][INFO] - Training Epoch: 5/10, step 253/574 completed (loss: 0.1193799376487732, acc: 0.9599999785423279)
[2024-11-29 03:13:30,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:30,975][root][INFO] - Training Epoch: 5/10, step 254/574 completed (loss: 0.014338932000100613, acc: 1.0)
[2024-11-29 03:13:31,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:31,172][root][INFO] - Training Epoch: 5/10, step 255/574 completed (loss: 0.41249850392341614, acc: 0.9354838728904724)
[2024-11-29 03:13:31,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:31,439][root][INFO] - Training Epoch: 5/10, step 256/574 completed (loss: 0.371487021446228, acc: 0.9122806787490845)
[2024-11-29 03:13:31,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:31,686][root][INFO] - Training Epoch: 5/10, step 257/574 completed (loss: 0.31416210532188416, acc: 0.9285714030265808)
[2024-11-29 03:13:31,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:31,942][root][INFO] - Training Epoch: 5/10, step 258/574 completed (loss: 0.11089533567428589, acc: 0.9605262875556946)
[2024-11-29 03:13:32,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:32,417][root][INFO] - Training Epoch: 5/10, step 259/574 completed (loss: 0.587955117225647, acc: 0.849056601524353)
[2024-11-29 03:13:32,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:32,908][root][INFO] - Training Epoch: 5/10, step 260/574 completed (loss: 0.6513183116912842, acc: 0.8333333134651184)
[2024-11-29 03:13:32,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:33,109][root][INFO] - Training Epoch: 5/10, step 261/574 completed (loss: 0.15848563611507416, acc: 0.9722222089767456)
[2024-11-29 03:13:33,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:33,358][root][INFO] - Training Epoch: 5/10, step 262/574 completed (loss: 0.3057425916194916, acc: 0.9032257795333862)
[2024-11-29 03:13:33,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:33,605][root][INFO] - Training Epoch: 5/10, step 263/574 completed (loss: 1.2827421426773071, acc: 0.7200000286102295)
[2024-11-29 03:13:33,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:33,847][root][INFO] - Training Epoch: 5/10, step 264/574 completed (loss: 0.7816810607910156, acc: 0.7083333134651184)
[2024-11-29 03:13:34,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:34,651][root][INFO] - Training Epoch: 5/10, step 265/574 completed (loss: 1.3683542013168335, acc: 0.6639999747276306)
[2024-11-29 03:13:34,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:34,868][root][INFO] - Training Epoch: 5/10, step 266/574 completed (loss: 1.1910358667373657, acc: 0.6966292262077332)
[2024-11-29 03:13:34,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:35,112][root][INFO] - Training Epoch: 5/10, step 267/574 completed (loss: 1.0866860151290894, acc: 0.7027027010917664)
[2024-11-29 03:13:35,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:35,470][root][INFO] - Training Epoch: 5/10, step 268/574 completed (loss: 0.7017421126365662, acc: 0.8103448152542114)
[2024-11-29 03:13:35,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:35,644][root][INFO] - Training Epoch: 5/10, step 269/574 completed (loss: 0.05334446579217911, acc: 1.0)
[2024-11-29 03:13:35,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:35,831][root][INFO] - Training Epoch: 5/10, step 270/574 completed (loss: 0.1086723804473877, acc: 1.0)
[2024-11-29 03:13:35,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:36,036][root][INFO] - Training Epoch: 5/10, step 271/574 completed (loss: 0.11427042633295059, acc: 0.9375)
[2024-11-29 03:13:36,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:36,280][root][INFO] - Training Epoch: 5/10, step 272/574 completed (loss: 0.08700048178434372, acc: 0.9666666388511658)
[2024-11-29 03:13:36,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:36,557][root][INFO] - Training Epoch: 5/10, step 273/574 completed (loss: 0.36741065979003906, acc: 0.9166666865348816)
[2024-11-29 03:13:36,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:36,760][root][INFO] - Training Epoch: 5/10, step 274/574 completed (loss: 0.10362718999385834, acc: 0.96875)
[2024-11-29 03:13:36,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:36,992][root][INFO] - Training Epoch: 5/10, step 275/574 completed (loss: 0.12441707402467728, acc: 1.0)
[2024-11-29 03:13:37,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:37,214][root][INFO] - Training Epoch: 5/10, step 276/574 completed (loss: 0.4135887026786804, acc: 0.8965517282485962)
[2024-11-29 03:13:37,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:37,438][root][INFO] - Training Epoch: 5/10, step 277/574 completed (loss: 0.13424094021320343, acc: 0.9200000166893005)
[2024-11-29 03:13:38,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:38,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:38,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:38,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:39,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:39,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:39,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:39,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:40,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:40,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:40,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:40,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:41,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:41,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:41,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:42,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:42,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:42,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:43,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:43,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:43,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:44,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:44,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:44,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:44,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:45,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:45,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:45,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:46,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:46,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:46,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:46,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:46,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:47,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:47,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:47,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:47,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:48,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:48,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:48,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:48,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:49,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:49,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:49,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:50,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:50,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:50,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:50,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:51,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:51,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:51,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:51,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:52,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:52,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:52,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:52,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:53,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:53,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:53,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:53,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:54,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:54,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:54,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:55,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:55,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:55,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:55,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:56,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:56,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:56,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:56,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:57,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:57,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:57,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:57,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:58,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:58,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:58,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:58,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:58,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:59,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:59,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:59,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:00,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:00,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:01,038][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.1440, device='cuda:0') eval_epoch_loss=tensor(1.1455, device='cuda:0') eval_epoch_acc=tensor(0.7422, device='cuda:0')
[2024-11-29 03:14:01,039][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:14:01,039][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:14:01,210][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_5_step_278_loss_1.1455086469650269/model.pt
[2024-11-29 03:14:01,213][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 5 is 0.7422412633895874
[2024-11-29 03:14:01,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:01,431][root][INFO] - Training Epoch: 5/10, step 278/574 completed (loss: 0.5039106011390686, acc: 0.8297872543334961)
[2024-11-29 03:14:01,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:01,616][root][INFO] - Training Epoch: 5/10, step 279/574 completed (loss: 0.27420926094055176, acc: 0.9583333134651184)
[2024-11-29 03:14:01,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:01,816][root][INFO] - Training Epoch: 5/10, step 280/574 completed (loss: 0.08818387985229492, acc: 0.9772727489471436)
[2024-11-29 03:14:01,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:02,131][root][INFO] - Training Epoch: 5/10, step 281/574 completed (loss: 1.0799514055252075, acc: 0.6626505851745605)
[2024-11-29 03:14:02,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:02,380][root][INFO] - Training Epoch: 5/10, step 282/574 completed (loss: 1.0413706302642822, acc: 0.7222222089767456)
[2024-11-29 03:14:02,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:02,573][root][INFO] - Training Epoch: 5/10, step 283/574 completed (loss: 0.23441119492053986, acc: 0.9473684430122375)
[2024-11-29 03:14:02,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:02,779][root][INFO] - Training Epoch: 5/10, step 284/574 completed (loss: 0.14631173014640808, acc: 0.9411764740943909)
[2024-11-29 03:14:02,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:03,011][root][INFO] - Training Epoch: 5/10, step 285/574 completed (loss: 0.3550757169723511, acc: 0.8999999761581421)
[2024-11-29 03:14:03,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:03,230][root][INFO] - Training Epoch: 5/10, step 286/574 completed (loss: 0.5812928676605225, acc: 0.84375)
[2024-11-29 03:14:03,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:03,481][root][INFO] - Training Epoch: 5/10, step 287/574 completed (loss: 0.8951787352561951, acc: 0.7519999742507935)
[2024-11-29 03:14:03,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:03,708][root][INFO] - Training Epoch: 5/10, step 288/574 completed (loss: 0.5832244753837585, acc: 0.8791208863258362)
[2024-11-29 03:14:03,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:03,944][root][INFO] - Training Epoch: 5/10, step 289/574 completed (loss: 0.6105353236198425, acc: 0.8322981595993042)
[2024-11-29 03:14:04,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:04,199][root][INFO] - Training Epoch: 5/10, step 290/574 completed (loss: 0.7457112669944763, acc: 0.7938144207000732)
[2024-11-29 03:14:04,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:04,462][root][INFO] - Training Epoch: 5/10, step 291/574 completed (loss: 0.10741333663463593, acc: 1.0)
[2024-11-29 03:14:04,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:04,697][root][INFO] - Training Epoch: 5/10, step 292/574 completed (loss: 0.6068549156188965, acc: 0.8571428656578064)
[2024-11-29 03:14:04,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:04,938][root][INFO] - Training Epoch: 5/10, step 293/574 completed (loss: 0.27619871497154236, acc: 0.9482758641242981)
[2024-11-29 03:14:05,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:05,319][root][INFO] - Training Epoch: 5/10, step 294/574 completed (loss: 0.7138974070549011, acc: 0.8181818127632141)
[2024-11-29 03:14:05,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:05,775][root][INFO] - Training Epoch: 5/10, step 295/574 completed (loss: 1.0422848463058472, acc: 0.7061855792999268)
[2024-11-29 03:14:05,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:05,956][root][INFO] - Training Epoch: 5/10, step 296/574 completed (loss: 0.6075375080108643, acc: 0.8620689511299133)
[2024-11-29 03:14:06,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:06,163][root][INFO] - Training Epoch: 5/10, step 297/574 completed (loss: 0.10236936062574387, acc: 1.0)
[2024-11-29 03:14:06,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:06,389][root][INFO] - Training Epoch: 5/10, step 298/574 completed (loss: 0.3451157510280609, acc: 0.8684210777282715)
[2024-11-29 03:14:06,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:06,614][root][INFO] - Training Epoch: 5/10, step 299/574 completed (loss: 0.22125862538814545, acc: 0.9285714030265808)
[2024-11-29 03:14:06,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:06,858][root][INFO] - Training Epoch: 5/10, step 300/574 completed (loss: 0.02424638159573078, acc: 1.0)
[2024-11-29 03:14:06,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:07,094][root][INFO] - Training Epoch: 5/10, step 301/574 completed (loss: 0.287077933549881, acc: 0.9245283007621765)
[2024-11-29 03:14:07,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:07,319][root][INFO] - Training Epoch: 5/10, step 302/574 completed (loss: 0.10286270081996918, acc: 0.9622641801834106)
[2024-11-29 03:14:07,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:07,533][root][INFO] - Training Epoch: 5/10, step 303/574 completed (loss: 0.06767977774143219, acc: 1.0)
[2024-11-29 03:14:07,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:07,771][root][INFO] - Training Epoch: 5/10, step 304/574 completed (loss: 0.0812450721859932, acc: 0.96875)
[2024-11-29 03:14:07,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:08,014][root][INFO] - Training Epoch: 5/10, step 305/574 completed (loss: 0.6107749938964844, acc: 0.8524590134620667)
[2024-11-29 03:14:08,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:08,223][root][INFO] - Training Epoch: 5/10, step 306/574 completed (loss: 0.2279413342475891, acc: 0.9333333373069763)
[2024-11-29 03:14:08,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:08,444][root][INFO] - Training Epoch: 5/10, step 307/574 completed (loss: 0.01042909361422062, acc: 1.0)
[2024-11-29 03:14:08,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:08,686][root][INFO] - Training Epoch: 5/10, step 308/574 completed (loss: 0.1861150860786438, acc: 0.9275362491607666)
[2024-11-29 03:14:08,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:09,014][root][INFO] - Training Epoch: 5/10, step 309/574 completed (loss: 0.34352439641952515, acc: 0.9027777910232544)
[2024-11-29 03:14:09,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:09,216][root][INFO] - Training Epoch: 5/10, step 310/574 completed (loss: 0.3026125431060791, acc: 0.9277108311653137)
[2024-11-29 03:14:09,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:09,461][root][INFO] - Training Epoch: 5/10, step 311/574 completed (loss: 0.43028509616851807, acc: 0.8846153616905212)
[2024-11-29 03:14:09,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:09,723][root][INFO] - Training Epoch: 5/10, step 312/574 completed (loss: 0.2413543462753296, acc: 0.9081632494926453)
[2024-11-29 03:14:09,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:09,965][root][INFO] - Training Epoch: 5/10, step 313/574 completed (loss: 0.0501522533595562, acc: 1.0)
[2024-11-29 03:14:10,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:10,200][root][INFO] - Training Epoch: 5/10, step 314/574 completed (loss: 0.05760042741894722, acc: 1.0)
[2024-11-29 03:14:10,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:10,437][root][INFO] - Training Epoch: 5/10, step 315/574 completed (loss: 0.13948072493076324, acc: 0.9354838728904724)
[2024-11-29 03:14:10,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:10,660][root][INFO] - Training Epoch: 5/10, step 316/574 completed (loss: 1.4337286949157715, acc: 0.7096773982048035)
[2024-11-29 03:14:10,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:10,899][root][INFO] - Training Epoch: 5/10, step 317/574 completed (loss: 0.13536788523197174, acc: 0.9701492786407471)
[2024-11-29 03:14:11,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:11,138][root][INFO] - Training Epoch: 5/10, step 318/574 completed (loss: 0.11984601616859436, acc: 0.9807692170143127)
[2024-11-29 03:14:11,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:11,369][root][INFO] - Training Epoch: 5/10, step 319/574 completed (loss: 0.08103825151920319, acc: 0.9777777791023254)
[2024-11-29 03:14:11,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:11,609][root][INFO] - Training Epoch: 5/10, step 320/574 completed (loss: 0.07283440977334976, acc: 0.9677419066429138)
[2024-11-29 03:14:11,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:11,823][root][INFO] - Training Epoch: 5/10, step 321/574 completed (loss: 0.051517024636268616, acc: 0.9800000190734863)
[2024-11-29 03:14:11,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:12,062][root][INFO] - Training Epoch: 5/10, step 322/574 completed (loss: 1.0367709398269653, acc: 0.6666666865348816)
[2024-11-29 03:14:12,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:12,281][root][INFO] - Training Epoch: 5/10, step 323/574 completed (loss: 1.4437544345855713, acc: 0.5428571701049805)
[2024-11-29 03:14:12,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:12,510][root][INFO] - Training Epoch: 5/10, step 324/574 completed (loss: 1.1863377094268799, acc: 0.6666666865348816)
[2024-11-29 03:14:12,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:12,733][root][INFO] - Training Epoch: 5/10, step 325/574 completed (loss: 2.1171627044677734, acc: 0.5121951103210449)
[2024-11-29 03:14:12,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:12,963][root][INFO] - Training Epoch: 5/10, step 326/574 completed (loss: 1.6148593425750732, acc: 0.44736841320991516)
[2024-11-29 03:14:13,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:13,193][root][INFO] - Training Epoch: 5/10, step 327/574 completed (loss: 0.4841994643211365, acc: 0.8947368264198303)
[2024-11-29 03:14:13,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:13,412][root][INFO] - Training Epoch: 5/10, step 328/574 completed (loss: 0.16011998057365417, acc: 0.9642857313156128)
[2024-11-29 03:14:13,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:13,676][root][INFO] - Training Epoch: 5/10, step 329/574 completed (loss: 0.03815910220146179, acc: 1.0)
[2024-11-29 03:14:13,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:13,885][root][INFO] - Training Epoch: 5/10, step 330/574 completed (loss: 0.027362236753106117, acc: 1.0)
[2024-11-29 03:14:13,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:14,114][root][INFO] - Training Epoch: 5/10, step 331/574 completed (loss: 0.2578651010990143, acc: 0.9032257795333862)
[2024-11-29 03:14:14,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:14,375][root][INFO] - Training Epoch: 5/10, step 332/574 completed (loss: 0.1909770965576172, acc: 0.9298245906829834)
[2024-11-29 03:14:14,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:14,570][root][INFO] - Training Epoch: 5/10, step 333/574 completed (loss: 0.19159053266048431, acc: 0.9375)
[2024-11-29 03:14:14,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:14,799][root][INFO] - Training Epoch: 5/10, step 334/574 completed (loss: 0.04302074387669563, acc: 1.0)
[2024-11-29 03:14:14,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:15,016][root][INFO] - Training Epoch: 5/10, step 335/574 completed (loss: 0.14671842753887177, acc: 0.8947368264198303)
[2024-11-29 03:14:15,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:15,254][root][INFO] - Training Epoch: 5/10, step 336/574 completed (loss: 1.1042548418045044, acc: 0.6800000071525574)
[2024-11-29 03:14:15,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:15,503][root][INFO] - Training Epoch: 5/10, step 337/574 completed (loss: 1.6065196990966797, acc: 0.6206896305084229)
[2024-11-29 03:14:15,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:15,741][root][INFO] - Training Epoch: 5/10, step 338/574 completed (loss: 1.3808212280273438, acc: 0.6382978558540344)
[2024-11-29 03:14:15,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:15,976][root][INFO] - Training Epoch: 5/10, step 339/574 completed (loss: 1.4808385372161865, acc: 0.650602400302887)
[2024-11-29 03:14:16,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:16,203][root][INFO] - Training Epoch: 5/10, step 340/574 completed (loss: 0.016199462115764618, acc: 1.0)
[2024-11-29 03:14:16,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:16,438][root][INFO] - Training Epoch: 5/10, step 341/574 completed (loss: 0.49260398745536804, acc: 0.9487179517745972)
[2024-11-29 03:14:16,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:16,686][root][INFO] - Training Epoch: 5/10, step 342/574 completed (loss: 0.560414731502533, acc: 0.8554216623306274)
[2024-11-29 03:14:16,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:16,929][root][INFO] - Training Epoch: 5/10, step 343/574 completed (loss: 1.033698320388794, acc: 0.7547169923782349)
[2024-11-29 03:14:17,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:17,169][root][INFO] - Training Epoch: 5/10, step 344/574 completed (loss: 0.14264443516731262, acc: 0.949367105960846)
[2024-11-29 03:14:17,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:17,400][root][INFO] - Training Epoch: 5/10, step 345/574 completed (loss: 0.08530198037624359, acc: 0.9803921580314636)
[2024-11-29 03:14:17,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:17,629][root][INFO] - Training Epoch: 5/10, step 346/574 completed (loss: 0.4841958284378052, acc: 0.8656716346740723)
[2024-11-29 03:14:17,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:17,874][root][INFO] - Training Epoch: 5/10, step 347/574 completed (loss: 0.03515253961086273, acc: 1.0)
[2024-11-29 03:14:17,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:18,113][root][INFO] - Training Epoch: 5/10, step 348/574 completed (loss: 0.1321285516023636, acc: 0.9599999785423279)
[2024-11-29 03:14:18,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:18,400][root][INFO] - Training Epoch: 5/10, step 349/574 completed (loss: 0.858955442905426, acc: 0.7777777910232544)
[2024-11-29 03:14:18,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:18,676][root][INFO] - Training Epoch: 5/10, step 350/574 completed (loss: 0.579587996006012, acc: 0.8604651093482971)
[2024-11-29 03:14:18,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:18,936][root][INFO] - Training Epoch: 5/10, step 351/574 completed (loss: 0.24174244701862335, acc: 0.9230769276618958)
[2024-11-29 03:14:19,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:19,211][root][INFO] - Training Epoch: 5/10, step 352/574 completed (loss: 1.1197508573532104, acc: 0.6888889074325562)
[2024-11-29 03:14:19,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:19,477][root][INFO] - Training Epoch: 5/10, step 353/574 completed (loss: 0.048898447304964066, acc: 1.0)
[2024-11-29 03:14:19,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:19,750][root][INFO] - Training Epoch: 5/10, step 354/574 completed (loss: 0.3413095772266388, acc: 0.8461538553237915)
[2024-11-29 03:14:19,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:20,034][root][INFO] - Training Epoch: 5/10, step 355/574 completed (loss: 1.2238067388534546, acc: 0.7032967209815979)
[2024-11-29 03:14:20,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:20,468][root][INFO] - Training Epoch: 5/10, step 356/574 completed (loss: 0.7674539685249329, acc: 0.782608687877655)
[2024-11-29 03:14:20,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:20,713][root][INFO] - Training Epoch: 5/10, step 357/574 completed (loss: 0.4235250651836395, acc: 0.8478260636329651)
[2024-11-29 03:14:20,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:20,934][root][INFO] - Training Epoch: 5/10, step 358/574 completed (loss: 0.5417508482933044, acc: 0.8367347121238708)
[2024-11-29 03:14:21,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:21,160][root][INFO] - Training Epoch: 5/10, step 359/574 completed (loss: 0.009686135686933994, acc: 1.0)
[2024-11-29 03:14:21,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:21,397][root][INFO] - Training Epoch: 5/10, step 360/574 completed (loss: 0.15607677400112152, acc: 0.9230769276618958)
[2024-11-29 03:14:21,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:21,616][root][INFO] - Training Epoch: 5/10, step 361/574 completed (loss: 0.6573997139930725, acc: 0.8048780560493469)
[2024-11-29 03:14:21,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:21,851][root][INFO] - Training Epoch: 5/10, step 362/574 completed (loss: 0.5427302718162537, acc: 0.8666666746139526)
[2024-11-29 03:14:21,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:22,115][root][INFO] - Training Epoch: 5/10, step 363/574 completed (loss: 0.16892221570014954, acc: 0.9736841917037964)
[2024-11-29 03:14:22,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:22,372][root][INFO] - Training Epoch: 5/10, step 364/574 completed (loss: 0.15314963459968567, acc: 0.9756097793579102)
[2024-11-29 03:14:22,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:22,628][root][INFO] - Training Epoch: 5/10, step 365/574 completed (loss: 0.05844605341553688, acc: 1.0)
[2024-11-29 03:14:22,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:22,859][root][INFO] - Training Epoch: 5/10, step 366/574 completed (loss: 0.024561041966080666, acc: 1.0)
[2024-11-29 03:14:22,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:23,111][root][INFO] - Training Epoch: 5/10, step 367/574 completed (loss: 0.14157310128211975, acc: 0.95652174949646)
[2024-11-29 03:14:23,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:23,306][root][INFO] - Training Epoch: 5/10, step 368/574 completed (loss: 0.2582556903362274, acc: 0.9285714030265808)
[2024-11-29 03:14:23,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:23,543][root][INFO] - Training Epoch: 5/10, step 369/574 completed (loss: 0.4521581828594208, acc: 0.90625)
[2024-11-29 03:14:23,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:24,052][root][INFO] - Training Epoch: 5/10, step 370/574 completed (loss: 1.0537484884262085, acc: 0.7212121486663818)
[2024-11-29 03:14:24,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:24,844][root][INFO] - Training Epoch: 5/10, step 371/574 completed (loss: 0.559785783290863, acc: 0.849056601524353)
[2024-11-29 03:14:24,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:25,120][root][INFO] - Training Epoch: 5/10, step 372/574 completed (loss: 0.36017680168151855, acc: 0.8999999761581421)
[2024-11-29 03:14:25,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:25,376][root][INFO] - Training Epoch: 5/10, step 373/574 completed (loss: 0.1560553014278412, acc: 0.9642857313156128)
[2024-11-29 03:14:25,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:25,628][root][INFO] - Training Epoch: 5/10, step 374/574 completed (loss: 0.08714424818754196, acc: 1.0)
[2024-11-29 03:14:25,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:25,860][root][INFO] - Training Epoch: 5/10, step 375/574 completed (loss: 0.027293803170323372, acc: 1.0)
[2024-11-29 03:14:25,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:26,133][root][INFO] - Training Epoch: 5/10, step 376/574 completed (loss: 0.14270839095115662, acc: 0.95652174949646)
[2024-11-29 03:14:26,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:26,398][root][INFO] - Training Epoch: 5/10, step 377/574 completed (loss: 0.12459257245063782, acc: 0.9583333134651184)
[2024-11-29 03:14:26,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:26,655][root][INFO] - Training Epoch: 5/10, step 378/574 completed (loss: 0.10337474942207336, acc: 0.9473684430122375)
[2024-11-29 03:14:26,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:27,137][root][INFO] - Training Epoch: 5/10, step 379/574 completed (loss: 0.5192169547080994, acc: 0.85628741979599)
[2024-11-29 03:14:27,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:27,464][root][INFO] - Training Epoch: 5/10, step 380/574 completed (loss: 0.4922148585319519, acc: 0.8796992301940918)
[2024-11-29 03:14:27,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:28,601][root][INFO] - Training Epoch: 5/10, step 381/574 completed (loss: 0.8933459520339966, acc: 0.7860962748527527)
[2024-11-29 03:14:28,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:29,075][root][INFO] - Training Epoch: 5/10, step 382/574 completed (loss: 0.27378231287002563, acc: 0.9279279112815857)
[2024-11-29 03:14:29,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:29,318][root][INFO] - Training Epoch: 5/10, step 383/574 completed (loss: 0.2182503640651703, acc: 0.9642857313156128)
[2024-11-29 03:14:29,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:29,547][root][INFO] - Training Epoch: 5/10, step 384/574 completed (loss: 0.04214492812752724, acc: 1.0)
[2024-11-29 03:14:29,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:29,795][root][INFO] - Training Epoch: 5/10, step 385/574 completed (loss: 0.16006511449813843, acc: 0.96875)
[2024-11-29 03:14:29,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:30,052][root][INFO] - Training Epoch: 5/10, step 386/574 completed (loss: 0.030474040657281876, acc: 1.0)
[2024-11-29 03:14:30,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:30,324][root][INFO] - Training Epoch: 5/10, step 387/574 completed (loss: 0.054447706788778305, acc: 1.0)
[2024-11-29 03:14:30,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:30,578][root][INFO] - Training Epoch: 5/10, step 388/574 completed (loss: 0.008459814824163914, acc: 1.0)
[2024-11-29 03:14:30,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:30,829][root][INFO] - Training Epoch: 5/10, step 389/574 completed (loss: 0.08809492737054825, acc: 0.949999988079071)
[2024-11-29 03:14:30,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:31,102][root][INFO] - Training Epoch: 5/10, step 390/574 completed (loss: 0.5361967086791992, acc: 0.9047619104385376)
[2024-11-29 03:14:31,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:31,373][root][INFO] - Training Epoch: 5/10, step 391/574 completed (loss: 1.3914083242416382, acc: 0.6666666865348816)
[2024-11-29 03:14:31,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:31,636][root][INFO] - Training Epoch: 5/10, step 392/574 completed (loss: 1.2081388235092163, acc: 0.6990291476249695)
[2024-11-29 03:14:31,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:32,073][root][INFO] - Training Epoch: 5/10, step 393/574 completed (loss: 1.1390663385391235, acc: 0.6911764740943909)
[2024-11-29 03:14:32,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:32,371][root][INFO] - Training Epoch: 5/10, step 394/574 completed (loss: 1.173152208328247, acc: 0.6866666674613953)
[2024-11-29 03:14:32,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:32,665][root][INFO] - Training Epoch: 5/10, step 395/574 completed (loss: 0.7756596207618713, acc: 0.8125)
[2024-11-29 03:14:32,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:32,901][root][INFO] - Training Epoch: 5/10, step 396/574 completed (loss: 0.312665730714798, acc: 0.930232584476471)
[2024-11-29 03:14:33,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:33,158][root][INFO] - Training Epoch: 5/10, step 397/574 completed (loss: 0.16176973283290863, acc: 0.9166666865348816)
[2024-11-29 03:14:33,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:33,425][root][INFO] - Training Epoch: 5/10, step 398/574 completed (loss: 0.39327701926231384, acc: 0.8604651093482971)
[2024-11-29 03:14:33,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:33,705][root][INFO] - Training Epoch: 5/10, step 399/574 completed (loss: 0.02359931915998459, acc: 1.0)
[2024-11-29 03:14:33,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:34,153][root][INFO] - Training Epoch: 5/10, step 400/574 completed (loss: 0.4508192539215088, acc: 0.8970588445663452)
[2024-11-29 03:14:34,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:34,333][root][INFO] - Training Epoch: 5/10, step 401/574 completed (loss: 0.5172765851020813, acc: 0.8533333539962769)
[2024-11-29 03:14:34,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:34,576][root][INFO] - Training Epoch: 5/10, step 402/574 completed (loss: 0.5127019882202148, acc: 0.8484848737716675)
[2024-11-29 03:14:34,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:34,798][root][INFO] - Training Epoch: 5/10, step 403/574 completed (loss: 0.2427833378314972, acc: 0.9090909361839294)
[2024-11-29 03:14:34,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:35,030][root][INFO] - Training Epoch: 5/10, step 404/574 completed (loss: 0.4905831217765808, acc: 0.8064516186714172)
[2024-11-29 03:14:35,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:35,253][root][INFO] - Training Epoch: 5/10, step 405/574 completed (loss: 0.03633878752589226, acc: 1.0)
[2024-11-29 03:14:35,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:35,478][root][INFO] - Training Epoch: 5/10, step 406/574 completed (loss: 0.041181039065122604, acc: 1.0)
[2024-11-29 03:14:35,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:35,755][root][INFO] - Training Epoch: 5/10, step 407/574 completed (loss: 0.037512730807065964, acc: 1.0)
[2024-11-29 03:14:35,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:36,015][root][INFO] - Training Epoch: 5/10, step 408/574 completed (loss: 0.10527218133211136, acc: 0.9629629850387573)
[2024-11-29 03:14:36,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:36,262][root][INFO] - Training Epoch: 5/10, step 409/574 completed (loss: 0.0817771777510643, acc: 0.9615384340286255)
[2024-11-29 03:14:36,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:36,501][root][INFO] - Training Epoch: 5/10, step 410/574 completed (loss: 0.15021450817584991, acc: 0.9655172228813171)
[2024-11-29 03:14:36,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:36,744][root][INFO] - Training Epoch: 5/10, step 411/574 completed (loss: 0.14983873069286346, acc: 0.9642857313156128)
[2024-11-29 03:14:36,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:36,986][root][INFO] - Training Epoch: 5/10, step 412/574 completed (loss: 0.2616647779941559, acc: 0.9333333373069763)
[2024-11-29 03:14:37,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:37,224][root][INFO] - Training Epoch: 5/10, step 413/574 completed (loss: 0.030109984800219536, acc: 1.0)
[2024-11-29 03:14:37,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:37,480][root][INFO] - Training Epoch: 5/10, step 414/574 completed (loss: 0.05929308757185936, acc: 1.0)
[2024-11-29 03:14:37,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:37,720][root][INFO] - Training Epoch: 5/10, step 415/574 completed (loss: 0.4004276990890503, acc: 0.8823529481887817)
[2024-11-29 03:14:37,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:37,951][root][INFO] - Training Epoch: 5/10, step 416/574 completed (loss: 0.11794785410165787, acc: 0.9615384340286255)
[2024-11-29 03:14:38,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:38,193][root][INFO] - Training Epoch: 5/10, step 417/574 completed (loss: 0.09419253468513489, acc: 1.0)
[2024-11-29 03:14:38,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:38,410][root][INFO] - Training Epoch: 5/10, step 418/574 completed (loss: 0.21273422241210938, acc: 0.9750000238418579)
[2024-11-29 03:14:38,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:38,636][root][INFO] - Training Epoch: 5/10, step 419/574 completed (loss: 0.06389854848384857, acc: 1.0)
[2024-11-29 03:14:38,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:38,844][root][INFO] - Training Epoch: 5/10, step 420/574 completed (loss: 0.03744162991642952, acc: 1.0)
[2024-11-29 03:14:39,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:39,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:40,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:40,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:40,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:40,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:41,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:41,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:41,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:42,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:42,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:42,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:42,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:43,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:43,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:43,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:43,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:44,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:44,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:44,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:44,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:45,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:45,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:45,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:45,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:46,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:46,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:46,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:46,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:47,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:47,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:47,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:47,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:48,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:48,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:48,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:48,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:49,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:49,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:49,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:50,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:50,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:50,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:51,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:51,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:51,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:51,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:52,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:52,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:52,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:52,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:53,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:53,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:53,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:54,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:54,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:54,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:54,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:55,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:55,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:55,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:55,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:56,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:56,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:56,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:56,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:57,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:57,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:57,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:58,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:58,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:58,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:59,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:59,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:59,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:59,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:00,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:00,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:00,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:00,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:01,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:01,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:01,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:01,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:02,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:02,937][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.0795, device='cuda:0') eval_epoch_loss=tensor(1.1248, device='cuda:0') eval_epoch_acc=tensor(0.7404, device='cuda:0')
[2024-11-29 03:15:02,938][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:15:02,938][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:15:03,128][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_5_step_421_loss_1.1247600317001343/model.pt
[2024-11-29 03:15:03,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:03,328][root][INFO] - Training Epoch: 5/10, step 421/574 completed (loss: 0.0923650935292244, acc: 0.9666666388511658)
[2024-11-29 03:15:03,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:03,513][root][INFO] - Training Epoch: 5/10, step 422/574 completed (loss: 0.34041324257850647, acc: 0.875)
[2024-11-29 03:15:03,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:03,720][root][INFO] - Training Epoch: 5/10, step 423/574 completed (loss: 0.45788607001304626, acc: 0.8888888955116272)
[2024-11-29 03:15:03,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:03,947][root][INFO] - Training Epoch: 5/10, step 424/574 completed (loss: 0.08987859636545181, acc: 1.0)
[2024-11-29 03:15:04,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:04,222][root][INFO] - Training Epoch: 5/10, step 425/574 completed (loss: 0.15689218044281006, acc: 0.939393937587738)
[2024-11-29 03:15:04,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:04,469][root][INFO] - Training Epoch: 5/10, step 426/574 completed (loss: 0.01061748806387186, acc: 1.0)
[2024-11-29 03:15:04,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:04,697][root][INFO] - Training Epoch: 5/10, step 427/574 completed (loss: 0.21370276808738708, acc: 0.9189189076423645)
[2024-11-29 03:15:04,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:04,922][root][INFO] - Training Epoch: 5/10, step 428/574 completed (loss: 0.013072255998849869, acc: 1.0)
[2024-11-29 03:15:05,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:05,156][root][INFO] - Training Epoch: 5/10, step 429/574 completed (loss: 0.04860088601708412, acc: 0.95652174949646)
[2024-11-29 03:15:05,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:05,363][root][INFO] - Training Epoch: 5/10, step 430/574 completed (loss: 0.010762308724224567, acc: 1.0)
[2024-11-29 03:15:05,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:05,588][root][INFO] - Training Epoch: 5/10, step 431/574 completed (loss: 0.025641951709985733, acc: 1.0)
[2024-11-29 03:15:05,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:05,827][root][INFO] - Training Epoch: 5/10, step 432/574 completed (loss: 0.003795106429606676, acc: 1.0)
[2024-11-29 03:15:05,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:06,083][root][INFO] - Training Epoch: 5/10, step 433/574 completed (loss: 0.27840456366539, acc: 0.9444444179534912)
[2024-11-29 03:15:06,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:06,290][root][INFO] - Training Epoch: 5/10, step 434/574 completed (loss: 0.005832582712173462, acc: 1.0)
[2024-11-29 03:15:06,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:06,515][root][INFO] - Training Epoch: 5/10, step 435/574 completed (loss: 0.05079228803515434, acc: 0.9696969985961914)
[2024-11-29 03:15:06,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:06,755][root][INFO] - Training Epoch: 5/10, step 436/574 completed (loss: 0.35066860914230347, acc: 0.8611111044883728)
[2024-11-29 03:15:06,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:06,999][root][INFO] - Training Epoch: 5/10, step 437/574 completed (loss: 0.03838607296347618, acc: 1.0)
[2024-11-29 03:15:07,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:07,234][root][INFO] - Training Epoch: 5/10, step 438/574 completed (loss: 0.004218030255287886, acc: 1.0)
[2024-11-29 03:15:07,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:07,468][root][INFO] - Training Epoch: 5/10, step 439/574 completed (loss: 0.4613851308822632, acc: 0.8717948794364929)
[2024-11-29 03:15:07,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:07,854][root][INFO] - Training Epoch: 5/10, step 440/574 completed (loss: 0.5205356478691101, acc: 0.8333333134651184)
[2024-11-29 03:15:08,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:08,508][root][INFO] - Training Epoch: 5/10, step 441/574 completed (loss: 1.1283724308013916, acc: 0.6480000019073486)
[2024-11-29 03:15:08,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:08,810][root][INFO] - Training Epoch: 5/10, step 442/574 completed (loss: 0.8871567845344543, acc: 0.7822580933570862)
[2024-11-29 03:15:08,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:09,366][root][INFO] - Training Epoch: 5/10, step 443/574 completed (loss: 0.8061402440071106, acc: 0.7960199117660522)
[2024-11-29 03:15:09,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:09,577][root][INFO] - Training Epoch: 5/10, step 444/574 completed (loss: 0.17470327019691467, acc: 0.9622641801834106)
[2024-11-29 03:15:09,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:09,903][root][INFO] - Training Epoch: 5/10, step 445/574 completed (loss: 0.10398602485656738, acc: 1.0)
[2024-11-29 03:15:09,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:10,103][root][INFO] - Training Epoch: 5/10, step 446/574 completed (loss: 0.6609283685684204, acc: 0.8260869383811951)
[2024-11-29 03:15:10,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:10,325][root][INFO] - Training Epoch: 5/10, step 447/574 completed (loss: 0.3510916829109192, acc: 0.9230769276618958)
[2024-11-29 03:15:10,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:10,552][root][INFO] - Training Epoch: 5/10, step 448/574 completed (loss: 0.07629506289958954, acc: 0.9642857313156128)
[2024-11-29 03:15:10,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:10,814][root][INFO] - Training Epoch: 5/10, step 449/574 completed (loss: 0.08564114570617676, acc: 0.9850746393203735)
[2024-11-29 03:15:10,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:11,035][root][INFO] - Training Epoch: 5/10, step 450/574 completed (loss: 0.15386104583740234, acc: 0.9166666865348816)
[2024-11-29 03:15:11,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:11,249][root][INFO] - Training Epoch: 5/10, step 451/574 completed (loss: 0.13896770775318146, acc: 0.945652186870575)
[2024-11-29 03:15:11,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:11,480][root][INFO] - Training Epoch: 5/10, step 452/574 completed (loss: 0.23124445974826813, acc: 0.9487179517745972)
[2024-11-29 03:15:11,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:11,716][root][INFO] - Training Epoch: 5/10, step 453/574 completed (loss: 0.4041430652141571, acc: 0.8815789222717285)
[2024-11-29 03:15:11,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:11,982][root][INFO] - Training Epoch: 5/10, step 454/574 completed (loss: 0.1727820634841919, acc: 0.9591836929321289)
[2024-11-29 03:15:12,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:12,230][root][INFO] - Training Epoch: 5/10, step 455/574 completed (loss: 0.221293106675148, acc: 0.9090909361839294)
[2024-11-29 03:15:12,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:12,470][root][INFO] - Training Epoch: 5/10, step 456/574 completed (loss: 0.7284437417984009, acc: 0.8350515365600586)
[2024-11-29 03:15:12,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:12,712][root][INFO] - Training Epoch: 5/10, step 457/574 completed (loss: 0.08387980610132217, acc: 0.9714285731315613)
[2024-11-29 03:15:12,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:13,016][root][INFO] - Training Epoch: 5/10, step 458/574 completed (loss: 0.9540167450904846, acc: 0.7034883499145508)
[2024-11-29 03:15:13,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:13,281][root][INFO] - Training Epoch: 5/10, step 459/574 completed (loss: 0.29105332493782043, acc: 0.9285714030265808)
[2024-11-29 03:15:13,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:13,532][root][INFO] - Training Epoch: 5/10, step 460/574 completed (loss: 0.4217005968093872, acc: 0.8641975522041321)
[2024-11-29 03:15:13,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:13,798][root][INFO] - Training Epoch: 5/10, step 461/574 completed (loss: 0.3958055377006531, acc: 0.9166666865348816)
[2024-11-29 03:15:13,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:14,046][root][INFO] - Training Epoch: 5/10, step 462/574 completed (loss: 0.09868540614843369, acc: 0.96875)
[2024-11-29 03:15:14,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:14,289][root][INFO] - Training Epoch: 5/10, step 463/574 completed (loss: 0.262195885181427, acc: 0.8846153616905212)
[2024-11-29 03:15:14,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:14,485][root][INFO] - Training Epoch: 5/10, step 464/574 completed (loss: 0.4147765040397644, acc: 0.8695651888847351)
[2024-11-29 03:15:14,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:14,708][root][INFO] - Training Epoch: 5/10, step 465/574 completed (loss: 0.5105862617492676, acc: 0.8333333134651184)
[2024-11-29 03:15:14,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:14,905][root][INFO] - Training Epoch: 5/10, step 466/574 completed (loss: 0.9471640586853027, acc: 0.7831325531005859)
[2024-11-29 03:15:15,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:15,177][root][INFO] - Training Epoch: 5/10, step 467/574 completed (loss: 0.39592090249061584, acc: 0.8828828930854797)
[2024-11-29 03:15:15,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:15,423][root][INFO] - Training Epoch: 5/10, step 468/574 completed (loss: 0.8435013294219971, acc: 0.8058252334594727)
[2024-11-29 03:15:15,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:15,692][root][INFO] - Training Epoch: 5/10, step 469/574 completed (loss: 0.9764126539230347, acc: 0.7967479825019836)
[2024-11-29 03:15:15,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:15,951][root][INFO] - Training Epoch: 5/10, step 470/574 completed (loss: 0.2530287504196167, acc: 0.9166666865348816)
[2024-11-29 03:15:16,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:16,211][root][INFO] - Training Epoch: 5/10, step 471/574 completed (loss: 0.14664366841316223, acc: 0.9642857313156128)
[2024-11-29 03:15:16,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:16,555][root][INFO] - Training Epoch: 5/10, step 472/574 completed (loss: 0.644100546836853, acc: 0.8235294222831726)
[2024-11-29 03:15:16,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:16,825][root][INFO] - Training Epoch: 5/10, step 473/574 completed (loss: 1.1125752925872803, acc: 0.6812227368354797)
[2024-11-29 03:15:16,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:17,060][root][INFO] - Training Epoch: 5/10, step 474/574 completed (loss: 0.6718015074729919, acc: 0.8125)
[2024-11-29 03:15:17,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:17,315][root][INFO] - Training Epoch: 5/10, step 475/574 completed (loss: 0.4865095913410187, acc: 0.8220859169960022)
[2024-11-29 03:15:17,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:17,522][root][INFO] - Training Epoch: 5/10, step 476/574 completed (loss: 0.4509962201118469, acc: 0.8705036044120789)
[2024-11-29 03:15:17,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:17,769][root][INFO] - Training Epoch: 5/10, step 477/574 completed (loss: 0.9406176209449768, acc: 0.7236180901527405)
[2024-11-29 03:15:17,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:17,985][root][INFO] - Training Epoch: 5/10, step 478/574 completed (loss: 0.3816191256046295, acc: 0.9166666865348816)
[2024-11-29 03:15:18,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:18,206][root][INFO] - Training Epoch: 5/10, step 479/574 completed (loss: 0.31913894414901733, acc: 0.8181818127632141)
[2024-11-29 03:15:18,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:18,440][root][INFO] - Training Epoch: 5/10, step 480/574 completed (loss: 0.40548455715179443, acc: 0.8888888955116272)
[2024-11-29 03:15:18,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:18,679][root][INFO] - Training Epoch: 5/10, step 481/574 completed (loss: 1.1816788911819458, acc: 0.699999988079071)
[2024-11-29 03:15:18,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:18,920][root][INFO] - Training Epoch: 5/10, step 482/574 completed (loss: 1.1817469596862793, acc: 0.699999988079071)
[2024-11-29 03:15:19,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:19,211][root][INFO] - Training Epoch: 5/10, step 483/574 completed (loss: 0.9325785040855408, acc: 0.7068965435028076)
[2024-11-29 03:15:19,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:19,448][root][INFO] - Training Epoch: 5/10, step 484/574 completed (loss: 0.26324307918548584, acc: 0.9032257795333862)
[2024-11-29 03:15:19,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:19,664][root][INFO] - Training Epoch: 5/10, step 485/574 completed (loss: 0.15865808725357056, acc: 0.9473684430122375)
[2024-11-29 03:15:19,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:19,875][root][INFO] - Training Epoch: 5/10, step 486/574 completed (loss: 0.651917040348053, acc: 0.8518518805503845)
[2024-11-29 03:15:19,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:20,124][root][INFO] - Training Epoch: 5/10, step 487/574 completed (loss: 0.9597058296203613, acc: 0.761904776096344)
[2024-11-29 03:15:20,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:20,367][root][INFO] - Training Epoch: 5/10, step 488/574 completed (loss: 0.6998400688171387, acc: 0.8181818127632141)
[2024-11-29 03:15:20,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:20,637][root][INFO] - Training Epoch: 5/10, step 489/574 completed (loss: 0.996975839138031, acc: 0.7538461685180664)
[2024-11-29 03:15:20,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:20,881][root][INFO] - Training Epoch: 5/10, step 490/574 completed (loss: 0.10293342173099518, acc: 1.0)
[2024-11-29 03:15:20,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:21,098][root][INFO] - Training Epoch: 5/10, step 491/574 completed (loss: 0.22465437650680542, acc: 0.9655172228813171)
[2024-11-29 03:15:21,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:21,335][root][INFO] - Training Epoch: 5/10, step 492/574 completed (loss: 0.4584202468395233, acc: 0.8039215803146362)
[2024-11-29 03:15:21,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:21,528][root][INFO] - Training Epoch: 5/10, step 493/574 completed (loss: 0.10628890246152878, acc: 1.0)
[2024-11-29 03:15:21,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:21,721][root][INFO] - Training Epoch: 5/10, step 494/574 completed (loss: 0.2863712012767792, acc: 1.0)
[2024-11-29 03:15:21,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:21,924][root][INFO] - Training Epoch: 5/10, step 495/574 completed (loss: 0.05476199463009834, acc: 1.0)
[2024-11-29 03:15:22,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:22,162][root][INFO] - Training Epoch: 5/10, step 496/574 completed (loss: 0.9583073854446411, acc: 0.7410714030265808)
[2024-11-29 03:15:22,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:22,454][root][INFO] - Training Epoch: 5/10, step 497/574 completed (loss: 0.3666405975818634, acc: 0.898876428604126)
[2024-11-29 03:15:22,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:22,704][root][INFO] - Training Epoch: 5/10, step 498/574 completed (loss: 0.8287274837493896, acc: 0.7640449404716492)
[2024-11-29 03:15:22,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:22,941][root][INFO] - Training Epoch: 5/10, step 499/574 completed (loss: 1.5252158641815186, acc: 0.5815602540969849)
[2024-11-29 03:15:23,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:23,215][root][INFO] - Training Epoch: 5/10, step 500/574 completed (loss: 0.8695604205131531, acc: 0.760869562625885)
[2024-11-29 03:15:23,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:23,461][root][INFO] - Training Epoch: 5/10, step 501/574 completed (loss: 0.18463429808616638, acc: 0.8799999952316284)
[2024-11-29 03:15:23,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:23,660][root][INFO] - Training Epoch: 5/10, step 502/574 completed (loss: 0.14670416712760925, acc: 0.9615384340286255)
[2024-11-29 03:15:23,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:23,933][root][INFO] - Training Epoch: 5/10, step 503/574 completed (loss: 0.5595242977142334, acc: 0.8148148059844971)
[2024-11-29 03:15:24,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:24,215][root][INFO] - Training Epoch: 5/10, step 504/574 completed (loss: 0.10400265455245972, acc: 0.9629629850387573)
[2024-11-29 03:15:24,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:24,475][root][INFO] - Training Epoch: 5/10, step 505/574 completed (loss: 0.6953415870666504, acc: 0.849056601524353)
[2024-11-29 03:15:24,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:24,727][root][INFO] - Training Epoch: 5/10, step 506/574 completed (loss: 1.2181942462921143, acc: 0.7241379022598267)
[2024-11-29 03:15:24,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:25,252][root][INFO] - Training Epoch: 5/10, step 507/574 completed (loss: 1.3286772966384888, acc: 0.6666666865348816)
[2024-11-29 03:15:25,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:25,597][root][INFO] - Training Epoch: 5/10, step 508/574 completed (loss: 0.8376087546348572, acc: 0.7746478915214539)
[2024-11-29 03:15:25,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:25,845][root][INFO] - Training Epoch: 5/10, step 509/574 completed (loss: 0.09562224894762039, acc: 0.949999988079071)
[2024-11-29 03:15:25,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:26,075][root][INFO] - Training Epoch: 5/10, step 510/574 completed (loss: 0.21025149524211884, acc: 0.8999999761581421)
[2024-11-29 03:15:26,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:26,336][root][INFO] - Training Epoch: 5/10, step 511/574 completed (loss: 0.23836739361286163, acc: 0.9230769276618958)
[2024-11-29 03:15:27,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:28,882][root][INFO] - Training Epoch: 5/10, step 512/574 completed (loss: 1.5091147422790527, acc: 0.6357142925262451)
[2024-11-29 03:15:29,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:29,578][root][INFO] - Training Epoch: 5/10, step 513/574 completed (loss: 0.4499122202396393, acc: 0.8333333134651184)
[2024-11-29 03:15:29,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:29,779][root][INFO] - Training Epoch: 5/10, step 514/574 completed (loss: 0.752454400062561, acc: 0.8214285969734192)
[2024-11-29 03:15:29,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:30,047][root][INFO] - Training Epoch: 5/10, step 515/574 completed (loss: 0.12065254896879196, acc: 0.949999988079071)
[2024-11-29 03:15:30,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:30,735][root][INFO] - Training Epoch: 5/10, step 516/574 completed (loss: 0.49428144097328186, acc: 0.8472222089767456)
[2024-11-29 03:15:30,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:30,958][root][INFO] - Training Epoch: 5/10, step 517/574 completed (loss: 0.009311560541391373, acc: 1.0)
[2024-11-29 03:15:31,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:31,199][root][INFO] - Training Epoch: 5/10, step 518/574 completed (loss: 0.23797333240509033, acc: 0.9354838728904724)
[2024-11-29 03:15:31,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:31,445][root][INFO] - Training Epoch: 5/10, step 519/574 completed (loss: 0.14221732318401337, acc: 0.949999988079071)
[2024-11-29 03:15:31,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:31,712][root][INFO] - Training Epoch: 5/10, step 520/574 completed (loss: 0.12034112960100174, acc: 1.0)
[2024-11-29 03:15:32,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:32,636][root][INFO] - Training Epoch: 5/10, step 521/574 completed (loss: 0.9459975957870483, acc: 0.7457627058029175)
[2024-11-29 03:15:32,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:32,877][root][INFO] - Training Epoch: 5/10, step 522/574 completed (loss: 0.3821350038051605, acc: 0.8805969953536987)
[2024-11-29 03:15:32,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:33,148][root][INFO] - Training Epoch: 5/10, step 523/574 completed (loss: 0.5572836399078369, acc: 0.8248175382614136)
[2024-11-29 03:15:33,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:33,642][root][INFO] - Training Epoch: 5/10, step 524/574 completed (loss: 0.8494545817375183, acc: 0.7749999761581421)
[2024-11-29 03:15:33,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:33,923][root][INFO] - Training Epoch: 5/10, step 525/574 completed (loss: 0.18921081721782684, acc: 0.9444444179534912)
[2024-11-29 03:15:34,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:34,167][root][INFO] - Training Epoch: 5/10, step 526/574 completed (loss: 0.10890989750623703, acc: 0.9807692170143127)
[2024-11-29 03:15:34,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:34,389][root][INFO] - Training Epoch: 5/10, step 527/574 completed (loss: 0.0869794487953186, acc: 1.0)
[2024-11-29 03:15:34,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:34,635][root][INFO] - Training Epoch: 5/10, step 528/574 completed (loss: 1.384967565536499, acc: 0.6229507923126221)
[2024-11-29 03:15:34,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:34,868][root][INFO] - Training Epoch: 5/10, step 529/574 completed (loss: 0.3192487359046936, acc: 0.9322034120559692)
[2024-11-29 03:15:34,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:35,112][root][INFO] - Training Epoch: 5/10, step 530/574 completed (loss: 1.4084900617599487, acc: 0.6511628031730652)
[2024-11-29 03:15:35,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:35,342][root][INFO] - Training Epoch: 5/10, step 531/574 completed (loss: 0.9231889843940735, acc: 0.7045454382896423)
[2024-11-29 03:15:35,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:35,537][root][INFO] - Training Epoch: 5/10, step 532/574 completed (loss: 1.1346944570541382, acc: 0.7169811129570007)
[2024-11-29 03:15:35,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:35,787][root][INFO] - Training Epoch: 5/10, step 533/574 completed (loss: 0.7997833490371704, acc: 0.7727272510528564)
[2024-11-29 03:15:35,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:36,043][root][INFO] - Training Epoch: 5/10, step 534/574 completed (loss: 0.6077718734741211, acc: 0.8399999737739563)
[2024-11-29 03:15:36,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:36,268][root][INFO] - Training Epoch: 5/10, step 535/574 completed (loss: 0.11884571611881256, acc: 1.0)
[2024-11-29 03:15:36,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:36,500][root][INFO] - Training Epoch: 5/10, step 536/574 completed (loss: 0.157016783952713, acc: 1.0)
[2024-11-29 03:15:36,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:36,820][root][INFO] - Training Epoch: 5/10, step 537/574 completed (loss: 0.729164183139801, acc: 0.8153846263885498)
[2024-11-29 03:15:36,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:37,081][root][INFO] - Training Epoch: 5/10, step 538/574 completed (loss: 0.6493598818778992, acc: 0.84375)
[2024-11-29 03:15:37,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:37,369][root][INFO] - Training Epoch: 5/10, step 539/574 completed (loss: 0.4765818417072296, acc: 0.875)
[2024-11-29 03:15:37,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:37,633][root][INFO] - Training Epoch: 5/10, step 540/574 completed (loss: 0.9998789429664612, acc: 0.7878788113594055)
[2024-11-29 03:15:37,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:37,885][root][INFO] - Training Epoch: 5/10, step 541/574 completed (loss: 0.217200368642807, acc: 0.9375)
[2024-11-29 03:15:38,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:38,137][root][INFO] - Training Epoch: 5/10, step 542/574 completed (loss: 0.08206970989704132, acc: 0.9677419066429138)
[2024-11-29 03:15:38,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:38,419][root][INFO] - Training Epoch: 5/10, step 543/574 completed (loss: 0.01787330023944378, acc: 1.0)
[2024-11-29 03:15:38,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:38,676][root][INFO] - Training Epoch: 5/10, step 544/574 completed (loss: 0.20297503471374512, acc: 0.9333333373069763)
[2024-11-29 03:15:38,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:38,933][root][INFO] - Training Epoch: 5/10, step 545/574 completed (loss: 0.07047438621520996, acc: 1.0)
[2024-11-29 03:15:39,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:39,169][root][INFO] - Training Epoch: 5/10, step 546/574 completed (loss: 0.02691624127328396, acc: 1.0)
[2024-11-29 03:15:39,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:39,396][root][INFO] - Training Epoch: 5/10, step 547/574 completed (loss: 0.02505606785416603, acc: 1.0)
[2024-11-29 03:15:39,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:39,648][root][INFO] - Training Epoch: 5/10, step 548/574 completed (loss: 0.10559800267219543, acc: 0.9677419066429138)
[2024-11-29 03:15:39,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:39,891][root][INFO] - Training Epoch: 5/10, step 549/574 completed (loss: 0.02639167383313179, acc: 1.0)
[2024-11-29 03:15:39,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:40,114][root][INFO] - Training Epoch: 5/10, step 550/574 completed (loss: 0.07919153571128845, acc: 1.0)
[2024-11-29 03:15:40,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:40,341][root][INFO] - Training Epoch: 5/10, step 551/574 completed (loss: 0.2641749680042267, acc: 0.925000011920929)
[2024-11-29 03:15:40,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:40,554][root][INFO] - Training Epoch: 5/10, step 552/574 completed (loss: 0.12689070403575897, acc: 0.9714285731315613)
[2024-11-29 03:15:40,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:40,810][root][INFO] - Training Epoch: 5/10, step 553/574 completed (loss: 0.5779297351837158, acc: 0.8613138794898987)
[2024-11-29 03:15:40,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:41,047][root][INFO] - Training Epoch: 5/10, step 554/574 completed (loss: 0.5038068294525146, acc: 0.8551723957061768)
[2024-11-29 03:15:41,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:41,275][root][INFO] - Training Epoch: 5/10, step 555/574 completed (loss: 0.6748023629188538, acc: 0.8285714387893677)
[2024-11-29 03:15:41,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:41,532][root][INFO] - Training Epoch: 5/10, step 556/574 completed (loss: 0.5530337691307068, acc: 0.8278145790100098)
[2024-11-29 03:15:41,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:41,813][root][INFO] - Training Epoch: 5/10, step 557/574 completed (loss: 0.326825886964798, acc: 0.9059829115867615)
[2024-11-29 03:15:41,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:42,076][root][INFO] - Training Epoch: 5/10, step 558/574 completed (loss: 0.08331496268510818, acc: 1.0)
[2024-11-29 03:15:42,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:42,351][root][INFO] - Training Epoch: 5/10, step 559/574 completed (loss: 0.03770923987030983, acc: 1.0)
[2024-11-29 03:15:42,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:42,584][root][INFO] - Training Epoch: 5/10, step 560/574 completed (loss: 0.4426407217979431, acc: 0.9615384340286255)
[2024-11-29 03:15:42,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:42,837][root][INFO] - Training Epoch: 5/10, step 561/574 completed (loss: 0.4450839161872864, acc: 0.8974359035491943)
[2024-11-29 03:15:42,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:43,091][root][INFO] - Training Epoch: 5/10, step 562/574 completed (loss: 0.588262677192688, acc: 0.8222222328186035)
[2024-11-29 03:15:43,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:43,309][root][INFO] - Training Epoch: 5/10, step 563/574 completed (loss: 0.6824330687522888, acc: 0.8051947951316833)
[2024-11-29 03:15:44,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:44,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:44,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:44,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:44,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:45,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:45,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:45,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:45,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:46,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:46,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:46,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:47,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:47,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:47,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:48,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:48,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:48,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:48,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:49,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:49,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:49,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:50,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:50,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:50,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:50,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:51,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:51,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:51,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:52,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:52,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:52,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:52,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:52,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:53,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:53,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:53,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:53,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:54,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:54,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:54,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:54,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:55,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:55,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:55,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:55,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:56,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:56,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:56,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:56,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:57,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:57,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:57,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:58,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:58,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:58,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:58,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:59,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:59,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:59,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:59,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:00,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:00,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:00,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:01,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:01,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:01,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:02,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:02,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:02,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:03,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:03,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:03,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:03,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:03,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:04,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:04,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:04,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:04,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:05,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:05,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:05,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:05,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:06,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:06,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:07,083][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.2921, device='cuda:0') eval_epoch_loss=tensor(1.1915, device='cuda:0') eval_epoch_acc=tensor(0.7281, device='cuda:0')
[2024-11-29 03:16:07,084][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:16:07,085][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:16:07,247][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_5_step_564_loss_1.1915390491485596/model.pt
[2024-11-29 03:16:07,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:07,414][root][INFO] - Training Epoch: 5/10, step 564/574 completed (loss: 0.2055911421775818, acc: 0.9375)
[2024-11-29 03:16:07,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:07,635][root][INFO] - Training Epoch: 5/10, step 565/574 completed (loss: 0.3189011514186859, acc: 0.8620689511299133)
[2024-11-29 03:16:07,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:07,857][root][INFO] - Training Epoch: 5/10, step 566/574 completed (loss: 0.40183794498443604, acc: 0.9166666865348816)
[2024-11-29 03:16:07,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:08,024][root][INFO] - Training Epoch: 5/10, step 567/574 completed (loss: 0.1316240429878235, acc: 0.9473684430122375)
[2024-11-29 03:16:08,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:08,284][root][INFO] - Training Epoch: 5/10, step 568/574 completed (loss: 0.239158496260643, acc: 0.9259259104728699)
[2024-11-29 03:16:08,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:08,580][root][INFO] - Training Epoch: 5/10, step 569/574 completed (loss: 0.7750820517539978, acc: 0.7807486653327942)
[2024-11-29 03:16:08,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:08,792][root][INFO] - Training Epoch: 5/10, step 570/574 completed (loss: 0.2071123868227005, acc: 0.9354838728904724)
[2024-11-29 03:16:08,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:09,066][root][INFO] - Training Epoch: 5/10, step 571/574 completed (loss: 0.4608980119228363, acc: 0.9059829115867615)
[2024-11-29 03:16:09,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:09,305][root][INFO] - Training Epoch: 5/10, step 572/574 completed (loss: 0.8423150777816772, acc: 0.7755101919174194)
[2024-11-29 03:16:09,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:09,565][root][INFO] - Training Epoch: 5/10, step 573/574 completed (loss: 0.7085232734680176, acc: 0.7861635088920593)
[2024-11-29 03:16:10,005][slam_llm.utils.train_utils][INFO] - Epoch 5: train_perplexity=1.7681, train_epoch_loss=0.5699, epoch time 264.0614891573787s
[2024-11-29 03:16:10,005][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 11 GB
[2024-11-29 03:16:10,005][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-11-29 03:16:10,005][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 11 GB
[2024-11-29 03:16:10,006][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 8
[2024-11-29 03:16:10,006][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:16:10,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:10,772][root][INFO] - Training Epoch: 6/10, step 0/574 completed (loss: 0.19941966235637665, acc: 0.9629629850387573)
[2024-11-29 03:16:10,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:10,994][root][INFO] - Training Epoch: 6/10, step 1/574 completed (loss: 0.20295962691307068, acc: 0.9599999785423279)
[2024-11-29 03:16:11,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:11,221][root][INFO] - Training Epoch: 6/10, step 2/574 completed (loss: 0.39927059412002563, acc: 0.837837815284729)
[2024-11-29 03:16:11,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:11,516][root][INFO] - Training Epoch: 6/10, step 3/574 completed (loss: 0.25991305708885193, acc: 0.9210526347160339)
[2024-11-29 03:16:11,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:11,763][root][INFO] - Training Epoch: 6/10, step 4/574 completed (loss: 0.46271705627441406, acc: 0.8918918967247009)
[2024-11-29 03:16:11,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:12,025][root][INFO] - Training Epoch: 6/10, step 5/574 completed (loss: 0.08067647367715836, acc: 0.9642857313156128)
[2024-11-29 03:16:12,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:12,295][root][INFO] - Training Epoch: 6/10, step 6/574 completed (loss: 0.598961591720581, acc: 0.8367347121238708)
[2024-11-29 03:16:12,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:12,528][root][INFO] - Training Epoch: 6/10, step 7/574 completed (loss: 0.4689565896987915, acc: 0.8999999761581421)
[2024-11-29 03:16:12,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:12,792][root][INFO] - Training Epoch: 6/10, step 8/574 completed (loss: 0.11161956191062927, acc: 0.9545454382896423)
[2024-11-29 03:16:12,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:13,087][root][INFO] - Training Epoch: 6/10, step 9/574 completed (loss: 0.017794502899050713, acc: 1.0)
[2024-11-29 03:16:13,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:13,336][root][INFO] - Training Epoch: 6/10, step 10/574 completed (loss: 0.21548111736774445, acc: 0.9259259104728699)
[2024-11-29 03:16:13,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:13,613][root][INFO] - Training Epoch: 6/10, step 11/574 completed (loss: 0.09644383937120438, acc: 0.9743589758872986)
[2024-11-29 03:16:13,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:13,870][root][INFO] - Training Epoch: 6/10, step 12/574 completed (loss: 0.03845034912228584, acc: 1.0)
[2024-11-29 03:16:13,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:14,126][root][INFO] - Training Epoch: 6/10, step 13/574 completed (loss: 0.28062674403190613, acc: 0.9347826242446899)
[2024-11-29 03:16:14,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:14,391][root][INFO] - Training Epoch: 6/10, step 14/574 completed (loss: 0.1412208527326584, acc: 0.9607843160629272)
[2024-11-29 03:16:14,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:14,589][root][INFO] - Training Epoch: 6/10, step 15/574 completed (loss: 0.28690028190612793, acc: 0.9387755393981934)
[2024-11-29 03:16:14,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:14,779][root][INFO] - Training Epoch: 6/10, step 16/574 completed (loss: 0.08911652117967606, acc: 0.9473684430122375)
[2024-11-29 03:16:14,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:15,015][root][INFO] - Training Epoch: 6/10, step 17/574 completed (loss: 0.2012573629617691, acc: 0.9583333134651184)
[2024-11-29 03:16:15,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:15,285][root][INFO] - Training Epoch: 6/10, step 18/574 completed (loss: 0.5832746624946594, acc: 0.8055555820465088)
[2024-11-29 03:16:15,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:15,499][root][INFO] - Training Epoch: 6/10, step 19/574 completed (loss: 0.2816140651702881, acc: 0.9473684430122375)
[2024-11-29 03:16:15,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:15,735][root][INFO] - Training Epoch: 6/10, step 20/574 completed (loss: 0.17483727633953094, acc: 0.9230769276618958)
[2024-11-29 03:16:15,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:15,945][root][INFO] - Training Epoch: 6/10, step 21/574 completed (loss: 0.32176005840301514, acc: 0.8965517282485962)
[2024-11-29 03:16:16,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:16,171][root][INFO] - Training Epoch: 6/10, step 22/574 completed (loss: 0.12938947975635529, acc: 0.9200000166893005)
[2024-11-29 03:16:16,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:16,421][root][INFO] - Training Epoch: 6/10, step 23/574 completed (loss: 0.04279386252164841, acc: 1.0)
[2024-11-29 03:16:16,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:16,678][root][INFO] - Training Epoch: 6/10, step 24/574 completed (loss: 0.038015108555555344, acc: 1.0)
[2024-11-29 03:16:16,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:16,931][root][INFO] - Training Epoch: 6/10, step 25/574 completed (loss: 0.7986251711845398, acc: 0.7924528121948242)
[2024-11-29 03:16:17,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:17,189][root][INFO] - Training Epoch: 6/10, step 26/574 completed (loss: 0.9823026061058044, acc: 0.8082191944122314)
[2024-11-29 03:16:17,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:18,459][root][INFO] - Training Epoch: 6/10, step 27/574 completed (loss: 1.5871825218200684, acc: 0.5968379378318787)
[2024-11-29 03:16:18,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:18,728][root][INFO] - Training Epoch: 6/10, step 28/574 completed (loss: 0.20919549465179443, acc: 0.9767441749572754)
[2024-11-29 03:16:18,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:18,984][root][INFO] - Training Epoch: 6/10, step 29/574 completed (loss: 0.6787963509559631, acc: 0.7710843086242676)
[2024-11-29 03:16:19,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:19,224][root][INFO] - Training Epoch: 6/10, step 30/574 completed (loss: 0.8693175911903381, acc: 0.790123462677002)
[2024-11-29 03:16:19,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:19,455][root][INFO] - Training Epoch: 6/10, step 31/574 completed (loss: 0.33536863327026367, acc: 0.8928571343421936)
[2024-11-29 03:16:19,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:19,718][root][INFO] - Training Epoch: 6/10, step 32/574 completed (loss: 0.056115761399269104, acc: 1.0)
[2024-11-29 03:16:19,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:19,966][root][INFO] - Training Epoch: 6/10, step 33/574 completed (loss: 0.04078326001763344, acc: 1.0)
[2024-11-29 03:16:20,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:20,202][root][INFO] - Training Epoch: 6/10, step 34/574 completed (loss: 0.625786542892456, acc: 0.831932783126831)
[2024-11-29 03:16:20,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:20,444][root][INFO] - Training Epoch: 6/10, step 35/574 completed (loss: 0.35228973627090454, acc: 0.868852436542511)
[2024-11-29 03:16:20,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:20,689][root][INFO] - Training Epoch: 6/10, step 36/574 completed (loss: 0.5852172374725342, acc: 0.8571428656578064)
[2024-11-29 03:16:20,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:20,920][root][INFO] - Training Epoch: 6/10, step 37/574 completed (loss: 0.43299779295921326, acc: 0.8983050584793091)
[2024-11-29 03:16:21,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:21,174][root][INFO] - Training Epoch: 6/10, step 38/574 completed (loss: 0.47257503867149353, acc: 0.8735632300376892)
[2024-11-29 03:16:21,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:21,409][root][INFO] - Training Epoch: 6/10, step 39/574 completed (loss: 0.6770914196968079, acc: 0.8095238208770752)
[2024-11-29 03:16:21,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:21,658][root][INFO] - Training Epoch: 6/10, step 40/574 completed (loss: 0.39471954107284546, acc: 0.8846153616905212)
[2024-11-29 03:16:21,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:21,966][root][INFO] - Training Epoch: 6/10, step 41/574 completed (loss: 0.32906174659729004, acc: 0.8783783912658691)
[2024-11-29 03:16:22,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:22,227][root][INFO] - Training Epoch: 6/10, step 42/574 completed (loss: 0.6366469264030457, acc: 0.8307692408561707)
[2024-11-29 03:16:22,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:22,577][root][INFO] - Training Epoch: 6/10, step 43/574 completed (loss: 0.6501662731170654, acc: 0.7979797720909119)
[2024-11-29 03:16:22,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:22,878][root][INFO] - Training Epoch: 6/10, step 44/574 completed (loss: 0.5887042284011841, acc: 0.8350515365600586)
[2024-11-29 03:16:22,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:23,166][root][INFO] - Training Epoch: 6/10, step 45/574 completed (loss: 0.6203246116638184, acc: 0.8529411554336548)
[2024-11-29 03:16:23,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:23,367][root][INFO] - Training Epoch: 6/10, step 46/574 completed (loss: 0.11073749512434006, acc: 1.0)
[2024-11-29 03:16:23,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:23,591][root][INFO] - Training Epoch: 6/10, step 47/574 completed (loss: 0.06019943580031395, acc: 1.0)
[2024-11-29 03:16:23,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:23,817][root][INFO] - Training Epoch: 6/10, step 48/574 completed (loss: 0.11923649162054062, acc: 0.9642857313156128)
[2024-11-29 03:16:23,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:24,050][root][INFO] - Training Epoch: 6/10, step 49/574 completed (loss: 0.059761013835668564, acc: 1.0)
[2024-11-29 03:16:24,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:24,256][root][INFO] - Training Epoch: 6/10, step 50/574 completed (loss: 0.6971118450164795, acc: 0.8245614171028137)
[2024-11-29 03:16:24,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:24,473][root][INFO] - Training Epoch: 6/10, step 51/574 completed (loss: 0.6520190834999084, acc: 0.8730158805847168)
[2024-11-29 03:16:24,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:24,669][root][INFO] - Training Epoch: 6/10, step 52/574 completed (loss: 0.9252296686172485, acc: 0.7183098793029785)
[2024-11-29 03:16:24,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:25,037][root][INFO] - Training Epoch: 6/10, step 53/574 completed (loss: 1.6561790704727173, acc: 0.5799999833106995)
[2024-11-29 03:16:25,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:25,232][root][INFO] - Training Epoch: 6/10, step 54/574 completed (loss: 0.9335597157478333, acc: 0.7567567825317383)
[2024-11-29 03:16:25,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:25,420][root][INFO] - Training Epoch: 6/10, step 55/574 completed (loss: 0.013219536282122135, acc: 1.0)
[2024-11-29 03:16:26,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:27,987][root][INFO] - Training Epoch: 6/10, step 56/574 completed (loss: 1.3239705562591553, acc: 0.6518771052360535)
[2024-11-29 03:16:28,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:29,220][root][INFO] - Training Epoch: 6/10, step 57/574 completed (loss: 1.5146528482437134, acc: 0.5991285443305969)
[2024-11-29 03:16:29,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:29,770][root][INFO] - Training Epoch: 6/10, step 58/574 completed (loss: 0.8650363683700562, acc: 0.7215909361839294)
[2024-11-29 03:16:29,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:30,247][root][INFO] - Training Epoch: 6/10, step 59/574 completed (loss: 0.496404767036438, acc: 0.8676470518112183)
[2024-11-29 03:16:30,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:30,712][root][INFO] - Training Epoch: 6/10, step 60/574 completed (loss: 0.8158917427062988, acc: 0.8115941882133484)
[2024-11-29 03:16:30,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:31,026][root][INFO] - Training Epoch: 6/10, step 61/574 completed (loss: 0.731339693069458, acc: 0.7749999761581421)
[2024-11-29 03:16:31,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:31,219][root][INFO] - Training Epoch: 6/10, step 62/574 completed (loss: 0.06504197418689728, acc: 1.0)
[2024-11-29 03:16:31,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:31,482][root][INFO] - Training Epoch: 6/10, step 63/574 completed (loss: 0.11059302091598511, acc: 0.9722222089767456)
[2024-11-29 03:16:31,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:31,744][root][INFO] - Training Epoch: 6/10, step 64/574 completed (loss: 0.09584031999111176, acc: 0.984375)
[2024-11-29 03:16:31,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:32,016][root][INFO] - Training Epoch: 6/10, step 65/574 completed (loss: 0.11418913304805756, acc: 0.9655172228813171)
[2024-11-29 03:16:32,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:32,280][root][INFO] - Training Epoch: 6/10, step 66/574 completed (loss: 0.7389225959777832, acc: 0.8035714030265808)
[2024-11-29 03:16:32,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:32,529][root][INFO] - Training Epoch: 6/10, step 67/574 completed (loss: 0.46047109365463257, acc: 0.8833333253860474)
[2024-11-29 03:16:32,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:32,761][root][INFO] - Training Epoch: 6/10, step 68/574 completed (loss: 0.037848688662052155, acc: 1.0)
[2024-11-29 03:16:32,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:33,014][root][INFO] - Training Epoch: 6/10, step 69/574 completed (loss: 0.6866959929466248, acc: 0.8611111044883728)
[2024-11-29 03:16:33,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:33,241][root][INFO] - Training Epoch: 6/10, step 70/574 completed (loss: 0.36685216426849365, acc: 0.9090909361839294)
[2024-11-29 03:16:33,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:33,520][root][INFO] - Training Epoch: 6/10, step 71/574 completed (loss: 1.2676595449447632, acc: 0.6470588445663452)
[2024-11-29 03:16:33,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:33,798][root][INFO] - Training Epoch: 6/10, step 72/574 completed (loss: 0.8702995181083679, acc: 0.6984127163887024)
[2024-11-29 03:16:33,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:34,013][root][INFO] - Training Epoch: 6/10, step 73/574 completed (loss: 1.6581170558929443, acc: 0.5487179756164551)
[2024-11-29 03:16:34,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:34,252][root][INFO] - Training Epoch: 6/10, step 74/574 completed (loss: 1.082858920097351, acc: 0.6632652878761292)
[2024-11-29 03:16:34,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:34,517][root][INFO] - Training Epoch: 6/10, step 75/574 completed (loss: 1.1677162647247314, acc: 0.6791045069694519)
[2024-11-29 03:16:34,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:34,820][root][INFO] - Training Epoch: 6/10, step 76/574 completed (loss: 1.725317358970642, acc: 0.55474454164505)
[2024-11-29 03:16:34,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:35,074][root][INFO] - Training Epoch: 6/10, step 77/574 completed (loss: 0.027173615992069244, acc: 1.0)
[2024-11-29 03:16:35,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:35,303][root][INFO] - Training Epoch: 6/10, step 78/574 completed (loss: 0.0817844346165657, acc: 0.9583333134651184)
[2024-11-29 03:16:35,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:35,543][root][INFO] - Training Epoch: 6/10, step 79/574 completed (loss: 0.1580064594745636, acc: 0.9696969985961914)
[2024-11-29 03:16:35,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:35,790][root][INFO] - Training Epoch: 6/10, step 80/574 completed (loss: 0.08127626776695251, acc: 0.9615384340286255)
[2024-11-29 03:16:35,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:36,045][root][INFO] - Training Epoch: 6/10, step 81/574 completed (loss: 0.35431385040283203, acc: 0.8653846383094788)
[2024-11-29 03:16:36,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:36,322][root][INFO] - Training Epoch: 6/10, step 82/574 completed (loss: 0.4249457120895386, acc: 0.8846153616905212)
[2024-11-29 03:16:36,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:36,543][root][INFO] - Training Epoch: 6/10, step 83/574 completed (loss: 0.2692878246307373, acc: 0.9375)
[2024-11-29 03:16:36,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:36,780][root][INFO] - Training Epoch: 6/10, step 84/574 completed (loss: 0.3651421368122101, acc: 0.8985507488250732)
[2024-11-29 03:16:36,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:37,024][root][INFO] - Training Epoch: 6/10, step 85/574 completed (loss: 0.42763033509254456, acc: 0.8600000143051147)
[2024-11-29 03:16:37,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:37,253][root][INFO] - Training Epoch: 6/10, step 86/574 completed (loss: 0.06853284686803818, acc: 1.0)
[2024-11-29 03:16:37,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:37,681][root][INFO] - Training Epoch: 6/10, step 87/574 completed (loss: 0.9525824189186096, acc: 0.7400000095367432)
[2024-11-29 03:16:37,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:37,931][root][INFO] - Training Epoch: 6/10, step 88/574 completed (loss: 1.0248537063598633, acc: 0.7184466123580933)
[2024-11-29 03:16:38,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:39,079][root][INFO] - Training Epoch: 6/10, step 89/574 completed (loss: 1.028679609298706, acc: 0.762135922908783)
[2024-11-29 03:16:39,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:39,778][root][INFO] - Training Epoch: 6/10, step 90/574 completed (loss: 1.4740089178085327, acc: 0.5967742204666138)
[2024-11-29 03:16:39,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:40,463][root][INFO] - Training Epoch: 6/10, step 91/574 completed (loss: 1.1902358531951904, acc: 0.6724137663841248)
[2024-11-29 03:16:40,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:41,098][root][INFO] - Training Epoch: 6/10, step 92/574 completed (loss: 0.878812849521637, acc: 0.800000011920929)
[2024-11-29 03:16:41,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:41,959][root][INFO] - Training Epoch: 6/10, step 93/574 completed (loss: 1.4786213636398315, acc: 0.5841584205627441)
[2024-11-29 03:16:42,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:42,194][root][INFO] - Training Epoch: 6/10, step 94/574 completed (loss: 1.058705449104309, acc: 0.6774193644523621)
[2024-11-29 03:16:42,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:42,437][root][INFO] - Training Epoch: 6/10, step 95/574 completed (loss: 0.6432453393936157, acc: 0.8115941882133484)
[2024-11-29 03:16:42,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:42,710][root][INFO] - Training Epoch: 6/10, step 96/574 completed (loss: 1.1738542318344116, acc: 0.6722689270973206)
[2024-11-29 03:16:42,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:42,987][root][INFO] - Training Epoch: 6/10, step 97/574 completed (loss: 1.4003772735595703, acc: 0.5961538553237915)
[2024-11-29 03:16:43,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:43,339][root][INFO] - Training Epoch: 6/10, step 98/574 completed (loss: 1.5454885959625244, acc: 0.569343090057373)
[2024-11-29 03:16:43,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:43,597][root][INFO] - Training Epoch: 6/10, step 99/574 completed (loss: 1.3588221073150635, acc: 0.6567164063453674)
[2024-11-29 03:16:43,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:43,830][root][INFO] - Training Epoch: 6/10, step 100/574 completed (loss: 0.6198509931564331, acc: 0.800000011920929)
[2024-11-29 03:16:43,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:44,091][root][INFO] - Training Epoch: 6/10, step 101/574 completed (loss: 0.033376142382621765, acc: 1.0)
[2024-11-29 03:16:44,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:44,264][root][INFO] - Training Epoch: 6/10, step 102/574 completed (loss: 0.03163374960422516, acc: 1.0)
[2024-11-29 03:16:44,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:44,459][root][INFO] - Training Epoch: 6/10, step 103/574 completed (loss: 0.06221645697951317, acc: 1.0)
[2024-11-29 03:16:44,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:44,716][root][INFO] - Training Epoch: 6/10, step 104/574 completed (loss: 0.45710691809654236, acc: 0.8793103694915771)
[2024-11-29 03:16:44,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:44,969][root][INFO] - Training Epoch: 6/10, step 105/574 completed (loss: 0.13408687710762024, acc: 0.930232584476471)
[2024-11-29 03:16:45,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:45,212][root][INFO] - Training Epoch: 6/10, step 106/574 completed (loss: 0.256736159324646, acc: 0.9200000166893005)
[2024-11-29 03:16:45,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:45,441][root][INFO] - Training Epoch: 6/10, step 107/574 completed (loss: 0.03294205293059349, acc: 1.0)
[2024-11-29 03:16:45,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:45,646][root][INFO] - Training Epoch: 6/10, step 108/574 completed (loss: 0.01048990711569786, acc: 1.0)
[2024-11-29 03:16:45,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:45,837][root][INFO] - Training Epoch: 6/10, step 109/574 completed (loss: 0.08729927986860275, acc: 0.976190447807312)
[2024-11-29 03:16:45,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:46,095][root][INFO] - Training Epoch: 6/10, step 110/574 completed (loss: 0.1587701439857483, acc: 0.9538461565971375)
[2024-11-29 03:16:46,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:46,427][root][INFO] - Training Epoch: 6/10, step 111/574 completed (loss: 0.3012740910053253, acc: 0.9298245906829834)
[2024-11-29 03:16:46,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:46,689][root][INFO] - Training Epoch: 6/10, step 112/574 completed (loss: 0.5579982995986938, acc: 0.8245614171028137)
[2024-11-29 03:16:46,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:46,958][root][INFO] - Training Epoch: 6/10, step 113/574 completed (loss: 0.3047373294830322, acc: 0.9230769276618958)
[2024-11-29 03:16:47,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:47,235][root][INFO] - Training Epoch: 6/10, step 114/574 completed (loss: 0.21258315443992615, acc: 0.9387755393981934)
[2024-11-29 03:16:47,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:47,483][root][INFO] - Training Epoch: 6/10, step 115/574 completed (loss: 0.028709791600704193, acc: 1.0)
[2024-11-29 03:16:47,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:47,747][root][INFO] - Training Epoch: 6/10, step 116/574 completed (loss: 0.40020033717155457, acc: 0.920634925365448)
[2024-11-29 03:16:47,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:47,984][root][INFO] - Training Epoch: 6/10, step 117/574 completed (loss: 0.6006816625595093, acc: 0.8536585569381714)
[2024-11-29 03:16:48,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:48,170][root][INFO] - Training Epoch: 6/10, step 118/574 completed (loss: 0.12953704595565796, acc: 0.9677419066429138)
[2024-11-29 03:16:48,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:48,988][root][INFO] - Training Epoch: 6/10, step 119/574 completed (loss: 1.1201541423797607, acc: 0.7224334478378296)
[2024-11-29 03:16:49,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:49,259][root][INFO] - Training Epoch: 6/10, step 120/574 completed (loss: 0.3846275508403778, acc: 0.8799999952316284)
[2024-11-29 03:16:49,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:49,576][root][INFO] - Training Epoch: 6/10, step 121/574 completed (loss: 0.2894594967365265, acc: 0.9230769276618958)
[2024-11-29 03:16:49,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:49,794][root][INFO] - Training Epoch: 6/10, step 122/574 completed (loss: 0.06639590114355087, acc: 1.0)
[2024-11-29 03:16:49,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:50,004][root][INFO] - Training Epoch: 6/10, step 123/574 completed (loss: 0.2483830451965332, acc: 0.9473684430122375)
[2024-11-29 03:16:50,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:50,284][root][INFO] - Training Epoch: 6/10, step 124/574 completed (loss: 1.3472745418548584, acc: 0.650306761264801)
[2024-11-29 03:16:50,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:50,539][root][INFO] - Training Epoch: 6/10, step 125/574 completed (loss: 1.335575819015503, acc: 0.6527777910232544)
[2024-11-29 03:16:50,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:50,753][root][INFO] - Training Epoch: 6/10, step 126/574 completed (loss: 1.0183382034301758, acc: 0.6833333373069763)
[2024-11-29 03:16:50,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:51,011][root][INFO] - Training Epoch: 6/10, step 127/574 completed (loss: 1.372141718864441, acc: 0.6428571343421936)
[2024-11-29 03:16:51,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:51,250][root][INFO] - Training Epoch: 6/10, step 128/574 completed (loss: 1.1045268774032593, acc: 0.7230769395828247)
[2024-11-29 03:16:51,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:51,550][root][INFO] - Training Epoch: 6/10, step 129/574 completed (loss: 1.026023268699646, acc: 0.7352941036224365)
[2024-11-29 03:16:51,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:51,751][root][INFO] - Training Epoch: 6/10, step 130/574 completed (loss: 0.48348113894462585, acc: 0.8461538553237915)
[2024-11-29 03:16:51,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:51,970][root][INFO] - Training Epoch: 6/10, step 131/574 completed (loss: 0.3517484664916992, acc: 0.8695651888847351)
[2024-11-29 03:16:52,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:52,181][root][INFO] - Training Epoch: 6/10, step 132/574 completed (loss: 0.8872256278991699, acc: 0.78125)
[2024-11-29 03:16:53,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:53,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:53,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:53,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:54,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:54,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:54,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:54,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:55,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:55,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:55,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:56,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:56,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:56,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:57,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:57,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:57,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:57,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:58,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:58,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:58,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:58,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:59,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:59,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:59,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:59,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:00,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:00,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:00,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:01,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:01,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:01,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:01,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:02,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:02,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:02,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:02,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:03,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:03,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:03,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:04,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:04,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:04,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:05,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:05,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:05,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:06,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:06,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:06,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:06,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:07,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:07,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:07,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:07,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:08,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:08,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:08,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:08,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:09,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:09,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:09,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:10,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:10,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:10,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:11,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:11,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:11,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:12,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:12,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:12,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:13,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:13,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:13,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:14,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:14,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:14,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:14,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:15,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:15,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:15,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:16,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:16,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:16,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:17,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:17,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:17,940][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.9463, device='cuda:0') eval_epoch_loss=tensor(1.0805, device='cuda:0') eval_epoch_acc=tensor(0.7501, device='cuda:0')
[2024-11-29 03:17:17,942][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:17:17,942][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:17:18,115][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_6_step_133_loss_1.0805429220199585/model.pt
[2024-11-29 03:17:18,117][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 6 is 0.7500692009925842
[2024-11-29 03:17:18,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:18,407][root][INFO] - Training Epoch: 6/10, step 133/574 completed (loss: 0.29172948002815247, acc: 0.9130434989929199)
[2024-11-29 03:17:18,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:18,628][root][INFO] - Training Epoch: 6/10, step 134/574 completed (loss: 0.6427053213119507, acc: 0.9142857193946838)
[2024-11-29 03:17:18,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:18,865][root][INFO] - Training Epoch: 6/10, step 135/574 completed (loss: 0.30937105417251587, acc: 0.807692289352417)
[2024-11-29 03:17:18,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:19,114][root][INFO] - Training Epoch: 6/10, step 136/574 completed (loss: 0.6499180793762207, acc: 0.8095238208770752)
[2024-11-29 03:17:19,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:19,359][root][INFO] - Training Epoch: 6/10, step 137/574 completed (loss: 1.3258846998214722, acc: 0.7333333492279053)
[2024-11-29 03:17:19,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:19,633][root][INFO] - Training Epoch: 6/10, step 138/574 completed (loss: 0.10430119186639786, acc: 0.95652174949646)
[2024-11-29 03:17:19,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:19,876][root][INFO] - Training Epoch: 6/10, step 139/574 completed (loss: 0.13178174197673798, acc: 1.0)
[2024-11-29 03:17:19,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:20,100][root][INFO] - Training Epoch: 6/10, step 140/574 completed (loss: 0.1829487383365631, acc: 0.9230769276618958)
[2024-11-29 03:17:20,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:20,381][root][INFO] - Training Epoch: 6/10, step 141/574 completed (loss: 0.2257753312587738, acc: 0.8709677457809448)
[2024-11-29 03:17:20,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:20,623][root][INFO] - Training Epoch: 6/10, step 142/574 completed (loss: 0.2582088112831116, acc: 0.9459459185600281)
[2024-11-29 03:17:20,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:21,103][root][INFO] - Training Epoch: 6/10, step 143/574 completed (loss: 0.749876081943512, acc: 0.780701756477356)
[2024-11-29 03:17:21,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:21,332][root][INFO] - Training Epoch: 6/10, step 144/574 completed (loss: 1.0668195486068726, acc: 0.6641790866851807)
[2024-11-29 03:17:21,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:21,565][root][INFO] - Training Epoch: 6/10, step 145/574 completed (loss: 0.7752278447151184, acc: 0.7653061151504517)
[2024-11-29 03:17:21,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:21,916][root][INFO] - Training Epoch: 6/10, step 146/574 completed (loss: 1.1115233898162842, acc: 0.5957446694374084)
[2024-11-29 03:17:21,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:22,125][root][INFO] - Training Epoch: 6/10, step 147/574 completed (loss: 0.7219909429550171, acc: 0.6714285612106323)
[2024-11-29 03:17:22,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:22,318][root][INFO] - Training Epoch: 6/10, step 148/574 completed (loss: 0.22415156662464142, acc: 0.9285714030265808)
[2024-11-29 03:17:22,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:22,514][root][INFO] - Training Epoch: 6/10, step 149/574 completed (loss: 0.23568128049373627, acc: 0.9130434989929199)
[2024-11-29 03:17:22,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:22,754][root][INFO] - Training Epoch: 6/10, step 150/574 completed (loss: 0.3835802376270294, acc: 0.8965517282485962)
[2024-11-29 03:17:22,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:22,979][root][INFO] - Training Epoch: 6/10, step 151/574 completed (loss: 0.5500765442848206, acc: 0.9130434989929199)
[2024-11-29 03:17:23,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:23,221][root][INFO] - Training Epoch: 6/10, step 152/574 completed (loss: 0.8029886484146118, acc: 0.7457627058029175)
[2024-11-29 03:17:23,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:23,466][root][INFO] - Training Epoch: 6/10, step 153/574 completed (loss: 0.7099032998085022, acc: 0.8245614171028137)
[2024-11-29 03:17:23,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:23,711][root][INFO] - Training Epoch: 6/10, step 154/574 completed (loss: 0.48489466309547424, acc: 0.8513513803482056)
[2024-11-29 03:17:23,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:23,941][root][INFO] - Training Epoch: 6/10, step 155/574 completed (loss: 0.11685322970151901, acc: 1.0)
[2024-11-29 03:17:24,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:24,159][root][INFO] - Training Epoch: 6/10, step 156/574 completed (loss: 0.7226473689079285, acc: 0.8260869383811951)
[2024-11-29 03:17:24,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:24,405][root][INFO] - Training Epoch: 6/10, step 157/574 completed (loss: 2.7794857025146484, acc: 0.3684210479259491)
[2024-11-29 03:17:25,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:26,080][root][INFO] - Training Epoch: 6/10, step 158/574 completed (loss: 1.7903050184249878, acc: 0.5)
[2024-11-29 03:17:26,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:26,261][root][INFO] - Training Epoch: 6/10, step 159/574 completed (loss: 1.4603056907653809, acc: 0.6111111044883728)
[2024-11-29 03:17:26,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:26,601][root][INFO] - Training Epoch: 6/10, step 160/574 completed (loss: 1.681029200553894, acc: 0.5813953280448914)
[2024-11-29 03:17:26,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:27,114][root][INFO] - Training Epoch: 6/10, step 161/574 completed (loss: 1.9416486024856567, acc: 0.529411792755127)
[2024-11-29 03:17:27,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:27,582][root][INFO] - Training Epoch: 6/10, step 162/574 completed (loss: 1.8413221836090088, acc: 0.5617977380752563)
[2024-11-29 03:17:27,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:27,796][root][INFO] - Training Epoch: 6/10, step 163/574 completed (loss: 0.5429847836494446, acc: 0.8863636255264282)
[2024-11-29 03:17:27,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:27,989][root][INFO] - Training Epoch: 6/10, step 164/574 completed (loss: 0.4902287423610687, acc: 0.9047619104385376)
[2024-11-29 03:17:28,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:28,209][root][INFO] - Training Epoch: 6/10, step 165/574 completed (loss: 1.3140151500701904, acc: 0.6551724076271057)
[2024-11-29 03:17:28,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:28,446][root][INFO] - Training Epoch: 6/10, step 166/574 completed (loss: 0.20417584478855133, acc: 0.8979591727256775)
[2024-11-29 03:17:28,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:28,707][root][INFO] - Training Epoch: 6/10, step 167/574 completed (loss: 0.25449663400650024, acc: 0.9599999785423279)
[2024-11-29 03:17:28,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:29,018][root][INFO] - Training Epoch: 6/10, step 168/574 completed (loss: 0.5212653279304504, acc: 0.8472222089767456)
[2024-11-29 03:17:29,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:29,261][root][INFO] - Training Epoch: 6/10, step 169/574 completed (loss: 1.2212135791778564, acc: 0.6960784196853638)
[2024-11-29 03:17:29,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:30,265][root][INFO] - Training Epoch: 6/10, step 170/574 completed (loss: 1.5216151475906372, acc: 0.6438356041908264)
[2024-11-29 03:17:30,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:30,505][root][INFO] - Training Epoch: 6/10, step 171/574 completed (loss: 0.2821165919303894, acc: 0.9166666865348816)
[2024-11-29 03:17:30,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:30,751][root][INFO] - Training Epoch: 6/10, step 172/574 completed (loss: 1.2426835298538208, acc: 0.5925925970077515)
[2024-11-29 03:17:30,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:31,028][root][INFO] - Training Epoch: 6/10, step 173/574 completed (loss: 0.2231738567352295, acc: 0.9285714030265808)
[2024-11-29 03:17:31,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:31,500][root][INFO] - Training Epoch: 6/10, step 174/574 completed (loss: 1.289993166923523, acc: 0.7345132827758789)
[2024-11-29 03:17:31,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:31,770][root][INFO] - Training Epoch: 6/10, step 175/574 completed (loss: 0.8943600058555603, acc: 0.7681159377098083)
[2024-11-29 03:17:31,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:32,011][root][INFO] - Training Epoch: 6/10, step 176/574 completed (loss: 0.31818196177482605, acc: 0.875)
[2024-11-29 03:17:32,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:32,862][root][INFO] - Training Epoch: 6/10, step 177/574 completed (loss: 1.3052712678909302, acc: 0.6488549709320068)
[2024-11-29 03:17:33,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:33,487][root][INFO] - Training Epoch: 6/10, step 178/574 completed (loss: 1.2162718772888184, acc: 0.6592592597007751)
[2024-11-29 03:17:33,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:33,733][root][INFO] - Training Epoch: 6/10, step 179/574 completed (loss: 0.3110053837299347, acc: 0.8360655903816223)
[2024-11-29 03:17:33,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:33,975][root][INFO] - Training Epoch: 6/10, step 180/574 completed (loss: 0.01110548060387373, acc: 1.0)
[2024-11-29 03:17:34,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:34,255][root][INFO] - Training Epoch: 6/10, step 181/574 completed (loss: 0.1333504319190979, acc: 0.9599999785423279)
[2024-11-29 03:17:34,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:34,495][root][INFO] - Training Epoch: 6/10, step 182/574 completed (loss: 0.09479714184999466, acc: 0.9642857313156128)
[2024-11-29 03:17:34,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:34,725][root][INFO] - Training Epoch: 6/10, step 183/574 completed (loss: 0.2795383334159851, acc: 0.9268292784690857)
[2024-11-29 03:17:34,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:34,981][root][INFO] - Training Epoch: 6/10, step 184/574 completed (loss: 0.939028263092041, acc: 0.7945619225502014)
[2024-11-29 03:17:35,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:35,228][root][INFO] - Training Epoch: 6/10, step 185/574 completed (loss: 0.893799901008606, acc: 0.7838616967201233)
[2024-11-29 03:17:35,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:35,623][root][INFO] - Training Epoch: 6/10, step 186/574 completed (loss: 0.8279191851615906, acc: 0.746874988079071)
[2024-11-29 03:17:35,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:36,053][root][INFO] - Training Epoch: 6/10, step 187/574 completed (loss: 1.0527923107147217, acc: 0.7298311591148376)
[2024-11-29 03:17:36,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:36,357][root][INFO] - Training Epoch: 6/10, step 188/574 completed (loss: 0.8313565254211426, acc: 0.7508896589279175)
[2024-11-29 03:17:36,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:36,551][root][INFO] - Training Epoch: 6/10, step 189/574 completed (loss: 0.6855710744857788, acc: 0.8799999952316284)
[2024-11-29 03:17:36,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:37,024][root][INFO] - Training Epoch: 6/10, step 190/574 completed (loss: 0.9091407656669617, acc: 0.6976743936538696)
[2024-11-29 03:17:37,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:37,732][root][INFO] - Training Epoch: 6/10, step 191/574 completed (loss: 1.4088144302368164, acc: 0.6111111044883728)
[2024-11-29 03:17:38,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:38,556][root][INFO] - Training Epoch: 6/10, step 192/574 completed (loss: 1.4895471334457397, acc: 0.6060606241226196)
[2024-11-29 03:17:38,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:39,201][root][INFO] - Training Epoch: 6/10, step 193/574 completed (loss: 0.7189192771911621, acc: 0.7882353067398071)
[2024-11-29 03:17:39,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:40,163][root][INFO] - Training Epoch: 6/10, step 194/574 completed (loss: 1.204163670539856, acc: 0.6419752836227417)
[2024-11-29 03:17:40,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:41,007][root][INFO] - Training Epoch: 6/10, step 195/574 completed (loss: 0.5985414981842041, acc: 0.8225806355476379)
[2024-11-29 03:17:41,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:41,181][root][INFO] - Training Epoch: 6/10, step 196/574 completed (loss: 0.07800624519586563, acc: 1.0)
[2024-11-29 03:17:41,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:41,424][root][INFO] - Training Epoch: 6/10, step 197/574 completed (loss: 0.4678855538368225, acc: 0.925000011920929)
[2024-11-29 03:17:41,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:41,661][root][INFO] - Training Epoch: 6/10, step 198/574 completed (loss: 0.4981115460395813, acc: 0.7941176295280457)
[2024-11-29 03:17:41,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:41,888][root][INFO] - Training Epoch: 6/10, step 199/574 completed (loss: 1.1333115100860596, acc: 0.7720588445663452)
[2024-11-29 03:17:41,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:42,102][root][INFO] - Training Epoch: 6/10, step 200/574 completed (loss: 0.8870413899421692, acc: 0.7203390002250671)
[2024-11-29 03:17:42,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:42,324][root][INFO] - Training Epoch: 6/10, step 201/574 completed (loss: 0.8768107891082764, acc: 0.7910447716712952)
[2024-11-29 03:17:42,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:42,620][root][INFO] - Training Epoch: 6/10, step 202/574 completed (loss: 0.913122296333313, acc: 0.708737850189209)
[2024-11-29 03:17:42,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:42,870][root][INFO] - Training Epoch: 6/10, step 203/574 completed (loss: 0.5136037468910217, acc: 0.8253968358039856)
[2024-11-29 03:17:42,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:43,070][root][INFO] - Training Epoch: 6/10, step 204/574 completed (loss: 0.10434580594301224, acc: 0.9780219793319702)
[2024-11-29 03:17:43,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:43,312][root][INFO] - Training Epoch: 6/10, step 205/574 completed (loss: 0.49093934893608093, acc: 0.8430493474006653)
[2024-11-29 03:17:43,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:43,629][root][INFO] - Training Epoch: 6/10, step 206/574 completed (loss: 0.7335460782051086, acc: 0.7637795209884644)
[2024-11-29 03:17:43,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:43,843][root][INFO] - Training Epoch: 6/10, step 207/574 completed (loss: 0.4680427610874176, acc: 0.857758641242981)
[2024-11-29 03:17:43,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:44,107][root][INFO] - Training Epoch: 6/10, step 208/574 completed (loss: 0.56998211145401, acc: 0.8623188138008118)
[2024-11-29 03:17:44,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:44,365][root][INFO] - Training Epoch: 6/10, step 209/574 completed (loss: 0.5559573173522949, acc: 0.8404669165611267)
[2024-11-29 03:17:44,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:44,590][root][INFO] - Training Epoch: 6/10, step 210/574 completed (loss: 0.3791270852088928, acc: 0.9347826242446899)
[2024-11-29 03:17:44,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:44,796][root][INFO] - Training Epoch: 6/10, step 211/574 completed (loss: 0.09341395646333694, acc: 1.0)
[2024-11-29 03:17:44,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:45,032][root][INFO] - Training Epoch: 6/10, step 212/574 completed (loss: 0.16670344769954681, acc: 0.9642857313156128)
[2024-11-29 03:17:45,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:45,312][root][INFO] - Training Epoch: 6/10, step 213/574 completed (loss: 0.395670086145401, acc: 0.8723404407501221)
[2024-11-29 03:17:45,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:45,953][root][INFO] - Training Epoch: 6/10, step 214/574 completed (loss: 0.3573033809661865, acc: 0.9230769276618958)
[2024-11-29 03:17:46,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:46,196][root][INFO] - Training Epoch: 6/10, step 215/574 completed (loss: 0.17646928131580353, acc: 0.9459459185600281)
[2024-11-29 03:17:46,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:46,412][root][INFO] - Training Epoch: 6/10, step 216/574 completed (loss: 0.11308509111404419, acc: 0.9767441749572754)
[2024-11-29 03:17:46,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:46,860][root][INFO] - Training Epoch: 6/10, step 217/574 completed (loss: 0.2053493857383728, acc: 0.9369369149208069)
[2024-11-29 03:17:46,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:47,153][root][INFO] - Training Epoch: 6/10, step 218/574 completed (loss: 0.33110323548316956, acc: 0.855555534362793)
[2024-11-29 03:17:47,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:47,364][root][INFO] - Training Epoch: 6/10, step 219/574 completed (loss: 0.17498695850372314, acc: 0.939393937587738)
[2024-11-29 03:17:47,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:47,581][root][INFO] - Training Epoch: 6/10, step 220/574 completed (loss: 0.06755831837654114, acc: 1.0)
[2024-11-29 03:17:47,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:47,798][root][INFO] - Training Epoch: 6/10, step 221/574 completed (loss: 0.06616564095020294, acc: 1.0)
[2024-11-29 03:17:47,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:48,019][root][INFO] - Training Epoch: 6/10, step 222/574 completed (loss: 0.8540066480636597, acc: 0.7307692170143127)
[2024-11-29 03:17:48,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:48,694][root][INFO] - Training Epoch: 6/10, step 223/574 completed (loss: 0.4901812970638275, acc: 0.885869562625885)
[2024-11-29 03:17:48,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:49,145][root][INFO] - Training Epoch: 6/10, step 224/574 completed (loss: 0.6925988793373108, acc: 0.8238636255264282)
[2024-11-29 03:17:49,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:49,491][root][INFO] - Training Epoch: 6/10, step 225/574 completed (loss: 0.7099543809890747, acc: 0.7872340679168701)
[2024-11-29 03:17:49,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:49,731][root][INFO] - Training Epoch: 6/10, step 226/574 completed (loss: 0.5794687867164612, acc: 0.8113207817077637)
[2024-11-29 03:17:49,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:49,994][root][INFO] - Training Epoch: 6/10, step 227/574 completed (loss: 0.1574477106332779, acc: 0.9666666388511658)
[2024-11-29 03:17:50,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:50,223][root][INFO] - Training Epoch: 6/10, step 228/574 completed (loss: 0.7191408276557922, acc: 0.8139534592628479)
[2024-11-29 03:17:50,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:50,474][root][INFO] - Training Epoch: 6/10, step 229/574 completed (loss: 1.5006581544876099, acc: 0.5666666626930237)
[2024-11-29 03:17:50,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:50,771][root][INFO] - Training Epoch: 6/10, step 230/574 completed (loss: 2.6072590351104736, acc: 0.3263157904148102)
[2024-11-29 03:17:50,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:51,009][root][INFO] - Training Epoch: 6/10, step 231/574 completed (loss: 1.9567830562591553, acc: 0.5222222208976746)
[2024-11-29 03:17:51,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:51,370][root][INFO] - Training Epoch: 6/10, step 232/574 completed (loss: 2.018949270248413, acc: 0.5055555701255798)
[2024-11-29 03:17:51,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:51,775][root][INFO] - Training Epoch: 6/10, step 233/574 completed (loss: 2.371216058731079, acc: 0.41743120551109314)
[2024-11-29 03:17:51,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:52,155][root][INFO] - Training Epoch: 6/10, step 234/574 completed (loss: 2.0098469257354736, acc: 0.5538461804389954)
[2024-11-29 03:17:52,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:52,357][root][INFO] - Training Epoch: 6/10, step 235/574 completed (loss: 0.04149315506219864, acc: 1.0)
[2024-11-29 03:17:52,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:52,588][root][INFO] - Training Epoch: 6/10, step 236/574 completed (loss: 0.16004328429698944, acc: 0.9166666865348816)
[2024-11-29 03:17:52,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:52,831][root][INFO] - Training Epoch: 6/10, step 237/574 completed (loss: 0.2172626405954361, acc: 0.9090909361839294)
[2024-11-29 03:17:52,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:53,076][root][INFO] - Training Epoch: 6/10, step 238/574 completed (loss: 0.5552085638046265, acc: 0.7777777910232544)
[2024-11-29 03:17:53,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:53,312][root][INFO] - Training Epoch: 6/10, step 239/574 completed (loss: 0.40427443385124207, acc: 0.8857142925262451)
[2024-11-29 03:17:53,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:53,543][root][INFO] - Training Epoch: 6/10, step 240/574 completed (loss: 0.8013704419136047, acc: 0.8636363744735718)
[2024-11-29 03:17:53,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:53,745][root][INFO] - Training Epoch: 6/10, step 241/574 completed (loss: 0.4254288673400879, acc: 0.8409090638160706)
[2024-11-29 03:17:53,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:54,243][root][INFO] - Training Epoch: 6/10, step 242/574 completed (loss: 1.1210715770721436, acc: 0.6290322542190552)
[2024-11-29 03:17:54,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:54,679][root][INFO] - Training Epoch: 6/10, step 243/574 completed (loss: 0.6244323253631592, acc: 0.8409090638160706)
[2024-11-29 03:17:54,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:54,940][root][INFO] - Training Epoch: 6/10, step 244/574 completed (loss: 0.047097887843847275, acc: 1.0)
[2024-11-29 03:17:55,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:55,182][root][INFO] - Training Epoch: 6/10, step 245/574 completed (loss: 0.4828062653541565, acc: 0.8846153616905212)
[2024-11-29 03:17:55,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:55,409][root][INFO] - Training Epoch: 6/10, step 246/574 completed (loss: 0.03840846195816994, acc: 0.9677419066429138)
[2024-11-29 03:17:55,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:55,680][root][INFO] - Training Epoch: 6/10, step 247/574 completed (loss: 0.11307547986507416, acc: 0.949999988079071)
[2024-11-29 03:17:55,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:55,970][root][INFO] - Training Epoch: 6/10, step 248/574 completed (loss: 0.2600722312927246, acc: 0.8648648858070374)
[2024-11-29 03:17:56,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:56,216][root][INFO] - Training Epoch: 6/10, step 249/574 completed (loss: 0.37313219904899597, acc: 0.9189189076423645)
[2024-11-29 03:17:56,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:56,503][root][INFO] - Training Epoch: 6/10, step 250/574 completed (loss: 0.032147523015737534, acc: 1.0)
[2024-11-29 03:17:56,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:56,752][root][INFO] - Training Epoch: 6/10, step 251/574 completed (loss: 0.2621742784976959, acc: 0.9117646813392639)
[2024-11-29 03:17:56,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:56,981][root][INFO] - Training Epoch: 6/10, step 252/574 completed (loss: 0.057566650211811066, acc: 0.9756097793579102)
[2024-11-29 03:17:57,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:57,228][root][INFO] - Training Epoch: 6/10, step 253/574 completed (loss: 0.02420244924724102, acc: 1.0)
[2024-11-29 03:17:57,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:57,446][root][INFO] - Training Epoch: 6/10, step 254/574 completed (loss: 0.055014800280332565, acc: 0.9599999785423279)
[2024-11-29 03:17:57,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:57,649][root][INFO] - Training Epoch: 6/10, step 255/574 completed (loss: 0.024465931579470634, acc: 1.0)
[2024-11-29 03:17:57,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:57,887][root][INFO] - Training Epoch: 6/10, step 256/574 completed (loss: 0.2544171214103699, acc: 0.9298245906829834)
[2024-11-29 03:17:57,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:58,090][root][INFO] - Training Epoch: 6/10, step 257/574 completed (loss: 0.12613828480243683, acc: 0.9714285731315613)
[2024-11-29 03:17:58,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:58,358][root][INFO] - Training Epoch: 6/10, step 258/574 completed (loss: 0.10770373791456223, acc: 0.9605262875556946)
[2024-11-29 03:17:58,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:58,927][root][INFO] - Training Epoch: 6/10, step 259/574 completed (loss: 0.5110730528831482, acc: 0.849056601524353)
[2024-11-29 03:17:59,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:59,417][root][INFO] - Training Epoch: 6/10, step 260/574 completed (loss: 0.5275823473930359, acc: 0.8666666746139526)
[2024-11-29 03:17:59,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:59,609][root][INFO] - Training Epoch: 6/10, step 261/574 completed (loss: 0.0507822148501873, acc: 1.0)
[2024-11-29 03:17:59,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:59,865][root][INFO] - Training Epoch: 6/10, step 262/574 completed (loss: 0.18742038309574127, acc: 0.9354838728904724)
[2024-11-29 03:17:59,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:00,119][root][INFO] - Training Epoch: 6/10, step 263/574 completed (loss: 1.0900853872299194, acc: 0.7200000286102295)
[2024-11-29 03:18:00,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:00,357][root][INFO] - Training Epoch: 6/10, step 264/574 completed (loss: 0.6551044583320618, acc: 0.8125)
[2024-11-29 03:18:00,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:01,189][root][INFO] - Training Epoch: 6/10, step 265/574 completed (loss: 1.1286424398422241, acc: 0.6800000071525574)
[2024-11-29 03:18:01,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:01,467][root][INFO] - Training Epoch: 6/10, step 266/574 completed (loss: 1.1380441188812256, acc: 0.6853932738304138)
[2024-11-29 03:18:01,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:01,726][root][INFO] - Training Epoch: 6/10, step 267/574 completed (loss: 0.8396015763282776, acc: 0.7567567825317383)
[2024-11-29 03:18:01,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:02,107][root][INFO] - Training Epoch: 6/10, step 268/574 completed (loss: 0.7409845590591431, acc: 0.7241379022598267)
[2024-11-29 03:18:02,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:02,350][root][INFO] - Training Epoch: 6/10, step 269/574 completed (loss: 0.017988210543990135, acc: 1.0)
[2024-11-29 03:18:02,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:02,640][root][INFO] - Training Epoch: 6/10, step 270/574 completed (loss: 0.09555673599243164, acc: 0.9545454382896423)
[2024-11-29 03:18:02,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:02,842][root][INFO] - Training Epoch: 6/10, step 271/574 completed (loss: 0.07207566499710083, acc: 1.0)
[2024-11-29 03:18:02,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:03,103][root][INFO] - Training Epoch: 6/10, step 272/574 completed (loss: 0.101483054459095, acc: 0.9666666388511658)
[2024-11-29 03:18:03,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:03,385][root][INFO] - Training Epoch: 6/10, step 273/574 completed (loss: 0.350534588098526, acc: 0.8833333253860474)
[2024-11-29 03:18:03,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:03,614][root][INFO] - Training Epoch: 6/10, step 274/574 completed (loss: 0.17225494980812073, acc: 0.9375)
[2024-11-29 03:18:03,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:03,839][root][INFO] - Training Epoch: 6/10, step 275/574 completed (loss: 0.10871786624193192, acc: 0.9666666388511658)
[2024-11-29 03:18:04,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:04,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:05,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:05,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:05,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:05,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:06,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:06,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:06,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:06,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:07,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:07,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:07,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:08,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:08,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:08,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:09,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:09,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:09,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:09,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:10,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:10,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:10,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:10,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:11,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:11,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:11,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:12,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:12,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:12,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:12,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:13,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:13,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:13,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:13,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:14,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:14,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:14,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:14,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:15,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:15,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:15,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:16,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:16,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:16,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:17,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:17,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:17,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:17,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:18,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:18,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:18,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:18,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:19,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:19,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:19,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:20,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:20,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:20,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:20,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:21,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:21,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:21,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:22,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:22,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:22,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:22,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:23,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:23,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:24,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:24,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:24,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:24,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:25,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:25,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:25,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:25,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:26,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:26,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:26,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:27,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:27,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:27,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:27,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:28,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:28,620][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.1127, device='cuda:0') eval_epoch_loss=tensor(1.1355, device='cuda:0') eval_epoch_acc=tensor(0.7480, device='cuda:0')
[2024-11-29 03:18:28,621][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:18:28,621][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:18:28,790][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_6_step_276_loss_1.1354961395263672/model.pt
[2024-11-29 03:18:28,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:28,980][root][INFO] - Training Epoch: 6/10, step 276/574 completed (loss: 0.4162181317806244, acc: 0.8620689511299133)
[2024-11-29 03:18:29,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:29,181][root][INFO] - Training Epoch: 6/10, step 277/574 completed (loss: 0.01747026853263378, acc: 1.0)
[2024-11-29 03:18:29,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:29,380][root][INFO] - Training Epoch: 6/10, step 278/574 completed (loss: 0.7442677021026611, acc: 0.8085106611251831)
[2024-11-29 03:18:29,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:29,609][root][INFO] - Training Epoch: 6/10, step 279/574 completed (loss: 0.48880496621131897, acc: 0.8958333134651184)
[2024-11-29 03:18:29,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:29,877][root][INFO] - Training Epoch: 6/10, step 280/574 completed (loss: 0.1106576919555664, acc: 0.9772727489471436)
[2024-11-29 03:18:30,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:30,213][root][INFO] - Training Epoch: 6/10, step 281/574 completed (loss: 0.7776291370391846, acc: 0.7831325531005859)
[2024-11-29 03:18:30,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:30,472][root][INFO] - Training Epoch: 6/10, step 282/574 completed (loss: 0.7289409637451172, acc: 0.7685185074806213)
[2024-11-29 03:18:30,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:30,764][root][INFO] - Training Epoch: 6/10, step 283/574 completed (loss: 0.11599219590425491, acc: 0.9736841917037964)
[2024-11-29 03:18:30,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:31,018][root][INFO] - Training Epoch: 6/10, step 284/574 completed (loss: 0.07881952077150345, acc: 0.970588207244873)
[2024-11-29 03:18:31,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:31,277][root][INFO] - Training Epoch: 6/10, step 285/574 completed (loss: 0.0761164128780365, acc: 0.9750000238418579)
[2024-11-29 03:18:31,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:31,539][root][INFO] - Training Epoch: 6/10, step 286/574 completed (loss: 0.5646015405654907, acc: 0.8671875)
[2024-11-29 03:18:31,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:31,793][root][INFO] - Training Epoch: 6/10, step 287/574 completed (loss: 0.6862526535987854, acc: 0.8080000281333923)
[2024-11-29 03:18:31,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:32,019][root][INFO] - Training Epoch: 6/10, step 288/574 completed (loss: 0.4609338641166687, acc: 0.8901098966598511)
[2024-11-29 03:18:32,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:32,227][root][INFO] - Training Epoch: 6/10, step 289/574 completed (loss: 0.5029013752937317, acc: 0.850931704044342)
[2024-11-29 03:18:32,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:32,512][root][INFO] - Training Epoch: 6/10, step 290/574 completed (loss: 0.6840848922729492, acc: 0.8195876479148865)
[2024-11-29 03:18:32,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:32,761][root][INFO] - Training Epoch: 6/10, step 291/574 completed (loss: 0.04943342134356499, acc: 1.0)
[2024-11-29 03:18:32,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:33,001][root][INFO] - Training Epoch: 6/10, step 292/574 completed (loss: 0.4624626934528351, acc: 0.8571428656578064)
[2024-11-29 03:18:33,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:33,212][root][INFO] - Training Epoch: 6/10, step 293/574 completed (loss: 0.22495338320732117, acc: 0.9655172228813171)
[2024-11-29 03:18:33,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:33,625][root][INFO] - Training Epoch: 6/10, step 294/574 completed (loss: 0.593410849571228, acc: 0.8363636136054993)
[2024-11-29 03:18:33,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:34,082][root][INFO] - Training Epoch: 6/10, step 295/574 completed (loss: 0.9296630620956421, acc: 0.7371134161949158)
[2024-11-29 03:18:34,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:34,324][root][INFO] - Training Epoch: 6/10, step 296/574 completed (loss: 0.3371979594230652, acc: 0.9137930870056152)
[2024-11-29 03:18:34,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:34,610][root][INFO] - Training Epoch: 6/10, step 297/574 completed (loss: 0.043971605598926544, acc: 1.0)
[2024-11-29 03:18:34,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:34,850][root][INFO] - Training Epoch: 6/10, step 298/574 completed (loss: 0.1525852233171463, acc: 0.9736841917037964)
[2024-11-29 03:18:34,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:35,086][root][INFO] - Training Epoch: 6/10, step 299/574 completed (loss: 0.16809788346290588, acc: 0.9464285969734192)
[2024-11-29 03:18:35,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:35,339][root][INFO] - Training Epoch: 6/10, step 300/574 completed (loss: 0.0274723619222641, acc: 1.0)
[2024-11-29 03:18:35,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:35,586][root][INFO] - Training Epoch: 6/10, step 301/574 completed (loss: 0.28180521726608276, acc: 0.9433962106704712)
[2024-11-29 03:18:35,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:35,825][root][INFO] - Training Epoch: 6/10, step 302/574 completed (loss: 0.07469134032726288, acc: 0.9811320900917053)
[2024-11-29 03:18:35,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:36,086][root][INFO] - Training Epoch: 6/10, step 303/574 completed (loss: 0.06441912800073624, acc: 1.0)
[2024-11-29 03:18:36,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:36,319][root][INFO] - Training Epoch: 6/10, step 304/574 completed (loss: 0.18402394652366638, acc: 0.90625)
[2024-11-29 03:18:36,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:36,564][root][INFO] - Training Epoch: 6/10, step 305/574 completed (loss: 0.5582908987998962, acc: 0.9016393423080444)
[2024-11-29 03:18:36,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:36,758][root][INFO] - Training Epoch: 6/10, step 306/574 completed (loss: 0.33908554911613464, acc: 0.9333333373069763)
[2024-11-29 03:18:36,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:36,996][root][INFO] - Training Epoch: 6/10, step 307/574 completed (loss: 0.004048035945743322, acc: 1.0)
[2024-11-29 03:18:37,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:37,224][root][INFO] - Training Epoch: 6/10, step 308/574 completed (loss: 0.25009649991989136, acc: 0.9130434989929199)
[2024-11-29 03:18:37,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:37,559][root][INFO] - Training Epoch: 6/10, step 309/574 completed (loss: 0.2626229226589203, acc: 0.9444444179534912)
[2024-11-29 03:18:37,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:37,820][root][INFO] - Training Epoch: 6/10, step 310/574 completed (loss: 0.24325761198997498, acc: 0.9397590160369873)
[2024-11-29 03:18:37,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:38,067][root][INFO] - Training Epoch: 6/10, step 311/574 completed (loss: 0.3963918685913086, acc: 0.8461538553237915)
[2024-11-29 03:18:38,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:38,316][root][INFO] - Training Epoch: 6/10, step 312/574 completed (loss: 0.11830660700798035, acc: 0.9489796161651611)
[2024-11-29 03:18:38,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:38,521][root][INFO] - Training Epoch: 6/10, step 313/574 completed (loss: 0.014195975847542286, acc: 1.0)
[2024-11-29 03:18:38,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:38,783][root][INFO] - Training Epoch: 6/10, step 314/574 completed (loss: 0.028777917847037315, acc: 1.0)
[2024-11-29 03:18:38,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:39,029][root][INFO] - Training Epoch: 6/10, step 315/574 completed (loss: 0.125735804438591, acc: 0.9354838728904724)
[2024-11-29 03:18:39,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:39,254][root][INFO] - Training Epoch: 6/10, step 316/574 completed (loss: 1.002383828163147, acc: 0.7419354915618896)
[2024-11-29 03:18:39,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:39,472][root][INFO] - Training Epoch: 6/10, step 317/574 completed (loss: 0.21673648059368134, acc: 0.9253731369972229)
[2024-11-29 03:18:39,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:39,699][root][INFO] - Training Epoch: 6/10, step 318/574 completed (loss: 0.1835973560810089, acc: 0.942307710647583)
[2024-11-29 03:18:39,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:39,957][root][INFO] - Training Epoch: 6/10, step 319/574 completed (loss: 0.16492468118667603, acc: 0.9555555582046509)
[2024-11-29 03:18:40,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:40,209][root][INFO] - Training Epoch: 6/10, step 320/574 completed (loss: 0.08983947336673737, acc: 0.9838709831237793)
[2024-11-29 03:18:40,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:40,473][root][INFO] - Training Epoch: 6/10, step 321/574 completed (loss: 0.022460151463747025, acc: 1.0)
[2024-11-29 03:18:40,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:40,755][root][INFO] - Training Epoch: 6/10, step 322/574 completed (loss: 0.6689410209655762, acc: 0.7777777910232544)
[2024-11-29 03:18:40,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:40,992][root][INFO] - Training Epoch: 6/10, step 323/574 completed (loss: 1.3920519351959229, acc: 0.6285714507102966)
[2024-11-29 03:18:41,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:41,228][root][INFO] - Training Epoch: 6/10, step 324/574 completed (loss: 0.9036046266555786, acc: 0.6666666865348816)
[2024-11-29 03:18:41,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:41,454][root][INFO] - Training Epoch: 6/10, step 325/574 completed (loss: 1.9202901124954224, acc: 0.46341463923454285)
[2024-11-29 03:18:41,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:41,693][root][INFO] - Training Epoch: 6/10, step 326/574 completed (loss: 0.9553049802780151, acc: 0.7631579041481018)
[2024-11-29 03:18:41,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:41,918][root][INFO] - Training Epoch: 6/10, step 327/574 completed (loss: 0.5052949786186218, acc: 0.8421052694320679)
[2024-11-29 03:18:42,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:42,173][root][INFO] - Training Epoch: 6/10, step 328/574 completed (loss: 0.06056066229939461, acc: 0.9642857313156128)
[2024-11-29 03:18:42,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:42,410][root][INFO] - Training Epoch: 6/10, step 329/574 completed (loss: 0.029401002451777458, acc: 1.0)
[2024-11-29 03:18:42,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:42,627][root][INFO] - Training Epoch: 6/10, step 330/574 completed (loss: 0.043837666511535645, acc: 1.0)
[2024-11-29 03:18:42,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:42,830][root][INFO] - Training Epoch: 6/10, step 331/574 completed (loss: 0.23646770417690277, acc: 0.9032257795333862)
[2024-11-29 03:18:42,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:43,116][root][INFO] - Training Epoch: 6/10, step 332/574 completed (loss: 0.12536831200122833, acc: 0.9824561476707458)
[2024-11-29 03:18:43,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:43,352][root][INFO] - Training Epoch: 6/10, step 333/574 completed (loss: 0.14060044288635254, acc: 0.96875)
[2024-11-29 03:18:43,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:43,633][root][INFO] - Training Epoch: 6/10, step 334/574 completed (loss: 0.10052433609962463, acc: 0.9666666388511658)
[2024-11-29 03:18:43,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:43,878][root][INFO] - Training Epoch: 6/10, step 335/574 completed (loss: 0.11424609273672104, acc: 1.0)
[2024-11-29 03:18:43,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:44,139][root][INFO] - Training Epoch: 6/10, step 336/574 completed (loss: 0.9335324168205261, acc: 0.699999988079071)
[2024-11-29 03:18:44,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:44,394][root][INFO] - Training Epoch: 6/10, step 337/574 completed (loss: 1.313443899154663, acc: 0.6206896305084229)
[2024-11-29 03:18:44,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:44,633][root][INFO] - Training Epoch: 6/10, step 338/574 completed (loss: 1.2020905017852783, acc: 0.6382978558540344)
[2024-11-29 03:18:44,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:44,853][root][INFO] - Training Epoch: 6/10, step 339/574 completed (loss: 1.282009482383728, acc: 0.6746987700462341)
[2024-11-29 03:18:44,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:45,058][root][INFO] - Training Epoch: 6/10, step 340/574 completed (loss: 0.16084420680999756, acc: 0.9130434989929199)
[2024-11-29 03:18:45,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:45,318][root][INFO] - Training Epoch: 6/10, step 341/574 completed (loss: 0.2578040659427643, acc: 0.9487179517745972)
[2024-11-29 03:18:45,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:45,576][root][INFO] - Training Epoch: 6/10, step 342/574 completed (loss: 0.4148324131965637, acc: 0.9036144614219666)
[2024-11-29 03:18:45,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:45,825][root][INFO] - Training Epoch: 6/10, step 343/574 completed (loss: 0.8725167512893677, acc: 0.7169811129570007)
[2024-11-29 03:18:45,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:46,042][root][INFO] - Training Epoch: 6/10, step 344/574 completed (loss: 0.15243695676326752, acc: 0.949367105960846)
[2024-11-29 03:18:46,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:46,244][root][INFO] - Training Epoch: 6/10, step 345/574 completed (loss: 0.12731382250785828, acc: 0.9607843160629272)
[2024-11-29 03:18:46,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:46,458][root][INFO] - Training Epoch: 6/10, step 346/574 completed (loss: 0.4111499488353729, acc: 0.9104477763175964)
[2024-11-29 03:18:46,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:46,659][root][INFO] - Training Epoch: 6/10, step 347/574 completed (loss: 0.08781351149082184, acc: 0.949999988079071)
[2024-11-29 03:18:46,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:46,888][root][INFO] - Training Epoch: 6/10, step 348/574 completed (loss: 0.03199024125933647, acc: 1.0)
[2024-11-29 03:18:47,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:47,188][root][INFO] - Training Epoch: 6/10, step 349/574 completed (loss: 0.8569425344467163, acc: 0.7777777910232544)
[2024-11-29 03:18:47,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:47,457][root][INFO] - Training Epoch: 6/10, step 350/574 completed (loss: 0.533683180809021, acc: 0.7906976938247681)
[2024-11-29 03:18:47,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:47,721][root][INFO] - Training Epoch: 6/10, step 351/574 completed (loss: 0.2191115915775299, acc: 0.9487179517745972)
[2024-11-29 03:18:47,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:47,999][root][INFO] - Training Epoch: 6/10, step 352/574 completed (loss: 0.6359169483184814, acc: 0.8666666746139526)
[2024-11-29 03:18:48,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:48,204][root][INFO] - Training Epoch: 6/10, step 353/574 completed (loss: 0.0169517882168293, acc: 1.0)
[2024-11-29 03:18:48,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:48,470][root][INFO] - Training Epoch: 6/10, step 354/574 completed (loss: 0.15729866921901703, acc: 0.9615384340286255)
[2024-11-29 03:18:48,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:48,752][root][INFO] - Training Epoch: 6/10, step 355/574 completed (loss: 0.7373104095458984, acc: 0.8241758346557617)
[2024-11-29 03:18:48,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:49,183][root][INFO] - Training Epoch: 6/10, step 356/574 completed (loss: 0.5595463514328003, acc: 0.8173912763595581)
[2024-11-29 03:18:49,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:49,430][root][INFO] - Training Epoch: 6/10, step 357/574 completed (loss: 0.2838127613067627, acc: 0.8913043737411499)
[2024-11-29 03:18:49,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:49,694][root][INFO] - Training Epoch: 6/10, step 358/574 completed (loss: 0.36330822110176086, acc: 0.8775510191917419)
[2024-11-29 03:18:49,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:49,953][root][INFO] - Training Epoch: 6/10, step 359/574 completed (loss: 0.08909878134727478, acc: 0.9583333134651184)
[2024-11-29 03:18:50,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:50,192][root][INFO] - Training Epoch: 6/10, step 360/574 completed (loss: 0.052556633949279785, acc: 1.0)
[2024-11-29 03:18:50,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:50,390][root][INFO] - Training Epoch: 6/10, step 361/574 completed (loss: 0.508630633354187, acc: 0.8292682766914368)
[2024-11-29 03:18:50,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:50,586][root][INFO] - Training Epoch: 6/10, step 362/574 completed (loss: 0.4814022183418274, acc: 0.8222222328186035)
[2024-11-29 03:18:50,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:50,807][root][INFO] - Training Epoch: 6/10, step 363/574 completed (loss: 0.11259732395410538, acc: 0.9736841917037964)
[2024-11-29 03:18:50,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:51,058][root][INFO] - Training Epoch: 6/10, step 364/574 completed (loss: 0.06745214760303497, acc: 1.0)
[2024-11-29 03:18:51,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:51,334][root][INFO] - Training Epoch: 6/10, step 365/574 completed (loss: 0.1238982304930687, acc: 0.9696969985961914)
[2024-11-29 03:18:51,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:51,580][root][INFO] - Training Epoch: 6/10, step 366/574 completed (loss: 0.007621446158736944, acc: 1.0)
[2024-11-29 03:18:51,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:51,837][root][INFO] - Training Epoch: 6/10, step 367/574 completed (loss: 0.021232586354017258, acc: 1.0)
[2024-11-29 03:18:51,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:52,084][root][INFO] - Training Epoch: 6/10, step 368/574 completed (loss: 0.11236042529344559, acc: 1.0)
[2024-11-29 03:18:52,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:52,331][root][INFO] - Training Epoch: 6/10, step 369/574 completed (loss: 0.42688068747520447, acc: 0.90625)
[2024-11-29 03:18:52,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:52,848][root][INFO] - Training Epoch: 6/10, step 370/574 completed (loss: 0.7329094409942627, acc: 0.7939394116401672)
[2024-11-29 03:18:53,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:53,654][root][INFO] - Training Epoch: 6/10, step 371/574 completed (loss: 0.3664035499095917, acc: 0.9056603908538818)
[2024-11-29 03:18:53,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:53,916][root][INFO] - Training Epoch: 6/10, step 372/574 completed (loss: 0.22443772852420807, acc: 0.9333333373069763)
[2024-11-29 03:18:54,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:54,186][root][INFO] - Training Epoch: 6/10, step 373/574 completed (loss: 0.09175880998373032, acc: 0.9642857313156128)
[2024-11-29 03:18:54,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:54,457][root][INFO] - Training Epoch: 6/10, step 374/574 completed (loss: 0.08286969363689423, acc: 0.9714285731315613)
[2024-11-29 03:18:54,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:54,701][root][INFO] - Training Epoch: 6/10, step 375/574 completed (loss: 0.011372873559594154, acc: 1.0)
[2024-11-29 03:18:54,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:54,944][root][INFO] - Training Epoch: 6/10, step 376/574 completed (loss: 0.007758319843560457, acc: 1.0)
[2024-11-29 03:18:55,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:55,168][root][INFO] - Training Epoch: 6/10, step 377/574 completed (loss: 0.022511625662446022, acc: 1.0)
[2024-11-29 03:18:55,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:55,414][root][INFO] - Training Epoch: 6/10, step 378/574 completed (loss: 0.04955215007066727, acc: 0.9894737005233765)
[2024-11-29 03:18:55,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:55,898][root][INFO] - Training Epoch: 6/10, step 379/574 completed (loss: 0.3956655263900757, acc: 0.910179615020752)
[2024-11-29 03:18:55,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:56,201][root][INFO] - Training Epoch: 6/10, step 380/574 completed (loss: 0.35164231061935425, acc: 0.9248120188713074)
[2024-11-29 03:18:56,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:57,325][root][INFO] - Training Epoch: 6/10, step 381/574 completed (loss: 0.7048860192298889, acc: 0.8342245817184448)
[2024-11-29 03:18:57,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:57,800][root][INFO] - Training Epoch: 6/10, step 382/574 completed (loss: 0.15260034799575806, acc: 0.954954981803894)
[2024-11-29 03:18:57,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:57,994][root][INFO] - Training Epoch: 6/10, step 383/574 completed (loss: 0.05241652578115463, acc: 1.0)
[2024-11-29 03:18:58,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:58,235][root][INFO] - Training Epoch: 6/10, step 384/574 completed (loss: 0.05791284516453743, acc: 0.9642857313156128)
[2024-11-29 03:18:58,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:58,471][root][INFO] - Training Epoch: 6/10, step 385/574 completed (loss: 0.06614375114440918, acc: 0.96875)
[2024-11-29 03:18:58,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:58,718][root][INFO] - Training Epoch: 6/10, step 386/574 completed (loss: 0.011730809696018696, acc: 1.0)
[2024-11-29 03:18:58,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:58,986][root][INFO] - Training Epoch: 6/10, step 387/574 completed (loss: 0.056298211216926575, acc: 0.9736841917037964)
[2024-11-29 03:18:59,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:59,239][root][INFO] - Training Epoch: 6/10, step 388/574 completed (loss: 0.010105935856699944, acc: 1.0)
[2024-11-29 03:18:59,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:59,520][root][INFO] - Training Epoch: 6/10, step 389/574 completed (loss: 0.05259393900632858, acc: 0.949999988079071)
[2024-11-29 03:18:59,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:59,787][root][INFO] - Training Epoch: 6/10, step 390/574 completed (loss: 0.4916974902153015, acc: 0.8571428656578064)
[2024-11-29 03:18:59,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:00,055][root][INFO] - Training Epoch: 6/10, step 391/574 completed (loss: 0.7651908993721008, acc: 0.8148148059844971)
[2024-11-29 03:19:00,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:00,331][root][INFO] - Training Epoch: 6/10, step 392/574 completed (loss: 0.8622176647186279, acc: 0.7864077687263489)
[2024-11-29 03:19:00,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:00,779][root][INFO] - Training Epoch: 6/10, step 393/574 completed (loss: 0.9987510442733765, acc: 0.7426470518112183)
[2024-11-29 03:19:00,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:01,042][root][INFO] - Training Epoch: 6/10, step 394/574 completed (loss: 0.8398913145065308, acc: 0.7333333492279053)
[2024-11-29 03:19:01,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:01,330][root][INFO] - Training Epoch: 6/10, step 395/574 completed (loss: 0.7028802037239075, acc: 0.8125)
[2024-11-29 03:19:01,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:01,542][root][INFO] - Training Epoch: 6/10, step 396/574 completed (loss: 0.14486505091190338, acc: 0.9767441749572754)
[2024-11-29 03:19:01,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:01,748][root][INFO] - Training Epoch: 6/10, step 397/574 completed (loss: 0.031105803325772285, acc: 1.0)
[2024-11-29 03:19:01,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:02,030][root][INFO] - Training Epoch: 6/10, step 398/574 completed (loss: 0.3632579743862152, acc: 0.9534883499145508)
[2024-11-29 03:19:02,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:02,279][root][INFO] - Training Epoch: 6/10, step 399/574 completed (loss: 0.013310752809047699, acc: 1.0)
[2024-11-29 03:19:02,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:02,727][root][INFO] - Training Epoch: 6/10, step 400/574 completed (loss: 0.25377732515335083, acc: 0.9117646813392639)
[2024-11-29 03:19:02,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:02,981][root][INFO] - Training Epoch: 6/10, step 401/574 completed (loss: 0.2874280512332916, acc: 0.9200000166893005)
[2024-11-29 03:19:03,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:03,263][root][INFO] - Training Epoch: 6/10, step 402/574 completed (loss: 0.2931690216064453, acc: 0.9090909361839294)
[2024-11-29 03:19:03,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:03,511][root][INFO] - Training Epoch: 6/10, step 403/574 completed (loss: 0.24904927611351013, acc: 0.9090909361839294)
[2024-11-29 03:19:03,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:03,761][root][INFO] - Training Epoch: 6/10, step 404/574 completed (loss: 0.22977551817893982, acc: 0.9677419066429138)
[2024-11-29 03:19:03,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:04,028][root][INFO] - Training Epoch: 6/10, step 405/574 completed (loss: 0.04947911947965622, acc: 1.0)
[2024-11-29 03:19:04,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:04,209][root][INFO] - Training Epoch: 6/10, step 406/574 completed (loss: 0.024108760058879852, acc: 1.0)
[2024-11-29 03:19:04,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:04,380][root][INFO] - Training Epoch: 6/10, step 407/574 completed (loss: 0.01504927221685648, acc: 1.0)
[2024-11-29 03:19:04,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:04,561][root][INFO] - Training Epoch: 6/10, step 408/574 completed (loss: 0.04610612988471985, acc: 1.0)
[2024-11-29 03:19:04,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:04,816][root][INFO] - Training Epoch: 6/10, step 409/574 completed (loss: 0.07240240275859833, acc: 0.9615384340286255)
[2024-11-29 03:19:04,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:05,045][root][INFO] - Training Epoch: 6/10, step 410/574 completed (loss: 0.12484435737133026, acc: 0.9482758641242981)
[2024-11-29 03:19:05,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:05,252][root][INFO] - Training Epoch: 6/10, step 411/574 completed (loss: 0.22144195437431335, acc: 0.9285714030265808)
[2024-11-29 03:19:05,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:05,500][root][INFO] - Training Epoch: 6/10, step 412/574 completed (loss: 0.0331486351788044, acc: 1.0)
[2024-11-29 03:19:05,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:05,742][root][INFO] - Training Epoch: 6/10, step 413/574 completed (loss: 0.13821132481098175, acc: 0.9696969985961914)
[2024-11-29 03:19:05,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:05,988][root][INFO] - Training Epoch: 6/10, step 414/574 completed (loss: 0.06855800747871399, acc: 1.0)
[2024-11-29 03:19:06,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:06,233][root][INFO] - Training Epoch: 6/10, step 415/574 completed (loss: 0.5081133842468262, acc: 0.8039215803146362)
[2024-11-29 03:19:06,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:06,423][root][INFO] - Training Epoch: 6/10, step 416/574 completed (loss: 0.03146598860621452, acc: 1.0)
[2024-11-29 03:19:06,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:06,671][root][INFO] - Training Epoch: 6/10, step 417/574 completed (loss: 0.08175618201494217, acc: 1.0)
[2024-11-29 03:19:06,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:06,925][root][INFO] - Training Epoch: 6/10, step 418/574 completed (loss: 0.24638691544532776, acc: 0.949999988079071)
[2024-11-29 03:19:07,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:07,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:08,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:08,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:08,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:08,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:09,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:09,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:09,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:10,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:10,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:10,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:11,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:11,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:11,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:12,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:12,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:12,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:12,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:13,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:13,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:13,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:14,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:14,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:14,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:14,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:15,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:15,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:15,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:15,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:16,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:16,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:16,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:16,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:17,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:17,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:17,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:17,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:18,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:18,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:18,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:18,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:19,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:19,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:19,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:20,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:20,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:20,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:20,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:21,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:21,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:21,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:22,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:22,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:22,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:22,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:23,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:23,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:23,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:24,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:24,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:24,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:25,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:25,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:25,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:25,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:26,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:26,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:26,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:27,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:27,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:27,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:28,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:28,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:28,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:29,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:29,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:29,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:30,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:30,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:30,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:30,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:31,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:31,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:31,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:32,496][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.9764, device='cuda:0') eval_epoch_loss=tensor(1.0907, device='cuda:0') eval_epoch_acc=tensor(0.7473, device='cuda:0')
[2024-11-29 03:19:32,497][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:19:32,498][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:19:32,679][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_6_step_419_loss_1.0907294750213623/model.pt
[2024-11-29 03:19:32,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:32,948][root][INFO] - Training Epoch: 6/10, step 419/574 completed (loss: 0.3572201132774353, acc: 0.8999999761581421)
[2024-11-29 03:19:33,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:33,181][root][INFO] - Training Epoch: 6/10, step 420/574 completed (loss: 0.07249501347541809, acc: 0.9523809552192688)
[2024-11-29 03:19:33,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:33,456][root][INFO] - Training Epoch: 6/10, step 421/574 completed (loss: 0.1403236836194992, acc: 0.9666666388511658)
[2024-11-29 03:19:33,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:33,697][root][INFO] - Training Epoch: 6/10, step 422/574 completed (loss: 0.3766557574272156, acc: 0.90625)
[2024-11-29 03:19:33,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:33,953][root][INFO] - Training Epoch: 6/10, step 423/574 completed (loss: 0.13152094185352325, acc: 0.9444444179534912)
[2024-11-29 03:19:34,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:34,209][root][INFO] - Training Epoch: 6/10, step 424/574 completed (loss: 0.25693050026893616, acc: 0.9259259104728699)
[2024-11-29 03:19:34,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:34,465][root][INFO] - Training Epoch: 6/10, step 425/574 completed (loss: 0.14341062307357788, acc: 0.939393937587738)
[2024-11-29 03:19:34,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:34,700][root][INFO] - Training Epoch: 6/10, step 426/574 completed (loss: 0.05277157947421074, acc: 1.0)
[2024-11-29 03:19:34,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:34,957][root][INFO] - Training Epoch: 6/10, step 427/574 completed (loss: 0.10690128058195114, acc: 1.0)
[2024-11-29 03:19:35,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:35,204][root][INFO] - Training Epoch: 6/10, step 428/574 completed (loss: 0.14846953749656677, acc: 1.0)
[2024-11-29 03:19:35,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:35,449][root][INFO] - Training Epoch: 6/10, step 429/574 completed (loss: 0.01190919615328312, acc: 1.0)
[2024-11-29 03:19:35,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:35,682][root][INFO] - Training Epoch: 6/10, step 430/574 completed (loss: 0.024155739694833755, acc: 1.0)
[2024-11-29 03:19:35,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:35,935][root][INFO] - Training Epoch: 6/10, step 431/574 completed (loss: 0.14958198368549347, acc: 0.9629629850387573)
[2024-11-29 03:19:36,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:36,182][root][INFO] - Training Epoch: 6/10, step 432/574 completed (loss: 0.07160407304763794, acc: 1.0)
[2024-11-29 03:19:36,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:36,530][root][INFO] - Training Epoch: 6/10, step 433/574 completed (loss: 0.14604206383228302, acc: 0.9444444179534912)
[2024-11-29 03:19:36,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:36,754][root][INFO] - Training Epoch: 6/10, step 434/574 completed (loss: 0.016753610223531723, acc: 1.0)
[2024-11-29 03:19:36,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:36,990][root][INFO] - Training Epoch: 6/10, step 435/574 completed (loss: 0.014397114515304565, acc: 1.0)
[2024-11-29 03:19:37,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:37,247][root][INFO] - Training Epoch: 6/10, step 436/574 completed (loss: 0.15521079301834106, acc: 0.9444444179534912)
[2024-11-29 03:19:37,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:37,512][root][INFO] - Training Epoch: 6/10, step 437/574 completed (loss: 0.1661316305398941, acc: 0.9545454382896423)
[2024-11-29 03:19:37,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:37,754][root][INFO] - Training Epoch: 6/10, step 438/574 completed (loss: 0.0506385900080204, acc: 0.9523809552192688)
[2024-11-29 03:19:37,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:37,993][root][INFO] - Training Epoch: 6/10, step 439/574 completed (loss: 0.15182895958423615, acc: 0.9230769276618958)
[2024-11-29 03:19:38,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:38,396][root][INFO] - Training Epoch: 6/10, step 440/574 completed (loss: 0.2984130382537842, acc: 0.8787878751754761)
[2024-11-29 03:19:38,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:39,059][root][INFO] - Training Epoch: 6/10, step 441/574 completed (loss: 0.8358516097068787, acc: 0.7200000286102295)
[2024-11-29 03:19:39,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:39,369][root][INFO] - Training Epoch: 6/10, step 442/574 completed (loss: 0.8207458853721619, acc: 0.7338709831237793)
[2024-11-29 03:19:39,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:39,982][root][INFO] - Training Epoch: 6/10, step 443/574 completed (loss: 0.616723358631134, acc: 0.8258706331253052)
[2024-11-29 03:19:40,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:40,190][root][INFO] - Training Epoch: 6/10, step 444/574 completed (loss: 0.05451507121324539, acc: 1.0)
[2024-11-29 03:19:40,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:40,533][root][INFO] - Training Epoch: 6/10, step 445/574 completed (loss: 0.06137549504637718, acc: 0.9772727489471436)
[2024-11-29 03:19:40,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:40,760][root][INFO] - Training Epoch: 6/10, step 446/574 completed (loss: 0.34438782930374146, acc: 0.8695651888847351)
[2024-11-29 03:19:40,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:41,008][root][INFO] - Training Epoch: 6/10, step 447/574 completed (loss: 0.16378124058246613, acc: 0.9615384340286255)
[2024-11-29 03:19:41,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:41,268][root][INFO] - Training Epoch: 6/10, step 448/574 completed (loss: 0.026075497269630432, acc: 1.0)
[2024-11-29 03:19:41,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:41,513][root][INFO] - Training Epoch: 6/10, step 449/574 completed (loss: 0.1610066443681717, acc: 0.9701492786407471)
[2024-11-29 03:19:41,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:41,779][root][INFO] - Training Epoch: 6/10, step 450/574 completed (loss: 0.09246586263179779, acc: 0.9583333134651184)
[2024-11-29 03:19:41,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:42,060][root][INFO] - Training Epoch: 6/10, step 451/574 completed (loss: 0.2112017571926117, acc: 0.95652174949646)
[2024-11-29 03:19:42,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:42,346][root][INFO] - Training Epoch: 6/10, step 452/574 completed (loss: 0.19652137160301208, acc: 0.9358974099159241)
[2024-11-29 03:19:42,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:42,553][root][INFO] - Training Epoch: 6/10, step 453/574 completed (loss: 0.35756948590278625, acc: 0.8947368264198303)
[2024-11-29 03:19:42,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:42,788][root][INFO] - Training Epoch: 6/10, step 454/574 completed (loss: 0.06817732751369476, acc: 0.9795918464660645)
[2024-11-29 03:19:42,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:43,022][root][INFO] - Training Epoch: 6/10, step 455/574 completed (loss: 0.15734252333641052, acc: 0.9696969985961914)
[2024-11-29 03:19:43,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:43,291][root][INFO] - Training Epoch: 6/10, step 456/574 completed (loss: 0.6787149310112, acc: 0.8659793734550476)
[2024-11-29 03:19:43,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:43,551][root][INFO] - Training Epoch: 6/10, step 457/574 completed (loss: 0.08074737340211868, acc: 0.9857142567634583)
[2024-11-29 03:19:43,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:43,891][root][INFO] - Training Epoch: 6/10, step 458/574 completed (loss: 0.5534495711326599, acc: 0.8430232405662537)
[2024-11-29 03:19:43,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:44,134][root][INFO] - Training Epoch: 6/10, step 459/574 completed (loss: 0.15358510613441467, acc: 0.9642857313156128)
[2024-11-29 03:19:44,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:44,349][root][INFO] - Training Epoch: 6/10, step 460/574 completed (loss: 0.3734491765499115, acc: 0.8641975522041321)
[2024-11-29 03:19:44,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:44,592][root][INFO] - Training Epoch: 6/10, step 461/574 completed (loss: 0.1011013314127922, acc: 0.9722222089767456)
[2024-11-29 03:19:44,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:44,840][root][INFO] - Training Epoch: 6/10, step 462/574 completed (loss: 0.059283189475536346, acc: 1.0)
[2024-11-29 03:19:44,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:45,099][root][INFO] - Training Epoch: 6/10, step 463/574 completed (loss: 0.18005147576332092, acc: 0.9615384340286255)
[2024-11-29 03:19:45,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:45,324][root][INFO] - Training Epoch: 6/10, step 464/574 completed (loss: 0.47206592559814453, acc: 0.8913043737411499)
[2024-11-29 03:19:45,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:45,550][root][INFO] - Training Epoch: 6/10, step 465/574 completed (loss: 0.2940840423107147, acc: 0.9047619104385376)
[2024-11-29 03:19:45,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:45,782][root][INFO] - Training Epoch: 6/10, step 466/574 completed (loss: 0.8069566488265991, acc: 0.8072289228439331)
[2024-11-29 03:19:45,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:46,048][root][INFO] - Training Epoch: 6/10, step 467/574 completed (loss: 0.2209903746843338, acc: 0.9369369149208069)
[2024-11-29 03:19:46,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:46,293][root][INFO] - Training Epoch: 6/10, step 468/574 completed (loss: 0.7685428857803345, acc: 0.7961165308952332)
[2024-11-29 03:19:46,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:46,518][root][INFO] - Training Epoch: 6/10, step 469/574 completed (loss: 0.7477012276649475, acc: 0.8292682766914368)
[2024-11-29 03:19:46,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:46,704][root][INFO] - Training Epoch: 6/10, step 470/574 completed (loss: 0.2055341750383377, acc: 0.9583333134651184)
[2024-11-29 03:19:46,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:46,963][root][INFO] - Training Epoch: 6/10, step 471/574 completed (loss: 0.07220586389303207, acc: 1.0)
[2024-11-29 03:19:47,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:47,342][root][INFO] - Training Epoch: 6/10, step 472/574 completed (loss: 0.597028911113739, acc: 0.813725471496582)
[2024-11-29 03:19:47,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:47,646][root][INFO] - Training Epoch: 6/10, step 473/574 completed (loss: 0.9864601492881775, acc: 0.7117903828620911)
[2024-11-29 03:19:47,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:47,907][root][INFO] - Training Epoch: 6/10, step 474/574 completed (loss: 0.6624180674552917, acc: 0.75)
[2024-11-29 03:19:48,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:48,152][root][INFO] - Training Epoch: 6/10, step 475/574 completed (loss: 0.3754662573337555, acc: 0.8895705342292786)
[2024-11-29 03:19:48,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:48,408][root][INFO] - Training Epoch: 6/10, step 476/574 completed (loss: 0.4279899001121521, acc: 0.8776978254318237)
[2024-11-29 03:19:48,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:48,669][root][INFO] - Training Epoch: 6/10, step 477/574 completed (loss: 0.7914043664932251, acc: 0.7788944840431213)
[2024-11-29 03:19:48,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:48,884][root][INFO] - Training Epoch: 6/10, step 478/574 completed (loss: 0.27159932255744934, acc: 0.9166666865348816)
[2024-11-29 03:19:48,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:49,128][root][INFO] - Training Epoch: 6/10, step 479/574 completed (loss: 0.16533754765987396, acc: 0.9696969985961914)
[2024-11-29 03:19:49,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:49,370][root][INFO] - Training Epoch: 6/10, step 480/574 completed (loss: 0.24271443486213684, acc: 0.9259259104728699)
[2024-11-29 03:19:49,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:49,629][root][INFO] - Training Epoch: 6/10, step 481/574 completed (loss: 0.6401277780532837, acc: 0.75)
[2024-11-29 03:19:49,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:49,880][root][INFO] - Training Epoch: 6/10, step 482/574 completed (loss: 0.7845200300216675, acc: 0.8500000238418579)
[2024-11-29 03:19:50,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:50,172][root][INFO] - Training Epoch: 6/10, step 483/574 completed (loss: 0.6642258763313293, acc: 0.8275862336158752)
[2024-11-29 03:19:50,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:50,419][root][INFO] - Training Epoch: 6/10, step 484/574 completed (loss: 0.11389778554439545, acc: 0.9677419066429138)
[2024-11-29 03:19:50,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:50,654][root][INFO] - Training Epoch: 6/10, step 485/574 completed (loss: 0.09205020219087601, acc: 0.9473684430122375)
[2024-11-29 03:19:50,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:50,888][root][INFO] - Training Epoch: 6/10, step 486/574 completed (loss: 0.5578912496566772, acc: 0.7777777910232544)
[2024-11-29 03:19:51,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:51,125][root][INFO] - Training Epoch: 6/10, step 487/574 completed (loss: 0.6901045441627502, acc: 0.8571428656578064)
[2024-11-29 03:19:51,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:51,383][root][INFO] - Training Epoch: 6/10, step 488/574 completed (loss: 0.35315752029418945, acc: 0.9090909361839294)
[2024-11-29 03:19:51,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:51,655][root][INFO] - Training Epoch: 6/10, step 489/574 completed (loss: 0.9819469451904297, acc: 0.7076923251152039)
[2024-11-29 03:19:51,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:51,909][root][INFO] - Training Epoch: 6/10, step 490/574 completed (loss: 0.06158607080578804, acc: 1.0)
[2024-11-29 03:19:52,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:52,190][root][INFO] - Training Epoch: 6/10, step 491/574 completed (loss: 0.28648683428764343, acc: 0.931034505367279)
[2024-11-29 03:19:52,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:52,433][root][INFO] - Training Epoch: 6/10, step 492/574 completed (loss: 0.22543907165527344, acc: 0.9411764740943909)
[2024-11-29 03:19:52,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:52,671][root][INFO] - Training Epoch: 6/10, step 493/574 completed (loss: 0.15249377489089966, acc: 1.0)
[2024-11-29 03:19:52,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:52,909][root][INFO] - Training Epoch: 6/10, step 494/574 completed (loss: 0.3384285867214203, acc: 0.9473684430122375)
[2024-11-29 03:19:53,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:53,173][root][INFO] - Training Epoch: 6/10, step 495/574 completed (loss: 0.11433520168066025, acc: 1.0)
[2024-11-29 03:19:53,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:53,439][root][INFO] - Training Epoch: 6/10, step 496/574 completed (loss: 0.7711992859840393, acc: 0.8125)
[2024-11-29 03:19:53,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:53,733][root][INFO] - Training Epoch: 6/10, step 497/574 completed (loss: 0.31392666697502136, acc: 0.8876404762268066)
[2024-11-29 03:19:53,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:54,034][root][INFO] - Training Epoch: 6/10, step 498/574 completed (loss: 0.5700258612632751, acc: 0.8426966071128845)
[2024-11-29 03:19:54,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:54,278][root][INFO] - Training Epoch: 6/10, step 499/574 completed (loss: 1.2436960935592651, acc: 0.6453900933265686)
[2024-11-29 03:19:54,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:54,510][root][INFO] - Training Epoch: 6/10, step 500/574 completed (loss: 0.5245712399482727, acc: 0.8478260636329651)
[2024-11-29 03:19:54,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:54,745][root][INFO] - Training Epoch: 6/10, step 501/574 completed (loss: 0.14695942401885986, acc: 0.8799999952316284)
[2024-11-29 03:19:54,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:54,992][root][INFO] - Training Epoch: 6/10, step 502/574 completed (loss: 0.024657409638166428, acc: 1.0)
[2024-11-29 03:19:55,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:55,255][root][INFO] - Training Epoch: 6/10, step 503/574 completed (loss: 0.3429323434829712, acc: 0.8518518805503845)
[2024-11-29 03:19:55,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:55,505][root][INFO] - Training Epoch: 6/10, step 504/574 completed (loss: 0.023600297048687935, acc: 1.0)
[2024-11-29 03:19:55,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:55,745][root][INFO] - Training Epoch: 6/10, step 505/574 completed (loss: 0.7706646919250488, acc: 0.7735849022865295)
[2024-11-29 03:19:55,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:55,991][root][INFO] - Training Epoch: 6/10, step 506/574 completed (loss: 1.0537683963775635, acc: 0.7241379022598267)
[2024-11-29 03:19:56,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:56,532][root][INFO] - Training Epoch: 6/10, step 507/574 completed (loss: 1.1587778329849243, acc: 0.7027027010917664)
[2024-11-29 03:19:56,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:56,875][root][INFO] - Training Epoch: 6/10, step 508/574 completed (loss: 0.7185299396514893, acc: 0.8732394576072693)
[2024-11-29 03:19:56,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:57,110][root][INFO] - Training Epoch: 6/10, step 509/574 completed (loss: 0.34237322211265564, acc: 0.8999999761581421)
[2024-11-29 03:19:57,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:57,393][root][INFO] - Training Epoch: 6/10, step 510/574 completed (loss: 0.17540158331394196, acc: 0.9333333373069763)
[2024-11-29 03:19:57,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:57,694][root][INFO] - Training Epoch: 6/10, step 511/574 completed (loss: 0.13875176012516022, acc: 0.9615384340286255)
[2024-11-29 03:19:58,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:00,017][root][INFO] - Training Epoch: 6/10, step 512/574 completed (loss: 1.616811752319336, acc: 0.6071428656578064)
[2024-11-29 03:20:00,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:00,676][root][INFO] - Training Epoch: 6/10, step 513/574 completed (loss: 0.5212628245353699, acc: 0.8730158805847168)
[2024-11-29 03:20:00,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:00,930][root][INFO] - Training Epoch: 6/10, step 514/574 completed (loss: 0.6150633692741394, acc: 0.8214285969734192)
[2024-11-29 03:20:01,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:01,157][root][INFO] - Training Epoch: 6/10, step 515/574 completed (loss: 0.05621708184480667, acc: 1.0)
[2024-11-29 03:20:01,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:01,766][root][INFO] - Training Epoch: 6/10, step 516/574 completed (loss: 0.3842218816280365, acc: 0.8888888955116272)
[2024-11-29 03:20:01,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:02,003][root][INFO] - Training Epoch: 6/10, step 517/574 completed (loss: 0.00790715403854847, acc: 1.0)
[2024-11-29 03:20:02,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:02,225][root][INFO] - Training Epoch: 6/10, step 518/574 completed (loss: 0.05868404731154442, acc: 1.0)
[2024-11-29 03:20:02,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:02,477][root][INFO] - Training Epoch: 6/10, step 519/574 completed (loss: 0.262480229139328, acc: 0.8999999761581421)
[2024-11-29 03:20:02,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:02,731][root][INFO] - Training Epoch: 6/10, step 520/574 completed (loss: 0.7817296385765076, acc: 0.8148148059844971)
[2024-11-29 03:20:03,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:03,639][root][INFO] - Training Epoch: 6/10, step 521/574 completed (loss: 0.8164541125297546, acc: 0.7796609997749329)
[2024-11-29 03:20:03,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:03,897][root][INFO] - Training Epoch: 6/10, step 522/574 completed (loss: 0.39131975173950195, acc: 0.8805969953536987)
[2024-11-29 03:20:04,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:04,163][root][INFO] - Training Epoch: 6/10, step 523/574 completed (loss: 0.36481812596321106, acc: 0.9270073175430298)
[2024-11-29 03:20:04,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:04,662][root][INFO] - Training Epoch: 6/10, step 524/574 completed (loss: 0.7002326846122742, acc: 0.8100000023841858)
[2024-11-29 03:20:04,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:04,902][root][INFO] - Training Epoch: 6/10, step 525/574 completed (loss: 0.09385720640420914, acc: 0.9814814925193787)
[2024-11-29 03:20:05,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:05,161][root][INFO] - Training Epoch: 6/10, step 526/574 completed (loss: 0.06136724725365639, acc: 0.9807692170143127)
[2024-11-29 03:20:05,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:05,445][root][INFO] - Training Epoch: 6/10, step 527/574 completed (loss: 0.11937585473060608, acc: 1.0)
[2024-11-29 03:20:05,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:05,692][root][INFO] - Training Epoch: 6/10, step 528/574 completed (loss: 1.1274603605270386, acc: 0.688524603843689)
[2024-11-29 03:20:05,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:05,958][root][INFO] - Training Epoch: 6/10, step 529/574 completed (loss: 0.30279412865638733, acc: 0.9491525292396545)
[2024-11-29 03:20:06,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:06,149][root][INFO] - Training Epoch: 6/10, step 530/574 completed (loss: 1.3961507081985474, acc: 0.6744186282157898)
[2024-11-29 03:20:06,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:06,432][root][INFO] - Training Epoch: 6/10, step 531/574 completed (loss: 0.7055984735488892, acc: 0.7954545617103577)
[2024-11-29 03:20:06,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:06,679][root][INFO] - Training Epoch: 6/10, step 532/574 completed (loss: 1.087289810180664, acc: 0.7169811129570007)
[2024-11-29 03:20:06,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:06,938][root][INFO] - Training Epoch: 6/10, step 533/574 completed (loss: 0.4769962430000305, acc: 0.8863636255264282)
[2024-11-29 03:20:07,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:07,182][root][INFO] - Training Epoch: 6/10, step 534/574 completed (loss: 0.638918399810791, acc: 0.8399999737739563)
[2024-11-29 03:20:07,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:07,435][root][INFO] - Training Epoch: 6/10, step 535/574 completed (loss: 0.2531220316886902, acc: 0.8999999761581421)
[2024-11-29 03:20:07,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:07,708][root][INFO] - Training Epoch: 6/10, step 536/574 completed (loss: 0.06066884845495224, acc: 1.0)
[2024-11-29 03:20:07,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:08,020][root][INFO] - Training Epoch: 6/10, step 537/574 completed (loss: 0.4553544521331787, acc: 0.8615384697914124)
[2024-11-29 03:20:08,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:08,272][root][INFO] - Training Epoch: 6/10, step 538/574 completed (loss: 0.6070436835289001, acc: 0.8125)
[2024-11-29 03:20:08,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:08,565][root][INFO] - Training Epoch: 6/10, step 539/574 completed (loss: 0.4381881654262543, acc: 0.84375)
[2024-11-29 03:20:08,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:08,799][root][INFO] - Training Epoch: 6/10, step 540/574 completed (loss: 0.848447322845459, acc: 0.8181818127632141)
[2024-11-29 03:20:08,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:09,007][root][INFO] - Training Epoch: 6/10, step 541/574 completed (loss: 0.31553155183792114, acc: 0.9375)
[2024-11-29 03:20:09,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:09,238][root][INFO] - Training Epoch: 6/10, step 542/574 completed (loss: 0.03716239333152771, acc: 1.0)
[2024-11-29 03:20:09,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:09,462][root][INFO] - Training Epoch: 6/10, step 543/574 completed (loss: 0.007161249406635761, acc: 1.0)
[2024-11-29 03:20:09,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:09,675][root][INFO] - Training Epoch: 6/10, step 544/574 completed (loss: 0.03136647865176201, acc: 1.0)
[2024-11-29 03:20:09,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:09,932][root][INFO] - Training Epoch: 6/10, step 545/574 completed (loss: 0.07617013901472092, acc: 0.9756097793579102)
[2024-11-29 03:20:10,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:10,167][root][INFO] - Training Epoch: 6/10, step 546/574 completed (loss: 0.00861146580427885, acc: 1.0)
[2024-11-29 03:20:10,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:10,393][root][INFO] - Training Epoch: 6/10, step 547/574 completed (loss: 0.08579279482364655, acc: 0.9736841917037964)
[2024-11-29 03:20:10,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:10,625][root][INFO] - Training Epoch: 6/10, step 548/574 completed (loss: 0.022988643497228622, acc: 1.0)
[2024-11-29 03:20:10,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:10,831][root][INFO] - Training Epoch: 6/10, step 549/574 completed (loss: 0.06703247129917145, acc: 1.0)
[2024-11-29 03:20:10,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:11,105][root][INFO] - Training Epoch: 6/10, step 550/574 completed (loss: 0.1269339919090271, acc: 0.939393937587738)
[2024-11-29 03:20:11,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:11,329][root][INFO] - Training Epoch: 6/10, step 551/574 completed (loss: 0.13732227683067322, acc: 0.949999988079071)
[2024-11-29 03:20:11,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:11,568][root][INFO] - Training Epoch: 6/10, step 552/574 completed (loss: 0.09028352797031403, acc: 0.9857142567634583)
[2024-11-29 03:20:11,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:11,777][root][INFO] - Training Epoch: 6/10, step 553/574 completed (loss: 0.41245415806770325, acc: 0.9051094651222229)
[2024-11-29 03:20:11,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:12,042][root][INFO] - Training Epoch: 6/10, step 554/574 completed (loss: 0.25435149669647217, acc: 0.931034505367279)
[2024-11-29 03:20:12,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:12,321][root][INFO] - Training Epoch: 6/10, step 555/574 completed (loss: 0.4404911696910858, acc: 0.8928571343421936)
[2024-11-29 03:20:12,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:12,579][root][INFO] - Training Epoch: 6/10, step 556/574 completed (loss: 0.4585880637168884, acc: 0.8807947039604187)
[2024-11-29 03:20:12,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:12,803][root][INFO] - Training Epoch: 6/10, step 557/574 completed (loss: 0.19517651200294495, acc: 0.9230769276618958)
[2024-11-29 03:20:12,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:13,046][root][INFO] - Training Epoch: 6/10, step 558/574 completed (loss: 0.07321254909038544, acc: 0.9599999785423279)
[2024-11-29 03:20:13,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:13,279][root][INFO] - Training Epoch: 6/10, step 559/574 completed (loss: 0.06940711289644241, acc: 0.9615384340286255)
[2024-11-29 03:20:13,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:13,520][root][INFO] - Training Epoch: 6/10, step 560/574 completed (loss: 0.1989835947751999, acc: 0.8846153616905212)
[2024-11-29 03:20:13,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:13,755][root][INFO] - Training Epoch: 6/10, step 561/574 completed (loss: 0.42607927322387695, acc: 0.8974359035491943)
[2024-11-29 03:20:14,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:14,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:14,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:15,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:15,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:15,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:16,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:16,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:16,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:17,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:17,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:17,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:18,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:18,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:18,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:18,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:19,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:19,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:19,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:19,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:20,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:20,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:20,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:20,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:21,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:21,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:21,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:22,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:22,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:22,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:22,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:23,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:23,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:23,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:23,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:24,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:24,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:24,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:24,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:25,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:25,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:25,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:25,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:26,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:26,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:26,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:26,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:27,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:27,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:27,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:27,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:28,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:28,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:28,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:28,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:29,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:29,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:29,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:29,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:30,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:30,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:30,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:31,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:31,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:31,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:32,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:32,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:32,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:32,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:33,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:33,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:33,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:33,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:34,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:34,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:34,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:35,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:35,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:35,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:35,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:36,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:36,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:36,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:36,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:37,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:37,786][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.0901, device='cuda:0') eval_epoch_loss=tensor(1.1282, device='cuda:0') eval_epoch_acc=tensor(0.7446, device='cuda:0')
[2024-11-29 03:20:37,787][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:20:37,788][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:20:37,948][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_6_step_562_loss_1.1281994581222534/model.pt
[2024-11-29 03:20:38,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:38,229][root][INFO] - Training Epoch: 6/10, step 562/574 completed (loss: 0.5380739569664001, acc: 0.855555534362793)
[2024-11-29 03:20:38,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:38,467][root][INFO] - Training Epoch: 6/10, step 563/574 completed (loss: 0.5103228688240051, acc: 0.8571428656578064)
[2024-11-29 03:20:38,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:38,672][root][INFO] - Training Epoch: 6/10, step 564/574 completed (loss: 0.2418718934059143, acc: 0.8958333134651184)
[2024-11-29 03:20:38,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:38,924][root][INFO] - Training Epoch: 6/10, step 565/574 completed (loss: 0.25504666566848755, acc: 0.931034505367279)
[2024-11-29 03:20:39,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:39,157][root][INFO] - Training Epoch: 6/10, step 566/574 completed (loss: 0.33560681343078613, acc: 0.9047619104385376)
[2024-11-29 03:20:39,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:39,346][root][INFO] - Training Epoch: 6/10, step 567/574 completed (loss: 0.0655888095498085, acc: 0.9736841917037964)
[2024-11-29 03:20:39,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:39,596][root][INFO] - Training Epoch: 6/10, step 568/574 completed (loss: 0.028476491570472717, acc: 1.0)
[2024-11-29 03:20:39,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:39,896][root][INFO] - Training Epoch: 6/10, step 569/574 completed (loss: 0.38832762837409973, acc: 0.8983957171440125)
[2024-11-29 03:20:39,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:40,099][root][INFO] - Training Epoch: 6/10, step 570/574 completed (loss: 0.02634168602526188, acc: 1.0)
[2024-11-29 03:20:40,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:40,371][root][INFO] - Training Epoch: 6/10, step 571/574 completed (loss: 0.41164758801460266, acc: 0.9230769276618958)
[2024-11-29 03:20:40,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:40,616][root][INFO] - Training Epoch: 6/10, step 572/574 completed (loss: 0.6659603714942932, acc: 0.8163265585899353)
[2024-11-29 03:20:40,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:40,869][root][INFO] - Training Epoch: 6/10, step 573/574 completed (loss: 0.5193602442741394, acc: 0.8616352081298828)
[2024-11-29 03:20:41,359][slam_llm.utils.train_utils][INFO] - Epoch 6: train_perplexity=1.5856, train_epoch_loss=0.4610, epoch time 271.3522651921958s
[2024-11-29 03:20:41,359][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 11 GB
[2024-11-29 03:20:41,359][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 21 GB
[2024-11-29 03:20:41,359][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 11 GB
[2024-11-29 03:20:41,359][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 9
[2024-11-29 03:20:41,359][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:20:41,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:42,038][root][INFO] - Training Epoch: 7/10, step 0/574 completed (loss: 0.1451677680015564, acc: 0.9629629850387573)
[2024-11-29 03:20:42,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:42,254][root][INFO] - Training Epoch: 7/10, step 1/574 completed (loss: 0.03614751994609833, acc: 1.0)
[2024-11-29 03:20:42,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:42,451][root][INFO] - Training Epoch: 7/10, step 2/574 completed (loss: 0.3003697097301483, acc: 0.8918918967247009)
[2024-11-29 03:20:42,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:42,699][root][INFO] - Training Epoch: 7/10, step 3/574 completed (loss: 0.278876394033432, acc: 0.9210526347160339)
[2024-11-29 03:20:42,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:42,942][root][INFO] - Training Epoch: 7/10, step 4/574 completed (loss: 0.17818039655685425, acc: 0.9459459185600281)
[2024-11-29 03:20:43,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:43,188][root][INFO] - Training Epoch: 7/10, step 5/574 completed (loss: 0.12439574301242828, acc: 0.9642857313156128)
[2024-11-29 03:20:43,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:43,431][root][INFO] - Training Epoch: 7/10, step 6/574 completed (loss: 0.3808007538318634, acc: 0.8775510191917419)
[2024-11-29 03:20:43,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:43,670][root][INFO] - Training Epoch: 7/10, step 7/574 completed (loss: 0.11580173671245575, acc: 0.9666666388511658)
[2024-11-29 03:20:43,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:43,904][root][INFO] - Training Epoch: 7/10, step 8/574 completed (loss: 0.015014469623565674, acc: 1.0)
[2024-11-29 03:20:44,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:44,148][root][INFO] - Training Epoch: 7/10, step 9/574 completed (loss: 0.014184365049004555, acc: 1.0)
[2024-11-29 03:20:44,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:44,391][root][INFO] - Training Epoch: 7/10, step 10/574 completed (loss: 0.02100350707769394, acc: 1.0)
[2024-11-29 03:20:44,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:44,638][root][INFO] - Training Epoch: 7/10, step 11/574 completed (loss: 0.16910484433174133, acc: 0.9230769276618958)
[2024-11-29 03:20:44,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:44,868][root][INFO] - Training Epoch: 7/10, step 12/574 completed (loss: 0.01881554163992405, acc: 1.0)
[2024-11-29 03:20:44,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:45,080][root][INFO] - Training Epoch: 7/10, step 13/574 completed (loss: 0.177577406167984, acc: 0.9347826242446899)
[2024-11-29 03:20:45,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:45,288][root][INFO] - Training Epoch: 7/10, step 14/574 completed (loss: 0.08983825147151947, acc: 0.9607843160629272)
[2024-11-29 03:20:45,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:45,506][root][INFO] - Training Epoch: 7/10, step 15/574 completed (loss: 0.10516996681690216, acc: 0.9591836929321289)
[2024-11-29 03:20:45,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:45,736][root][INFO] - Training Epoch: 7/10, step 16/574 completed (loss: 0.013361157849431038, acc: 1.0)
[2024-11-29 03:20:45,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:45,972][root][INFO] - Training Epoch: 7/10, step 17/574 completed (loss: 0.03822866082191467, acc: 1.0)
[2024-11-29 03:20:46,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:46,194][root][INFO] - Training Epoch: 7/10, step 18/574 completed (loss: 0.28651607036590576, acc: 0.8888888955116272)
[2024-11-29 03:20:46,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:46,428][root][INFO] - Training Epoch: 7/10, step 19/574 completed (loss: 0.08231882005929947, acc: 1.0)
[2024-11-29 03:20:46,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:46,653][root][INFO] - Training Epoch: 7/10, step 20/574 completed (loss: 0.05895053595304489, acc: 0.9615384340286255)
[2024-11-29 03:20:46,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:46,879][root][INFO] - Training Epoch: 7/10, step 21/574 completed (loss: 0.29037705063819885, acc: 0.931034505367279)
[2024-11-29 03:20:46,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:47,122][root][INFO] - Training Epoch: 7/10, step 22/574 completed (loss: 0.03297341242432594, acc: 1.0)
[2024-11-29 03:20:47,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:47,383][root][INFO] - Training Epoch: 7/10, step 23/574 completed (loss: 0.030260812491178513, acc: 1.0)
[2024-11-29 03:20:47,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:47,633][root][INFO] - Training Epoch: 7/10, step 24/574 completed (loss: 0.01860729604959488, acc: 1.0)
[2024-11-29 03:20:47,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:47,847][root][INFO] - Training Epoch: 7/10, step 25/574 completed (loss: 0.36970359086990356, acc: 0.8867924809455872)
[2024-11-29 03:20:47,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:48,012][root][INFO] - Training Epoch: 7/10, step 26/574 completed (loss: 0.6088419556617737, acc: 0.8219178318977356)
[2024-11-29 03:20:48,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:49,134][root][INFO] - Training Epoch: 7/10, step 27/574 completed (loss: 1.3098992109298706, acc: 0.687747061252594)
[2024-11-29 03:20:49,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:49,300][root][INFO] - Training Epoch: 7/10, step 28/574 completed (loss: 0.2551972568035126, acc: 0.930232584476471)
[2024-11-29 03:20:49,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:49,505][root][INFO] - Training Epoch: 7/10, step 29/574 completed (loss: 0.4288046061992645, acc: 0.891566276550293)
[2024-11-29 03:20:49,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:49,731][root][INFO] - Training Epoch: 7/10, step 30/574 completed (loss: 0.7374590635299683, acc: 0.8271604776382446)
[2024-11-29 03:20:49,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:49,989][root][INFO] - Training Epoch: 7/10, step 31/574 completed (loss: 0.18551282584667206, acc: 0.9642857313156128)
[2024-11-29 03:20:50,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:50,245][root][INFO] - Training Epoch: 7/10, step 32/574 completed (loss: 0.016379252076148987, acc: 1.0)
[2024-11-29 03:20:50,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:50,476][root][INFO] - Training Epoch: 7/10, step 33/574 completed (loss: 0.007501703221350908, acc: 1.0)
[2024-11-29 03:20:50,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:50,725][root][INFO] - Training Epoch: 7/10, step 34/574 completed (loss: 0.5284284353256226, acc: 0.8655462265014648)
[2024-11-29 03:20:50,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:50,962][root][INFO] - Training Epoch: 7/10, step 35/574 completed (loss: 0.2434282898902893, acc: 0.9344262480735779)
[2024-11-29 03:20:51,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:51,209][root][INFO] - Training Epoch: 7/10, step 36/574 completed (loss: 0.43281131982803345, acc: 0.841269850730896)
[2024-11-29 03:20:51,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:51,457][root][INFO] - Training Epoch: 7/10, step 37/574 completed (loss: 0.36408311128616333, acc: 0.8983050584793091)
[2024-11-29 03:20:51,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:51,739][root][INFO] - Training Epoch: 7/10, step 38/574 completed (loss: 0.3715955913066864, acc: 0.8965517282485962)
[2024-11-29 03:20:51,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:52,024][root][INFO] - Training Epoch: 7/10, step 39/574 completed (loss: 0.3597959578037262, acc: 0.9047619104385376)
[2024-11-29 03:20:52,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:52,287][root][INFO] - Training Epoch: 7/10, step 40/574 completed (loss: 0.3282608985900879, acc: 0.8846153616905212)
[2024-11-29 03:20:52,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:52,564][root][INFO] - Training Epoch: 7/10, step 41/574 completed (loss: 0.14616242051124573, acc: 0.9594594836235046)
[2024-11-29 03:20:52,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:52,810][root][INFO] - Training Epoch: 7/10, step 42/574 completed (loss: 0.5733711123466492, acc: 0.8461538553237915)
[2024-11-29 03:20:52,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:53,128][root][INFO] - Training Epoch: 7/10, step 43/574 completed (loss: 0.5739647746086121, acc: 0.8282828330993652)
[2024-11-29 03:20:53,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:53,433][root][INFO] - Training Epoch: 7/10, step 44/574 completed (loss: 0.4719630777835846, acc: 0.8659793734550476)
[2024-11-29 03:20:53,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:53,720][root][INFO] - Training Epoch: 7/10, step 45/574 completed (loss: 0.6387431621551514, acc: 0.8235294222831726)
[2024-11-29 03:20:53,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:53,941][root][INFO] - Training Epoch: 7/10, step 46/574 completed (loss: 0.028926907107234, acc: 1.0)
[2024-11-29 03:20:54,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:54,168][root][INFO] - Training Epoch: 7/10, step 47/574 completed (loss: 0.01695285364985466, acc: 1.0)
[2024-11-29 03:20:54,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:54,393][root][INFO] - Training Epoch: 7/10, step 48/574 completed (loss: 0.07081251591444016, acc: 1.0)
[2024-11-29 03:20:54,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:54,635][root][INFO] - Training Epoch: 7/10, step 49/574 completed (loss: 0.12355205416679382, acc: 0.9722222089767456)
[2024-11-29 03:20:54,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:54,894][root][INFO] - Training Epoch: 7/10, step 50/574 completed (loss: 0.5307552218437195, acc: 0.8245614171028137)
[2024-11-29 03:20:55,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:55,174][root][INFO] - Training Epoch: 7/10, step 51/574 completed (loss: 0.3588027060031891, acc: 0.8730158805847168)
[2024-11-29 03:20:55,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:55,397][root][INFO] - Training Epoch: 7/10, step 52/574 completed (loss: 0.6098681688308716, acc: 0.8309859037399292)
[2024-11-29 03:20:55,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:55,779][root][INFO] - Training Epoch: 7/10, step 53/574 completed (loss: 1.474794864654541, acc: 0.6066666841506958)
[2024-11-29 03:20:55,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:55,996][root][INFO] - Training Epoch: 7/10, step 54/574 completed (loss: 0.4412815570831299, acc: 0.8648648858070374)
[2024-11-29 03:20:56,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:56,249][root][INFO] - Training Epoch: 7/10, step 55/574 completed (loss: 0.04930752143263817, acc: 0.9615384340286255)
[2024-11-29 03:20:57,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:58,778][root][INFO] - Training Epoch: 7/10, step 56/574 completed (loss: 1.2776460647583008, acc: 0.6348122954368591)
[2024-11-29 03:20:59,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:59,966][root][INFO] - Training Epoch: 7/10, step 57/574 completed (loss: 1.5065581798553467, acc: 0.6209150552749634)
[2024-11-29 03:21:00,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:00,486][root][INFO] - Training Epoch: 7/10, step 58/574 completed (loss: 0.7452261447906494, acc: 0.7727272510528564)
[2024-11-29 03:21:00,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:00,960][root][INFO] - Training Epoch: 7/10, step 59/574 completed (loss: 0.3915250897407532, acc: 0.8602941036224365)
[2024-11-29 03:21:01,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:01,424][root][INFO] - Training Epoch: 7/10, step 60/574 completed (loss: 0.7904833555221558, acc: 0.7536231875419617)
[2024-11-29 03:21:01,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:01,743][root][INFO] - Training Epoch: 7/10, step 61/574 completed (loss: 0.7199931144714355, acc: 0.7875000238418579)
[2024-11-29 03:21:01,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:01,924][root][INFO] - Training Epoch: 7/10, step 62/574 completed (loss: 0.08396746963262558, acc: 0.970588207244873)
[2024-11-29 03:21:02,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:02,122][root][INFO] - Training Epoch: 7/10, step 63/574 completed (loss: 0.11587852984666824, acc: 0.9444444179534912)
[2024-11-29 03:21:02,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:02,374][root][INFO] - Training Epoch: 7/10, step 64/574 completed (loss: 0.049084682017564774, acc: 1.0)
[2024-11-29 03:21:02,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:02,645][root][INFO] - Training Epoch: 7/10, step 65/574 completed (loss: 0.07137452811002731, acc: 0.9655172228813171)
[2024-11-29 03:21:02,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:02,884][root][INFO] - Training Epoch: 7/10, step 66/574 completed (loss: 0.4928138852119446, acc: 0.8571428656578064)
[2024-11-29 03:21:02,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:03,124][root][INFO] - Training Epoch: 7/10, step 67/574 completed (loss: 0.21645332872867584, acc: 0.9166666865348816)
[2024-11-29 03:21:03,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:03,364][root][INFO] - Training Epoch: 7/10, step 68/574 completed (loss: 0.00826939195394516, acc: 1.0)
[2024-11-29 03:21:03,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:03,605][root][INFO] - Training Epoch: 7/10, step 69/574 completed (loss: 0.4464923143386841, acc: 0.8611111044883728)
[2024-11-29 03:21:03,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:03,858][root][INFO] - Training Epoch: 7/10, step 70/574 completed (loss: 0.30096253752708435, acc: 0.9696969985961914)
[2024-11-29 03:21:03,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:04,095][root][INFO] - Training Epoch: 7/10, step 71/574 completed (loss: 0.9928238987922668, acc: 0.7132353186607361)
[2024-11-29 03:21:04,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:04,322][root][INFO] - Training Epoch: 7/10, step 72/574 completed (loss: 0.5922544598579407, acc: 0.841269850730896)
[2024-11-29 03:21:04,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:04,565][root][INFO] - Training Epoch: 7/10, step 73/574 completed (loss: 1.4655327796936035, acc: 0.620512843132019)
[2024-11-29 03:21:04,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:04,761][root][INFO] - Training Epoch: 7/10, step 74/574 completed (loss: 0.7454499006271362, acc: 0.7653061151504517)
[2024-11-29 03:21:04,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:05,018][root][INFO] - Training Epoch: 7/10, step 75/574 completed (loss: 1.0779011249542236, acc: 0.6865671873092651)
[2024-11-29 03:21:05,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:05,326][root][INFO] - Training Epoch: 7/10, step 76/574 completed (loss: 1.6581194400787354, acc: 0.5656934380531311)
[2024-11-29 03:21:05,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:05,537][root][INFO] - Training Epoch: 7/10, step 77/574 completed (loss: 0.0066179027780890465, acc: 1.0)
[2024-11-29 03:21:05,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:05,756][root][INFO] - Training Epoch: 7/10, step 78/574 completed (loss: 0.025846848264336586, acc: 1.0)
[2024-11-29 03:21:05,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:05,976][root][INFO] - Training Epoch: 7/10, step 79/574 completed (loss: 0.08282186836004257, acc: 0.9696969985961914)
[2024-11-29 03:21:06,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:06,204][root][INFO] - Training Epoch: 7/10, step 80/574 completed (loss: 0.016880201175808907, acc: 1.0)
[2024-11-29 03:21:06,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:06,439][root][INFO] - Training Epoch: 7/10, step 81/574 completed (loss: 0.2330510914325714, acc: 0.9230769276618958)
[2024-11-29 03:21:06,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:06,637][root][INFO] - Training Epoch: 7/10, step 82/574 completed (loss: 0.2395753711462021, acc: 0.9615384340286255)
[2024-11-29 03:21:06,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:06,884][root][INFO] - Training Epoch: 7/10, step 83/574 completed (loss: 0.10313372313976288, acc: 0.96875)
[2024-11-29 03:21:07,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:07,139][root][INFO] - Training Epoch: 7/10, step 84/574 completed (loss: 0.23340344429016113, acc: 0.95652174949646)
[2024-11-29 03:21:07,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:07,361][root][INFO] - Training Epoch: 7/10, step 85/574 completed (loss: 0.18091820180416107, acc: 0.9800000190734863)
[2024-11-29 03:21:07,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:07,621][root][INFO] - Training Epoch: 7/10, step 86/574 completed (loss: 0.09262759983539581, acc: 0.95652174949646)
[2024-11-29 03:21:07,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:07,996][root][INFO] - Training Epoch: 7/10, step 87/574 completed (loss: 1.0325489044189453, acc: 0.6800000071525574)
[2024-11-29 03:21:08,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:08,254][root][INFO] - Training Epoch: 7/10, step 88/574 completed (loss: 0.8439361453056335, acc: 0.8155339956283569)
[2024-11-29 03:21:08,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:09,284][root][INFO] - Training Epoch: 7/10, step 89/574 completed (loss: 0.9100334644317627, acc: 0.7572815418243408)
[2024-11-29 03:21:09,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:09,982][root][INFO] - Training Epoch: 7/10, step 90/574 completed (loss: 1.3642116785049438, acc: 0.6344085931777954)
[2024-11-29 03:21:10,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:10,669][root][INFO] - Training Epoch: 7/10, step 91/574 completed (loss: 1.0937817096710205, acc: 0.6982758641242981)
[2024-11-29 03:21:10,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:11,300][root][INFO] - Training Epoch: 7/10, step 92/574 completed (loss: 0.820641040802002, acc: 0.7894737124443054)
[2024-11-29 03:21:11,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:12,200][root][INFO] - Training Epoch: 7/10, step 93/574 completed (loss: 1.0553762912750244, acc: 0.6930692791938782)
[2024-11-29 03:21:12,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:12,419][root][INFO] - Training Epoch: 7/10, step 94/574 completed (loss: 0.8662703037261963, acc: 0.7580645084381104)
[2024-11-29 03:21:12,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:12,573][root][INFO] - Training Epoch: 7/10, step 95/574 completed (loss: 0.48734840750694275, acc: 0.8695651888847351)
[2024-11-29 03:21:12,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:12,786][root][INFO] - Training Epoch: 7/10, step 96/574 completed (loss: 1.0361979007720947, acc: 0.6554622054100037)
[2024-11-29 03:21:12,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:12,984][root][INFO] - Training Epoch: 7/10, step 97/574 completed (loss: 1.207810878753662, acc: 0.625)
[2024-11-29 03:21:13,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:13,253][root][INFO] - Training Epoch: 7/10, step 98/574 completed (loss: 1.3317376375198364, acc: 0.6788321137428284)
[2024-11-29 03:21:13,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:13,503][root][INFO] - Training Epoch: 7/10, step 99/574 completed (loss: 1.0464136600494385, acc: 0.7014925479888916)
[2024-11-29 03:21:13,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:13,760][root][INFO] - Training Epoch: 7/10, step 100/574 completed (loss: 0.1750236302614212, acc: 1.0)
[2024-11-29 03:21:13,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:14,033][root][INFO] - Training Epoch: 7/10, step 101/574 completed (loss: 0.0062448130920529366, acc: 1.0)
[2024-11-29 03:21:14,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:14,294][root][INFO] - Training Epoch: 7/10, step 102/574 completed (loss: 0.0057057528756558895, acc: 1.0)
[2024-11-29 03:21:14,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:14,526][root][INFO] - Training Epoch: 7/10, step 103/574 completed (loss: 0.04426803067326546, acc: 1.0)
[2024-11-29 03:21:14,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:14,764][root][INFO] - Training Epoch: 7/10, step 104/574 completed (loss: 0.45612800121307373, acc: 0.8793103694915771)
[2024-11-29 03:21:14,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:15,009][root][INFO] - Training Epoch: 7/10, step 105/574 completed (loss: 0.08917555958032608, acc: 0.9534883499145508)
[2024-11-29 03:21:15,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:15,248][root][INFO] - Training Epoch: 7/10, step 106/574 completed (loss: 0.06021144241094589, acc: 1.0)
[2024-11-29 03:21:15,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:15,478][root][INFO] - Training Epoch: 7/10, step 107/574 completed (loss: 0.010282653383910656, acc: 1.0)
[2024-11-29 03:21:15,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:15,669][root][INFO] - Training Epoch: 7/10, step 108/574 completed (loss: 0.0030482723377645016, acc: 1.0)
[2024-11-29 03:21:15,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:15,841][root][INFO] - Training Epoch: 7/10, step 109/574 completed (loss: 0.09836572408676147, acc: 0.9523809552192688)
[2024-11-29 03:21:15,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:16,047][root][INFO] - Training Epoch: 7/10, step 110/574 completed (loss: 0.13002194464206696, acc: 0.9538461565971375)
[2024-11-29 03:21:16,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:16,358][root][INFO] - Training Epoch: 7/10, step 111/574 completed (loss: 0.17731641232967377, acc: 0.9298245906829834)
[2024-11-29 03:21:16,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:16,606][root][INFO] - Training Epoch: 7/10, step 112/574 completed (loss: 0.4123733341693878, acc: 0.8771929740905762)
[2024-11-29 03:21:16,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:16,818][root][INFO] - Training Epoch: 7/10, step 113/574 completed (loss: 0.26029568910598755, acc: 0.9230769276618958)
[2024-11-29 03:21:16,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:17,064][root][INFO] - Training Epoch: 7/10, step 114/574 completed (loss: 0.18441350758075714, acc: 0.9387755393981934)
[2024-11-29 03:21:17,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:17,314][root][INFO] - Training Epoch: 7/10, step 115/574 completed (loss: 0.028854161500930786, acc: 1.0)
[2024-11-29 03:21:17,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:17,595][root][INFO] - Training Epoch: 7/10, step 116/574 completed (loss: 0.2673274874687195, acc: 0.920634925365448)
[2024-11-29 03:21:17,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:17,850][root][INFO] - Training Epoch: 7/10, step 117/574 completed (loss: 0.3825575113296509, acc: 0.9105691313743591)
[2024-11-29 03:21:17,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:18,126][root][INFO] - Training Epoch: 7/10, step 118/574 completed (loss: 0.09050461649894714, acc: 0.9838709831237793)
[2024-11-29 03:21:18,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:18,909][root][INFO] - Training Epoch: 7/10, step 119/574 completed (loss: 1.0320457220077515, acc: 0.7262357473373413)
[2024-11-29 03:21:19,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:19,161][root][INFO] - Training Epoch: 7/10, step 120/574 completed (loss: 0.27601373195648193, acc: 0.8933333158493042)
[2024-11-29 03:21:19,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:19,462][root][INFO] - Training Epoch: 7/10, step 121/574 completed (loss: 0.3645937144756317, acc: 0.9038461446762085)
[2024-11-29 03:21:19,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:19,673][root][INFO] - Training Epoch: 7/10, step 122/574 completed (loss: 0.06239071488380432, acc: 0.9583333134651184)
[2024-11-29 03:21:19,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:19,884][root][INFO] - Training Epoch: 7/10, step 123/574 completed (loss: 0.22284527122974396, acc: 0.9473684430122375)
[2024-11-29 03:21:20,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:20,124][root][INFO] - Training Epoch: 7/10, step 124/574 completed (loss: 1.172795057296753, acc: 0.6564416885375977)
[2024-11-29 03:21:20,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:20,364][root][INFO] - Training Epoch: 7/10, step 125/574 completed (loss: 1.156162977218628, acc: 0.7222222089767456)
[2024-11-29 03:21:20,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:20,632][root][INFO] - Training Epoch: 7/10, step 126/574 completed (loss: 0.8404725193977356, acc: 0.7583333253860474)
[2024-11-29 03:21:20,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:20,902][root][INFO] - Training Epoch: 7/10, step 127/574 completed (loss: 1.1896520853042603, acc: 0.6547619104385376)
[2024-11-29 03:21:21,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:21,166][root][INFO] - Training Epoch: 7/10, step 128/574 completed (loss: 1.0000505447387695, acc: 0.7538461685180664)
[2024-11-29 03:21:21,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:21,475][root][INFO] - Training Epoch: 7/10, step 129/574 completed (loss: 0.9163243770599365, acc: 0.75)
[2024-11-29 03:21:21,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:21,692][root][INFO] - Training Epoch: 7/10, step 130/574 completed (loss: 0.5784927010536194, acc: 0.7692307829856873)
[2024-11-29 03:21:22,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:22,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:23,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:23,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:23,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:23,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:24,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:24,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:24,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:24,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:25,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:25,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:25,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:26,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:26,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:26,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:26,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:27,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:27,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:27,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:27,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:28,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:28,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:28,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:28,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:29,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:29,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:29,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:29,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:29,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:30,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:30,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:30,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:31,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:31,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:31,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:31,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:32,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:32,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:32,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:33,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:33,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:33,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:33,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:34,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:34,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:34,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:35,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:35,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:35,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:35,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:36,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:36,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:36,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:36,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:37,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:37,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:37,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:37,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:38,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:38,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:38,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:38,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:39,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:39,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:39,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:39,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:40,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:40,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:40,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:41,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:41,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:41,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:41,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:42,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:42,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:42,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:43,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:43,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:43,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:43,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:44,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:44,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:44,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:44,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:45,413][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.0110, device='cuda:0') eval_epoch_loss=tensor(1.1023, device='cuda:0') eval_epoch_acc=tensor(0.7613, device='cuda:0')
[2024-11-29 03:21:45,414][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:21:45,415][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:21:45,600][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_7_step_131_loss_1.1022703647613525/model.pt
[2024-11-29 03:21:45,606][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 7 is 0.7612593173980713
[2024-11-29 03:21:45,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:45,916][root][INFO] - Training Epoch: 7/10, step 131/574 completed (loss: 0.4645257294178009, acc: 0.8260869383811951)
[2024-11-29 03:21:46,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:46,123][root][INFO] - Training Epoch: 7/10, step 132/574 completed (loss: 0.6352764964103699, acc: 0.8125)
[2024-11-29 03:21:46,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:46,312][root][INFO] - Training Epoch: 7/10, step 133/574 completed (loss: 0.26426419615745544, acc: 0.9130434989929199)
[2024-11-29 03:21:46,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:46,538][root][INFO] - Training Epoch: 7/10, step 134/574 completed (loss: 0.33994871377944946, acc: 0.9428571462631226)
[2024-11-29 03:21:46,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:46,779][root][INFO] - Training Epoch: 7/10, step 135/574 completed (loss: 0.030161254107952118, acc: 1.0)
[2024-11-29 03:21:46,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:47,014][root][INFO] - Training Epoch: 7/10, step 136/574 completed (loss: 0.6668881773948669, acc: 0.8095238208770752)
[2024-11-29 03:21:47,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:47,249][root][INFO] - Training Epoch: 7/10, step 137/574 completed (loss: 1.5454745292663574, acc: 0.6333333253860474)
[2024-11-29 03:21:47,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:47,434][root][INFO] - Training Epoch: 7/10, step 138/574 completed (loss: 0.14654329419136047, acc: 0.95652174949646)
[2024-11-29 03:21:47,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:47,632][root][INFO] - Training Epoch: 7/10, step 139/574 completed (loss: 0.1949043720960617, acc: 0.9523809552192688)
[2024-11-29 03:21:47,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:47,888][root][INFO] - Training Epoch: 7/10, step 140/574 completed (loss: 0.09297918528318405, acc: 1.0)
[2024-11-29 03:21:48,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:48,155][root][INFO] - Training Epoch: 7/10, step 141/574 completed (loss: 0.18876516819000244, acc: 0.9677419066429138)
[2024-11-29 03:21:48,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:48,394][root][INFO] - Training Epoch: 7/10, step 142/574 completed (loss: 0.24718156456947327, acc: 0.9459459185600281)
[2024-11-29 03:21:48,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:48,855][root][INFO] - Training Epoch: 7/10, step 143/574 completed (loss: 0.6423324942588806, acc: 0.8157894611358643)
[2024-11-29 03:21:48,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:49,074][root][INFO] - Training Epoch: 7/10, step 144/574 completed (loss: 0.8422316908836365, acc: 0.7910447716712952)
[2024-11-29 03:21:49,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:49,353][root][INFO] - Training Epoch: 7/10, step 145/574 completed (loss: 0.6494256258010864, acc: 0.8367347121238708)
[2024-11-29 03:21:49,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:49,714][root][INFO] - Training Epoch: 7/10, step 146/574 completed (loss: 1.0141046047210693, acc: 0.7021276354789734)
[2024-11-29 03:21:49,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:49,918][root][INFO] - Training Epoch: 7/10, step 147/574 completed (loss: 0.6870015263557434, acc: 0.7857142686843872)
[2024-11-29 03:21:50,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:50,152][root][INFO] - Training Epoch: 7/10, step 148/574 completed (loss: 0.26449471712112427, acc: 0.9642857313156128)
[2024-11-29 03:21:50,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:50,449][root][INFO] - Training Epoch: 7/10, step 149/574 completed (loss: 0.5490013957023621, acc: 0.9130434989929199)
[2024-11-29 03:21:50,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:50,679][root][INFO] - Training Epoch: 7/10, step 150/574 completed (loss: 0.4924110174179077, acc: 0.8965517282485962)
[2024-11-29 03:21:50,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:50,934][root][INFO] - Training Epoch: 7/10, step 151/574 completed (loss: 0.5503226518630981, acc: 0.8695651888847351)
[2024-11-29 03:21:51,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:51,208][root][INFO] - Training Epoch: 7/10, step 152/574 completed (loss: 0.5892211198806763, acc: 0.8305084705352783)
[2024-11-29 03:21:51,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:51,464][root][INFO] - Training Epoch: 7/10, step 153/574 completed (loss: 0.39756178855895996, acc: 0.8947368264198303)
[2024-11-29 03:21:51,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:51,717][root][INFO] - Training Epoch: 7/10, step 154/574 completed (loss: 0.5679522156715393, acc: 0.837837815284729)
[2024-11-29 03:21:51,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:51,980][root][INFO] - Training Epoch: 7/10, step 155/574 completed (loss: 0.04661356285214424, acc: 1.0)
[2024-11-29 03:21:52,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:52,242][root][INFO] - Training Epoch: 7/10, step 156/574 completed (loss: 0.6186612844467163, acc: 0.8260869383811951)
[2024-11-29 03:21:52,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:52,513][root][INFO] - Training Epoch: 7/10, step 157/574 completed (loss: 2.689462184906006, acc: 0.3684210479259491)
[2024-11-29 03:21:53,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:54,159][root][INFO] - Training Epoch: 7/10, step 158/574 completed (loss: 1.4066433906555176, acc: 0.6756756901741028)
[2024-11-29 03:21:54,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:54,424][root][INFO] - Training Epoch: 7/10, step 159/574 completed (loss: 1.3707863092422485, acc: 0.6666666865348816)
[2024-11-29 03:21:54,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:54,737][root][INFO] - Training Epoch: 7/10, step 160/574 completed (loss: 1.538004994392395, acc: 0.5813953280448914)
[2024-11-29 03:21:54,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:55,242][root][INFO] - Training Epoch: 7/10, step 161/574 completed (loss: 1.6650221347808838, acc: 0.5529412031173706)
[2024-11-29 03:21:55,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:55,709][root][INFO] - Training Epoch: 7/10, step 162/574 completed (loss: 1.5028032064437866, acc: 0.6516854166984558)
[2024-11-29 03:21:55,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:55,946][root][INFO] - Training Epoch: 7/10, step 163/574 completed (loss: 0.46873170137405396, acc: 0.8409090638160706)
[2024-11-29 03:21:56,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:56,180][root][INFO] - Training Epoch: 7/10, step 164/574 completed (loss: 0.3358767032623291, acc: 0.9047619104385376)
[2024-11-29 03:21:56,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:56,445][root][INFO] - Training Epoch: 7/10, step 165/574 completed (loss: 1.8920578956604004, acc: 0.48275861144065857)
[2024-11-29 03:21:56,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:56,681][root][INFO] - Training Epoch: 7/10, step 166/574 completed (loss: 0.25802919268608093, acc: 0.8979591727256775)
[2024-11-29 03:21:56,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:56,906][root][INFO] - Training Epoch: 7/10, step 167/574 completed (loss: 0.33590421080589294, acc: 0.9200000166893005)
[2024-11-29 03:21:57,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:57,203][root][INFO] - Training Epoch: 7/10, step 168/574 completed (loss: 0.6995059251785278, acc: 0.8194444179534912)
[2024-11-29 03:21:57,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:57,467][root][INFO] - Training Epoch: 7/10, step 169/574 completed (loss: 1.2953691482543945, acc: 0.686274528503418)
[2024-11-29 03:21:57,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:58,421][root][INFO] - Training Epoch: 7/10, step 170/574 completed (loss: 1.5820430517196655, acc: 0.534246563911438)
[2024-11-29 03:21:58,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:58,617][root][INFO] - Training Epoch: 7/10, step 171/574 completed (loss: 0.35105010867118835, acc: 0.875)
[2024-11-29 03:21:58,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:58,869][root][INFO] - Training Epoch: 7/10, step 172/574 completed (loss: 0.8812955021858215, acc: 0.6666666865348816)
[2024-11-29 03:21:58,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:59,077][root][INFO] - Training Epoch: 7/10, step 173/574 completed (loss: 0.3337213099002838, acc: 0.8928571343421936)
[2024-11-29 03:21:59,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:59,528][root][INFO] - Training Epoch: 7/10, step 174/574 completed (loss: 1.2277425527572632, acc: 0.7433628439903259)
[2024-11-29 03:21:59,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:59,728][root][INFO] - Training Epoch: 7/10, step 175/574 completed (loss: 0.6293239593505859, acc: 0.7971014380455017)
[2024-11-29 03:21:59,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:59,998][root][INFO] - Training Epoch: 7/10, step 176/574 completed (loss: 0.37831947207450867, acc: 0.8863636255264282)
[2024-11-29 03:22:00,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:00,836][root][INFO] - Training Epoch: 7/10, step 177/574 completed (loss: 1.308415174484253, acc: 0.6488549709320068)
[2024-11-29 03:22:01,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:01,409][root][INFO] - Training Epoch: 7/10, step 178/574 completed (loss: 0.9980081915855408, acc: 0.7407407164573669)
[2024-11-29 03:22:01,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:01,670][root][INFO] - Training Epoch: 7/10, step 179/574 completed (loss: 0.33579766750335693, acc: 0.868852436542511)
[2024-11-29 03:22:01,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:01,922][root][INFO] - Training Epoch: 7/10, step 180/574 completed (loss: 0.11212354898452759, acc: 0.9583333134651184)
[2024-11-29 03:22:02,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:02,147][root][INFO] - Training Epoch: 7/10, step 181/574 completed (loss: 0.02797837182879448, acc: 1.0)
[2024-11-29 03:22:02,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:02,322][root][INFO] - Training Epoch: 7/10, step 182/574 completed (loss: 0.05200562998652458, acc: 1.0)
[2024-11-29 03:22:02,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:02,488][root][INFO] - Training Epoch: 7/10, step 183/574 completed (loss: 0.16986671090126038, acc: 0.9268292784690857)
[2024-11-29 03:22:02,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:02,715][root][INFO] - Training Epoch: 7/10, step 184/574 completed (loss: 0.7941625118255615, acc: 0.8308157324790955)
[2024-11-29 03:22:02,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:02,965][root][INFO] - Training Epoch: 7/10, step 185/574 completed (loss: 0.8092989325523376, acc: 0.7723342776298523)
[2024-11-29 03:22:03,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:03,365][root][INFO] - Training Epoch: 7/10, step 186/574 completed (loss: 0.7375558614730835, acc: 0.7749999761581421)
[2024-11-29 03:22:03,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:03,794][root][INFO] - Training Epoch: 7/10, step 187/574 completed (loss: 1.0917179584503174, acc: 0.7354596853256226)
[2024-11-29 03:22:03,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:04,100][root][INFO] - Training Epoch: 7/10, step 188/574 completed (loss: 0.6831464171409607, acc: 0.7758007049560547)
[2024-11-29 03:22:04,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:04,372][root][INFO] - Training Epoch: 7/10, step 189/574 completed (loss: 0.2489437311887741, acc: 0.9599999785423279)
[2024-11-29 03:22:04,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:04,842][root][INFO] - Training Epoch: 7/10, step 190/574 completed (loss: 0.6239089369773865, acc: 0.8023256063461304)
[2024-11-29 03:22:05,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:05,536][root][INFO] - Training Epoch: 7/10, step 191/574 completed (loss: 1.2224427461624146, acc: 0.6190476417541504)
[2024-11-29 03:22:05,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:06,342][root][INFO] - Training Epoch: 7/10, step 192/574 completed (loss: 1.3806291818618774, acc: 0.6212121248245239)
[2024-11-29 03:22:06,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:06,985][root][INFO] - Training Epoch: 7/10, step 193/574 completed (loss: 0.6780582070350647, acc: 0.8352941274642944)
[2024-11-29 03:22:07,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:07,944][root][INFO] - Training Epoch: 7/10, step 194/574 completed (loss: 1.131641149520874, acc: 0.6913580298423767)
[2024-11-29 03:22:08,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:08,788][root][INFO] - Training Epoch: 7/10, step 195/574 completed (loss: 0.36835095286369324, acc: 0.8387096524238586)
[2024-11-29 03:22:08,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:08,961][root][INFO] - Training Epoch: 7/10, step 196/574 completed (loss: 0.09987931698560715, acc: 0.9642857313156128)
[2024-11-29 03:22:09,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:09,154][root][INFO] - Training Epoch: 7/10, step 197/574 completed (loss: 0.5257768034934998, acc: 0.8999999761581421)
[2024-11-29 03:22:09,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:09,365][root][INFO] - Training Epoch: 7/10, step 198/574 completed (loss: 0.4413378834724426, acc: 0.8529411554336548)
[2024-11-29 03:22:09,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:09,642][root][INFO] - Training Epoch: 7/10, step 199/574 completed (loss: 1.1042412519454956, acc: 0.75)
[2024-11-29 03:22:09,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:09,941][root][INFO] - Training Epoch: 7/10, step 200/574 completed (loss: 0.8192706108093262, acc: 0.7796609997749329)
[2024-11-29 03:22:10,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:10,211][root][INFO] - Training Epoch: 7/10, step 201/574 completed (loss: 0.8744752407073975, acc: 0.7761194109916687)
[2024-11-29 03:22:10,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:10,473][root][INFO] - Training Epoch: 7/10, step 202/574 completed (loss: 0.7850933074951172, acc: 0.7961165308952332)
[2024-11-29 03:22:10,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:10,671][root][INFO] - Training Epoch: 7/10, step 203/574 completed (loss: 0.44444671273231506, acc: 0.8730158805847168)
[2024-11-29 03:22:10,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:10,864][root][INFO] - Training Epoch: 7/10, step 204/574 completed (loss: 0.11040448397397995, acc: 0.9780219793319702)
[2024-11-29 03:22:10,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:11,115][root][INFO] - Training Epoch: 7/10, step 205/574 completed (loss: 0.28704920411109924, acc: 0.8878923654556274)
[2024-11-29 03:22:11,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:11,416][root][INFO] - Training Epoch: 7/10, step 206/574 completed (loss: 0.5148325562477112, acc: 0.8385826945304871)
[2024-11-29 03:22:11,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:11,655][root][INFO] - Training Epoch: 7/10, step 207/574 completed (loss: 0.4008982479572296, acc: 0.8836206793785095)
[2024-11-29 03:22:11,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:11,901][root][INFO] - Training Epoch: 7/10, step 208/574 completed (loss: 0.4929713308811188, acc: 0.8731883764266968)
[2024-11-29 03:22:12,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:12,168][root][INFO] - Training Epoch: 7/10, step 209/574 completed (loss: 0.5773636102676392, acc: 0.8404669165611267)
[2024-11-29 03:22:12,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:12,411][root][INFO] - Training Epoch: 7/10, step 210/574 completed (loss: 0.3419979214668274, acc: 0.9021739363670349)
[2024-11-29 03:22:12,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:12,643][root][INFO] - Training Epoch: 7/10, step 211/574 completed (loss: 0.05046290531754494, acc: 1.0)
[2024-11-29 03:22:12,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:12,894][root][INFO] - Training Epoch: 7/10, step 212/574 completed (loss: 0.12571997940540314, acc: 0.9642857313156128)
[2024-11-29 03:22:13,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:13,156][root][INFO] - Training Epoch: 7/10, step 213/574 completed (loss: 0.4300936162471771, acc: 0.914893627166748)
[2024-11-29 03:22:13,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:13,742][root][INFO] - Training Epoch: 7/10, step 214/574 completed (loss: 0.25353842973709106, acc: 0.9461538195610046)
[2024-11-29 03:22:13,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:13,956][root][INFO] - Training Epoch: 7/10, step 215/574 completed (loss: 0.09558261930942535, acc: 0.9729729890823364)
[2024-11-29 03:22:14,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:14,171][root][INFO] - Training Epoch: 7/10, step 216/574 completed (loss: 0.05915137752890587, acc: 0.9883720874786377)
[2024-11-29 03:22:14,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:14,615][root][INFO] - Training Epoch: 7/10, step 217/574 completed (loss: 0.26666897535324097, acc: 0.9279279112815857)
[2024-11-29 03:22:14,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:14,912][root][INFO] - Training Epoch: 7/10, step 218/574 completed (loss: 0.18461820483207703, acc: 0.9222221970558167)
[2024-11-29 03:22:15,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:15,177][root][INFO] - Training Epoch: 7/10, step 219/574 completed (loss: 0.041143450886011124, acc: 1.0)
[2024-11-29 03:22:15,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:15,419][root][INFO] - Training Epoch: 7/10, step 220/574 completed (loss: 0.09103064984083176, acc: 0.9629629850387573)
[2024-11-29 03:22:15,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:15,663][root][INFO] - Training Epoch: 7/10, step 221/574 completed (loss: 0.07919133454561234, acc: 1.0)
[2024-11-29 03:22:15,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:15,937][root][INFO] - Training Epoch: 7/10, step 222/574 completed (loss: 0.46014678478240967, acc: 0.807692289352417)
[2024-11-29 03:22:16,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:16,600][root][INFO] - Training Epoch: 7/10, step 223/574 completed (loss: 0.45033934712409973, acc: 0.8913043737411499)
[2024-11-29 03:22:16,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:17,051][root][INFO] - Training Epoch: 7/10, step 224/574 completed (loss: 0.6723153591156006, acc: 0.8068181872367859)
[2024-11-29 03:22:17,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:17,397][root][INFO] - Training Epoch: 7/10, step 225/574 completed (loss: 0.48375600576400757, acc: 0.8510638475418091)
[2024-11-29 03:22:17,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:17,634][root][INFO] - Training Epoch: 7/10, step 226/574 completed (loss: 0.2390085607767105, acc: 0.9622641801834106)
[2024-11-29 03:22:17,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:17,866][root][INFO] - Training Epoch: 7/10, step 227/574 completed (loss: 0.12198904901742935, acc: 0.9666666388511658)
[2024-11-29 03:22:17,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:18,092][root][INFO] - Training Epoch: 7/10, step 228/574 completed (loss: 0.5804194808006287, acc: 0.8604651093482971)
[2024-11-29 03:22:18,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:18,353][root][INFO] - Training Epoch: 7/10, step 229/574 completed (loss: 1.1271328926086426, acc: 0.699999988079071)
[2024-11-29 03:22:18,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:18,615][root][INFO] - Training Epoch: 7/10, step 230/574 completed (loss: 2.133230447769165, acc: 0.46315789222717285)
[2024-11-29 03:22:18,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:18,890][root][INFO] - Training Epoch: 7/10, step 231/574 completed (loss: 1.7622872591018677, acc: 0.5555555820465088)
[2024-11-29 03:22:19,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:19,232][root][INFO] - Training Epoch: 7/10, step 232/574 completed (loss: 1.7731655836105347, acc: 0.550000011920929)
[2024-11-29 03:22:19,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:19,636][root][INFO] - Training Epoch: 7/10, step 233/574 completed (loss: 2.2430665493011475, acc: 0.4220183491706848)
[2024-11-29 03:22:19,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:20,018][root][INFO] - Training Epoch: 7/10, step 234/574 completed (loss: 1.8613120317459106, acc: 0.5769230723381042)
[2024-11-29 03:22:20,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:20,202][root][INFO] - Training Epoch: 7/10, step 235/574 completed (loss: 0.01986265741288662, acc: 1.0)
[2024-11-29 03:22:20,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:20,369][root][INFO] - Training Epoch: 7/10, step 236/574 completed (loss: 0.04364858195185661, acc: 1.0)
[2024-11-29 03:22:20,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:20,610][root][INFO] - Training Epoch: 7/10, step 237/574 completed (loss: 0.15140463411808014, acc: 0.9545454382896423)
[2024-11-29 03:22:20,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:20,799][root][INFO] - Training Epoch: 7/10, step 238/574 completed (loss: 0.7096912860870361, acc: 0.7777777910232544)
[2024-11-29 03:22:20,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:20,991][root][INFO] - Training Epoch: 7/10, step 239/574 completed (loss: 0.43149909377098083, acc: 0.8571428656578064)
[2024-11-29 03:22:21,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:21,247][root][INFO] - Training Epoch: 7/10, step 240/574 completed (loss: 0.7880449891090393, acc: 0.8181818127632141)
[2024-11-29 03:22:21,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:21,490][root][INFO] - Training Epoch: 7/10, step 241/574 completed (loss: 0.18086256086826324, acc: 0.9318181872367859)
[2024-11-29 03:22:21,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:21,986][root][INFO] - Training Epoch: 7/10, step 242/574 completed (loss: 0.747985303401947, acc: 0.8064516186714172)
[2024-11-29 03:22:22,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:22,421][root][INFO] - Training Epoch: 7/10, step 243/574 completed (loss: 0.5756298303604126, acc: 0.8181818127632141)
[2024-11-29 03:22:22,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:22,646][root][INFO] - Training Epoch: 7/10, step 244/574 completed (loss: 0.02543998323380947, acc: 1.0)
[2024-11-29 03:22:22,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:22,888][root][INFO] - Training Epoch: 7/10, step 245/574 completed (loss: 0.24686449766159058, acc: 0.9615384340286255)
[2024-11-29 03:22:22,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:23,121][root][INFO] - Training Epoch: 7/10, step 246/574 completed (loss: 0.02352409064769745, acc: 1.0)
[2024-11-29 03:22:23,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:23,353][root][INFO] - Training Epoch: 7/10, step 247/574 completed (loss: 0.02281726896762848, acc: 1.0)
[2024-11-29 03:22:23,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:23,605][root][INFO] - Training Epoch: 7/10, step 248/574 completed (loss: 0.21615301072597504, acc: 0.9189189076423645)
[2024-11-29 03:22:23,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:23,825][root][INFO] - Training Epoch: 7/10, step 249/574 completed (loss: 0.3364224135875702, acc: 0.8918918967247009)
[2024-11-29 03:22:23,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:24,099][root][INFO] - Training Epoch: 7/10, step 250/574 completed (loss: 0.013748124241828918, acc: 1.0)
[2024-11-29 03:22:24,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:24,317][root][INFO] - Training Epoch: 7/10, step 251/574 completed (loss: 0.10335425287485123, acc: 0.9852941036224365)
[2024-11-29 03:22:24,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:24,537][root][INFO] - Training Epoch: 7/10, step 252/574 completed (loss: 0.02848639152944088, acc: 1.0)
[2024-11-29 03:22:24,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:24,752][root][INFO] - Training Epoch: 7/10, step 253/574 completed (loss: 0.14353349804878235, acc: 0.9599999785423279)
[2024-11-29 03:22:24,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:24,972][root][INFO] - Training Epoch: 7/10, step 254/574 completed (loss: 0.006505575962364674, acc: 1.0)
[2024-11-29 03:22:25,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:25,213][root][INFO] - Training Epoch: 7/10, step 255/574 completed (loss: 0.02467028982937336, acc: 1.0)
[2024-11-29 03:22:25,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:25,386][root][INFO] - Training Epoch: 7/10, step 256/574 completed (loss: 0.15081025660037994, acc: 0.9649122953414917)
[2024-11-29 03:22:25,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:25,610][root][INFO] - Training Epoch: 7/10, step 257/574 completed (loss: 0.1134897768497467, acc: 0.9714285731315613)
[2024-11-29 03:22:25,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:25,866][root][INFO] - Training Epoch: 7/10, step 258/574 completed (loss: 0.09425971657037735, acc: 0.9605262875556946)
[2024-11-29 03:22:26,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:26,342][root][INFO] - Training Epoch: 7/10, step 259/574 completed (loss: 0.3274291157722473, acc: 0.9150943160057068)
[2024-11-29 03:22:26,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:26,831][root][INFO] - Training Epoch: 7/10, step 260/574 completed (loss: 0.4882965385913849, acc: 0.8583333492279053)
[2024-11-29 03:22:26,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:27,018][root][INFO] - Training Epoch: 7/10, step 261/574 completed (loss: 0.22402900457382202, acc: 0.8888888955116272)
[2024-11-29 03:22:27,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:27,253][root][INFO] - Training Epoch: 7/10, step 262/574 completed (loss: 0.5923535823822021, acc: 0.8387096524238586)
[2024-11-29 03:22:27,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:27,528][root][INFO] - Training Epoch: 7/10, step 263/574 completed (loss: 0.7517649531364441, acc: 0.7599999904632568)
[2024-11-29 03:22:27,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:27,775][root][INFO] - Training Epoch: 7/10, step 264/574 completed (loss: 0.48841097950935364, acc: 0.875)
[2024-11-29 03:22:28,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:28,581][root][INFO] - Training Epoch: 7/10, step 265/574 completed (loss: 1.0178375244140625, acc: 0.6880000233650208)
[2024-11-29 03:22:28,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:28,827][root][INFO] - Training Epoch: 7/10, step 266/574 completed (loss: 0.8657789826393127, acc: 0.7078651785850525)
[2024-11-29 03:22:28,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:29,085][root][INFO] - Training Epoch: 7/10, step 267/574 completed (loss: 0.7403716444969177, acc: 0.7837837934494019)
[2024-11-29 03:22:29,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:29,447][root][INFO] - Training Epoch: 7/10, step 268/574 completed (loss: 0.37454670667648315, acc: 0.8620689511299133)
[2024-11-29 03:22:29,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:29,658][root][INFO] - Training Epoch: 7/10, step 269/574 completed (loss: 0.4704769253730774, acc: 0.9090909361839294)
[2024-11-29 03:22:29,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:29,920][root][INFO] - Training Epoch: 7/10, step 270/574 completed (loss: 0.037269268184900284, acc: 1.0)
[2024-11-29 03:22:30,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:30,120][root][INFO] - Training Epoch: 7/10, step 271/574 completed (loss: 0.043799612671136856, acc: 1.0)
[2024-11-29 03:22:30,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:30,303][root][INFO] - Training Epoch: 7/10, step 272/574 completed (loss: 0.15444782376289368, acc: 0.8999999761581421)
[2024-11-29 03:22:30,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:30,582][root][INFO] - Training Epoch: 7/10, step 273/574 completed (loss: 0.40440598130226135, acc: 0.8666666746139526)
[2024-11-29 03:22:31,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:31,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:31,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:32,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:32,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:32,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:32,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:33,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:33,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:33,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:34,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:34,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:34,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:35,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:35,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:35,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:36,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:36,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:36,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:36,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:37,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:37,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:37,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:38,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:38,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:38,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:38,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:39,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:39,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:39,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:39,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:40,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:40,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:40,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:40,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:41,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:41,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:41,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:41,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:42,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:42,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:42,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:43,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:43,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:43,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:43,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:44,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:44,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:44,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:44,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:45,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:45,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:45,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:46,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:46,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:46,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:46,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:47,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:47,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:47,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:47,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:48,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:48,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:49,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:49,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:49,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:49,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:50,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:50,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:50,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:51,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:51,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:51,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:51,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:51,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:52,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:52,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:52,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:53,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:53,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:53,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:53,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:54,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:54,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:54,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:55,128][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.0336, device='cuda:0') eval_epoch_loss=tensor(1.1098, device='cuda:0') eval_epoch_acc=tensor(0.7558, device='cuda:0')
[2024-11-29 03:22:55,129][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:22:55,129][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:22:55,292][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_7_step_274_loss_1.109761357307434/model.pt
[2024-11-29 03:22:55,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:55,484][root][INFO] - Training Epoch: 7/10, step 274/574 completed (loss: 0.06404055655002594, acc: 1.0)
[2024-11-29 03:22:55,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:55,738][root][INFO] - Training Epoch: 7/10, step 275/574 completed (loss: 0.10528472065925598, acc: 0.9666666388511658)
[2024-11-29 03:22:55,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:55,965][root][INFO] - Training Epoch: 7/10, step 276/574 completed (loss: 0.06701938062906265, acc: 1.0)
[2024-11-29 03:22:56,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:56,188][root][INFO] - Training Epoch: 7/10, step 277/574 completed (loss: 0.030510125681757927, acc: 1.0)
[2024-11-29 03:22:56,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:56,437][root][INFO] - Training Epoch: 7/10, step 278/574 completed (loss: 0.34883278608322144, acc: 0.8723404407501221)
[2024-11-29 03:22:56,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:56,674][root][INFO] - Training Epoch: 7/10, step 279/574 completed (loss: 0.2425859421491623, acc: 0.9375)
[2024-11-29 03:22:56,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:56,914][root][INFO] - Training Epoch: 7/10, step 280/574 completed (loss: 0.0425453819334507, acc: 1.0)
[2024-11-29 03:22:57,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:57,251][root][INFO] - Training Epoch: 7/10, step 281/574 completed (loss: 0.7862935066223145, acc: 0.8072289228439331)
[2024-11-29 03:22:57,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:57,512][root][INFO] - Training Epoch: 7/10, step 282/574 completed (loss: 0.6243839263916016, acc: 0.7777777910232544)
[2024-11-29 03:22:57,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:57,769][root][INFO] - Training Epoch: 7/10, step 283/574 completed (loss: 0.0639750063419342, acc: 0.9736841917037964)
[2024-11-29 03:22:57,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:57,998][root][INFO] - Training Epoch: 7/10, step 284/574 completed (loss: 0.04961641505360603, acc: 1.0)
[2024-11-29 03:22:58,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:58,253][root][INFO] - Training Epoch: 7/10, step 285/574 completed (loss: 0.21398964524269104, acc: 0.8999999761581421)
[2024-11-29 03:22:58,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:58,475][root][INFO] - Training Epoch: 7/10, step 286/574 completed (loss: 0.5572187900543213, acc: 0.8671875)
[2024-11-29 03:22:58,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:58,708][root][INFO] - Training Epoch: 7/10, step 287/574 completed (loss: 0.7256492972373962, acc: 0.8159999847412109)
[2024-11-29 03:22:58,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:58,954][root][INFO] - Training Epoch: 7/10, step 288/574 completed (loss: 0.42245617508888245, acc: 0.8901098966598511)
[2024-11-29 03:22:59,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:59,176][root][INFO] - Training Epoch: 7/10, step 289/574 completed (loss: 0.34275010228157043, acc: 0.8819875717163086)
[2024-11-29 03:22:59,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:59,416][root][INFO] - Training Epoch: 7/10, step 290/574 completed (loss: 0.5213639736175537, acc: 0.8453608155250549)
[2024-11-29 03:22:59,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:59,617][root][INFO] - Training Epoch: 7/10, step 291/574 completed (loss: 0.10815966874361038, acc: 0.9545454382896423)
[2024-11-29 03:22:59,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:59,854][root][INFO] - Training Epoch: 7/10, step 292/574 completed (loss: 0.15057238936424255, acc: 0.9523809552192688)
[2024-11-29 03:22:59,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:00,083][root][INFO] - Training Epoch: 7/10, step 293/574 completed (loss: 0.14130505919456482, acc: 0.982758641242981)
[2024-11-29 03:23:00,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:00,495][root][INFO] - Training Epoch: 7/10, step 294/574 completed (loss: 0.37605738639831543, acc: 0.9090909361839294)
[2024-11-29 03:23:00,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:00,952][root][INFO] - Training Epoch: 7/10, step 295/574 completed (loss: 0.7154963612556458, acc: 0.7731958627700806)
[2024-11-29 03:23:01,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:01,141][root][INFO] - Training Epoch: 7/10, step 296/574 completed (loss: 0.4515020549297333, acc: 0.8103448152542114)
[2024-11-29 03:23:01,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:01,353][root][INFO] - Training Epoch: 7/10, step 297/574 completed (loss: 0.04807990416884422, acc: 1.0)
[2024-11-29 03:23:01,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:01,570][root][INFO] - Training Epoch: 7/10, step 298/574 completed (loss: 0.1407846212387085, acc: 1.0)
[2024-11-29 03:23:01,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:01,762][root][INFO] - Training Epoch: 7/10, step 299/574 completed (loss: 0.1477590948343277, acc: 0.9821428656578064)
[2024-11-29 03:23:01,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:01,983][root][INFO] - Training Epoch: 7/10, step 300/574 completed (loss: 0.052177805453538895, acc: 1.0)
[2024-11-29 03:23:02,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:02,241][root][INFO] - Training Epoch: 7/10, step 301/574 completed (loss: 0.34206029772758484, acc: 0.849056601524353)
[2024-11-29 03:23:02,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:02,464][root][INFO] - Training Epoch: 7/10, step 302/574 completed (loss: 0.019179031252861023, acc: 1.0)
[2024-11-29 03:23:02,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:02,682][root][INFO] - Training Epoch: 7/10, step 303/574 completed (loss: 0.1595660150051117, acc: 0.970588207244873)
[2024-11-29 03:23:02,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:02,893][root][INFO] - Training Epoch: 7/10, step 304/574 completed (loss: 0.12406937777996063, acc: 0.96875)
[2024-11-29 03:23:03,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:03,133][root][INFO] - Training Epoch: 7/10, step 305/574 completed (loss: 0.46459871530532837, acc: 0.868852436542511)
[2024-11-29 03:23:03,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:03,406][root][INFO] - Training Epoch: 7/10, step 306/574 completed (loss: 0.04281779006123543, acc: 1.0)
[2024-11-29 03:23:03,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:03,655][root][INFO] - Training Epoch: 7/10, step 307/574 completed (loss: 0.012239084579050541, acc: 1.0)
[2024-11-29 03:23:03,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:03,894][root][INFO] - Training Epoch: 7/10, step 308/574 completed (loss: 0.26700007915496826, acc: 0.9420289993286133)
[2024-11-29 03:23:04,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:04,212][root][INFO] - Training Epoch: 7/10, step 309/574 completed (loss: 0.29436516761779785, acc: 0.9166666865348816)
[2024-11-29 03:23:04,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:04,425][root][INFO] - Training Epoch: 7/10, step 310/574 completed (loss: 0.35637691617012024, acc: 0.891566276550293)
[2024-11-29 03:23:04,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:04,632][root][INFO] - Training Epoch: 7/10, step 311/574 completed (loss: 0.39760398864746094, acc: 0.9102563858032227)
[2024-11-29 03:23:04,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:04,894][root][INFO] - Training Epoch: 7/10, step 312/574 completed (loss: 0.10968253761529922, acc: 0.9897959232330322)
[2024-11-29 03:23:04,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:05,115][root][INFO] - Training Epoch: 7/10, step 313/574 completed (loss: 0.01896214857697487, acc: 1.0)
[2024-11-29 03:23:05,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:05,328][root][INFO] - Training Epoch: 7/10, step 314/574 completed (loss: 0.051741693168878555, acc: 1.0)
[2024-11-29 03:23:05,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:05,560][root][INFO] - Training Epoch: 7/10, step 315/574 completed (loss: 0.07804270833730698, acc: 0.9677419066429138)
[2024-11-29 03:23:05,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:05,788][root][INFO] - Training Epoch: 7/10, step 316/574 completed (loss: 0.8810857534408569, acc: 0.8064516186714172)
[2024-11-29 03:23:05,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:06,038][root][INFO] - Training Epoch: 7/10, step 317/574 completed (loss: 0.10830575227737427, acc: 0.9402984976768494)
[2024-11-29 03:23:06,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:06,263][root][INFO] - Training Epoch: 7/10, step 318/574 completed (loss: 0.14734907448291779, acc: 0.9519230723381042)
[2024-11-29 03:23:06,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:06,479][root][INFO] - Training Epoch: 7/10, step 319/574 completed (loss: 0.04091517627239227, acc: 1.0)
[2024-11-29 03:23:06,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:06,723][root][INFO] - Training Epoch: 7/10, step 320/574 completed (loss: 0.09888482838869095, acc: 0.9677419066429138)
[2024-11-29 03:23:06,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:06,936][root][INFO] - Training Epoch: 7/10, step 321/574 completed (loss: 0.01161780022084713, acc: 1.0)
[2024-11-29 03:23:07,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:07,175][root][INFO] - Training Epoch: 7/10, step 322/574 completed (loss: 0.40323135256767273, acc: 0.8888888955116272)
[2024-11-29 03:23:07,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:07,410][root][INFO] - Training Epoch: 7/10, step 323/574 completed (loss: 1.1099187135696411, acc: 0.6571428775787354)
[2024-11-29 03:23:07,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:07,643][root][INFO] - Training Epoch: 7/10, step 324/574 completed (loss: 0.7648289203643799, acc: 0.7692307829856873)
[2024-11-29 03:23:07,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:07,842][root][INFO] - Training Epoch: 7/10, step 325/574 completed (loss: 1.540664792060852, acc: 0.5365853905677795)
[2024-11-29 03:23:07,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:08,056][root][INFO] - Training Epoch: 7/10, step 326/574 completed (loss: 0.7802088260650635, acc: 0.7368420958518982)
[2024-11-29 03:23:08,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:08,299][root][INFO] - Training Epoch: 7/10, step 327/574 completed (loss: 0.2970343232154846, acc: 0.9473684430122375)
[2024-11-29 03:23:08,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:08,528][root][INFO] - Training Epoch: 7/10, step 328/574 completed (loss: 0.1035311296582222, acc: 0.9642857313156128)
[2024-11-29 03:23:08,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:08,765][root][INFO] - Training Epoch: 7/10, step 329/574 completed (loss: 0.21214912831783295, acc: 0.9629629850387573)
[2024-11-29 03:23:08,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:08,998][root][INFO] - Training Epoch: 7/10, step 330/574 completed (loss: 0.008760930970311165, acc: 1.0)
[2024-11-29 03:23:09,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:09,243][root][INFO] - Training Epoch: 7/10, step 331/574 completed (loss: 0.10195211321115494, acc: 0.9516128897666931)
[2024-11-29 03:23:09,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:09,508][root][INFO] - Training Epoch: 7/10, step 332/574 completed (loss: 0.11887600272893906, acc: 0.9649122953414917)
[2024-11-29 03:23:09,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:09,715][root][INFO] - Training Epoch: 7/10, step 333/574 completed (loss: 0.08045929670333862, acc: 0.96875)
[2024-11-29 03:23:09,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:09,897][root][INFO] - Training Epoch: 7/10, step 334/574 completed (loss: 0.059954993426799774, acc: 1.0)
[2024-11-29 03:23:09,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:10,093][root][INFO] - Training Epoch: 7/10, step 335/574 completed (loss: 0.05346723645925522, acc: 1.0)
[2024-11-29 03:23:10,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:10,315][root][INFO] - Training Epoch: 7/10, step 336/574 completed (loss: 0.6296331286430359, acc: 0.8199999928474426)
[2024-11-29 03:23:10,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:10,550][root][INFO] - Training Epoch: 7/10, step 337/574 completed (loss: 1.0731242895126343, acc: 0.7011494040489197)
[2024-11-29 03:23:10,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:10,838][root][INFO] - Training Epoch: 7/10, step 338/574 completed (loss: 1.0532128810882568, acc: 0.6914893388748169)
[2024-11-29 03:23:10,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:11,090][root][INFO] - Training Epoch: 7/10, step 339/574 completed (loss: 1.0288076400756836, acc: 0.7228915691375732)
[2024-11-29 03:23:11,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:11,334][root][INFO] - Training Epoch: 7/10, step 340/574 completed (loss: 0.044483836740255356, acc: 1.0)
[2024-11-29 03:23:11,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:11,567][root][INFO] - Training Epoch: 7/10, step 341/574 completed (loss: 0.16394850611686707, acc: 0.9743589758872986)
[2024-11-29 03:23:11,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:11,817][root][INFO] - Training Epoch: 7/10, step 342/574 completed (loss: 0.28960755467414856, acc: 0.891566276550293)
[2024-11-29 03:23:11,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:12,043][root][INFO] - Training Epoch: 7/10, step 343/574 completed (loss: 0.7288641929626465, acc: 0.7924528121948242)
[2024-11-29 03:23:12,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:12,255][root][INFO] - Training Epoch: 7/10, step 344/574 completed (loss: 0.09367543458938599, acc: 0.9746835231781006)
[2024-11-29 03:23:12,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:12,479][root][INFO] - Training Epoch: 7/10, step 345/574 completed (loss: 0.07755903154611588, acc: 0.9607843160629272)
[2024-11-29 03:23:12,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:12,715][root][INFO] - Training Epoch: 7/10, step 346/574 completed (loss: 0.342063844203949, acc: 0.9104477763175964)
[2024-11-29 03:23:12,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:12,955][root][INFO] - Training Epoch: 7/10, step 347/574 completed (loss: 0.0026729798410087824, acc: 1.0)
[2024-11-29 03:23:13,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:13,190][root][INFO] - Training Epoch: 7/10, step 348/574 completed (loss: 0.05085991322994232, acc: 1.0)
[2024-11-29 03:23:13,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:13,491][root][INFO] - Training Epoch: 7/10, step 349/574 completed (loss: 0.5650117993354797, acc: 0.8611111044883728)
[2024-11-29 03:23:13,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:13,710][root][INFO] - Training Epoch: 7/10, step 350/574 completed (loss: 0.3897826075553894, acc: 0.8372092843055725)
[2024-11-29 03:23:13,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:13,951][root][INFO] - Training Epoch: 7/10, step 351/574 completed (loss: 0.07833465188741684, acc: 1.0)
[2024-11-29 03:23:14,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:14,221][root][INFO] - Training Epoch: 7/10, step 352/574 completed (loss: 0.5922655463218689, acc: 0.8666666746139526)
[2024-11-29 03:23:14,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:14,412][root][INFO] - Training Epoch: 7/10, step 353/574 completed (loss: 0.10613107681274414, acc: 0.95652174949646)
[2024-11-29 03:23:14,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:14,604][root][INFO] - Training Epoch: 7/10, step 354/574 completed (loss: 0.1511044055223465, acc: 0.9230769276618958)
[2024-11-29 03:23:14,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:14,841][root][INFO] - Training Epoch: 7/10, step 355/574 completed (loss: 0.5231173634529114, acc: 0.8131868243217468)
[2024-11-29 03:23:14,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:15,268][root][INFO] - Training Epoch: 7/10, step 356/574 completed (loss: 0.4358740746974945, acc: 0.8695651888847351)
[2024-11-29 03:23:15,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:15,487][root][INFO] - Training Epoch: 7/10, step 357/574 completed (loss: 0.39690157771110535, acc: 0.8804348111152649)
[2024-11-29 03:23:15,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:15,693][root][INFO] - Training Epoch: 7/10, step 358/574 completed (loss: 0.3023298680782318, acc: 0.8775510191917419)
[2024-11-29 03:23:15,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:15,904][root][INFO] - Training Epoch: 7/10, step 359/574 completed (loss: 0.1619332879781723, acc: 0.9583333134651184)
[2024-11-29 03:23:16,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:16,135][root][INFO] - Training Epoch: 7/10, step 360/574 completed (loss: 0.0650356262922287, acc: 1.0)
[2024-11-29 03:23:16,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:16,346][root][INFO] - Training Epoch: 7/10, step 361/574 completed (loss: 0.43947485089302063, acc: 0.8780487775802612)
[2024-11-29 03:23:16,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:16,581][root][INFO] - Training Epoch: 7/10, step 362/574 completed (loss: 0.6883783340454102, acc: 0.8666666746139526)
[2024-11-29 03:23:16,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:16,828][root][INFO] - Training Epoch: 7/10, step 363/574 completed (loss: 0.16030991077423096, acc: 0.9473684430122375)
[2024-11-29 03:23:16,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:17,066][root][INFO] - Training Epoch: 7/10, step 364/574 completed (loss: 0.03207371011376381, acc: 1.0)
[2024-11-29 03:23:17,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:17,298][root][INFO] - Training Epoch: 7/10, step 365/574 completed (loss: 0.07229751348495483, acc: 0.9696969985961914)
[2024-11-29 03:23:17,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:17,518][root][INFO] - Training Epoch: 7/10, step 366/574 completed (loss: 0.13519370555877686, acc: 0.9583333134651184)
[2024-11-29 03:23:17,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:17,745][root][INFO] - Training Epoch: 7/10, step 367/574 completed (loss: 0.030717166140675545, acc: 1.0)
[2024-11-29 03:23:17,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:17,969][root][INFO] - Training Epoch: 7/10, step 368/574 completed (loss: 0.07534235715866089, acc: 1.0)
[2024-11-29 03:23:18,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:18,208][root][INFO] - Training Epoch: 7/10, step 369/574 completed (loss: 0.34560006856918335, acc: 0.90625)
[2024-11-29 03:23:18,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:18,715][root][INFO] - Training Epoch: 7/10, step 370/574 completed (loss: 0.5891822576522827, acc: 0.8484848737716675)
[2024-11-29 03:23:19,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:19,506][root][INFO] - Training Epoch: 7/10, step 371/574 completed (loss: 0.3225620687007904, acc: 0.8867924809455872)
[2024-11-29 03:23:19,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:19,724][root][INFO] - Training Epoch: 7/10, step 372/574 completed (loss: 0.1445271223783493, acc: 0.9666666388511658)
[2024-11-29 03:23:19,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:19,934][root][INFO] - Training Epoch: 7/10, step 373/574 completed (loss: 0.08413495123386383, acc: 0.9642857313156128)
[2024-11-29 03:23:20,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:20,162][root][INFO] - Training Epoch: 7/10, step 374/574 completed (loss: 0.0427970215678215, acc: 1.0)
[2024-11-29 03:23:20,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:20,377][root][INFO] - Training Epoch: 7/10, step 375/574 completed (loss: 0.0278824083507061, acc: 1.0)
[2024-11-29 03:23:20,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:20,613][root][INFO] - Training Epoch: 7/10, step 376/574 completed (loss: 0.017103876918554306, acc: 1.0)
[2024-11-29 03:23:20,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:20,857][root][INFO] - Training Epoch: 7/10, step 377/574 completed (loss: 0.09768065810203552, acc: 1.0)
[2024-11-29 03:23:20,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:21,101][root][INFO] - Training Epoch: 7/10, step 378/574 completed (loss: 0.03444942086935043, acc: 0.9894737005233765)
[2024-11-29 03:23:21,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:21,594][root][INFO] - Training Epoch: 7/10, step 379/574 completed (loss: 0.3123849332332611, acc: 0.9341317415237427)
[2024-11-29 03:23:21,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:21,897][root][INFO] - Training Epoch: 7/10, step 380/574 completed (loss: 0.3207703232765198, acc: 0.932330846786499)
[2024-11-29 03:23:22,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:22,896][root][INFO] - Training Epoch: 7/10, step 381/574 completed (loss: 0.6289750337600708, acc: 0.855614960193634)
[2024-11-29 03:23:23,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:23,371][root][INFO] - Training Epoch: 7/10, step 382/574 completed (loss: 0.12231528759002686, acc: 0.954954981803894)
[2024-11-29 03:23:23,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:23,551][root][INFO] - Training Epoch: 7/10, step 383/574 completed (loss: 0.02711504139006138, acc: 1.0)
[2024-11-29 03:23:23,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:23,753][root][INFO] - Training Epoch: 7/10, step 384/574 completed (loss: 0.05386994034051895, acc: 0.9642857313156128)
[2024-11-29 03:23:23,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:23,975][root][INFO] - Training Epoch: 7/10, step 385/574 completed (loss: 0.056629471480846405, acc: 1.0)
[2024-11-29 03:23:24,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:24,216][root][INFO] - Training Epoch: 7/10, step 386/574 completed (loss: 0.013838366605341434, acc: 1.0)
[2024-11-29 03:23:24,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:24,438][root][INFO] - Training Epoch: 7/10, step 387/574 completed (loss: 0.022490261122584343, acc: 1.0)
[2024-11-29 03:23:24,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:24,673][root][INFO] - Training Epoch: 7/10, step 388/574 completed (loss: 0.01849614828824997, acc: 1.0)
[2024-11-29 03:23:24,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:24,912][root][INFO] - Training Epoch: 7/10, step 389/574 completed (loss: 0.0055288891308009624, acc: 1.0)
[2024-11-29 03:23:25,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:25,142][root][INFO] - Training Epoch: 7/10, step 390/574 completed (loss: 0.39234665036201477, acc: 0.9523809552192688)
[2024-11-29 03:23:25,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:25,372][root][INFO] - Training Epoch: 7/10, step 391/574 completed (loss: 0.5263802409172058, acc: 0.8333333134651184)
[2024-11-29 03:23:25,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:25,618][root][INFO] - Training Epoch: 7/10, step 392/574 completed (loss: 0.8522829413414001, acc: 0.7766990065574646)
[2024-11-29 03:23:25,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:26,063][root][INFO] - Training Epoch: 7/10, step 393/574 completed (loss: 0.8000492453575134, acc: 0.8014705777168274)
[2024-11-29 03:23:26,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:26,326][root][INFO] - Training Epoch: 7/10, step 394/574 completed (loss: 0.7254875302314758, acc: 0.7866666913032532)
[2024-11-29 03:23:26,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:26,613][root][INFO] - Training Epoch: 7/10, step 395/574 completed (loss: 0.5063381791114807, acc: 0.8541666865348816)
[2024-11-29 03:23:26,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:26,807][root][INFO] - Training Epoch: 7/10, step 396/574 completed (loss: 0.14962878823280334, acc: 0.9767441749572754)
[2024-11-29 03:23:26,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:27,027][root][INFO] - Training Epoch: 7/10, step 397/574 completed (loss: 0.009431564249098301, acc: 1.0)
[2024-11-29 03:23:27,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:27,256][root][INFO] - Training Epoch: 7/10, step 398/574 completed (loss: 0.24409231543540955, acc: 0.9534883499145508)
[2024-11-29 03:23:27,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:27,476][root][INFO] - Training Epoch: 7/10, step 399/574 completed (loss: 0.19215114414691925, acc: 0.9599999785423279)
[2024-11-29 03:23:27,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:27,924][root][INFO] - Training Epoch: 7/10, step 400/574 completed (loss: 0.23114491999149323, acc: 0.9558823704719543)
[2024-11-29 03:23:28,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:28,115][root][INFO] - Training Epoch: 7/10, step 401/574 completed (loss: 0.2769642770290375, acc: 0.9066666960716248)
[2024-11-29 03:23:28,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:28,313][root][INFO] - Training Epoch: 7/10, step 402/574 completed (loss: 0.21086949110031128, acc: 0.9090909361839294)
[2024-11-29 03:23:28,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:28,515][root][INFO] - Training Epoch: 7/10, step 403/574 completed (loss: 0.03419661521911621, acc: 1.0)
[2024-11-29 03:23:28,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:28,728][root][INFO] - Training Epoch: 7/10, step 404/574 completed (loss: 0.38465821743011475, acc: 0.8709677457809448)
[2024-11-29 03:23:28,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:28,945][root][INFO] - Training Epoch: 7/10, step 405/574 completed (loss: 0.04566682130098343, acc: 1.0)
[2024-11-29 03:23:29,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:29,162][root][INFO] - Training Epoch: 7/10, step 406/574 completed (loss: 0.027204344049096107, acc: 1.0)
[2024-11-29 03:23:29,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:29,390][root][INFO] - Training Epoch: 7/10, step 407/574 completed (loss: 0.058771345764398575, acc: 0.9722222089767456)
[2024-11-29 03:23:29,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:29,623][root][INFO] - Training Epoch: 7/10, step 408/574 completed (loss: 0.0414811410009861, acc: 1.0)
[2024-11-29 03:23:29,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:29,891][root][INFO] - Training Epoch: 7/10, step 409/574 completed (loss: 0.019839851185679436, acc: 1.0)
[2024-11-29 03:23:30,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:30,136][root][INFO] - Training Epoch: 7/10, step 410/574 completed (loss: 0.07959417998790741, acc: 0.9655172228813171)
[2024-11-29 03:23:30,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:30,372][root][INFO] - Training Epoch: 7/10, step 411/574 completed (loss: 0.11423178762197495, acc: 0.9642857313156128)
[2024-11-29 03:23:30,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:30,612][root][INFO] - Training Epoch: 7/10, step 412/574 completed (loss: 0.02218162827193737, acc: 1.0)
[2024-11-29 03:23:30,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:30,830][root][INFO] - Training Epoch: 7/10, step 413/574 completed (loss: 0.05238794907927513, acc: 0.9696969985961914)
[2024-11-29 03:23:30,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:31,069][root][INFO] - Training Epoch: 7/10, step 414/574 completed (loss: 0.010627462528645992, acc: 1.0)
[2024-11-29 03:23:31,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:31,318][root][INFO] - Training Epoch: 7/10, step 415/574 completed (loss: 0.5132409930229187, acc: 0.8627451062202454)
[2024-11-29 03:23:31,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:31,555][root][INFO] - Training Epoch: 7/10, step 416/574 completed (loss: 0.07544466108083725, acc: 0.9615384340286255)
[2024-11-29 03:23:32,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:32,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:32,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:33,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:33,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:33,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:33,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:34,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:34,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:34,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:35,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:35,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:35,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:36,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:36,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:36,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:36,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:37,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:37,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:37,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:38,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:38,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:38,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:38,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:39,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:39,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:39,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:39,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:40,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:40,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:40,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:41,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:41,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:41,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:41,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:41,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:42,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:42,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:42,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:43,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:43,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:43,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:44,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:44,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:44,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:44,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:45,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:45,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:45,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:46,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:46,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:46,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:46,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:47,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:47,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:47,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:47,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:48,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:48,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:48,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:49,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:49,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:49,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:49,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:50,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:50,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:50,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:50,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:51,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:51,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:51,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:52,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:52,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:52,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:52,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:53,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:53,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:53,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:53,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:54,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:54,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:54,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:54,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:55,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:55,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:56,077][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.9663, device='cuda:0') eval_epoch_loss=tensor(1.0873, device='cuda:0') eval_epoch_acc=tensor(0.7597, device='cuda:0')
[2024-11-29 03:23:56,078][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:23:56,078][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:23:56,256][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_7_step_417_loss_1.0873136520385742/model.pt
[2024-11-29 03:23:56,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:56,531][root][INFO] - Training Epoch: 7/10, step 417/574 completed (loss: 0.031867194920778275, acc: 1.0)
[2024-11-29 03:23:56,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:56,776][root][INFO] - Training Epoch: 7/10, step 418/574 completed (loss: 0.04318583011627197, acc: 1.0)
[2024-11-29 03:23:56,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:57,028][root][INFO] - Training Epoch: 7/10, step 419/574 completed (loss: 0.23260588943958282, acc: 0.949999988079071)
[2024-11-29 03:23:57,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:57,268][root][INFO] - Training Epoch: 7/10, step 420/574 completed (loss: 0.02903720550239086, acc: 1.0)
[2024-11-29 03:23:57,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:57,543][root][INFO] - Training Epoch: 7/10, step 421/574 completed (loss: 0.028233008459210396, acc: 1.0)
[2024-11-29 03:23:57,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:57,797][root][INFO] - Training Epoch: 7/10, step 422/574 completed (loss: 0.12623947858810425, acc: 0.96875)
[2024-11-29 03:23:57,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:58,053][root][INFO] - Training Epoch: 7/10, step 423/574 completed (loss: 0.14599213004112244, acc: 0.9444444179534912)
[2024-11-29 03:23:58,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:58,300][root][INFO] - Training Epoch: 7/10, step 424/574 completed (loss: 0.15289701521396637, acc: 0.9629629850387573)
[2024-11-29 03:23:58,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:58,531][root][INFO] - Training Epoch: 7/10, step 425/574 completed (loss: 0.1487000733613968, acc: 0.9696969985961914)
[2024-11-29 03:23:58,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:58,773][root][INFO] - Training Epoch: 7/10, step 426/574 completed (loss: 0.009531928226351738, acc: 1.0)
[2024-11-29 03:23:58,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:59,013][root][INFO] - Training Epoch: 7/10, step 427/574 completed (loss: 0.12311866134405136, acc: 0.9459459185600281)
[2024-11-29 03:23:59,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:59,246][root][INFO] - Training Epoch: 7/10, step 428/574 completed (loss: 0.022088661789894104, acc: 1.0)
[2024-11-29 03:23:59,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:59,494][root][INFO] - Training Epoch: 7/10, step 429/574 completed (loss: 0.010873754508793354, acc: 1.0)
[2024-11-29 03:23:59,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:59,738][root][INFO] - Training Epoch: 7/10, step 430/574 completed (loss: 0.022863540798425674, acc: 1.0)
[2024-11-29 03:23:59,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:00,012][root][INFO] - Training Epoch: 7/10, step 431/574 completed (loss: 0.03159373998641968, acc: 1.0)
[2024-11-29 03:24:00,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:00,224][root][INFO] - Training Epoch: 7/10, step 432/574 completed (loss: 0.009798914194107056, acc: 1.0)
[2024-11-29 03:24:00,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:00,512][root][INFO] - Training Epoch: 7/10, step 433/574 completed (loss: 0.05158758908510208, acc: 1.0)
[2024-11-29 03:24:00,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:00,745][root][INFO] - Training Epoch: 7/10, step 434/574 completed (loss: 0.009401742368936539, acc: 1.0)
[2024-11-29 03:24:00,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:00,974][root][INFO] - Training Epoch: 7/10, step 435/574 completed (loss: 0.05068643391132355, acc: 0.9696969985961914)
[2024-11-29 03:24:01,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:01,225][root][INFO] - Training Epoch: 7/10, step 436/574 completed (loss: 0.15229108929634094, acc: 0.9444444179534912)
[2024-11-29 03:24:01,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:01,466][root][INFO] - Training Epoch: 7/10, step 437/574 completed (loss: 0.07799562811851501, acc: 0.9545454382896423)
[2024-11-29 03:24:01,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:01,711][root][INFO] - Training Epoch: 7/10, step 438/574 completed (loss: 0.003944816533476114, acc: 1.0)
[2024-11-29 03:24:01,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:01,927][root][INFO] - Training Epoch: 7/10, step 439/574 completed (loss: 0.06081746891140938, acc: 0.9743589758872986)
[2024-11-29 03:24:02,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:02,298][root][INFO] - Training Epoch: 7/10, step 440/574 completed (loss: 0.28148719668388367, acc: 0.8939393758773804)
[2024-11-29 03:24:02,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:02,987][root][INFO] - Training Epoch: 7/10, step 441/574 completed (loss: 0.7357286214828491, acc: 0.7919999957084656)
[2024-11-29 03:24:03,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:03,293][root][INFO] - Training Epoch: 7/10, step 442/574 completed (loss: 0.6932266354560852, acc: 0.7983871102333069)
[2024-11-29 03:24:03,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:03,850][root][INFO] - Training Epoch: 7/10, step 443/574 completed (loss: 0.5685359835624695, acc: 0.8358209133148193)
[2024-11-29 03:24:03,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:04,080][root][INFO] - Training Epoch: 7/10, step 444/574 completed (loss: 0.1938067376613617, acc: 0.9245283007621765)
[2024-11-29 03:24:04,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:04,400][root][INFO] - Training Epoch: 7/10, step 445/574 completed (loss: 0.031093530356884003, acc: 1.0)
[2024-11-29 03:24:04,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:04,621][root][INFO] - Training Epoch: 7/10, step 446/574 completed (loss: 0.2411993443965912, acc: 0.8695651888847351)
[2024-11-29 03:24:04,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:04,894][root][INFO] - Training Epoch: 7/10, step 447/574 completed (loss: 0.14703935384750366, acc: 0.9615384340286255)
[2024-11-29 03:24:05,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:05,161][root][INFO] - Training Epoch: 7/10, step 448/574 completed (loss: 0.16689595580101013, acc: 0.9642857313156128)
[2024-11-29 03:24:05,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:05,362][root][INFO] - Training Epoch: 7/10, step 449/574 completed (loss: 0.08604007214307785, acc: 0.9850746393203735)
[2024-11-29 03:24:05,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:05,613][root][INFO] - Training Epoch: 7/10, step 450/574 completed (loss: 0.09976013004779816, acc: 0.9722222089767456)
[2024-11-29 03:24:05,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:05,879][root][INFO] - Training Epoch: 7/10, step 451/574 completed (loss: 0.048708755522966385, acc: 1.0)
[2024-11-29 03:24:06,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:06,138][root][INFO] - Training Epoch: 7/10, step 452/574 completed (loss: 0.13457047939300537, acc: 0.9358974099159241)
[2024-11-29 03:24:06,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:06,378][root][INFO] - Training Epoch: 7/10, step 453/574 completed (loss: 0.46217450499534607, acc: 0.9078947305679321)
[2024-11-29 03:24:06,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:06,654][root][INFO] - Training Epoch: 7/10, step 454/574 completed (loss: 0.1329258680343628, acc: 0.9387755393981934)
[2024-11-29 03:24:06,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:06,892][root][INFO] - Training Epoch: 7/10, step 455/574 completed (loss: 0.3937074840068817, acc: 0.8787878751754761)
[2024-11-29 03:24:06,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:07,129][root][INFO] - Training Epoch: 7/10, step 456/574 completed (loss: 0.44289344549179077, acc: 0.8865979313850403)
[2024-11-29 03:24:07,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:07,329][root][INFO] - Training Epoch: 7/10, step 457/574 completed (loss: 0.06929497420787811, acc: 0.9714285731315613)
[2024-11-29 03:24:07,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:07,629][root][INFO] - Training Epoch: 7/10, step 458/574 completed (loss: 0.4757889211177826, acc: 0.8488371968269348)
[2024-11-29 03:24:07,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:07,881][root][INFO] - Training Epoch: 7/10, step 459/574 completed (loss: 0.0828830823302269, acc: 0.9821428656578064)
[2024-11-29 03:24:07,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:08,118][root][INFO] - Training Epoch: 7/10, step 460/574 completed (loss: 0.3977726995944977, acc: 0.8765432238578796)
[2024-11-29 03:24:08,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:08,379][root][INFO] - Training Epoch: 7/10, step 461/574 completed (loss: 0.07885100692510605, acc: 1.0)
[2024-11-29 03:24:08,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:08,655][root][INFO] - Training Epoch: 7/10, step 462/574 completed (loss: 0.08777687698602676, acc: 0.96875)
[2024-11-29 03:24:08,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:08,891][root][INFO] - Training Epoch: 7/10, step 463/574 completed (loss: 0.1331910490989685, acc: 0.9615384340286255)
[2024-11-29 03:24:08,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:09,116][root][INFO] - Training Epoch: 7/10, step 464/574 completed (loss: 0.11383393406867981, acc: 0.97826087474823)
[2024-11-29 03:24:09,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:09,339][root][INFO] - Training Epoch: 7/10, step 465/574 completed (loss: 0.2203056961297989, acc: 0.9285714030265808)
[2024-11-29 03:24:09,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:09,603][root][INFO] - Training Epoch: 7/10, step 466/574 completed (loss: 0.7701533436775208, acc: 0.8192771077156067)
[2024-11-29 03:24:09,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:09,881][root][INFO] - Training Epoch: 7/10, step 467/574 completed (loss: 0.20866093039512634, acc: 0.9459459185600281)
[2024-11-29 03:24:09,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:10,127][root][INFO] - Training Epoch: 7/10, step 468/574 completed (loss: 0.5388585329055786, acc: 0.844660222530365)
[2024-11-29 03:24:10,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:10,340][root][INFO] - Training Epoch: 7/10, step 469/574 completed (loss: 0.6956221461296082, acc: 0.8130081295967102)
[2024-11-29 03:24:10,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:10,534][root][INFO] - Training Epoch: 7/10, step 470/574 completed (loss: 0.07831396907567978, acc: 1.0)
[2024-11-29 03:24:10,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:10,783][root][INFO] - Training Epoch: 7/10, step 471/574 completed (loss: 0.08112587034702301, acc: 1.0)
[2024-11-29 03:24:10,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:11,113][root][INFO] - Training Epoch: 7/10, step 472/574 completed (loss: 0.2856220304965973, acc: 0.8921568393707275)
[2024-11-29 03:24:11,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:11,394][root][INFO] - Training Epoch: 7/10, step 473/574 completed (loss: 0.7976348996162415, acc: 0.7423580884933472)
[2024-11-29 03:24:11,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:11,666][root][INFO] - Training Epoch: 7/10, step 474/574 completed (loss: 0.4155537188053131, acc: 0.8541666865348816)
[2024-11-29 03:24:11,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:11,964][root][INFO] - Training Epoch: 7/10, step 475/574 completed (loss: 0.3122096657752991, acc: 0.907975435256958)
[2024-11-29 03:24:12,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:12,206][root][INFO] - Training Epoch: 7/10, step 476/574 completed (loss: 0.27285924553871155, acc: 0.9280575513839722)
[2024-11-29 03:24:12,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:12,475][root][INFO] - Training Epoch: 7/10, step 477/574 completed (loss: 0.6691147089004517, acc: 0.80402010679245)
[2024-11-29 03:24:12,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:12,715][root][INFO] - Training Epoch: 7/10, step 478/574 completed (loss: 0.13512828946113586, acc: 1.0)
[2024-11-29 03:24:12,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:12,956][root][INFO] - Training Epoch: 7/10, step 479/574 completed (loss: 0.22380925714969635, acc: 0.9090909361839294)
[2024-11-29 03:24:13,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:13,188][root][INFO] - Training Epoch: 7/10, step 480/574 completed (loss: 0.16306661069393158, acc: 0.9629629850387573)
[2024-11-29 03:24:13,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:13,444][root][INFO] - Training Epoch: 7/10, step 481/574 completed (loss: 0.38575154542922974, acc: 0.8999999761581421)
[2024-11-29 03:24:13,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:13,596][root][INFO] - Training Epoch: 7/10, step 482/574 completed (loss: 0.5890057682991028, acc: 0.8500000238418579)
[2024-11-29 03:24:13,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:13,870][root][INFO] - Training Epoch: 7/10, step 483/574 completed (loss: 0.5707467794418335, acc: 0.7586206793785095)
[2024-11-29 03:24:13,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:14,114][root][INFO] - Training Epoch: 7/10, step 484/574 completed (loss: 0.020007161423563957, acc: 1.0)
[2024-11-29 03:24:14,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:14,352][root][INFO] - Training Epoch: 7/10, step 485/574 completed (loss: 0.03994382172822952, acc: 1.0)
[2024-11-29 03:24:14,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:14,600][root][INFO] - Training Epoch: 7/10, step 486/574 completed (loss: 0.8509891033172607, acc: 0.8518518805503845)
[2024-11-29 03:24:14,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:14,872][root][INFO] - Training Epoch: 7/10, step 487/574 completed (loss: 0.8829563856124878, acc: 0.8095238208770752)
[2024-11-29 03:24:14,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:15,132][root][INFO] - Training Epoch: 7/10, step 488/574 completed (loss: 0.17668841779232025, acc: 0.9545454382896423)
[2024-11-29 03:24:15,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:15,407][root][INFO] - Training Epoch: 7/10, step 489/574 completed (loss: 0.6863521933555603, acc: 0.8153846263885498)
[2024-11-29 03:24:15,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:15,611][root][INFO] - Training Epoch: 7/10, step 490/574 completed (loss: 0.07357767224311829, acc: 1.0)
[2024-11-29 03:24:15,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:15,844][root][INFO] - Training Epoch: 7/10, step 491/574 completed (loss: 0.059816185384988785, acc: 1.0)
[2024-11-29 03:24:15,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:16,097][root][INFO] - Training Epoch: 7/10, step 492/574 completed (loss: 0.23348179459571838, acc: 0.9411764740943909)
[2024-11-29 03:24:16,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:16,338][root][INFO] - Training Epoch: 7/10, step 493/574 completed (loss: 0.1970415711402893, acc: 0.931034505367279)
[2024-11-29 03:24:16,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:16,580][root][INFO] - Training Epoch: 7/10, step 494/574 completed (loss: 0.36971187591552734, acc: 0.8421052694320679)
[2024-11-29 03:24:16,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:16,818][root][INFO] - Training Epoch: 7/10, step 495/574 completed (loss: 0.16393856704235077, acc: 0.9473684430122375)
[2024-11-29 03:24:16,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:17,111][root][INFO] - Training Epoch: 7/10, step 496/574 completed (loss: 0.5732170939445496, acc: 0.8214285969734192)
[2024-11-29 03:24:17,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:17,430][root][INFO] - Training Epoch: 7/10, step 497/574 completed (loss: 0.26240116357803345, acc: 0.932584285736084)
[2024-11-29 03:24:17,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:17,737][root][INFO] - Training Epoch: 7/10, step 498/574 completed (loss: 0.4480346441268921, acc: 0.8539325594902039)
[2024-11-29 03:24:17,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:17,992][root][INFO] - Training Epoch: 7/10, step 499/574 completed (loss: 1.1741094589233398, acc: 0.6666666865348816)
[2024-11-29 03:24:18,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:18,258][root][INFO] - Training Epoch: 7/10, step 500/574 completed (loss: 0.6250178813934326, acc: 0.8586956262588501)
[2024-11-29 03:24:18,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:18,493][root][INFO] - Training Epoch: 7/10, step 501/574 completed (loss: 0.03424317389726639, acc: 1.0)
[2024-11-29 03:24:18,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:18,735][root][INFO] - Training Epoch: 7/10, step 502/574 completed (loss: 0.09061116725206375, acc: 0.9615384340286255)
[2024-11-29 03:24:18,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:18,993][root][INFO] - Training Epoch: 7/10, step 503/574 completed (loss: 0.2825067341327667, acc: 0.9259259104728699)
[2024-11-29 03:24:19,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:19,235][root][INFO] - Training Epoch: 7/10, step 504/574 completed (loss: 0.04511859640479088, acc: 1.0)
[2024-11-29 03:24:19,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:19,489][root][INFO] - Training Epoch: 7/10, step 505/574 completed (loss: 0.5344730019569397, acc: 0.849056601524353)
[2024-11-29 03:24:19,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:19,735][root][INFO] - Training Epoch: 7/10, step 506/574 completed (loss: 0.9079766869544983, acc: 0.8620689511299133)
[2024-11-29 03:24:19,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:20,250][root][INFO] - Training Epoch: 7/10, step 507/574 completed (loss: 1.0068902969360352, acc: 0.7477477192878723)
[2024-11-29 03:24:20,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:20,595][root][INFO] - Training Epoch: 7/10, step 508/574 completed (loss: 0.6877709627151489, acc: 0.8450704216957092)
[2024-11-29 03:24:20,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:20,832][root][INFO] - Training Epoch: 7/10, step 509/574 completed (loss: 0.208640456199646, acc: 0.8999999761581421)
[2024-11-29 03:24:20,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:21,104][root][INFO] - Training Epoch: 7/10, step 510/574 completed (loss: 0.08597378432750702, acc: 0.9666666388511658)
[2024-11-29 03:24:21,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:21,330][root][INFO] - Training Epoch: 7/10, step 511/574 completed (loss: 0.2919430434703827, acc: 0.9230769276618958)
[2024-11-29 03:24:22,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:23,803][root][INFO] - Training Epoch: 7/10, step 512/574 completed (loss: 1.3405792713165283, acc: 0.6499999761581421)
[2024-11-29 03:24:24,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:24,502][root][INFO] - Training Epoch: 7/10, step 513/574 completed (loss: 0.219247967004776, acc: 0.9523809552192688)
[2024-11-29 03:24:24,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:24,673][root][INFO] - Training Epoch: 7/10, step 514/574 completed (loss: 0.43975335359573364, acc: 0.8571428656578064)
[2024-11-29 03:24:24,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:24,892][root][INFO] - Training Epoch: 7/10, step 515/574 completed (loss: 0.08285676687955856, acc: 0.949999988079071)
[2024-11-29 03:24:25,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:25,515][root][INFO] - Training Epoch: 7/10, step 516/574 completed (loss: 0.492605060338974, acc: 0.9166666865348816)
[2024-11-29 03:24:25,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:25,695][root][INFO] - Training Epoch: 7/10, step 517/574 completed (loss: 0.010721229948103428, acc: 1.0)
[2024-11-29 03:24:25,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:25,866][root][INFO] - Training Epoch: 7/10, step 518/574 completed (loss: 0.1634293645620346, acc: 0.9354838728904724)
[2024-11-29 03:24:25,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:26,063][root][INFO] - Training Epoch: 7/10, step 519/574 completed (loss: 0.08116722851991653, acc: 1.0)
[2024-11-29 03:24:26,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:26,286][root][INFO] - Training Epoch: 7/10, step 520/574 completed (loss: 0.04572892561554909, acc: 1.0)
[2024-11-29 03:24:26,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:27,205][root][INFO] - Training Epoch: 7/10, step 521/574 completed (loss: 0.7469404935836792, acc: 0.7881355881690979)
[2024-11-29 03:24:27,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:27,480][root][INFO] - Training Epoch: 7/10, step 522/574 completed (loss: 0.2695769965648651, acc: 0.9104477763175964)
[2024-11-29 03:24:27,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:27,754][root][INFO] - Training Epoch: 7/10, step 523/574 completed (loss: 0.2657893896102905, acc: 0.9270073175430298)
[2024-11-29 03:24:27,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:28,223][root][INFO] - Training Epoch: 7/10, step 524/574 completed (loss: 0.6095121502876282, acc: 0.8299999833106995)
[2024-11-29 03:24:28,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:28,449][root][INFO] - Training Epoch: 7/10, step 525/574 completed (loss: 0.12362905591726303, acc: 0.9814814925193787)
[2024-11-29 03:24:28,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:28,676][root][INFO] - Training Epoch: 7/10, step 526/574 completed (loss: 0.1682332158088684, acc: 0.9615384340286255)
[2024-11-29 03:24:28,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:28,906][root][INFO] - Training Epoch: 7/10, step 527/574 completed (loss: 0.12004340440034866, acc: 0.9523809552192688)
[2024-11-29 03:24:29,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:29,166][root][INFO] - Training Epoch: 7/10, step 528/574 completed (loss: 1.2535195350646973, acc: 0.688524603843689)
[2024-11-29 03:24:29,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:29,408][root][INFO] - Training Epoch: 7/10, step 529/574 completed (loss: 0.19136975705623627, acc: 0.9661017060279846)
[2024-11-29 03:24:29,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:29,647][root][INFO] - Training Epoch: 7/10, step 530/574 completed (loss: 1.270166039466858, acc: 0.7209302186965942)
[2024-11-29 03:24:29,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:29,896][root][INFO] - Training Epoch: 7/10, step 531/574 completed (loss: 0.6362525224685669, acc: 0.7727272510528564)
[2024-11-29 03:24:30,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:30,151][root][INFO] - Training Epoch: 7/10, step 532/574 completed (loss: 0.8319830894470215, acc: 0.7924528121948242)
[2024-11-29 03:24:30,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:30,363][root][INFO] - Training Epoch: 7/10, step 533/574 completed (loss: 0.33997029066085815, acc: 0.9090909361839294)
[2024-11-29 03:24:30,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:30,580][root][INFO] - Training Epoch: 7/10, step 534/574 completed (loss: 0.37695538997650146, acc: 0.9200000166893005)
[2024-11-29 03:24:30,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:30,810][root][INFO] - Training Epoch: 7/10, step 535/574 completed (loss: 0.04081802815198898, acc: 1.0)
[2024-11-29 03:24:30,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:31,032][root][INFO] - Training Epoch: 7/10, step 536/574 completed (loss: 0.05775979533791542, acc: 1.0)
[2024-11-29 03:24:31,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:31,336][root][INFO] - Training Epoch: 7/10, step 537/574 completed (loss: 0.4326429069042206, acc: 0.892307698726654)
[2024-11-29 03:24:31,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:31,558][root][INFO] - Training Epoch: 7/10, step 538/574 completed (loss: 0.4503175914287567, acc: 0.890625)
[2024-11-29 03:24:31,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:31,841][root][INFO] - Training Epoch: 7/10, step 539/574 completed (loss: 0.2634088397026062, acc: 0.90625)
[2024-11-29 03:24:31,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:32,028][root][INFO] - Training Epoch: 7/10, step 540/574 completed (loss: 0.8706396222114563, acc: 0.7575757503509521)
[2024-11-29 03:24:32,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:32,243][root][INFO] - Training Epoch: 7/10, step 541/574 completed (loss: 0.05913575366139412, acc: 1.0)
[2024-11-29 03:24:32,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:32,476][root][INFO] - Training Epoch: 7/10, step 542/574 completed (loss: 0.02511480078101158, acc: 1.0)
[2024-11-29 03:24:32,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:32,698][root][INFO] - Training Epoch: 7/10, step 543/574 completed (loss: 0.0343838706612587, acc: 1.0)
[2024-11-29 03:24:32,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:32,915][root][INFO] - Training Epoch: 7/10, step 544/574 completed (loss: 0.05470286309719086, acc: 1.0)
[2024-11-29 03:24:33,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:33,134][root][INFO] - Training Epoch: 7/10, step 545/574 completed (loss: 0.035237837582826614, acc: 1.0)
[2024-11-29 03:24:33,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:33,370][root][INFO] - Training Epoch: 7/10, step 546/574 completed (loss: 0.033194541931152344, acc: 1.0)
[2024-11-29 03:24:33,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:33,610][root][INFO] - Training Epoch: 7/10, step 547/574 completed (loss: 0.04215029999613762, acc: 1.0)
[2024-11-29 03:24:33,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:33,844][root][INFO] - Training Epoch: 7/10, step 548/574 completed (loss: 0.09796168655157089, acc: 0.9354838728904724)
[2024-11-29 03:24:33,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:34,078][root][INFO] - Training Epoch: 7/10, step 549/574 completed (loss: 0.015273861587047577, acc: 1.0)
[2024-11-29 03:24:34,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:34,313][root][INFO] - Training Epoch: 7/10, step 550/574 completed (loss: 0.10777907818555832, acc: 0.9696969985961914)
[2024-11-29 03:24:34,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:34,538][root][INFO] - Training Epoch: 7/10, step 551/574 completed (loss: 0.1303466409444809, acc: 0.9750000238418579)
[2024-11-29 03:24:34,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:34,783][root][INFO] - Training Epoch: 7/10, step 552/574 completed (loss: 0.03805667161941528, acc: 1.0)
[2024-11-29 03:24:34,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:35,026][root][INFO] - Training Epoch: 7/10, step 553/574 completed (loss: 0.40713170170783997, acc: 0.8832116723060608)
[2024-11-29 03:24:35,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:35,275][root][INFO] - Training Epoch: 7/10, step 554/574 completed (loss: 0.23725230991840363, acc: 0.9379310607910156)
[2024-11-29 03:24:35,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:35,490][root][INFO] - Training Epoch: 7/10, step 555/574 completed (loss: 0.4134967625141144, acc: 0.8857142925262451)
[2024-11-29 03:24:35,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:35,729][root][INFO] - Training Epoch: 7/10, step 556/574 completed (loss: 0.4041493535041809, acc: 0.8940397500991821)
[2024-11-29 03:24:35,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:35,953][root][INFO] - Training Epoch: 7/10, step 557/574 completed (loss: 0.12461023777723312, acc: 0.9658119678497314)
[2024-11-29 03:24:36,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:36,162][root][INFO] - Training Epoch: 7/10, step 558/574 completed (loss: 0.08359535038471222, acc: 0.9599999785423279)
[2024-11-29 03:24:36,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:36,385][root][INFO] - Training Epoch: 7/10, step 559/574 completed (loss: 0.04678945988416672, acc: 1.0)
[2024-11-29 03:24:37,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:37,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:37,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:37,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:38,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:38,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:38,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:38,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:39,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:39,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:39,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:40,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:40,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:40,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:41,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:41,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:41,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:42,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:42,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:42,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:42,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:43,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:43,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:43,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:44,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:44,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:44,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:45,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:45,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:45,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:45,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:46,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:46,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:46,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:46,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:47,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:47,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:47,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:47,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:48,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:48,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:48,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:49,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:49,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:49,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:49,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:50,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:50,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:50,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:51,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:51,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:51,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:51,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:52,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:52,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:52,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:53,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:53,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:53,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:53,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:54,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:54,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:54,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:55,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:55,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:55,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:56,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:56,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:56,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:57,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:57,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:57,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:58,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:58,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:58,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:58,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:59,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:59,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:59,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:00,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:00,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:00,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:00,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:01,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:01,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:01,991][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.3297, device='cuda:0') eval_epoch_loss=tensor(1.2029, device='cuda:0') eval_epoch_acc=tensor(0.7490, device='cuda:0')
[2024-11-29 03:25:01,992][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:25:01,992][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:25:02,162][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_7_step_560_loss_1.202867865562439/model.pt
[2024-11-29 03:25:02,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:02,451][root][INFO] - Training Epoch: 7/10, step 560/574 completed (loss: 0.011118496768176556, acc: 1.0)
[2024-11-29 03:25:02,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:02,666][root][INFO] - Training Epoch: 7/10, step 561/574 completed (loss: 0.13797348737716675, acc: 0.9743589758872986)
[2024-11-29 03:25:02,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:02,918][root][INFO] - Training Epoch: 7/10, step 562/574 completed (loss: 0.2784661054611206, acc: 0.8888888955116272)
[2024-11-29 03:25:03,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:03,176][root][INFO] - Training Epoch: 7/10, step 563/574 completed (loss: 0.43659690022468567, acc: 0.9090909361839294)
[2024-11-29 03:25:03,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:03,408][root][INFO] - Training Epoch: 7/10, step 564/574 completed (loss: 0.291525274515152, acc: 0.9166666865348816)
[2024-11-29 03:25:03,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:03,654][root][INFO] - Training Epoch: 7/10, step 565/574 completed (loss: 0.5462385416030884, acc: 0.8620689511299133)
[2024-11-29 03:25:03,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:03,886][root][INFO] - Training Epoch: 7/10, step 566/574 completed (loss: 0.13623006641864777, acc: 0.9404761791229248)
[2024-11-29 03:25:04,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:04,149][root][INFO] - Training Epoch: 7/10, step 567/574 completed (loss: 0.024387499317526817, acc: 1.0)
[2024-11-29 03:25:04,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:04,377][root][INFO] - Training Epoch: 7/10, step 568/574 completed (loss: 0.010965048335492611, acc: 1.0)
[2024-11-29 03:25:04,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:04,661][root][INFO] - Training Epoch: 7/10, step 569/574 completed (loss: 0.33545970916748047, acc: 0.9144384860992432)
[2024-11-29 03:25:04,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:04,846][root][INFO] - Training Epoch: 7/10, step 570/574 completed (loss: 0.03328775241971016, acc: 1.0)
[2024-11-29 03:25:04,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:05,094][root][INFO] - Training Epoch: 7/10, step 571/574 completed (loss: 0.32876503467559814, acc: 0.9145299196243286)
[2024-11-29 03:25:05,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:05,374][root][INFO] - Training Epoch: 7/10, step 572/574 completed (loss: 0.61878502368927, acc: 0.8163265585899353)
[2024-11-29 03:25:05,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:05,637][root][INFO] - Training Epoch: 7/10, step 573/574 completed (loss: 0.4516451358795166, acc: 0.8553459048271179)
[2024-11-29 03:25:06,148][slam_llm.utils.train_utils][INFO] - Epoch 7: train_perplexity=1.4670, train_epoch_loss=0.3832, epoch time 264.7866622470319s
[2024-11-29 03:25:06,148][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 11 GB
[2024-11-29 03:25:06,148][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-11-29 03:25:06,148][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 11 GB
[2024-11-29 03:25:06,148][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 10
[2024-11-29 03:25:06,148][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:25:06,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:06,823][root][INFO] - Training Epoch: 8/10, step 0/574 completed (loss: 0.01836523972451687, acc: 1.0)
[2024-11-29 03:25:06,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:07,012][root][INFO] - Training Epoch: 8/10, step 1/574 completed (loss: 0.135062575340271, acc: 0.9599999785423279)
[2024-11-29 03:25:07,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:07,226][root][INFO] - Training Epoch: 8/10, step 2/574 completed (loss: 0.3587739169597626, acc: 0.8918918967247009)
[2024-11-29 03:25:07,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:07,481][root][INFO] - Training Epoch: 8/10, step 3/574 completed (loss: 0.2580645680427551, acc: 0.9473684430122375)
[2024-11-29 03:25:07,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:07,699][root][INFO] - Training Epoch: 8/10, step 4/574 completed (loss: 0.2296406328678131, acc: 0.9459459185600281)
[2024-11-29 03:25:07,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:07,944][root][INFO] - Training Epoch: 8/10, step 5/574 completed (loss: 0.03442620858550072, acc: 1.0)
[2024-11-29 03:25:08,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:08,192][root][INFO] - Training Epoch: 8/10, step 6/574 completed (loss: 0.31486204266548157, acc: 0.8979591727256775)
[2024-11-29 03:25:08,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:08,425][root][INFO] - Training Epoch: 8/10, step 7/574 completed (loss: 0.07825952023267746, acc: 0.9666666388511658)
[2024-11-29 03:25:08,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:08,663][root][INFO] - Training Epoch: 8/10, step 8/574 completed (loss: 0.07035892456769943, acc: 1.0)
[2024-11-29 03:25:08,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:08,904][root][INFO] - Training Epoch: 8/10, step 9/574 completed (loss: 0.004819664638489485, acc: 1.0)
[2024-11-29 03:25:09,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:09,144][root][INFO] - Training Epoch: 8/10, step 10/574 completed (loss: 0.03918251395225525, acc: 1.0)
[2024-11-29 03:25:09,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:09,380][root][INFO] - Training Epoch: 8/10, step 11/574 completed (loss: 0.052233293652534485, acc: 1.0)
[2024-11-29 03:25:09,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:09,642][root][INFO] - Training Epoch: 8/10, step 12/574 completed (loss: 0.06629399210214615, acc: 0.9696969985961914)
[2024-11-29 03:25:09,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:09,903][root][INFO] - Training Epoch: 8/10, step 13/574 completed (loss: 0.09598154574632645, acc: 0.97826087474823)
[2024-11-29 03:25:10,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:10,140][root][INFO] - Training Epoch: 8/10, step 14/574 completed (loss: 0.08970312029123306, acc: 0.9803921580314636)
[2024-11-29 03:25:10,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:10,358][root][INFO] - Training Epoch: 8/10, step 15/574 completed (loss: 0.1505286544561386, acc: 0.9387755393981934)
[2024-11-29 03:25:10,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:10,588][root][INFO] - Training Epoch: 8/10, step 16/574 completed (loss: 0.027812981978058815, acc: 1.0)
[2024-11-29 03:25:10,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:10,848][root][INFO] - Training Epoch: 8/10, step 17/574 completed (loss: 0.17745982110500336, acc: 0.9166666865348816)
[2024-11-29 03:25:10,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:11,083][root][INFO] - Training Epoch: 8/10, step 18/574 completed (loss: 0.40855443477630615, acc: 0.8888888955116272)
[2024-11-29 03:25:11,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:11,337][root][INFO] - Training Epoch: 8/10, step 19/574 completed (loss: 0.16972921788692474, acc: 0.9473684430122375)
[2024-11-29 03:25:11,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:11,605][root][INFO] - Training Epoch: 8/10, step 20/574 completed (loss: 0.05144309997558594, acc: 1.0)
[2024-11-29 03:25:11,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:11,841][root][INFO] - Training Epoch: 8/10, step 21/574 completed (loss: 0.13884460926055908, acc: 0.9655172228813171)
[2024-11-29 03:25:11,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:12,031][root][INFO] - Training Epoch: 8/10, step 22/574 completed (loss: 0.261378675699234, acc: 0.9200000166893005)
[2024-11-29 03:25:12,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:12,259][root][INFO] - Training Epoch: 8/10, step 23/574 completed (loss: 0.03241078928112984, acc: 1.0)
[2024-11-29 03:25:12,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:12,447][root][INFO] - Training Epoch: 8/10, step 24/574 completed (loss: 0.030224362388253212, acc: 1.0)
[2024-11-29 03:25:12,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:12,647][root][INFO] - Training Epoch: 8/10, step 25/574 completed (loss: 0.28472498059272766, acc: 0.9056603908538818)
[2024-11-29 03:25:12,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:12,827][root][INFO] - Training Epoch: 8/10, step 26/574 completed (loss: 0.7724811434745789, acc: 0.767123281955719)
[2024-11-29 03:25:13,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:13,947][root][INFO] - Training Epoch: 8/10, step 27/574 completed (loss: 1.1470606327056885, acc: 0.7035573124885559)
[2024-11-29 03:25:14,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:14,113][root][INFO] - Training Epoch: 8/10, step 28/574 completed (loss: 0.22779487073421478, acc: 0.9069767594337463)
[2024-11-29 03:25:14,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:14,331][root][INFO] - Training Epoch: 8/10, step 29/574 completed (loss: 0.40622425079345703, acc: 0.891566276550293)
[2024-11-29 03:25:14,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:14,570][root][INFO] - Training Epoch: 8/10, step 30/574 completed (loss: 0.7326911687850952, acc: 0.8024691343307495)
[2024-11-29 03:25:14,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:14,800][root][INFO] - Training Epoch: 8/10, step 31/574 completed (loss: 0.11801690608263016, acc: 0.9285714030265808)
[2024-11-29 03:25:14,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:15,057][root][INFO] - Training Epoch: 8/10, step 32/574 completed (loss: 0.04646395891904831, acc: 0.9629629850387573)
[2024-11-29 03:25:15,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:15,299][root][INFO] - Training Epoch: 8/10, step 33/574 completed (loss: 0.04172201082110405, acc: 1.0)
[2024-11-29 03:25:15,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:15,556][root][INFO] - Training Epoch: 8/10, step 34/574 completed (loss: 0.3938612937927246, acc: 0.8823529481887817)
[2024-11-29 03:25:15,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:15,807][root][INFO] - Training Epoch: 8/10, step 35/574 completed (loss: 0.1289527267217636, acc: 0.9508196711540222)
[2024-11-29 03:25:15,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:16,044][root][INFO] - Training Epoch: 8/10, step 36/574 completed (loss: 0.43791690468788147, acc: 0.8730158805847168)
[2024-11-29 03:25:16,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:16,259][root][INFO] - Training Epoch: 8/10, step 37/574 completed (loss: 0.35769280791282654, acc: 0.8813559412956238)
[2024-11-29 03:25:16,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:16,525][root][INFO] - Training Epoch: 8/10, step 38/574 completed (loss: 0.28494343161582947, acc: 0.8965517282485962)
[2024-11-29 03:25:16,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:16,772][root][INFO] - Training Epoch: 8/10, step 39/574 completed (loss: 0.34969669580459595, acc: 0.8571428656578064)
[2024-11-29 03:25:16,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:17,017][root][INFO] - Training Epoch: 8/10, step 40/574 completed (loss: 0.3301387429237366, acc: 0.9230769276618958)
[2024-11-29 03:25:17,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:17,300][root][INFO] - Training Epoch: 8/10, step 41/574 completed (loss: 0.3012397885322571, acc: 0.9054054021835327)
[2024-11-29 03:25:17,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:17,535][root][INFO] - Training Epoch: 8/10, step 42/574 completed (loss: 0.6021989583969116, acc: 0.8461538553237915)
[2024-11-29 03:25:17,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:17,876][root][INFO] - Training Epoch: 8/10, step 43/574 completed (loss: 0.5719823837280273, acc: 0.8484848737716675)
[2024-11-29 03:25:18,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:18,181][root][INFO] - Training Epoch: 8/10, step 44/574 completed (loss: 0.29041460156440735, acc: 0.9484536051750183)
[2024-11-29 03:25:18,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:18,475][root][INFO] - Training Epoch: 8/10, step 45/574 completed (loss: 0.4326050579547882, acc: 0.8970588445663452)
[2024-11-29 03:25:18,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:18,731][root][INFO] - Training Epoch: 8/10, step 46/574 completed (loss: 0.07782631367444992, acc: 1.0)
[2024-11-29 03:25:18,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:18,897][root][INFO] - Training Epoch: 8/10, step 47/574 completed (loss: 0.019004888832569122, acc: 1.0)
[2024-11-29 03:25:18,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:19,104][root][INFO] - Training Epoch: 8/10, step 48/574 completed (loss: 0.22916989028453827, acc: 0.9642857313156128)
[2024-11-29 03:25:19,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:19,340][root][INFO] - Training Epoch: 8/10, step 49/574 completed (loss: 0.08042198419570923, acc: 0.9722222089767456)
[2024-11-29 03:25:19,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:19,568][root][INFO] - Training Epoch: 8/10, step 50/574 completed (loss: 0.6559216976165771, acc: 0.8245614171028137)
[2024-11-29 03:25:19,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:19,825][root][INFO] - Training Epoch: 8/10, step 51/574 completed (loss: 0.592315137386322, acc: 0.7777777910232544)
[2024-11-29 03:25:19,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:20,091][root][INFO] - Training Epoch: 8/10, step 52/574 completed (loss: 0.6022381782531738, acc: 0.8028169274330139)
[2024-11-29 03:25:20,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:20,490][root][INFO] - Training Epoch: 8/10, step 53/574 completed (loss: 1.3265377283096313, acc: 0.6466666460037231)
[2024-11-29 03:25:20,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:20,673][root][INFO] - Training Epoch: 8/10, step 54/574 completed (loss: 0.37013691663742065, acc: 0.8108108043670654)
[2024-11-29 03:25:20,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:20,919][root][INFO] - Training Epoch: 8/10, step 55/574 completed (loss: 0.005111414007842541, acc: 1.0)
[2024-11-29 03:25:22,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:23,422][root][INFO] - Training Epoch: 8/10, step 56/574 completed (loss: 1.0518094301223755, acc: 0.703071653842926)
[2024-11-29 03:25:23,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:24,546][root][INFO] - Training Epoch: 8/10, step 57/574 completed (loss: 1.3514026403427124, acc: 0.6383442282676697)
[2024-11-29 03:25:24,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:25,066][root][INFO] - Training Epoch: 8/10, step 58/574 completed (loss: 0.624367356300354, acc: 0.7954545617103577)
[2024-11-29 03:25:25,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:25,539][root][INFO] - Training Epoch: 8/10, step 59/574 completed (loss: 0.41512927412986755, acc: 0.875)
[2024-11-29 03:25:25,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:26,003][root][INFO] - Training Epoch: 8/10, step 60/574 completed (loss: 0.7303072214126587, acc: 0.804347813129425)
[2024-11-29 03:25:26,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:26,317][root][INFO] - Training Epoch: 8/10, step 61/574 completed (loss: 0.6921091675758362, acc: 0.7875000238418579)
[2024-11-29 03:25:26,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:26,575][root][INFO] - Training Epoch: 8/10, step 62/574 completed (loss: 0.26224395632743835, acc: 0.970588207244873)
[2024-11-29 03:25:26,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:26,850][root][INFO] - Training Epoch: 8/10, step 63/574 completed (loss: 0.1259388029575348, acc: 0.9722222089767456)
[2024-11-29 03:25:26,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:27,128][root][INFO] - Training Epoch: 8/10, step 64/574 completed (loss: 0.04248398169875145, acc: 1.0)
[2024-11-29 03:25:27,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:27,405][root][INFO] - Training Epoch: 8/10, step 65/574 completed (loss: 0.018376322463154793, acc: 1.0)
[2024-11-29 03:25:27,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:27,657][root][INFO] - Training Epoch: 8/10, step 66/574 completed (loss: 0.5403499603271484, acc: 0.8392857313156128)
[2024-11-29 03:25:27,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:27,899][root][INFO] - Training Epoch: 8/10, step 67/574 completed (loss: 0.45199301838874817, acc: 0.8999999761581421)
[2024-11-29 03:25:28,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:28,118][root][INFO] - Training Epoch: 8/10, step 68/574 completed (loss: 0.009499731473624706, acc: 1.0)
[2024-11-29 03:25:28,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:28,358][root][INFO] - Training Epoch: 8/10, step 69/574 completed (loss: 0.45858871936798096, acc: 0.8888888955116272)
[2024-11-29 03:25:28,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:28,620][root][INFO] - Training Epoch: 8/10, step 70/574 completed (loss: 0.2871340811252594, acc: 0.9090909361839294)
[2024-11-29 03:25:28,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:28,864][root][INFO] - Training Epoch: 8/10, step 71/574 completed (loss: 0.9371100664138794, acc: 0.7720588445663452)
[2024-11-29 03:25:28,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:29,107][root][INFO] - Training Epoch: 8/10, step 72/574 completed (loss: 0.6061329245567322, acc: 0.841269850730896)
[2024-11-29 03:25:29,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:29,357][root][INFO] - Training Epoch: 8/10, step 73/574 completed (loss: 1.4073072671890259, acc: 0.620512843132019)
[2024-11-29 03:25:29,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:29,636][root][INFO] - Training Epoch: 8/10, step 74/574 completed (loss: 0.7683926224708557, acc: 0.7755101919174194)
[2024-11-29 03:25:29,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:29,867][root][INFO] - Training Epoch: 8/10, step 75/574 completed (loss: 0.8883211016654968, acc: 0.746268630027771)
[2024-11-29 03:25:29,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:30,154][root][INFO] - Training Epoch: 8/10, step 76/574 completed (loss: 1.4667059183120728, acc: 0.5766423344612122)
[2024-11-29 03:25:30,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:30,365][root][INFO] - Training Epoch: 8/10, step 77/574 completed (loss: 0.018244750797748566, acc: 1.0)
[2024-11-29 03:25:30,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:30,591][root][INFO] - Training Epoch: 8/10, step 78/574 completed (loss: 0.1283666044473648, acc: 0.9583333134651184)
[2024-11-29 03:25:30,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:30,810][root][INFO] - Training Epoch: 8/10, step 79/574 completed (loss: 0.03793516755104065, acc: 1.0)
[2024-11-29 03:25:30,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:31,065][root][INFO] - Training Epoch: 8/10, step 80/574 completed (loss: 0.0995565801858902, acc: 0.9615384340286255)
[2024-11-29 03:25:31,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:31,342][root][INFO] - Training Epoch: 8/10, step 81/574 completed (loss: 0.2579808831214905, acc: 0.8846153616905212)
[2024-11-29 03:25:31,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:31,597][root][INFO] - Training Epoch: 8/10, step 82/574 completed (loss: 0.24556609988212585, acc: 0.9038461446762085)
[2024-11-29 03:25:31,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:31,845][root][INFO] - Training Epoch: 8/10, step 83/574 completed (loss: 0.12207981199026108, acc: 1.0)
[2024-11-29 03:25:31,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:32,103][root][INFO] - Training Epoch: 8/10, step 84/574 completed (loss: 0.21048811078071594, acc: 0.9420289993286133)
[2024-11-29 03:25:32,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:32,357][root][INFO] - Training Epoch: 8/10, step 85/574 completed (loss: 0.18614687025547028, acc: 0.9599999785423279)
[2024-11-29 03:25:32,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:32,621][root][INFO] - Training Epoch: 8/10, step 86/574 completed (loss: 0.07164030522108078, acc: 1.0)
[2024-11-29 03:25:32,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:32,988][root][INFO] - Training Epoch: 8/10, step 87/574 completed (loss: 0.5428317785263062, acc: 0.8799999952316284)
[2024-11-29 03:25:33,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:33,252][root][INFO] - Training Epoch: 8/10, step 88/574 completed (loss: 0.9388120174407959, acc: 0.7572815418243408)
[2024-11-29 03:25:33,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:34,262][root][INFO] - Training Epoch: 8/10, step 89/574 completed (loss: 0.8760175108909607, acc: 0.7475728392601013)
[2024-11-29 03:25:34,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:34,958][root][INFO] - Training Epoch: 8/10, step 90/574 completed (loss: 1.3604087829589844, acc: 0.6451612710952759)
[2024-11-29 03:25:35,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:35,638][root][INFO] - Training Epoch: 8/10, step 91/574 completed (loss: 0.990064799785614, acc: 0.7155172228813171)
[2024-11-29 03:25:35,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:36,268][root][INFO] - Training Epoch: 8/10, step 92/574 completed (loss: 0.8226857781410217, acc: 0.7789473533630371)
[2024-11-29 03:25:36,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:37,128][root][INFO] - Training Epoch: 8/10, step 93/574 completed (loss: 1.1073720455169678, acc: 0.7227723002433777)
[2024-11-29 03:25:37,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:37,290][root][INFO] - Training Epoch: 8/10, step 94/574 completed (loss: 0.66471928358078, acc: 0.8225806355476379)
[2024-11-29 03:25:37,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:37,496][root][INFO] - Training Epoch: 8/10, step 95/574 completed (loss: 0.4009592533111572, acc: 0.8695651888847351)
[2024-11-29 03:25:37,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:37,780][root][INFO] - Training Epoch: 8/10, step 96/574 completed (loss: 1.0490772724151611, acc: 0.7310924530029297)
[2024-11-29 03:25:37,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:38,041][root][INFO] - Training Epoch: 8/10, step 97/574 completed (loss: 0.9353257417678833, acc: 0.7211538553237915)
[2024-11-29 03:25:38,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:38,322][root][INFO] - Training Epoch: 8/10, step 98/574 completed (loss: 1.175352931022644, acc: 0.7080292105674744)
[2024-11-29 03:25:38,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:38,593][root][INFO] - Training Epoch: 8/10, step 99/574 completed (loss: 0.6809976100921631, acc: 0.8358209133148193)
[2024-11-29 03:25:38,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:38,839][root][INFO] - Training Epoch: 8/10, step 100/574 completed (loss: 0.12904348969459534, acc: 0.949999988079071)
[2024-11-29 03:25:38,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:39,119][root][INFO] - Training Epoch: 8/10, step 101/574 completed (loss: 0.012434828095138073, acc: 1.0)
[2024-11-29 03:25:39,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:39,379][root][INFO] - Training Epoch: 8/10, step 102/574 completed (loss: 0.022838177159428596, acc: 1.0)
[2024-11-29 03:25:39,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:39,630][root][INFO] - Training Epoch: 8/10, step 103/574 completed (loss: 0.01870592311024666, acc: 1.0)
[2024-11-29 03:25:39,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:39,868][root][INFO] - Training Epoch: 8/10, step 104/574 completed (loss: 0.2979796826839447, acc: 0.931034505367279)
[2024-11-29 03:25:39,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:40,112][root][INFO] - Training Epoch: 8/10, step 105/574 completed (loss: 0.04419195279479027, acc: 0.9767441749572754)
[2024-11-29 03:25:40,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:40,348][root][INFO] - Training Epoch: 8/10, step 106/574 completed (loss: 0.0518069788813591, acc: 1.0)
[2024-11-29 03:25:40,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:40,620][root][INFO] - Training Epoch: 8/10, step 107/574 completed (loss: 0.005420673172920942, acc: 1.0)
[2024-11-29 03:25:40,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:40,865][root][INFO] - Training Epoch: 8/10, step 108/574 completed (loss: 0.004996136762201786, acc: 1.0)
[2024-11-29 03:25:40,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:41,104][root][INFO] - Training Epoch: 8/10, step 109/574 completed (loss: 0.28246554732322693, acc: 0.9523809552192688)
[2024-11-29 03:25:41,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:41,347][root][INFO] - Training Epoch: 8/10, step 110/574 completed (loss: 0.1706823855638504, acc: 0.9692307710647583)
[2024-11-29 03:25:41,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:41,662][root][INFO] - Training Epoch: 8/10, step 111/574 completed (loss: 0.4358663260936737, acc: 0.8421052694320679)
[2024-11-29 03:25:41,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:41,897][root][INFO] - Training Epoch: 8/10, step 112/574 completed (loss: 0.4030078947544098, acc: 0.8771929740905762)
[2024-11-29 03:25:41,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:42,099][root][INFO] - Training Epoch: 8/10, step 113/574 completed (loss: 0.2870076596736908, acc: 0.8974359035491943)
[2024-11-29 03:25:42,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:42,343][root][INFO] - Training Epoch: 8/10, step 114/574 completed (loss: 0.2730146646499634, acc: 0.9387755393981934)
[2024-11-29 03:25:42,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:42,544][root][INFO] - Training Epoch: 8/10, step 115/574 completed (loss: 0.036472152918577194, acc: 1.0)
[2024-11-29 03:25:42,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:42,796][root][INFO] - Training Epoch: 8/10, step 116/574 completed (loss: 0.2162351906299591, acc: 0.9523809552192688)
[2024-11-29 03:25:42,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:43,040][root][INFO] - Training Epoch: 8/10, step 117/574 completed (loss: 0.38005292415618896, acc: 0.8861788511276245)
[2024-11-29 03:25:43,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:43,276][root][INFO] - Training Epoch: 8/10, step 118/574 completed (loss: 0.14773070812225342, acc: 0.9677419066429138)
[2024-11-29 03:25:43,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:44,061][root][INFO] - Training Epoch: 8/10, step 119/574 completed (loss: 0.9563571214675903, acc: 0.73384028673172)
[2024-11-29 03:25:44,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:44,269][root][INFO] - Training Epoch: 8/10, step 120/574 completed (loss: 0.23084816336631775, acc: 0.9066666960716248)
[2024-11-29 03:25:44,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:44,560][root][INFO] - Training Epoch: 8/10, step 121/574 completed (loss: 0.3567160367965698, acc: 0.9038461446762085)
[2024-11-29 03:25:44,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:44,747][root][INFO] - Training Epoch: 8/10, step 122/574 completed (loss: 0.04749364033341408, acc: 0.9583333134651184)
[2024-11-29 03:25:44,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:44,975][root][INFO] - Training Epoch: 8/10, step 123/574 completed (loss: 0.15551313757896423, acc: 1.0)
[2024-11-29 03:25:45,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:45,215][root][INFO] - Training Epoch: 8/10, step 124/574 completed (loss: 1.133947491645813, acc: 0.6748466491699219)
[2024-11-29 03:25:45,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:45,469][root][INFO] - Training Epoch: 8/10, step 125/574 completed (loss: 1.0528398752212524, acc: 0.7083333134651184)
[2024-11-29 03:25:45,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:45,692][root][INFO] - Training Epoch: 8/10, step 126/574 completed (loss: 0.6965400576591492, acc: 0.7749999761581421)
[2024-11-29 03:25:45,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:45,940][root][INFO] - Training Epoch: 8/10, step 127/574 completed (loss: 1.0028387308120728, acc: 0.7202380895614624)
[2024-11-29 03:25:46,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:46,192][root][INFO] - Training Epoch: 8/10, step 128/574 completed (loss: 0.8303623199462891, acc: 0.7743589878082275)
[2024-11-29 03:25:47,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:47,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:47,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:47,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:48,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:48,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:48,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:48,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:49,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:49,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:49,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:49,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:50,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:50,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:50,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:51,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:51,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:51,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:51,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:52,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:52,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:52,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:52,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:53,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:53,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:53,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:53,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:54,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:54,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:54,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:54,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:55,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:55,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:55,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:56,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:56,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:56,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:56,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:57,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:57,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:57,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:58,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:58,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:58,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:58,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:59,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:59,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:59,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:59,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:00,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:00,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:00,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:01,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:01,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:01,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:02,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:02,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:02,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:02,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:03,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:03,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:03,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:04,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:04,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:04,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:05,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:05,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:05,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:06,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:06,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:06,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:07,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:07,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:07,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:07,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:07,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:08,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:08,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:08,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:09,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:09,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:09,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:09,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:10,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:10,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:10,940][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.8808, device='cuda:0') eval_epoch_loss=tensor(1.0581, device='cuda:0') eval_epoch_acc=tensor(0.7702, device='cuda:0')
[2024-11-29 03:26:10,941][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:26:10,942][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:26:11,242][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_8_step_129_loss_1.058051586151123/model.pt
[2024-11-29 03:26:11,245][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 8 is 0.7702134251594543
[2024-11-29 03:26:11,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:11,577][root][INFO] - Training Epoch: 8/10, step 129/574 completed (loss: 0.8624810576438904, acc: 0.7647058963775635)
[2024-11-29 03:26:11,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:11,802][root][INFO] - Training Epoch: 8/10, step 130/574 completed (loss: 0.29122084379196167, acc: 0.9230769276618958)
[2024-11-29 03:26:11,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:12,009][root][INFO] - Training Epoch: 8/10, step 131/574 completed (loss: 0.6654667854309082, acc: 0.8695651888847351)
[2024-11-29 03:26:12,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:12,179][root][INFO] - Training Epoch: 8/10, step 132/574 completed (loss: 0.35290220379829407, acc: 0.8125)
[2024-11-29 03:26:12,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:12,445][root][INFO] - Training Epoch: 8/10, step 133/574 completed (loss: 0.12736254930496216, acc: 0.95652174949646)
[2024-11-29 03:26:12,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:12,723][root][INFO] - Training Epoch: 8/10, step 134/574 completed (loss: 0.44021397829055786, acc: 0.8285714387893677)
[2024-11-29 03:26:12,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:13,013][root][INFO] - Training Epoch: 8/10, step 135/574 completed (loss: 0.16626307368278503, acc: 0.9230769276618958)
[2024-11-29 03:26:13,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:13,258][root][INFO] - Training Epoch: 8/10, step 136/574 completed (loss: 0.4045684039592743, acc: 0.8333333134651184)
[2024-11-29 03:26:13,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:13,532][root][INFO] - Training Epoch: 8/10, step 137/574 completed (loss: 0.7657005786895752, acc: 0.800000011920929)
[2024-11-29 03:26:13,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:13,779][root][INFO] - Training Epoch: 8/10, step 138/574 completed (loss: 0.19087858498096466, acc: 0.95652174949646)
[2024-11-29 03:26:13,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:14,008][root][INFO] - Training Epoch: 8/10, step 139/574 completed (loss: 0.2822602689266205, acc: 0.9047619104385376)
[2024-11-29 03:26:14,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:14,217][root][INFO] - Training Epoch: 8/10, step 140/574 completed (loss: 0.11573231965303421, acc: 0.9615384340286255)
[2024-11-29 03:26:14,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:14,483][root][INFO] - Training Epoch: 8/10, step 141/574 completed (loss: 0.08335526287555695, acc: 1.0)
[2024-11-29 03:26:14,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:14,706][root][INFO] - Training Epoch: 8/10, step 142/574 completed (loss: 0.12471289187669754, acc: 0.9459459185600281)
[2024-11-29 03:26:14,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:15,144][root][INFO] - Training Epoch: 8/10, step 143/574 completed (loss: 0.5248845815658569, acc: 0.7982456088066101)
[2024-11-29 03:26:15,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:15,367][root][INFO] - Training Epoch: 8/10, step 144/574 completed (loss: 0.8066930770874023, acc: 0.7686567306518555)
[2024-11-29 03:26:15,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:15,676][root][INFO] - Training Epoch: 8/10, step 145/574 completed (loss: 0.5122312307357788, acc: 0.8775510191917419)
[2024-11-29 03:26:15,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:16,032][root][INFO] - Training Epoch: 8/10, step 146/574 completed (loss: 0.719481348991394, acc: 0.7446808218955994)
[2024-11-29 03:26:16,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:16,288][root][INFO] - Training Epoch: 8/10, step 147/574 completed (loss: 0.42721545696258545, acc: 0.8857142925262451)
[2024-11-29 03:26:16,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:16,527][root][INFO] - Training Epoch: 8/10, step 148/574 completed (loss: 0.20479759573936462, acc: 0.9285714030265808)
[2024-11-29 03:26:16,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:16,768][root][INFO] - Training Epoch: 8/10, step 149/574 completed (loss: 0.2078605741262436, acc: 0.95652174949646)
[2024-11-29 03:26:16,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:16,994][root][INFO] - Training Epoch: 8/10, step 150/574 completed (loss: 0.2636123299598694, acc: 0.8965517282485962)
[2024-11-29 03:26:17,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:17,267][root][INFO] - Training Epoch: 8/10, step 151/574 completed (loss: 0.5545163154602051, acc: 0.8260869383811951)
[2024-11-29 03:26:17,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:17,546][root][INFO] - Training Epoch: 8/10, step 152/574 completed (loss: 0.3416650593280792, acc: 0.8813559412956238)
[2024-11-29 03:26:17,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:17,775][root][INFO] - Training Epoch: 8/10, step 153/574 completed (loss: 0.5562559962272644, acc: 0.8771929740905762)
[2024-11-29 03:26:17,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:18,041][root][INFO] - Training Epoch: 8/10, step 154/574 completed (loss: 0.3853836953639984, acc: 0.8783783912658691)
[2024-11-29 03:26:18,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:18,303][root][INFO] - Training Epoch: 8/10, step 155/574 completed (loss: 0.06782989948987961, acc: 1.0)
[2024-11-29 03:26:18,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:18,527][root][INFO] - Training Epoch: 8/10, step 156/574 completed (loss: 0.3361028730869293, acc: 0.9130434989929199)
[2024-11-29 03:26:18,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:18,795][root][INFO] - Training Epoch: 8/10, step 157/574 completed (loss: 2.6085612773895264, acc: 0.4736842215061188)
[2024-11-29 03:26:19,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:20,456][root][INFO] - Training Epoch: 8/10, step 158/574 completed (loss: 0.9885101318359375, acc: 0.6891891956329346)
[2024-11-29 03:26:20,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:20,660][root][INFO] - Training Epoch: 8/10, step 159/574 completed (loss: 0.9108434319496155, acc: 0.7962962985038757)
[2024-11-29 03:26:20,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:20,992][root][INFO] - Training Epoch: 8/10, step 160/574 completed (loss: 1.4398442506790161, acc: 0.604651153087616)
[2024-11-29 03:26:21,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:21,494][root][INFO] - Training Epoch: 8/10, step 161/574 completed (loss: 1.4883121252059937, acc: 0.6117647290229797)
[2024-11-29 03:26:21,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:21,965][root][INFO] - Training Epoch: 8/10, step 162/574 completed (loss: 1.2453325986862183, acc: 0.6853932738304138)
[2024-11-29 03:26:22,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:22,224][root][INFO] - Training Epoch: 8/10, step 163/574 completed (loss: 0.44648435711860657, acc: 0.8863636255264282)
[2024-11-29 03:26:22,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:22,491][root][INFO] - Training Epoch: 8/10, step 164/574 completed (loss: 0.16161906719207764, acc: 0.9523809552192688)
[2024-11-29 03:26:22,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:22,791][root][INFO] - Training Epoch: 8/10, step 165/574 completed (loss: 1.147220253944397, acc: 0.7241379022598267)
[2024-11-29 03:26:22,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:23,067][root][INFO] - Training Epoch: 8/10, step 166/574 completed (loss: 0.16384504735469818, acc: 0.9795918464660645)
[2024-11-29 03:26:23,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:23,364][root][INFO] - Training Epoch: 8/10, step 167/574 completed (loss: 0.13353079557418823, acc: 0.9800000190734863)
[2024-11-29 03:26:23,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:23,701][root][INFO] - Training Epoch: 8/10, step 168/574 completed (loss: 0.27387475967407227, acc: 0.9027777910232544)
[2024-11-29 03:26:23,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:23,923][root][INFO] - Training Epoch: 8/10, step 169/574 completed (loss: 1.0063587427139282, acc: 0.813725471496582)
[2024-11-29 03:26:24,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:24,899][root][INFO] - Training Epoch: 8/10, step 170/574 completed (loss: 1.1182219982147217, acc: 0.7054794430732727)
[2024-11-29 03:26:24,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:25,081][root][INFO] - Training Epoch: 8/10, step 171/574 completed (loss: 0.11976858228445053, acc: 1.0)
[2024-11-29 03:26:25,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:25,329][root][INFO] - Training Epoch: 8/10, step 172/574 completed (loss: 0.38214242458343506, acc: 0.9629629850387573)
[2024-11-29 03:26:25,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:25,504][root][INFO] - Training Epoch: 8/10, step 173/574 completed (loss: 0.25898048281669617, acc: 0.9285714030265808)
[2024-11-29 03:26:25,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:25,961][root][INFO] - Training Epoch: 8/10, step 174/574 completed (loss: 1.1188344955444336, acc: 0.7345132827758789)
[2024-11-29 03:26:26,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:26,215][root][INFO] - Training Epoch: 8/10, step 175/574 completed (loss: 0.6074182391166687, acc: 0.8260869383811951)
[2024-11-29 03:26:26,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:26,455][root][INFO] - Training Epoch: 8/10, step 176/574 completed (loss: 0.3238344192504883, acc: 0.8977272510528564)
[2024-11-29 03:26:26,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:27,272][root][INFO] - Training Epoch: 8/10, step 177/574 completed (loss: 0.9508845210075378, acc: 0.732824444770813)
[2024-11-29 03:26:27,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:27,848][root][INFO] - Training Epoch: 8/10, step 178/574 completed (loss: 0.9311299920082092, acc: 0.7333333492279053)
[2024-11-29 03:26:27,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:28,106][root][INFO] - Training Epoch: 8/10, step 179/574 completed (loss: 0.3397824168205261, acc: 0.8360655903816223)
[2024-11-29 03:26:28,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:28,363][root][INFO] - Training Epoch: 8/10, step 180/574 completed (loss: 0.015869688242673874, acc: 1.0)
[2024-11-29 03:26:28,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:28,555][root][INFO] - Training Epoch: 8/10, step 181/574 completed (loss: 0.004562553018331528, acc: 1.0)
[2024-11-29 03:26:28,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:28,730][root][INFO] - Training Epoch: 8/10, step 182/574 completed (loss: 0.019696807488799095, acc: 1.0)
[2024-11-29 03:26:28,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:28,915][root][INFO] - Training Epoch: 8/10, step 183/574 completed (loss: 0.2405722737312317, acc: 0.9146341681480408)
[2024-11-29 03:26:29,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:29,151][root][INFO] - Training Epoch: 8/10, step 184/574 completed (loss: 0.784792423248291, acc: 0.8338368535041809)
[2024-11-29 03:26:29,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:29,377][root][INFO] - Training Epoch: 8/10, step 185/574 completed (loss: 0.7659237384796143, acc: 0.7953890562057495)
[2024-11-29 03:26:29,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:29,786][root][INFO] - Training Epoch: 8/10, step 186/574 completed (loss: 0.5685969591140747, acc: 0.8343750238418579)
[2024-11-29 03:26:29,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:30,216][root][INFO] - Training Epoch: 8/10, step 187/574 completed (loss: 0.9586011171340942, acc: 0.7392120361328125)
[2024-11-29 03:26:30,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:30,518][root][INFO] - Training Epoch: 8/10, step 188/574 completed (loss: 0.5942052602767944, acc: 0.8327401876449585)
[2024-11-29 03:26:30,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:30,701][root][INFO] - Training Epoch: 8/10, step 189/574 completed (loss: 0.2703638970851898, acc: 0.8399999737739563)
[2024-11-29 03:26:30,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:31,166][root][INFO] - Training Epoch: 8/10, step 190/574 completed (loss: 0.817221999168396, acc: 0.7209302186965942)
[2024-11-29 03:26:31,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:31,861][root][INFO] - Training Epoch: 8/10, step 191/574 completed (loss: 1.1552538871765137, acc: 0.6904761791229248)
[2024-11-29 03:26:32,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:32,674][root][INFO] - Training Epoch: 8/10, step 192/574 completed (loss: 1.1539626121520996, acc: 0.6515151262283325)
[2024-11-29 03:26:32,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:33,319][root][INFO] - Training Epoch: 8/10, step 193/574 completed (loss: 0.5587174296379089, acc: 0.8823529481887817)
[2024-11-29 03:26:33,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:34,276][root][INFO] - Training Epoch: 8/10, step 194/574 completed (loss: 1.0825971364974976, acc: 0.7037037014961243)
[2024-11-29 03:26:34,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:35,118][root][INFO] - Training Epoch: 8/10, step 195/574 completed (loss: 0.27679410576820374, acc: 0.8709677457809448)
[2024-11-29 03:26:35,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:35,286][root][INFO] - Training Epoch: 8/10, step 196/574 completed (loss: 0.018181011080741882, acc: 1.0)
[2024-11-29 03:26:35,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:35,545][root][INFO] - Training Epoch: 8/10, step 197/574 completed (loss: 0.5286349058151245, acc: 0.8999999761581421)
[2024-11-29 03:26:35,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:35,802][root][INFO] - Training Epoch: 8/10, step 198/574 completed (loss: 0.274650514125824, acc: 0.8970588445663452)
[2024-11-29 03:26:35,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:36,104][root][INFO] - Training Epoch: 8/10, step 199/574 completed (loss: 0.9171721935272217, acc: 0.779411792755127)
[2024-11-29 03:26:36,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:36,355][root][INFO] - Training Epoch: 8/10, step 200/574 completed (loss: 0.7187967300415039, acc: 0.8220338821411133)
[2024-11-29 03:26:36,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:36,613][root][INFO] - Training Epoch: 8/10, step 201/574 completed (loss: 0.6945056915283203, acc: 0.7985074520111084)
[2024-11-29 03:26:36,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:36,885][root][INFO] - Training Epoch: 8/10, step 202/574 completed (loss: 0.9247893691062927, acc: 0.737864077091217)
[2024-11-29 03:26:36,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:37,094][root][INFO] - Training Epoch: 8/10, step 203/574 completed (loss: 0.3754565417766571, acc: 0.9047619104385376)
[2024-11-29 03:26:37,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:37,299][root][INFO] - Training Epoch: 8/10, step 204/574 completed (loss: 0.12254789471626282, acc: 0.9560439586639404)
[2024-11-29 03:26:37,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:37,602][root][INFO] - Training Epoch: 8/10, step 205/574 completed (loss: 0.2996262013912201, acc: 0.9058296084403992)
[2024-11-29 03:26:37,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:37,912][root][INFO] - Training Epoch: 8/10, step 206/574 completed (loss: 0.506443202495575, acc: 0.8661417365074158)
[2024-11-29 03:26:38,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:38,169][root][INFO] - Training Epoch: 8/10, step 207/574 completed (loss: 0.32047897577285767, acc: 0.9051724076271057)
[2024-11-29 03:26:38,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:38,419][root][INFO] - Training Epoch: 8/10, step 208/574 completed (loss: 0.4621904492378235, acc: 0.8659420013427734)
[2024-11-29 03:26:38,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:38,679][root][INFO] - Training Epoch: 8/10, step 209/574 completed (loss: 0.39125460386276245, acc: 0.8832684755325317)
[2024-11-29 03:26:38,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:38,893][root][INFO] - Training Epoch: 8/10, step 210/574 completed (loss: 0.3192645013332367, acc: 0.9347826242446899)
[2024-11-29 03:26:38,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:39,102][root][INFO] - Training Epoch: 8/10, step 211/574 completed (loss: 0.051553986966609955, acc: 1.0)
[2024-11-29 03:26:39,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:39,344][root][INFO] - Training Epoch: 8/10, step 212/574 completed (loss: 0.11957453936338425, acc: 0.9642857313156128)
[2024-11-29 03:26:39,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:39,587][root][INFO] - Training Epoch: 8/10, step 213/574 completed (loss: 0.49862387776374817, acc: 0.8723404407501221)
[2024-11-29 03:26:39,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:40,202][root][INFO] - Training Epoch: 8/10, step 214/574 completed (loss: 0.2612323462963104, acc: 0.9461538195610046)
[2024-11-29 03:26:40,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:40,427][root][INFO] - Training Epoch: 8/10, step 215/574 completed (loss: 0.11919943988323212, acc: 0.9594594836235046)
[2024-11-29 03:26:40,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:40,654][root][INFO] - Training Epoch: 8/10, step 216/574 completed (loss: 0.09443870931863785, acc: 0.9534883499145508)
[2024-11-29 03:26:40,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:41,110][root][INFO] - Training Epoch: 8/10, step 217/574 completed (loss: 0.1383582502603531, acc: 0.9729729890823364)
[2024-11-29 03:26:41,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:41,403][root][INFO] - Training Epoch: 8/10, step 218/574 completed (loss: 0.140100359916687, acc: 0.9555555582046509)
[2024-11-29 03:26:41,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:41,611][root][INFO] - Training Epoch: 8/10, step 219/574 completed (loss: 0.021063251420855522, acc: 1.0)
[2024-11-29 03:26:41,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:41,887][root][INFO] - Training Epoch: 8/10, step 220/574 completed (loss: 0.02499125339090824, acc: 1.0)
[2024-11-29 03:26:42,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:42,143][root][INFO] - Training Epoch: 8/10, step 221/574 completed (loss: 0.06135397404432297, acc: 0.9599999785423279)
[2024-11-29 03:26:42,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:42,392][root][INFO] - Training Epoch: 8/10, step 222/574 completed (loss: 0.4305392801761627, acc: 0.9038461446762085)
[2024-11-29 03:26:42,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:43,086][root][INFO] - Training Epoch: 8/10, step 223/574 completed (loss: 0.4115050435066223, acc: 0.875)
[2024-11-29 03:26:43,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:43,542][root][INFO] - Training Epoch: 8/10, step 224/574 completed (loss: 0.6138851642608643, acc: 0.8465909361839294)
[2024-11-29 03:26:43,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:43,908][root][INFO] - Training Epoch: 8/10, step 225/574 completed (loss: 0.42913803458213806, acc: 0.8829787373542786)
[2024-11-29 03:26:44,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:44,163][root][INFO] - Training Epoch: 8/10, step 226/574 completed (loss: 0.38450899720191956, acc: 0.8679245114326477)
[2024-11-29 03:26:44,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:44,436][root][INFO] - Training Epoch: 8/10, step 227/574 completed (loss: 0.160702183842659, acc: 0.949999988079071)
[2024-11-29 03:26:44,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:44,706][root][INFO] - Training Epoch: 8/10, step 228/574 completed (loss: 0.4896260201931, acc: 0.9069767594337463)
[2024-11-29 03:26:44,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:44,946][root][INFO] - Training Epoch: 8/10, step 229/574 completed (loss: 1.0894882678985596, acc: 0.6666666865348816)
[2024-11-29 03:26:45,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:45,231][root][INFO] - Training Epoch: 8/10, step 230/574 completed (loss: 2.2236757278442383, acc: 0.4842105209827423)
[2024-11-29 03:26:45,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:45,431][root][INFO] - Training Epoch: 8/10, step 231/574 completed (loss: 1.5742443799972534, acc: 0.5333333611488342)
[2024-11-29 03:26:45,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:45,759][root][INFO] - Training Epoch: 8/10, step 232/574 completed (loss: 1.6685898303985596, acc: 0.5944444537162781)
[2024-11-29 03:26:45,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:46,167][root][INFO] - Training Epoch: 8/10, step 233/574 completed (loss: 2.1469199657440186, acc: 0.46330276131629944)
[2024-11-29 03:26:46,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:46,544][root][INFO] - Training Epoch: 8/10, step 234/574 completed (loss: 1.6762741804122925, acc: 0.5769230723381042)
[2024-11-29 03:26:46,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:46,788][root][INFO] - Training Epoch: 8/10, step 235/574 completed (loss: 0.009299583733081818, acc: 1.0)
[2024-11-29 03:26:46,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:46,997][root][INFO] - Training Epoch: 8/10, step 236/574 completed (loss: 0.035648297518491745, acc: 1.0)
[2024-11-29 03:26:47,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:47,245][root][INFO] - Training Epoch: 8/10, step 237/574 completed (loss: 0.1031467393040657, acc: 1.0)
[2024-11-29 03:26:47,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:47,427][root][INFO] - Training Epoch: 8/10, step 238/574 completed (loss: 0.3561776578426361, acc: 0.9259259104728699)
[2024-11-29 03:26:47,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:47,686][root][INFO] - Training Epoch: 8/10, step 239/574 completed (loss: 0.3486748933792114, acc: 0.8857142925262451)
[2024-11-29 03:26:47,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:47,947][root][INFO] - Training Epoch: 8/10, step 240/574 completed (loss: 0.4898391664028168, acc: 0.8636363744735718)
[2024-11-29 03:26:48,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:48,236][root][INFO] - Training Epoch: 8/10, step 241/574 completed (loss: 0.18318939208984375, acc: 0.9545454382896423)
[2024-11-29 03:26:48,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:48,744][root][INFO] - Training Epoch: 8/10, step 242/574 completed (loss: 0.6535604596138, acc: 0.774193525314331)
[2024-11-29 03:26:48,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:49,183][root][INFO] - Training Epoch: 8/10, step 243/574 completed (loss: 0.5357045531272888, acc: 0.8636363744735718)
[2024-11-29 03:26:49,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:49,381][root][INFO] - Training Epoch: 8/10, step 244/574 completed (loss: 0.029631901532411575, acc: 1.0)
[2024-11-29 03:26:49,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:49,604][root][INFO] - Training Epoch: 8/10, step 245/574 completed (loss: 0.5276951193809509, acc: 0.807692289352417)
[2024-11-29 03:26:49,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:49,838][root][INFO] - Training Epoch: 8/10, step 246/574 completed (loss: 0.19607171416282654, acc: 0.9677419066429138)
[2024-11-29 03:26:49,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:50,090][root][INFO] - Training Epoch: 8/10, step 247/574 completed (loss: 0.056013595312833786, acc: 0.949999988079071)
[2024-11-29 03:26:50,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:50,351][root][INFO] - Training Epoch: 8/10, step 248/574 completed (loss: 0.09138061106204987, acc: 0.9729729890823364)
[2024-11-29 03:26:50,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:50,575][root][INFO] - Training Epoch: 8/10, step 249/574 completed (loss: 0.09137861430644989, acc: 0.9729729890823364)
[2024-11-29 03:26:50,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:50,791][root][INFO] - Training Epoch: 8/10, step 250/574 completed (loss: 0.019176514819264412, acc: 1.0)
[2024-11-29 03:26:50,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:51,050][root][INFO] - Training Epoch: 8/10, step 251/574 completed (loss: 0.4040219485759735, acc: 0.8970588445663452)
[2024-11-29 03:26:51,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:51,295][root][INFO] - Training Epoch: 8/10, step 252/574 completed (loss: 0.08228132128715515, acc: 0.9512194991111755)
[2024-11-29 03:26:51,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:51,547][root][INFO] - Training Epoch: 8/10, step 253/574 completed (loss: 0.16410993039608002, acc: 0.9200000166893005)
[2024-11-29 03:26:51,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:51,798][root][INFO] - Training Epoch: 8/10, step 254/574 completed (loss: 0.0233636274933815, acc: 1.0)
[2024-11-29 03:26:51,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:52,061][root][INFO] - Training Epoch: 8/10, step 255/574 completed (loss: 0.04111273214221001, acc: 1.0)
[2024-11-29 03:26:52,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:52,304][root][INFO] - Training Epoch: 8/10, step 256/574 completed (loss: 0.14045895636081696, acc: 0.9473684430122375)
[2024-11-29 03:26:52,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:52,501][root][INFO] - Training Epoch: 8/10, step 257/574 completed (loss: 0.12453930824995041, acc: 0.9428571462631226)
[2024-11-29 03:26:52,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:52,753][root][INFO] - Training Epoch: 8/10, step 258/574 completed (loss: 0.15657129883766174, acc: 0.9473684430122375)
[2024-11-29 03:26:52,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:53,250][root][INFO] - Training Epoch: 8/10, step 259/574 completed (loss: 0.3774281144142151, acc: 0.8867924809455872)
[2024-11-29 03:26:53,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:53,738][root][INFO] - Training Epoch: 8/10, step 260/574 completed (loss: 0.47677913308143616, acc: 0.875)
[2024-11-29 03:26:53,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:53,948][root][INFO] - Training Epoch: 8/10, step 261/574 completed (loss: 0.05206624045968056, acc: 1.0)
[2024-11-29 03:26:54,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:54,200][root][INFO] - Training Epoch: 8/10, step 262/574 completed (loss: 0.17977839708328247, acc: 0.9677419066429138)
[2024-11-29 03:26:54,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:54,498][root][INFO] - Training Epoch: 8/10, step 263/574 completed (loss: 0.7191162705421448, acc: 0.7733333110809326)
[2024-11-29 03:26:54,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:54,719][root][INFO] - Training Epoch: 8/10, step 264/574 completed (loss: 0.7003079056739807, acc: 0.7708333134651184)
[2024-11-29 03:26:54,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:55,501][root][INFO] - Training Epoch: 8/10, step 265/574 completed (loss: 1.0018422603607178, acc: 0.7360000014305115)
[2024-11-29 03:26:55,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:55,708][root][INFO] - Training Epoch: 8/10, step 266/574 completed (loss: 0.7425264716148376, acc: 0.7977527976036072)
[2024-11-29 03:26:55,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:55,956][root][INFO] - Training Epoch: 8/10, step 267/574 completed (loss: 0.5409461259841919, acc: 0.8513513803482056)
[2024-11-29 03:26:56,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:56,314][root][INFO] - Training Epoch: 8/10, step 268/574 completed (loss: 0.312102347612381, acc: 0.8793103694915771)
[2024-11-29 03:26:56,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:56,575][root][INFO] - Training Epoch: 8/10, step 269/574 completed (loss: 0.03905787318944931, acc: 1.0)
[2024-11-29 03:26:56,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:56,825][root][INFO] - Training Epoch: 8/10, step 270/574 completed (loss: 0.026488613337278366, acc: 1.0)
[2024-11-29 03:26:56,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:57,064][root][INFO] - Training Epoch: 8/10, step 271/574 completed (loss: 0.0760742798447609, acc: 0.96875)
[2024-11-29 03:26:57,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:58,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:58,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:58,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:58,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:59,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:59,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:59,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:59,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:00,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:00,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:00,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:01,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:01,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:01,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:01,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:02,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:02,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:02,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:03,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:03,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:03,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:03,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:04,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:04,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:04,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:04,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:05,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:05,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:05,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:06,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:06,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:06,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:06,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:07,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:07,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:07,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:07,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:08,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:08,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:08,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:08,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:09,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:09,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:09,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:09,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:10,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:10,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:10,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:10,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:11,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:11,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:11,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:11,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:11,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:12,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:12,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:12,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:13,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:13,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:13,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:14,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:14,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:14,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:14,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:15,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:15,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:15,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:16,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:16,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:16,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:16,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:17,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:17,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:17,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:17,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:18,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:18,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:18,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:18,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:19,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:19,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:19,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:19,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:20,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:20,769][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.0083, device='cuda:0') eval_epoch_loss=tensor(1.1014, device='cuda:0') eval_epoch_acc=tensor(0.7560, device='cuda:0')
[2024-11-29 03:27:20,771][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:27:20,771][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:27:21,014][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_8_step_272_loss_1.1013915538787842/model.pt
[2024-11-29 03:27:21,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:21,211][root][INFO] - Training Epoch: 8/10, step 272/574 completed (loss: 0.03897843509912491, acc: 1.0)
[2024-11-29 03:27:21,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:21,483][root][INFO] - Training Epoch: 8/10, step 273/574 completed (loss: 0.755576491355896, acc: 0.7333333492279053)
[2024-11-29 03:27:21,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:21,657][root][INFO] - Training Epoch: 8/10, step 274/574 completed (loss: 0.04244494065642357, acc: 1.0)
[2024-11-29 03:27:21,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:21,856][root][INFO] - Training Epoch: 8/10, step 275/574 completed (loss: 0.02917451784014702, acc: 1.0)
[2024-11-29 03:27:21,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:22,130][root][INFO] - Training Epoch: 8/10, step 276/574 completed (loss: 0.06231478229165077, acc: 0.9655172228813171)
[2024-11-29 03:27:22,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:22,428][root][INFO] - Training Epoch: 8/10, step 277/574 completed (loss: 0.02713686041533947, acc: 1.0)
[2024-11-29 03:27:22,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:22,693][root][INFO] - Training Epoch: 8/10, step 278/574 completed (loss: 0.4239223301410675, acc: 0.914893627166748)
[2024-11-29 03:27:22,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:22,976][root][INFO] - Training Epoch: 8/10, step 279/574 completed (loss: 0.22887809574604034, acc: 0.9166666865348816)
[2024-11-29 03:27:23,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:23,241][root][INFO] - Training Epoch: 8/10, step 280/574 completed (loss: 0.03847229480743408, acc: 1.0)
[2024-11-29 03:27:23,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:23,564][root][INFO] - Training Epoch: 8/10, step 281/574 completed (loss: 0.5092810988426208, acc: 0.8674699068069458)
[2024-11-29 03:27:23,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:23,810][root][INFO] - Training Epoch: 8/10, step 282/574 completed (loss: 0.5271885991096497, acc: 0.8518518805503845)
[2024-11-29 03:27:23,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:23,996][root][INFO] - Training Epoch: 8/10, step 283/574 completed (loss: 0.021140040829777718, acc: 1.0)
[2024-11-29 03:27:24,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:24,256][root][INFO] - Training Epoch: 8/10, step 284/574 completed (loss: 0.2446678727865219, acc: 0.9411764740943909)
[2024-11-29 03:27:24,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:24,528][root][INFO] - Training Epoch: 8/10, step 285/574 completed (loss: 0.13212734460830688, acc: 0.9750000238418579)
[2024-11-29 03:27:24,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:24,750][root][INFO] - Training Epoch: 8/10, step 286/574 completed (loss: 0.3392656743526459, acc: 0.9140625)
[2024-11-29 03:27:24,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:24,990][root][INFO] - Training Epoch: 8/10, step 287/574 completed (loss: 0.5726920962333679, acc: 0.8479999899864197)
[2024-11-29 03:27:25,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:25,202][root][INFO] - Training Epoch: 8/10, step 288/574 completed (loss: 0.328169047832489, acc: 0.8681318759918213)
[2024-11-29 03:27:25,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:25,415][root][INFO] - Training Epoch: 8/10, step 289/574 completed (loss: 0.3611219525337219, acc: 0.9006211161613464)
[2024-11-29 03:27:25,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:25,680][root][INFO] - Training Epoch: 8/10, step 290/574 completed (loss: 0.48127490282058716, acc: 0.8814433217048645)
[2024-11-29 03:27:25,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:25,960][root][INFO] - Training Epoch: 8/10, step 291/574 completed (loss: 0.019212180748581886, acc: 1.0)
[2024-11-29 03:27:26,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:26,215][root][INFO] - Training Epoch: 8/10, step 292/574 completed (loss: 0.11225976049900055, acc: 0.976190447807312)
[2024-11-29 03:27:26,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:26,429][root][INFO] - Training Epoch: 8/10, step 293/574 completed (loss: 0.16103233397006989, acc: 0.9655172228813171)
[2024-11-29 03:27:26,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:26,816][root][INFO] - Training Epoch: 8/10, step 294/574 completed (loss: 0.3571085035800934, acc: 0.8909090757369995)
[2024-11-29 03:27:26,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:27,274][root][INFO] - Training Epoch: 8/10, step 295/574 completed (loss: 0.7069741487503052, acc: 0.7886598110198975)
[2024-11-29 03:27:27,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:27,449][root][INFO] - Training Epoch: 8/10, step 296/574 completed (loss: 0.34946417808532715, acc: 0.931034505367279)
[2024-11-29 03:27:27,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:27,707][root][INFO] - Training Epoch: 8/10, step 297/574 completed (loss: 0.06676412373781204, acc: 1.0)
[2024-11-29 03:27:27,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:27,931][root][INFO] - Training Epoch: 8/10, step 298/574 completed (loss: 0.20524385571479797, acc: 0.9210526347160339)
[2024-11-29 03:27:28,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:28,152][root][INFO] - Training Epoch: 8/10, step 299/574 completed (loss: 0.13137897849082947, acc: 0.9642857313156128)
[2024-11-29 03:27:28,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:28,382][root][INFO] - Training Epoch: 8/10, step 300/574 completed (loss: 0.017828000709414482, acc: 1.0)
[2024-11-29 03:27:28,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:28,572][root][INFO] - Training Epoch: 8/10, step 301/574 completed (loss: 0.2843573987483978, acc: 0.9622641801834106)
[2024-11-29 03:27:28,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:28,813][root][INFO] - Training Epoch: 8/10, step 302/574 completed (loss: 0.019678665325045586, acc: 1.0)
[2024-11-29 03:27:28,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:29,053][root][INFO] - Training Epoch: 8/10, step 303/574 completed (loss: 0.04083721712231636, acc: 1.0)
[2024-11-29 03:27:29,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:29,299][root][INFO] - Training Epoch: 8/10, step 304/574 completed (loss: 0.08666777610778809, acc: 0.96875)
[2024-11-29 03:27:29,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:29,539][root][INFO] - Training Epoch: 8/10, step 305/574 completed (loss: 0.3070966303348541, acc: 0.9016393423080444)
[2024-11-29 03:27:29,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:29,733][root][INFO] - Training Epoch: 8/10, step 306/574 completed (loss: 0.19838105142116547, acc: 0.9666666388511658)
[2024-11-29 03:27:29,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:29,901][root][INFO] - Training Epoch: 8/10, step 307/574 completed (loss: 0.004920444451272488, acc: 1.0)
[2024-11-29 03:27:30,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:30,138][root][INFO] - Training Epoch: 8/10, step 308/574 completed (loss: 0.10712119191884995, acc: 0.9420289993286133)
[2024-11-29 03:27:30,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:30,455][root][INFO] - Training Epoch: 8/10, step 309/574 completed (loss: 0.18620102107524872, acc: 0.9583333134651184)
[2024-11-29 03:27:30,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:30,641][root][INFO] - Training Epoch: 8/10, step 310/574 completed (loss: 0.20401878654956818, acc: 0.9397590160369873)
[2024-11-29 03:27:30,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:30,891][root][INFO] - Training Epoch: 8/10, step 311/574 completed (loss: 0.18747492134571075, acc: 0.9615384340286255)
[2024-11-29 03:27:31,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:31,153][root][INFO] - Training Epoch: 8/10, step 312/574 completed (loss: 0.1795881688594818, acc: 0.9591836929321289)
[2024-11-29 03:27:31,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:31,409][root][INFO] - Training Epoch: 8/10, step 313/574 completed (loss: 0.013508540578186512, acc: 1.0)
[2024-11-29 03:27:31,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:31,693][root][INFO] - Training Epoch: 8/10, step 314/574 completed (loss: 0.05637761577963829, acc: 1.0)
[2024-11-29 03:27:31,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:31,990][root][INFO] - Training Epoch: 8/10, step 315/574 completed (loss: 0.029081346467137337, acc: 1.0)
[2024-11-29 03:27:32,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:32,232][root][INFO] - Training Epoch: 8/10, step 316/574 completed (loss: 1.138221025466919, acc: 0.8064516186714172)
[2024-11-29 03:27:32,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:32,499][root][INFO] - Training Epoch: 8/10, step 317/574 completed (loss: 0.140326589345932, acc: 0.9552238583564758)
[2024-11-29 03:27:32,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:32,752][root][INFO] - Training Epoch: 8/10, step 318/574 completed (loss: 0.11160517483949661, acc: 0.9807692170143127)
[2024-11-29 03:27:32,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:33,026][root][INFO] - Training Epoch: 8/10, step 319/574 completed (loss: 0.03687995672225952, acc: 1.0)
[2024-11-29 03:27:33,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:33,299][root][INFO] - Training Epoch: 8/10, step 320/574 completed (loss: 0.0619891881942749, acc: 0.9838709831237793)
[2024-11-29 03:27:33,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:33,556][root][INFO] - Training Epoch: 8/10, step 321/574 completed (loss: 0.013134380802512169, acc: 1.0)
[2024-11-29 03:27:33,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:33,788][root][INFO] - Training Epoch: 8/10, step 322/574 completed (loss: 0.52935791015625, acc: 0.8518518805503845)
[2024-11-29 03:27:33,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:34,013][root][INFO] - Training Epoch: 8/10, step 323/574 completed (loss: 0.8585885763168335, acc: 0.800000011920929)
[2024-11-29 03:27:34,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:34,261][root][INFO] - Training Epoch: 8/10, step 324/574 completed (loss: 0.7651340961456299, acc: 0.7948718070983887)
[2024-11-29 03:27:34,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:34,492][root][INFO] - Training Epoch: 8/10, step 325/574 completed (loss: 1.1451504230499268, acc: 0.707317054271698)
[2024-11-29 03:27:34,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:34,761][root][INFO] - Training Epoch: 8/10, step 326/574 completed (loss: 0.43442007899284363, acc: 0.9210526347160339)
[2024-11-29 03:27:34,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:35,008][root][INFO] - Training Epoch: 8/10, step 327/574 completed (loss: 0.21252140402793884, acc: 0.9473684430122375)
[2024-11-29 03:27:35,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:35,282][root][INFO] - Training Epoch: 8/10, step 328/574 completed (loss: 0.010105259716510773, acc: 1.0)
[2024-11-29 03:27:35,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:35,497][root][INFO] - Training Epoch: 8/10, step 329/574 completed (loss: 0.020297488197684288, acc: 1.0)
[2024-11-29 03:27:35,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:35,729][root][INFO] - Training Epoch: 8/10, step 330/574 completed (loss: 0.008304289542138577, acc: 1.0)
[2024-11-29 03:27:35,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:35,997][root][INFO] - Training Epoch: 8/10, step 331/574 completed (loss: 0.14072811603546143, acc: 0.9516128897666931)
[2024-11-29 03:27:36,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:36,292][root][INFO] - Training Epoch: 8/10, step 332/574 completed (loss: 0.18958555161952972, acc: 0.9824561476707458)
[2024-11-29 03:27:36,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:36,547][root][INFO] - Training Epoch: 8/10, step 333/574 completed (loss: 0.44773590564727783, acc: 0.9375)
[2024-11-29 03:27:36,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:36,788][root][INFO] - Training Epoch: 8/10, step 334/574 completed (loss: 0.02064758539199829, acc: 1.0)
[2024-11-29 03:27:36,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:37,013][root][INFO] - Training Epoch: 8/10, step 335/574 completed (loss: 0.18675297498703003, acc: 0.9473684430122375)
[2024-11-29 03:27:37,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:37,239][root][INFO] - Training Epoch: 8/10, step 336/574 completed (loss: 0.6577502489089966, acc: 0.8399999737739563)
[2024-11-29 03:27:37,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:37,469][root][INFO] - Training Epoch: 8/10, step 337/574 completed (loss: 0.8383995890617371, acc: 0.7816091775894165)
[2024-11-29 03:27:37,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:37,727][root][INFO] - Training Epoch: 8/10, step 338/574 completed (loss: 0.9292658567428589, acc: 0.7553191781044006)
[2024-11-29 03:27:37,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:37,983][root][INFO] - Training Epoch: 8/10, step 339/574 completed (loss: 0.8030562996864319, acc: 0.8072289228439331)
[2024-11-29 03:27:38,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:38,228][root][INFO] - Training Epoch: 8/10, step 340/574 completed (loss: 0.05878059193491936, acc: 1.0)
[2024-11-29 03:27:38,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:38,476][root][INFO] - Training Epoch: 8/10, step 341/574 completed (loss: 0.07914528250694275, acc: 1.0)
[2024-11-29 03:27:38,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:38,748][root][INFO] - Training Epoch: 8/10, step 342/574 completed (loss: 0.22796720266342163, acc: 0.9156626462936401)
[2024-11-29 03:27:38,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:39,015][root][INFO] - Training Epoch: 8/10, step 343/574 completed (loss: 0.8029752969741821, acc: 0.8113207817077637)
[2024-11-29 03:27:39,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:39,260][root][INFO] - Training Epoch: 8/10, step 344/574 completed (loss: 0.12928108870983124, acc: 0.9746835231781006)
[2024-11-29 03:27:39,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:39,516][root][INFO] - Training Epoch: 8/10, step 345/574 completed (loss: 0.17480337619781494, acc: 0.9411764740943909)
[2024-11-29 03:27:39,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:39,783][root][INFO] - Training Epoch: 8/10, step 346/574 completed (loss: 0.2692674994468689, acc: 0.89552241563797)
[2024-11-29 03:27:39,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:40,003][root][INFO] - Training Epoch: 8/10, step 347/574 completed (loss: 0.022960003465414047, acc: 1.0)
[2024-11-29 03:27:40,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:40,274][root][INFO] - Training Epoch: 8/10, step 348/574 completed (loss: 0.0783134400844574, acc: 1.0)
[2024-11-29 03:27:40,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:40,608][root][INFO] - Training Epoch: 8/10, step 349/574 completed (loss: 0.5807250738143921, acc: 0.8055555820465088)
[2024-11-29 03:27:40,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:40,907][root][INFO] - Training Epoch: 8/10, step 350/574 completed (loss: 0.3184147775173187, acc: 0.8604651093482971)
[2024-11-29 03:27:41,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:41,168][root][INFO] - Training Epoch: 8/10, step 351/574 completed (loss: 0.23006096482276917, acc: 0.9230769276618958)
[2024-11-29 03:27:41,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:41,443][root][INFO] - Training Epoch: 8/10, step 352/574 completed (loss: 0.35028496384620667, acc: 0.8888888955116272)
[2024-11-29 03:27:41,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:41,712][root][INFO] - Training Epoch: 8/10, step 353/574 completed (loss: 0.015363008715212345, acc: 1.0)
[2024-11-29 03:27:41,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:41,932][root][INFO] - Training Epoch: 8/10, step 354/574 completed (loss: 0.24092534184455872, acc: 0.9615384340286255)
[2024-11-29 03:27:42,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:42,230][root][INFO] - Training Epoch: 8/10, step 355/574 completed (loss: 0.5201622247695923, acc: 0.8021978139877319)
[2024-11-29 03:27:42,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:42,664][root][INFO] - Training Epoch: 8/10, step 356/574 completed (loss: 0.41926607489585876, acc: 0.852173924446106)
[2024-11-29 03:27:42,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:42,902][root][INFO] - Training Epoch: 8/10, step 357/574 completed (loss: 0.301237553358078, acc: 0.9021739363670349)
[2024-11-29 03:27:42,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:43,092][root][INFO] - Training Epoch: 8/10, step 358/574 completed (loss: 0.3069160580635071, acc: 0.8979591727256775)
[2024-11-29 03:27:43,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:43,266][root][INFO] - Training Epoch: 8/10, step 359/574 completed (loss: 0.004624414723366499, acc: 1.0)
[2024-11-29 03:27:43,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:43,419][root][INFO] - Training Epoch: 8/10, step 360/574 completed (loss: 0.03384992852807045, acc: 1.0)
[2024-11-29 03:27:43,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:43,691][root][INFO] - Training Epoch: 8/10, step 361/574 completed (loss: 0.2180148810148239, acc: 0.9268292784690857)
[2024-11-29 03:27:43,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:43,939][root][INFO] - Training Epoch: 8/10, step 362/574 completed (loss: 0.3023114502429962, acc: 0.8888888955116272)
[2024-11-29 03:27:44,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:44,185][root][INFO] - Training Epoch: 8/10, step 363/574 completed (loss: 0.06237621605396271, acc: 0.9868420958518982)
[2024-11-29 03:27:44,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:44,422][root][INFO] - Training Epoch: 8/10, step 364/574 completed (loss: 0.01625865139067173, acc: 1.0)
[2024-11-29 03:27:44,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:44,649][root][INFO] - Training Epoch: 8/10, step 365/574 completed (loss: 0.01875181868672371, acc: 1.0)
[2024-11-29 03:27:44,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:44,909][root][INFO] - Training Epoch: 8/10, step 366/574 completed (loss: 0.01441717054694891, acc: 1.0)
[2024-11-29 03:27:45,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:45,166][root][INFO] - Training Epoch: 8/10, step 367/574 completed (loss: 0.018320487812161446, acc: 1.0)
[2024-11-29 03:27:45,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:45,406][root][INFO] - Training Epoch: 8/10, step 368/574 completed (loss: 0.020365511998534203, acc: 1.0)
[2024-11-29 03:27:45,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:45,664][root][INFO] - Training Epoch: 8/10, step 369/574 completed (loss: 0.8453484177589417, acc: 0.8125)
[2024-11-29 03:27:45,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:46,200][root][INFO] - Training Epoch: 8/10, step 370/574 completed (loss: 0.6404191255569458, acc: 0.8363636136054993)
[2024-11-29 03:27:46,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:46,987][root][INFO] - Training Epoch: 8/10, step 371/574 completed (loss: 0.32349565625190735, acc: 0.9056603908538818)
[2024-11-29 03:27:47,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:47,209][root][INFO] - Training Epoch: 8/10, step 372/574 completed (loss: 0.24188491702079773, acc: 0.9444444179534912)
[2024-11-29 03:27:47,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:47,465][root][INFO] - Training Epoch: 8/10, step 373/574 completed (loss: 0.06653621792793274, acc: 0.9642857313156128)
[2024-11-29 03:27:47,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:47,729][root][INFO] - Training Epoch: 8/10, step 374/574 completed (loss: 0.05835334211587906, acc: 1.0)
[2024-11-29 03:27:47,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:47,977][root][INFO] - Training Epoch: 8/10, step 375/574 completed (loss: 0.06189092993736267, acc: 0.9599999785423279)
[2024-11-29 03:27:48,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:48,209][root][INFO] - Training Epoch: 8/10, step 376/574 completed (loss: 0.0031383971218019724, acc: 1.0)
[2024-11-29 03:27:48,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:48,452][root][INFO] - Training Epoch: 8/10, step 377/574 completed (loss: 0.06714439392089844, acc: 0.9791666865348816)
[2024-11-29 03:27:48,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:48,732][root][INFO] - Training Epoch: 8/10, step 378/574 completed (loss: 0.07919519394636154, acc: 0.9578947424888611)
[2024-11-29 03:27:48,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:49,250][root][INFO] - Training Epoch: 8/10, step 379/574 completed (loss: 0.2690216600894928, acc: 0.9281437397003174)
[2024-11-29 03:27:49,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:49,551][root][INFO] - Training Epoch: 8/10, step 380/574 completed (loss: 0.20382985472679138, acc: 0.9398496150970459)
[2024-11-29 03:27:50,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:50,673][root][INFO] - Training Epoch: 8/10, step 381/574 completed (loss: 0.6896786689758301, acc: 0.8181818127632141)
[2024-11-29 03:27:50,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:51,147][root][INFO] - Training Epoch: 8/10, step 382/574 completed (loss: 0.115887351334095, acc: 0.9729729890823364)
[2024-11-29 03:27:51,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:51,367][root][INFO] - Training Epoch: 8/10, step 383/574 completed (loss: 0.059587229043245316, acc: 1.0)
[2024-11-29 03:27:51,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:51,595][root][INFO] - Training Epoch: 8/10, step 384/574 completed (loss: 0.012211124412715435, acc: 1.0)
[2024-11-29 03:27:51,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:51,789][root][INFO] - Training Epoch: 8/10, step 385/574 completed (loss: 0.0626211166381836, acc: 0.96875)
[2024-11-29 03:27:51,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:52,013][root][INFO] - Training Epoch: 8/10, step 386/574 completed (loss: 0.017769411206245422, acc: 1.0)
[2024-11-29 03:27:52,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:52,258][root][INFO] - Training Epoch: 8/10, step 387/574 completed (loss: 0.08292314410209656, acc: 0.9736841917037964)
[2024-11-29 03:27:52,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:52,496][root][INFO] - Training Epoch: 8/10, step 388/574 completed (loss: 0.03288373351097107, acc: 1.0)
[2024-11-29 03:27:52,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:52,766][root][INFO] - Training Epoch: 8/10, step 389/574 completed (loss: 0.07812458276748657, acc: 1.0)
[2024-11-29 03:27:52,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:53,004][root][INFO] - Training Epoch: 8/10, step 390/574 completed (loss: 0.15519802272319794, acc: 0.9523809552192688)
[2024-11-29 03:27:53,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:53,292][root][INFO] - Training Epoch: 8/10, step 391/574 completed (loss: 0.5487794280052185, acc: 0.8518518805503845)
[2024-11-29 03:27:53,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:53,546][root][INFO] - Training Epoch: 8/10, step 392/574 completed (loss: 0.5480685830116272, acc: 0.844660222530365)
[2024-11-29 03:27:53,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:53,978][root][INFO] - Training Epoch: 8/10, step 393/574 completed (loss: 0.679506778717041, acc: 0.8308823704719543)
[2024-11-29 03:27:54,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:54,241][root][INFO] - Training Epoch: 8/10, step 394/574 completed (loss: 0.5486103892326355, acc: 0.8266666531562805)
[2024-11-29 03:27:54,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:54,527][root][INFO] - Training Epoch: 8/10, step 395/574 completed (loss: 0.43247300386428833, acc: 0.875)
[2024-11-29 03:27:54,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:54,719][root][INFO] - Training Epoch: 8/10, step 396/574 completed (loss: 0.04745887219905853, acc: 1.0)
[2024-11-29 03:27:54,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:54,975][root][INFO] - Training Epoch: 8/10, step 397/574 completed (loss: 0.058969032019376755, acc: 1.0)
[2024-11-29 03:27:55,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:55,198][root][INFO] - Training Epoch: 8/10, step 398/574 completed (loss: 0.40934500098228455, acc: 0.9069767594337463)
[2024-11-29 03:27:55,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:55,371][root][INFO] - Training Epoch: 8/10, step 399/574 completed (loss: 0.011784505099058151, acc: 1.0)
[2024-11-29 03:27:55,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:55,819][root][INFO] - Training Epoch: 8/10, step 400/574 completed (loss: 0.20282220840454102, acc: 0.9264705777168274)
[2024-11-29 03:27:55,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:56,054][root][INFO] - Training Epoch: 8/10, step 401/574 completed (loss: 0.19248585402965546, acc: 0.9200000166893005)
[2024-11-29 03:27:56,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:56,291][root][INFO] - Training Epoch: 8/10, step 402/574 completed (loss: 0.09367619454860687, acc: 0.9696969985961914)
[2024-11-29 03:27:56,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:56,532][root][INFO] - Training Epoch: 8/10, step 403/574 completed (loss: 0.15870420634746552, acc: 0.9696969985961914)
[2024-11-29 03:27:56,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:56,794][root][INFO] - Training Epoch: 8/10, step 404/574 completed (loss: 0.25077399611473083, acc: 0.9677419066429138)
[2024-11-29 03:27:56,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:57,019][root][INFO] - Training Epoch: 8/10, step 405/574 completed (loss: 0.17629177868366241, acc: 0.9259259104728699)
[2024-11-29 03:27:57,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:57,257][root][INFO] - Training Epoch: 8/10, step 406/574 completed (loss: 0.1198115274310112, acc: 0.9599999785423279)
[2024-11-29 03:27:57,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:57,492][root][INFO] - Training Epoch: 8/10, step 407/574 completed (loss: 0.07119336724281311, acc: 0.9722222089767456)
[2024-11-29 03:27:57,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:57,746][root][INFO] - Training Epoch: 8/10, step 408/574 completed (loss: 0.032019104808568954, acc: 1.0)
[2024-11-29 03:27:57,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:58,010][root][INFO] - Training Epoch: 8/10, step 409/574 completed (loss: 0.017569493502378464, acc: 1.0)
[2024-11-29 03:27:58,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:58,223][root][INFO] - Training Epoch: 8/10, step 410/574 completed (loss: 0.11383312940597534, acc: 0.982758641242981)
[2024-11-29 03:27:58,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:58,465][root][INFO] - Training Epoch: 8/10, step 411/574 completed (loss: 0.017906615510582924, acc: 1.0)
[2024-11-29 03:27:58,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:58,657][root][INFO] - Training Epoch: 8/10, step 412/574 completed (loss: 0.007391316816210747, acc: 1.0)
[2024-11-29 03:27:58,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:58,894][root][INFO] - Training Epoch: 8/10, step 413/574 completed (loss: 0.1496635228395462, acc: 0.939393937587738)
[2024-11-29 03:27:59,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:59,127][root][INFO] - Training Epoch: 8/10, step 414/574 completed (loss: 0.7642711997032166, acc: 0.9090909361839294)
[2024-11-29 03:27:59,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:00,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:00,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:00,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:00,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:01,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:01,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:01,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:01,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:02,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:02,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:02,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:03,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:03,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:03,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:03,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:04,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:04,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:04,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:04,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:05,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:05,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:05,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:06,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:06,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:06,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:06,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:07,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:07,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:07,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:08,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:08,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:08,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:08,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:09,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:09,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:09,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:09,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:10,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:10,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:10,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:11,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:11,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:11,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:11,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:12,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:12,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:12,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:12,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:13,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:13,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:13,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:14,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:14,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:14,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:14,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:15,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:15,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:15,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:15,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:16,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:16,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:16,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:17,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:17,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:17,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:17,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:18,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:18,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:18,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:19,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:19,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:19,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:19,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:20,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:20,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:20,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:20,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:21,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:21,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:21,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:21,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:22,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:22,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:22,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:23,214][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.1719, device='cuda:0') eval_epoch_loss=tensor(1.1543, device='cuda:0') eval_epoch_acc=tensor(0.7523, device='cuda:0')
[2024-11-29 03:28:23,215][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:28:23,215][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:28:23,432][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_8_step_415_loss_1.1543217897415161/model.pt
[2024-11-29 03:28:23,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:23,695][root][INFO] - Training Epoch: 8/10, step 415/574 completed (loss: 0.17188143730163574, acc: 0.9607843160629272)
[2024-11-29 03:28:23,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:23,928][root][INFO] - Training Epoch: 8/10, step 416/574 completed (loss: 0.014271966181695461, acc: 1.0)
[2024-11-29 03:28:24,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:24,189][root][INFO] - Training Epoch: 8/10, step 417/574 completed (loss: 0.0962461456656456, acc: 1.0)
[2024-11-29 03:28:24,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:24,466][root][INFO] - Training Epoch: 8/10, step 418/574 completed (loss: 0.06363829225301743, acc: 0.9750000238418579)
[2024-11-29 03:28:24,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:24,709][root][INFO] - Training Epoch: 8/10, step 419/574 completed (loss: 0.3681284487247467, acc: 0.949999988079071)
[2024-11-29 03:28:24,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:24,966][root][INFO] - Training Epoch: 8/10, step 420/574 completed (loss: 0.0638323426246643, acc: 1.0)
[2024-11-29 03:28:25,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:25,217][root][INFO] - Training Epoch: 8/10, step 421/574 completed (loss: 0.04314908757805824, acc: 1.0)
[2024-11-29 03:28:25,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:25,479][root][INFO] - Training Epoch: 8/10, step 422/574 completed (loss: 0.10430477559566498, acc: 0.96875)
[2024-11-29 03:28:25,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:25,746][root][INFO] - Training Epoch: 8/10, step 423/574 completed (loss: 0.24939033389091492, acc: 0.9166666865348816)
[2024-11-29 03:28:25,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:26,012][root][INFO] - Training Epoch: 8/10, step 424/574 completed (loss: 0.03442985936999321, acc: 1.0)
[2024-11-29 03:28:26,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:26,248][root][INFO] - Training Epoch: 8/10, step 425/574 completed (loss: 0.04548012465238571, acc: 1.0)
[2024-11-29 03:28:26,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:26,502][root][INFO] - Training Epoch: 8/10, step 426/574 completed (loss: 0.031864773482084274, acc: 1.0)
[2024-11-29 03:28:26,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:26,731][root][INFO] - Training Epoch: 8/10, step 427/574 completed (loss: 0.09390262514352798, acc: 0.9729729890823364)
[2024-11-29 03:28:26,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:26,951][root][INFO] - Training Epoch: 8/10, step 428/574 completed (loss: 0.05690617486834526, acc: 1.0)
[2024-11-29 03:28:27,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:27,217][root][INFO] - Training Epoch: 8/10, step 429/574 completed (loss: 0.0150819793343544, acc: 1.0)
[2024-11-29 03:28:27,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:27,465][root][INFO] - Training Epoch: 8/10, step 430/574 completed (loss: 0.012290692888200283, acc: 1.0)
[2024-11-29 03:28:27,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:27,687][root][INFO] - Training Epoch: 8/10, step 431/574 completed (loss: 0.01417237613350153, acc: 1.0)
[2024-11-29 03:28:27,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:27,956][root][INFO] - Training Epoch: 8/10, step 432/574 completed (loss: 0.010922056622803211, acc: 1.0)
[2024-11-29 03:28:28,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:28,219][root][INFO] - Training Epoch: 8/10, step 433/574 completed (loss: 0.044159188866615295, acc: 1.0)
[2024-11-29 03:28:28,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:28,493][root][INFO] - Training Epoch: 8/10, step 434/574 completed (loss: 0.004436391405761242, acc: 1.0)
[2024-11-29 03:28:28,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:28,765][root][INFO] - Training Epoch: 8/10, step 435/574 completed (loss: 0.011083930730819702, acc: 1.0)
[2024-11-29 03:28:28,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:29,058][root][INFO] - Training Epoch: 8/10, step 436/574 completed (loss: 0.06009689345955849, acc: 1.0)
[2024-11-29 03:28:29,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:29,330][root][INFO] - Training Epoch: 8/10, step 437/574 completed (loss: 0.06620814651250839, acc: 0.9772727489471436)
[2024-11-29 03:28:29,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:29,588][root][INFO] - Training Epoch: 8/10, step 438/574 completed (loss: 0.012223105877637863, acc: 1.0)
[2024-11-29 03:28:29,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:29,822][root][INFO] - Training Epoch: 8/10, step 439/574 completed (loss: 0.03697465360164642, acc: 1.0)
[2024-11-29 03:28:29,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:30,184][root][INFO] - Training Epoch: 8/10, step 440/574 completed (loss: 0.2675746977329254, acc: 0.9242424368858337)
[2024-11-29 03:28:30,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:30,817][root][INFO] - Training Epoch: 8/10, step 441/574 completed (loss: 0.6286670565605164, acc: 0.8560000061988831)
[2024-11-29 03:28:30,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:31,118][root][INFO] - Training Epoch: 8/10, step 442/574 completed (loss: 0.57350754737854, acc: 0.8387096524238586)
[2024-11-29 03:28:31,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:31,674][root][INFO] - Training Epoch: 8/10, step 443/574 completed (loss: 0.5781062841415405, acc: 0.8258706331253052)
[2024-11-29 03:28:31,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:31,835][root][INFO] - Training Epoch: 8/10, step 444/574 completed (loss: 0.2057373821735382, acc: 0.9433962106704712)
[2024-11-29 03:28:31,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:32,155][root][INFO] - Training Epoch: 8/10, step 445/574 completed (loss: 0.03151485696434975, acc: 1.0)
[2024-11-29 03:28:32,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:32,386][root][INFO] - Training Epoch: 8/10, step 446/574 completed (loss: 0.0336831733584404, acc: 1.0)
[2024-11-29 03:28:32,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:32,663][root][INFO] - Training Epoch: 8/10, step 447/574 completed (loss: 0.10524223744869232, acc: 0.9615384340286255)
[2024-11-29 03:28:32,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:32,943][root][INFO] - Training Epoch: 8/10, step 448/574 completed (loss: 0.08476469665765762, acc: 0.9642857313156128)
[2024-11-29 03:28:33,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:33,171][root][INFO] - Training Epoch: 8/10, step 449/574 completed (loss: 0.09514927864074707, acc: 0.9701492786407471)
[2024-11-29 03:28:33,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:33,388][root][INFO] - Training Epoch: 8/10, step 450/574 completed (loss: 0.018449893221259117, acc: 1.0)
[2024-11-29 03:28:33,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:33,626][root][INFO] - Training Epoch: 8/10, step 451/574 completed (loss: 0.05522063001990318, acc: 0.97826087474823)
[2024-11-29 03:28:33,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:33,891][root][INFO] - Training Epoch: 8/10, step 452/574 completed (loss: 0.08843544125556946, acc: 0.9871794581413269)
[2024-11-29 03:28:34,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:34,152][root][INFO] - Training Epoch: 8/10, step 453/574 completed (loss: 0.42946067452430725, acc: 0.8815789222717285)
[2024-11-29 03:28:34,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:34,407][root][INFO] - Training Epoch: 8/10, step 454/574 completed (loss: 0.04308099299669266, acc: 1.0)
[2024-11-29 03:28:34,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:34,672][root][INFO] - Training Epoch: 8/10, step 455/574 completed (loss: 0.26076990365982056, acc: 0.939393937587738)
[2024-11-29 03:28:34,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:34,950][root][INFO] - Training Epoch: 8/10, step 456/574 completed (loss: 0.4000345468521118, acc: 0.9278350472450256)
[2024-11-29 03:28:35,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:35,202][root][INFO] - Training Epoch: 8/10, step 457/574 completed (loss: 0.039746105670928955, acc: 1.0)
[2024-11-29 03:28:35,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:35,496][root][INFO] - Training Epoch: 8/10, step 458/574 completed (loss: 0.35331547260284424, acc: 0.895348846912384)
[2024-11-29 03:28:35,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:35,754][root][INFO] - Training Epoch: 8/10, step 459/574 completed (loss: 0.08608974516391754, acc: 0.9821428656578064)
[2024-11-29 03:28:35,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:36,017][root][INFO] - Training Epoch: 8/10, step 460/574 completed (loss: 0.18433628976345062, acc: 0.9382715821266174)
[2024-11-29 03:28:36,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:36,265][root][INFO] - Training Epoch: 8/10, step 461/574 completed (loss: 0.11691805720329285, acc: 0.9444444179534912)
[2024-11-29 03:28:36,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:36,501][root][INFO] - Training Epoch: 8/10, step 462/574 completed (loss: 0.01955377496778965, acc: 1.0)
[2024-11-29 03:28:36,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:36,738][root][INFO] - Training Epoch: 8/10, step 463/574 completed (loss: 0.024753162637352943, acc: 1.0)
[2024-11-29 03:28:36,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:36,982][root][INFO] - Training Epoch: 8/10, step 464/574 completed (loss: 0.14595326781272888, acc: 0.95652174949646)
[2024-11-29 03:28:37,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:37,208][root][INFO] - Training Epoch: 8/10, step 465/574 completed (loss: 0.1195950135588646, acc: 0.976190447807312)
[2024-11-29 03:28:37,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:37,460][root][INFO] - Training Epoch: 8/10, step 466/574 completed (loss: 0.6005112528800964, acc: 0.8674699068069458)
[2024-11-29 03:28:37,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:37,715][root][INFO] - Training Epoch: 8/10, step 467/574 completed (loss: 0.1060781478881836, acc: 0.9819819927215576)
[2024-11-29 03:28:37,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:37,949][root][INFO] - Training Epoch: 8/10, step 468/574 completed (loss: 0.398758202791214, acc: 0.9029126167297363)
[2024-11-29 03:28:38,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:38,193][root][INFO] - Training Epoch: 8/10, step 469/574 completed (loss: 0.6449713110923767, acc: 0.8536585569381714)
[2024-11-29 03:28:38,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:38,385][root][INFO] - Training Epoch: 8/10, step 470/574 completed (loss: 0.057867053896188736, acc: 0.9583333134651184)
[2024-11-29 03:28:38,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:38,573][root][INFO] - Training Epoch: 8/10, step 471/574 completed (loss: 0.03186837583780289, acc: 1.0)
[2024-11-29 03:28:38,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:38,908][root][INFO] - Training Epoch: 8/10, step 472/574 completed (loss: 0.44613268971443176, acc: 0.8529411554336548)
[2024-11-29 03:28:39,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:39,183][root][INFO] - Training Epoch: 8/10, step 473/574 completed (loss: 0.8607562184333801, acc: 0.7554585337638855)
[2024-11-29 03:28:39,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:39,406][root][INFO] - Training Epoch: 8/10, step 474/574 completed (loss: 0.27354949712753296, acc: 0.9166666865348816)
[2024-11-29 03:28:39,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:39,685][root][INFO] - Training Epoch: 8/10, step 475/574 completed (loss: 0.21297435462474823, acc: 0.9447852969169617)
[2024-11-29 03:28:39,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:39,937][root][INFO] - Training Epoch: 8/10, step 476/574 completed (loss: 0.2873227894306183, acc: 0.9136690497398376)
[2024-11-29 03:28:40,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:40,192][root][INFO] - Training Epoch: 8/10, step 477/574 completed (loss: 0.5863321423530579, acc: 0.8291457295417786)
[2024-11-29 03:28:40,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:40,411][root][INFO] - Training Epoch: 8/10, step 478/574 completed (loss: 0.19649094343185425, acc: 0.9444444179534912)
[2024-11-29 03:28:40,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:40,619][root][INFO] - Training Epoch: 8/10, step 479/574 completed (loss: 0.15040147304534912, acc: 0.9696969985961914)
[2024-11-29 03:28:40,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:40,842][root][INFO] - Training Epoch: 8/10, step 480/574 completed (loss: 0.3116253614425659, acc: 0.9259259104728699)
[2024-11-29 03:28:40,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:41,101][root][INFO] - Training Epoch: 8/10, step 481/574 completed (loss: 0.2940695285797119, acc: 0.8999999761581421)
[2024-11-29 03:28:41,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:41,345][root][INFO] - Training Epoch: 8/10, step 482/574 completed (loss: 0.6377159357070923, acc: 0.8500000238418579)
[2024-11-29 03:28:41,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:41,625][root][INFO] - Training Epoch: 8/10, step 483/574 completed (loss: 0.4179956912994385, acc: 0.8793103694915771)
[2024-11-29 03:28:41,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:41,793][root][INFO] - Training Epoch: 8/10, step 484/574 completed (loss: 0.03247399255633354, acc: 1.0)
[2024-11-29 03:28:41,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:42,017][root][INFO] - Training Epoch: 8/10, step 485/574 completed (loss: 0.23613053560256958, acc: 0.9473684430122375)
[2024-11-29 03:28:42,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:42,250][root][INFO] - Training Epoch: 8/10, step 486/574 completed (loss: 0.4997410476207733, acc: 0.8518518805503845)
[2024-11-29 03:28:42,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:42,499][root][INFO] - Training Epoch: 8/10, step 487/574 completed (loss: 0.23569007217884064, acc: 0.9523809552192688)
[2024-11-29 03:28:42,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:42,738][root][INFO] - Training Epoch: 8/10, step 488/574 completed (loss: 0.2936153709888458, acc: 0.8636363744735718)
[2024-11-29 03:28:42,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:42,988][root][INFO] - Training Epoch: 8/10, step 489/574 completed (loss: 0.6798653602600098, acc: 0.7846153974533081)
[2024-11-29 03:28:43,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:43,232][root][INFO] - Training Epoch: 8/10, step 490/574 completed (loss: 0.035040583461523056, acc: 1.0)
[2024-11-29 03:28:43,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:43,488][root][INFO] - Training Epoch: 8/10, step 491/574 completed (loss: 0.2204665243625641, acc: 0.8965517282485962)
[2024-11-29 03:28:43,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:43,732][root][INFO] - Training Epoch: 8/10, step 492/574 completed (loss: 0.19564568996429443, acc: 0.9215686321258545)
[2024-11-29 03:28:43,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:43,957][root][INFO] - Training Epoch: 8/10, step 493/574 completed (loss: 0.12087210267782211, acc: 0.9655172228813171)
[2024-11-29 03:28:44,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:44,176][root][INFO] - Training Epoch: 8/10, step 494/574 completed (loss: 0.3336920142173767, acc: 0.8947368264198303)
[2024-11-29 03:28:44,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:44,436][root][INFO] - Training Epoch: 8/10, step 495/574 completed (loss: 0.3265088200569153, acc: 0.9473684430122375)
[2024-11-29 03:28:44,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:44,667][root][INFO] - Training Epoch: 8/10, step 496/574 completed (loss: 0.5392998456954956, acc: 0.8214285969734192)
[2024-11-29 03:28:44,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:44,936][root][INFO] - Training Epoch: 8/10, step 497/574 completed (loss: 0.2252417802810669, acc: 0.932584285736084)
[2024-11-29 03:28:45,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:45,185][root][INFO] - Training Epoch: 8/10, step 498/574 completed (loss: 0.5238900780677795, acc: 0.8426966071128845)
[2024-11-29 03:28:45,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:45,440][root][INFO] - Training Epoch: 8/10, step 499/574 completed (loss: 0.8429876565933228, acc: 0.758865237236023)
[2024-11-29 03:28:45,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:45,744][root][INFO] - Training Epoch: 8/10, step 500/574 completed (loss: 0.43279942870140076, acc: 0.8478260636329651)
[2024-11-29 03:28:45,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:45,984][root][INFO] - Training Epoch: 8/10, step 501/574 completed (loss: 0.01824573241174221, acc: 1.0)
[2024-11-29 03:28:46,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:46,222][root][INFO] - Training Epoch: 8/10, step 502/574 completed (loss: 0.026188699528574944, acc: 1.0)
[2024-11-29 03:28:46,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:46,468][root][INFO] - Training Epoch: 8/10, step 503/574 completed (loss: 0.2099676877260208, acc: 0.9259259104728699)
[2024-11-29 03:28:46,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:46,713][root][INFO] - Training Epoch: 8/10, step 504/574 completed (loss: 0.0320223830640316, acc: 1.0)
[2024-11-29 03:28:46,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:46,924][root][INFO] - Training Epoch: 8/10, step 505/574 completed (loss: 0.6308544278144836, acc: 0.7924528121948242)
[2024-11-29 03:28:47,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:47,166][root][INFO] - Training Epoch: 8/10, step 506/574 completed (loss: 0.9329787492752075, acc: 0.7241379022598267)
[2024-11-29 03:28:47,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:47,683][root][INFO] - Training Epoch: 8/10, step 507/574 completed (loss: 0.937933087348938, acc: 0.7477477192878723)
[2024-11-29 03:28:47,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:48,027][root][INFO] - Training Epoch: 8/10, step 508/574 completed (loss: 0.6270298957824707, acc: 0.8873239159584045)
[2024-11-29 03:28:48,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:48,244][root][INFO] - Training Epoch: 8/10, step 509/574 completed (loss: 0.04729843884706497, acc: 1.0)
[2024-11-29 03:28:48,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:48,501][root][INFO] - Training Epoch: 8/10, step 510/574 completed (loss: 0.05736726522445679, acc: 0.9666666388511658)
[2024-11-29 03:28:48,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:48,753][root][INFO] - Training Epoch: 8/10, step 511/574 completed (loss: 0.07701005041599274, acc: 1.0)
[2024-11-29 03:28:50,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:51,269][root][INFO] - Training Epoch: 8/10, step 512/574 completed (loss: 1.1566388607025146, acc: 0.7071428298950195)
[2024-11-29 03:28:51,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:51,930][root][INFO] - Training Epoch: 8/10, step 513/574 completed (loss: 0.3146432936191559, acc: 0.9047619104385376)
[2024-11-29 03:28:52,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:52,169][root][INFO] - Training Epoch: 8/10, step 514/574 completed (loss: 0.492927223443985, acc: 0.8928571343421936)
[2024-11-29 03:28:52,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:52,423][root][INFO] - Training Epoch: 8/10, step 515/574 completed (loss: 0.055305346846580505, acc: 1.0)
[2024-11-29 03:28:52,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:53,042][root][INFO] - Training Epoch: 8/10, step 516/574 completed (loss: 0.3759081959724426, acc: 0.875)
[2024-11-29 03:28:53,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:53,282][root][INFO] - Training Epoch: 8/10, step 517/574 completed (loss: 0.02044089324772358, acc: 1.0)
[2024-11-29 03:28:53,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:53,544][root][INFO] - Training Epoch: 8/10, step 518/574 completed (loss: 0.09060335159301758, acc: 0.9677419066429138)
[2024-11-29 03:28:53,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:53,790][root][INFO] - Training Epoch: 8/10, step 519/574 completed (loss: 0.39804449677467346, acc: 0.8500000238418579)
[2024-11-29 03:28:53,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:54,033][root][INFO] - Training Epoch: 8/10, step 520/574 completed (loss: 0.05439458787441254, acc: 1.0)
[2024-11-29 03:28:54,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:54,946][root][INFO] - Training Epoch: 8/10, step 521/574 completed (loss: 0.6818670034408569, acc: 0.8177965879440308)
[2024-11-29 03:28:55,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:55,199][root][INFO] - Training Epoch: 8/10, step 522/574 completed (loss: 0.2063964307308197, acc: 0.9626865386962891)
[2024-11-29 03:28:55,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:55,465][root][INFO] - Training Epoch: 8/10, step 523/574 completed (loss: 0.25640442967414856, acc: 0.9270073175430298)
[2024-11-29 03:28:55,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:55,933][root][INFO] - Training Epoch: 8/10, step 524/574 completed (loss: 0.6758891940116882, acc: 0.8100000023841858)
[2024-11-29 03:28:56,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:56,171][root][INFO] - Training Epoch: 8/10, step 525/574 completed (loss: 0.044241342693567276, acc: 1.0)
[2024-11-29 03:28:56,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:56,423][root][INFO] - Training Epoch: 8/10, step 526/574 completed (loss: 0.1128522977232933, acc: 0.9615384340286255)
[2024-11-29 03:28:56,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:56,703][root][INFO] - Training Epoch: 8/10, step 527/574 completed (loss: 0.2509540617465973, acc: 0.9523809552192688)
[2024-11-29 03:28:56,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:56,941][root][INFO] - Training Epoch: 8/10, step 528/574 completed (loss: 0.8172615766525269, acc: 0.7377049326896667)
[2024-11-29 03:28:57,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:57,174][root][INFO] - Training Epoch: 8/10, step 529/574 completed (loss: 0.22109583020210266, acc: 0.9491525292396545)
[2024-11-29 03:28:57,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:57,385][root][INFO] - Training Epoch: 8/10, step 530/574 completed (loss: 1.0730034112930298, acc: 0.7906976938247681)
[2024-11-29 03:28:57,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:57,585][root][INFO] - Training Epoch: 8/10, step 531/574 completed (loss: 0.3745851218700409, acc: 0.8863636255264282)
[2024-11-29 03:28:57,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:57,858][root][INFO] - Training Epoch: 8/10, step 532/574 completed (loss: 0.594277024269104, acc: 0.8679245114326477)
[2024-11-29 03:28:57,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:58,098][root][INFO] - Training Epoch: 8/10, step 533/574 completed (loss: 0.3305085003376007, acc: 0.9090909361839294)
[2024-11-29 03:28:58,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:58,351][root][INFO] - Training Epoch: 8/10, step 534/574 completed (loss: 0.6478822231292725, acc: 0.8799999952316284)
[2024-11-29 03:28:58,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:58,580][root][INFO] - Training Epoch: 8/10, step 535/574 completed (loss: 0.01103623304516077, acc: 1.0)
[2024-11-29 03:28:58,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:58,807][root][INFO] - Training Epoch: 8/10, step 536/574 completed (loss: 0.03759269416332245, acc: 1.0)
[2024-11-29 03:28:58,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:59,133][root][INFO] - Training Epoch: 8/10, step 537/574 completed (loss: 0.2996410131454468, acc: 0.9230769276618958)
[2024-11-29 03:28:59,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:59,395][root][INFO] - Training Epoch: 8/10, step 538/574 completed (loss: 0.311778724193573, acc: 0.90625)
[2024-11-29 03:28:59,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:59,680][root][INFO] - Training Epoch: 8/10, step 539/574 completed (loss: 0.2996157705783844, acc: 0.875)
[2024-11-29 03:28:59,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:59,916][root][INFO] - Training Epoch: 8/10, step 540/574 completed (loss: 0.8954142928123474, acc: 0.7878788113594055)
[2024-11-29 03:29:00,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:00,158][root][INFO] - Training Epoch: 8/10, step 541/574 completed (loss: 0.048039570450782776, acc: 1.0)
[2024-11-29 03:29:00,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:00,403][root][INFO] - Training Epoch: 8/10, step 542/574 completed (loss: 0.07488323003053665, acc: 1.0)
[2024-11-29 03:29:00,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:00,642][root][INFO] - Training Epoch: 8/10, step 543/574 completed (loss: 0.060378096997737885, acc: 0.95652174949646)
[2024-11-29 03:29:00,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:00,909][root][INFO] - Training Epoch: 8/10, step 544/574 completed (loss: 0.07408776134252548, acc: 1.0)
[2024-11-29 03:29:01,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:01,150][root][INFO] - Training Epoch: 8/10, step 545/574 completed (loss: 0.05663237348198891, acc: 1.0)
[2024-11-29 03:29:01,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:01,387][root][INFO] - Training Epoch: 8/10, step 546/574 completed (loss: 0.020715679973363876, acc: 1.0)
[2024-11-29 03:29:01,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:01,630][root][INFO] - Training Epoch: 8/10, step 547/574 completed (loss: 0.02103426493704319, acc: 1.0)
[2024-11-29 03:29:01,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:01,874][root][INFO] - Training Epoch: 8/10, step 548/574 completed (loss: 0.04425806924700737, acc: 1.0)
[2024-11-29 03:29:01,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:02,111][root][INFO] - Training Epoch: 8/10, step 549/574 completed (loss: 0.013458787463605404, acc: 1.0)
[2024-11-29 03:29:02,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:02,347][root][INFO] - Training Epoch: 8/10, step 550/574 completed (loss: 0.07635218650102615, acc: 0.9696969985961914)
[2024-11-29 03:29:02,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:02,570][root][INFO] - Training Epoch: 8/10, step 551/574 completed (loss: 0.08104343712329865, acc: 0.949999988079071)
[2024-11-29 03:29:02,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:02,809][root][INFO] - Training Epoch: 8/10, step 552/574 completed (loss: 0.060089729726314545, acc: 0.9857142567634583)
[2024-11-29 03:29:02,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:03,015][root][INFO] - Training Epoch: 8/10, step 553/574 completed (loss: 0.48070597648620605, acc: 0.8759124279022217)
[2024-11-29 03:29:03,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:03,226][root][INFO] - Training Epoch: 8/10, step 554/574 completed (loss: 0.17779450118541718, acc: 0.9379310607910156)
[2024-11-29 03:29:03,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:03,455][root][INFO] - Training Epoch: 8/10, step 555/574 completed (loss: 0.45038408041000366, acc: 0.8571428656578064)
[2024-11-29 03:29:03,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:03,711][root][INFO] - Training Epoch: 8/10, step 556/574 completed (loss: 0.34114065766334534, acc: 0.9205297827720642)
[2024-11-29 03:29:03,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:03,977][root][INFO] - Training Epoch: 8/10, step 557/574 completed (loss: 0.21197499334812164, acc: 0.94017094373703)
[2024-11-29 03:29:04,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:04,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:05,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:05,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:05,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:06,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:06,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:06,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:06,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:07,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:07,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:07,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:08,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:08,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:08,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:09,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:09,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:09,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:09,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:10,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:10,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:10,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:10,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:11,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:11,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:11,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:12,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:12,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:12,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:12,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:13,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:13,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:13,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:13,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:14,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:14,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:14,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:15,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:15,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:15,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:15,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:16,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:16,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:16,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:17,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:17,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:17,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:17,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:17,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:18,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:18,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:18,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:19,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:19,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:19,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:19,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:20,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:20,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:20,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:20,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:21,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:21,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:21,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:22,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:22,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:22,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:22,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:23,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:23,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:23,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:24,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:24,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:24,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:24,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:25,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:25,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:25,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:25,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:26,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:26,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:26,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:26,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:27,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:27,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:27,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:28,241][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.2919, device='cuda:0') eval_epoch_loss=tensor(1.1915, device='cuda:0') eval_epoch_acc=tensor(0.7497, device='cuda:0')
[2024-11-29 03:29:28,243][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:29:28,243][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:29:28,523][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_8_step_558_loss_1.1914680004119873/model.pt
[2024-11-29 03:29:28,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:28,722][root][INFO] - Training Epoch: 8/10, step 558/574 completed (loss: 0.06159926950931549, acc: 0.9599999785423279)
[2024-11-29 03:29:28,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:28,914][root][INFO] - Training Epoch: 8/10, step 559/574 completed (loss: 0.026357177644968033, acc: 1.0)
[2024-11-29 03:29:29,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:29,122][root][INFO] - Training Epoch: 8/10, step 560/574 completed (loss: 0.026372017338871956, acc: 1.0)
[2024-11-29 03:29:29,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:29,390][root][INFO] - Training Epoch: 8/10, step 561/574 completed (loss: 0.08473926782608032, acc: 1.0)
[2024-11-29 03:29:29,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:29,662][root][INFO] - Training Epoch: 8/10, step 562/574 completed (loss: 0.5394473671913147, acc: 0.8777777552604675)
[2024-11-29 03:29:29,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:29,910][root][INFO] - Training Epoch: 8/10, step 563/574 completed (loss: 0.34900540113449097, acc: 0.9350649118423462)
[2024-11-29 03:29:30,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:30,184][root][INFO] - Training Epoch: 8/10, step 564/574 completed (loss: 0.2869704067707062, acc: 0.8958333134651184)
[2024-11-29 03:29:30,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:30,443][root][INFO] - Training Epoch: 8/10, step 565/574 completed (loss: 0.3155469298362732, acc: 0.8793103694915771)
[2024-11-29 03:29:30,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:30,672][root][INFO] - Training Epoch: 8/10, step 566/574 completed (loss: 0.10291829705238342, acc: 0.976190447807312)
[2024-11-29 03:29:30,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:30,882][root][INFO] - Training Epoch: 8/10, step 567/574 completed (loss: 0.022212402895092964, acc: 1.0)
[2024-11-29 03:29:30,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:31,129][root][INFO] - Training Epoch: 8/10, step 568/574 completed (loss: 0.010389722883701324, acc: 1.0)
[2024-11-29 03:29:31,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:31,432][root][INFO] - Training Epoch: 8/10, step 569/574 completed (loss: 0.2935951352119446, acc: 0.9197860956192017)
[2024-11-29 03:29:31,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:31,657][root][INFO] - Training Epoch: 8/10, step 570/574 completed (loss: 0.07613003998994827, acc: 0.9838709831237793)
[2024-11-29 03:29:31,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:31,876][root][INFO] - Training Epoch: 8/10, step 571/574 completed (loss: 0.16028305888175964, acc: 0.9487179517745972)
[2024-11-29 03:29:31,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:32,100][root][INFO] - Training Epoch: 8/10, step 572/574 completed (loss: 0.48287808895111084, acc: 0.8724489808082581)
[2024-11-29 03:29:32,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:32,342][root][INFO] - Training Epoch: 8/10, step 573/574 completed (loss: 0.40424346923828125, acc: 0.8427672982215881)
[2024-11-29 03:29:32,767][slam_llm.utils.train_utils][INFO] - Epoch 8: train_perplexity=1.4047, train_epoch_loss=0.3398, epoch time 266.6180436387658s
[2024-11-29 03:29:32,768][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 11 GB
[2024-11-29 03:29:32,768][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-11-29 03:29:32,768][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 11 GB
[2024-11-29 03:29:32,768][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 12
[2024-11-29 03:29:32,768][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:29:33,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:33,516][root][INFO] - Training Epoch: 9/10, step 0/574 completed (loss: 0.1856236755847931, acc: 0.9629629850387573)
[2024-11-29 03:29:33,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:33,755][root][INFO] - Training Epoch: 9/10, step 1/574 completed (loss: 0.4459519684314728, acc: 0.9599999785423279)
[2024-11-29 03:29:33,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:34,036][root][INFO] - Training Epoch: 9/10, step 2/574 completed (loss: 0.22145695984363556, acc: 0.9459459185600281)
[2024-11-29 03:29:34,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:34,316][root][INFO] - Training Epoch: 9/10, step 3/574 completed (loss: 0.18228892982006073, acc: 0.9210526347160339)
[2024-11-29 03:29:34,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:34,542][root][INFO] - Training Epoch: 9/10, step 4/574 completed (loss: 0.26771870255470276, acc: 0.9189189076423645)
[2024-11-29 03:29:34,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:34,789][root][INFO] - Training Epoch: 9/10, step 5/574 completed (loss: 0.05261402577161789, acc: 1.0)
[2024-11-29 03:29:34,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:35,051][root][INFO] - Training Epoch: 9/10, step 6/574 completed (loss: 0.45682814717292786, acc: 0.8571428656578064)
[2024-11-29 03:29:35,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:35,314][root][INFO] - Training Epoch: 9/10, step 7/574 completed (loss: 0.2551209032535553, acc: 0.8999999761581421)
[2024-11-29 03:29:35,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:35,565][root][INFO] - Training Epoch: 9/10, step 8/574 completed (loss: 0.05689436197280884, acc: 0.9545454382896423)
[2024-11-29 03:29:35,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:35,832][root][INFO] - Training Epoch: 9/10, step 9/574 completed (loss: 0.011615127325057983, acc: 1.0)
[2024-11-29 03:29:35,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:36,071][root][INFO] - Training Epoch: 9/10, step 10/574 completed (loss: 0.030803361907601357, acc: 1.0)
[2024-11-29 03:29:36,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:36,302][root][INFO] - Training Epoch: 9/10, step 11/574 completed (loss: 0.03197157010436058, acc: 1.0)
[2024-11-29 03:29:36,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:36,530][root][INFO] - Training Epoch: 9/10, step 12/574 completed (loss: 0.03435151278972626, acc: 0.9696969985961914)
[2024-11-29 03:29:36,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:36,754][root][INFO] - Training Epoch: 9/10, step 13/574 completed (loss: 0.07635108381509781, acc: 1.0)
[2024-11-29 03:29:36,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:37,026][root][INFO] - Training Epoch: 9/10, step 14/574 completed (loss: 0.09662478417158127, acc: 0.9607843160629272)
[2024-11-29 03:29:37,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:37,296][root][INFO] - Training Epoch: 9/10, step 15/574 completed (loss: 0.04209168627858162, acc: 1.0)
[2024-11-29 03:29:37,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:37,552][root][INFO] - Training Epoch: 9/10, step 16/574 completed (loss: 0.09493130445480347, acc: 0.9473684430122375)
[2024-11-29 03:29:37,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:37,803][root][INFO] - Training Epoch: 9/10, step 17/574 completed (loss: 0.009160435758531094, acc: 1.0)
[2024-11-29 03:29:37,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:38,009][root][INFO] - Training Epoch: 9/10, step 18/574 completed (loss: 0.19628620147705078, acc: 0.9722222089767456)
[2024-11-29 03:29:38,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:38,272][root][INFO] - Training Epoch: 9/10, step 19/574 completed (loss: 0.06978985667228699, acc: 0.9473684430122375)
[2024-11-29 03:29:38,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:38,485][root][INFO] - Training Epoch: 9/10, step 20/574 completed (loss: 0.11000479757785797, acc: 0.9615384340286255)
[2024-11-29 03:29:38,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:38,711][root][INFO] - Training Epoch: 9/10, step 21/574 completed (loss: 0.06478583067655563, acc: 1.0)
[2024-11-29 03:29:38,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:38,972][root][INFO] - Training Epoch: 9/10, step 22/574 completed (loss: 0.05804575979709625, acc: 0.9599999785423279)
[2024-11-29 03:29:39,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:39,216][root][INFO] - Training Epoch: 9/10, step 23/574 completed (loss: 0.029868479818105698, acc: 1.0)
[2024-11-29 03:29:39,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:39,487][root][INFO] - Training Epoch: 9/10, step 24/574 completed (loss: 0.007076570764183998, acc: 1.0)
[2024-11-29 03:29:39,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:39,736][root][INFO] - Training Epoch: 9/10, step 25/574 completed (loss: 0.20219701528549194, acc: 0.9245283007621765)
[2024-11-29 03:29:39,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:40,002][root][INFO] - Training Epoch: 9/10, step 26/574 completed (loss: 0.38615164160728455, acc: 0.9041095972061157)
[2024-11-29 03:29:40,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:41,169][root][INFO] - Training Epoch: 9/10, step 27/574 completed (loss: 1.02493417263031, acc: 0.7154150009155273)
[2024-11-29 03:29:41,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:41,344][root][INFO] - Training Epoch: 9/10, step 28/574 completed (loss: 0.22542700171470642, acc: 0.930232584476471)
[2024-11-29 03:29:41,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:41,541][root][INFO] - Training Epoch: 9/10, step 29/574 completed (loss: 0.4161010980606079, acc: 0.9036144614219666)
[2024-11-29 03:29:41,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:41,767][root][INFO] - Training Epoch: 9/10, step 30/574 completed (loss: 0.48806801438331604, acc: 0.8641975522041321)
[2024-11-29 03:29:41,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:42,010][root][INFO] - Training Epoch: 9/10, step 31/574 completed (loss: 0.018850799649953842, acc: 1.0)
[2024-11-29 03:29:42,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:42,240][root][INFO] - Training Epoch: 9/10, step 32/574 completed (loss: 0.14352943003177643, acc: 0.9629629850387573)
[2024-11-29 03:29:42,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:42,504][root][INFO] - Training Epoch: 9/10, step 33/574 completed (loss: 0.011370943859219551, acc: 1.0)
[2024-11-29 03:29:42,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:42,752][root][INFO] - Training Epoch: 9/10, step 34/574 completed (loss: 0.3494797945022583, acc: 0.8907563090324402)
[2024-11-29 03:29:42,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:43,005][root][INFO] - Training Epoch: 9/10, step 35/574 completed (loss: 0.16604436933994293, acc: 0.9672130942344666)
[2024-11-29 03:29:43,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:43,194][root][INFO] - Training Epoch: 9/10, step 36/574 completed (loss: 0.29511740803718567, acc: 0.8888888955116272)
[2024-11-29 03:29:43,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:43,448][root][INFO] - Training Epoch: 9/10, step 37/574 completed (loss: 0.1988130509853363, acc: 0.9322034120559692)
[2024-11-29 03:29:43,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:43,710][root][INFO] - Training Epoch: 9/10, step 38/574 completed (loss: 0.2866635322570801, acc: 0.9195402264595032)
[2024-11-29 03:29:43,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:43,955][root][INFO] - Training Epoch: 9/10, step 39/574 completed (loss: 0.0857938677072525, acc: 1.0)
[2024-11-29 03:29:44,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:44,245][root][INFO] - Training Epoch: 9/10, step 40/574 completed (loss: 0.19305123388767242, acc: 0.9230769276618958)
[2024-11-29 03:29:44,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:44,555][root][INFO] - Training Epoch: 9/10, step 41/574 completed (loss: 0.18661126494407654, acc: 0.9594594836235046)
[2024-11-29 03:29:44,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:44,835][root][INFO] - Training Epoch: 9/10, step 42/574 completed (loss: 0.4884169399738312, acc: 0.892307698726654)
[2024-11-29 03:29:44,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:45,177][root][INFO] - Training Epoch: 9/10, step 43/574 completed (loss: 0.5656455755233765, acc: 0.868686854839325)
[2024-11-29 03:29:45,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:45,487][root][INFO] - Training Epoch: 9/10, step 44/574 completed (loss: 0.46243777871131897, acc: 0.8659793734550476)
[2024-11-29 03:29:45,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:45,777][root][INFO] - Training Epoch: 9/10, step 45/574 completed (loss: 0.4284898340702057, acc: 0.8970588445663452)
[2024-11-29 03:29:45,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:46,027][root][INFO] - Training Epoch: 9/10, step 46/574 completed (loss: 0.13067707419395447, acc: 0.9615384340286255)
[2024-11-29 03:29:46,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:46,279][root][INFO] - Training Epoch: 9/10, step 47/574 completed (loss: 0.030076058581471443, acc: 1.0)
[2024-11-29 03:29:46,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:46,522][root][INFO] - Training Epoch: 9/10, step 48/574 completed (loss: 0.042007166892290115, acc: 1.0)
[2024-11-29 03:29:46,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:46,782][root][INFO] - Training Epoch: 9/10, step 49/574 completed (loss: 0.10354936122894287, acc: 0.9722222089767456)
[2024-11-29 03:29:46,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:47,067][root][INFO] - Training Epoch: 9/10, step 50/574 completed (loss: 0.2762553095817566, acc: 0.9122806787490845)
[2024-11-29 03:29:47,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:47,295][root][INFO] - Training Epoch: 9/10, step 51/574 completed (loss: 0.44804906845092773, acc: 0.8730158805847168)
[2024-11-29 03:29:47,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:47,514][root][INFO] - Training Epoch: 9/10, step 52/574 completed (loss: 0.3691326975822449, acc: 0.8732394576072693)
[2024-11-29 03:29:47,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:47,886][root][INFO] - Training Epoch: 9/10, step 53/574 completed (loss: 1.1600786447525024, acc: 0.653333306312561)
[2024-11-29 03:29:47,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:48,065][root][INFO] - Training Epoch: 9/10, step 54/574 completed (loss: 0.3825686573982239, acc: 0.8648648858070374)
[2024-11-29 03:29:48,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:48,251][root][INFO] - Training Epoch: 9/10, step 55/574 completed (loss: 0.09580589085817337, acc: 0.9615384340286255)
[2024-11-29 03:29:49,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:50,718][root][INFO] - Training Epoch: 9/10, step 56/574 completed (loss: 1.1232681274414062, acc: 0.703071653842926)
[2024-11-29 03:29:51,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:51,837][root][INFO] - Training Epoch: 9/10, step 57/574 completed (loss: 1.4189077615737915, acc: 0.6143791079521179)
[2024-11-29 03:29:52,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:52,352][root][INFO] - Training Epoch: 9/10, step 58/574 completed (loss: 0.5776520371437073, acc: 0.8068181872367859)
[2024-11-29 03:29:52,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:52,825][root][INFO] - Training Epoch: 9/10, step 59/574 completed (loss: 0.2000250518321991, acc: 0.9411764740943909)
[2024-11-29 03:29:52,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:53,288][root][INFO] - Training Epoch: 9/10, step 60/574 completed (loss: 0.6777049899101257, acc: 0.8188405632972717)
[2024-11-29 03:29:53,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:53,601][root][INFO] - Training Epoch: 9/10, step 61/574 completed (loss: 0.41909879446029663, acc: 0.875)
[2024-11-29 03:29:53,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:53,822][root][INFO] - Training Epoch: 9/10, step 62/574 completed (loss: 0.24536076188087463, acc: 0.970588207244873)
[2024-11-29 03:29:53,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:54,030][root][INFO] - Training Epoch: 9/10, step 63/574 completed (loss: 0.057381466031074524, acc: 1.0)
[2024-11-29 03:29:54,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:54,301][root][INFO] - Training Epoch: 9/10, step 64/574 completed (loss: 0.15298649668693542, acc: 0.9375)
[2024-11-29 03:29:54,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:54,568][root][INFO] - Training Epoch: 9/10, step 65/574 completed (loss: 0.21754179894924164, acc: 0.8965517282485962)
[2024-11-29 03:29:54,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:54,832][root][INFO] - Training Epoch: 9/10, step 66/574 completed (loss: 0.288524866104126, acc: 0.9107142686843872)
[2024-11-29 03:29:54,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:55,096][root][INFO] - Training Epoch: 9/10, step 67/574 completed (loss: 0.29002368450164795, acc: 0.8999999761581421)
[2024-11-29 03:29:55,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:55,325][root][INFO] - Training Epoch: 9/10, step 68/574 completed (loss: 0.006109458394348621, acc: 1.0)
[2024-11-29 03:29:55,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:55,580][root][INFO] - Training Epoch: 9/10, step 69/574 completed (loss: 0.35503512620925903, acc: 0.9444444179534912)
[2024-11-29 03:29:55,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:55,835][root][INFO] - Training Epoch: 9/10, step 70/574 completed (loss: 0.1148451641201973, acc: 1.0)
[2024-11-29 03:29:55,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:56,086][root][INFO] - Training Epoch: 9/10, step 71/574 completed (loss: 0.9272409081459045, acc: 0.7720588445663452)
[2024-11-29 03:29:56,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:56,344][root][INFO] - Training Epoch: 9/10, step 72/574 completed (loss: 0.4791634678840637, acc: 0.8650793433189392)
[2024-11-29 03:29:56,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:56,605][root][INFO] - Training Epoch: 9/10, step 73/574 completed (loss: 1.135684609413147, acc: 0.6871795058250427)
[2024-11-29 03:29:56,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:56,841][root][INFO] - Training Epoch: 9/10, step 74/574 completed (loss: 0.567569375038147, acc: 0.8469387888908386)
[2024-11-29 03:29:56,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:57,083][root][INFO] - Training Epoch: 9/10, step 75/574 completed (loss: 0.8340110778808594, acc: 0.746268630027771)
[2024-11-29 03:29:57,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:57,382][root][INFO] - Training Epoch: 9/10, step 76/574 completed (loss: 1.3571704626083374, acc: 0.6496350169181824)
[2024-11-29 03:29:57,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:57,541][root][INFO] - Training Epoch: 9/10, step 77/574 completed (loss: 0.013938060961663723, acc: 1.0)
[2024-11-29 03:29:57,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:57,704][root][INFO] - Training Epoch: 9/10, step 78/574 completed (loss: 0.06012057885527611, acc: 1.0)
[2024-11-29 03:29:57,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:57,959][root][INFO] - Training Epoch: 9/10, step 79/574 completed (loss: 0.05000130459666252, acc: 1.0)
[2024-11-29 03:29:58,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:58,239][root][INFO] - Training Epoch: 9/10, step 80/574 completed (loss: 0.0526481457054615, acc: 0.9615384340286255)
[2024-11-29 03:29:58,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:58,508][root][INFO] - Training Epoch: 9/10, step 81/574 completed (loss: 0.13268592953681946, acc: 1.0)
[2024-11-29 03:29:58,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:58,778][root][INFO] - Training Epoch: 9/10, step 82/574 completed (loss: 0.1872214525938034, acc: 0.9615384340286255)
[2024-11-29 03:29:58,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:59,029][root][INFO] - Training Epoch: 9/10, step 83/574 completed (loss: 0.21776239573955536, acc: 0.90625)
[2024-11-29 03:29:59,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:59,289][root][INFO] - Training Epoch: 9/10, step 84/574 completed (loss: 0.17552785575389862, acc: 0.95652174949646)
[2024-11-29 03:29:59,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:59,520][root][INFO] - Training Epoch: 9/10, step 85/574 completed (loss: 0.143302321434021, acc: 0.9800000190734863)
[2024-11-29 03:29:59,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:59,747][root][INFO] - Training Epoch: 9/10, step 86/574 completed (loss: 0.02793557569384575, acc: 1.0)
[2024-11-29 03:29:59,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:00,125][root][INFO] - Training Epoch: 9/10, step 87/574 completed (loss: 0.4514371454715729, acc: 0.8399999737739563)
[2024-11-29 03:30:00,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:00,419][root][INFO] - Training Epoch: 9/10, step 88/574 completed (loss: 0.6853013038635254, acc: 0.7961165308952332)
[2024-11-29 03:30:00,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:01,440][root][INFO] - Training Epoch: 9/10, step 89/574 completed (loss: 0.8375644087791443, acc: 0.7669903039932251)
[2024-11-29 03:30:01,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:02,136][root][INFO] - Training Epoch: 9/10, step 90/574 completed (loss: 1.260848045349121, acc: 0.698924720287323)
[2024-11-29 03:30:02,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:02,817][root][INFO] - Training Epoch: 9/10, step 91/574 completed (loss: 0.9735694527626038, acc: 0.75)
[2024-11-29 03:30:03,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:03,448][root][INFO] - Training Epoch: 9/10, step 92/574 completed (loss: 0.5849427580833435, acc: 0.8421052694320679)
[2024-11-29 03:30:03,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:04,310][root][INFO] - Training Epoch: 9/10, step 93/574 completed (loss: 1.011423110961914, acc: 0.7227723002433777)
[2024-11-29 03:30:04,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:04,490][root][INFO] - Training Epoch: 9/10, step 94/574 completed (loss: 0.5537768006324768, acc: 0.8064516186714172)
[2024-11-29 03:30:04,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:04,725][root][INFO] - Training Epoch: 9/10, step 95/574 completed (loss: 0.4394014775753021, acc: 0.8695651888847351)
[2024-11-29 03:30:04,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:04,968][root][INFO] - Training Epoch: 9/10, step 96/574 completed (loss: 0.7078961133956909, acc: 0.7815126180648804)
[2024-11-29 03:30:05,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:05,246][root][INFO] - Training Epoch: 9/10, step 97/574 completed (loss: 0.7607543468475342, acc: 0.7884615659713745)
[2024-11-29 03:30:05,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:05,521][root][INFO] - Training Epoch: 9/10, step 98/574 completed (loss: 1.1651344299316406, acc: 0.6788321137428284)
[2024-11-29 03:30:05,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:05,726][root][INFO] - Training Epoch: 9/10, step 99/574 completed (loss: 0.6135521531105042, acc: 0.8208954930305481)
[2024-11-29 03:30:05,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:05,960][root][INFO] - Training Epoch: 9/10, step 100/574 completed (loss: 0.15736673772335052, acc: 0.949999988079071)
[2024-11-29 03:30:06,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:06,209][root][INFO] - Training Epoch: 9/10, step 101/574 completed (loss: 0.17209944128990173, acc: 0.9090909361839294)
[2024-11-29 03:30:06,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:06,475][root][INFO] - Training Epoch: 9/10, step 102/574 completed (loss: 0.014457544311881065, acc: 1.0)
[2024-11-29 03:30:06,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:06,680][root][INFO] - Training Epoch: 9/10, step 103/574 completed (loss: 0.017793001607060432, acc: 1.0)
[2024-11-29 03:30:06,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:06,921][root][INFO] - Training Epoch: 9/10, step 104/574 completed (loss: 0.2159857451915741, acc: 0.9655172228813171)
[2024-11-29 03:30:07,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:07,182][root][INFO] - Training Epoch: 9/10, step 105/574 completed (loss: 0.036349669098854065, acc: 1.0)
[2024-11-29 03:30:07,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:07,397][root][INFO] - Training Epoch: 9/10, step 106/574 completed (loss: 0.0467248260974884, acc: 1.0)
[2024-11-29 03:30:07,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:07,637][root][INFO] - Training Epoch: 9/10, step 107/574 completed (loss: 0.005988608114421368, acc: 1.0)
[2024-11-29 03:30:07,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:07,871][root][INFO] - Training Epoch: 9/10, step 108/574 completed (loss: 0.04826447740197182, acc: 0.9615384340286255)
[2024-11-29 03:30:07,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:08,100][root][INFO] - Training Epoch: 9/10, step 109/574 completed (loss: 0.03831065073609352, acc: 1.0)
[2024-11-29 03:30:08,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:08,348][root][INFO] - Training Epoch: 9/10, step 110/574 completed (loss: 0.11247029155492783, acc: 0.9538461565971375)
[2024-11-29 03:30:08,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:08,657][root][INFO] - Training Epoch: 9/10, step 111/574 completed (loss: 0.2120099514722824, acc: 0.9824561476707458)
[2024-11-29 03:30:08,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:08,913][root][INFO] - Training Epoch: 9/10, step 112/574 completed (loss: 0.2321932166814804, acc: 0.9473684430122375)
[2024-11-29 03:30:09,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:09,173][root][INFO] - Training Epoch: 9/10, step 113/574 completed (loss: 0.3014174997806549, acc: 0.8717948794364929)
[2024-11-29 03:30:09,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:09,436][root][INFO] - Training Epoch: 9/10, step 114/574 completed (loss: 0.13973845541477203, acc: 0.9795918464660645)
[2024-11-29 03:30:09,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:09,638][root][INFO] - Training Epoch: 9/10, step 115/574 completed (loss: 0.02267799898982048, acc: 1.0)
[2024-11-29 03:30:09,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:09,888][root][INFO] - Training Epoch: 9/10, step 116/574 completed (loss: 0.1783474236726761, acc: 0.9682539701461792)
[2024-11-29 03:30:09,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:10,131][root][INFO] - Training Epoch: 9/10, step 117/574 completed (loss: 0.2909861207008362, acc: 0.9105691313743591)
[2024-11-29 03:30:10,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:10,403][root][INFO] - Training Epoch: 9/10, step 118/574 completed (loss: 0.06979314237833023, acc: 0.9838709831237793)
[2024-11-29 03:30:10,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:11,186][root][INFO] - Training Epoch: 9/10, step 119/574 completed (loss: 0.8574447631835938, acc: 0.7566539645195007)
[2024-11-29 03:30:11,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:11,401][root][INFO] - Training Epoch: 9/10, step 120/574 completed (loss: 0.2444833368062973, acc: 0.9200000166893005)
[2024-11-29 03:30:11,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:11,707][root][INFO] - Training Epoch: 9/10, step 121/574 completed (loss: 0.06501735746860504, acc: 0.9807692170143127)
[2024-11-29 03:30:11,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:11,907][root][INFO] - Training Epoch: 9/10, step 122/574 completed (loss: 0.04276175796985626, acc: 1.0)
[2024-11-29 03:30:12,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:12,137][root][INFO] - Training Epoch: 9/10, step 123/574 completed (loss: 0.43614065647125244, acc: 0.9473684430122375)
[2024-11-29 03:30:12,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:12,426][root][INFO] - Training Epoch: 9/10, step 124/574 completed (loss: 0.8682737946510315, acc: 0.7668711543083191)
[2024-11-29 03:30:12,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:12,687][root][INFO] - Training Epoch: 9/10, step 125/574 completed (loss: 0.8022648096084595, acc: 0.7708333134651184)
[2024-11-29 03:30:12,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:12,891][root][INFO] - Training Epoch: 9/10, step 126/574 completed (loss: 0.6190465688705444, acc: 0.824999988079071)
[2024-11-29 03:30:13,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:13,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:14,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:14,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:14,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:14,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:15,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:15,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:15,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:16,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:16,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:16,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:16,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:17,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:17,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:17,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:18,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:18,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:18,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:18,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:19,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:19,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:19,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:19,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:20,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:20,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:20,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:20,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:21,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:21,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:21,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:22,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:22,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:22,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:22,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:23,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:23,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:23,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:23,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:24,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:24,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:24,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:24,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:25,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:25,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:25,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:25,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:26,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:26,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:26,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:27,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:27,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:27,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:27,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:28,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:28,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:28,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:28,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:29,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:29,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:29,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:29,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:30,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:30,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:30,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:31,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:31,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:31,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:31,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:32,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:32,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:32,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:32,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:33,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:33,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:33,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:33,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:34,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:34,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:34,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:34,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:35,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:35,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:35,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:35,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:36,348][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.9379, device='cuda:0') eval_epoch_loss=tensor(1.0777, device='cuda:0') eval_epoch_acc=tensor(0.7704, device='cuda:0')
[2024-11-29 03:30:36,349][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:30:36,349][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:30:36,552][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_9_step_127_loss_1.077687382698059/model.pt
[2024-11-29 03:30:36,555][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 9 is 0.7704082727432251
[2024-11-29 03:30:36,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:36,858][root][INFO] - Training Epoch: 9/10, step 127/574 completed (loss: 0.7976845502853394, acc: 0.7857142686843872)
[2024-11-29 03:30:36,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:37,107][root][INFO] - Training Epoch: 9/10, step 128/574 completed (loss: 0.7699176669120789, acc: 0.7794871926307678)
[2024-11-29 03:30:37,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:37,407][root][INFO] - Training Epoch: 9/10, step 129/574 completed (loss: 0.6680216789245605, acc: 0.8235294222831726)
[2024-11-29 03:30:37,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:37,621][root][INFO] - Training Epoch: 9/10, step 130/574 completed (loss: 0.18455512821674347, acc: 0.9615384340286255)
[2024-11-29 03:30:37,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:37,842][root][INFO] - Training Epoch: 9/10, step 131/574 completed (loss: 0.1635080724954605, acc: 0.95652174949646)
[2024-11-29 03:30:37,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:38,090][root][INFO] - Training Epoch: 9/10, step 132/574 completed (loss: 0.3374883532524109, acc: 0.875)
[2024-11-29 03:30:38,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:38,321][root][INFO] - Training Epoch: 9/10, step 133/574 completed (loss: 0.19737350940704346, acc: 0.95652174949646)
[2024-11-29 03:30:38,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:38,556][root][INFO] - Training Epoch: 9/10, step 134/574 completed (loss: 0.1021934226155281, acc: 0.9714285731315613)
[2024-11-29 03:30:38,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:38,804][root][INFO] - Training Epoch: 9/10, step 135/574 completed (loss: 0.05276288464665413, acc: 1.0)
[2024-11-29 03:30:38,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:39,042][root][INFO] - Training Epoch: 9/10, step 136/574 completed (loss: 0.2621253728866577, acc: 0.9285714030265808)
[2024-11-29 03:30:39,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:39,282][root][INFO] - Training Epoch: 9/10, step 137/574 completed (loss: 0.6684066653251648, acc: 0.8666666746139526)
[2024-11-29 03:30:39,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:39,510][root][INFO] - Training Epoch: 9/10, step 138/574 completed (loss: 0.2800997793674469, acc: 0.95652174949646)
[2024-11-29 03:30:39,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:39,754][root][INFO] - Training Epoch: 9/10, step 139/574 completed (loss: 0.2813816964626312, acc: 0.8571428656578064)
[2024-11-29 03:30:39,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:39,983][root][INFO] - Training Epoch: 9/10, step 140/574 completed (loss: 0.04770972952246666, acc: 1.0)
[2024-11-29 03:30:40,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:40,229][root][INFO] - Training Epoch: 9/10, step 141/574 completed (loss: 0.09038451313972473, acc: 0.9677419066429138)
[2024-11-29 03:30:40,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:40,484][root][INFO] - Training Epoch: 9/10, step 142/574 completed (loss: 0.19948174059391022, acc: 0.9189189076423645)
[2024-11-29 03:30:40,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:40,925][root][INFO] - Training Epoch: 9/10, step 143/574 completed (loss: 0.556250274181366, acc: 0.8245614171028137)
[2024-11-29 03:30:41,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:41,149][root][INFO] - Training Epoch: 9/10, step 144/574 completed (loss: 0.6075308918952942, acc: 0.8358209133148193)
[2024-11-29 03:30:41,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:41,402][root][INFO] - Training Epoch: 9/10, step 145/574 completed (loss: 0.3209056556224823, acc: 0.918367326259613)
[2024-11-29 03:30:41,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:41,756][root][INFO] - Training Epoch: 9/10, step 146/574 completed (loss: 0.7187609672546387, acc: 0.7765957713127136)
[2024-11-29 03:30:41,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:41,997][root][INFO] - Training Epoch: 9/10, step 147/574 completed (loss: 0.4222699701786041, acc: 0.8571428656578064)
[2024-11-29 03:30:42,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:42,230][root][INFO] - Training Epoch: 9/10, step 148/574 completed (loss: 0.10855202376842499, acc: 0.9642857313156128)
[2024-11-29 03:30:42,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:42,418][root][INFO] - Training Epoch: 9/10, step 149/574 completed (loss: 0.34807685017585754, acc: 0.8695651888847351)
[2024-11-29 03:30:42,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:42,642][root][INFO] - Training Epoch: 9/10, step 150/574 completed (loss: 0.22060364484786987, acc: 0.9655172228813171)
[2024-11-29 03:30:42,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:42,918][root][INFO] - Training Epoch: 9/10, step 151/574 completed (loss: 0.42266973853111267, acc: 0.9347826242446899)
[2024-11-29 03:30:43,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:43,141][root][INFO] - Training Epoch: 9/10, step 152/574 completed (loss: 0.3474501967430115, acc: 0.9322034120559692)
[2024-11-29 03:30:43,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:43,378][root][INFO] - Training Epoch: 9/10, step 153/574 completed (loss: 0.4163551926612854, acc: 0.8771929740905762)
[2024-11-29 03:30:43,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:43,609][root][INFO] - Training Epoch: 9/10, step 154/574 completed (loss: 0.2842605412006378, acc: 0.9459459185600281)
[2024-11-29 03:30:43,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:43,871][root][INFO] - Training Epoch: 9/10, step 155/574 completed (loss: 0.12287621945142746, acc: 0.9642857313156128)
[2024-11-29 03:30:43,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:44,090][root][INFO] - Training Epoch: 9/10, step 156/574 completed (loss: 0.1961672157049179, acc: 0.95652174949646)
[2024-11-29 03:30:44,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:44,305][root][INFO] - Training Epoch: 9/10, step 157/574 completed (loss: 2.255315065383911, acc: 0.3684210479259491)
[2024-11-29 03:30:45,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:45,916][root][INFO] - Training Epoch: 9/10, step 158/574 completed (loss: 0.8308923840522766, acc: 0.7837837934494019)
[2024-11-29 03:30:45,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:46,117][root][INFO] - Training Epoch: 9/10, step 159/574 completed (loss: 0.8966177701950073, acc: 0.7962962985038757)
[2024-11-29 03:30:46,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:46,420][root][INFO] - Training Epoch: 9/10, step 160/574 completed (loss: 1.322531819343567, acc: 0.6627907156944275)
[2024-11-29 03:30:46,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:46,919][root][INFO] - Training Epoch: 9/10, step 161/574 completed (loss: 1.2033175230026245, acc: 0.7176470756530762)
[2024-11-29 03:30:47,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:47,388][root][INFO] - Training Epoch: 9/10, step 162/574 completed (loss: 1.011978030204773, acc: 0.7528089880943298)
[2024-11-29 03:30:47,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:47,639][root][INFO] - Training Epoch: 9/10, step 163/574 completed (loss: 0.27748122811317444, acc: 0.9545454382896423)
[2024-11-29 03:30:47,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:47,831][root][INFO] - Training Epoch: 9/10, step 164/574 completed (loss: 0.3245552182197571, acc: 0.9523809552192688)
[2024-11-29 03:30:47,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:48,050][root][INFO] - Training Epoch: 9/10, step 165/574 completed (loss: 0.9555261135101318, acc: 0.7931034564971924)
[2024-11-29 03:30:48,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:48,332][root][INFO] - Training Epoch: 9/10, step 166/574 completed (loss: 0.25647491216659546, acc: 0.918367326259613)
[2024-11-29 03:30:48,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:48,585][root][INFO] - Training Epoch: 9/10, step 167/574 completed (loss: 0.14810174703598022, acc: 0.9399999976158142)
[2024-11-29 03:30:48,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:48,883][root][INFO] - Training Epoch: 9/10, step 168/574 completed (loss: 0.30840274691581726, acc: 0.9166666865348816)
[2024-11-29 03:30:49,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:49,146][root][INFO] - Training Epoch: 9/10, step 169/574 completed (loss: 0.8377661108970642, acc: 0.7941176295280457)
[2024-11-29 03:30:49,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:50,059][root][INFO] - Training Epoch: 9/10, step 170/574 completed (loss: 0.9740834832191467, acc: 0.7191780805587769)
[2024-11-29 03:30:50,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:50,267][root][INFO] - Training Epoch: 9/10, step 171/574 completed (loss: 0.11904311180114746, acc: 0.9166666865348816)
[2024-11-29 03:30:50,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:50,511][root][INFO] - Training Epoch: 9/10, step 172/574 completed (loss: 0.3675157427787781, acc: 0.8888888955116272)
[2024-11-29 03:30:50,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:50,705][root][INFO] - Training Epoch: 9/10, step 173/574 completed (loss: 0.30451110005378723, acc: 0.9285714030265808)
[2024-11-29 03:30:50,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:51,157][root][INFO] - Training Epoch: 9/10, step 174/574 completed (loss: 0.9731380939483643, acc: 0.7168141603469849)
[2024-11-29 03:30:51,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:51,351][root][INFO] - Training Epoch: 9/10, step 175/574 completed (loss: 0.7242099642753601, acc: 0.8115941882133484)
[2024-11-29 03:30:51,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:51,585][root][INFO] - Training Epoch: 9/10, step 176/574 completed (loss: 0.3391864001750946, acc: 0.8636363744735718)
[2024-11-29 03:30:51,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:52,385][root][INFO] - Training Epoch: 9/10, step 177/574 completed (loss: 0.8699076175689697, acc: 0.7175572514533997)
[2024-11-29 03:30:52,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:52,959][root][INFO] - Training Epoch: 9/10, step 178/574 completed (loss: 0.6997449398040771, acc: 0.800000011920929)
[2024-11-29 03:30:53,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:53,197][root][INFO] - Training Epoch: 9/10, step 179/574 completed (loss: 0.19418081641197205, acc: 0.9508196711540222)
[2024-11-29 03:30:53,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:53,442][root][INFO] - Training Epoch: 9/10, step 180/574 completed (loss: 0.013992886990308762, acc: 1.0)
[2024-11-29 03:30:53,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:53,716][root][INFO] - Training Epoch: 9/10, step 181/574 completed (loss: 0.10112952440977097, acc: 0.9599999785423279)
[2024-11-29 03:30:53,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:53,923][root][INFO] - Training Epoch: 9/10, step 182/574 completed (loss: 0.04323666915297508, acc: 1.0)
[2024-11-29 03:30:54,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:54,140][root][INFO] - Training Epoch: 9/10, step 183/574 completed (loss: 0.161332905292511, acc: 0.9512194991111755)
[2024-11-29 03:30:54,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:54,394][root][INFO] - Training Epoch: 9/10, step 184/574 completed (loss: 0.7100017666816711, acc: 0.8277945518493652)
[2024-11-29 03:30:54,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:54,635][root][INFO] - Training Epoch: 9/10, step 185/574 completed (loss: 0.7816275358200073, acc: 0.7867435216903687)
[2024-11-29 03:30:54,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:55,034][root][INFO] - Training Epoch: 9/10, step 186/574 completed (loss: 0.5414819121360779, acc: 0.8500000238418579)
[2024-11-29 03:30:55,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:55,461][root][INFO] - Training Epoch: 9/10, step 187/574 completed (loss: 0.9110233783721924, acc: 0.7654784321784973)
[2024-11-29 03:30:55,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:55,764][root][INFO] - Training Epoch: 9/10, step 188/574 completed (loss: 0.5727216601371765, acc: 0.8398576378822327)
[2024-11-29 03:30:55,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:56,006][root][INFO] - Training Epoch: 9/10, step 189/574 completed (loss: 0.40383797883987427, acc: 0.8399999737739563)
[2024-11-29 03:30:56,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:56,472][root][INFO] - Training Epoch: 9/10, step 190/574 completed (loss: 0.8338539004325867, acc: 0.7790697813034058)
[2024-11-29 03:30:56,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:57,173][root][INFO] - Training Epoch: 9/10, step 191/574 completed (loss: 1.119398593902588, acc: 0.7222222089767456)
[2024-11-29 03:30:57,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:57,981][root][INFO] - Training Epoch: 9/10, step 192/574 completed (loss: 1.1245423555374146, acc: 0.6666666865348816)
[2024-11-29 03:30:58,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:58,626][root][INFO] - Training Epoch: 9/10, step 193/574 completed (loss: 0.5342932343482971, acc: 0.8705882430076599)
[2024-11-29 03:30:58,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:59,582][root][INFO] - Training Epoch: 9/10, step 194/574 completed (loss: 0.8803284168243408, acc: 0.7345678806304932)
[2024-11-29 03:30:59,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:00,422][root][INFO] - Training Epoch: 9/10, step 195/574 completed (loss: 0.23950760066509247, acc: 0.9354838728904724)
[2024-11-29 03:31:00,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:00,597][root][INFO] - Training Epoch: 9/10, step 196/574 completed (loss: 0.08261304348707199, acc: 0.9642857313156128)
[2024-11-29 03:31:00,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:00,785][root][INFO] - Training Epoch: 9/10, step 197/574 completed (loss: 0.4713866114616394, acc: 0.875)
[2024-11-29 03:31:00,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:01,002][root][INFO] - Training Epoch: 9/10, step 198/574 completed (loss: 0.26555249094963074, acc: 0.8823529481887817)
[2024-11-29 03:31:01,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:01,229][root][INFO] - Training Epoch: 9/10, step 199/574 completed (loss: 1.0268803834915161, acc: 0.7426470518112183)
[2024-11-29 03:31:01,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:01,498][root][INFO] - Training Epoch: 9/10, step 200/574 completed (loss: 0.6776849031448364, acc: 0.7796609997749329)
[2024-11-29 03:31:01,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:01,736][root][INFO] - Training Epoch: 9/10, step 201/574 completed (loss: 0.663994312286377, acc: 0.8283582329750061)
[2024-11-29 03:31:01,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:01,973][root][INFO] - Training Epoch: 9/10, step 202/574 completed (loss: 0.708583414554596, acc: 0.7281553149223328)
[2024-11-29 03:31:02,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:02,203][root][INFO] - Training Epoch: 9/10, step 203/574 completed (loss: 0.4300747811794281, acc: 0.9523809552192688)
[2024-11-29 03:31:02,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:02,424][root][INFO] - Training Epoch: 9/10, step 204/574 completed (loss: 0.10675334930419922, acc: 0.9780219793319702)
[2024-11-29 03:31:02,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:02,670][root][INFO] - Training Epoch: 9/10, step 205/574 completed (loss: 0.3060937821865082, acc: 0.9103139042854309)
[2024-11-29 03:31:02,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:02,969][root][INFO] - Training Epoch: 9/10, step 206/574 completed (loss: 0.5334024429321289, acc: 0.8307086825370789)
[2024-11-29 03:31:03,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:03,170][root][INFO] - Training Epoch: 9/10, step 207/574 completed (loss: 0.2562025189399719, acc: 0.9094827771186829)
[2024-11-29 03:31:03,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:03,406][root][INFO] - Training Epoch: 9/10, step 208/574 completed (loss: 0.4144279956817627, acc: 0.8985507488250732)
[2024-11-29 03:31:03,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:03,661][root][INFO] - Training Epoch: 9/10, step 209/574 completed (loss: 0.44689735770225525, acc: 0.8677042722702026)
[2024-11-29 03:31:03,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:03,866][root][INFO] - Training Epoch: 9/10, step 210/574 completed (loss: 0.4886150062084198, acc: 0.9021739363670349)
[2024-11-29 03:31:03,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:04,059][root][INFO] - Training Epoch: 9/10, step 211/574 completed (loss: 0.09347860515117645, acc: 0.95652174949646)
[2024-11-29 03:31:04,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:04,293][root][INFO] - Training Epoch: 9/10, step 212/574 completed (loss: 0.06900481879711151, acc: 1.0)
[2024-11-29 03:31:04,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:04,529][root][INFO] - Training Epoch: 9/10, step 213/574 completed (loss: 0.30141517519950867, acc: 0.914893627166748)
[2024-11-29 03:31:04,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:05,136][root][INFO] - Training Epoch: 9/10, step 214/574 completed (loss: 0.34550532698631287, acc: 0.9230769276618958)
[2024-11-29 03:31:05,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:05,369][root][INFO] - Training Epoch: 9/10, step 215/574 completed (loss: 0.3859366178512573, acc: 0.9189189076423645)
[2024-11-29 03:31:05,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:05,577][root][INFO] - Training Epoch: 9/10, step 216/574 completed (loss: 0.13869385421276093, acc: 0.9651162624359131)
[2024-11-29 03:31:05,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:06,023][root][INFO] - Training Epoch: 9/10, step 217/574 completed (loss: 0.20909300446510315, acc: 0.954954981803894)
[2024-11-29 03:31:06,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:06,317][root][INFO] - Training Epoch: 9/10, step 218/574 completed (loss: 0.2906349301338196, acc: 0.8999999761581421)
[2024-11-29 03:31:06,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:06,484][root][INFO] - Training Epoch: 9/10, step 219/574 completed (loss: 0.022916710004210472, acc: 1.0)
[2024-11-29 03:31:06,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:06,727][root][INFO] - Training Epoch: 9/10, step 220/574 completed (loss: 0.08083483576774597, acc: 0.9629629850387573)
[2024-11-29 03:31:06,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:06,947][root][INFO] - Training Epoch: 9/10, step 221/574 completed (loss: 0.01975441165268421, acc: 1.0)
[2024-11-29 03:31:07,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:07,184][root][INFO] - Training Epoch: 9/10, step 222/574 completed (loss: 0.33968573808670044, acc: 0.8846153616905212)
[2024-11-29 03:31:07,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:07,850][root][INFO] - Training Epoch: 9/10, step 223/574 completed (loss: 0.3146592080593109, acc: 0.907608687877655)
[2024-11-29 03:31:07,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:08,301][root][INFO] - Training Epoch: 9/10, step 224/574 completed (loss: 0.4346937835216522, acc: 0.8977272510528564)
[2024-11-29 03:31:08,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:08,647][root][INFO] - Training Epoch: 9/10, step 225/574 completed (loss: 0.31545573472976685, acc: 0.8936170339584351)
[2024-11-29 03:31:08,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:08,913][root][INFO] - Training Epoch: 9/10, step 226/574 completed (loss: 0.11923443526029587, acc: 0.9811320900917053)
[2024-11-29 03:31:09,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:09,162][root][INFO] - Training Epoch: 9/10, step 227/574 completed (loss: 0.11425693333148956, acc: 0.9666666388511658)
[2024-11-29 03:31:09,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:09,380][root][INFO] - Training Epoch: 9/10, step 228/574 completed (loss: 0.5844343900680542, acc: 0.8372092843055725)
[2024-11-29 03:31:09,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:09,610][root][INFO] - Training Epoch: 9/10, step 229/574 completed (loss: 0.8594049215316772, acc: 0.7333333492279053)
[2024-11-29 03:31:09,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:09,859][root][INFO] - Training Epoch: 9/10, step 230/574 completed (loss: 1.881953239440918, acc: 0.5368421077728271)
[2024-11-29 03:31:09,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:10,066][root][INFO] - Training Epoch: 9/10, step 231/574 completed (loss: 1.6165095567703247, acc: 0.6333333253860474)
[2024-11-29 03:31:10,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:10,395][root][INFO] - Training Epoch: 9/10, step 232/574 completed (loss: 1.6640396118164062, acc: 0.5555555820465088)
[2024-11-29 03:31:10,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:10,798][root][INFO] - Training Epoch: 9/10, step 233/574 completed (loss: 2.1026368141174316, acc: 0.4587155878543854)
[2024-11-29 03:31:10,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:11,175][root][INFO] - Training Epoch: 9/10, step 234/574 completed (loss: 1.5156569480895996, acc: 0.6153846383094788)
[2024-11-29 03:31:11,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:11,336][root][INFO] - Training Epoch: 9/10, step 235/574 completed (loss: 0.040595781058073044, acc: 1.0)
[2024-11-29 03:31:11,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:11,548][root][INFO] - Training Epoch: 9/10, step 236/574 completed (loss: 0.08332298696041107, acc: 0.9583333134651184)
[2024-11-29 03:31:11,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:11,800][root][INFO] - Training Epoch: 9/10, step 237/574 completed (loss: 0.07141861319541931, acc: 1.0)
[2024-11-29 03:31:11,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:12,040][root][INFO] - Training Epoch: 9/10, step 238/574 completed (loss: 0.3015490174293518, acc: 0.9629629850387573)
[2024-11-29 03:31:12,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:12,308][root][INFO] - Training Epoch: 9/10, step 239/574 completed (loss: 0.1819124072790146, acc: 0.9142857193946838)
[2024-11-29 03:31:12,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:12,584][root][INFO] - Training Epoch: 9/10, step 240/574 completed (loss: 0.4746216833591461, acc: 0.8863636255264282)
[2024-11-29 03:31:12,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:12,838][root][INFO] - Training Epoch: 9/10, step 241/574 completed (loss: 0.2047155350446701, acc: 0.9090909361839294)
[2024-11-29 03:31:12,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:13,337][root][INFO] - Training Epoch: 9/10, step 242/574 completed (loss: 0.6570959687232971, acc: 0.8387096524238586)
[2024-11-29 03:31:13,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:13,772][root][INFO] - Training Epoch: 9/10, step 243/574 completed (loss: 0.3121020793914795, acc: 0.9090909361839294)
[2024-11-29 03:31:13,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:14,011][root][INFO] - Training Epoch: 9/10, step 244/574 completed (loss: 0.01617078296840191, acc: 1.0)
[2024-11-29 03:31:14,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:14,265][root][INFO] - Training Epoch: 9/10, step 245/574 completed (loss: 0.2708361744880676, acc: 0.8846153616905212)
[2024-11-29 03:31:14,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:14,511][root][INFO] - Training Epoch: 9/10, step 246/574 completed (loss: 0.06122850626707077, acc: 0.9677419066429138)
[2024-11-29 03:31:14,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:14,800][root][INFO] - Training Epoch: 9/10, step 247/574 completed (loss: 0.05262308567762375, acc: 1.0)
[2024-11-29 03:31:14,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:15,058][root][INFO] - Training Epoch: 9/10, step 248/574 completed (loss: 0.10439780354499817, acc: 0.9459459185600281)
[2024-11-29 03:31:15,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:15,256][root][INFO] - Training Epoch: 9/10, step 249/574 completed (loss: 0.11959418654441833, acc: 0.9459459185600281)
[2024-11-29 03:31:15,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:15,465][root][INFO] - Training Epoch: 9/10, step 250/574 completed (loss: 0.09853847324848175, acc: 0.9729729890823364)
[2024-11-29 03:31:15,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:15,694][root][INFO] - Training Epoch: 9/10, step 251/574 completed (loss: 0.10984082520008087, acc: 0.9558823704719543)
[2024-11-29 03:31:15,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:15,910][root][INFO] - Training Epoch: 9/10, step 252/574 completed (loss: 0.10946599394083023, acc: 0.9268292784690857)
[2024-11-29 03:31:16,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:16,130][root][INFO] - Training Epoch: 9/10, step 253/574 completed (loss: 0.0262954942882061, acc: 1.0)
[2024-11-29 03:31:16,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:16,367][root][INFO] - Training Epoch: 9/10, step 254/574 completed (loss: 0.003943738527595997, acc: 1.0)
[2024-11-29 03:31:16,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:16,608][root][INFO] - Training Epoch: 9/10, step 255/574 completed (loss: 0.023605382069945335, acc: 1.0)
[2024-11-29 03:31:16,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:16,827][root][INFO] - Training Epoch: 9/10, step 256/574 completed (loss: 0.04927019029855728, acc: 1.0)
[2024-11-29 03:31:16,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:17,059][root][INFO] - Training Epoch: 9/10, step 257/574 completed (loss: 0.07675571739673615, acc: 0.9857142567634583)
[2024-11-29 03:31:17,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:17,299][root][INFO] - Training Epoch: 9/10, step 258/574 completed (loss: 0.02814546413719654, acc: 1.0)
[2024-11-29 03:31:17,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:17,775][root][INFO] - Training Epoch: 9/10, step 259/574 completed (loss: 0.31400763988494873, acc: 0.9339622855186462)
[2024-11-29 03:31:17,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:18,264][root][INFO] - Training Epoch: 9/10, step 260/574 completed (loss: 0.3416357636451721, acc: 0.925000011920929)
[2024-11-29 03:31:18,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:18,503][root][INFO] - Training Epoch: 9/10, step 261/574 completed (loss: 0.01395084336400032, acc: 1.0)
[2024-11-29 03:31:18,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:18,724][root][INFO] - Training Epoch: 9/10, step 262/574 completed (loss: 0.04407690092921257, acc: 1.0)
[2024-11-29 03:31:18,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:18,968][root][INFO] - Training Epoch: 9/10, step 263/574 completed (loss: 0.4419667422771454, acc: 0.8266666531562805)
[2024-11-29 03:31:19,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:19,198][root][INFO] - Training Epoch: 9/10, step 264/574 completed (loss: 0.4406451880931854, acc: 0.875)
[2024-11-29 03:31:19,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:19,919][root][INFO] - Training Epoch: 9/10, step 265/574 completed (loss: 0.9107096195220947, acc: 0.7440000176429749)
[2024-11-29 03:31:19,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:20,136][root][INFO] - Training Epoch: 9/10, step 266/574 completed (loss: 0.6128929257392883, acc: 0.7752808928489685)
[2024-11-29 03:31:20,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:20,383][root][INFO] - Training Epoch: 9/10, step 267/574 completed (loss: 0.3963726758956909, acc: 0.8648648858070374)
[2024-11-29 03:31:20,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:20,742][root][INFO] - Training Epoch: 9/10, step 268/574 completed (loss: 0.3437362313270569, acc: 0.8965517282485962)
[2024-11-29 03:31:20,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:20,942][root][INFO] - Training Epoch: 9/10, step 269/574 completed (loss: 0.0039601088501513, acc: 1.0)
[2024-11-29 03:31:21,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:22,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:22,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:22,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:22,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:22,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:23,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:23,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:23,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:24,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:24,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:24,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:24,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:25,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:25,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:25,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:25,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:26,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:26,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:26,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:27,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:27,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:27,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:27,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:28,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:28,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:28,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:28,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:29,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:29,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:29,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:30,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:30,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:30,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:30,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:31,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:31,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:31,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:32,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:32,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:32,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:32,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:32,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:33,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:33,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:33,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:34,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:34,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:34,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:34,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:35,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:35,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:35,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:35,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:36,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:36,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:36,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:36,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:37,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:37,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:37,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:38,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:38,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:38,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:38,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:39,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:39,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:39,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:40,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:40,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:40,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:41,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:41,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:41,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:41,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:42,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:42,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:42,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:43,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:43,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:43,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:43,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:44,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:44,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:44,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:45,259][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.0815, device='cuda:0') eval_epoch_loss=tensor(1.1254, device='cuda:0') eval_epoch_acc=tensor(0.7703, device='cuda:0')
[2024-11-29 03:31:45,260][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:31:45,260][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:31:45,538][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_9_step_270_loss_1.1254260540008545/model.pt
[2024-11-29 03:31:45,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:45,753][root][INFO] - Training Epoch: 9/10, step 270/574 completed (loss: 0.012659761123359203, acc: 1.0)
[2024-11-29 03:31:45,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:45,951][root][INFO] - Training Epoch: 9/10, step 271/574 completed (loss: 0.08068564534187317, acc: 0.96875)
[2024-11-29 03:31:46,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:46,203][root][INFO] - Training Epoch: 9/10, step 272/574 completed (loss: 0.04004016891121864, acc: 0.9666666388511658)
[2024-11-29 03:31:46,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:46,494][root][INFO] - Training Epoch: 9/10, step 273/574 completed (loss: 0.3825772702693939, acc: 0.8999999761581421)
[2024-11-29 03:31:46,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:46,753][root][INFO] - Training Epoch: 9/10, step 274/574 completed (loss: 0.16406449675559998, acc: 0.9375)
[2024-11-29 03:31:46,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:46,936][root][INFO] - Training Epoch: 9/10, step 275/574 completed (loss: 0.06692305952310562, acc: 1.0)
[2024-11-29 03:31:47,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:47,194][root][INFO] - Training Epoch: 9/10, step 276/574 completed (loss: 0.014437859877943993, acc: 1.0)
[2024-11-29 03:31:47,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:47,403][root][INFO] - Training Epoch: 9/10, step 277/574 completed (loss: 0.020751100033521652, acc: 1.0)
[2024-11-29 03:31:47,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:47,632][root][INFO] - Training Epoch: 9/10, step 278/574 completed (loss: 0.1991596668958664, acc: 0.936170220375061)
[2024-11-29 03:31:47,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:47,884][root][INFO] - Training Epoch: 9/10, step 279/574 completed (loss: 0.24868567287921906, acc: 0.9583333134651184)
[2024-11-29 03:31:47,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:48,122][root][INFO] - Training Epoch: 9/10, step 280/574 completed (loss: 0.0466359406709671, acc: 0.9772727489471436)
[2024-11-29 03:31:48,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:48,443][root][INFO] - Training Epoch: 9/10, step 281/574 completed (loss: 0.4388996660709381, acc: 0.8554216623306274)
[2024-11-29 03:31:48,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:48,690][root][INFO] - Training Epoch: 9/10, step 282/574 completed (loss: 0.5060372352600098, acc: 0.8425925970077515)
[2024-11-29 03:31:48,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:48,941][root][INFO] - Training Epoch: 9/10, step 283/574 completed (loss: 0.041030675172805786, acc: 0.9736841917037964)
[2024-11-29 03:31:49,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:49,179][root][INFO] - Training Epoch: 9/10, step 284/574 completed (loss: 0.008070900104939938, acc: 1.0)
[2024-11-29 03:31:49,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:49,401][root][INFO] - Training Epoch: 9/10, step 285/574 completed (loss: 0.08418724685907364, acc: 0.9750000238418579)
[2024-11-29 03:31:49,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:49,655][root][INFO] - Training Epoch: 9/10, step 286/574 completed (loss: 0.338032990694046, acc: 0.90625)
[2024-11-29 03:31:49,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:49,937][root][INFO] - Training Epoch: 9/10, step 287/574 completed (loss: 0.30241987109184265, acc: 0.9120000004768372)
[2024-11-29 03:31:50,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:50,215][root][INFO] - Training Epoch: 9/10, step 288/574 completed (loss: 0.10581967979669571, acc: 0.9670329689979553)
[2024-11-29 03:31:50,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:50,461][root][INFO] - Training Epoch: 9/10, step 289/574 completed (loss: 0.23171547055244446, acc: 0.9378882050514221)
[2024-11-29 03:31:50,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:50,720][root][INFO] - Training Epoch: 9/10, step 290/574 completed (loss: 0.501115083694458, acc: 0.8402062058448792)
[2024-11-29 03:31:50,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:50,959][root][INFO] - Training Epoch: 9/10, step 291/574 completed (loss: 0.017023105174303055, acc: 1.0)
[2024-11-29 03:31:51,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:51,223][root][INFO] - Training Epoch: 9/10, step 292/574 completed (loss: 0.1488897204399109, acc: 0.9523809552192688)
[2024-11-29 03:31:51,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:51,447][root][INFO] - Training Epoch: 9/10, step 293/574 completed (loss: 0.13043878972530365, acc: 0.9655172228813171)
[2024-11-29 03:31:51,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:51,826][root][INFO] - Training Epoch: 9/10, step 294/574 completed (loss: 0.2150076925754547, acc: 0.9636363387107849)
[2024-11-29 03:31:51,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:52,281][root][INFO] - Training Epoch: 9/10, step 295/574 completed (loss: 0.5703370571136475, acc: 0.8350515365600586)
[2024-11-29 03:31:52,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:52,466][root][INFO] - Training Epoch: 9/10, step 296/574 completed (loss: 0.3080677390098572, acc: 0.931034505367279)
[2024-11-29 03:31:52,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:52,678][root][INFO] - Training Epoch: 9/10, step 297/574 completed (loss: 0.009952235966920853, acc: 1.0)
[2024-11-29 03:31:52,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:52,930][root][INFO] - Training Epoch: 9/10, step 298/574 completed (loss: 0.10297374427318573, acc: 0.9736841917037964)
[2024-11-29 03:31:53,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:53,189][root][INFO] - Training Epoch: 9/10, step 299/574 completed (loss: 0.09028327465057373, acc: 0.9821428656578064)
[2024-11-29 03:31:53,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:53,429][root][INFO] - Training Epoch: 9/10, step 300/574 completed (loss: 0.003689005272462964, acc: 1.0)
[2024-11-29 03:31:53,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:53,694][root][INFO] - Training Epoch: 9/10, step 301/574 completed (loss: 0.09937575459480286, acc: 0.9622641801834106)
[2024-11-29 03:31:53,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:53,979][root][INFO] - Training Epoch: 9/10, step 302/574 completed (loss: 0.009870890527963638, acc: 1.0)
[2024-11-29 03:31:54,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:54,264][root][INFO] - Training Epoch: 9/10, step 303/574 completed (loss: 0.02801692672073841, acc: 1.0)
[2024-11-29 03:31:54,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:54,525][root][INFO] - Training Epoch: 9/10, step 304/574 completed (loss: 0.019169867038726807, acc: 1.0)
[2024-11-29 03:31:54,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:54,782][root][INFO] - Training Epoch: 9/10, step 305/574 completed (loss: 0.27711808681488037, acc: 0.9180327653884888)
[2024-11-29 03:31:54,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:55,049][root][INFO] - Training Epoch: 9/10, step 306/574 completed (loss: 0.06754306703805923, acc: 0.9666666388511658)
[2024-11-29 03:31:55,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:55,328][root][INFO] - Training Epoch: 9/10, step 307/574 completed (loss: 0.02635538950562477, acc: 1.0)
[2024-11-29 03:31:55,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:55,557][root][INFO] - Training Epoch: 9/10, step 308/574 completed (loss: 0.046327657997608185, acc: 0.9855072498321533)
[2024-11-29 03:31:55,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:55,878][root][INFO] - Training Epoch: 9/10, step 309/574 completed (loss: 0.10552499443292618, acc: 0.9583333134651184)
[2024-11-29 03:31:55,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:56,087][root][INFO] - Training Epoch: 9/10, step 310/574 completed (loss: 0.11945684254169464, acc: 0.9759036302566528)
[2024-11-29 03:31:56,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:56,307][root][INFO] - Training Epoch: 9/10, step 311/574 completed (loss: 0.15464477241039276, acc: 0.9743589758872986)
[2024-11-29 03:31:56,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:56,586][root][INFO] - Training Epoch: 9/10, step 312/574 completed (loss: 0.10829157382249832, acc: 0.9591836929321289)
[2024-11-29 03:31:56,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:56,827][root][INFO] - Training Epoch: 9/10, step 313/574 completed (loss: 0.02860594354569912, acc: 1.0)
[2024-11-29 03:31:56,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:57,014][root][INFO] - Training Epoch: 9/10, step 314/574 completed (loss: 0.15205708146095276, acc: 0.9583333134651184)
[2024-11-29 03:31:57,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:57,300][root][INFO] - Training Epoch: 9/10, step 315/574 completed (loss: 0.01046669390052557, acc: 1.0)
[2024-11-29 03:31:57,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:57,554][root][INFO] - Training Epoch: 9/10, step 316/574 completed (loss: 0.6040627360343933, acc: 0.8064516186714172)
[2024-11-29 03:31:57,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:57,814][root][INFO] - Training Epoch: 9/10, step 317/574 completed (loss: 0.06928617507219315, acc: 0.9701492786407471)
[2024-11-29 03:31:57,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:58,098][root][INFO] - Training Epoch: 9/10, step 318/574 completed (loss: 0.09399369359016418, acc: 0.9903846383094788)
[2024-11-29 03:31:58,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:58,323][root][INFO] - Training Epoch: 9/10, step 319/574 completed (loss: 0.03654018044471741, acc: 1.0)
[2024-11-29 03:31:58,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:58,551][root][INFO] - Training Epoch: 9/10, step 320/574 completed (loss: 0.08366658538579941, acc: 0.9677419066429138)
[2024-11-29 03:31:58,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:58,792][root][INFO] - Training Epoch: 9/10, step 321/574 completed (loss: 0.014147883281111717, acc: 1.0)
[2024-11-29 03:31:58,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:59,021][root][INFO] - Training Epoch: 9/10, step 322/574 completed (loss: 0.5659493803977966, acc: 0.8148148059844971)
[2024-11-29 03:31:59,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:59,289][root][INFO] - Training Epoch: 9/10, step 323/574 completed (loss: 0.9775633811950684, acc: 0.7428571581840515)
[2024-11-29 03:31:59,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:59,546][root][INFO] - Training Epoch: 9/10, step 324/574 completed (loss: 0.5291892290115356, acc: 0.8461538553237915)
[2024-11-29 03:31:59,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:59,791][root][INFO] - Training Epoch: 9/10, step 325/574 completed (loss: 1.0724830627441406, acc: 0.6585366129875183)
[2024-11-29 03:31:59,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:00,059][root][INFO] - Training Epoch: 9/10, step 326/574 completed (loss: 0.49331504106521606, acc: 0.8421052694320679)
[2024-11-29 03:32:00,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:00,302][root][INFO] - Training Epoch: 9/10, step 327/574 completed (loss: 0.09234505891799927, acc: 1.0)
[2024-11-29 03:32:00,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:00,531][root][INFO] - Training Epoch: 9/10, step 328/574 completed (loss: 0.07652846723794937, acc: 0.9642857313156128)
[2024-11-29 03:32:00,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:00,783][root][INFO] - Training Epoch: 9/10, step 329/574 completed (loss: 0.0331299863755703, acc: 1.0)
[2024-11-29 03:32:00,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:00,997][root][INFO] - Training Epoch: 9/10, step 330/574 completed (loss: 0.02265494503080845, acc: 1.0)
[2024-11-29 03:32:01,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:01,217][root][INFO] - Training Epoch: 9/10, step 331/574 completed (loss: 0.1094926968216896, acc: 0.9677419066429138)
[2024-11-29 03:32:01,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:01,496][root][INFO] - Training Epoch: 9/10, step 332/574 completed (loss: 0.04308033362030983, acc: 1.0)
[2024-11-29 03:32:01,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:01,686][root][INFO] - Training Epoch: 9/10, step 333/574 completed (loss: 0.016676392406225204, acc: 1.0)
[2024-11-29 03:32:01,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:01,897][root][INFO] - Training Epoch: 9/10, step 334/574 completed (loss: 0.037688855081796646, acc: 1.0)
[2024-11-29 03:32:01,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:02,103][root][INFO] - Training Epoch: 9/10, step 335/574 completed (loss: 0.02866455726325512, acc: 1.0)
[2024-11-29 03:32:02,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:02,343][root][INFO] - Training Epoch: 9/10, step 336/574 completed (loss: 0.5915767550468445, acc: 0.7799999713897705)
[2024-11-29 03:32:02,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:02,628][root][INFO] - Training Epoch: 9/10, step 337/574 completed (loss: 0.5521802306175232, acc: 0.8505747318267822)
[2024-11-29 03:32:02,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:02,910][root][INFO] - Training Epoch: 9/10, step 338/574 completed (loss: 0.7177326679229736, acc: 0.8191489577293396)
[2024-11-29 03:32:03,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:03,178][root][INFO] - Training Epoch: 9/10, step 339/574 completed (loss: 0.6968457102775574, acc: 0.8072289228439331)
[2024-11-29 03:32:03,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:03,378][root][INFO] - Training Epoch: 9/10, step 340/574 completed (loss: 0.005368351005017757, acc: 1.0)
[2024-11-29 03:32:03,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:03,559][root][INFO] - Training Epoch: 9/10, step 341/574 completed (loss: 0.15291234850883484, acc: 0.9487179517745972)
[2024-11-29 03:32:03,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:03,808][root][INFO] - Training Epoch: 9/10, step 342/574 completed (loss: 0.3451905846595764, acc: 0.9036144614219666)
[2024-11-29 03:32:03,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:04,032][root][INFO] - Training Epoch: 9/10, step 343/574 completed (loss: 0.45569396018981934, acc: 0.8679245114326477)
[2024-11-29 03:32:04,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:04,273][root][INFO] - Training Epoch: 9/10, step 344/574 completed (loss: 0.123127780854702, acc: 0.9873417615890503)
[2024-11-29 03:32:04,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:04,547][root][INFO] - Training Epoch: 9/10, step 345/574 completed (loss: 0.01750362478196621, acc: 1.0)
[2024-11-29 03:32:04,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:04,793][root][INFO] - Training Epoch: 9/10, step 346/574 completed (loss: 0.2560383379459381, acc: 0.9402984976768494)
[2024-11-29 03:32:04,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:05,043][root][INFO] - Training Epoch: 9/10, step 347/574 completed (loss: 0.0034848912619054317, acc: 1.0)
[2024-11-29 03:32:05,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:05,289][root][INFO] - Training Epoch: 9/10, step 348/574 completed (loss: 0.1520325243473053, acc: 0.9599999785423279)
[2024-11-29 03:32:05,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:05,597][root][INFO] - Training Epoch: 9/10, step 349/574 completed (loss: 0.3820619285106659, acc: 0.8888888955116272)
[2024-11-29 03:32:05,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:05,806][root][INFO] - Training Epoch: 9/10, step 350/574 completed (loss: 0.17489872872829437, acc: 0.9069767594337463)
[2024-11-29 03:32:05,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:06,056][root][INFO] - Training Epoch: 9/10, step 351/574 completed (loss: 0.08454079180955887, acc: 1.0)
[2024-11-29 03:32:06,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:06,332][root][INFO] - Training Epoch: 9/10, step 352/574 completed (loss: 0.2312128096818924, acc: 0.9111111164093018)
[2024-11-29 03:32:06,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:06,541][root][INFO] - Training Epoch: 9/10, step 353/574 completed (loss: 0.015965204685926437, acc: 1.0)
[2024-11-29 03:32:06,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:06,762][root][INFO] - Training Epoch: 9/10, step 354/574 completed (loss: 0.1848517805337906, acc: 0.9230769276618958)
[2024-11-29 03:32:06,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:07,068][root][INFO] - Training Epoch: 9/10, step 355/574 completed (loss: 0.3723726272583008, acc: 0.9120879173278809)
[2024-11-29 03:32:07,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:07,518][root][INFO] - Training Epoch: 9/10, step 356/574 completed (loss: 0.3604311943054199, acc: 0.8695651888847351)
[2024-11-29 03:32:07,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:07,786][root][INFO] - Training Epoch: 9/10, step 357/574 completed (loss: 0.3521387279033661, acc: 0.8586956262588501)
[2024-11-29 03:32:07,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:08,042][root][INFO] - Training Epoch: 9/10, step 358/574 completed (loss: 0.142807275056839, acc: 0.9591836929321289)
[2024-11-29 03:32:08,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:08,315][root][INFO] - Training Epoch: 9/10, step 359/574 completed (loss: 0.06973598152399063, acc: 0.9583333134651184)
[2024-11-29 03:32:08,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:08,637][root][INFO] - Training Epoch: 9/10, step 360/574 completed (loss: 0.03624496981501579, acc: 1.0)
[2024-11-29 03:32:08,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:08,899][root][INFO] - Training Epoch: 9/10, step 361/574 completed (loss: 0.3088955879211426, acc: 0.8536585569381714)
[2024-11-29 03:32:09,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:09,163][root][INFO] - Training Epoch: 9/10, step 362/574 completed (loss: 0.21978875994682312, acc: 0.9111111164093018)
[2024-11-29 03:32:09,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:09,432][root][INFO] - Training Epoch: 9/10, step 363/574 completed (loss: 0.04944673180580139, acc: 1.0)
[2024-11-29 03:32:09,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:09,674][root][INFO] - Training Epoch: 9/10, step 364/574 completed (loss: 0.1170259341597557, acc: 0.9756097793579102)
[2024-11-29 03:32:09,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:09,914][root][INFO] - Training Epoch: 9/10, step 365/574 completed (loss: 0.029661666601896286, acc: 1.0)
[2024-11-29 03:32:09,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:10,127][root][INFO] - Training Epoch: 9/10, step 366/574 completed (loss: 0.0027975712437182665, acc: 1.0)
[2024-11-29 03:32:10,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:10,401][root][INFO] - Training Epoch: 9/10, step 367/574 completed (loss: 0.005523985717445612, acc: 1.0)
[2024-11-29 03:32:10,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:10,676][root][INFO] - Training Epoch: 9/10, step 368/574 completed (loss: 0.03298019990324974, acc: 1.0)
[2024-11-29 03:32:10,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:10,930][root][INFO] - Training Epoch: 9/10, step 369/574 completed (loss: 0.47711625695228577, acc: 0.84375)
[2024-11-29 03:32:11,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:11,477][root][INFO] - Training Epoch: 9/10, step 370/574 completed (loss: 0.616303563117981, acc: 0.8363636136054993)
[2024-11-29 03:32:11,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:12,276][root][INFO] - Training Epoch: 9/10, step 371/574 completed (loss: 0.30075642466545105, acc: 0.9245283007621765)
[2024-11-29 03:32:12,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:12,543][root][INFO] - Training Epoch: 9/10, step 372/574 completed (loss: 0.22539815306663513, acc: 0.9333333373069763)
[2024-11-29 03:32:12,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:12,795][root][INFO] - Training Epoch: 9/10, step 373/574 completed (loss: 0.036299921572208405, acc: 0.9821428656578064)
[2024-11-29 03:32:12,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:13,085][root][INFO] - Training Epoch: 9/10, step 374/574 completed (loss: 0.03588294982910156, acc: 1.0)
[2024-11-29 03:32:13,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:13,332][root][INFO] - Training Epoch: 9/10, step 375/574 completed (loss: 0.007198885083198547, acc: 1.0)
[2024-11-29 03:32:13,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:13,627][root][INFO] - Training Epoch: 9/10, step 376/574 completed (loss: 0.0038617809768766165, acc: 1.0)
[2024-11-29 03:32:13,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:13,877][root][INFO] - Training Epoch: 9/10, step 377/574 completed (loss: 0.1116398498415947, acc: 0.9375)
[2024-11-29 03:32:14,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:14,140][root][INFO] - Training Epoch: 9/10, step 378/574 completed (loss: 0.04944932460784912, acc: 0.9894737005233765)
[2024-11-29 03:32:14,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:14,654][root][INFO] - Training Epoch: 9/10, step 379/574 completed (loss: 0.25530725717544556, acc: 0.940119743347168)
[2024-11-29 03:32:14,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:14,966][root][INFO] - Training Epoch: 9/10, step 380/574 completed (loss: 0.2071858048439026, acc: 0.9398496150970459)
[2024-11-29 03:32:15,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:16,228][root][INFO] - Training Epoch: 9/10, step 381/574 completed (loss: 0.5955609679222107, acc: 0.8770053386688232)
[2024-11-29 03:32:16,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:16,706][root][INFO] - Training Epoch: 9/10, step 382/574 completed (loss: 0.11503147333860397, acc: 0.954954981803894)
[2024-11-29 03:32:16,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:16,932][root][INFO] - Training Epoch: 9/10, step 383/574 completed (loss: 0.11433331668376923, acc: 0.9285714030265808)
[2024-11-29 03:32:17,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:17,189][root][INFO] - Training Epoch: 9/10, step 384/574 completed (loss: 0.011521735228598118, acc: 1.0)
[2024-11-29 03:32:17,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:17,450][root][INFO] - Training Epoch: 9/10, step 385/574 completed (loss: 0.3129269778728485, acc: 0.875)
[2024-11-29 03:32:17,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:17,711][root][INFO] - Training Epoch: 9/10, step 386/574 completed (loss: 0.005534254014492035, acc: 1.0)
[2024-11-29 03:32:17,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:17,931][root][INFO] - Training Epoch: 9/10, step 387/574 completed (loss: 0.1270374059677124, acc: 0.9473684430122375)
[2024-11-29 03:32:18,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:18,177][root][INFO] - Training Epoch: 9/10, step 388/574 completed (loss: 0.013749370351433754, acc: 1.0)
[2024-11-29 03:32:18,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:18,441][root][INFO] - Training Epoch: 9/10, step 389/574 completed (loss: 0.005180911161005497, acc: 1.0)
[2024-11-29 03:32:18,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:18,693][root][INFO] - Training Epoch: 9/10, step 390/574 completed (loss: 0.08217401802539825, acc: 1.0)
[2024-11-29 03:32:18,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:18,935][root][INFO] - Training Epoch: 9/10, step 391/574 completed (loss: 0.31890466809272766, acc: 0.8518518805503845)
[2024-11-29 03:32:19,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:19,219][root][INFO] - Training Epoch: 9/10, step 392/574 completed (loss: 0.5183663964271545, acc: 0.8349514603614807)
[2024-11-29 03:32:19,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:19,687][root][INFO] - Training Epoch: 9/10, step 393/574 completed (loss: 0.664553165435791, acc: 0.8235294222831726)
[2024-11-29 03:32:19,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:19,954][root][INFO] - Training Epoch: 9/10, step 394/574 completed (loss: 0.42806360125541687, acc: 0.8799999952316284)
[2024-11-29 03:32:20,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:20,248][root][INFO] - Training Epoch: 9/10, step 395/574 completed (loss: 0.412458598613739, acc: 0.8611111044883728)
[2024-11-29 03:32:20,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:20,532][root][INFO] - Training Epoch: 9/10, step 396/574 completed (loss: 0.17303042113780975, acc: 0.8837209343910217)
[2024-11-29 03:32:20,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:20,762][root][INFO] - Training Epoch: 9/10, step 397/574 completed (loss: 0.029983727261424065, acc: 1.0)
[2024-11-29 03:32:20,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:20,991][root][INFO] - Training Epoch: 9/10, step 398/574 completed (loss: 0.06063874438405037, acc: 0.9767441749572754)
[2024-11-29 03:32:21,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:21,252][root][INFO] - Training Epoch: 9/10, step 399/574 completed (loss: 0.005618863273411989, acc: 1.0)
[2024-11-29 03:32:21,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:21,736][root][INFO] - Training Epoch: 9/10, step 400/574 completed (loss: 0.1339413970708847, acc: 0.9558823704719543)
[2024-11-29 03:32:21,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:21,983][root][INFO] - Training Epoch: 9/10, step 401/574 completed (loss: 0.12465053796768188, acc: 0.9599999785423279)
[2024-11-29 03:32:22,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:22,173][root][INFO] - Training Epoch: 9/10, step 402/574 completed (loss: 0.0879787877202034, acc: 0.9696969985961914)
[2024-11-29 03:32:22,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:22,431][root][INFO] - Training Epoch: 9/10, step 403/574 completed (loss: 0.018568815663456917, acc: 1.0)
[2024-11-29 03:32:22,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:22,682][root][INFO] - Training Epoch: 9/10, step 404/574 completed (loss: 0.24192528426647186, acc: 0.9032257795333862)
[2024-11-29 03:32:22,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:22,931][root][INFO] - Training Epoch: 9/10, step 405/574 completed (loss: 0.01008581556379795, acc: 1.0)
[2024-11-29 03:32:23,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:23,191][root][INFO] - Training Epoch: 9/10, step 406/574 completed (loss: 0.00822195503860712, acc: 1.0)
[2024-11-29 03:32:23,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:23,438][root][INFO] - Training Epoch: 9/10, step 407/574 completed (loss: 0.06279503554105759, acc: 0.9722222089767456)
[2024-11-29 03:32:23,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:23,714][root][INFO] - Training Epoch: 9/10, step 408/574 completed (loss: 0.017910856753587723, acc: 1.0)
[2024-11-29 03:32:23,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:23,926][root][INFO] - Training Epoch: 9/10, step 409/574 completed (loss: 0.12612217664718628, acc: 0.9230769276618958)
[2024-11-29 03:32:24,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:24,119][root][INFO] - Training Epoch: 9/10, step 410/574 completed (loss: 0.028118962422013283, acc: 1.0)
[2024-11-29 03:32:24,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:24,385][root][INFO] - Training Epoch: 9/10, step 411/574 completed (loss: 0.17728601396083832, acc: 0.9642857313156128)
[2024-11-29 03:32:24,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:24,605][root][INFO] - Training Epoch: 9/10, step 412/574 completed (loss: 0.01964743249118328, acc: 1.0)
[2024-11-29 03:32:25,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:25,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:25,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:26,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:26,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:26,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:27,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:27,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:27,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:27,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:28,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:28,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:28,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:28,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:29,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:29,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:29,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:30,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:30,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:30,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:30,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:31,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:31,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:31,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:32,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:32,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:32,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:32,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:33,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:33,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:33,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:33,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:33,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:34,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:34,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:34,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:34,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:35,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:35,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:35,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:36,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:36,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:36,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:36,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:37,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:37,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:37,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:37,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:38,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:38,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:38,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:38,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:38,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:39,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:39,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:39,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:39,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:40,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:40,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:40,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:40,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:41,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:41,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:41,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:41,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:42,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:42,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:42,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:43,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:43,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:43,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:43,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:44,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:44,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:44,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:44,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:45,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:45,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:45,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:45,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:46,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:46,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:46,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:46,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:47,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:47,655][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.0726, device='cuda:0') eval_epoch_loss=tensor(1.1225, device='cuda:0') eval_epoch_acc=tensor(0.7681, device='cuda:0')
[2024-11-29 03:32:47,657][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:32:47,657][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:32:47,847][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_9_step_413_loss_1.122521996498108/model.pt
[2024-11-29 03:32:47,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:48,113][root][INFO] - Training Epoch: 9/10, step 413/574 completed (loss: 0.08704791218042374, acc: 0.9696969985961914)
[2024-11-29 03:32:48,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:48,397][root][INFO] - Training Epoch: 9/10, step 414/574 completed (loss: 0.0070236860774457455, acc: 1.0)
[2024-11-29 03:32:48,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:48,651][root][INFO] - Training Epoch: 9/10, step 415/574 completed (loss: 0.14358870685100555, acc: 0.9019607901573181)
[2024-11-29 03:32:48,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:48,893][root][INFO] - Training Epoch: 9/10, step 416/574 completed (loss: 0.007923056371510029, acc: 1.0)
[2024-11-29 03:32:49,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:49,161][root][INFO] - Training Epoch: 9/10, step 417/574 completed (loss: 0.016420112922787666, acc: 1.0)
[2024-11-29 03:32:49,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:49,414][root][INFO] - Training Epoch: 9/10, step 418/574 completed (loss: 0.040813203901052475, acc: 1.0)
[2024-11-29 03:32:49,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:49,671][root][INFO] - Training Epoch: 9/10, step 419/574 completed (loss: 0.017168885096907616, acc: 1.0)
[2024-11-29 03:32:49,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:49,913][root][INFO] - Training Epoch: 9/10, step 420/574 completed (loss: 0.19107969105243683, acc: 0.9523809552192688)
[2024-11-29 03:32:50,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:50,177][root][INFO] - Training Epoch: 9/10, step 421/574 completed (loss: 0.06718125194311142, acc: 1.0)
[2024-11-29 03:32:50,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:50,422][root][INFO] - Training Epoch: 9/10, step 422/574 completed (loss: 0.06677771359682083, acc: 1.0)
[2024-11-29 03:32:50,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:50,702][root][INFO] - Training Epoch: 9/10, step 423/574 completed (loss: 0.06830432265996933, acc: 1.0)
[2024-11-29 03:32:50,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:50,919][root][INFO] - Training Epoch: 9/10, step 424/574 completed (loss: 0.021460413932800293, acc: 1.0)
[2024-11-29 03:32:51,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:51,163][root][INFO] - Training Epoch: 9/10, step 425/574 completed (loss: 0.009225144982337952, acc: 1.0)
[2024-11-29 03:32:51,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:51,390][root][INFO] - Training Epoch: 9/10, step 426/574 completed (loss: 0.03693906590342522, acc: 1.0)
[2024-11-29 03:32:51,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:51,651][root][INFO] - Training Epoch: 9/10, step 427/574 completed (loss: 0.15090081095695496, acc: 0.9189189076423645)
[2024-11-29 03:32:51,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:51,896][root][INFO] - Training Epoch: 9/10, step 428/574 completed (loss: 0.06770586222410202, acc: 0.9629629850387573)
[2024-11-29 03:32:52,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:52,136][root][INFO] - Training Epoch: 9/10, step 429/574 completed (loss: 0.15031369030475616, acc: 0.95652174949646)
[2024-11-29 03:32:52,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:52,386][root][INFO] - Training Epoch: 9/10, step 430/574 completed (loss: 0.005233982112258673, acc: 1.0)
[2024-11-29 03:32:52,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:52,610][root][INFO] - Training Epoch: 9/10, step 431/574 completed (loss: 0.0070033990778028965, acc: 1.0)
[2024-11-29 03:32:52,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:52,837][root][INFO] - Training Epoch: 9/10, step 432/574 completed (loss: 0.18990497291088104, acc: 0.95652174949646)
[2024-11-29 03:32:52,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:53,087][root][INFO] - Training Epoch: 9/10, step 433/574 completed (loss: 0.05698863044381142, acc: 1.0)
[2024-11-29 03:32:53,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:53,312][root][INFO] - Training Epoch: 9/10, step 434/574 completed (loss: 0.001563289319165051, acc: 1.0)
[2024-11-29 03:32:53,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:53,580][root][INFO] - Training Epoch: 9/10, step 435/574 completed (loss: 0.010927816852927208, acc: 1.0)
[2024-11-29 03:32:53,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:53,825][root][INFO] - Training Epoch: 9/10, step 436/574 completed (loss: 0.06977678090333939, acc: 0.9722222089767456)
[2024-11-29 03:32:53,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:54,073][root][INFO] - Training Epoch: 9/10, step 437/574 completed (loss: 0.025964636355638504, acc: 1.0)
[2024-11-29 03:32:54,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:54,344][root][INFO] - Training Epoch: 9/10, step 438/574 completed (loss: 0.0048201605677604675, acc: 1.0)
[2024-11-29 03:32:54,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:54,594][root][INFO] - Training Epoch: 9/10, step 439/574 completed (loss: 0.054889876395463943, acc: 1.0)
[2024-11-29 03:32:54,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:54,986][root][INFO] - Training Epoch: 9/10, step 440/574 completed (loss: 0.14363034069538116, acc: 0.9545454382896423)
[2024-11-29 03:32:55,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:55,714][root][INFO] - Training Epoch: 9/10, step 441/574 completed (loss: 0.5025296807289124, acc: 0.8240000009536743)
[2024-11-29 03:32:55,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:56,018][root][INFO] - Training Epoch: 9/10, step 442/574 completed (loss: 0.5163630247116089, acc: 0.8145161271095276)
[2024-11-29 03:32:56,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:56,579][root][INFO] - Training Epoch: 9/10, step 443/574 completed (loss: 0.5268841981887817, acc: 0.8407959938049316)
[2024-11-29 03:32:56,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:56,838][root][INFO] - Training Epoch: 9/10, step 444/574 completed (loss: 0.08950238674879074, acc: 0.9811320900917053)
[2024-11-29 03:32:56,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:57,173][root][INFO] - Training Epoch: 9/10, step 445/574 completed (loss: 0.013916530646383762, acc: 1.0)
[2024-11-29 03:32:57,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:57,431][root][INFO] - Training Epoch: 9/10, step 446/574 completed (loss: 0.1827152669429779, acc: 0.95652174949646)
[2024-11-29 03:32:57,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:57,704][root][INFO] - Training Epoch: 9/10, step 447/574 completed (loss: 0.04874410107731819, acc: 1.0)
[2024-11-29 03:32:57,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:57,948][root][INFO] - Training Epoch: 9/10, step 448/574 completed (loss: 0.04765983298420906, acc: 1.0)
[2024-11-29 03:32:58,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:58,186][root][INFO] - Training Epoch: 9/10, step 449/574 completed (loss: 0.11810091882944107, acc: 0.9552238583564758)
[2024-11-29 03:32:58,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:58,421][root][INFO] - Training Epoch: 9/10, step 450/574 completed (loss: 0.042067378759384155, acc: 0.9861111044883728)
[2024-11-29 03:32:58,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:58,658][root][INFO] - Training Epoch: 9/10, step 451/574 completed (loss: 0.03582208976149559, acc: 1.0)
[2024-11-29 03:32:58,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:58,913][root][INFO] - Training Epoch: 9/10, step 452/574 completed (loss: 0.05423787236213684, acc: 0.9871794581413269)
[2024-11-29 03:32:59,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:59,161][root][INFO] - Training Epoch: 9/10, step 453/574 completed (loss: 0.17762742936611176, acc: 0.9342105388641357)
[2024-11-29 03:32:59,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:59,392][root][INFO] - Training Epoch: 9/10, step 454/574 completed (loss: 0.06320105493068695, acc: 0.9795918464660645)
[2024-11-29 03:32:59,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:59,629][root][INFO] - Training Epoch: 9/10, step 455/574 completed (loss: 0.3392827808856964, acc: 0.939393937587738)
[2024-11-29 03:32:59,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:59,888][root][INFO] - Training Epoch: 9/10, step 456/574 completed (loss: 0.4993472397327423, acc: 0.876288652420044)
[2024-11-29 03:32:59,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:00,127][root][INFO] - Training Epoch: 9/10, step 457/574 completed (loss: 0.16794879734516144, acc: 0.9285714030265808)
[2024-11-29 03:33:00,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:00,427][root][INFO] - Training Epoch: 9/10, step 458/574 completed (loss: 0.46257221698760986, acc: 0.8895348906517029)
[2024-11-29 03:33:00,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:00,635][root][INFO] - Training Epoch: 9/10, step 459/574 completed (loss: 0.13439062237739563, acc: 0.9464285969734192)
[2024-11-29 03:33:00,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:00,880][root][INFO] - Training Epoch: 9/10, step 460/574 completed (loss: 0.2267387956380844, acc: 0.9259259104728699)
[2024-11-29 03:33:00,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:01,107][root][INFO] - Training Epoch: 9/10, step 461/574 completed (loss: 0.04883812367916107, acc: 1.0)
[2024-11-29 03:33:01,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:01,355][root][INFO] - Training Epoch: 9/10, step 462/574 completed (loss: 0.1870148479938507, acc: 0.9375)
[2024-11-29 03:33:01,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:01,602][root][INFO] - Training Epoch: 9/10, step 463/574 completed (loss: 0.08132510632276535, acc: 0.9615384340286255)
[2024-11-29 03:33:01,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:01,850][root][INFO] - Training Epoch: 9/10, step 464/574 completed (loss: 0.07546228170394897, acc: 0.97826087474823)
[2024-11-29 03:33:01,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:02,108][root][INFO] - Training Epoch: 9/10, step 465/574 completed (loss: 0.13399608433246613, acc: 0.9523809552192688)
[2024-11-29 03:33:02,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:02,387][root][INFO] - Training Epoch: 9/10, step 466/574 completed (loss: 0.7191195487976074, acc: 0.8313252925872803)
[2024-11-29 03:33:02,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:02,628][root][INFO] - Training Epoch: 9/10, step 467/574 completed (loss: 0.2366880476474762, acc: 0.9459459185600281)
[2024-11-29 03:33:02,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:02,874][root][INFO] - Training Epoch: 9/10, step 468/574 completed (loss: 0.4760211706161499, acc: 0.8737863898277283)
[2024-11-29 03:33:03,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:03,148][root][INFO] - Training Epoch: 9/10, step 469/574 completed (loss: 0.4427574872970581, acc: 0.8780487775802612)
[2024-11-29 03:33:03,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:03,394][root][INFO] - Training Epoch: 9/10, step 470/574 completed (loss: 0.009227457456290722, acc: 1.0)
[2024-11-29 03:33:03,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:03,609][root][INFO] - Training Epoch: 9/10, step 471/574 completed (loss: 0.04765265807509422, acc: 1.0)
[2024-11-29 03:33:03,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:03,938][root][INFO] - Training Epoch: 9/10, step 472/574 completed (loss: 0.2343677133321762, acc: 0.9411764740943909)
[2024-11-29 03:33:04,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:04,193][root][INFO] - Training Epoch: 9/10, step 473/574 completed (loss: 0.6956660747528076, acc: 0.7729257345199585)
[2024-11-29 03:33:04,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:04,451][root][INFO] - Training Epoch: 9/10, step 474/574 completed (loss: 0.21139538288116455, acc: 0.9270833134651184)
[2024-11-29 03:33:04,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:04,701][root][INFO] - Training Epoch: 9/10, step 475/574 completed (loss: 0.2642645537853241, acc: 0.9263803958892822)
[2024-11-29 03:33:04,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:04,953][root][INFO] - Training Epoch: 9/10, step 476/574 completed (loss: 0.24301676452159882, acc: 0.9208633303642273)
[2024-11-29 03:33:05,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:05,206][root][INFO] - Training Epoch: 9/10, step 477/574 completed (loss: 0.48816564679145813, acc: 0.839195966720581)
[2024-11-29 03:33:05,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:05,426][root][INFO] - Training Epoch: 9/10, step 478/574 completed (loss: 0.1235869824886322, acc: 0.9444444179534912)
[2024-11-29 03:33:05,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:05,672][root][INFO] - Training Epoch: 9/10, step 479/574 completed (loss: 0.03635983169078827, acc: 1.0)
[2024-11-29 03:33:05,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:05,891][root][INFO] - Training Epoch: 9/10, step 480/574 completed (loss: 0.19079473614692688, acc: 0.9629629850387573)
[2024-11-29 03:33:05,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:06,128][root][INFO] - Training Epoch: 9/10, step 481/574 completed (loss: 0.16640134155750275, acc: 0.949999988079071)
[2024-11-29 03:33:06,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:06,370][root][INFO] - Training Epoch: 9/10, step 482/574 completed (loss: 0.545677125453949, acc: 0.8500000238418579)
[2024-11-29 03:33:06,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:06,662][root][INFO] - Training Epoch: 9/10, step 483/574 completed (loss: 0.30378949642181396, acc: 0.8965517282485962)
[2024-11-29 03:33:06,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:06,865][root][INFO] - Training Epoch: 9/10, step 484/574 completed (loss: 0.02031417191028595, acc: 1.0)
[2024-11-29 03:33:06,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:07,081][root][INFO] - Training Epoch: 9/10, step 485/574 completed (loss: 0.048351533710956573, acc: 1.0)
[2024-11-29 03:33:07,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:07,359][root][INFO] - Training Epoch: 9/10, step 486/574 completed (loss: 0.3131977319717407, acc: 0.8888888955116272)
[2024-11-29 03:33:07,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:07,596][root][INFO] - Training Epoch: 9/10, step 487/574 completed (loss: 0.4872620105743408, acc: 0.9047619104385376)
[2024-11-29 03:33:07,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:07,836][root][INFO] - Training Epoch: 9/10, step 488/574 completed (loss: 0.4066726863384247, acc: 0.8181818127632141)
[2024-11-29 03:33:07,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:08,090][root][INFO] - Training Epoch: 9/10, step 489/574 completed (loss: 0.18734946846961975, acc: 0.9230769276618958)
[2024-11-29 03:33:08,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:08,315][root][INFO] - Training Epoch: 9/10, step 490/574 completed (loss: 0.015086213126778603, acc: 1.0)
[2024-11-29 03:33:08,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:08,535][root][INFO] - Training Epoch: 9/10, step 491/574 completed (loss: 0.1937922239303589, acc: 0.9655172228813171)
[2024-11-29 03:33:08,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:08,764][root][INFO] - Training Epoch: 9/10, step 492/574 completed (loss: 0.09297025203704834, acc: 0.9411764740943909)
[2024-11-29 03:33:08,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:08,991][root][INFO] - Training Epoch: 9/10, step 493/574 completed (loss: 0.07733211666345596, acc: 0.9655172228813171)
[2024-11-29 03:33:09,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:09,225][root][INFO] - Training Epoch: 9/10, step 494/574 completed (loss: 0.0330464206635952, acc: 1.0)
[2024-11-29 03:33:09,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:09,454][root][INFO] - Training Epoch: 9/10, step 495/574 completed (loss: 0.33286166191101074, acc: 0.8947368264198303)
[2024-11-29 03:33:09,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:09,704][root][INFO] - Training Epoch: 9/10, step 496/574 completed (loss: 0.3958001434803009, acc: 0.8928571343421936)
[2024-11-29 03:33:09,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:09,975][root][INFO] - Training Epoch: 9/10, step 497/574 completed (loss: 0.1498056948184967, acc: 0.9213483333587646)
[2024-11-29 03:33:10,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:10,194][root][INFO] - Training Epoch: 9/10, step 498/574 completed (loss: 0.30176278948783875, acc: 0.898876428604126)
[2024-11-29 03:33:10,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:10,431][root][INFO] - Training Epoch: 9/10, step 499/574 completed (loss: 0.7967413663864136, acc: 0.7801418304443359)
[2024-11-29 03:33:10,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:10,652][root][INFO] - Training Epoch: 9/10, step 500/574 completed (loss: 0.31132927536964417, acc: 0.9021739363670349)
[2024-11-29 03:33:10,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:10,872][root][INFO] - Training Epoch: 9/10, step 501/574 completed (loss: 0.021045831963419914, acc: 1.0)
[2024-11-29 03:33:10,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:11,100][root][INFO] - Training Epoch: 9/10, step 502/574 completed (loss: 0.004236205480992794, acc: 1.0)
[2024-11-29 03:33:11,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:11,341][root][INFO] - Training Epoch: 9/10, step 503/574 completed (loss: 0.26267409324645996, acc: 0.9259259104728699)
[2024-11-29 03:33:11,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:11,594][root][INFO] - Training Epoch: 9/10, step 504/574 completed (loss: 0.04167790710926056, acc: 1.0)
[2024-11-29 03:33:11,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:11,849][root][INFO] - Training Epoch: 9/10, step 505/574 completed (loss: 0.836744487285614, acc: 0.8113207817077637)
[2024-11-29 03:33:11,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:12,103][root][INFO] - Training Epoch: 9/10, step 506/574 completed (loss: 1.3261162042617798, acc: 0.7241379022598267)
[2024-11-29 03:33:12,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:12,669][root][INFO] - Training Epoch: 9/10, step 507/574 completed (loss: 0.866977334022522, acc: 0.7837837934494019)
[2024-11-29 03:33:12,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:13,039][root][INFO] - Training Epoch: 9/10, step 508/574 completed (loss: 0.6308261752128601, acc: 0.8028169274330139)
[2024-11-29 03:33:13,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:13,267][root][INFO] - Training Epoch: 9/10, step 509/574 completed (loss: 0.03166980296373367, acc: 1.0)
[2024-11-29 03:33:13,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:13,528][root][INFO] - Training Epoch: 9/10, step 510/574 completed (loss: 0.02502521313726902, acc: 1.0)
[2024-11-29 03:33:13,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:13,790][root][INFO] - Training Epoch: 9/10, step 511/574 completed (loss: 0.032592713832855225, acc: 1.0)
[2024-11-29 03:33:15,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:16,519][root][INFO] - Training Epoch: 9/10, step 512/574 completed (loss: 0.9500659108161926, acc: 0.7357142567634583)
[2024-11-29 03:33:16,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:17,241][root][INFO] - Training Epoch: 9/10, step 513/574 completed (loss: 0.2207949459552765, acc: 0.9603174328804016)
[2024-11-29 03:33:17,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:17,483][root][INFO] - Training Epoch: 9/10, step 514/574 completed (loss: 0.3676401972770691, acc: 0.8928571343421936)
[2024-11-29 03:33:17,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:17,725][root][INFO] - Training Epoch: 9/10, step 515/574 completed (loss: 0.06880049407482147, acc: 0.9833333492279053)
[2024-11-29 03:33:17,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:18,387][root][INFO] - Training Epoch: 9/10, step 516/574 completed (loss: 0.3134899139404297, acc: 0.9166666865348816)
[2024-11-29 03:33:18,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:18,644][root][INFO] - Training Epoch: 9/10, step 517/574 completed (loss: 0.14683745801448822, acc: 0.9615384340286255)
[2024-11-29 03:33:18,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:18,937][root][INFO] - Training Epoch: 9/10, step 518/574 completed (loss: 0.12947474420070648, acc: 0.9677419066429138)
[2024-11-29 03:33:19,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:19,195][root][INFO] - Training Epoch: 9/10, step 519/574 completed (loss: 0.3202381432056427, acc: 0.949999988079071)
[2024-11-29 03:33:19,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:19,411][root][INFO] - Training Epoch: 9/10, step 520/574 completed (loss: 0.12322252243757248, acc: 1.0)
[2024-11-29 03:33:19,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:20,400][root][INFO] - Training Epoch: 9/10, step 521/574 completed (loss: 0.7532097101211548, acc: 0.7966101765632629)
[2024-11-29 03:33:20,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:20,650][root][INFO] - Training Epoch: 9/10, step 522/574 completed (loss: 0.27181848883628845, acc: 0.9179104566574097)
[2024-11-29 03:33:20,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:20,947][root][INFO] - Training Epoch: 9/10, step 523/574 completed (loss: 0.30051952600479126, acc: 0.9124087691307068)
[2024-11-29 03:33:21,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:21,491][root][INFO] - Training Epoch: 9/10, step 524/574 completed (loss: 0.49679046869277954, acc: 0.8650000095367432)
[2024-11-29 03:33:21,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:21,741][root][INFO] - Training Epoch: 9/10, step 525/574 completed (loss: 0.017038924619555473, acc: 1.0)
[2024-11-29 03:33:21,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:22,025][root][INFO] - Training Epoch: 9/10, step 526/574 completed (loss: 0.07496464252471924, acc: 0.9807692170143127)
[2024-11-29 03:33:22,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:22,270][root][INFO] - Training Epoch: 9/10, step 527/574 completed (loss: 0.05767929553985596, acc: 1.0)
[2024-11-29 03:33:22,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:22,594][root][INFO] - Training Epoch: 9/10, step 528/574 completed (loss: 1.1208422183990479, acc: 0.688524603843689)
[2024-11-29 03:33:22,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:22,836][root][INFO] - Training Epoch: 9/10, step 529/574 completed (loss: 0.19565297663211823, acc: 0.9661017060279846)
[2024-11-29 03:33:22,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:23,083][root][INFO] - Training Epoch: 9/10, step 530/574 completed (loss: 1.3437739610671997, acc: 0.7674418687820435)
[2024-11-29 03:33:23,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:23,301][root][INFO] - Training Epoch: 9/10, step 531/574 completed (loss: 0.25212106108665466, acc: 0.9545454382896423)
[2024-11-29 03:33:23,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:23,548][root][INFO] - Training Epoch: 9/10, step 532/574 completed (loss: 0.7078722715377808, acc: 0.849056601524353)
[2024-11-29 03:33:23,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:23,806][root][INFO] - Training Epoch: 9/10, step 533/574 completed (loss: 0.2158905416727066, acc: 0.9318181872367859)
[2024-11-29 03:33:23,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:24,051][root][INFO] - Training Epoch: 9/10, step 534/574 completed (loss: 0.5009267926216125, acc: 0.8799999952316284)
[2024-11-29 03:33:24,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:24,323][root][INFO] - Training Epoch: 9/10, step 535/574 completed (loss: 0.08076958358287811, acc: 0.949999988079071)
[2024-11-29 03:33:24,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:24,608][root][INFO] - Training Epoch: 9/10, step 536/574 completed (loss: 0.01603878289461136, acc: 1.0)
[2024-11-29 03:33:24,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:24,949][root][INFO] - Training Epoch: 9/10, step 537/574 completed (loss: 0.20517200231552124, acc: 0.9384615421295166)
[2024-11-29 03:33:25,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:25,230][root][INFO] - Training Epoch: 9/10, step 538/574 completed (loss: 0.248657688498497, acc: 0.921875)
[2024-11-29 03:33:25,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:25,548][root][INFO] - Training Epoch: 9/10, step 539/574 completed (loss: 0.3021675646305084, acc: 0.90625)
[2024-11-29 03:33:25,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:25,807][root][INFO] - Training Epoch: 9/10, step 540/574 completed (loss: 0.8004467487335205, acc: 0.7878788113594055)
[2024-11-29 03:33:25,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:26,064][root][INFO] - Training Epoch: 9/10, step 541/574 completed (loss: 0.019124332815408707, acc: 1.0)
[2024-11-29 03:33:26,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:26,313][root][INFO] - Training Epoch: 9/10, step 542/574 completed (loss: 0.09893150627613068, acc: 0.9677419066429138)
[2024-11-29 03:33:26,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:26,547][root][INFO] - Training Epoch: 9/10, step 543/574 completed (loss: 0.0071243708953261375, acc: 1.0)
[2024-11-29 03:33:26,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:26,780][root][INFO] - Training Epoch: 9/10, step 544/574 completed (loss: 0.25415751338005066, acc: 0.9666666388511658)
[2024-11-29 03:33:26,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:27,024][root][INFO] - Training Epoch: 9/10, step 545/574 completed (loss: 0.09409613907337189, acc: 0.9756097793579102)
[2024-11-29 03:33:27,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:27,283][root][INFO] - Training Epoch: 9/10, step 546/574 completed (loss: 0.02231837622821331, acc: 1.0)
[2024-11-29 03:33:27,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:27,524][root][INFO] - Training Epoch: 9/10, step 547/574 completed (loss: 0.018198782578110695, acc: 1.0)
[2024-11-29 03:33:27,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:27,797][root][INFO] - Training Epoch: 9/10, step 548/574 completed (loss: 0.14852848649024963, acc: 0.9677419066429138)
[2024-11-29 03:33:27,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:28,034][root][INFO] - Training Epoch: 9/10, step 549/574 completed (loss: 0.016893845051527023, acc: 1.0)
[2024-11-29 03:33:28,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:28,289][root][INFO] - Training Epoch: 9/10, step 550/574 completed (loss: 0.05899127200245857, acc: 0.9696969985961914)
[2024-11-29 03:33:28,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:28,569][root][INFO] - Training Epoch: 9/10, step 551/574 completed (loss: 0.05453572794795036, acc: 0.9750000238418579)
[2024-11-29 03:33:28,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:28,799][root][INFO] - Training Epoch: 9/10, step 552/574 completed (loss: 0.1499159336090088, acc: 0.9142857193946838)
[2024-11-29 03:33:28,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:29,047][root][INFO] - Training Epoch: 9/10, step 553/574 completed (loss: 0.29969069361686707, acc: 0.9197080135345459)
[2024-11-29 03:33:29,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:29,270][root][INFO] - Training Epoch: 9/10, step 554/574 completed (loss: 0.2324827015399933, acc: 0.9241379499435425)
[2024-11-29 03:33:29,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:29,482][root][INFO] - Training Epoch: 9/10, step 555/574 completed (loss: 0.26292625069618225, acc: 0.9071428775787354)
[2024-11-29 03:33:30,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:30,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:30,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:31,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:31,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:31,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:31,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:32,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:32,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:32,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:33,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:33,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:33,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:34,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:34,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:34,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:34,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:35,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:35,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:35,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:35,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:36,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:36,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:36,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:36,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:37,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:37,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:37,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:37,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:38,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:38,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:38,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:38,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:39,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:39,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:39,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:40,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:40,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:40,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:40,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:41,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:41,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:41,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:41,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:42,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:42,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:42,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:42,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:43,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:43,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:43,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:43,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:44,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:44,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:44,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:45,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:45,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:45,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:45,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:45,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:46,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:46,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:46,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:47,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:47,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:47,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:47,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:48,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:48,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:48,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:48,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:49,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:49,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:49,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:50,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:50,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:50,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:50,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:51,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:51,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:51,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:51,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:52,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:52,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:52,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:53,346][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.0569, device='cuda:0') eval_epoch_loss=tensor(1.1174, device='cuda:0') eval_epoch_acc=tensor(0.7617, device='cuda:0')
[2024-11-29 03:33:53,347][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:33:53,347][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:33:53,562][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_9_step_556_loss_1.117404580116272/model.pt
[2024-11-29 03:33:53,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:53,833][root][INFO] - Training Epoch: 9/10, step 556/574 completed (loss: 0.2989916503429413, acc: 0.9139072895050049)
[2024-11-29 03:33:53,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:54,075][root][INFO] - Training Epoch: 9/10, step 557/574 completed (loss: 0.06343988329172134, acc: 0.9829059839248657)
[2024-11-29 03:33:54,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:54,342][root][INFO] - Training Epoch: 9/10, step 558/574 completed (loss: 0.007562196347862482, acc: 1.0)
[2024-11-29 03:33:54,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:54,631][root][INFO] - Training Epoch: 9/10, step 559/574 completed (loss: 0.04075213149189949, acc: 1.0)
[2024-11-29 03:33:54,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:54,806][root][INFO] - Training Epoch: 9/10, step 560/574 completed (loss: 0.0622706338763237, acc: 0.9615384340286255)
[2024-11-29 03:33:54,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:55,031][root][INFO] - Training Epoch: 9/10, step 561/574 completed (loss: 0.05944887176156044, acc: 0.9743589758872986)
[2024-11-29 03:33:55,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:55,273][root][INFO] - Training Epoch: 9/10, step 562/574 completed (loss: 0.2702576220035553, acc: 0.8999999761581421)
[2024-11-29 03:33:55,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:55,505][root][INFO] - Training Epoch: 9/10, step 563/574 completed (loss: 0.24928288161754608, acc: 0.9220778942108154)
[2024-11-29 03:33:55,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:55,748][root][INFO] - Training Epoch: 9/10, step 564/574 completed (loss: 0.14947070181369781, acc: 0.9375)
[2024-11-29 03:33:55,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:55,979][root][INFO] - Training Epoch: 9/10, step 565/574 completed (loss: 0.2210167795419693, acc: 0.9482758641242981)
[2024-11-29 03:33:56,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:56,198][root][INFO] - Training Epoch: 9/10, step 566/574 completed (loss: 0.07503119111061096, acc: 0.988095223903656)
[2024-11-29 03:33:56,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:56,399][root][INFO] - Training Epoch: 9/10, step 567/574 completed (loss: 0.05180182680487633, acc: 0.9736841917037964)
[2024-11-29 03:33:56,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:56,634][root][INFO] - Training Epoch: 9/10, step 568/574 completed (loss: 0.007783591281622648, acc: 1.0)
[2024-11-29 03:33:56,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:56,923][root][INFO] - Training Epoch: 9/10, step 569/574 completed (loss: 0.2920234501361847, acc: 0.9144384860992432)
[2024-11-29 03:33:57,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:57,130][root][INFO] - Training Epoch: 9/10, step 570/574 completed (loss: 0.03760448470711708, acc: 1.0)
[2024-11-29 03:33:57,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:57,361][root][INFO] - Training Epoch: 9/10, step 571/574 completed (loss: 0.06563913822174072, acc: 0.9914529919624329)
[2024-11-29 03:33:57,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:57,600][root][INFO] - Training Epoch: 9/10, step 572/574 completed (loss: 0.4437364935874939, acc: 0.8622449040412903)
[2024-11-29 03:33:57,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:57,860][root][INFO] - Training Epoch: 9/10, step 573/574 completed (loss: 0.24332566559314728, acc: 0.9182389974594116)
[2024-11-29 03:33:58,358][slam_llm.utils.train_utils][INFO] - Epoch 9: train_perplexity=1.3363, train_epoch_loss=0.2899, epoch time 265.5880475975573s
[2024-11-29 03:33:58,358][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 11 GB
[2024-11-29 03:33:58,358][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 16 GB
[2024-11-29 03:33:58,359][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 11 GB
[2024-11-29 03:33:58,359][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 14
[2024-11-29 03:33:58,359][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:33:58,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:59,045][root][INFO] - Training Epoch: 10/10, step 0/574 completed (loss: 0.015699582174420357, acc: 1.0)
[2024-11-29 03:33:59,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:59,277][root][INFO] - Training Epoch: 10/10, step 1/574 completed (loss: 0.01207810640335083, acc: 1.0)
[2024-11-29 03:33:59,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:59,485][root][INFO] - Training Epoch: 10/10, step 2/574 completed (loss: 0.13414929807186127, acc: 0.9459459185600281)
[2024-11-29 03:33:59,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:59,717][root][INFO] - Training Epoch: 10/10, step 3/574 completed (loss: 0.07510512322187424, acc: 0.9736841917037964)
[2024-11-29 03:33:59,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:59,978][root][INFO] - Training Epoch: 10/10, step 4/574 completed (loss: 0.16968609392642975, acc: 0.9729729890823364)
[2024-11-29 03:34:00,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:00,231][root][INFO] - Training Epoch: 10/10, step 5/574 completed (loss: 0.011266837827861309, acc: 1.0)
[2024-11-29 03:34:00,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:00,453][root][INFO] - Training Epoch: 10/10, step 6/574 completed (loss: 0.15115231275558472, acc: 0.9591836929321289)
[2024-11-29 03:34:00,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:00,647][root][INFO] - Training Epoch: 10/10, step 7/574 completed (loss: 0.14251475036144257, acc: 0.9333333373069763)
[2024-11-29 03:34:00,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:00,910][root][INFO] - Training Epoch: 10/10, step 8/574 completed (loss: 0.005576645489782095, acc: 1.0)
[2024-11-29 03:34:01,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:01,163][root][INFO] - Training Epoch: 10/10, step 9/574 completed (loss: 0.02998165413737297, acc: 1.0)
[2024-11-29 03:34:01,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:01,431][root][INFO] - Training Epoch: 10/10, step 10/574 completed (loss: 0.06323552131652832, acc: 0.9629629850387573)
[2024-11-29 03:34:01,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:01,637][root][INFO] - Training Epoch: 10/10, step 11/574 completed (loss: 0.05050309747457504, acc: 1.0)
[2024-11-29 03:34:01,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:01,881][root][INFO] - Training Epoch: 10/10, step 12/574 completed (loss: 0.020734969526529312, acc: 1.0)
[2024-11-29 03:34:02,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:02,163][root][INFO] - Training Epoch: 10/10, step 13/574 completed (loss: 0.1103910282254219, acc: 0.95652174949646)
[2024-11-29 03:34:02,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:02,415][root][INFO] - Training Epoch: 10/10, step 14/574 completed (loss: 0.03495701029896736, acc: 0.9803921580314636)
[2024-11-29 03:34:02,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:02,668][root][INFO] - Training Epoch: 10/10, step 15/574 completed (loss: 0.12051853537559509, acc: 0.9591836929321289)
[2024-11-29 03:34:02,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:02,913][root][INFO] - Training Epoch: 10/10, step 16/574 completed (loss: 0.0035477762576192617, acc: 1.0)
[2024-11-29 03:34:03,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:03,166][root][INFO] - Training Epoch: 10/10, step 17/574 completed (loss: 0.012382992543280125, acc: 1.0)
[2024-11-29 03:34:03,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:03,413][root][INFO] - Training Epoch: 10/10, step 18/574 completed (loss: 0.1484488546848297, acc: 0.9444444179534912)
[2024-11-29 03:34:03,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:03,661][root][INFO] - Training Epoch: 10/10, step 19/574 completed (loss: 0.22823257744312286, acc: 0.9473684430122375)
[2024-11-29 03:34:03,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:03,908][root][INFO] - Training Epoch: 10/10, step 20/574 completed (loss: 0.10938053578138351, acc: 0.9615384340286255)
[2024-11-29 03:34:04,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:04,123][root][INFO] - Training Epoch: 10/10, step 21/574 completed (loss: 0.02798190340399742, acc: 1.0)
[2024-11-29 03:34:04,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:04,271][root][INFO] - Training Epoch: 10/10, step 22/574 completed (loss: 0.07698654383420944, acc: 0.9599999785423279)
[2024-11-29 03:34:04,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:04,480][root][INFO] - Training Epoch: 10/10, step 23/574 completed (loss: 0.005449000280350447, acc: 1.0)
[2024-11-29 03:34:04,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:04,709][root][INFO] - Training Epoch: 10/10, step 24/574 completed (loss: 0.0980720967054367, acc: 0.9375)
[2024-11-29 03:34:04,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:04,965][root][INFO] - Training Epoch: 10/10, step 25/574 completed (loss: 0.323395311832428, acc: 0.9056603908538818)
[2024-11-29 03:34:05,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:05,204][root][INFO] - Training Epoch: 10/10, step 26/574 completed (loss: 0.3482263684272766, acc: 0.9178082346916199)
[2024-11-29 03:34:05,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:06,525][root][INFO] - Training Epoch: 10/10, step 27/574 completed (loss: 0.967030942440033, acc: 0.739130437374115)
[2024-11-29 03:34:06,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:06,705][root][INFO] - Training Epoch: 10/10, step 28/574 completed (loss: 0.19082973897457123, acc: 0.930232584476471)
[2024-11-29 03:34:06,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:06,926][root][INFO] - Training Epoch: 10/10, step 29/574 completed (loss: 0.24891531467437744, acc: 0.891566276550293)
[2024-11-29 03:34:07,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:07,163][root][INFO] - Training Epoch: 10/10, step 30/574 completed (loss: 0.3704976737499237, acc: 0.9012345671653748)
[2024-11-29 03:34:07,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:07,405][root][INFO] - Training Epoch: 10/10, step 31/574 completed (loss: 0.02381223253905773, acc: 1.0)
[2024-11-29 03:34:07,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:07,688][root][INFO] - Training Epoch: 10/10, step 32/574 completed (loss: 0.034528668969869614, acc: 1.0)
[2024-11-29 03:34:07,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:07,970][root][INFO] - Training Epoch: 10/10, step 33/574 completed (loss: 0.008293397724628448, acc: 1.0)
[2024-11-29 03:34:08,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:08,232][root][INFO] - Training Epoch: 10/10, step 34/574 completed (loss: 0.20430798828601837, acc: 0.9495798349380493)
[2024-11-29 03:34:08,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:08,500][root][INFO] - Training Epoch: 10/10, step 35/574 completed (loss: 0.1392296850681305, acc: 0.9508196711540222)
[2024-11-29 03:34:08,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:08,740][root][INFO] - Training Epoch: 10/10, step 36/574 completed (loss: 0.305597186088562, acc: 0.8888888955116272)
[2024-11-29 03:34:08,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:08,969][root][INFO] - Training Epoch: 10/10, step 37/574 completed (loss: 0.1605772227048874, acc: 0.9661017060279846)
[2024-11-29 03:34:09,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:09,244][root][INFO] - Training Epoch: 10/10, step 38/574 completed (loss: 0.24174700677394867, acc: 0.9195402264595032)
[2024-11-29 03:34:09,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:09,467][root][INFO] - Training Epoch: 10/10, step 39/574 completed (loss: 0.06436589360237122, acc: 1.0)
[2024-11-29 03:34:09,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:09,698][root][INFO] - Training Epoch: 10/10, step 40/574 completed (loss: 0.3103730082511902, acc: 0.9615384340286255)
[2024-11-29 03:34:09,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:09,990][root][INFO] - Training Epoch: 10/10, step 41/574 completed (loss: 0.34976431727409363, acc: 0.9324324131011963)
[2024-11-29 03:34:10,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:10,255][root][INFO] - Training Epoch: 10/10, step 42/574 completed (loss: 0.6037586331367493, acc: 0.892307698726654)
[2024-11-29 03:34:10,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:10,595][root][INFO] - Training Epoch: 10/10, step 43/574 completed (loss: 0.35175153613090515, acc: 0.8585858345031738)
[2024-11-29 03:34:10,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:10,910][root][INFO] - Training Epoch: 10/10, step 44/574 completed (loss: 0.31720924377441406, acc: 0.9175257682800293)
[2024-11-29 03:34:11,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:11,214][root][INFO] - Training Epoch: 10/10, step 45/574 completed (loss: 0.38636475801467896, acc: 0.875)
[2024-11-29 03:34:11,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:11,440][root][INFO] - Training Epoch: 10/10, step 46/574 completed (loss: 0.04012451320886612, acc: 1.0)
[2024-11-29 03:34:11,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:11,664][root][INFO] - Training Epoch: 10/10, step 47/574 completed (loss: 0.009319605305790901, acc: 1.0)
[2024-11-29 03:34:11,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:11,914][root][INFO] - Training Epoch: 10/10, step 48/574 completed (loss: 0.012023949064314365, acc: 1.0)
[2024-11-29 03:34:12,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:12,165][root][INFO] - Training Epoch: 10/10, step 49/574 completed (loss: 0.021367618814110756, acc: 1.0)
[2024-11-29 03:34:12,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:12,406][root][INFO] - Training Epoch: 10/10, step 50/574 completed (loss: 0.2471601814031601, acc: 0.9298245906829834)
[2024-11-29 03:34:12,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:12,675][root][INFO] - Training Epoch: 10/10, step 51/574 completed (loss: 0.4352308213710785, acc: 0.920634925365448)
[2024-11-29 03:34:12,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:12,923][root][INFO] - Training Epoch: 10/10, step 52/574 completed (loss: 0.3191424608230591, acc: 0.8873239159584045)
[2024-11-29 03:34:13,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:13,324][root][INFO] - Training Epoch: 10/10, step 53/574 completed (loss: 1.15418541431427, acc: 0.6866666674613953)
[2024-11-29 03:34:13,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:13,499][root][INFO] - Training Epoch: 10/10, step 54/574 completed (loss: 0.13235850632190704, acc: 0.9729729890823364)
[2024-11-29 03:34:13,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:13,662][root][INFO] - Training Epoch: 10/10, step 55/574 completed (loss: 0.011169134639203548, acc: 1.0)
[2024-11-29 03:34:14,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:16,098][root][INFO] - Training Epoch: 10/10, step 56/574 completed (loss: 1.0654938220977783, acc: 0.7064846158027649)
[2024-11-29 03:34:16,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:17,216][root][INFO] - Training Epoch: 10/10, step 57/574 completed (loss: 1.3484464883804321, acc: 0.6514161229133606)
[2024-11-29 03:34:17,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:17,736][root][INFO] - Training Epoch: 10/10, step 58/574 completed (loss: 0.4564704895019531, acc: 0.8465909361839294)
[2024-11-29 03:34:17,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:18,217][root][INFO] - Training Epoch: 10/10, step 59/574 completed (loss: 0.20773790776729584, acc: 0.9264705777168274)
[2024-11-29 03:34:18,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:18,685][root][INFO] - Training Epoch: 10/10, step 60/574 completed (loss: 0.5397368669509888, acc: 0.8333333134651184)
[2024-11-29 03:34:18,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:19,003][root][INFO] - Training Epoch: 10/10, step 61/574 completed (loss: 0.3342423141002655, acc: 0.9125000238418579)
[2024-11-29 03:34:19,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:19,273][root][INFO] - Training Epoch: 10/10, step 62/574 completed (loss: 0.1368941068649292, acc: 0.970588207244873)
[2024-11-29 03:34:19,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:19,523][root][INFO] - Training Epoch: 10/10, step 63/574 completed (loss: 0.017472542822360992, acc: 1.0)
[2024-11-29 03:34:19,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:19,759][root][INFO] - Training Epoch: 10/10, step 64/574 completed (loss: 0.19928696751594543, acc: 0.96875)
[2024-11-29 03:34:19,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:19,995][root][INFO] - Training Epoch: 10/10, step 65/574 completed (loss: 0.015694987028837204, acc: 1.0)
[2024-11-29 03:34:20,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:20,244][root][INFO] - Training Epoch: 10/10, step 66/574 completed (loss: 0.24263839423656464, acc: 0.9107142686843872)
[2024-11-29 03:34:20,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:20,495][root][INFO] - Training Epoch: 10/10, step 67/574 completed (loss: 0.10279650241136551, acc: 0.9833333492279053)
[2024-11-29 03:34:20,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:20,742][root][INFO] - Training Epoch: 10/10, step 68/574 completed (loss: 0.017230726778507233, acc: 1.0)
[2024-11-29 03:34:20,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:20,973][root][INFO] - Training Epoch: 10/10, step 69/574 completed (loss: 0.15277355909347534, acc: 0.9444444179534912)
[2024-11-29 03:34:21,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:21,185][root][INFO] - Training Epoch: 10/10, step 70/574 completed (loss: 0.07519061118364334, acc: 1.0)
[2024-11-29 03:34:21,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:21,406][root][INFO] - Training Epoch: 10/10, step 71/574 completed (loss: 0.7442560791969299, acc: 0.7647058963775635)
[2024-11-29 03:34:21,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:21,652][root][INFO] - Training Epoch: 10/10, step 72/574 completed (loss: 0.4954412579536438, acc: 0.8809523582458496)
[2024-11-29 03:34:21,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:21,876][root][INFO] - Training Epoch: 10/10, step 73/574 completed (loss: 1.0778361558914185, acc: 0.7179487347602844)
[2024-11-29 03:34:21,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:22,148][root][INFO] - Training Epoch: 10/10, step 74/574 completed (loss: 0.4023932218551636, acc: 0.8775510191917419)
[2024-11-29 03:34:22,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:22,461][root][INFO] - Training Epoch: 10/10, step 75/574 completed (loss: 0.6480194330215454, acc: 0.8432835936546326)
[2024-11-29 03:34:22,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:22,787][root][INFO] - Training Epoch: 10/10, step 76/574 completed (loss: 1.3237910270690918, acc: 0.6459854245185852)
[2024-11-29 03:34:22,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:23,031][root][INFO] - Training Epoch: 10/10, step 77/574 completed (loss: 0.004257907625287771, acc: 1.0)
[2024-11-29 03:34:23,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:23,239][root][INFO] - Training Epoch: 10/10, step 78/574 completed (loss: 0.010989555157721043, acc: 1.0)
[2024-11-29 03:34:23,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:23,471][root][INFO] - Training Epoch: 10/10, step 79/574 completed (loss: 0.11394252628087997, acc: 0.9696969985961914)
[2024-11-29 03:34:23,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:23,758][root][INFO] - Training Epoch: 10/10, step 80/574 completed (loss: 0.01893736608326435, acc: 1.0)
[2024-11-29 03:34:23,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:24,024][root][INFO] - Training Epoch: 10/10, step 81/574 completed (loss: 0.11002004146575928, acc: 0.9615384340286255)
[2024-11-29 03:34:24,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:24,272][root][INFO] - Training Epoch: 10/10, step 82/574 completed (loss: 0.3096346855163574, acc: 0.9038461446762085)
[2024-11-29 03:34:24,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:24,427][root][INFO] - Training Epoch: 10/10, step 83/574 completed (loss: 0.23552444577217102, acc: 0.9375)
[2024-11-29 03:34:24,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:24,614][root][INFO] - Training Epoch: 10/10, step 84/574 completed (loss: 0.10397908836603165, acc: 0.9710144996643066)
[2024-11-29 03:34:24,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:24,838][root][INFO] - Training Epoch: 10/10, step 85/574 completed (loss: 0.08826218545436859, acc: 0.9800000190734863)
[2024-11-29 03:34:24,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:25,039][root][INFO] - Training Epoch: 10/10, step 86/574 completed (loss: 0.04878612607717514, acc: 1.0)
[2024-11-29 03:34:25,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:25,427][root][INFO] - Training Epoch: 10/10, step 87/574 completed (loss: 0.5002907514572144, acc: 0.8999999761581421)
[2024-11-29 03:34:25,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:25,679][root][INFO] - Training Epoch: 10/10, step 88/574 completed (loss: 0.616948127746582, acc: 0.8543689250946045)
[2024-11-29 03:34:26,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:26,722][root][INFO] - Training Epoch: 10/10, step 89/574 completed (loss: 0.7234483957290649, acc: 0.8009708523750305)
[2024-11-29 03:34:26,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:27,450][root][INFO] - Training Epoch: 10/10, step 90/574 completed (loss: 1.1601755619049072, acc: 0.7311828136444092)
[2024-11-29 03:34:27,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:28,130][root][INFO] - Training Epoch: 10/10, step 91/574 completed (loss: 0.8310750722885132, acc: 0.7887930870056152)
[2024-11-29 03:34:28,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:28,762][root][INFO] - Training Epoch: 10/10, step 92/574 completed (loss: 0.5733137130737305, acc: 0.7894737124443054)
[2024-11-29 03:34:29,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:29,624][root][INFO] - Training Epoch: 10/10, step 93/574 completed (loss: 0.7660144567489624, acc: 0.7722772359848022)
[2024-11-29 03:34:29,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:29,853][root][INFO] - Training Epoch: 10/10, step 94/574 completed (loss: 0.37071436643600464, acc: 0.8709677457809448)
[2024-11-29 03:34:29,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:30,087][root][INFO] - Training Epoch: 10/10, step 95/574 completed (loss: 0.2919595241546631, acc: 0.9130434989929199)
[2024-11-29 03:34:30,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:30,329][root][INFO] - Training Epoch: 10/10, step 96/574 completed (loss: 0.5753431916236877, acc: 0.8151260614395142)
[2024-11-29 03:34:30,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:30,610][root][INFO] - Training Epoch: 10/10, step 97/574 completed (loss: 0.6560009717941284, acc: 0.817307710647583)
[2024-11-29 03:34:30,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:30,912][root][INFO] - Training Epoch: 10/10, step 98/574 completed (loss: 1.0184320211410522, acc: 0.7226277589797974)
[2024-11-29 03:34:31,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:31,172][root][INFO] - Training Epoch: 10/10, step 99/574 completed (loss: 0.7559663653373718, acc: 0.7910447716712952)
[2024-11-29 03:34:31,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:31,415][root][INFO] - Training Epoch: 10/10, step 100/574 completed (loss: 0.04080485180020332, acc: 1.0)
[2024-11-29 03:34:31,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:31,621][root][INFO] - Training Epoch: 10/10, step 101/574 completed (loss: 0.015750639140605927, acc: 1.0)
[2024-11-29 03:34:31,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:31,860][root][INFO] - Training Epoch: 10/10, step 102/574 completed (loss: 0.023524418473243713, acc: 1.0)
[2024-11-29 03:34:31,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:32,091][root][INFO] - Training Epoch: 10/10, step 103/574 completed (loss: 0.04140646755695343, acc: 0.9772727489471436)
[2024-11-29 03:34:32,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:32,329][root][INFO] - Training Epoch: 10/10, step 104/574 completed (loss: 0.13635708391666412, acc: 0.9482758641242981)
[2024-11-29 03:34:32,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:32,555][root][INFO] - Training Epoch: 10/10, step 105/574 completed (loss: 0.03933270275592804, acc: 1.0)
[2024-11-29 03:34:32,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:32,785][root][INFO] - Training Epoch: 10/10, step 106/574 completed (loss: 0.018826279789209366, acc: 1.0)
[2024-11-29 03:34:32,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:33,015][root][INFO] - Training Epoch: 10/10, step 107/574 completed (loss: 0.012390893884003162, acc: 1.0)
[2024-11-29 03:34:33,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:33,272][root][INFO] - Training Epoch: 10/10, step 108/574 completed (loss: 0.011732571758329868, acc: 1.0)
[2024-11-29 03:34:33,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:33,535][root][INFO] - Training Epoch: 10/10, step 109/574 completed (loss: 0.1428537368774414, acc: 0.9523809552192688)
[2024-11-29 03:34:33,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:33,805][root][INFO] - Training Epoch: 10/10, step 110/574 completed (loss: 0.032193828374147415, acc: 1.0)
[2024-11-29 03:34:33,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:34,126][root][INFO] - Training Epoch: 10/10, step 111/574 completed (loss: 0.08777378499507904, acc: 0.9824561476707458)
[2024-11-29 03:34:34,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:34,386][root][INFO] - Training Epoch: 10/10, step 112/574 completed (loss: 0.21842311322689056, acc: 0.9473684430122375)
[2024-11-29 03:34:34,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:34,615][root][INFO] - Training Epoch: 10/10, step 113/574 completed (loss: 0.1294047087430954, acc: 0.9487179517745972)
[2024-11-29 03:34:34,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:34,873][root][INFO] - Training Epoch: 10/10, step 114/574 completed (loss: 0.19341909885406494, acc: 0.9387755393981934)
[2024-11-29 03:34:34,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:35,097][root][INFO] - Training Epoch: 10/10, step 115/574 completed (loss: 0.036624208092689514, acc: 1.0)
[2024-11-29 03:34:35,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:35,371][root][INFO] - Training Epoch: 10/10, step 116/574 completed (loss: 0.1464042216539383, acc: 0.9841269850730896)
[2024-11-29 03:34:35,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:35,640][root][INFO] - Training Epoch: 10/10, step 117/574 completed (loss: 0.2855461537837982, acc: 0.9512194991111755)
[2024-11-29 03:34:35,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:35,872][root][INFO] - Training Epoch: 10/10, step 118/574 completed (loss: 0.03364413231611252, acc: 1.0)
[2024-11-29 03:34:36,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:36,658][root][INFO] - Training Epoch: 10/10, step 119/574 completed (loss: 0.8062019944190979, acc: 0.7832699418067932)
[2024-11-29 03:34:36,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:36,913][root][INFO] - Training Epoch: 10/10, step 120/574 completed (loss: 0.09602563083171844, acc: 0.9733333587646484)
[2024-11-29 03:34:37,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:37,225][root][INFO] - Training Epoch: 10/10, step 121/574 completed (loss: 0.11070811748504639, acc: 0.9807692170143127)
[2024-11-29 03:34:37,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:37,457][root][INFO] - Training Epoch: 10/10, step 122/574 completed (loss: 0.006888032425194979, acc: 1.0)
[2024-11-29 03:34:37,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:37,709][root][INFO] - Training Epoch: 10/10, step 123/574 completed (loss: 0.04768743738532066, acc: 1.0)
[2024-11-29 03:34:37,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:37,952][root][INFO] - Training Epoch: 10/10, step 124/574 completed (loss: 0.6629395484924316, acc: 0.803680956363678)
[2024-11-29 03:34:38,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:38,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:39,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:39,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:39,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:40,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:40,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:40,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:41,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:41,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:41,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:41,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:42,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:42,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:42,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:43,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:43,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:43,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:43,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:44,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:44,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:44,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:44,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:45,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:45,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:45,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:46,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:46,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:46,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:46,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:47,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:47,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:47,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:47,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:48,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:48,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:48,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:48,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:49,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:49,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:49,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:49,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:50,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:50,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:50,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:51,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:51,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:51,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:52,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:52,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:52,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:52,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:53,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:53,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:53,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:53,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:54,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:54,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:54,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:54,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:55,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:55,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:55,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:56,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:56,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:56,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:56,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:57,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:57,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:57,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:57,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:58,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:58,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:58,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:58,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:59,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:59,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:59,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:59,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:00,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:00,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:00,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:01,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:01,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:01,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:02,412][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.3537, device='cuda:0') eval_epoch_loss=tensor(1.2100, device='cuda:0') eval_epoch_acc=tensor(0.7637, device='cuda:0')
[2024-11-29 03:35:02,414][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:35:02,415][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:35:02,653][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_10_step_125_loss_1.2100495100021362/model.pt
[2024-11-29 03:35:02,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:02,963][root][INFO] - Training Epoch: 10/10, step 125/574 completed (loss: 0.8028161525726318, acc: 0.7708333134651184)
[2024-11-29 03:35:03,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:03,185][root][INFO] - Training Epoch: 10/10, step 126/574 completed (loss: 0.5379258990287781, acc: 0.8583333492279053)
[2024-11-29 03:35:03,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:03,454][root][INFO] - Training Epoch: 10/10, step 127/574 completed (loss: 0.7325982451438904, acc: 0.761904776096344)
[2024-11-29 03:35:03,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:03,688][root][INFO] - Training Epoch: 10/10, step 128/574 completed (loss: 0.624563992023468, acc: 0.8410256505012512)
[2024-11-29 03:35:03,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:03,990][root][INFO] - Training Epoch: 10/10, step 129/574 completed (loss: 0.6762680411338806, acc: 0.8161764740943909)
[2024-11-29 03:35:04,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:04,225][root][INFO] - Training Epoch: 10/10, step 130/574 completed (loss: 0.46379411220550537, acc: 0.8846153616905212)
[2024-11-29 03:35:04,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:04,495][root][INFO] - Training Epoch: 10/10, step 131/574 completed (loss: 0.07127030193805695, acc: 1.0)
[2024-11-29 03:35:04,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:04,741][root][INFO] - Training Epoch: 10/10, step 132/574 completed (loss: 0.20001737773418427, acc: 0.9375)
[2024-11-29 03:35:04,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:04,980][root][INFO] - Training Epoch: 10/10, step 133/574 completed (loss: 0.20422808825969696, acc: 0.95652174949646)
[2024-11-29 03:35:05,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:05,208][root][INFO] - Training Epoch: 10/10, step 134/574 completed (loss: 0.03778133913874626, acc: 1.0)
[2024-11-29 03:35:05,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:05,456][root][INFO] - Training Epoch: 10/10, step 135/574 completed (loss: 0.018155159428715706, acc: 1.0)
[2024-11-29 03:35:05,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:05,714][root][INFO] - Training Epoch: 10/10, step 136/574 completed (loss: 0.4730706512928009, acc: 0.9285714030265808)
[2024-11-29 03:35:05,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:05,931][root][INFO] - Training Epoch: 10/10, step 137/574 completed (loss: 0.46532848477363586, acc: 0.8333333134651184)
[2024-11-29 03:35:06,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:06,161][root][INFO] - Training Epoch: 10/10, step 138/574 completed (loss: 0.09100065380334854, acc: 0.95652174949646)
[2024-11-29 03:35:06,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:06,382][root][INFO] - Training Epoch: 10/10, step 139/574 completed (loss: 0.3629932999610901, acc: 0.9047619104385376)
[2024-11-29 03:35:06,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:06,615][root][INFO] - Training Epoch: 10/10, step 140/574 completed (loss: 0.11162687838077545, acc: 1.0)
[2024-11-29 03:35:06,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:06,872][root][INFO] - Training Epoch: 10/10, step 141/574 completed (loss: 0.0947071835398674, acc: 0.9354838728904724)
[2024-11-29 03:35:07,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:07,178][root][INFO] - Training Epoch: 10/10, step 142/574 completed (loss: 0.130135178565979, acc: 0.9729729890823364)
[2024-11-29 03:35:07,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:07,650][root][INFO] - Training Epoch: 10/10, step 143/574 completed (loss: 0.3706357181072235, acc: 0.8771929740905762)
[2024-11-29 03:35:07,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:07,924][root][INFO] - Training Epoch: 10/10, step 144/574 completed (loss: 0.7292547821998596, acc: 0.7686567306518555)
[2024-11-29 03:35:08,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:08,184][root][INFO] - Training Epoch: 10/10, step 145/574 completed (loss: 0.3805774450302124, acc: 0.8979591727256775)
[2024-11-29 03:35:08,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:08,554][root][INFO] - Training Epoch: 10/10, step 146/574 completed (loss: 0.726584255695343, acc: 0.8085106611251831)
[2024-11-29 03:35:08,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:08,806][root][INFO] - Training Epoch: 10/10, step 147/574 completed (loss: 0.5125572085380554, acc: 0.8428571224212646)
[2024-11-29 03:35:08,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:09,066][root][INFO] - Training Epoch: 10/10, step 148/574 completed (loss: 0.5765637159347534, acc: 0.8928571343421936)
[2024-11-29 03:35:09,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:09,338][root][INFO] - Training Epoch: 10/10, step 149/574 completed (loss: 0.0815427377820015, acc: 0.95652174949646)
[2024-11-29 03:35:09,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:09,594][root][INFO] - Training Epoch: 10/10, step 150/574 completed (loss: 0.05204431340098381, acc: 1.0)
[2024-11-29 03:35:09,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:09,838][root][INFO] - Training Epoch: 10/10, step 151/574 completed (loss: 0.4279460906982422, acc: 0.8260869383811951)
[2024-11-29 03:35:09,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:10,099][root][INFO] - Training Epoch: 10/10, step 152/574 completed (loss: 0.5259751677513123, acc: 0.8305084705352783)
[2024-11-29 03:35:10,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:10,382][root][INFO] - Training Epoch: 10/10, step 153/574 completed (loss: 0.45646995306015015, acc: 0.9122806787490845)
[2024-11-29 03:35:10,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:10,609][root][INFO] - Training Epoch: 10/10, step 154/574 completed (loss: 0.3102230131626129, acc: 0.9054054021835327)
[2024-11-29 03:35:10,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:10,847][root][INFO] - Training Epoch: 10/10, step 155/574 completed (loss: 0.03318323567509651, acc: 1.0)
[2024-11-29 03:35:10,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:11,086][root][INFO] - Training Epoch: 10/10, step 156/574 completed (loss: 0.12767718732357025, acc: 1.0)
[2024-11-29 03:35:11,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:11,341][root][INFO] - Training Epoch: 10/10, step 157/574 completed (loss: 1.884909749031067, acc: 0.4736842215061188)
[2024-11-29 03:35:12,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:13,017][root][INFO] - Training Epoch: 10/10, step 158/574 completed (loss: 1.07762610912323, acc: 0.7297297120094299)
[2024-11-29 03:35:13,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:13,243][root][INFO] - Training Epoch: 10/10, step 159/574 completed (loss: 0.7330184578895569, acc: 0.8518518805503845)
[2024-11-29 03:35:13,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:13,549][root][INFO] - Training Epoch: 10/10, step 160/574 completed (loss: 1.2256547212600708, acc: 0.6511628031730652)
[2024-11-29 03:35:13,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:14,062][root][INFO] - Training Epoch: 10/10, step 161/574 completed (loss: 1.157679796218872, acc: 0.6941176652908325)
[2024-11-29 03:35:14,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:14,530][root][INFO] - Training Epoch: 10/10, step 162/574 completed (loss: 1.0100513696670532, acc: 0.7303370833396912)
[2024-11-29 03:35:14,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:14,775][root][INFO] - Training Epoch: 10/10, step 163/574 completed (loss: 0.3083643913269043, acc: 0.9090909361839294)
[2024-11-29 03:35:14,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:15,016][root][INFO] - Training Epoch: 10/10, step 164/574 completed (loss: 0.06139145419001579, acc: 1.0)
[2024-11-29 03:35:15,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:15,253][root][INFO] - Training Epoch: 10/10, step 165/574 completed (loss: 0.742745041847229, acc: 0.8275862336158752)
[2024-11-29 03:35:15,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:15,521][root][INFO] - Training Epoch: 10/10, step 166/574 completed (loss: 0.11107849329710007, acc: 0.9795918464660645)
[2024-11-29 03:35:15,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:15,782][root][INFO] - Training Epoch: 10/10, step 167/574 completed (loss: 0.362993061542511, acc: 0.9200000166893005)
[2024-11-29 03:35:15,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:16,099][root][INFO] - Training Epoch: 10/10, step 168/574 completed (loss: 0.2973908483982086, acc: 0.9166666865348816)
[2024-11-29 03:35:16,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:16,357][root][INFO] - Training Epoch: 10/10, step 169/574 completed (loss: 1.003511905670166, acc: 0.7647058963775635)
[2024-11-29 03:35:16,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:17,332][root][INFO] - Training Epoch: 10/10, step 170/574 completed (loss: 0.6735389828681946, acc: 0.8150684833526611)
[2024-11-29 03:35:17,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:17,565][root][INFO] - Training Epoch: 10/10, step 171/574 completed (loss: 0.1819840669631958, acc: 0.9583333134651184)
[2024-11-29 03:35:17,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:17,795][root][INFO] - Training Epoch: 10/10, step 172/574 completed (loss: 0.15707360208034515, acc: 0.9629629850387573)
[2024-11-29 03:35:17,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:18,058][root][INFO] - Training Epoch: 10/10, step 173/574 completed (loss: 0.30472180247306824, acc: 0.8928571343421936)
[2024-11-29 03:35:18,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:18,511][root][INFO] - Training Epoch: 10/10, step 174/574 completed (loss: 1.2108315229415894, acc: 0.7256637215614319)
[2024-11-29 03:35:18,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:18,735][root][INFO] - Training Epoch: 10/10, step 175/574 completed (loss: 0.6736290454864502, acc: 0.8115941882133484)
[2024-11-29 03:35:18,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:18,964][root][INFO] - Training Epoch: 10/10, step 176/574 completed (loss: 0.216766819357872, acc: 0.9204545617103577)
[2024-11-29 03:35:19,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:19,854][root][INFO] - Training Epoch: 10/10, step 177/574 completed (loss: 0.7312721610069275, acc: 0.7938931584358215)
[2024-11-29 03:35:20,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:20,430][root][INFO] - Training Epoch: 10/10, step 178/574 completed (loss: 0.7514040470123291, acc: 0.7777777910232544)
[2024-11-29 03:35:20,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:20,682][root][INFO] - Training Epoch: 10/10, step 179/574 completed (loss: 0.12801511585712433, acc: 0.9672130942344666)
[2024-11-29 03:35:20,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:20,914][root][INFO] - Training Epoch: 10/10, step 180/574 completed (loss: 0.020279845222830772, acc: 1.0)
[2024-11-29 03:35:20,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:21,084][root][INFO] - Training Epoch: 10/10, step 181/574 completed (loss: 0.049888454377651215, acc: 1.0)
[2024-11-29 03:35:21,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:21,350][root][INFO] - Training Epoch: 10/10, step 182/574 completed (loss: 0.025901181623339653, acc: 1.0)
[2024-11-29 03:35:21,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:21,627][root][INFO] - Training Epoch: 10/10, step 183/574 completed (loss: 0.042239949107170105, acc: 1.0)
[2024-11-29 03:35:21,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:21,904][root][INFO] - Training Epoch: 10/10, step 184/574 completed (loss: 0.6130101084709167, acc: 0.8580060601234436)
[2024-11-29 03:35:22,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:22,157][root][INFO] - Training Epoch: 10/10, step 185/574 completed (loss: 0.6177342534065247, acc: 0.8213256597518921)
[2024-11-29 03:35:22,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:22,564][root][INFO] - Training Epoch: 10/10, step 186/574 completed (loss: 0.47887498140335083, acc: 0.875)
[2024-11-29 03:35:22,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:22,991][root][INFO] - Training Epoch: 10/10, step 187/574 completed (loss: 0.8660518527030945, acc: 0.7786116600036621)
[2024-11-29 03:35:23,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:23,297][root][INFO] - Training Epoch: 10/10, step 188/574 completed (loss: 0.5073145627975464, acc: 0.8434163928031921)
[2024-11-29 03:35:23,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:23,527][root][INFO] - Training Epoch: 10/10, step 189/574 completed (loss: 0.07170525193214417, acc: 0.9599999785423279)
[2024-11-29 03:35:23,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:24,014][root][INFO] - Training Epoch: 10/10, step 190/574 completed (loss: 0.4575004577636719, acc: 0.8720930218696594)
[2024-11-29 03:35:24,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:24,781][root][INFO] - Training Epoch: 10/10, step 191/574 completed (loss: 1.0059361457824707, acc: 0.7063491940498352)
[2024-11-29 03:35:25,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:25,618][root][INFO] - Training Epoch: 10/10, step 192/574 completed (loss: 1.0541666746139526, acc: 0.7196969985961914)
[2024-11-29 03:35:25,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:26,286][root][INFO] - Training Epoch: 10/10, step 193/574 completed (loss: 0.3438229262828827, acc: 0.9058823585510254)
[2024-11-29 03:35:26,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:27,280][root][INFO] - Training Epoch: 10/10, step 194/574 completed (loss: 0.8906894326210022, acc: 0.7469135522842407)
[2024-11-29 03:35:27,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:28,124][root][INFO] - Training Epoch: 10/10, step 195/574 completed (loss: 0.1843545138835907, acc: 0.9193548560142517)
[2024-11-29 03:35:28,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:28,378][root][INFO] - Training Epoch: 10/10, step 196/574 completed (loss: 0.05348753184080124, acc: 0.9642857313156128)
[2024-11-29 03:35:28,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:28,610][root][INFO] - Training Epoch: 10/10, step 197/574 completed (loss: 0.39744889736175537, acc: 0.8999999761581421)
[2024-11-29 03:35:28,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:28,872][root][INFO] - Training Epoch: 10/10, step 198/574 completed (loss: 0.3218887150287628, acc: 0.9117646813392639)
[2024-11-29 03:35:28,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:29,147][root][INFO] - Training Epoch: 10/10, step 199/574 completed (loss: 1.0160303115844727, acc: 0.7647058963775635)
[2024-11-29 03:35:29,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:29,426][root][INFO] - Training Epoch: 10/10, step 200/574 completed (loss: 0.5605040788650513, acc: 0.8474576473236084)
[2024-11-29 03:35:29,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:29,683][root][INFO] - Training Epoch: 10/10, step 201/574 completed (loss: 0.6028337478637695, acc: 0.8656716346740723)
[2024-11-29 03:35:29,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:29,914][root][INFO] - Training Epoch: 10/10, step 202/574 completed (loss: 0.5418444275856018, acc: 0.844660222530365)
[2024-11-29 03:35:30,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:30,198][root][INFO] - Training Epoch: 10/10, step 203/574 completed (loss: 0.29375773668289185, acc: 0.9523809552192688)
[2024-11-29 03:35:30,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:30,461][root][INFO] - Training Epoch: 10/10, step 204/574 completed (loss: 0.06481358408927917, acc: 0.9780219793319702)
[2024-11-29 03:35:30,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:30,729][root][INFO] - Training Epoch: 10/10, step 205/574 completed (loss: 0.19436970353126526, acc: 0.9417040348052979)
[2024-11-29 03:35:30,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:31,048][root][INFO] - Training Epoch: 10/10, step 206/574 completed (loss: 0.36849677562713623, acc: 0.8700787425041199)
[2024-11-29 03:35:31,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:31,316][root][INFO] - Training Epoch: 10/10, step 207/574 completed (loss: 0.32216426730155945, acc: 0.9008620977401733)
[2024-11-29 03:35:31,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:31,599][root][INFO] - Training Epoch: 10/10, step 208/574 completed (loss: 0.3486163914203644, acc: 0.9166666865348816)
[2024-11-29 03:35:31,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:31,871][root][INFO] - Training Epoch: 10/10, step 209/574 completed (loss: 0.4256449043750763, acc: 0.8638132214546204)
[2024-11-29 03:35:31,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:32,082][root][INFO] - Training Epoch: 10/10, step 210/574 completed (loss: 0.24863556027412415, acc: 0.9347826242446899)
[2024-11-29 03:35:32,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:32,257][root][INFO] - Training Epoch: 10/10, step 211/574 completed (loss: 0.06384272873401642, acc: 0.95652174949646)
[2024-11-29 03:35:32,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:32,478][root][INFO] - Training Epoch: 10/10, step 212/574 completed (loss: 0.14122667908668518, acc: 0.9285714030265808)
[2024-11-29 03:35:32,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:32,743][root][INFO] - Training Epoch: 10/10, step 213/574 completed (loss: 0.14630787074565887, acc: 0.957446813583374)
[2024-11-29 03:35:32,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:33,370][root][INFO] - Training Epoch: 10/10, step 214/574 completed (loss: 0.2472905069589615, acc: 0.9461538195610046)
[2024-11-29 03:35:33,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:33,584][root][INFO] - Training Epoch: 10/10, step 215/574 completed (loss: 0.08510253578424454, acc: 0.9864864945411682)
[2024-11-29 03:35:33,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:33,821][root][INFO] - Training Epoch: 10/10, step 216/574 completed (loss: 0.09397366642951965, acc: 0.9418604373931885)
[2024-11-29 03:35:33,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:34,275][root][INFO] - Training Epoch: 10/10, step 217/574 completed (loss: 0.2018233984708786, acc: 0.9369369149208069)
[2024-11-29 03:35:34,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:34,569][root][INFO] - Training Epoch: 10/10, step 218/574 completed (loss: 0.19548296928405762, acc: 0.9333333373069763)
[2024-11-29 03:35:34,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:34,796][root][INFO] - Training Epoch: 10/10, step 219/574 completed (loss: 0.03811680153012276, acc: 1.0)
[2024-11-29 03:35:34,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:35,003][root][INFO] - Training Epoch: 10/10, step 220/574 completed (loss: 0.01866447925567627, acc: 1.0)
[2024-11-29 03:35:35,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:35,253][root][INFO] - Training Epoch: 10/10, step 221/574 completed (loss: 0.005640992894768715, acc: 1.0)
[2024-11-29 03:35:35,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:35,516][root][INFO] - Training Epoch: 10/10, step 222/574 completed (loss: 0.3199966251850128, acc: 0.942307710647583)
[2024-11-29 03:35:35,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:36,240][root][INFO] - Training Epoch: 10/10, step 223/574 completed (loss: 0.26416873931884766, acc: 0.9130434989929199)
[2024-11-29 03:35:36,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:36,691][root][INFO] - Training Epoch: 10/10, step 224/574 completed (loss: 0.41484135389328003, acc: 0.8863636255264282)
[2024-11-29 03:35:36,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:37,038][root][INFO] - Training Epoch: 10/10, step 225/574 completed (loss: 0.33490413427352905, acc: 0.9255319237709045)
[2024-11-29 03:35:37,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:37,289][root][INFO] - Training Epoch: 10/10, step 226/574 completed (loss: 0.1173476129770279, acc: 0.9622641801834106)
[2024-11-29 03:35:37,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:37,538][root][INFO] - Training Epoch: 10/10, step 227/574 completed (loss: 0.17367376387119293, acc: 0.949999988079071)
[2024-11-29 03:35:37,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:37,787][root][INFO] - Training Epoch: 10/10, step 228/574 completed (loss: 0.6941644549369812, acc: 0.8372092843055725)
[2024-11-29 03:35:37,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:38,029][root][INFO] - Training Epoch: 10/10, step 229/574 completed (loss: 0.6538746356964111, acc: 0.800000011920929)
[2024-11-29 03:35:38,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:38,295][root][INFO] - Training Epoch: 10/10, step 230/574 completed (loss: 2.0616462230682373, acc: 0.5368421077728271)
[2024-11-29 03:35:38,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:38,497][root][INFO] - Training Epoch: 10/10, step 231/574 completed (loss: 1.5216408967971802, acc: 0.6333333253860474)
[2024-11-29 03:35:38,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:38,829][root][INFO] - Training Epoch: 10/10, step 232/574 completed (loss: 1.5263102054595947, acc: 0.5666666626930237)
[2024-11-29 03:35:38,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:39,232][root][INFO] - Training Epoch: 10/10, step 233/574 completed (loss: 1.9459619522094727, acc: 0.5045871734619141)
[2024-11-29 03:35:39,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:39,611][root][INFO] - Training Epoch: 10/10, step 234/574 completed (loss: 1.371410846710205, acc: 0.607692301273346)
[2024-11-29 03:35:39,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:39,826][root][INFO] - Training Epoch: 10/10, step 235/574 completed (loss: 0.0397009551525116, acc: 1.0)
[2024-11-29 03:35:39,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:40,092][root][INFO] - Training Epoch: 10/10, step 236/574 completed (loss: 0.09897597879171371, acc: 1.0)
[2024-11-29 03:35:40,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:40,342][root][INFO] - Training Epoch: 10/10, step 237/574 completed (loss: 0.3643113374710083, acc: 0.8636363744735718)
[2024-11-29 03:35:40,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:40,606][root][INFO] - Training Epoch: 10/10, step 238/574 completed (loss: 0.536806583404541, acc: 0.9259259104728699)
[2024-11-29 03:35:40,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:40,826][root][INFO] - Training Epoch: 10/10, step 239/574 completed (loss: 0.2798503637313843, acc: 0.9428571462631226)
[2024-11-29 03:35:40,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:41,092][root][INFO] - Training Epoch: 10/10, step 240/574 completed (loss: 0.3676585257053375, acc: 0.9318181872367859)
[2024-11-29 03:35:41,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:41,353][root][INFO] - Training Epoch: 10/10, step 241/574 completed (loss: 0.2715565860271454, acc: 0.9772727489471436)
[2024-11-29 03:35:41,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:41,849][root][INFO] - Training Epoch: 10/10, step 242/574 completed (loss: 0.7462223172187805, acc: 0.7903226017951965)
[2024-11-29 03:35:41,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:42,283][root][INFO] - Training Epoch: 10/10, step 243/574 completed (loss: 0.3252613842487335, acc: 0.9090909361839294)
[2024-11-29 03:35:42,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:42,512][root][INFO] - Training Epoch: 10/10, step 244/574 completed (loss: 0.00878263358026743, acc: 1.0)
[2024-11-29 03:35:42,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:42,755][root][INFO] - Training Epoch: 10/10, step 245/574 completed (loss: 0.3630337715148926, acc: 0.8461538553237915)
[2024-11-29 03:35:42,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:42,997][root][INFO] - Training Epoch: 10/10, step 246/574 completed (loss: 0.052688442170619965, acc: 1.0)
[2024-11-29 03:35:43,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:43,203][root][INFO] - Training Epoch: 10/10, step 247/574 completed (loss: 0.06568266451358795, acc: 1.0)
[2024-11-29 03:35:43,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:43,467][root][INFO] - Training Epoch: 10/10, step 248/574 completed (loss: 0.08452659845352173, acc: 1.0)
[2024-11-29 03:35:43,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:43,738][root][INFO] - Training Epoch: 10/10, step 249/574 completed (loss: 0.05547944828867912, acc: 1.0)
[2024-11-29 03:35:43,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:44,003][root][INFO] - Training Epoch: 10/10, step 250/574 completed (loss: 0.02620663493871689, acc: 1.0)
[2024-11-29 03:35:44,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:44,265][root][INFO] - Training Epoch: 10/10, step 251/574 completed (loss: 0.07037382572889328, acc: 0.970588207244873)
[2024-11-29 03:35:44,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:44,511][root][INFO] - Training Epoch: 10/10, step 252/574 completed (loss: 0.02410133369266987, acc: 1.0)
[2024-11-29 03:35:44,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:44,714][root][INFO] - Training Epoch: 10/10, step 253/574 completed (loss: 0.019238349050283432, acc: 1.0)
[2024-11-29 03:35:44,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:44,903][root][INFO] - Training Epoch: 10/10, step 254/574 completed (loss: 0.008212273940443993, acc: 1.0)
[2024-11-29 03:35:44,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:45,102][root][INFO] - Training Epoch: 10/10, step 255/574 completed (loss: 0.04907521978020668, acc: 1.0)
[2024-11-29 03:35:45,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:45,295][root][INFO] - Training Epoch: 10/10, step 256/574 completed (loss: 0.08788599073886871, acc: 0.9824561476707458)
[2024-11-29 03:35:45,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:45,471][root][INFO] - Training Epoch: 10/10, step 257/574 completed (loss: 0.15039213001728058, acc: 0.9571428298950195)
[2024-11-29 03:35:45,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:45,734][root][INFO] - Training Epoch: 10/10, step 258/574 completed (loss: 0.09336010366678238, acc: 0.9736841917037964)
[2024-11-29 03:35:45,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:46,231][root][INFO] - Training Epoch: 10/10, step 259/574 completed (loss: 0.25734028220176697, acc: 0.9245283007621765)
[2024-11-29 03:35:46,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:46,724][root][INFO] - Training Epoch: 10/10, step 260/574 completed (loss: 0.2770824730396271, acc: 0.925000011920929)
[2024-11-29 03:35:46,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:46,908][root][INFO] - Training Epoch: 10/10, step 261/574 completed (loss: 0.11522441357374191, acc: 0.9444444179534912)
[2024-11-29 03:35:46,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:47,118][root][INFO] - Training Epoch: 10/10, step 262/574 completed (loss: 0.1211397796869278, acc: 0.9354838728904724)
[2024-11-29 03:35:47,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:47,360][root][INFO] - Training Epoch: 10/10, step 263/574 completed (loss: 0.48941054940223694, acc: 0.8799999952316284)
[2024-11-29 03:35:47,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:47,616][root][INFO] - Training Epoch: 10/10, step 264/574 completed (loss: 0.28490203619003296, acc: 0.8958333134651184)
[2024-11-29 03:35:47,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:48,419][root][INFO] - Training Epoch: 10/10, step 265/574 completed (loss: 0.8528282642364502, acc: 0.7680000066757202)
[2024-11-29 03:35:48,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:48,639][root][INFO] - Training Epoch: 10/10, step 266/574 completed (loss: 0.5652585625648499, acc: 0.8202247023582458)
[2024-11-29 03:35:48,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:48,885][root][INFO] - Training Epoch: 10/10, step 267/574 completed (loss: 0.3102429509162903, acc: 0.8783783912658691)
[2024-11-29 03:35:49,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:49,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:50,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:50,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:50,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:50,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:51,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:51,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:51,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:51,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:52,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:52,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:52,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:53,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:53,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:53,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:53,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:54,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:54,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:54,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:54,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:55,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:55,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:55,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:55,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:56,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:56,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:56,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:56,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:57,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:57,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:57,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:58,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:58,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:58,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:58,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:58,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:59,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:59,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:59,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:00,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:00,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:00,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:00,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:00,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:01,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:01,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:01,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:02,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:02,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:02,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:02,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:02,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:03,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:03,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:03,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:04,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:04,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:04,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:04,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:05,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:05,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:05,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:06,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:06,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:06,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:06,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:07,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:07,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:08,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:08,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:08,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:08,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:08,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:09,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:09,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:09,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:10,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:10,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:10,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:10,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:11,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:11,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:11,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:11,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:12,609][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.1325, device='cuda:0') eval_epoch_loss=tensor(1.1418, device='cuda:0') eval_epoch_acc=tensor(0.7669, device='cuda:0')
[2024-11-29 03:36:12,610][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:36:12,610][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:36:12,813][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_10_step_268_loss_1.141819953918457/model.pt
[2024-11-29 03:36:12,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:13,202][root][INFO] - Training Epoch: 10/10, step 268/574 completed (loss: 0.27122679352760315, acc: 0.9137930870056152)
[2024-11-29 03:36:13,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:13,413][root][INFO] - Training Epoch: 10/10, step 269/574 completed (loss: 0.07684773206710815, acc: 0.9545454382896423)
[2024-11-29 03:36:13,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:13,614][root][INFO] - Training Epoch: 10/10, step 270/574 completed (loss: 0.013227900490164757, acc: 1.0)
[2024-11-29 03:36:13,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:13,812][root][INFO] - Training Epoch: 10/10, step 271/574 completed (loss: 0.04624798893928528, acc: 1.0)
[2024-11-29 03:36:13,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:14,012][root][INFO] - Training Epoch: 10/10, step 272/574 completed (loss: 0.02522607333958149, acc: 1.0)
[2024-11-29 03:36:14,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:14,291][root][INFO] - Training Epoch: 10/10, step 273/574 completed (loss: 0.3768109977245331, acc: 0.8999999761581421)
[2024-11-29 03:36:14,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:14,495][root][INFO] - Training Epoch: 10/10, step 274/574 completed (loss: 0.010268856771290302, acc: 1.0)
[2024-11-29 03:36:14,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:14,699][root][INFO] - Training Epoch: 10/10, step 275/574 completed (loss: 0.020642943680286407, acc: 1.0)
[2024-11-29 03:36:14,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:14,911][root][INFO] - Training Epoch: 10/10, step 276/574 completed (loss: 0.024230513721704483, acc: 1.0)
[2024-11-29 03:36:15,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:15,129][root][INFO] - Training Epoch: 10/10, step 277/574 completed (loss: 0.005169436801224947, acc: 1.0)
[2024-11-29 03:36:15,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:15,340][root][INFO] - Training Epoch: 10/10, step 278/574 completed (loss: 0.13588233292102814, acc: 0.978723406791687)
[2024-11-29 03:36:15,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:15,568][root][INFO] - Training Epoch: 10/10, step 279/574 completed (loss: 0.07028020173311234, acc: 0.9791666865348816)
[2024-11-29 03:36:15,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:15,795][root][INFO] - Training Epoch: 10/10, step 280/574 completed (loss: 0.011476775631308556, acc: 1.0)
[2024-11-29 03:36:15,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:16,112][root][INFO] - Training Epoch: 10/10, step 281/574 completed (loss: 0.3217417597770691, acc: 0.9277108311653137)
[2024-11-29 03:36:16,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:16,356][root][INFO] - Training Epoch: 10/10, step 282/574 completed (loss: 0.45729637145996094, acc: 0.8611111044883728)
[2024-11-29 03:36:16,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:16,511][root][INFO] - Training Epoch: 10/10, step 283/574 completed (loss: 0.011161339469254017, acc: 1.0)
[2024-11-29 03:36:16,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:16,679][root][INFO] - Training Epoch: 10/10, step 284/574 completed (loss: 0.055950988084077835, acc: 0.970588207244873)
[2024-11-29 03:36:16,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:16,888][root][INFO] - Training Epoch: 10/10, step 285/574 completed (loss: 0.2422773540019989, acc: 0.949999988079071)
[2024-11-29 03:36:16,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:17,090][root][INFO] - Training Epoch: 10/10, step 286/574 completed (loss: 0.32408103346824646, acc: 0.921875)
[2024-11-29 03:36:17,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:17,327][root][INFO] - Training Epoch: 10/10, step 287/574 completed (loss: 0.18194662034511566, acc: 0.9520000219345093)
[2024-11-29 03:36:17,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:17,543][root][INFO] - Training Epoch: 10/10, step 288/574 completed (loss: 0.12608185410499573, acc: 0.9560439586639404)
[2024-11-29 03:36:17,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:17,827][root][INFO] - Training Epoch: 10/10, step 289/574 completed (loss: 0.1486695259809494, acc: 0.9627329111099243)
[2024-11-29 03:36:17,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:18,101][root][INFO] - Training Epoch: 10/10, step 290/574 completed (loss: 0.388381689786911, acc: 0.8814433217048645)
[2024-11-29 03:36:18,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:18,289][root][INFO] - Training Epoch: 10/10, step 291/574 completed (loss: 0.027126789093017578, acc: 1.0)
[2024-11-29 03:36:18,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:18,565][root][INFO] - Training Epoch: 10/10, step 292/574 completed (loss: 0.09748397767543793, acc: 0.976190447807312)
[2024-11-29 03:36:18,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:18,847][root][INFO] - Training Epoch: 10/10, step 293/574 completed (loss: 0.2039143443107605, acc: 0.931034505367279)
[2024-11-29 03:36:19,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:19,251][root][INFO] - Training Epoch: 10/10, step 294/574 completed (loss: 0.2135971188545227, acc: 0.9454545378684998)
[2024-11-29 03:36:19,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:19,707][root][INFO] - Training Epoch: 10/10, step 295/574 completed (loss: 0.4208804965019226, acc: 0.8608247637748718)
[2024-11-29 03:36:19,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:19,903][root][INFO] - Training Epoch: 10/10, step 296/574 completed (loss: 0.26479315757751465, acc: 0.931034505367279)
[2024-11-29 03:36:19,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:20,130][root][INFO] - Training Epoch: 10/10, step 297/574 completed (loss: 0.00835126731544733, acc: 1.0)
[2024-11-29 03:36:20,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:20,348][root][INFO] - Training Epoch: 10/10, step 298/574 completed (loss: 0.07502355426549911, acc: 0.9736841917037964)
[2024-11-29 03:36:20,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:20,540][root][INFO] - Training Epoch: 10/10, step 299/574 completed (loss: 0.041166070848703384, acc: 0.9821428656578064)
[2024-11-29 03:36:20,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:20,742][root][INFO] - Training Epoch: 10/10, step 300/574 completed (loss: 0.114105723798275, acc: 0.96875)
[2024-11-29 03:36:20,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:20,920][root][INFO] - Training Epoch: 10/10, step 301/574 completed (loss: 0.11255329847335815, acc: 0.9622641801834106)
[2024-11-29 03:36:21,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:21,141][root][INFO] - Training Epoch: 10/10, step 302/574 completed (loss: 0.1712309569120407, acc: 0.9811320900917053)
[2024-11-29 03:36:21,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:21,378][root][INFO] - Training Epoch: 10/10, step 303/574 completed (loss: 0.09798143059015274, acc: 0.970588207244873)
[2024-11-29 03:36:21,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:21,615][root][INFO] - Training Epoch: 10/10, step 304/574 completed (loss: 0.010738505981862545, acc: 1.0)
[2024-11-29 03:36:21,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:21,892][root][INFO] - Training Epoch: 10/10, step 305/574 completed (loss: 0.22182965278625488, acc: 0.9180327653884888)
[2024-11-29 03:36:21,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:22,086][root][INFO] - Training Epoch: 10/10, step 306/574 completed (loss: 0.00620083324611187, acc: 1.0)
[2024-11-29 03:36:22,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:22,327][root][INFO] - Training Epoch: 10/10, step 307/574 completed (loss: 0.002747579710558057, acc: 1.0)
[2024-11-29 03:36:22,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:22,598][root][INFO] - Training Epoch: 10/10, step 308/574 completed (loss: 0.06323246657848358, acc: 0.9855072498321533)
[2024-11-29 03:36:22,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:22,917][root][INFO] - Training Epoch: 10/10, step 309/574 completed (loss: 0.16256067156791687, acc: 0.9583333134651184)
[2024-11-29 03:36:23,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:23,177][root][INFO] - Training Epoch: 10/10, step 310/574 completed (loss: 0.06710053980350494, acc: 0.9879518151283264)
[2024-11-29 03:36:23,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:23,463][root][INFO] - Training Epoch: 10/10, step 311/574 completed (loss: 0.18048784136772156, acc: 0.9487179517745972)
[2024-11-29 03:36:23,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:23,726][root][INFO] - Training Epoch: 10/10, step 312/574 completed (loss: 0.08855987340211868, acc: 0.9795918464660645)
[2024-11-29 03:36:23,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:23,983][root][INFO] - Training Epoch: 10/10, step 313/574 completed (loss: 0.01742335595190525, acc: 1.0)
[2024-11-29 03:36:24,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:24,167][root][INFO] - Training Epoch: 10/10, step 314/574 completed (loss: 0.009820747189223766, acc: 1.0)
[2024-11-29 03:36:24,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:24,400][root][INFO] - Training Epoch: 10/10, step 315/574 completed (loss: 0.02587028779089451, acc: 1.0)
[2024-11-29 03:36:24,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:24,669][root][INFO] - Training Epoch: 10/10, step 316/574 completed (loss: 0.3720388412475586, acc: 0.9354838728904724)
[2024-11-29 03:36:24,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:24,920][root][INFO] - Training Epoch: 10/10, step 317/574 completed (loss: 0.03991357609629631, acc: 1.0)
[2024-11-29 03:36:25,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:25,176][root][INFO] - Training Epoch: 10/10, step 318/574 completed (loss: 0.10415767878293991, acc: 0.9711538553237915)
[2024-11-29 03:36:25,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:25,396][root][INFO] - Training Epoch: 10/10, step 319/574 completed (loss: 0.04980602115392685, acc: 1.0)
[2024-11-29 03:36:25,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:25,638][root][INFO] - Training Epoch: 10/10, step 320/574 completed (loss: 0.020893385633826256, acc: 1.0)
[2024-11-29 03:36:25,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:25,872][root][INFO] - Training Epoch: 10/10, step 321/574 completed (loss: 0.009222310036420822, acc: 1.0)
[2024-11-29 03:36:25,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:26,128][root][INFO] - Training Epoch: 10/10, step 322/574 completed (loss: 0.34244275093078613, acc: 0.8888888955116272)
[2024-11-29 03:36:26,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:26,325][root][INFO] - Training Epoch: 10/10, step 323/574 completed (loss: 0.6013731360435486, acc: 0.800000011920929)
[2024-11-29 03:36:26,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:26,587][root][INFO] - Training Epoch: 10/10, step 324/574 completed (loss: 0.4404902458190918, acc: 0.8717948794364929)
[2024-11-29 03:36:26,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:26,826][root][INFO] - Training Epoch: 10/10, step 325/574 completed (loss: 0.7626147866249084, acc: 0.7804877758026123)
[2024-11-29 03:36:26,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:27,074][root][INFO] - Training Epoch: 10/10, step 326/574 completed (loss: 0.39124321937561035, acc: 0.9210526347160339)
[2024-11-29 03:36:27,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:27,298][root][INFO] - Training Epoch: 10/10, step 327/574 completed (loss: 0.10665139555931091, acc: 0.9473684430122375)
[2024-11-29 03:36:27,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:27,540][root][INFO] - Training Epoch: 10/10, step 328/574 completed (loss: 0.009584689512848854, acc: 1.0)
[2024-11-29 03:36:27,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:27,789][root][INFO] - Training Epoch: 10/10, step 329/574 completed (loss: 0.009634984657168388, acc: 1.0)
[2024-11-29 03:36:27,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:28,045][root][INFO] - Training Epoch: 10/10, step 330/574 completed (loss: 0.00449727987870574, acc: 1.0)
[2024-11-29 03:36:28,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:28,308][root][INFO] - Training Epoch: 10/10, step 331/574 completed (loss: 0.06768923997879028, acc: 0.9838709831237793)
[2024-11-29 03:36:28,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:28,588][root][INFO] - Training Epoch: 10/10, step 332/574 completed (loss: 0.044016607105731964, acc: 1.0)
[2024-11-29 03:36:28,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:28,777][root][INFO] - Training Epoch: 10/10, step 333/574 completed (loss: 0.07604677230119705, acc: 0.96875)
[2024-11-29 03:36:28,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:29,034][root][INFO] - Training Epoch: 10/10, step 334/574 completed (loss: 0.008246700279414654, acc: 1.0)
[2024-11-29 03:36:29,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:29,259][root][INFO] - Training Epoch: 10/10, step 335/574 completed (loss: 0.1749931275844574, acc: 0.8947368264198303)
[2024-11-29 03:36:29,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:29,486][root][INFO] - Training Epoch: 10/10, step 336/574 completed (loss: 0.16623106598854065, acc: 0.9399999976158142)
[2024-11-29 03:36:29,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:29,780][root][INFO] - Training Epoch: 10/10, step 337/574 completed (loss: 0.9252098202705383, acc: 0.7356321811676025)
[2024-11-29 03:36:29,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:30,018][root][INFO] - Training Epoch: 10/10, step 338/574 completed (loss: 0.44469207525253296, acc: 0.8936170339584351)
[2024-11-29 03:36:30,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:30,270][root][INFO] - Training Epoch: 10/10, step 339/574 completed (loss: 0.6522091031074524, acc: 0.8192771077156067)
[2024-11-29 03:36:30,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:30,512][root][INFO] - Training Epoch: 10/10, step 340/574 completed (loss: 0.007204502355307341, acc: 1.0)
[2024-11-29 03:36:30,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:30,740][root][INFO] - Training Epoch: 10/10, step 341/574 completed (loss: 0.0619957260787487, acc: 1.0)
[2024-11-29 03:36:30,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:30,987][root][INFO] - Training Epoch: 10/10, step 342/574 completed (loss: 0.09579717367887497, acc: 0.9759036302566528)
[2024-11-29 03:36:31,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:31,212][root][INFO] - Training Epoch: 10/10, step 343/574 completed (loss: 0.40098848938941956, acc: 0.9056603908538818)
[2024-11-29 03:36:31,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:31,451][root][INFO] - Training Epoch: 10/10, step 344/574 completed (loss: 0.1100853756070137, acc: 0.9620253443717957)
[2024-11-29 03:36:31,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:31,679][root][INFO] - Training Epoch: 10/10, step 345/574 completed (loss: 0.10694921761751175, acc: 0.9607843160629272)
[2024-11-29 03:36:31,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:31,925][root][INFO] - Training Epoch: 10/10, step 346/574 completed (loss: 0.26022785902023315, acc: 0.9552238583564758)
[2024-11-29 03:36:32,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:32,181][root][INFO] - Training Epoch: 10/10, step 347/574 completed (loss: 0.00422819284722209, acc: 1.0)
[2024-11-29 03:36:32,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:32,452][root][INFO] - Training Epoch: 10/10, step 348/574 completed (loss: 0.3457566797733307, acc: 0.9599999785423279)
[2024-11-29 03:36:32,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:32,763][root][INFO] - Training Epoch: 10/10, step 349/574 completed (loss: 0.3899574279785156, acc: 0.8611111044883728)
[2024-11-29 03:36:32,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:32,988][root][INFO] - Training Epoch: 10/10, step 350/574 completed (loss: 0.20928950607776642, acc: 0.930232584476471)
[2024-11-29 03:36:33,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:33,224][root][INFO] - Training Epoch: 10/10, step 351/574 completed (loss: 0.10818647593259811, acc: 0.9487179517745972)
[2024-11-29 03:36:33,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:33,501][root][INFO] - Training Epoch: 10/10, step 352/574 completed (loss: 0.2808959186077118, acc: 0.8888888955116272)
[2024-11-29 03:36:33,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:33,712][root][INFO] - Training Epoch: 10/10, step 353/574 completed (loss: 0.00832189992070198, acc: 1.0)
[2024-11-29 03:36:33,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:33,973][root][INFO] - Training Epoch: 10/10, step 354/574 completed (loss: 0.0965578556060791, acc: 1.0)
[2024-11-29 03:36:34,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:34,249][root][INFO] - Training Epoch: 10/10, step 355/574 completed (loss: 0.28185445070266724, acc: 0.8791208863258362)
[2024-11-29 03:36:34,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:34,689][root][INFO] - Training Epoch: 10/10, step 356/574 completed (loss: 0.39967525005340576, acc: 0.843478262424469)
[2024-11-29 03:36:34,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:34,920][root][INFO] - Training Epoch: 10/10, step 357/574 completed (loss: 0.31615301966667175, acc: 0.9130434989929199)
[2024-11-29 03:36:35,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:35,168][root][INFO] - Training Epoch: 10/10, step 358/574 completed (loss: 0.12411167472600937, acc: 0.9795918464660645)
[2024-11-29 03:36:35,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:35,378][root][INFO] - Training Epoch: 10/10, step 359/574 completed (loss: 0.006406574975699186, acc: 1.0)
[2024-11-29 03:36:35,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:35,606][root][INFO] - Training Epoch: 10/10, step 360/574 completed (loss: 0.056222762912511826, acc: 0.9615384340286255)
[2024-11-29 03:36:35,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:35,843][root][INFO] - Training Epoch: 10/10, step 361/574 completed (loss: 0.5097867846488953, acc: 0.8780487775802612)
[2024-11-29 03:36:35,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:36,084][root][INFO] - Training Epoch: 10/10, step 362/574 completed (loss: 0.20667703449726105, acc: 0.9555555582046509)
[2024-11-29 03:36:36,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:36,308][root][INFO] - Training Epoch: 10/10, step 363/574 completed (loss: 0.06541691720485687, acc: 0.9868420958518982)
[2024-11-29 03:36:36,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:36,517][root][INFO] - Training Epoch: 10/10, step 364/574 completed (loss: 0.058157503604888916, acc: 1.0)
[2024-11-29 03:36:36,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:36,738][root][INFO] - Training Epoch: 10/10, step 365/574 completed (loss: 0.0227125845849514, acc: 1.0)
[2024-11-29 03:36:36,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:36,973][root][INFO] - Training Epoch: 10/10, step 366/574 completed (loss: 0.03340644761919975, acc: 1.0)
[2024-11-29 03:36:37,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:37,209][root][INFO] - Training Epoch: 10/10, step 367/574 completed (loss: 0.029383817687630653, acc: 1.0)
[2024-11-29 03:36:37,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:37,459][root][INFO] - Training Epoch: 10/10, step 368/574 completed (loss: 0.23792687058448792, acc: 0.9642857313156128)
[2024-11-29 03:36:37,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:37,696][root][INFO] - Training Epoch: 10/10, step 369/574 completed (loss: 0.3394145965576172, acc: 0.96875)
[2024-11-29 03:36:37,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:38,211][root][INFO] - Training Epoch: 10/10, step 370/574 completed (loss: 0.4855117201805115, acc: 0.8727272748947144)
[2024-11-29 03:36:38,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:38,987][root][INFO] - Training Epoch: 10/10, step 371/574 completed (loss: 0.20857542753219604, acc: 0.9339622855186462)
[2024-11-29 03:36:39,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:39,219][root][INFO] - Training Epoch: 10/10, step 372/574 completed (loss: 0.09247195720672607, acc: 0.9555555582046509)
[2024-11-29 03:36:39,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:39,431][root][INFO] - Training Epoch: 10/10, step 373/574 completed (loss: 0.0556708462536335, acc: 0.9821428656578064)
[2024-11-29 03:36:39,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:39,671][root][INFO] - Training Epoch: 10/10, step 374/574 completed (loss: 0.09424515813589096, acc: 0.9714285731315613)
[2024-11-29 03:36:39,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:39,913][root][INFO] - Training Epoch: 10/10, step 375/574 completed (loss: 0.013523575849831104, acc: 1.0)
[2024-11-29 03:36:40,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:40,170][root][INFO] - Training Epoch: 10/10, step 376/574 completed (loss: 0.002876989310607314, acc: 1.0)
[2024-11-29 03:36:40,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:40,397][root][INFO] - Training Epoch: 10/10, step 377/574 completed (loss: 0.1108371913433075, acc: 0.9583333134651184)
[2024-11-29 03:36:40,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:40,620][root][INFO] - Training Epoch: 10/10, step 378/574 completed (loss: 0.030575912445783615, acc: 0.9894737005233765)
[2024-11-29 03:36:40,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:41,112][root][INFO] - Training Epoch: 10/10, step 379/574 completed (loss: 0.22575023770332336, acc: 0.946107804775238)
[2024-11-29 03:36:41,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:41,416][root][INFO] - Training Epoch: 10/10, step 380/574 completed (loss: 0.11351076513528824, acc: 0.969924807548523)
[2024-11-29 03:36:41,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:42,396][root][INFO] - Training Epoch: 10/10, step 381/574 completed (loss: 0.629929780960083, acc: 0.8342245817184448)
[2024-11-29 03:36:42,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:42,871][root][INFO] - Training Epoch: 10/10, step 382/574 completed (loss: 0.0680895522236824, acc: 0.9909909963607788)
[2024-11-29 03:36:42,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:43,088][root][INFO] - Training Epoch: 10/10, step 383/574 completed (loss: 0.053102221339941025, acc: 1.0)
[2024-11-29 03:36:43,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:43,317][root][INFO] - Training Epoch: 10/10, step 384/574 completed (loss: 0.0072563267312943935, acc: 1.0)
[2024-11-29 03:36:43,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:43,495][root][INFO] - Training Epoch: 10/10, step 385/574 completed (loss: 0.030449215322732925, acc: 1.0)
[2024-11-29 03:36:43,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:43,709][root][INFO] - Training Epoch: 10/10, step 386/574 completed (loss: 0.015980036929249763, acc: 1.0)
[2024-11-29 03:36:43,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:43,919][root][INFO] - Training Epoch: 10/10, step 387/574 completed (loss: 0.021429497748613358, acc: 1.0)
[2024-11-29 03:36:44,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:44,159][root][INFO] - Training Epoch: 10/10, step 388/574 completed (loss: 0.005677483044564724, acc: 1.0)
[2024-11-29 03:36:44,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:44,409][root][INFO] - Training Epoch: 10/10, step 389/574 completed (loss: 0.007260516285896301, acc: 1.0)
[2024-11-29 03:36:44,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:44,653][root][INFO] - Training Epoch: 10/10, step 390/574 completed (loss: 0.4975425601005554, acc: 0.9047619104385376)
[2024-11-29 03:36:44,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:44,890][root][INFO] - Training Epoch: 10/10, step 391/574 completed (loss: 0.3347897231578827, acc: 0.8518518805503845)
[2024-11-29 03:36:44,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:45,112][root][INFO] - Training Epoch: 10/10, step 392/574 completed (loss: 0.6360247135162354, acc: 0.8252426981925964)
[2024-11-29 03:36:45,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:45,542][root][INFO] - Training Epoch: 10/10, step 393/574 completed (loss: 0.7342696189880371, acc: 0.845588207244873)
[2024-11-29 03:36:45,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:45,824][root][INFO] - Training Epoch: 10/10, step 394/574 completed (loss: 0.45390188694000244, acc: 0.8600000143051147)
[2024-11-29 03:36:45,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:46,116][root][INFO] - Training Epoch: 10/10, step 395/574 completed (loss: 0.41899561882019043, acc: 0.8888888955116272)
[2024-11-29 03:36:46,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:46,345][root][INFO] - Training Epoch: 10/10, step 396/574 completed (loss: 0.12480394542217255, acc: 0.9534883499145508)
[2024-11-29 03:36:46,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:46,576][root][INFO] - Training Epoch: 10/10, step 397/574 completed (loss: 0.02344845049083233, acc: 1.0)
[2024-11-29 03:36:46,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:46,866][root][INFO] - Training Epoch: 10/10, step 398/574 completed (loss: 0.4147324562072754, acc: 0.8604651093482971)
[2024-11-29 03:36:46,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:47,097][root][INFO] - Training Epoch: 10/10, step 399/574 completed (loss: 0.11705588549375534, acc: 0.9200000166893005)
[2024-11-29 03:36:47,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:47,543][root][INFO] - Training Epoch: 10/10, step 400/574 completed (loss: 0.226187601685524, acc: 0.9264705777168274)
[2024-11-29 03:36:47,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:47,791][root][INFO] - Training Epoch: 10/10, step 401/574 completed (loss: 0.16321982443332672, acc: 0.9466666579246521)
[2024-11-29 03:36:47,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:48,019][root][INFO] - Training Epoch: 10/10, step 402/574 completed (loss: 0.11376683413982391, acc: 0.9696969985961914)
[2024-11-29 03:36:48,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:48,242][root][INFO] - Training Epoch: 10/10, step 403/574 completed (loss: 0.229203462600708, acc: 0.9090909361839294)
[2024-11-29 03:36:48,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:48,476][root][INFO] - Training Epoch: 10/10, step 404/574 completed (loss: 0.24015231430530548, acc: 0.9032257795333862)
[2024-11-29 03:36:48,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:48,739][root][INFO] - Training Epoch: 10/10, step 405/574 completed (loss: 0.013192235492169857, acc: 1.0)
[2024-11-29 03:36:48,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:48,958][root][INFO] - Training Epoch: 10/10, step 406/574 completed (loss: 0.022970760241150856, acc: 1.0)
[2024-11-29 03:36:49,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:49,218][root][INFO] - Training Epoch: 10/10, step 407/574 completed (loss: 0.029473373666405678, acc: 1.0)
[2024-11-29 03:36:49,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:49,429][root][INFO] - Training Epoch: 10/10, step 408/574 completed (loss: 0.0544431135058403, acc: 0.9629629850387573)
[2024-11-29 03:36:49,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:49,624][root][INFO] - Training Epoch: 10/10, step 409/574 completed (loss: 0.04378484934568405, acc: 1.0)
[2024-11-29 03:36:49,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:49,898][root][INFO] - Training Epoch: 10/10, step 410/574 completed (loss: 0.04541488364338875, acc: 1.0)
[2024-11-29 03:36:50,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:50,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:51,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:51,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:51,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:52,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:52,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:52,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:52,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:53,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:53,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:53,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:54,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:54,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:54,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:54,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:55,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:55,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:55,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:55,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:56,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:56,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:56,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:56,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:57,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:57,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:57,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:57,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:58,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:58,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:58,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:58,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:59,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:59,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:59,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:59,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:00,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:00,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:00,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:01,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:01,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:01,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:01,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:02,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:02,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:02,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:02,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:03,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:03,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:03,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:03,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:03,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:04,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:04,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:04,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:04,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:05,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:05,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:05,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:06,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:06,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:06,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:07,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:07,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:07,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:07,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:08,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:08,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:08,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:09,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:09,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:09,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:09,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:09,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:10,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:10,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:10,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:11,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:11,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:11,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:11,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:12,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:12,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:12,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:13,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:13,581][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.9287, device='cuda:0') eval_epoch_loss=tensor(1.0746, device='cuda:0') eval_epoch_acc=tensor(0.7624, device='cuda:0')
[2024-11-29 03:37:13,583][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:37:13,583][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:37:13,769][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_10_step_411_loss_1.0745502710342407/model.pt
[2024-11-29 03:37:13,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:14,069][root][INFO] - Training Epoch: 10/10, step 411/574 completed (loss: 0.05369294434785843, acc: 1.0)
[2024-11-29 03:37:14,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:14,314][root][INFO] - Training Epoch: 10/10, step 412/574 completed (loss: 0.050428759306669235, acc: 0.9666666388511658)
[2024-11-29 03:37:14,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:14,555][root][INFO] - Training Epoch: 10/10, step 413/574 completed (loss: 0.024826737120747566, acc: 1.0)
[2024-11-29 03:37:14,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:14,817][root][INFO] - Training Epoch: 10/10, step 414/574 completed (loss: 0.12268161028623581, acc: 0.9545454382896423)
[2024-11-29 03:37:14,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:15,088][root][INFO] - Training Epoch: 10/10, step 415/574 completed (loss: 0.1566091775894165, acc: 0.9607843160629272)
[2024-11-29 03:37:15,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:15,326][root][INFO] - Training Epoch: 10/10, step 416/574 completed (loss: 0.1588490754365921, acc: 0.9615384340286255)
[2024-11-29 03:37:15,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:15,592][root][INFO] - Training Epoch: 10/10, step 417/574 completed (loss: 0.07761172950267792, acc: 1.0)
[2024-11-29 03:37:15,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:15,847][root][INFO] - Training Epoch: 10/10, step 418/574 completed (loss: 0.09854014217853546, acc: 0.949999988079071)
[2024-11-29 03:37:15,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:16,056][root][INFO] - Training Epoch: 10/10, step 419/574 completed (loss: 0.0713704377412796, acc: 1.0)
[2024-11-29 03:37:16,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:16,305][root][INFO] - Training Epoch: 10/10, step 420/574 completed (loss: 0.056618671864271164, acc: 1.0)
[2024-11-29 03:37:16,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:16,565][root][INFO] - Training Epoch: 10/10, step 421/574 completed (loss: 0.03766316547989845, acc: 1.0)
[2024-11-29 03:37:16,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:16,807][root][INFO] - Training Epoch: 10/10, step 422/574 completed (loss: 0.027661222964525223, acc: 1.0)
[2024-11-29 03:37:16,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:17,035][root][INFO] - Training Epoch: 10/10, step 423/574 completed (loss: 0.11956766992807388, acc: 0.9722222089767456)
[2024-11-29 03:37:17,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:17,272][root][INFO] - Training Epoch: 10/10, step 424/574 completed (loss: 0.059531256556510925, acc: 0.9629629850387573)
[2024-11-29 03:37:17,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:17,531][root][INFO] - Training Epoch: 10/10, step 425/574 completed (loss: 0.031586769968271255, acc: 1.0)
[2024-11-29 03:37:17,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:17,803][root][INFO] - Training Epoch: 10/10, step 426/574 completed (loss: 0.006783283781260252, acc: 1.0)
[2024-11-29 03:37:17,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:18,068][root][INFO] - Training Epoch: 10/10, step 427/574 completed (loss: 0.08421444892883301, acc: 0.9729729890823364)
[2024-11-29 03:37:18,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:18,309][root][INFO] - Training Epoch: 10/10, step 428/574 completed (loss: 0.005685954820364714, acc: 1.0)
[2024-11-29 03:37:18,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:18,553][root][INFO] - Training Epoch: 10/10, step 429/574 completed (loss: 0.07395458966493607, acc: 0.95652174949646)
[2024-11-29 03:37:18,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:18,866][root][INFO] - Training Epoch: 10/10, step 430/574 completed (loss: 0.03267526254057884, acc: 1.0)
[2024-11-29 03:37:18,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:19,131][root][INFO] - Training Epoch: 10/10, step 431/574 completed (loss: 0.01363817322999239, acc: 1.0)
[2024-11-29 03:37:19,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:19,389][root][INFO] - Training Epoch: 10/10, step 432/574 completed (loss: 0.0031792577356100082, acc: 1.0)
[2024-11-29 03:37:19,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:19,683][root][INFO] - Training Epoch: 10/10, step 433/574 completed (loss: 0.017679430544376373, acc: 1.0)
[2024-11-29 03:37:19,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:19,908][root][INFO] - Training Epoch: 10/10, step 434/574 completed (loss: 0.0012713144533336163, acc: 1.0)
[2024-11-29 03:37:20,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:20,156][root][INFO] - Training Epoch: 10/10, step 435/574 completed (loss: 0.0021245141979306936, acc: 1.0)
[2024-11-29 03:37:20,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:20,415][root][INFO] - Training Epoch: 10/10, step 436/574 completed (loss: 0.06390056759119034, acc: 1.0)
[2024-11-29 03:37:20,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:20,636][root][INFO] - Training Epoch: 10/10, step 437/574 completed (loss: 0.052449896931648254, acc: 0.9772727489471436)
[2024-11-29 03:37:20,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:20,852][root][INFO] - Training Epoch: 10/10, step 438/574 completed (loss: 0.017299208790063858, acc: 1.0)
[2024-11-29 03:37:20,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:21,021][root][INFO] - Training Epoch: 10/10, step 439/574 completed (loss: 0.06828527897596359, acc: 1.0)
[2024-11-29 03:37:21,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:21,392][root][INFO] - Training Epoch: 10/10, step 440/574 completed (loss: 0.14058789610862732, acc: 0.9545454382896423)
[2024-11-29 03:37:21,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:22,022][root][INFO] - Training Epoch: 10/10, step 441/574 completed (loss: 0.534469723701477, acc: 0.8479999899864197)
[2024-11-29 03:37:22,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:22,325][root][INFO] - Training Epoch: 10/10, step 442/574 completed (loss: 0.44729283452033997, acc: 0.8629032373428345)
[2024-11-29 03:37:22,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:22,881][root][INFO] - Training Epoch: 10/10, step 443/574 completed (loss: 0.41979679465293884, acc: 0.8756219148635864)
[2024-11-29 03:37:22,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:23,107][root][INFO] - Training Epoch: 10/10, step 444/574 completed (loss: 0.03995116427540779, acc: 1.0)
[2024-11-29 03:37:23,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:23,431][root][INFO] - Training Epoch: 10/10, step 445/574 completed (loss: 0.012894093990325928, acc: 1.0)
[2024-11-29 03:37:23,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:23,668][root][INFO] - Training Epoch: 10/10, step 446/574 completed (loss: 0.059696923941373825, acc: 1.0)
[2024-11-29 03:37:23,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:23,917][root][INFO] - Training Epoch: 10/10, step 447/574 completed (loss: 0.007446276023983955, acc: 1.0)
[2024-11-29 03:37:24,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:24,148][root][INFO] - Training Epoch: 10/10, step 448/574 completed (loss: 0.10344351828098297, acc: 0.9642857313156128)
[2024-11-29 03:37:24,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:24,383][root][INFO] - Training Epoch: 10/10, step 449/574 completed (loss: 0.03779257833957672, acc: 0.9850746393203735)
[2024-11-29 03:37:24,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:24,622][root][INFO] - Training Epoch: 10/10, step 450/574 completed (loss: 0.04973677918314934, acc: 0.9861111044883728)
[2024-11-29 03:37:24,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:24,860][root][INFO] - Training Epoch: 10/10, step 451/574 completed (loss: 0.08508265763521194, acc: 0.97826087474823)
[2024-11-29 03:37:24,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:25,109][root][INFO] - Training Epoch: 10/10, step 452/574 completed (loss: 0.19873040914535522, acc: 0.9230769276618958)
[2024-11-29 03:37:25,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:25,330][root][INFO] - Training Epoch: 10/10, step 453/574 completed (loss: 0.21426093578338623, acc: 0.9342105388641357)
[2024-11-29 03:37:25,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:25,531][root][INFO] - Training Epoch: 10/10, step 454/574 completed (loss: 0.18999062478542328, acc: 0.9591836929321289)
[2024-11-29 03:37:25,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:25,722][root][INFO] - Training Epoch: 10/10, step 455/574 completed (loss: 0.03667387366294861, acc: 1.0)
[2024-11-29 03:37:25,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:25,884][root][INFO] - Training Epoch: 10/10, step 456/574 completed (loss: 0.2831500172615051, acc: 0.9278350472450256)
[2024-11-29 03:37:25,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:26,093][root][INFO] - Training Epoch: 10/10, step 457/574 completed (loss: 0.11559998989105225, acc: 0.9714285731315613)
[2024-11-29 03:37:26,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:26,380][root][INFO] - Training Epoch: 10/10, step 458/574 completed (loss: 0.26459282636642456, acc: 0.9186046719551086)
[2024-11-29 03:37:26,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:26,624][root][INFO] - Training Epoch: 10/10, step 459/574 completed (loss: 0.21684730052947998, acc: 0.9642857313156128)
[2024-11-29 03:37:26,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:26,845][root][INFO] - Training Epoch: 10/10, step 460/574 completed (loss: 0.16900815069675446, acc: 0.9259259104728699)
[2024-11-29 03:37:26,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:27,044][root][INFO] - Training Epoch: 10/10, step 461/574 completed (loss: 0.02277812547981739, acc: 1.0)
[2024-11-29 03:37:27,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:27,262][root][INFO] - Training Epoch: 10/10, step 462/574 completed (loss: 0.35220858454704285, acc: 0.9375)
[2024-11-29 03:37:27,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:27,511][root][INFO] - Training Epoch: 10/10, step 463/574 completed (loss: 0.019857017323374748, acc: 1.0)
[2024-11-29 03:37:27,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:27,786][root][INFO] - Training Epoch: 10/10, step 464/574 completed (loss: 0.05668839067220688, acc: 0.97826087474823)
[2024-11-29 03:37:27,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:28,037][root][INFO] - Training Epoch: 10/10, step 465/574 completed (loss: 0.14462679624557495, acc: 0.9642857313156128)
[2024-11-29 03:37:28,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:28,216][root][INFO] - Training Epoch: 10/10, step 466/574 completed (loss: 0.5467627644538879, acc: 0.8433734774589539)
[2024-11-29 03:37:28,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:28,451][root][INFO] - Training Epoch: 10/10, step 467/574 completed (loss: 0.1209849938750267, acc: 0.9459459185600281)
[2024-11-29 03:37:28,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:28,691][root][INFO] - Training Epoch: 10/10, step 468/574 completed (loss: 0.5449410676956177, acc: 0.8737863898277283)
[2024-11-29 03:37:28,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:28,953][root][INFO] - Training Epoch: 10/10, step 469/574 completed (loss: 0.5693750977516174, acc: 0.8455284833908081)
[2024-11-29 03:37:29,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:29,199][root][INFO] - Training Epoch: 10/10, step 470/574 completed (loss: 0.14745081961154938, acc: 0.9583333134651184)
[2024-11-29 03:37:29,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:29,444][root][INFO] - Training Epoch: 10/10, step 471/574 completed (loss: 0.2751733362674713, acc: 0.9642857313156128)
[2024-11-29 03:37:29,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:29,773][root][INFO] - Training Epoch: 10/10, step 472/574 completed (loss: 0.3604222238063812, acc: 0.8529411554336548)
[2024-11-29 03:37:29,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:30,055][root][INFO] - Training Epoch: 10/10, step 473/574 completed (loss: 0.6043806672096252, acc: 0.7903929948806763)
[2024-11-29 03:37:30,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:30,324][root][INFO] - Training Epoch: 10/10, step 474/574 completed (loss: 0.15922245383262634, acc: 0.9583333134651184)
[2024-11-29 03:37:30,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:30,576][root][INFO] - Training Epoch: 10/10, step 475/574 completed (loss: 0.21101593971252441, acc: 0.9447852969169617)
[2024-11-29 03:37:30,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:30,818][root][INFO] - Training Epoch: 10/10, step 476/574 completed (loss: 0.2546553909778595, acc: 0.9136690497398376)
[2024-11-29 03:37:30,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:31,079][root][INFO] - Training Epoch: 10/10, step 477/574 completed (loss: 0.4922311007976532, acc: 0.8693467378616333)
[2024-11-29 03:37:31,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:31,312][root][INFO] - Training Epoch: 10/10, step 478/574 completed (loss: 0.14840148389339447, acc: 0.9722222089767456)
[2024-11-29 03:37:31,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:31,602][root][INFO] - Training Epoch: 10/10, step 479/574 completed (loss: 0.07130156457424164, acc: 0.9696969985961914)
[2024-11-29 03:37:31,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:31,836][root][INFO] - Training Epoch: 10/10, step 480/574 completed (loss: 0.12588320672512054, acc: 0.9629629850387573)
[2024-11-29 03:37:31,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:32,088][root][INFO] - Training Epoch: 10/10, step 481/574 completed (loss: 0.05776134878396988, acc: 1.0)
[2024-11-29 03:37:32,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:32,288][root][INFO] - Training Epoch: 10/10, step 482/574 completed (loss: 0.34457913041114807, acc: 0.949999988079071)
[2024-11-29 03:37:32,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:32,561][root][INFO] - Training Epoch: 10/10, step 483/574 completed (loss: 0.3809690773487091, acc: 0.8965517282485962)
[2024-11-29 03:37:32,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:32,782][root][INFO] - Training Epoch: 10/10, step 484/574 completed (loss: 0.05940501019358635, acc: 1.0)
[2024-11-29 03:37:32,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:33,014][root][INFO] - Training Epoch: 10/10, step 485/574 completed (loss: 0.013765309937298298, acc: 1.0)
[2024-11-29 03:37:33,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:33,257][root][INFO] - Training Epoch: 10/10, step 486/574 completed (loss: 0.10182999819517136, acc: 1.0)
[2024-11-29 03:37:33,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:33,477][root][INFO] - Training Epoch: 10/10, step 487/574 completed (loss: 0.07822681218385696, acc: 1.0)
[2024-11-29 03:37:33,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:33,729][root][INFO] - Training Epoch: 10/10, step 488/574 completed (loss: 0.05788225308060646, acc: 1.0)
[2024-11-29 03:37:33,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:33,985][root][INFO] - Training Epoch: 10/10, step 489/574 completed (loss: 0.24545413255691528, acc: 0.892307698726654)
[2024-11-29 03:37:34,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:34,186][root][INFO] - Training Epoch: 10/10, step 490/574 completed (loss: 0.022209446877241135, acc: 1.0)
[2024-11-29 03:37:34,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:34,393][root][INFO] - Training Epoch: 10/10, step 491/574 completed (loss: 0.10852836817502975, acc: 0.931034505367279)
[2024-11-29 03:37:34,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:34,624][root][INFO] - Training Epoch: 10/10, step 492/574 completed (loss: 0.035603150725364685, acc: 1.0)
[2024-11-29 03:37:34,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:34,853][root][INFO] - Training Epoch: 10/10, step 493/574 completed (loss: 0.024339202791452408, acc: 1.0)
[2024-11-29 03:37:34,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:35,067][root][INFO] - Training Epoch: 10/10, step 494/574 completed (loss: 0.03715259209275246, acc: 1.0)
[2024-11-29 03:37:35,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:35,295][root][INFO] - Training Epoch: 10/10, step 495/574 completed (loss: 0.01845001056790352, acc: 1.0)
[2024-11-29 03:37:35,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:35,547][root][INFO] - Training Epoch: 10/10, step 496/574 completed (loss: 0.4860118329524994, acc: 0.8571428656578064)
[2024-11-29 03:37:35,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:35,820][root][INFO] - Training Epoch: 10/10, step 497/574 completed (loss: 0.278856098651886, acc: 0.9438202381134033)
[2024-11-29 03:37:35,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:36,098][root][INFO] - Training Epoch: 10/10, step 498/574 completed (loss: 0.3797752857208252, acc: 0.898876428604126)
[2024-11-29 03:37:36,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:36,341][root][INFO] - Training Epoch: 10/10, step 499/574 completed (loss: 0.9044753909111023, acc: 0.7446808218955994)
[2024-11-29 03:37:36,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:36,578][root][INFO] - Training Epoch: 10/10, step 500/574 completed (loss: 0.2924349308013916, acc: 0.9130434989929199)
[2024-11-29 03:37:36,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:36,789][root][INFO] - Training Epoch: 10/10, step 501/574 completed (loss: 0.00513926986604929, acc: 1.0)
[2024-11-29 03:37:36,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:37,014][root][INFO] - Training Epoch: 10/10, step 502/574 completed (loss: 0.0021144929341971874, acc: 1.0)
[2024-11-29 03:37:37,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:37,250][root][INFO] - Training Epoch: 10/10, step 503/574 completed (loss: 0.056930337101221085, acc: 0.9629629850387573)
[2024-11-29 03:37:37,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:37,500][root][INFO] - Training Epoch: 10/10, step 504/574 completed (loss: 0.036767397075891495, acc: 0.9629629850387573)
[2024-11-29 03:37:37,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:37,770][root][INFO] - Training Epoch: 10/10, step 505/574 completed (loss: 0.2903285622596741, acc: 0.8867924809455872)
[2024-11-29 03:37:37,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:38,040][root][INFO] - Training Epoch: 10/10, step 506/574 completed (loss: 1.093551516532898, acc: 0.7931034564971924)
[2024-11-29 03:37:38,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:38,561][root][INFO] - Training Epoch: 10/10, step 507/574 completed (loss: 0.7942067980766296, acc: 0.8018018007278442)
[2024-11-29 03:37:38,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:38,903][root][INFO] - Training Epoch: 10/10, step 508/574 completed (loss: 0.4802735149860382, acc: 0.9014084339141846)
[2024-11-29 03:37:38,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:39,112][root][INFO] - Training Epoch: 10/10, step 509/574 completed (loss: 0.002244990086182952, acc: 1.0)
[2024-11-29 03:37:39,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:39,352][root][INFO] - Training Epoch: 10/10, step 510/574 completed (loss: 0.03397924080491066, acc: 1.0)
[2024-11-29 03:37:39,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:39,609][root][INFO] - Training Epoch: 10/10, step 511/574 completed (loss: 0.04898925870656967, acc: 1.0)
[2024-11-29 03:37:40,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:42,097][root][INFO] - Training Epoch: 10/10, step 512/574 completed (loss: 1.0632810592651367, acc: 0.7642857432365417)
[2024-11-29 03:37:42,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:42,756][root][INFO] - Training Epoch: 10/10, step 513/574 completed (loss: 0.20253734290599823, acc: 0.9444444179534912)
[2024-11-29 03:37:42,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:42,950][root][INFO] - Training Epoch: 10/10, step 514/574 completed (loss: 0.3819755017757416, acc: 0.8928571343421936)
[2024-11-29 03:37:43,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:43,175][root][INFO] - Training Epoch: 10/10, step 515/574 completed (loss: 0.049687910825014114, acc: 1.0)
[2024-11-29 03:37:43,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:43,772][root][INFO] - Training Epoch: 10/10, step 516/574 completed (loss: 0.18899603188037872, acc: 0.9722222089767456)
[2024-11-29 03:37:43,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:44,000][root][INFO] - Training Epoch: 10/10, step 517/574 completed (loss: 0.019533667713403702, acc: 1.0)
[2024-11-29 03:37:44,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:44,231][root][INFO] - Training Epoch: 10/10, step 518/574 completed (loss: 0.052787262946367264, acc: 1.0)
[2024-11-29 03:37:44,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:44,476][root][INFO] - Training Epoch: 10/10, step 519/574 completed (loss: 0.03278174623847008, acc: 1.0)
[2024-11-29 03:37:44,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:44,664][root][INFO] - Training Epoch: 10/10, step 520/574 completed (loss: 0.08757520467042923, acc: 1.0)
[2024-11-29 03:37:44,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:45,542][root][INFO] - Training Epoch: 10/10, step 521/574 completed (loss: 0.8110203742980957, acc: 0.7838982939720154)
[2024-11-29 03:37:45,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:45,787][root][INFO] - Training Epoch: 10/10, step 522/574 completed (loss: 0.3415740430355072, acc: 0.9104477763175964)
[2024-11-29 03:37:45,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:46,055][root][INFO] - Training Epoch: 10/10, step 523/574 completed (loss: 0.3285791575908661, acc: 0.9051094651222229)
[2024-11-29 03:37:46,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:46,526][root][INFO] - Training Epoch: 10/10, step 524/574 completed (loss: 0.5914105772972107, acc: 0.8550000190734863)
[2024-11-29 03:37:46,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:46,767][root][INFO] - Training Epoch: 10/10, step 525/574 completed (loss: 0.0238786768168211, acc: 1.0)
[2024-11-29 03:37:46,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:47,030][root][INFO] - Training Epoch: 10/10, step 526/574 completed (loss: 0.03479048237204552, acc: 1.0)
[2024-11-29 03:37:47,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:47,282][root][INFO] - Training Epoch: 10/10, step 527/574 completed (loss: 0.08044518530368805, acc: 0.9523809552192688)
[2024-11-29 03:37:47,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:47,492][root][INFO] - Training Epoch: 10/10, step 528/574 completed (loss: 0.6477991938591003, acc: 0.868852436542511)
[2024-11-29 03:37:47,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:47,728][root][INFO] - Training Epoch: 10/10, step 529/574 completed (loss: 0.10852348804473877, acc: 0.9661017060279846)
[2024-11-29 03:37:47,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:47,941][root][INFO] - Training Epoch: 10/10, step 530/574 completed (loss: 0.9978851675987244, acc: 0.7906976938247681)
[2024-11-29 03:37:48,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:48,210][root][INFO] - Training Epoch: 10/10, step 531/574 completed (loss: 0.20876817405223846, acc: 0.9545454382896423)
[2024-11-29 03:37:48,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:48,459][root][INFO] - Training Epoch: 10/10, step 532/574 completed (loss: 0.5146274566650391, acc: 0.8867924809455872)
[2024-11-29 03:37:48,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:48,695][root][INFO] - Training Epoch: 10/10, step 533/574 completed (loss: 0.30111414194107056, acc: 0.9318181872367859)
[2024-11-29 03:37:48,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:48,930][root][INFO] - Training Epoch: 10/10, step 534/574 completed (loss: 0.3191935420036316, acc: 0.9599999785423279)
[2024-11-29 03:37:49,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:49,155][root][INFO] - Training Epoch: 10/10, step 535/574 completed (loss: 0.028291020542383194, acc: 1.0)
[2024-11-29 03:37:49,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:49,402][root][INFO] - Training Epoch: 10/10, step 536/574 completed (loss: 0.03520529717206955, acc: 1.0)
[2024-11-29 03:37:49,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:49,702][root][INFO] - Training Epoch: 10/10, step 537/574 completed (loss: 0.14678612351417542, acc: 0.9692307710647583)
[2024-11-29 03:37:49,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:49,932][root][INFO] - Training Epoch: 10/10, step 538/574 completed (loss: 0.2939961850643158, acc: 0.90625)
[2024-11-29 03:37:50,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:50,220][root][INFO] - Training Epoch: 10/10, step 539/574 completed (loss: 0.1414009928703308, acc: 0.96875)
[2024-11-29 03:37:50,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:50,414][root][INFO] - Training Epoch: 10/10, step 540/574 completed (loss: 0.8708446621894836, acc: 0.8181818127632141)
[2024-11-29 03:37:50,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:50,662][root][INFO] - Training Epoch: 10/10, step 541/574 completed (loss: 0.004581846762448549, acc: 1.0)
[2024-11-29 03:37:50,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:50,930][root][INFO] - Training Epoch: 10/10, step 542/574 completed (loss: 0.07106861472129822, acc: 0.9677419066429138)
[2024-11-29 03:37:51,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:51,146][root][INFO] - Training Epoch: 10/10, step 543/574 completed (loss: 0.011903314851224422, acc: 1.0)
[2024-11-29 03:37:51,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:51,401][root][INFO] - Training Epoch: 10/10, step 544/574 completed (loss: 0.024687962606549263, acc: 1.0)
[2024-11-29 03:37:51,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:51,705][root][INFO] - Training Epoch: 10/10, step 545/574 completed (loss: 0.012427817098796368, acc: 1.0)
[2024-11-29 03:37:51,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:51,948][root][INFO] - Training Epoch: 10/10, step 546/574 completed (loss: 0.015955647453665733, acc: 1.0)
[2024-11-29 03:37:52,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:52,178][root][INFO] - Training Epoch: 10/10, step 547/574 completed (loss: 0.01402799692004919, acc: 1.0)
[2024-11-29 03:37:52,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:52,419][root][INFO] - Training Epoch: 10/10, step 548/574 completed (loss: 0.054633039981126785, acc: 0.9677419066429138)
[2024-11-29 03:37:52,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:52,657][root][INFO] - Training Epoch: 10/10, step 549/574 completed (loss: 0.009217899292707443, acc: 1.0)
[2024-11-29 03:37:52,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:52,906][root][INFO] - Training Epoch: 10/10, step 550/574 completed (loss: 0.03231825679540634, acc: 1.0)
[2024-11-29 03:37:53,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:53,123][root][INFO] - Training Epoch: 10/10, step 551/574 completed (loss: 0.10631849616765976, acc: 0.9750000238418579)
[2024-11-29 03:37:53,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:53,326][root][INFO] - Training Epoch: 10/10, step 552/574 completed (loss: 0.06512485444545746, acc: 0.9857142567634583)
[2024-11-29 03:37:53,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:53,563][root][INFO] - Training Epoch: 10/10, step 553/574 completed (loss: 0.2865535020828247, acc: 0.9343065619468689)
[2024-11-29 03:37:54,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:54,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:54,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:55,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:55,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:55,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:56,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:56,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:56,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:57,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:57,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:57,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:58,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:58,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:58,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:59,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:59,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:59,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:59,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:59,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:00,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:00,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:00,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:00,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:01,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:01,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:01,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:01,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:02,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:02,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:02,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:02,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:03,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:03,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:03,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:04,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:04,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:04,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:04,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:05,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:05,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:05,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:05,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:06,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:06,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:06,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:07,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:07,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:07,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:07,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:08,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:08,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:08,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:09,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:09,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:09,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:09,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:10,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:10,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:10,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:11,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:11,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:11,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:12,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:12,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:12,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:12,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:13,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:13,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:14,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:14,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:14,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:14,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:15,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:15,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:15,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:15,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:15,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:16,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:16,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:16,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:16,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:17,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:17,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:17,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:18,232][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.3566, device='cuda:0') eval_epoch_loss=tensor(1.2109, device='cuda:0') eval_epoch_acc=tensor(0.7576, device='cuda:0')
[2024-11-29 03:38:18,233][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:38:18,233][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:38:18,512][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_10_step_554_loss_1.2109386920928955/model.pt
[2024-11-29 03:38:18,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:18,822][root][INFO] - Training Epoch: 10/10, step 554/574 completed (loss: 0.16732336580753326, acc: 0.951724112033844)
[2024-11-29 03:38:18,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:19,049][root][INFO] - Training Epoch: 10/10, step 555/574 completed (loss: 0.2629644572734833, acc: 0.9285714030265808)
[2024-11-29 03:38:19,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:19,250][root][INFO] - Training Epoch: 10/10, step 556/574 completed (loss: 0.22573493421077728, acc: 0.9470198750495911)
[2024-11-29 03:38:19,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:19,465][root][INFO] - Training Epoch: 10/10, step 557/574 completed (loss: 0.08320421725511551, acc: 0.9658119678497314)
[2024-11-29 03:38:19,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:19,678][root][INFO] - Training Epoch: 10/10, step 558/574 completed (loss: 0.07504501193761826, acc: 0.9599999785423279)
[2024-11-29 03:38:19,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:19,928][root][INFO] - Training Epoch: 10/10, step 559/574 completed (loss: 0.1024819165468216, acc: 0.9615384340286255)
[2024-11-29 03:38:20,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:20,202][root][INFO] - Training Epoch: 10/10, step 560/574 completed (loss: 0.0614447146654129, acc: 0.9615384340286255)
[2024-11-29 03:38:20,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:20,447][root][INFO] - Training Epoch: 10/10, step 561/574 completed (loss: 0.13575401902198792, acc: 0.9743589758872986)
[2024-11-29 03:38:20,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:20,728][root][INFO] - Training Epoch: 10/10, step 562/574 completed (loss: 0.2586895525455475, acc: 0.9333333373069763)
[2024-11-29 03:38:20,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:21,018][root][INFO] - Training Epoch: 10/10, step 563/574 completed (loss: 0.2271653413772583, acc: 0.948051929473877)
[2024-11-29 03:38:21,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:21,247][root][INFO] - Training Epoch: 10/10, step 564/574 completed (loss: 0.060340385884046555, acc: 0.9791666865348816)
[2024-11-29 03:38:21,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:21,490][root][INFO] - Training Epoch: 10/10, step 565/574 completed (loss: 0.20978596806526184, acc: 0.9482758641242981)
[2024-11-29 03:38:21,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:21,739][root][INFO] - Training Epoch: 10/10, step 566/574 completed (loss: 0.10669974237680435, acc: 0.9642857313156128)
[2024-11-29 03:38:21,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:21,989][root][INFO] - Training Epoch: 10/10, step 567/574 completed (loss: 0.039949193596839905, acc: 1.0)
[2024-11-29 03:38:22,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:22,240][root][INFO] - Training Epoch: 10/10, step 568/574 completed (loss: 0.047761719673871994, acc: 0.9629629850387573)
[2024-11-29 03:38:22,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:22,541][root][INFO] - Training Epoch: 10/10, step 569/574 completed (loss: 0.26573851704597473, acc: 0.9197860956192017)
[2024-11-29 03:38:22,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:22,763][root][INFO] - Training Epoch: 10/10, step 570/574 completed (loss: 0.021778801456093788, acc: 1.0)
[2024-11-29 03:38:22,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:22,997][root][INFO] - Training Epoch: 10/10, step 571/574 completed (loss: 0.1814262866973877, acc: 0.9743589758872986)
[2024-11-29 03:38:23,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:23,240][root][INFO] - Training Epoch: 10/10, step 572/574 completed (loss: 0.4298315644264221, acc: 0.8928571343421936)
[2024-11-29 03:38:23,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:23,495][root][INFO] - Training Epoch: 10/10, step 573/574 completed (loss: 0.34552255272865295, acc: 0.8993710875511169)
[2024-11-29 03:38:24,020][slam_llm.utils.train_utils][INFO] - Epoch 10: train_perplexity=1.2918, train_epoch_loss=0.2560, epoch time 265.66021061874926s
[2024-11-29 03:38:24,021][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 11 GB
[2024-11-29 03:38:24,021][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 16 GB
[2024-11-29 03:38:24,021][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 11 GB
[2024-11-29 03:38:24,021][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 15
[2024-11-29 03:38:24,021][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:38:24,024][root][INFO] - Key: avg_train_prep, Value: 6.5121588706970215
[2024-11-29 03:38:24,025][root][INFO] - Key: avg_train_loss, Value: 0.9398736357688904
[2024-11-29 03:38:24,026][root][INFO] - Key: avg_train_acc, Value: 0.7818143963813782
[2024-11-29 03:38:24,026][root][INFO] - Key: avg_eval_prep, Value: 7.075782775878906
[2024-11-29 03:38:24,026][root][INFO] - Key: avg_eval_loss, Value: 1.3952029943466187
[2024-11-29 03:38:24,026][root][INFO] - Key: avg_eval_acc, Value: 0.6859957575798035
[2024-11-29 03:38:24,026][root][INFO] - Key: avg_epoch_time, Value: 267.9602148190141
[2024-11-29 03:38:24,026][root][INFO] - Key: avg_checkpoint_time, Value: 0.21820945609360934
