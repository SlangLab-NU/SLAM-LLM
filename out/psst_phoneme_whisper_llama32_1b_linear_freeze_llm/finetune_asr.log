[2024-11-29 02:53:02,954][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 10, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': False, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': True}
[2024-11-29 02:53:02,954][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-11-29 02:53:02,954][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'encoder_name': 'whisper', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt', 'encoder_dim': 1280, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-11-29 02:53:02,954][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'psst_phoneme_whisper_llama32_1b_linear_freeze_llm', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-11-29_02-53-02.txt', 'log_interval': 5}
[2024-11-29 02:53:44,491][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2024-11-29 02:53:44,493][slam_llm.utils.train_utils][INFO] - --> whisper has 635.04896 Million params

[2024-11-29 02:53:44,496][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2024-11-29 02:53:44,497][slam_llm.utils.train_utils][INFO] - --> whisper has 0.0 Million params

[2024-11-29 02:53:51,865][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-29 02:53:51,866][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-11-29 02:53:51,868][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-29 02:53:51,868][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 0.0 Million params

[2024-11-29 02:53:52,007][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-11-29 02:53:52,008][slam_llm.utils.train_utils][INFO] - --> linear has 17.3056 Million params

[2024-11-29 02:53:52,008][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-11-29 02:53:52,010][slam_llm.utils.train_utils][INFO] - --> asr has 17.3056 Million params

[2024-11-29 02:53:54,332][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'mel', 'mel_size': 128, 'normalize': True}
[2024-11-29 02:53:55,011][root][INFO] - --> Training Set Length = 2298
[2024-11-29 02:53:55,017][root][INFO] - --> Validation Set Length = 341
[2024-11-29 02:53:55,018][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-29 02:53:55,018][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-29 02:53:57,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:59,307][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-11-29 02:54:00,313][root][INFO] - Training Epoch: 1/10, step 0/574 completed (loss: 9.609065055847168, acc: 0.0)
[2024-11-29 02:54:00,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:00,899][root][INFO] - Training Epoch: 1/10, step 1/574 completed (loss: 9.858453750610352, acc: 0.0)
[2024-11-29 02:54:00,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:01,658][root][INFO] - Training Epoch: 1/10, step 2/574 completed (loss: 9.03811264038086, acc: 0.0)
[2024-11-29 02:54:01,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:02,245][root][INFO] - Training Epoch: 1/10, step 3/574 completed (loss: 9.344588279724121, acc: 0.0)
[2024-11-29 02:54:02,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:02,834][root][INFO] - Training Epoch: 1/10, step 4/574 completed (loss: 8.92759895324707, acc: 0.0)
[2024-11-29 02:54:02,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:03,423][root][INFO] - Training Epoch: 1/10, step 5/574 completed (loss: 9.757650375366211, acc: 0.0)
[2024-11-29 02:54:03,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:04,011][root][INFO] - Training Epoch: 1/10, step 6/574 completed (loss: 9.7418212890625, acc: 0.0)
[2024-11-29 02:54:04,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:04,597][root][INFO] - Training Epoch: 1/10, step 7/574 completed (loss: 9.920393943786621, acc: 0.0)
[2024-11-29 02:54:04,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:05,182][root][INFO] - Training Epoch: 1/10, step 8/574 completed (loss: 9.767998695373535, acc: 0.0)
[2024-11-29 02:54:05,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:05,768][root][INFO] - Training Epoch: 1/10, step 9/574 completed (loss: 8.863447189331055, acc: 0.0)
[2024-11-29 02:54:05,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:06,353][root][INFO] - Training Epoch: 1/10, step 10/574 completed (loss: 8.938356399536133, acc: 0.0)
[2024-11-29 02:54:06,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:06,941][root][INFO] - Training Epoch: 1/10, step 11/574 completed (loss: 8.922813415527344, acc: 0.0)
[2024-11-29 02:54:07,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:07,530][root][INFO] - Training Epoch: 1/10, step 12/574 completed (loss: 9.078353881835938, acc: 0.0)
[2024-11-29 02:54:07,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:08,126][root][INFO] - Training Epoch: 1/10, step 13/574 completed (loss: 8.554999351501465, acc: 0.0)
[2024-11-29 02:54:08,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:08,716][root][INFO] - Training Epoch: 1/10, step 14/574 completed (loss: 8.565118789672852, acc: 0.0)
[2024-11-29 02:54:08,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:09,306][root][INFO] - Training Epoch: 1/10, step 15/574 completed (loss: 8.102946281433105, acc: 0.0)
[2024-11-29 02:54:09,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:09,892][root][INFO] - Training Epoch: 1/10, step 16/574 completed (loss: 8.929911613464355, acc: 0.0)
[2024-11-29 02:54:09,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:10,481][root][INFO] - Training Epoch: 1/10, step 17/574 completed (loss: 8.220463752746582, acc: 0.0)
[2024-11-29 02:54:10,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:11,071][root][INFO] - Training Epoch: 1/10, step 18/574 completed (loss: 7.620388507843018, acc: 0.0)
[2024-11-29 02:54:11,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:11,659][root][INFO] - Training Epoch: 1/10, step 19/574 completed (loss: 7.5490288734436035, acc: 0.0)
[2024-11-29 02:54:11,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:12,246][root][INFO] - Training Epoch: 1/10, step 20/574 completed (loss: 8.002402305603027, acc: 0.0)
[2024-11-29 02:54:12,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:12,831][root][INFO] - Training Epoch: 1/10, step 21/574 completed (loss: 6.992081642150879, acc: 0.0)
[2024-11-29 02:54:12,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:13,417][root][INFO] - Training Epoch: 1/10, step 22/574 completed (loss: 7.5953521728515625, acc: 0.0)
[2024-11-29 02:54:13,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:14,003][root][INFO] - Training Epoch: 1/10, step 23/574 completed (loss: 7.612051010131836, acc: 0.0)
[2024-11-29 02:54:14,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:14,591][root][INFO] - Training Epoch: 1/10, step 24/574 completed (loss: 7.116955757141113, acc: 0.0)
[2024-11-29 02:54:14,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:15,194][root][INFO] - Training Epoch: 1/10, step 25/574 completed (loss: 7.168700218200684, acc: 0.01886792480945587)
[2024-11-29 02:54:15,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:15,786][root][INFO] - Training Epoch: 1/10, step 26/574 completed (loss: 6.880774021148682, acc: 0.04109589010477066)
[2024-11-29 02:54:15,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:16,461][root][INFO] - Training Epoch: 1/10, step 27/574 completed (loss: 5.536619663238525, acc: 0.07905138283967972)
[2024-11-29 02:54:16,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:17,049][root][INFO] - Training Epoch: 1/10, step 28/574 completed (loss: 6.99449348449707, acc: 0.06976744532585144)
[2024-11-29 02:54:17,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:17,640][root][INFO] - Training Epoch: 1/10, step 29/574 completed (loss: 6.248076915740967, acc: 0.048192769289016724)
[2024-11-29 02:54:17,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:18,237][root][INFO] - Training Epoch: 1/10, step 30/574 completed (loss: 5.708493709564209, acc: 0.07407407462596893)
[2024-11-29 02:54:18,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:18,823][root][INFO] - Training Epoch: 1/10, step 31/574 completed (loss: 6.563452243804932, acc: 0.0)
[2024-11-29 02:54:18,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:19,408][root][INFO] - Training Epoch: 1/10, step 32/574 completed (loss: 6.227174758911133, acc: 0.03703703731298447)
[2024-11-29 02:54:19,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:19,995][root][INFO] - Training Epoch: 1/10, step 33/574 completed (loss: 6.731686115264893, acc: 0.043478261679410934)
[2024-11-29 02:54:20,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:20,593][root][INFO] - Training Epoch: 1/10, step 34/574 completed (loss: 5.701199054718018, acc: 0.06722689419984818)
[2024-11-29 02:54:20,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:21,183][root][INFO] - Training Epoch: 1/10, step 35/574 completed (loss: 6.11277437210083, acc: 0.06557376682758331)
[2024-11-29 02:54:21,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:21,787][root][INFO] - Training Epoch: 1/10, step 36/574 completed (loss: 5.287487030029297, acc: 0.1269841343164444)
[2024-11-29 02:54:21,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:22,375][root][INFO] - Training Epoch: 1/10, step 37/574 completed (loss: 6.112375259399414, acc: 0.06779661029577255)
[2024-11-29 02:54:22,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:22,969][root][INFO] - Training Epoch: 1/10, step 38/574 completed (loss: 5.556337356567383, acc: 0.08045977354049683)
[2024-11-29 02:54:23,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:23,555][root][INFO] - Training Epoch: 1/10, step 39/574 completed (loss: 5.774479389190674, acc: 0.0)
[2024-11-29 02:54:23,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:24,145][root][INFO] - Training Epoch: 1/10, step 40/574 completed (loss: 5.142392158508301, acc: 0.0)
[2024-11-29 02:54:24,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:24,741][root][INFO] - Training Epoch: 1/10, step 41/574 completed (loss: 5.2877092361450195, acc: 0.04054053872823715)
[2024-11-29 02:54:24,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:25,334][root][INFO] - Training Epoch: 1/10, step 42/574 completed (loss: 5.463919639587402, acc: 0.1538461595773697)
[2024-11-29 02:54:25,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:25,931][root][INFO] - Training Epoch: 1/10, step 43/574 completed (loss: 5.281566143035889, acc: 0.08080808073282242)
[2024-11-29 02:54:26,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:26,537][root][INFO] - Training Epoch: 1/10, step 44/574 completed (loss: 5.188177585601807, acc: 0.09278350323438644)
[2024-11-29 02:54:26,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:27,144][root][INFO] - Training Epoch: 1/10, step 45/574 completed (loss: 5.832699775695801, acc: 0.05882352963089943)
[2024-11-29 02:54:27,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:27,730][root][INFO] - Training Epoch: 1/10, step 46/574 completed (loss: 5.774014472961426, acc: 0.03846153989434242)
[2024-11-29 02:54:27,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:28,329][root][INFO] - Training Epoch: 1/10, step 47/574 completed (loss: 5.145162582397461, acc: 0.03703703731298447)
[2024-11-29 02:54:28,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:28,918][root][INFO] - Training Epoch: 1/10, step 48/574 completed (loss: 5.363145351409912, acc: 0.0357142873108387)
[2024-11-29 02:54:28,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:29,508][root][INFO] - Training Epoch: 1/10, step 49/574 completed (loss: 5.036065578460693, acc: 0.02777777798473835)
[2024-11-29 02:54:29,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:30,103][root][INFO] - Training Epoch: 1/10, step 50/574 completed (loss: 5.492857933044434, acc: 0.07017543911933899)
[2024-11-29 02:54:30,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:30,701][root][INFO] - Training Epoch: 1/10, step 51/574 completed (loss: 5.549317359924316, acc: 0.095238097012043)
[2024-11-29 02:54:30,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:31,296][root][INFO] - Training Epoch: 1/10, step 52/574 completed (loss: 6.31534481048584, acc: 0.028169013559818268)
[2024-11-29 02:54:31,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:31,909][root][INFO] - Training Epoch: 1/10, step 53/574 completed (loss: 5.391735553741455, acc: 0.06666667014360428)
[2024-11-29 02:54:31,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:32,496][root][INFO] - Training Epoch: 1/10, step 54/574 completed (loss: 6.0366716384887695, acc: 0.054054055362939835)
[2024-11-29 02:54:32,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:33,084][root][INFO] - Training Epoch: 1/10, step 55/574 completed (loss: 4.943188667297363, acc: 0.07692307978868484)
[2024-11-29 02:54:33,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:33,783][root][INFO] - Training Epoch: 1/10, step 56/574 completed (loss: 3.7727842330932617, acc: 0.27303755283355713)
[2024-11-29 02:54:33,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:34,433][root][INFO] - Training Epoch: 1/10, step 57/574 completed (loss: 4.212253570556641, acc: 0.23311546444892883)
[2024-11-29 02:54:34,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:35,045][root][INFO] - Training Epoch: 1/10, step 58/574 completed (loss: 4.840185165405273, acc: 0.1931818127632141)
[2024-11-29 02:54:35,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:35,643][root][INFO] - Training Epoch: 1/10, step 59/574 completed (loss: 4.499989986419678, acc: 0.1764705926179886)
[2024-11-29 02:54:35,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:36,256][root][INFO] - Training Epoch: 1/10, step 60/574 completed (loss: 4.63219690322876, acc: 0.14492753148078918)
[2024-11-29 02:54:36,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:36,865][root][INFO] - Training Epoch: 1/10, step 61/574 completed (loss: 4.746522426605225, acc: 0.16249999403953552)
[2024-11-29 02:54:36,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:37,456][root][INFO] - Training Epoch: 1/10, step 62/574 completed (loss: 4.795929908752441, acc: 0.11764705926179886)
[2024-11-29 02:54:37,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:38,045][root][INFO] - Training Epoch: 1/10, step 63/574 completed (loss: 5.694743633270264, acc: 0.0833333358168602)
[2024-11-29 02:54:38,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:38,640][root][INFO] - Training Epoch: 1/10, step 64/574 completed (loss: 4.159228801727295, acc: 0.28125)
[2024-11-29 02:54:38,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:39,228][root][INFO] - Training Epoch: 1/10, step 65/574 completed (loss: 4.412753105163574, acc: 0.17241379618644714)
[2024-11-29 02:54:39,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:39,818][root][INFO] - Training Epoch: 1/10, step 66/574 completed (loss: 5.56748628616333, acc: 0.0892857164144516)
[2024-11-29 02:54:39,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:40,409][root][INFO] - Training Epoch: 1/10, step 67/574 completed (loss: 5.184170722961426, acc: 0.06666667014360428)
[2024-11-29 02:54:40,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:40,998][root][INFO] - Training Epoch: 1/10, step 68/574 completed (loss: 5.284266948699951, acc: 0.0)
[2024-11-29 02:54:41,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:41,589][root][INFO] - Training Epoch: 1/10, step 69/574 completed (loss: 4.554793834686279, acc: 0.0833333358168602)
[2024-11-29 02:54:41,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:42,176][root][INFO] - Training Epoch: 1/10, step 70/574 completed (loss: 5.624938011169434, acc: 0.06060606241226196)
[2024-11-29 02:54:42,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:42,786][root][INFO] - Training Epoch: 1/10, step 71/574 completed (loss: 4.6184916496276855, acc: 0.11029411852359772)
[2024-11-29 02:54:42,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:43,380][root][INFO] - Training Epoch: 1/10, step 72/574 completed (loss: 4.328253269195557, acc: 0.0476190485060215)
[2024-11-29 02:54:43,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:43,994][root][INFO] - Training Epoch: 1/10, step 73/574 completed (loss: 4.649866104125977, acc: 0.11794871836900711)
[2024-11-29 02:54:44,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:44,585][root][INFO] - Training Epoch: 1/10, step 74/574 completed (loss: 5.540821075439453, acc: 0.030612245202064514)
[2024-11-29 02:54:44,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:45,181][root][INFO] - Training Epoch: 1/10, step 75/574 completed (loss: 4.440547943115234, acc: 0.06716418266296387)
[2024-11-29 02:54:45,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:45,806][root][INFO] - Training Epoch: 1/10, step 76/574 completed (loss: 4.4673848152160645, acc: 0.17883211374282837)
[2024-11-29 02:54:45,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:46,397][root][INFO] - Training Epoch: 1/10, step 77/574 completed (loss: 4.864522457122803, acc: 0.0476190485060215)
[2024-11-29 02:54:46,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:46,983][root][INFO] - Training Epoch: 1/10, step 78/574 completed (loss: 4.733339309692383, acc: 0.1666666716337204)
[2024-11-29 02:54:47,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:47,569][root][INFO] - Training Epoch: 1/10, step 79/574 completed (loss: 4.481380939483643, acc: 0.09090909361839294)
[2024-11-29 02:54:47,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:48,159][root][INFO] - Training Epoch: 1/10, step 80/574 completed (loss: 4.445476531982422, acc: 0.11538461595773697)
[2024-11-29 02:54:48,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:48,752][root][INFO] - Training Epoch: 1/10, step 81/574 completed (loss: 4.9379425048828125, acc: 0.07692307978868484)
[2024-11-29 02:54:48,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:49,345][root][INFO] - Training Epoch: 1/10, step 82/574 completed (loss: 5.306002616882324, acc: 0.09615384787321091)
[2024-11-29 02:54:49,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:49,933][root][INFO] - Training Epoch: 1/10, step 83/574 completed (loss: 4.088698387145996, acc: 0.25)
[2024-11-29 02:54:50,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:50,524][root][INFO] - Training Epoch: 1/10, step 84/574 completed (loss: 4.924600601196289, acc: 0.15942029654979706)
[2024-11-29 02:54:50,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:51,122][root][INFO] - Training Epoch: 1/10, step 85/574 completed (loss: 4.965771198272705, acc: 0.14000000059604645)
[2024-11-29 02:54:51,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:51,709][root][INFO] - Training Epoch: 1/10, step 86/574 completed (loss: 4.622603416442871, acc: 0.1304347813129425)
[2024-11-29 02:54:51,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:52,301][root][INFO] - Training Epoch: 1/10, step 87/574 completed (loss: 4.910095691680908, acc: 0.18000000715255737)
[2024-11-29 02:54:52,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:52,897][root][INFO] - Training Epoch: 1/10, step 88/574 completed (loss: 4.899569034576416, acc: 0.13592232763767242)
[2024-11-29 02:54:52,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:53,509][root][INFO] - Training Epoch: 1/10, step 89/574 completed (loss: 4.370847702026367, acc: 0.2330097109079361)
[2024-11-29 02:54:53,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:54,121][root][INFO] - Training Epoch: 1/10, step 90/574 completed (loss: 4.654368877410889, acc: 0.16129031777381897)
[2024-11-29 02:54:54,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:54,742][root][INFO] - Training Epoch: 1/10, step 91/574 completed (loss: 3.9386396408081055, acc: 0.2887931168079376)
[2024-11-29 02:54:54,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:55,338][root][INFO] - Training Epoch: 1/10, step 92/574 completed (loss: 4.333682537078857, acc: 0.2526315748691559)
[2024-11-29 02:54:55,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:55,952][root][INFO] - Training Epoch: 1/10, step 93/574 completed (loss: 4.581826210021973, acc: 0.14851485192775726)
[2024-11-29 02:54:56,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:56,544][root][INFO] - Training Epoch: 1/10, step 94/574 completed (loss: 4.227659702301025, acc: 0.11290322244167328)
[2024-11-29 02:54:56,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:57,136][root][INFO] - Training Epoch: 1/10, step 95/574 completed (loss: 4.259091377258301, acc: 0.18840579688549042)
[2024-11-29 02:54:57,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:57,732][root][INFO] - Training Epoch: 1/10, step 96/574 completed (loss: 4.881150722503662, acc: 0.10084033757448196)
[2024-11-29 02:54:57,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:58,332][root][INFO] - Training Epoch: 1/10, step 97/574 completed (loss: 4.294367790222168, acc: 0.16346153616905212)
[2024-11-29 02:54:58,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:58,932][root][INFO] - Training Epoch: 1/10, step 98/574 completed (loss: 4.464293956756592, acc: 0.15328466892242432)
[2024-11-29 02:54:59,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:59,524][root][INFO] - Training Epoch: 1/10, step 99/574 completed (loss: 4.969815731048584, acc: 0.16417910158634186)
[2024-11-29 02:54:59,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:00,112][root][INFO] - Training Epoch: 1/10, step 100/574 completed (loss: 4.666781425476074, acc: 0.15000000596046448)
[2024-11-29 02:55:00,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:00,699][root][INFO] - Training Epoch: 1/10, step 101/574 completed (loss: 4.380127429962158, acc: 0.13636364042758942)
[2024-11-29 02:55:00,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:01,287][root][INFO] - Training Epoch: 1/10, step 102/574 completed (loss: 4.18403959274292, acc: 0.17391304671764374)
[2024-11-29 02:55:01,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:01,878][root][INFO] - Training Epoch: 1/10, step 103/574 completed (loss: 4.095935344696045, acc: 0.13636364042758942)
[2024-11-29 02:55:01,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:02,471][root][INFO] - Training Epoch: 1/10, step 104/574 completed (loss: 4.170012474060059, acc: 0.13793103396892548)
[2024-11-29 02:55:02,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:03,065][root][INFO] - Training Epoch: 1/10, step 105/574 completed (loss: 4.065883159637451, acc: 0.1627907007932663)
[2024-11-29 02:55:03,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:03,653][root][INFO] - Training Epoch: 1/10, step 106/574 completed (loss: 3.8956334590911865, acc: 0.20000000298023224)
[2024-11-29 02:55:03,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:04,240][root][INFO] - Training Epoch: 1/10, step 107/574 completed (loss: 3.87274432182312, acc: 0.23529411852359772)
[2024-11-29 02:55:04,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:04,828][root][INFO] - Training Epoch: 1/10, step 108/574 completed (loss: 4.021926403045654, acc: 0.1538461595773697)
[2024-11-29 02:55:04,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:05,417][root][INFO] - Training Epoch: 1/10, step 109/574 completed (loss: 4.291258811950684, acc: 0.095238097012043)
[2024-11-29 02:55:05,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:06,014][root][INFO] - Training Epoch: 1/10, step 110/574 completed (loss: 4.8465800285339355, acc: 0.1230769231915474)
[2024-11-29 02:55:06,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:06,609][root][INFO] - Training Epoch: 1/10, step 111/574 completed (loss: 4.233147144317627, acc: 0.15789473056793213)
[2024-11-29 02:55:06,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:07,198][root][INFO] - Training Epoch: 1/10, step 112/574 completed (loss: 4.782454490661621, acc: 0.10526315867900848)
[2024-11-29 02:55:07,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:07,786][root][INFO] - Training Epoch: 1/10, step 113/574 completed (loss: 4.363617420196533, acc: 0.025641025975346565)
[2024-11-29 02:55:07,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:08,377][root][INFO] - Training Epoch: 1/10, step 114/574 completed (loss: 4.377119541168213, acc: 0.06122449040412903)
[2024-11-29 02:55:08,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:08,965][root][INFO] - Training Epoch: 1/10, step 115/574 completed (loss: 4.166449546813965, acc: 0.22727273404598236)
[2024-11-29 02:55:09,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:09,561][root][INFO] - Training Epoch: 1/10, step 116/574 completed (loss: 3.6892802715301514, acc: 0.1746031790971756)
[2024-11-29 02:55:09,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:10,159][root][INFO] - Training Epoch: 1/10, step 117/574 completed (loss: 3.884692668914795, acc: 0.23577235639095306)
[2024-11-29 02:55:10,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:10,753][root][INFO] - Training Epoch: 1/10, step 118/574 completed (loss: 4.343555450439453, acc: 0.14516128599643707)
[2024-11-29 02:55:10,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:11,394][root][INFO] - Training Epoch: 1/10, step 119/574 completed (loss: 3.909024715423584, acc: 0.26615968346595764)
[2024-11-29 02:55:11,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:11,991][root][INFO] - Training Epoch: 1/10, step 120/574 completed (loss: 4.230036735534668, acc: 0.20000000298023224)
[2024-11-29 02:55:12,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:12,585][root][INFO] - Training Epoch: 1/10, step 121/574 completed (loss: 4.980773448944092, acc: 0.1538461595773697)
[2024-11-29 02:55:12,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:13,172][root][INFO] - Training Epoch: 1/10, step 122/574 completed (loss: 4.526327610015869, acc: 0.0416666679084301)
[2024-11-29 02:55:13,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:13,758][root][INFO] - Training Epoch: 1/10, step 123/574 completed (loss: 3.46457839012146, acc: 0.2631579041481018)
[2024-11-29 02:55:13,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:14,357][root][INFO] - Training Epoch: 1/10, step 124/574 completed (loss: 3.9114933013916016, acc: 0.20858895778656006)
[2024-11-29 02:55:14,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:14,967][root][INFO] - Training Epoch: 1/10, step 125/574 completed (loss: 3.2645578384399414, acc: 0.2569444477558136)
[2024-11-29 02:55:15,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:15,561][root][INFO] - Training Epoch: 1/10, step 126/574 completed (loss: 3.7797701358795166, acc: 0.19166666269302368)
[2024-11-29 02:55:15,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:16,185][root][INFO] - Training Epoch: 1/10, step 127/574 completed (loss: 3.4180080890655518, acc: 0.2023809552192688)
[2024-11-29 02:55:16,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:16,796][root][INFO] - Training Epoch: 1/10, step 128/574 completed (loss: 3.727313756942749, acc: 0.22564102709293365)
[2024-11-29 02:55:16,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:17,418][root][INFO] - Training Epoch: 1/10, step 129/574 completed (loss: 3.2672133445739746, acc: 0.33088234066963196)
[2024-11-29 02:55:17,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:18,006][root][INFO] - Training Epoch: 1/10, step 130/574 completed (loss: 3.93729305267334, acc: 0.1538461595773697)
[2024-11-29 02:55:18,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:18,593][root][INFO] - Training Epoch: 1/10, step 131/574 completed (loss: 3.3018245697021484, acc: 0.260869562625885)
[2024-11-29 02:55:18,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:19,181][root][INFO] - Training Epoch: 1/10, step 132/574 completed (loss: 3.9347147941589355, acc: 0.1875)
[2024-11-29 02:55:19,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:19,768][root][INFO] - Training Epoch: 1/10, step 133/574 completed (loss: 3.3937735557556152, acc: 0.260869562625885)
[2024-11-29 02:55:19,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:20,357][root][INFO] - Training Epoch: 1/10, step 134/574 completed (loss: 3.7681164741516113, acc: 0.08571428805589676)
[2024-11-29 02:55:20,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:20,945][root][INFO] - Training Epoch: 1/10, step 135/574 completed (loss: 3.6926825046539307, acc: 0.1538461595773697)
[2024-11-29 02:55:21,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:21,533][root][INFO] - Training Epoch: 1/10, step 136/574 completed (loss: 3.815173864364624, acc: 0.1666666716337204)
[2024-11-29 02:55:21,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:22,121][root][INFO] - Training Epoch: 1/10, step 137/574 completed (loss: 3.079157829284668, acc: 0.36666667461395264)
[2024-11-29 02:55:22,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:22,706][root][INFO] - Training Epoch: 1/10, step 138/574 completed (loss: 2.9974722862243652, acc: 0.17391304671764374)
[2024-11-29 02:55:22,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:23,293][root][INFO] - Training Epoch: 1/10, step 139/574 completed (loss: 4.0762505531311035, acc: 0.2380952388048172)
[2024-11-29 02:55:23,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:23,878][root][INFO] - Training Epoch: 1/10, step 140/574 completed (loss: 3.3932948112487793, acc: 0.26923078298568726)
[2024-11-29 02:55:23,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:24,466][root][INFO] - Training Epoch: 1/10, step 141/574 completed (loss: 3.638157367706299, acc: 0.19354838132858276)
[2024-11-29 02:55:24,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:25,054][root][INFO] - Training Epoch: 1/10, step 142/574 completed (loss: 3.973642349243164, acc: 0.10810811072587967)
[2024-11-29 02:55:25,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:26,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:26,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:27,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:27,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:28,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:28,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:29,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:30,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:30,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:31,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:31,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:32,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:32,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:33,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:33,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:34,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:34,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:35,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:35,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:36,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:36,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:37,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:37,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:38,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:38,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:39,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:39,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:40,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:40,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:41,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:42,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:42,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:43,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:43,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:44,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:44,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:45,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:45,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:46,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:46,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:47,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:47,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:48,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:48,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:49,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:49,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:50,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:51,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:51,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:52,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:52,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:53,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:53,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:54,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:54,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:55,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:55,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:56,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:56,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:57,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:57,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:58,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:58,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:59,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:59,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:00,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:01,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:01,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:02,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:02,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:03,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:03,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:04,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:04,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:05,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:05,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:06,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:06,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:07,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:07,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:08,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:09,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:09,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:10,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:11,012][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(41.6097, device='cuda:0') eval_epoch_loss=tensor(3.7283, device='cuda:0') eval_epoch_acc=tensor(0.2393, device='cuda:0')
[2024-11-29 02:56:11,014][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 02:56:11,014][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 02:56:11,297][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_1_step_143_loss_3.7283337116241455/model.pt
[2024-11-29 02:56:11,301][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 3.7283337116241455
[2024-11-29 02:56:11,302][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.2393042892217636
[2024-11-29 02:56:11,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:11,929][root][INFO] - Training Epoch: 1/10, step 143/574 completed (loss: 3.4911210536956787, acc: 0.3070175349712372)
[2024-11-29 02:56:12,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:12,526][root][INFO] - Training Epoch: 1/10, step 144/574 completed (loss: 3.4437291622161865, acc: 0.28358209133148193)
[2024-11-29 02:56:12,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:13,127][root][INFO] - Training Epoch: 1/10, step 145/574 completed (loss: 3.8216586112976074, acc: 0.22448979318141937)
[2024-11-29 02:56:13,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:13,734][root][INFO] - Training Epoch: 1/10, step 146/574 completed (loss: 3.7180111408233643, acc: 0.27659574151039124)
[2024-11-29 02:56:13,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:14,329][root][INFO] - Training Epoch: 1/10, step 147/574 completed (loss: 4.126131534576416, acc: 0.27142858505249023)
[2024-11-29 02:56:14,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:14,915][root][INFO] - Training Epoch: 1/10, step 148/574 completed (loss: 4.224824905395508, acc: 0.1071428582072258)
[2024-11-29 02:56:14,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:15,502][root][INFO] - Training Epoch: 1/10, step 149/574 completed (loss: 3.47049880027771, acc: 0.17391304671764374)
[2024-11-29 02:56:15,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:16,092][root][INFO] - Training Epoch: 1/10, step 150/574 completed (loss: 3.5838828086853027, acc: 0.24137930572032928)
[2024-11-29 02:56:16,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:16,681][root][INFO] - Training Epoch: 1/10, step 151/574 completed (loss: 3.852083206176758, acc: 0.21739129722118378)
[2024-11-29 02:56:16,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:17,276][root][INFO] - Training Epoch: 1/10, step 152/574 completed (loss: 3.1199188232421875, acc: 0.2711864411830902)
[2024-11-29 02:56:17,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:17,867][root][INFO] - Training Epoch: 1/10, step 153/574 completed (loss: 4.009777545928955, acc: 0.17543859779834747)
[2024-11-29 02:56:17,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:18,460][root][INFO] - Training Epoch: 1/10, step 154/574 completed (loss: 3.866745710372925, acc: 0.2432432472705841)
[2024-11-29 02:56:18,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:19,047][root][INFO] - Training Epoch: 1/10, step 155/574 completed (loss: 4.201079368591309, acc: 0.1785714328289032)
[2024-11-29 02:56:19,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:19,633][root][INFO] - Training Epoch: 1/10, step 156/574 completed (loss: 2.8312904834747314, acc: 0.3913043439388275)
[2024-11-29 02:56:19,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:20,222][root][INFO] - Training Epoch: 1/10, step 157/574 completed (loss: 3.858535051345825, acc: 0.21052631735801697)
[2024-11-29 02:56:20,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:20,815][root][INFO] - Training Epoch: 1/10, step 158/574 completed (loss: 4.706342697143555, acc: 0.21621622145175934)
[2024-11-29 02:56:20,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:21,406][root][INFO] - Training Epoch: 1/10, step 159/574 completed (loss: 4.016364574432373, acc: 0.18518517911434174)
[2024-11-29 02:56:21,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:22,001][root][INFO] - Training Epoch: 1/10, step 160/574 completed (loss: 4.530030727386475, acc: 0.151162788271904)
[2024-11-29 02:56:22,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:22,599][root][INFO] - Training Epoch: 1/10, step 161/574 completed (loss: 4.512425422668457, acc: 0.15294118225574493)
[2024-11-29 02:56:22,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:23,198][root][INFO] - Training Epoch: 1/10, step 162/574 completed (loss: 4.3036603927612305, acc: 0.17977528274059296)
[2024-11-29 02:56:23,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:23,791][root][INFO] - Training Epoch: 1/10, step 163/574 completed (loss: 4.429369926452637, acc: 0.15909090638160706)
[2024-11-29 02:56:23,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:24,377][root][INFO] - Training Epoch: 1/10, step 164/574 completed (loss: 3.8699398040771484, acc: 0.2380952388048172)
[2024-11-29 02:56:24,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:24,965][root][INFO] - Training Epoch: 1/10, step 165/574 completed (loss: 3.5635290145874023, acc: 0.17241379618644714)
[2024-11-29 02:56:25,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:25,560][root][INFO] - Training Epoch: 1/10, step 166/574 completed (loss: 2.7630860805511475, acc: 0.44897958636283875)
[2024-11-29 02:56:25,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:26,148][root][INFO] - Training Epoch: 1/10, step 167/574 completed (loss: 3.374450922012329, acc: 0.23999999463558197)
[2024-11-29 02:56:26,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:26,743][root][INFO] - Training Epoch: 1/10, step 168/574 completed (loss: 3.618778705596924, acc: 0.2638888955116272)
[2024-11-29 02:56:26,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:27,340][root][INFO] - Training Epoch: 1/10, step 169/574 completed (loss: 3.648770809173584, acc: 0.18627451360225677)
[2024-11-29 02:56:27,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:27,968][root][INFO] - Training Epoch: 1/10, step 170/574 completed (loss: 4.17551851272583, acc: 0.2945205569267273)
[2024-11-29 02:56:28,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:28,555][root][INFO] - Training Epoch: 1/10, step 171/574 completed (loss: 3.513652801513672, acc: 0.2083333283662796)
[2024-11-29 02:56:28,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:29,142][root][INFO] - Training Epoch: 1/10, step 172/574 completed (loss: 4.082452774047852, acc: 0.1111111119389534)
[2024-11-29 02:56:29,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:29,731][root][INFO] - Training Epoch: 1/10, step 173/574 completed (loss: 3.8878445625305176, acc: 0.25)
[2024-11-29 02:56:29,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:30,342][root][INFO] - Training Epoch: 1/10, step 174/574 completed (loss: 3.3020036220550537, acc: 0.3362831771373749)
[2024-11-29 02:56:30,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:30,936][root][INFO] - Training Epoch: 1/10, step 175/574 completed (loss: 4.215862274169922, acc: 0.14492753148078918)
[2024-11-29 02:56:31,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:31,531][root][INFO] - Training Epoch: 1/10, step 176/574 completed (loss: 3.753300428390503, acc: 0.22727273404598236)
[2024-11-29 02:56:31,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:32,145][root][INFO] - Training Epoch: 1/10, step 177/574 completed (loss: 3.769594192504883, acc: 0.25190839171409607)
[2024-11-29 02:56:32,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:32,756][root][INFO] - Training Epoch: 1/10, step 178/574 completed (loss: 4.09489107131958, acc: 0.15555556118488312)
[2024-11-29 02:56:32,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:33,349][root][INFO] - Training Epoch: 1/10, step 179/574 completed (loss: 4.072572231292725, acc: 0.2295081913471222)
[2024-11-29 02:56:33,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:33,936][root][INFO] - Training Epoch: 1/10, step 180/574 completed (loss: 3.795421838760376, acc: 0.0833333358168602)
[2024-11-29 02:56:34,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:34,524][root][INFO] - Training Epoch: 1/10, step 181/574 completed (loss: 3.353774309158325, acc: 0.20000000298023224)
[2024-11-29 02:56:34,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:35,111][root][INFO] - Training Epoch: 1/10, step 182/574 completed (loss: 4.140768051147461, acc: 0.1428571492433548)
[2024-11-29 02:56:35,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:35,705][root][INFO] - Training Epoch: 1/10, step 183/574 completed (loss: 3.7178544998168945, acc: 0.18292683362960815)
[2024-11-29 02:56:35,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:36,331][root][INFO] - Training Epoch: 1/10, step 184/574 completed (loss: 3.8196332454681396, acc: 0.18126888573169708)
[2024-11-29 02:56:36,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:36,955][root][INFO] - Training Epoch: 1/10, step 185/574 completed (loss: 3.5621261596679688, acc: 0.19884726405143738)
[2024-11-29 02:56:37,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:37,576][root][INFO] - Training Epoch: 1/10, step 186/574 completed (loss: 3.7644474506378174, acc: 0.20624999701976776)
[2024-11-29 02:56:37,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:38,230][root][INFO] - Training Epoch: 1/10, step 187/574 completed (loss: 3.672032356262207, acc: 0.20825515687465668)
[2024-11-29 02:56:38,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:38,864][root][INFO] - Training Epoch: 1/10, step 188/574 completed (loss: 3.62331485748291, acc: 0.22064056992530823)
[2024-11-29 02:56:38,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:39,450][root][INFO] - Training Epoch: 1/10, step 189/574 completed (loss: 4.5900654792785645, acc: 0.11999999731779099)
[2024-11-29 02:56:39,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:40,044][root][INFO] - Training Epoch: 1/10, step 190/574 completed (loss: 4.28087043762207, acc: 0.22093023359775543)
[2024-11-29 02:56:40,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:40,641][root][INFO] - Training Epoch: 1/10, step 191/574 completed (loss: 4.051935195922852, acc: 0.261904776096344)
[2024-11-29 02:56:40,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:41,240][root][INFO] - Training Epoch: 1/10, step 192/574 completed (loss: 3.845705270767212, acc: 0.2651515007019043)
[2024-11-29 02:56:41,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:41,835][root][INFO] - Training Epoch: 1/10, step 193/574 completed (loss: 3.6950526237487793, acc: 0.30588236451148987)
[2024-11-29 02:56:41,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:42,447][root][INFO] - Training Epoch: 1/10, step 194/574 completed (loss: 3.2683022022247314, acc: 0.35185185074806213)
[2024-11-29 02:56:42,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:43,045][root][INFO] - Training Epoch: 1/10, step 195/574 completed (loss: 3.661011219024658, acc: 0.25806450843811035)
[2024-11-29 02:56:43,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:43,633][root][INFO] - Training Epoch: 1/10, step 196/574 completed (loss: 3.737966299057007, acc: 0.1428571492433548)
[2024-11-29 02:56:43,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:44,220][root][INFO] - Training Epoch: 1/10, step 197/574 completed (loss: 4.30767822265625, acc: 0.125)
[2024-11-29 02:56:44,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:44,813][root][INFO] - Training Epoch: 1/10, step 198/574 completed (loss: 4.089885234832764, acc: 0.1764705926179886)
[2024-11-29 02:56:44,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:45,413][root][INFO] - Training Epoch: 1/10, step 199/574 completed (loss: 4.004106044769287, acc: 0.20588235557079315)
[2024-11-29 02:56:45,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:46,012][root][INFO] - Training Epoch: 1/10, step 200/574 completed (loss: 3.388779640197754, acc: 0.22033898532390594)
[2024-11-29 02:56:46,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:46,609][root][INFO] - Training Epoch: 1/10, step 201/574 completed (loss: 3.797168254852295, acc: 0.21641790866851807)
[2024-11-29 02:56:46,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:47,206][root][INFO] - Training Epoch: 1/10, step 202/574 completed (loss: 4.175626754760742, acc: 0.1553398072719574)
[2024-11-29 02:56:47,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:47,802][root][INFO] - Training Epoch: 1/10, step 203/574 completed (loss: 3.297239065170288, acc: 0.3174603283405304)
[2024-11-29 02:56:47,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:48,398][root][INFO] - Training Epoch: 1/10, step 204/574 completed (loss: 3.3924312591552734, acc: 0.24175824224948883)
[2024-11-29 02:56:48,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:49,024][root][INFO] - Training Epoch: 1/10, step 205/574 completed (loss: 3.4790775775909424, acc: 0.21524663269519806)
[2024-11-29 02:56:49,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:49,648][root][INFO] - Training Epoch: 1/10, step 206/574 completed (loss: 3.360851287841797, acc: 0.25590550899505615)
[2024-11-29 02:56:49,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:50,262][root][INFO] - Training Epoch: 1/10, step 207/574 completed (loss: 3.4062299728393555, acc: 0.25)
[2024-11-29 02:56:50,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:50,880][root][INFO] - Training Epoch: 1/10, step 208/574 completed (loss: 3.041952133178711, acc: 0.34057971835136414)
[2024-11-29 02:56:50,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:51,501][root][INFO] - Training Epoch: 1/10, step 209/574 completed (loss: 3.426705837249756, acc: 0.2373540848493576)
[2024-11-29 02:56:51,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:52,116][root][INFO] - Training Epoch: 1/10, step 210/574 completed (loss: 3.676457643508911, acc: 0.17391304671764374)
[2024-11-29 02:56:52,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:52,704][root][INFO] - Training Epoch: 1/10, step 211/574 completed (loss: 3.1006131172180176, acc: 0.30434781312942505)
[2024-11-29 02:56:52,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:53,292][root][INFO] - Training Epoch: 1/10, step 212/574 completed (loss: 3.3904643058776855, acc: 0.1785714328289032)
[2024-11-29 02:56:53,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:53,887][root][INFO] - Training Epoch: 1/10, step 213/574 completed (loss: 3.3480985164642334, acc: 0.25531914830207825)
[2024-11-29 02:56:53,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:54,495][root][INFO] - Training Epoch: 1/10, step 214/574 completed (loss: 3.662444829940796, acc: 0.20000000298023224)
[2024-11-29 02:56:54,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:55,088][root][INFO] - Training Epoch: 1/10, step 215/574 completed (loss: 3.54923939704895, acc: 0.20270270109176636)
[2024-11-29 02:56:55,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:55,680][root][INFO] - Training Epoch: 1/10, step 216/574 completed (loss: 3.371225357055664, acc: 0.25581395626068115)
[2024-11-29 02:56:55,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:56,277][root][INFO] - Training Epoch: 1/10, step 217/574 completed (loss: 3.677826404571533, acc: 0.2612612545490265)
[2024-11-29 02:56:56,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:56,873][root][INFO] - Training Epoch: 1/10, step 218/574 completed (loss: 3.185004949569702, acc: 0.31111112236976624)
[2024-11-29 02:56:56,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:57,461][root][INFO] - Training Epoch: 1/10, step 219/574 completed (loss: 3.2332987785339355, acc: 0.3636363744735718)
[2024-11-29 02:56:57,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:58,049][root][INFO] - Training Epoch: 1/10, step 220/574 completed (loss: 3.072488307952881, acc: 0.25925925374031067)
[2024-11-29 02:56:58,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:58,638][root][INFO] - Training Epoch: 1/10, step 221/574 completed (loss: 2.9985833168029785, acc: 0.3199999928474426)
[2024-11-29 02:56:58,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:59,232][root][INFO] - Training Epoch: 1/10, step 222/574 completed (loss: 3.3568904399871826, acc: 0.21153846383094788)
[2024-11-29 02:56:59,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:59,847][root][INFO] - Training Epoch: 1/10, step 223/574 completed (loss: 3.32210373878479, acc: 0.2663043439388275)
[2024-11-29 02:56:59,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:00,460][root][INFO] - Training Epoch: 1/10, step 224/574 completed (loss: 3.3797528743743896, acc: 0.2613636255264282)
[2024-11-29 02:57:00,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:01,073][root][INFO] - Training Epoch: 1/10, step 225/574 completed (loss: 3.3383750915527344, acc: 0.23404255509376526)
[2024-11-29 02:57:01,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:01,664][root][INFO] - Training Epoch: 1/10, step 226/574 completed (loss: 4.145567893981934, acc: 0.18867924809455872)
[2024-11-29 02:57:01,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:02,256][root][INFO] - Training Epoch: 1/10, step 227/574 completed (loss: 3.064103126525879, acc: 0.30000001192092896)
[2024-11-29 02:57:02,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:02,850][root][INFO] - Training Epoch: 1/10, step 228/574 completed (loss: 2.7887046337127686, acc: 0.5116279125213623)
[2024-11-29 02:57:02,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:03,440][root][INFO] - Training Epoch: 1/10, step 229/574 completed (loss: 3.1644370555877686, acc: 0.23333333432674408)
[2024-11-29 02:57:03,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:04,042][root][INFO] - Training Epoch: 1/10, step 230/574 completed (loss: 3.7956974506378174, acc: 0.15789473056793213)
[2024-11-29 02:57:04,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:04,638][root][INFO] - Training Epoch: 1/10, step 231/574 completed (loss: 3.359097957611084, acc: 0.2666666805744171)
[2024-11-29 02:57:04,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:05,250][root][INFO] - Training Epoch: 1/10, step 232/574 completed (loss: 2.935957908630371, acc: 0.39444443583488464)
[2024-11-29 02:57:05,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:05,865][root][INFO] - Training Epoch: 1/10, step 233/574 completed (loss: 3.152554512023926, acc: 0.3623853325843811)
[2024-11-29 02:57:05,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:06,478][root][INFO] - Training Epoch: 1/10, step 234/574 completed (loss: 3.32147479057312, acc: 0.32307693362236023)
[2024-11-29 02:57:06,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:07,065][root][INFO] - Training Epoch: 1/10, step 235/574 completed (loss: 3.012274980545044, acc: 0.15789473056793213)
[2024-11-29 02:57:07,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:07,651][root][INFO] - Training Epoch: 1/10, step 236/574 completed (loss: 2.9622411727905273, acc: 0.2083333283662796)
[2024-11-29 02:57:07,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:08,239][root][INFO] - Training Epoch: 1/10, step 237/574 completed (loss: 3.3225173950195312, acc: 0.22727273404598236)
[2024-11-29 02:57:08,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:08,827][root][INFO] - Training Epoch: 1/10, step 238/574 completed (loss: 3.08449125289917, acc: 0.37037035822868347)
[2024-11-29 02:57:08,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:09,415][root][INFO] - Training Epoch: 1/10, step 239/574 completed (loss: 2.892047882080078, acc: 0.34285715222358704)
[2024-11-29 02:57:09,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:10,005][root][INFO] - Training Epoch: 1/10, step 240/574 completed (loss: 3.180131673812866, acc: 0.3181818127632141)
[2024-11-29 02:57:10,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:10,594][root][INFO] - Training Epoch: 1/10, step 241/574 completed (loss: 3.068070888519287, acc: 0.2954545319080353)
[2024-11-29 02:57:10,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:11,188][root][INFO] - Training Epoch: 1/10, step 242/574 completed (loss: 4.143701553344727, acc: 0.17741934955120087)
[2024-11-29 02:57:11,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:11,779][root][INFO] - Training Epoch: 1/10, step 243/574 completed (loss: 3.28987717628479, acc: 0.3181818127632141)
[2024-11-29 02:57:11,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:12,377][root][INFO] - Training Epoch: 1/10, step 244/574 completed (loss: 3.7269105911254883, acc: 0.190476194024086)
[2024-11-29 02:57:12,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:12,964][root][INFO] - Training Epoch: 1/10, step 245/574 completed (loss: 3.6556613445281982, acc: 0.3461538553237915)
[2024-11-29 02:57:13,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:13,553][root][INFO] - Training Epoch: 1/10, step 246/574 completed (loss: 3.936776638031006, acc: 0.16129031777381897)
[2024-11-29 02:57:13,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:14,139][root][INFO] - Training Epoch: 1/10, step 247/574 completed (loss: 2.875924825668335, acc: 0.25)
[2024-11-29 02:57:14,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:14,733][root][INFO] - Training Epoch: 1/10, step 248/574 completed (loss: 4.351267337799072, acc: 0.1621621549129486)
[2024-11-29 02:57:14,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:15,321][root][INFO] - Training Epoch: 1/10, step 249/574 completed (loss: 3.6401772499084473, acc: 0.18918919563293457)
[2024-11-29 02:57:15,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:15,911][root][INFO] - Training Epoch: 1/10, step 250/574 completed (loss: 4.0261712074279785, acc: 0.2432432472705841)
[2024-11-29 02:57:15,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:16,507][root][INFO] - Training Epoch: 1/10, step 251/574 completed (loss: 4.004547119140625, acc: 0.1617647111415863)
[2024-11-29 02:57:16,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:17,096][root][INFO] - Training Epoch: 1/10, step 252/574 completed (loss: 3.0748655796051025, acc: 0.3414634168148041)
[2024-11-29 02:57:17,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:17,685][root][INFO] - Training Epoch: 1/10, step 253/574 completed (loss: 3.973369836807251, acc: 0.23999999463558197)
[2024-11-29 02:57:17,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:18,274][root][INFO] - Training Epoch: 1/10, step 254/574 completed (loss: 2.925358295440674, acc: 0.3199999928474426)
[2024-11-29 02:57:18,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:18,860][root][INFO] - Training Epoch: 1/10, step 255/574 completed (loss: 3.714456081390381, acc: 0.09677419066429138)
[2024-11-29 02:57:18,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:19,452][root][INFO] - Training Epoch: 1/10, step 256/574 completed (loss: 4.491074085235596, acc: 0.15789473056793213)
[2024-11-29 02:57:19,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:20,041][root][INFO] - Training Epoch: 1/10, step 257/574 completed (loss: 3.8026013374328613, acc: 0.20000000298023224)
[2024-11-29 02:57:20,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:20,634][root][INFO] - Training Epoch: 1/10, step 258/574 completed (loss: 3.9440934658050537, acc: 0.21052631735801697)
[2024-11-29 02:57:20,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:21,244][root][INFO] - Training Epoch: 1/10, step 259/574 completed (loss: 3.2123773097991943, acc: 0.25471699237823486)
[2024-11-29 02:57:21,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:21,860][root][INFO] - Training Epoch: 1/10, step 260/574 completed (loss: 3.5049920082092285, acc: 0.2666666805744171)
[2024-11-29 02:57:21,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:22,454][root][INFO] - Training Epoch: 1/10, step 261/574 completed (loss: 3.4383223056793213, acc: 0.1944444477558136)
[2024-11-29 02:57:22,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:23,042][root][INFO] - Training Epoch: 1/10, step 262/574 completed (loss: 3.632223606109619, acc: 0.19354838132858276)
[2024-11-29 02:57:23,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:23,640][root][INFO] - Training Epoch: 1/10, step 263/574 completed (loss: 3.4965174198150635, acc: 0.13333334028720856)
[2024-11-29 02:57:23,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:24,229][root][INFO] - Training Epoch: 1/10, step 264/574 completed (loss: 3.726844072341919, acc: 0.1666666716337204)
[2024-11-29 02:57:24,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:24,845][root][INFO] - Training Epoch: 1/10, step 265/574 completed (loss: 3.466362476348877, acc: 0.2800000011920929)
[2024-11-29 02:57:24,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:25,440][root][INFO] - Training Epoch: 1/10, step 266/574 completed (loss: 3.223938226699829, acc: 0.2247191071510315)
[2024-11-29 02:57:25,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:26,033][root][INFO] - Training Epoch: 1/10, step 267/574 completed (loss: 3.9912447929382324, acc: 0.22972972691059113)
[2024-11-29 02:57:26,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:26,629][root][INFO] - Training Epoch: 1/10, step 268/574 completed (loss: 3.4317519664764404, acc: 0.2931034564971924)
[2024-11-29 02:57:26,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:27,215][root][INFO] - Training Epoch: 1/10, step 269/574 completed (loss: 3.4964563846588135, acc: 0.09090909361839294)
[2024-11-29 02:57:27,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:27,801][root][INFO] - Training Epoch: 1/10, step 270/574 completed (loss: 2.614729881286621, acc: 0.3181818127632141)
[2024-11-29 02:57:27,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:28,391][root][INFO] - Training Epoch: 1/10, step 271/574 completed (loss: 2.8349409103393555, acc: 0.40625)
[2024-11-29 02:57:28,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:28,979][root][INFO] - Training Epoch: 1/10, step 272/574 completed (loss: 3.246809482574463, acc: 0.30000001192092896)
[2024-11-29 02:57:29,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:29,571][root][INFO] - Training Epoch: 1/10, step 273/574 completed (loss: 3.0593457221984863, acc: 0.3333333432674408)
[2024-11-29 02:57:29,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:30,158][root][INFO] - Training Epoch: 1/10, step 274/574 completed (loss: 2.814788341522217, acc: 0.375)
[2024-11-29 02:57:30,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:30,745][root][INFO] - Training Epoch: 1/10, step 275/574 completed (loss: 3.0665366649627686, acc: 0.36666667461395264)
[2024-11-29 02:57:30,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:31,333][root][INFO] - Training Epoch: 1/10, step 276/574 completed (loss: 3.47165584564209, acc: 0.2068965584039688)
[2024-11-29 02:57:31,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:31,921][root][INFO] - Training Epoch: 1/10, step 277/574 completed (loss: 2.940197706222534, acc: 0.20000000298023224)
[2024-11-29 02:57:32,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:32,513][root][INFO] - Training Epoch: 1/10, step 278/574 completed (loss: 3.633859395980835, acc: 0.21276596188545227)
[2024-11-29 02:57:32,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:33,104][root][INFO] - Training Epoch: 1/10, step 279/574 completed (loss: 3.2934730052948, acc: 0.2083333283662796)
[2024-11-29 02:57:33,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:33,695][root][INFO] - Training Epoch: 1/10, step 280/574 completed (loss: 2.8785059452056885, acc: 0.2954545319080353)
[2024-11-29 02:57:33,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:34,293][root][INFO] - Training Epoch: 1/10, step 281/574 completed (loss: 3.2849671840667725, acc: 0.2530120611190796)
[2024-11-29 02:57:34,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:34,888][root][INFO] - Training Epoch: 1/10, step 282/574 completed (loss: 3.4685773849487305, acc: 0.2222222238779068)
[2024-11-29 02:57:34,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:35,475][root][INFO] - Training Epoch: 1/10, step 283/574 completed (loss: 3.8658740520477295, acc: 0.15789473056793213)
[2024-11-29 02:57:35,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:36,063][root][INFO] - Training Epoch: 1/10, step 284/574 completed (loss: 3.1299023628234863, acc: 0.2647058963775635)
[2024-11-29 02:57:36,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:36,653][root][INFO] - Training Epoch: 1/10, step 285/574 completed (loss: 3.0107667446136475, acc: 0.20000000298023224)
[2024-11-29 02:57:37,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:37,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:38,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:39,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:39,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:40,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:40,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:41,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:41,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:42,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:42,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:43,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:43,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:44,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:44,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:45,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:45,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:46,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:46,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:47,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:47,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:48,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:49,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:49,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:50,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:50,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:51,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:51,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:52,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:52,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:53,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:53,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:54,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:54,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:55,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:55,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:56,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:56,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:57,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:58,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:58,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:59,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:59,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:00,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:00,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:01,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:01,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:02,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:02,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:03,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:03,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:04,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:04,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:05,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:06,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:06,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:07,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:07,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:08,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:08,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:09,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:09,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:10,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:10,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:11,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:11,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:12,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:12,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:13,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:13,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:14,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:15,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:15,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:16,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:16,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:17,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:17,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:18,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:18,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:19,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:19,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:20,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:21,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:21,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:22,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:22,914][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(31.8357, device='cuda:0') eval_epoch_loss=tensor(3.4606, device='cuda:0') eval_epoch_acc=tensor(0.2376, device='cuda:0')
[2024-11-29 02:58:22,915][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 02:58:22,915][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 02:58:23,238][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_1_step_286_loss_3.4605867862701416/model.pt
[2024-11-29 02:58:23,243][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 3.4605867862701416
[2024-11-29 02:58:23,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:23,859][root][INFO] - Training Epoch: 1/10, step 286/574 completed (loss: 3.2018234729766846, acc: 0.28125)
[2024-11-29 02:58:23,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:24,473][root][INFO] - Training Epoch: 1/10, step 287/574 completed (loss: 3.6739418506622314, acc: 0.1679999977350235)
[2024-11-29 02:58:24,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:25,070][root][INFO] - Training Epoch: 1/10, step 288/574 completed (loss: 3.2358243465423584, acc: 0.2967033088207245)
[2024-11-29 02:58:25,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:25,668][root][INFO] - Training Epoch: 1/10, step 289/574 completed (loss: 3.4779598712921143, acc: 0.21118012070655823)
[2024-11-29 02:58:25,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:26,284][root][INFO] - Training Epoch: 1/10, step 290/574 completed (loss: 3.3684868812561035, acc: 0.2525773048400879)
[2024-11-29 02:58:26,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:26,872][root][INFO] - Training Epoch: 1/10, step 291/574 completed (loss: 3.5712625980377197, acc: 0.13636364042758942)
[2024-11-29 02:58:26,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:27,464][root][INFO] - Training Epoch: 1/10, step 292/574 completed (loss: 2.83850359916687, acc: 0.190476194024086)
[2024-11-29 02:58:27,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:28,060][root][INFO] - Training Epoch: 1/10, step 293/574 completed (loss: 3.623814821243286, acc: 0.2931034564971924)
[2024-11-29 02:58:28,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:28,658][root][INFO] - Training Epoch: 1/10, step 294/574 completed (loss: 2.579413890838623, acc: 0.41818180680274963)
[2024-11-29 02:58:28,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:29,283][root][INFO] - Training Epoch: 1/10, step 295/574 completed (loss: 3.143667697906494, acc: 0.34020617604255676)
[2024-11-29 02:58:29,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:29,877][root][INFO] - Training Epoch: 1/10, step 296/574 completed (loss: 3.6034162044525146, acc: 0.13793103396892548)
[2024-11-29 02:58:29,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:30,468][root][INFO] - Training Epoch: 1/10, step 297/574 completed (loss: 3.1603403091430664, acc: 0.29629629850387573)
[2024-11-29 02:58:30,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:31,066][root][INFO] - Training Epoch: 1/10, step 298/574 completed (loss: 3.4402332305908203, acc: 0.21052631735801697)
[2024-11-29 02:58:31,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:31,662][root][INFO] - Training Epoch: 1/10, step 299/574 completed (loss: 3.2768967151641846, acc: 0.125)
[2024-11-29 02:58:31,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:32,256][root][INFO] - Training Epoch: 1/10, step 300/574 completed (loss: 3.1111152172088623, acc: 0.125)
[2024-11-29 02:58:32,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:32,850][root][INFO] - Training Epoch: 1/10, step 301/574 completed (loss: 3.46407413482666, acc: 0.22641509771347046)
[2024-11-29 02:58:32,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:33,443][root][INFO] - Training Epoch: 1/10, step 302/574 completed (loss: 3.149402618408203, acc: 0.3396226465702057)
[2024-11-29 02:58:33,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:34,033][root][INFO] - Training Epoch: 1/10, step 303/574 completed (loss: 2.959296703338623, acc: 0.29411765933036804)
[2024-11-29 02:58:34,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:34,623][root][INFO] - Training Epoch: 1/10, step 304/574 completed (loss: 3.1574013233184814, acc: 0.28125)
[2024-11-29 02:58:34,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:35,221][root][INFO] - Training Epoch: 1/10, step 305/574 completed (loss: 3.279979944229126, acc: 0.37704917788505554)
[2024-11-29 02:58:35,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:35,808][root][INFO] - Training Epoch: 1/10, step 306/574 completed (loss: 2.8025219440460205, acc: 0.46666666865348816)
[2024-11-29 02:58:35,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:36,397][root][INFO] - Training Epoch: 1/10, step 307/574 completed (loss: 3.4771318435668945, acc: 0.31578946113586426)
[2024-11-29 02:58:36,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:36,995][root][INFO] - Training Epoch: 1/10, step 308/574 completed (loss: 3.2217812538146973, acc: 0.18840579688549042)
[2024-11-29 02:58:37,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:37,599][root][INFO] - Training Epoch: 1/10, step 309/574 completed (loss: 2.9670755863189697, acc: 0.2777777910232544)
[2024-11-29 02:58:37,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:38,196][root][INFO] - Training Epoch: 1/10, step 310/574 completed (loss: 3.14245867729187, acc: 0.3132530152797699)
[2024-11-29 02:58:38,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:38,798][root][INFO] - Training Epoch: 1/10, step 311/574 completed (loss: 3.1635849475860596, acc: 0.28205129504203796)
[2024-11-29 02:58:38,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:39,410][root][INFO] - Training Epoch: 1/10, step 312/574 completed (loss: 3.2198517322540283, acc: 0.2551020383834839)
[2024-11-29 02:58:39,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:40,000][root][INFO] - Training Epoch: 1/10, step 313/574 completed (loss: 3.225410223007202, acc: 0.25)
[2024-11-29 02:58:40,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:40,586][root][INFO] - Training Epoch: 1/10, step 314/574 completed (loss: 2.839508295059204, acc: 0.25)
[2024-11-29 02:58:40,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:41,173][root][INFO] - Training Epoch: 1/10, step 315/574 completed (loss: 3.465623378753662, acc: 0.16129031777381897)
[2024-11-29 02:58:41,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:41,768][root][INFO] - Training Epoch: 1/10, step 316/574 completed (loss: 3.247286558151245, acc: 0.22580644488334656)
[2024-11-29 02:58:41,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:42,367][root][INFO] - Training Epoch: 1/10, step 317/574 completed (loss: 3.0106098651885986, acc: 0.3283582031726837)
[2024-11-29 02:58:42,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:42,969][root][INFO] - Training Epoch: 1/10, step 318/574 completed (loss: 2.6375985145568848, acc: 0.36538460850715637)
[2024-11-29 02:58:43,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:43,558][root][INFO] - Training Epoch: 1/10, step 319/574 completed (loss: 3.013733148574829, acc: 0.2666666805744171)
[2024-11-29 02:58:43,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:44,153][root][INFO] - Training Epoch: 1/10, step 320/574 completed (loss: 2.949455738067627, acc: 0.30645161867141724)
[2024-11-29 02:58:44,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:44,746][root][INFO] - Training Epoch: 1/10, step 321/574 completed (loss: 2.6177563667297363, acc: 0.47999998927116394)
[2024-11-29 02:58:44,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:45,338][root][INFO] - Training Epoch: 1/10, step 322/574 completed (loss: 3.2143521308898926, acc: 0.18518517911434174)
[2024-11-29 02:58:45,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:45,930][root][INFO] - Training Epoch: 1/10, step 323/574 completed (loss: 3.814995527267456, acc: 0.1428571492433548)
[2024-11-29 02:58:46,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:46,519][root][INFO] - Training Epoch: 1/10, step 324/574 completed (loss: 4.016383171081543, acc: 0.25641027092933655)
[2024-11-29 02:58:46,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:47,112][root][INFO] - Training Epoch: 1/10, step 325/574 completed (loss: 3.476844549179077, acc: 0.17073170840740204)
[2024-11-29 02:58:47,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:47,712][root][INFO] - Training Epoch: 1/10, step 326/574 completed (loss: 3.1209335327148438, acc: 0.2631579041481018)
[2024-11-29 02:58:47,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:48,299][root][INFO] - Training Epoch: 1/10, step 327/574 completed (loss: 3.6212544441223145, acc: 0.2631579041481018)
[2024-11-29 02:58:48,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:48,890][root][INFO] - Training Epoch: 1/10, step 328/574 completed (loss: 3.105052947998047, acc: 0.2142857164144516)
[2024-11-29 02:58:48,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:49,477][root][INFO] - Training Epoch: 1/10, step 329/574 completed (loss: 3.190044641494751, acc: 0.25925925374031067)
[2024-11-29 02:58:49,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:50,066][root][INFO] - Training Epoch: 1/10, step 330/574 completed (loss: 2.819152355194092, acc: 0.3125)
[2024-11-29 02:58:50,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:50,659][root][INFO] - Training Epoch: 1/10, step 331/574 completed (loss: 3.554992914199829, acc: 0.25806450843811035)
[2024-11-29 02:58:50,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:51,257][root][INFO] - Training Epoch: 1/10, step 332/574 completed (loss: 2.6974074840545654, acc: 0.35087719559669495)
[2024-11-29 02:58:51,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:51,844][root][INFO] - Training Epoch: 1/10, step 333/574 completed (loss: 2.984814405441284, acc: 0.25)
[2024-11-29 02:58:51,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:52,432][root][INFO] - Training Epoch: 1/10, step 334/574 completed (loss: 2.875932216644287, acc: 0.4000000059604645)
[2024-11-29 02:58:52,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:53,019][root][INFO] - Training Epoch: 1/10, step 335/574 completed (loss: 2.4104044437408447, acc: 0.3684210479259491)
[2024-11-29 02:58:53,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:53,611][root][INFO] - Training Epoch: 1/10, step 336/574 completed (loss: 2.8697752952575684, acc: 0.23999999463558197)
[2024-11-29 02:58:53,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:54,208][root][INFO] - Training Epoch: 1/10, step 337/574 completed (loss: 3.4402003288269043, acc: 0.24137930572032928)
[2024-11-29 02:58:54,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:54,803][root][INFO] - Training Epoch: 1/10, step 338/574 completed (loss: 3.754493474960327, acc: 0.21276596188545227)
[2024-11-29 02:58:54,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:55,405][root][INFO] - Training Epoch: 1/10, step 339/574 completed (loss: 3.0253894329071045, acc: 0.33734938502311707)
[2024-11-29 02:58:55,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:55,996][root][INFO] - Training Epoch: 1/10, step 340/574 completed (loss: 2.7766082286834717, acc: 0.260869562625885)
[2024-11-29 02:58:56,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:56,585][root][INFO] - Training Epoch: 1/10, step 341/574 completed (loss: 3.6332945823669434, acc: 0.1538461595773697)
[2024-11-29 02:58:56,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:57,177][root][INFO] - Training Epoch: 1/10, step 342/574 completed (loss: 3.6834254264831543, acc: 0.1807228922843933)
[2024-11-29 02:58:57,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:57,772][root][INFO] - Training Epoch: 1/10, step 343/574 completed (loss: 3.542841672897339, acc: 0.18867924809455872)
[2024-11-29 02:58:57,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:58,364][root][INFO] - Training Epoch: 1/10, step 344/574 completed (loss: 3.4200775623321533, acc: 0.2278480976819992)
[2024-11-29 02:58:58,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:58,956][root][INFO] - Training Epoch: 1/10, step 345/574 completed (loss: 3.004643201828003, acc: 0.29411765933036804)
[2024-11-29 02:58:59,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:59,550][root][INFO] - Training Epoch: 1/10, step 346/574 completed (loss: 3.189776659011841, acc: 0.2238806039094925)
[2024-11-29 02:58:59,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:00,139][root][INFO] - Training Epoch: 1/10, step 347/574 completed (loss: 2.7173562049865723, acc: 0.3499999940395355)
[2024-11-29 02:59:00,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:00,726][root][INFO] - Training Epoch: 1/10, step 348/574 completed (loss: 3.126201868057251, acc: 0.4000000059604645)
[2024-11-29 02:59:00,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:01,315][root][INFO] - Training Epoch: 1/10, step 349/574 completed (loss: 3.0944247245788574, acc: 0.3888888955116272)
[2024-11-29 02:59:01,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:01,907][root][INFO] - Training Epoch: 1/10, step 350/574 completed (loss: 3.381312847137451, acc: 0.25581395626068115)
[2024-11-29 02:59:01,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:02,504][root][INFO] - Training Epoch: 1/10, step 351/574 completed (loss: 3.120828151702881, acc: 0.38461539149284363)
[2024-11-29 02:59:02,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:03,098][root][INFO] - Training Epoch: 1/10, step 352/574 completed (loss: 3.6307132244110107, acc: 0.2222222238779068)
[2024-11-29 02:59:03,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:03,684][root][INFO] - Training Epoch: 1/10, step 353/574 completed (loss: 2.24934983253479, acc: 0.43478259444236755)
[2024-11-29 02:59:03,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:04,272][root][INFO] - Training Epoch: 1/10, step 354/574 completed (loss: 4.034697532653809, acc: 0.11538461595773697)
[2024-11-29 02:59:04,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:04,875][root][INFO] - Training Epoch: 1/10, step 355/574 completed (loss: 3.2908103466033936, acc: 0.18681319057941437)
[2024-11-29 02:59:04,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:05,491][root][INFO] - Training Epoch: 1/10, step 356/574 completed (loss: 2.8694095611572266, acc: 0.33043476939201355)
[2024-11-29 02:59:05,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:06,082][root][INFO] - Training Epoch: 1/10, step 357/574 completed (loss: 3.1362907886505127, acc: 0.18478260934352875)
[2024-11-29 02:59:06,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:06,676][root][INFO] - Training Epoch: 1/10, step 358/574 completed (loss: 3.048092842102051, acc: 0.30612245202064514)
[2024-11-29 02:59:06,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:07,264][root][INFO] - Training Epoch: 1/10, step 359/574 completed (loss: 3.187373399734497, acc: 0.2083333283662796)
[2024-11-29 02:59:07,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:07,853][root][INFO] - Training Epoch: 1/10, step 360/574 completed (loss: 2.798123836517334, acc: 0.26923078298568726)
[2024-11-29 02:59:07,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:08,442][root][INFO] - Training Epoch: 1/10, step 361/574 completed (loss: 3.4319026470184326, acc: 0.2195121943950653)
[2024-11-29 02:59:08,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:09,034][root][INFO] - Training Epoch: 1/10, step 362/574 completed (loss: 2.8235952854156494, acc: 0.24444444477558136)
[2024-11-29 02:59:09,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:09,631][root][INFO] - Training Epoch: 1/10, step 363/574 completed (loss: 3.280991315841675, acc: 0.25)
[2024-11-29 02:59:09,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:10,227][root][INFO] - Training Epoch: 1/10, step 364/574 completed (loss: 3.1190223693847656, acc: 0.24390244483947754)
[2024-11-29 02:59:10,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:10,818][root][INFO] - Training Epoch: 1/10, step 365/574 completed (loss: 3.10271954536438, acc: 0.1818181872367859)
[2024-11-29 02:59:10,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:11,406][root][INFO] - Training Epoch: 1/10, step 366/574 completed (loss: 2.281421184539795, acc: 0.4583333432674408)
[2024-11-29 02:59:11,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:11,994][root][INFO] - Training Epoch: 1/10, step 367/574 completed (loss: 2.843928813934326, acc: 0.30434781312942505)
[2024-11-29 02:59:12,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:12,590][root][INFO] - Training Epoch: 1/10, step 368/574 completed (loss: 2.809453248977661, acc: 0.2857142984867096)
[2024-11-29 02:59:12,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:13,180][root][INFO] - Training Epoch: 1/10, step 369/574 completed (loss: 2.699789524078369, acc: 0.4375)
[2024-11-29 02:59:13,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:13,797][root][INFO] - Training Epoch: 1/10, step 370/574 completed (loss: 3.3661298751831055, acc: 0.27272728085517883)
[2024-11-29 02:59:13,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:14,408][root][INFO] - Training Epoch: 1/10, step 371/574 completed (loss: 2.5729587078094482, acc: 0.4433962404727936)
[2024-11-29 02:59:14,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:15,002][root][INFO] - Training Epoch: 1/10, step 372/574 completed (loss: 2.8738653659820557, acc: 0.35555556416511536)
[2024-11-29 02:59:15,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:15,594][root][INFO] - Training Epoch: 1/10, step 373/574 completed (loss: 3.2840282917022705, acc: 0.2142857164144516)
[2024-11-29 02:59:15,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:16,187][root][INFO] - Training Epoch: 1/10, step 374/574 completed (loss: 2.557398557662964, acc: 0.3142857253551483)
[2024-11-29 02:59:16,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:16,775][root][INFO] - Training Epoch: 1/10, step 375/574 completed (loss: 2.936415910720825, acc: 0.23999999463558197)
[2024-11-29 02:59:16,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:17,361][root][INFO] - Training Epoch: 1/10, step 376/574 completed (loss: 2.5718271732330322, acc: 0.3913043439388275)
[2024-11-29 02:59:17,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:17,951][root][INFO] - Training Epoch: 1/10, step 377/574 completed (loss: 3.205374002456665, acc: 0.25)
[2024-11-29 02:59:18,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:18,547][root][INFO] - Training Epoch: 1/10, step 378/574 completed (loss: 3.1655516624450684, acc: 0.23157894611358643)
[2024-11-29 02:59:18,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:19,159][root][INFO] - Training Epoch: 1/10, step 379/574 completed (loss: 2.914829730987549, acc: 0.38323354721069336)
[2024-11-29 02:59:19,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:19,760][root][INFO] - Training Epoch: 1/10, step 380/574 completed (loss: 2.5865225791931152, acc: 0.42105263471603394)
[2024-11-29 02:59:19,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:20,382][root][INFO] - Training Epoch: 1/10, step 381/574 completed (loss: 2.9013607501983643, acc: 0.3582887649536133)
[2024-11-29 02:59:20,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:20,993][root][INFO] - Training Epoch: 1/10, step 382/574 completed (loss: 2.6739161014556885, acc: 0.3963963985443115)
[2024-11-29 02:59:21,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:21,582][root][INFO] - Training Epoch: 1/10, step 383/574 completed (loss: 3.0479586124420166, acc: 0.2857142984867096)
[2024-11-29 02:59:21,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:22,171][root][INFO] - Training Epoch: 1/10, step 384/574 completed (loss: 2.351548433303833, acc: 0.3928571343421936)
[2024-11-29 02:59:22,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:22,762][root][INFO] - Training Epoch: 1/10, step 385/574 completed (loss: 3.3629584312438965, acc: 0.15625)
[2024-11-29 02:59:22,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:23,350][root][INFO] - Training Epoch: 1/10, step 386/574 completed (loss: 3.386671304702759, acc: 0.25)
[2024-11-29 02:59:23,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:23,947][root][INFO] - Training Epoch: 1/10, step 387/574 completed (loss: 2.761526107788086, acc: 0.2631579041481018)
[2024-11-29 02:59:24,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:24,533][root][INFO] - Training Epoch: 1/10, step 388/574 completed (loss: 2.696211814880371, acc: 0.3181818127632141)
[2024-11-29 02:59:24,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:25,122][root][INFO] - Training Epoch: 1/10, step 389/574 completed (loss: 2.5237679481506348, acc: 0.4000000059604645)
[2024-11-29 02:59:25,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:25,710][root][INFO] - Training Epoch: 1/10, step 390/574 completed (loss: 2.5882768630981445, acc: 0.380952388048172)
[2024-11-29 02:59:25,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:26,301][root][INFO] - Training Epoch: 1/10, step 391/574 completed (loss: 2.8380625247955322, acc: 0.40740740299224854)
[2024-11-29 02:59:26,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:26,898][root][INFO] - Training Epoch: 1/10, step 392/574 completed (loss: 3.46714448928833, acc: 0.19417475163936615)
[2024-11-29 02:59:26,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:27,514][root][INFO] - Training Epoch: 1/10, step 393/574 completed (loss: 2.8706912994384766, acc: 0.3382352888584137)
[2024-11-29 02:59:27,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:28,113][root][INFO] - Training Epoch: 1/10, step 394/574 completed (loss: 3.3324763774871826, acc: 0.25333333015441895)
[2024-11-29 02:59:28,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:28,710][root][INFO] - Training Epoch: 1/10, step 395/574 completed (loss: 2.986233711242676, acc: 0.2430555522441864)
[2024-11-29 02:59:28,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:29,300][root][INFO] - Training Epoch: 1/10, step 396/574 completed (loss: 3.161364793777466, acc: 0.25581395626068115)
[2024-11-29 02:59:29,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:29,886][root][INFO] - Training Epoch: 1/10, step 397/574 completed (loss: 2.684597969055176, acc: 0.3333333432674408)
[2024-11-29 02:59:29,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:30,475][root][INFO] - Training Epoch: 1/10, step 398/574 completed (loss: 2.7288529872894287, acc: 0.302325576543808)
[2024-11-29 02:59:30,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:31,062][root][INFO] - Training Epoch: 1/10, step 399/574 completed (loss: 2.556652545928955, acc: 0.4399999976158142)
[2024-11-29 02:59:31,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:31,658][root][INFO] - Training Epoch: 1/10, step 400/574 completed (loss: 3.0528876781463623, acc: 0.30882352590560913)
[2024-11-29 02:59:31,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:32,250][root][INFO] - Training Epoch: 1/10, step 401/574 completed (loss: 2.989356517791748, acc: 0.3466666638851166)
[2024-11-29 02:59:32,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:32,841][root][INFO] - Training Epoch: 1/10, step 402/574 completed (loss: 3.439495801925659, acc: 0.3030303120613098)
[2024-11-29 02:59:32,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:33,431][root][INFO] - Training Epoch: 1/10, step 403/574 completed (loss: 2.9761464595794678, acc: 0.27272728085517883)
[2024-11-29 02:59:33,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:34,018][root][INFO] - Training Epoch: 1/10, step 404/574 completed (loss: 3.423354148864746, acc: 0.19354838132858276)
[2024-11-29 02:59:34,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:34,607][root][INFO] - Training Epoch: 1/10, step 405/574 completed (loss: 2.773402452468872, acc: 0.37037035822868347)
[2024-11-29 02:59:34,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:35,194][root][INFO] - Training Epoch: 1/10, step 406/574 completed (loss: 2.403712749481201, acc: 0.5199999809265137)
[2024-11-29 02:59:35,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:35,782][root][INFO] - Training Epoch: 1/10, step 407/574 completed (loss: 2.1101529598236084, acc: 0.4722222089767456)
[2024-11-29 02:59:35,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:36,371][root][INFO] - Training Epoch: 1/10, step 408/574 completed (loss: 2.26888370513916, acc: 0.5185185074806213)
[2024-11-29 02:59:36,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:36,959][root][INFO] - Training Epoch: 1/10, step 409/574 completed (loss: 2.066709041595459, acc: 0.5769230723381042)
[2024-11-29 02:59:37,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:37,552][root][INFO] - Training Epoch: 1/10, step 410/574 completed (loss: 2.726611375808716, acc: 0.4137931168079376)
[2024-11-29 02:59:37,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:38,144][root][INFO] - Training Epoch: 1/10, step 411/574 completed (loss: 3.4326188564300537, acc: 0.1785714328289032)
[2024-11-29 02:59:38,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:38,733][root][INFO] - Training Epoch: 1/10, step 412/574 completed (loss: 2.6255178451538086, acc: 0.3333333432674408)
[2024-11-29 02:59:38,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:39,322][root][INFO] - Training Epoch: 1/10, step 413/574 completed (loss: 3.2254960536956787, acc: 0.1818181872367859)
[2024-11-29 02:59:39,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:39,909][root][INFO] - Training Epoch: 1/10, step 414/574 completed (loss: 2.736433267593384, acc: 0.3636363744735718)
[2024-11-29 02:59:39,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:40,500][root][INFO] - Training Epoch: 1/10, step 415/574 completed (loss: 2.895907163619995, acc: 0.2549019753932953)
[2024-11-29 02:59:40,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:41,089][root][INFO] - Training Epoch: 1/10, step 416/574 completed (loss: 3.209535837173462, acc: 0.23076923191547394)
[2024-11-29 02:59:41,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:41,675][root][INFO] - Training Epoch: 1/10, step 417/574 completed (loss: 2.9750285148620605, acc: 0.3333333432674408)
[2024-11-29 02:59:41,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:42,268][root][INFO] - Training Epoch: 1/10, step 418/574 completed (loss: 2.8231608867645264, acc: 0.3499999940395355)
[2024-11-29 02:59:42,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:42,857][root][INFO] - Training Epoch: 1/10, step 419/574 completed (loss: 2.653167724609375, acc: 0.30000001192092896)
[2024-11-29 02:59:42,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:43,444][root][INFO] - Training Epoch: 1/10, step 420/574 completed (loss: 3.1807055473327637, acc: 0.3333333432674408)
[2024-11-29 02:59:43,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:44,031][root][INFO] - Training Epoch: 1/10, step 421/574 completed (loss: 2.7094006538391113, acc: 0.36666667461395264)
[2024-11-29 02:59:44,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:44,619][root][INFO] - Training Epoch: 1/10, step 422/574 completed (loss: 3.0169336795806885, acc: 0.1875)
[2024-11-29 02:59:44,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:45,207][root][INFO] - Training Epoch: 1/10, step 423/574 completed (loss: 3.138584613800049, acc: 0.3055555522441864)
[2024-11-29 02:59:45,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:45,797][root][INFO] - Training Epoch: 1/10, step 424/574 completed (loss: 2.9005422592163086, acc: 0.29629629850387573)
[2024-11-29 02:59:45,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:46,386][root][INFO] - Training Epoch: 1/10, step 425/574 completed (loss: 2.3546831607818604, acc: 0.3333333432674408)
[2024-11-29 02:59:46,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:46,975][root][INFO] - Training Epoch: 1/10, step 426/574 completed (loss: 2.1469414234161377, acc: 0.5652173757553101)
[2024-11-29 02:59:47,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:47,569][root][INFO] - Training Epoch: 1/10, step 427/574 completed (loss: 1.7865973711013794, acc: 0.5135135054588318)
[2024-11-29 02:59:47,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:48,158][root][INFO] - Training Epoch: 1/10, step 428/574 completed (loss: 2.511277437210083, acc: 0.5555555820465088)
[2024-11-29 02:59:48,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:49,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:49,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:50,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:50,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:51,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:51,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:52,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:53,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:53,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:54,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:54,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:55,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:55,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:56,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:56,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:57,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:57,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:58,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:58,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:59,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:59,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:00,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:00,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:01,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:02,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:02,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:03,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:03,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:04,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:04,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:05,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:05,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:06,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:06,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:07,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:07,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:08,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:08,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:09,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:09,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:10,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:10,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:11,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:11,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:12,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:13,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:13,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:14,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:14,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:15,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:15,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:16,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:16,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:17,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:17,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:18,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:18,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:19,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:19,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:20,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:20,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:21,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:22,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:22,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:23,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:23,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:24,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:24,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:25,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:25,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:26,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:26,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:27,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:27,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:28,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:28,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:29,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:30,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:30,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:31,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:31,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:32,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:32,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:33,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:34,158][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(22.8424, device='cuda:0') eval_epoch_loss=tensor(3.1286, device='cuda:0') eval_epoch_acc=tensor(0.2667, device='cuda:0')
[2024-11-29 03:00:34,159][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:00:34,159][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:00:34,482][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_1_step_429_loss_3.1286184787750244/model.pt
[2024-11-29 03:00:34,485][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 3.1286184787750244
[2024-11-29 03:00:34,485][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.26666200160980225
[2024-11-29 03:00:34,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:35,086][root][INFO] - Training Epoch: 1/10, step 429/574 completed (loss: 2.405593156814575, acc: 0.3913043439388275)
[2024-11-29 03:00:35,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:35,675][root][INFO] - Training Epoch: 1/10, step 430/574 completed (loss: 2.5810658931732178, acc: 0.25925925374031067)
[2024-11-29 03:00:35,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:36,261][root][INFO] - Training Epoch: 1/10, step 431/574 completed (loss: 2.860924005508423, acc: 0.2222222238779068)
[2024-11-29 03:00:36,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:36,847][root][INFO] - Training Epoch: 1/10, step 432/574 completed (loss: 2.9781334400177, acc: 0.3478260934352875)
[2024-11-29 03:00:36,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:37,436][root][INFO] - Training Epoch: 1/10, step 433/574 completed (loss: 2.4512763023376465, acc: 0.4444444477558136)
[2024-11-29 03:00:37,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:38,031][root][INFO] - Training Epoch: 1/10, step 434/574 completed (loss: 1.9615575075149536, acc: 0.47999998927116394)
[2024-11-29 03:00:38,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:38,624][root][INFO] - Training Epoch: 1/10, step 435/574 completed (loss: 2.0752694606781006, acc: 0.4848484992980957)
[2024-11-29 03:00:38,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:39,212][root][INFO] - Training Epoch: 1/10, step 436/574 completed (loss: 2.501890182495117, acc: 0.4722222089767456)
[2024-11-29 03:00:39,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:39,805][root][INFO] - Training Epoch: 1/10, step 437/574 completed (loss: 2.3724896907806396, acc: 0.5227272510528564)
[2024-11-29 03:00:39,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:40,394][root][INFO] - Training Epoch: 1/10, step 438/574 completed (loss: 1.8925390243530273, acc: 0.380952388048172)
[2024-11-29 03:00:40,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:40,986][root][INFO] - Training Epoch: 1/10, step 439/574 completed (loss: 2.901632785797119, acc: 0.28205129504203796)
[2024-11-29 03:00:41,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:41,582][root][INFO] - Training Epoch: 1/10, step 440/574 completed (loss: 2.9328725337982178, acc: 0.3484848439693451)
[2024-11-29 03:00:41,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:42,196][root][INFO] - Training Epoch: 1/10, step 441/574 completed (loss: 3.7058255672454834, acc: 0.19200000166893005)
[2024-11-29 03:00:42,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:42,796][root][INFO] - Training Epoch: 1/10, step 442/574 completed (loss: 3.1164209842681885, acc: 0.25806450843811035)
[2024-11-29 03:00:42,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:43,410][root][INFO] - Training Epoch: 1/10, step 443/574 completed (loss: 3.2236242294311523, acc: 0.2537313401699066)
[2024-11-29 03:00:43,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:44,004][root][INFO] - Training Epoch: 1/10, step 444/574 completed (loss: 2.870222330093384, acc: 0.3207547068595886)
[2024-11-29 03:00:44,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:44,597][root][INFO] - Training Epoch: 1/10, step 445/574 completed (loss: 3.069984197616577, acc: 0.27272728085517883)
[2024-11-29 03:00:44,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:45,185][root][INFO] - Training Epoch: 1/10, step 446/574 completed (loss: 2.6925714015960693, acc: 0.3478260934352875)
[2024-11-29 03:00:45,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:45,774][root][INFO] - Training Epoch: 1/10, step 447/574 completed (loss: 2.6714844703674316, acc: 0.26923078298568726)
[2024-11-29 03:00:45,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:46,362][root][INFO] - Training Epoch: 1/10, step 448/574 completed (loss: 2.8677637577056885, acc: 0.2857142984867096)
[2024-11-29 03:00:46,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:46,953][root][INFO] - Training Epoch: 1/10, step 449/574 completed (loss: 3.6657230854034424, acc: 0.2238806039094925)
[2024-11-29 03:00:47,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:47,544][root][INFO] - Training Epoch: 1/10, step 450/574 completed (loss: 2.962592601776123, acc: 0.3333333432674408)
[2024-11-29 03:00:47,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:48,135][root][INFO] - Training Epoch: 1/10, step 451/574 completed (loss: 3.2650349140167236, acc: 0.27173912525177)
[2024-11-29 03:00:48,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:48,727][root][INFO] - Training Epoch: 1/10, step 452/574 completed (loss: 3.276262044906616, acc: 0.1666666716337204)
[2024-11-29 03:00:48,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:49,322][root][INFO] - Training Epoch: 1/10, step 453/574 completed (loss: 3.5041792392730713, acc: 0.18421052396297455)
[2024-11-29 03:00:49,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:49,919][root][INFO] - Training Epoch: 1/10, step 454/574 completed (loss: 2.8273215293884277, acc: 0.36734694242477417)
[2024-11-29 03:00:50,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:50,512][root][INFO] - Training Epoch: 1/10, step 455/574 completed (loss: 3.0465214252471924, acc: 0.27272728085517883)
[2024-11-29 03:00:50,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:51,108][root][INFO] - Training Epoch: 1/10, step 456/574 completed (loss: 2.886197328567505, acc: 0.22680412232875824)
[2024-11-29 03:00:51,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:51,699][root][INFO] - Training Epoch: 1/10, step 457/574 completed (loss: 3.102715015411377, acc: 0.2571428716182709)
[2024-11-29 03:00:51,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:52,318][root][INFO] - Training Epoch: 1/10, step 458/574 completed (loss: 3.1492812633514404, acc: 0.25)
[2024-11-29 03:00:52,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:52,909][root][INFO] - Training Epoch: 1/10, step 459/574 completed (loss: 3.1204841136932373, acc: 0.25)
[2024-11-29 03:00:52,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:53,505][root][INFO] - Training Epoch: 1/10, step 460/574 completed (loss: 3.120055913925171, acc: 0.25925925374031067)
[2024-11-29 03:00:53,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:54,096][root][INFO] - Training Epoch: 1/10, step 461/574 completed (loss: 2.3543310165405273, acc: 0.3888888955116272)
[2024-11-29 03:00:54,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:54,686][root][INFO] - Training Epoch: 1/10, step 462/574 completed (loss: 2.985236883163452, acc: 0.21875)
[2024-11-29 03:00:54,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:55,274][root][INFO] - Training Epoch: 1/10, step 463/574 completed (loss: 2.723328113555908, acc: 0.3076923191547394)
[2024-11-29 03:00:55,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:55,867][root][INFO] - Training Epoch: 1/10, step 464/574 completed (loss: 3.170968532562256, acc: 0.15217390656471252)
[2024-11-29 03:00:55,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:56,462][root][INFO] - Training Epoch: 1/10, step 465/574 completed (loss: 3.337651252746582, acc: 0.2976190447807312)
[2024-11-29 03:00:56,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:57,057][root][INFO] - Training Epoch: 1/10, step 466/574 completed (loss: 3.112752914428711, acc: 0.1927710771560669)
[2024-11-29 03:00:57,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:57,670][root][INFO] - Training Epoch: 1/10, step 467/574 completed (loss: 3.0082898139953613, acc: 0.23423422873020172)
[2024-11-29 03:00:57,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:58,267][root][INFO] - Training Epoch: 1/10, step 468/574 completed (loss: 3.101886749267578, acc: 0.26213592290878296)
[2024-11-29 03:00:58,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:58,883][root][INFO] - Training Epoch: 1/10, step 469/574 completed (loss: 3.0092852115631104, acc: 0.30894309282302856)
[2024-11-29 03:00:58,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:59,476][root][INFO] - Training Epoch: 1/10, step 470/574 completed (loss: 2.356452703475952, acc: 0.375)
[2024-11-29 03:00:59,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:00,063][root][INFO] - Training Epoch: 1/10, step 471/574 completed (loss: 2.7816550731658936, acc: 0.2142857164144516)
[2024-11-29 03:01:00,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:00,678][root][INFO] - Training Epoch: 1/10, step 472/574 completed (loss: 2.8409423828125, acc: 0.30392158031463623)
[2024-11-29 03:01:00,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:01,296][root][INFO] - Training Epoch: 1/10, step 473/574 completed (loss: 3.062197685241699, acc: 0.235807865858078)
[2024-11-29 03:01:01,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:01,904][root][INFO] - Training Epoch: 1/10, step 474/574 completed (loss: 2.878018379211426, acc: 0.3020833432674408)
[2024-11-29 03:01:01,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:02,507][root][INFO] - Training Epoch: 1/10, step 475/574 completed (loss: 2.8014373779296875, acc: 0.3190183937549591)
[2024-11-29 03:01:02,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:03,105][root][INFO] - Training Epoch: 1/10, step 476/574 completed (loss: 3.0777435302734375, acc: 0.2589927911758423)
[2024-11-29 03:01:03,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:03,720][root][INFO] - Training Epoch: 1/10, step 477/574 completed (loss: 3.1464626789093018, acc: 0.2763819098472595)
[2024-11-29 03:01:03,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:04,314][root][INFO] - Training Epoch: 1/10, step 478/574 completed (loss: 2.943436622619629, acc: 0.3055555522441864)
[2024-11-29 03:01:04,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:04,904][root][INFO] - Training Epoch: 1/10, step 479/574 completed (loss: 2.513136386871338, acc: 0.3636363744735718)
[2024-11-29 03:01:04,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:05,491][root][INFO] - Training Epoch: 1/10, step 480/574 completed (loss: 2.827207326889038, acc: 0.2222222238779068)
[2024-11-29 03:01:05,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:06,088][root][INFO] - Training Epoch: 1/10, step 481/574 completed (loss: 2.6817092895507812, acc: 0.30000001192092896)
[2024-11-29 03:01:06,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:06,679][root][INFO] - Training Epoch: 1/10, step 482/574 completed (loss: 2.353938579559326, acc: 0.4000000059604645)
[2024-11-29 03:01:06,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:07,279][root][INFO] - Training Epoch: 1/10, step 483/574 completed (loss: 2.86396861076355, acc: 0.32758620381355286)
[2024-11-29 03:01:07,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:07,867][root][INFO] - Training Epoch: 1/10, step 484/574 completed (loss: 2.538832187652588, acc: 0.4516128897666931)
[2024-11-29 03:01:07,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:08,459][root][INFO] - Training Epoch: 1/10, step 485/574 completed (loss: 2.349870443344116, acc: 0.3684210479259491)
[2024-11-29 03:01:08,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:09,056][root][INFO] - Training Epoch: 1/10, step 486/574 completed (loss: 2.9276163578033447, acc: 0.2222222238779068)
[2024-11-29 03:01:09,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:09,647][root][INFO] - Training Epoch: 1/10, step 487/574 completed (loss: 2.954113483428955, acc: 0.2857142984867096)
[2024-11-29 03:01:09,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:10,234][root][INFO] - Training Epoch: 1/10, step 488/574 completed (loss: 2.7481534481048584, acc: 0.3181818127632141)
[2024-11-29 03:01:10,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:10,825][root][INFO] - Training Epoch: 1/10, step 489/574 completed (loss: 2.774686336517334, acc: 0.29230770468711853)
[2024-11-29 03:01:10,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:11,418][root][INFO] - Training Epoch: 1/10, step 490/574 completed (loss: 2.212562084197998, acc: 0.4333333373069763)
[2024-11-29 03:01:11,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:12,006][root][INFO] - Training Epoch: 1/10, step 491/574 completed (loss: 2.5227372646331787, acc: 0.4137931168079376)
[2024-11-29 03:01:12,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:12,596][root][INFO] - Training Epoch: 1/10, step 492/574 completed (loss: 2.9295387268066406, acc: 0.27450981736183167)
[2024-11-29 03:01:12,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:13,185][root][INFO] - Training Epoch: 1/10, step 493/574 completed (loss: 2.268153190612793, acc: 0.5517241358757019)
[2024-11-29 03:01:13,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:13,772][root][INFO] - Training Epoch: 1/10, step 494/574 completed (loss: 1.8134742975234985, acc: 0.5263158082962036)
[2024-11-29 03:01:13,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:14,364][root][INFO] - Training Epoch: 1/10, step 495/574 completed (loss: 3.258734941482544, acc: 0.21052631735801697)
[2024-11-29 03:01:14,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:14,960][root][INFO] - Training Epoch: 1/10, step 496/574 completed (loss: 3.2242064476013184, acc: 0.2053571492433548)
[2024-11-29 03:01:15,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:15,556][root][INFO] - Training Epoch: 1/10, step 497/574 completed (loss: 2.782100200653076, acc: 0.3258427083492279)
[2024-11-29 03:01:15,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:16,152][root][INFO] - Training Epoch: 1/10, step 498/574 completed (loss: 3.1049773693084717, acc: 0.2921348214149475)
[2024-11-29 03:01:16,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:16,761][root][INFO] - Training Epoch: 1/10, step 499/574 completed (loss: 3.1392087936401367, acc: 0.29078012704849243)
[2024-11-29 03:01:16,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:17,362][root][INFO] - Training Epoch: 1/10, step 500/574 completed (loss: 3.160304546356201, acc: 0.27173912525177)
[2024-11-29 03:01:17,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:17,952][root][INFO] - Training Epoch: 1/10, step 501/574 completed (loss: 2.494922637939453, acc: 0.4399999976158142)
[2024-11-29 03:01:18,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:18,539][root][INFO] - Training Epoch: 1/10, step 502/574 completed (loss: 2.7175772190093994, acc: 0.3076923191547394)
[2024-11-29 03:01:18,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:19,125][root][INFO] - Training Epoch: 1/10, step 503/574 completed (loss: 2.692633628845215, acc: 0.2222222238779068)
[2024-11-29 03:01:19,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:19,711][root][INFO] - Training Epoch: 1/10, step 504/574 completed (loss: 2.6582367420196533, acc: 0.25925925374031067)
[2024-11-29 03:01:19,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:20,302][root][INFO] - Training Epoch: 1/10, step 505/574 completed (loss: 2.5765223503112793, acc: 0.3396226465702057)
[2024-11-29 03:01:20,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:20,890][root][INFO] - Training Epoch: 1/10, step 506/574 completed (loss: 2.737658977508545, acc: 0.24137930572032928)
[2024-11-29 03:01:20,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:21,486][root][INFO] - Training Epoch: 1/10, step 507/574 completed (loss: 3.0343685150146484, acc: 0.315315306186676)
[2024-11-29 03:01:21,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:22,081][root][INFO] - Training Epoch: 1/10, step 508/574 completed (loss: 3.0215373039245605, acc: 0.2957746386528015)
[2024-11-29 03:01:22,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:22,667][root][INFO] - Training Epoch: 1/10, step 509/574 completed (loss: 1.4525295495986938, acc: 0.550000011920929)
[2024-11-29 03:01:22,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:23,254][root][INFO] - Training Epoch: 1/10, step 510/574 completed (loss: 2.9169797897338867, acc: 0.23333333432674408)
[2024-11-29 03:01:23,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:23,840][root][INFO] - Training Epoch: 1/10, step 511/574 completed (loss: 2.7719061374664307, acc: 0.3461538553237915)
[2024-11-29 03:01:23,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:24,473][root][INFO] - Training Epoch: 1/10, step 512/574 completed (loss: 3.0786402225494385, acc: 0.30714285373687744)
[2024-11-29 03:01:24,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:25,084][root][INFO] - Training Epoch: 1/10, step 513/574 completed (loss: 3.33046817779541, acc: 0.3095238208770752)
[2024-11-29 03:01:25,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:25,670][root][INFO] - Training Epoch: 1/10, step 514/574 completed (loss: 3.366598606109619, acc: 0.4642857015132904)
[2024-11-29 03:01:25,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:26,260][root][INFO] - Training Epoch: 1/10, step 515/574 completed (loss: 2.784674882888794, acc: 0.38333332538604736)
[2024-11-29 03:01:26,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:26,858][root][INFO] - Training Epoch: 1/10, step 516/574 completed (loss: 3.2032954692840576, acc: 0.2638888955116272)
[2024-11-29 03:01:26,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:27,443][root][INFO] - Training Epoch: 1/10, step 517/574 completed (loss: 2.1899120807647705, acc: 0.4615384638309479)
[2024-11-29 03:01:27,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:28,032][root][INFO] - Training Epoch: 1/10, step 518/574 completed (loss: 3.4331719875335693, acc: 0.25806450843811035)
[2024-11-29 03:01:28,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:28,611][root][INFO] - Training Epoch: 1/10, step 519/574 completed (loss: 2.6644997596740723, acc: 0.3499999940395355)
[2024-11-29 03:01:28,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:29,199][root][INFO] - Training Epoch: 1/10, step 520/574 completed (loss: 2.986985445022583, acc: 0.29629629850387573)
[2024-11-29 03:01:29,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:29,941][root][INFO] - Training Epoch: 1/10, step 521/574 completed (loss: 2.9668385982513428, acc: 0.27966102957725525)
[2024-11-29 03:01:30,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:30,564][root][INFO] - Training Epoch: 1/10, step 522/574 completed (loss: 2.8072478771209717, acc: 0.28358209133148193)
[2024-11-29 03:01:30,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:31,159][root][INFO] - Training Epoch: 1/10, step 523/574 completed (loss: 3.0063180923461914, acc: 0.2700729966163635)
[2024-11-29 03:01:31,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:31,779][root][INFO] - Training Epoch: 1/10, step 524/574 completed (loss: 2.6121129989624023, acc: 0.36500000953674316)
[2024-11-29 03:01:31,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:32,377][root][INFO] - Training Epoch: 1/10, step 525/574 completed (loss: 3.41943359375, acc: 0.1666666716337204)
[2024-11-29 03:01:32,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:32,969][root][INFO] - Training Epoch: 1/10, step 526/574 completed (loss: 2.4884088039398193, acc: 0.3461538553237915)
[2024-11-29 03:01:33,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:33,555][root][INFO] - Training Epoch: 1/10, step 527/574 completed (loss: 2.8748350143432617, acc: 0.380952388048172)
[2024-11-29 03:01:33,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:34,148][root][INFO] - Training Epoch: 1/10, step 528/574 completed (loss: 3.1650185585021973, acc: 0.21311475336551666)
[2024-11-29 03:01:34,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:34,737][root][INFO] - Training Epoch: 1/10, step 529/574 completed (loss: 2.755181312561035, acc: 0.3050847351551056)
[2024-11-29 03:01:34,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:35,329][root][INFO] - Training Epoch: 1/10, step 530/574 completed (loss: 3.542276382446289, acc: 0.20930232107639313)
[2024-11-29 03:01:35,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:35,917][root][INFO] - Training Epoch: 1/10, step 531/574 completed (loss: 3.2436368465423584, acc: 0.34090909361839294)
[2024-11-29 03:01:35,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:36,508][root][INFO] - Training Epoch: 1/10, step 532/574 completed (loss: 2.9119303226470947, acc: 0.22641509771347046)
[2024-11-29 03:01:36,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:37,097][root][INFO] - Training Epoch: 1/10, step 533/574 completed (loss: 3.067047357559204, acc: 0.3863636255264282)
[2024-11-29 03:01:37,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:37,682][root][INFO] - Training Epoch: 1/10, step 534/574 completed (loss: 2.534921169281006, acc: 0.3199999928474426)
[2024-11-29 03:01:37,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:38,268][root][INFO] - Training Epoch: 1/10, step 535/574 completed (loss: 2.5158777236938477, acc: 0.3499999940395355)
[2024-11-29 03:01:38,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:38,852][root][INFO] - Training Epoch: 1/10, step 536/574 completed (loss: 2.321938991546631, acc: 0.3636363744735718)
[2024-11-29 03:01:38,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:39,444][root][INFO] - Training Epoch: 1/10, step 537/574 completed (loss: 2.44599986076355, acc: 0.4153846204280853)
[2024-11-29 03:01:39,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:40,037][root][INFO] - Training Epoch: 1/10, step 538/574 completed (loss: 2.6233327388763428, acc: 0.359375)
[2024-11-29 03:01:40,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:40,623][root][INFO] - Training Epoch: 1/10, step 539/574 completed (loss: 2.264927625656128, acc: 0.5)
[2024-11-29 03:01:40,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:41,210][root][INFO] - Training Epoch: 1/10, step 540/574 completed (loss: 2.920628309249878, acc: 0.27272728085517883)
[2024-11-29 03:01:41,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:41,795][root][INFO] - Training Epoch: 1/10, step 541/574 completed (loss: 2.3608224391937256, acc: 0.375)
[2024-11-29 03:01:41,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:42,382][root][INFO] - Training Epoch: 1/10, step 542/574 completed (loss: 2.2272284030914307, acc: 0.32258063554763794)
[2024-11-29 03:01:42,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:42,969][root][INFO] - Training Epoch: 1/10, step 543/574 completed (loss: 1.702256202697754, acc: 0.47826087474823)
[2024-11-29 03:01:43,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:43,556][root][INFO] - Training Epoch: 1/10, step 544/574 completed (loss: 3.1380374431610107, acc: 0.23333333432674408)
[2024-11-29 03:01:43,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:44,145][root][INFO] - Training Epoch: 1/10, step 545/574 completed (loss: 2.9020702838897705, acc: 0.3658536672592163)
[2024-11-29 03:01:44,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:44,733][root][INFO] - Training Epoch: 1/10, step 546/574 completed (loss: 1.952522873878479, acc: 0.4571428596973419)
[2024-11-29 03:01:44,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:45,324][root][INFO] - Training Epoch: 1/10, step 547/574 completed (loss: 2.3066556453704834, acc: 0.44736841320991516)
[2024-11-29 03:01:45,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:45,911][root][INFO] - Training Epoch: 1/10, step 548/574 completed (loss: 2.3895304203033447, acc: 0.4193548262119293)
[2024-11-29 03:01:45,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:46,497][root][INFO] - Training Epoch: 1/10, step 549/574 completed (loss: 1.7089391946792603, acc: 0.5600000023841858)
[2024-11-29 03:01:46,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:47,087][root][INFO] - Training Epoch: 1/10, step 550/574 completed (loss: 2.225945234298706, acc: 0.3636363744735718)
[2024-11-29 03:01:47,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:47,676][root][INFO] - Training Epoch: 1/10, step 551/574 completed (loss: 2.4726710319519043, acc: 0.375)
[2024-11-29 03:01:47,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:48,266][root][INFO] - Training Epoch: 1/10, step 552/574 completed (loss: 2.748728036880493, acc: 0.3142857253551483)
[2024-11-29 03:01:48,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:48,875][root][INFO] - Training Epoch: 1/10, step 553/574 completed (loss: 3.3535780906677246, acc: 0.23357664048671722)
[2024-11-29 03:01:48,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:49,482][root][INFO] - Training Epoch: 1/10, step 554/574 completed (loss: 2.8327085971832275, acc: 0.32413792610168457)
[2024-11-29 03:01:49,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:50,078][root][INFO] - Training Epoch: 1/10, step 555/574 completed (loss: 3.2721195220947266, acc: 0.22142857313156128)
[2024-11-29 03:01:50,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:50,673][root][INFO] - Training Epoch: 1/10, step 556/574 completed (loss: 3.2742526531219482, acc: 0.125827819108963)
[2024-11-29 03:01:50,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:51,268][root][INFO] - Training Epoch: 1/10, step 557/574 completed (loss: 3.1210224628448486, acc: 0.24786324799060822)
[2024-11-29 03:01:51,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:51,854][root][INFO] - Training Epoch: 1/10, step 558/574 completed (loss: 2.4098353385925293, acc: 0.47999998927116394)
[2024-11-29 03:01:51,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:52,439][root][INFO] - Training Epoch: 1/10, step 559/574 completed (loss: 2.362290859222412, acc: 0.42307692766189575)
[2024-11-29 03:01:52,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:53,023][root][INFO] - Training Epoch: 1/10, step 560/574 completed (loss: 2.167673110961914, acc: 0.38461539149284363)
[2024-11-29 03:01:53,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:53,612][root][INFO] - Training Epoch: 1/10, step 561/574 completed (loss: 2.8764283657073975, acc: 0.3589743673801422)
[2024-11-29 03:01:53,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:54,219][root][INFO] - Training Epoch: 1/10, step 562/574 completed (loss: 2.6220779418945312, acc: 0.3444444537162781)
[2024-11-29 03:01:54,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:54,808][root][INFO] - Training Epoch: 1/10, step 563/574 completed (loss: 2.923488140106201, acc: 0.27272728085517883)
[2024-11-29 03:01:54,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:55,395][root][INFO] - Training Epoch: 1/10, step 564/574 completed (loss: 2.772372007369995, acc: 0.2916666567325592)
[2024-11-29 03:01:55,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:55,982][root][INFO] - Training Epoch: 1/10, step 565/574 completed (loss: 3.07480788230896, acc: 0.2931034564971924)
[2024-11-29 03:01:56,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:56,576][root][INFO] - Training Epoch: 1/10, step 566/574 completed (loss: 2.8072307109832764, acc: 0.2738095223903656)
[2024-11-29 03:01:56,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:57,163][root][INFO] - Training Epoch: 1/10, step 567/574 completed (loss: 2.4436111450195312, acc: 0.31578946113586426)
[2024-11-29 03:01:57,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:57,748][root][INFO] - Training Epoch: 1/10, step 568/574 completed (loss: 2.704923391342163, acc: 0.1111111119389534)
[2024-11-29 03:01:57,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:58,370][root][INFO] - Training Epoch: 1/10, step 569/574 completed (loss: 2.928290843963623, acc: 0.27807486057281494)
[2024-11-29 03:01:58,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:58,958][root][INFO] - Training Epoch: 1/10, step 570/574 completed (loss: 2.405477523803711, acc: 0.30645161867141724)
[2024-11-29 03:01:59,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:59,554][root][INFO] - Training Epoch: 1/10, step 571/574 completed (loss: 3.0029053688049316, acc: 0.25641027092933655)
[2024-11-29 03:02:00,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:00,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:01,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:01,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:02,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:03,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:03,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:04,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:04,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:05,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:05,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:06,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:06,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:07,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:07,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:08,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:08,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:09,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:09,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:10,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:10,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:11,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:11,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:12,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:12,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:13,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:13,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:14,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:14,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:15,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:16,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:16,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:17,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:17,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:18,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:18,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:19,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:19,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:20,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:20,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:21,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:21,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:22,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:22,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:23,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:23,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:24,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:25,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:25,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:26,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:26,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:27,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:27,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:28,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:28,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:29,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:29,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:30,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:30,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:31,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:31,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:32,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:32,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:33,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:33,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:34,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:35,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:35,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:36,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:36,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:37,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:37,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:38,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:38,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:39,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:39,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:40,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:40,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:41,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:41,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:42,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:42,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:43,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:43,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:44,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:45,278][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(14.7934, device='cuda:0') eval_epoch_loss=tensor(2.6942, device='cuda:0') eval_epoch_acc=tensor(0.3385, device='cuda:0')
[2024-11-29 03:02:45,279][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:02:45,279][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:02:45,551][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_1_step_572_loss_2.694180965423584/model.pt
[2024-11-29 03:02:45,554][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 2.694180965423584
[2024-11-29 03:02:45,554][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.33852511644363403
[2024-11-29 03:02:45,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:46,186][root][INFO] - Training Epoch: 1/10, step 572/574 completed (loss: 3.085078001022339, acc: 0.21938775479793549)
[2024-11-29 03:02:46,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:46,803][root][INFO] - Training Epoch: 1/10, step 573/574 completed (loss: 3.135769844055176, acc: 0.22012577950954437)
[2024-11-29 03:02:47,203][slam_llm.utils.train_utils][INFO] - Epoch 1: train_perplexity=40.3159, train_epoch_loss=3.6967, epoch time 532.181244192645s
[2024-11-29 03:02:47,204][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 14 GB
[2024-11-29 03:02:47,204][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-29 03:02:47,204][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 14 GB
[2024-11-29 03:02:47,204][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 1
[2024-11-29 03:02:47,204][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-29 03:02:47,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:48,277][root][INFO] - Training Epoch: 2/10, step 0/574 completed (loss: 2.801431894302368, acc: 0.37037035822868347)
[2024-11-29 03:02:48,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:48,864][root][INFO] - Training Epoch: 2/10, step 1/574 completed (loss: 2.3340511322021484, acc: 0.4399999976158142)
[2024-11-29 03:02:48,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:49,452][root][INFO] - Training Epoch: 2/10, step 2/574 completed (loss: 3.206505298614502, acc: 0.2702702581882477)
[2024-11-29 03:02:49,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:50,040][root][INFO] - Training Epoch: 2/10, step 3/574 completed (loss: 3.018444061279297, acc: 0.2368421107530594)
[2024-11-29 03:02:50,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:50,632][root][INFO] - Training Epoch: 2/10, step 4/574 completed (loss: 2.3591678142547607, acc: 0.3513513505458832)
[2024-11-29 03:02:50,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:51,220][root][INFO] - Training Epoch: 2/10, step 5/574 completed (loss: 2.6738407611846924, acc: 0.3571428656578064)
[2024-11-29 03:02:51,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:51,810][root][INFO] - Training Epoch: 2/10, step 6/574 completed (loss: 2.9439408779144287, acc: 0.26530611515045166)
[2024-11-29 03:02:51,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:52,397][root][INFO] - Training Epoch: 2/10, step 7/574 completed (loss: 2.3506669998168945, acc: 0.36666667461395264)
[2024-11-29 03:02:52,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:52,983][root][INFO] - Training Epoch: 2/10, step 8/574 completed (loss: 1.4854083061218262, acc: 0.6818181872367859)
[2024-11-29 03:02:53,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:53,570][root][INFO] - Training Epoch: 2/10, step 9/574 completed (loss: 1.997821569442749, acc: 0.42307692766189575)
[2024-11-29 03:02:53,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:54,158][root][INFO] - Training Epoch: 2/10, step 10/574 completed (loss: 2.2371315956115723, acc: 0.40740740299224854)
[2024-11-29 03:02:54,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:54,748][root][INFO] - Training Epoch: 2/10, step 11/574 completed (loss: 2.905871868133545, acc: 0.23076923191547394)
[2024-11-29 03:02:54,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:55,336][root][INFO] - Training Epoch: 2/10, step 12/574 completed (loss: 2.713233232498169, acc: 0.27272728085517883)
[2024-11-29 03:02:55,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:55,928][root][INFO] - Training Epoch: 2/10, step 13/574 completed (loss: 2.6174275875091553, acc: 0.28260868787765503)
[2024-11-29 03:02:56,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:56,519][root][INFO] - Training Epoch: 2/10, step 14/574 completed (loss: 2.7001564502716064, acc: 0.27450981736183167)
[2024-11-29 03:02:56,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:57,111][root][INFO] - Training Epoch: 2/10, step 15/574 completed (loss: 2.0083911418914795, acc: 0.4897959232330322)
[2024-11-29 03:02:57,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:57,696][root][INFO] - Training Epoch: 2/10, step 16/574 completed (loss: 1.958060622215271, acc: 0.4736842215061188)
[2024-11-29 03:02:57,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:58,284][root][INFO] - Training Epoch: 2/10, step 17/574 completed (loss: 2.296504259109497, acc: 0.25)
[2024-11-29 03:02:58,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:58,874][root][INFO] - Training Epoch: 2/10, step 18/574 completed (loss: 3.415536642074585, acc: 0.1944444477558136)
[2024-11-29 03:02:58,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:59,462][root][INFO] - Training Epoch: 2/10, step 19/574 completed (loss: 2.6619672775268555, acc: 0.3684210479259491)
[2024-11-29 03:02:59,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:00,053][root][INFO] - Training Epoch: 2/10, step 20/574 completed (loss: 2.9925613403320312, acc: 0.1538461595773697)
[2024-11-29 03:03:00,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:00,642][root][INFO] - Training Epoch: 2/10, step 21/574 completed (loss: 2.47055721282959, acc: 0.4482758641242981)
[2024-11-29 03:03:00,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:01,228][root][INFO] - Training Epoch: 2/10, step 22/574 completed (loss: 2.7165298461914062, acc: 0.2800000011920929)
[2024-11-29 03:03:01,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:01,816][root][INFO] - Training Epoch: 2/10, step 23/574 completed (loss: 2.227199077606201, acc: 0.4285714328289032)
[2024-11-29 03:03:01,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:02,405][root][INFO] - Training Epoch: 2/10, step 24/574 completed (loss: 2.598658800125122, acc: 0.25)
[2024-11-29 03:03:02,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:03,000][root][INFO] - Training Epoch: 2/10, step 25/574 completed (loss: 3.131565570831299, acc: 0.18867924809455872)
[2024-11-29 03:03:03,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:03,591][root][INFO] - Training Epoch: 2/10, step 26/574 completed (loss: 2.8956916332244873, acc: 0.2602739632129669)
[2024-11-29 03:03:03,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:04,263][root][INFO] - Training Epoch: 2/10, step 27/574 completed (loss: 3.0010886192321777, acc: 0.24901185929775238)
[2024-11-29 03:03:04,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:04,853][root][INFO] - Training Epoch: 2/10, step 28/574 completed (loss: 3.093902826309204, acc: 0.20930232107639313)
[2024-11-29 03:03:04,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:05,446][root][INFO] - Training Epoch: 2/10, step 29/574 completed (loss: 2.971797227859497, acc: 0.21686747670173645)
[2024-11-29 03:03:05,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:06,042][root][INFO] - Training Epoch: 2/10, step 30/574 completed (loss: 2.840514659881592, acc: 0.2469135820865631)
[2024-11-29 03:03:06,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:06,629][root][INFO] - Training Epoch: 2/10, step 31/574 completed (loss: 2.6768624782562256, acc: 0.2857142984867096)
[2024-11-29 03:03:06,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:07,214][root][INFO] - Training Epoch: 2/10, step 32/574 completed (loss: 2.37140154838562, acc: 0.3333333432674408)
[2024-11-29 03:03:07,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:07,805][root][INFO] - Training Epoch: 2/10, step 33/574 completed (loss: 2.5278475284576416, acc: 0.43478259444236755)
[2024-11-29 03:03:07,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:08,407][root][INFO] - Training Epoch: 2/10, step 34/574 completed (loss: 2.7501914501190186, acc: 0.29411765933036804)
[2024-11-29 03:03:08,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:08,998][root][INFO] - Training Epoch: 2/10, step 35/574 completed (loss: 2.614253282546997, acc: 0.3442623019218445)
[2024-11-29 03:03:09,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:09,594][root][INFO] - Training Epoch: 2/10, step 36/574 completed (loss: 2.4334609508514404, acc: 0.30158731341362)
[2024-11-29 03:03:09,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:10,183][root][INFO] - Training Epoch: 2/10, step 37/574 completed (loss: 3.198101758956909, acc: 0.20338982343673706)
[2024-11-29 03:03:10,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:10,776][root][INFO] - Training Epoch: 2/10, step 38/574 completed (loss: 2.534942865371704, acc: 0.37931033968925476)
[2024-11-29 03:03:10,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:11,362][root][INFO] - Training Epoch: 2/10, step 39/574 completed (loss: 2.5427334308624268, acc: 0.2380952388048172)
[2024-11-29 03:03:11,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:11,951][root][INFO] - Training Epoch: 2/10, step 40/574 completed (loss: 2.9301376342773438, acc: 0.11538461595773697)
[2024-11-29 03:03:12,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:12,546][root][INFO] - Training Epoch: 2/10, step 41/574 completed (loss: 3.133955717086792, acc: 0.20270270109176636)
[2024-11-29 03:03:12,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:13,137][root][INFO] - Training Epoch: 2/10, step 42/574 completed (loss: 3.1665422916412354, acc: 0.20000000298023224)
[2024-11-29 03:03:13,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:13,729][root][INFO] - Training Epoch: 2/10, step 43/574 completed (loss: 3.1969985961914062, acc: 0.20202019810676575)
[2024-11-29 03:03:13,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:14,324][root][INFO] - Training Epoch: 2/10, step 44/574 completed (loss: 2.7993128299713135, acc: 0.3711340129375458)
[2024-11-29 03:03:14,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:14,921][root][INFO] - Training Epoch: 2/10, step 45/574 completed (loss: 3.060276985168457, acc: 0.2720588147640228)
[2024-11-29 03:03:15,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:15,508][root][INFO] - Training Epoch: 2/10, step 46/574 completed (loss: 1.999174952507019, acc: 0.42307692766189575)
[2024-11-29 03:03:15,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:16,095][root][INFO] - Training Epoch: 2/10, step 47/574 completed (loss: 1.7921173572540283, acc: 0.5185185074806213)
[2024-11-29 03:03:16,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:16,684][root][INFO] - Training Epoch: 2/10, step 48/574 completed (loss: 2.3348095417022705, acc: 0.3928571343421936)
[2024-11-29 03:03:16,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:17,274][root][INFO] - Training Epoch: 2/10, step 49/574 completed (loss: 2.381566047668457, acc: 0.3611111044883728)
[2024-11-29 03:03:17,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:17,866][root][INFO] - Training Epoch: 2/10, step 50/574 completed (loss: 2.6742939949035645, acc: 0.3333333432674408)
[2024-11-29 03:03:17,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:18,459][root][INFO] - Training Epoch: 2/10, step 51/574 completed (loss: 2.6631362438201904, acc: 0.3333333432674408)
[2024-11-29 03:03:18,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:19,053][root][INFO] - Training Epoch: 2/10, step 52/574 completed (loss: 3.0422937870025635, acc: 0.30985915660858154)
[2024-11-29 03:03:19,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:19,663][root][INFO] - Training Epoch: 2/10, step 53/574 completed (loss: 3.3877601623535156, acc: 0.30666667222976685)
[2024-11-29 03:03:19,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:20,251][root][INFO] - Training Epoch: 2/10, step 54/574 completed (loss: 2.362794876098633, acc: 0.45945945382118225)
[2024-11-29 03:03:20,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:20,838][root][INFO] - Training Epoch: 2/10, step 55/574 completed (loss: 2.0790579319000244, acc: 0.4615384638309479)
[2024-11-29 03:03:20,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:21,538][root][INFO] - Training Epoch: 2/10, step 56/574 completed (loss: 2.677478790283203, acc: 0.361774742603302)
[2024-11-29 03:03:21,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:22,192][root][INFO] - Training Epoch: 2/10, step 57/574 completed (loss: 3.045278549194336, acc: 0.3028322458267212)
[2024-11-29 03:03:22,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:22,808][root][INFO] - Training Epoch: 2/10, step 58/574 completed (loss: 2.6272075176239014, acc: 0.3579545319080353)
[2024-11-29 03:03:22,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:23,406][root][INFO] - Training Epoch: 2/10, step 59/574 completed (loss: 2.9762892723083496, acc: 0.34558823704719543)
[2024-11-29 03:03:23,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:24,020][root][INFO] - Training Epoch: 2/10, step 60/574 completed (loss: 2.725620746612549, acc: 0.34057971835136414)
[2024-11-29 03:03:24,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:24,632][root][INFO] - Training Epoch: 2/10, step 61/574 completed (loss: 2.223245143890381, acc: 0.5249999761581421)
[2024-11-29 03:03:24,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:25,224][root][INFO] - Training Epoch: 2/10, step 62/574 completed (loss: 2.368067979812622, acc: 0.29411765933036804)
[2024-11-29 03:03:25,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:25,815][root][INFO] - Training Epoch: 2/10, step 63/574 completed (loss: 2.632436513900757, acc: 0.3888888955116272)
[2024-11-29 03:03:25,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:26,414][root][INFO] - Training Epoch: 2/10, step 64/574 completed (loss: 2.184985876083374, acc: 0.375)
[2024-11-29 03:03:26,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:27,002][root][INFO] - Training Epoch: 2/10, step 65/574 completed (loss: 1.604812502861023, acc: 0.5862069129943848)
[2024-11-29 03:03:27,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:27,592][root][INFO] - Training Epoch: 2/10, step 66/574 completed (loss: 2.762012004852295, acc: 0.3571428656578064)
[2024-11-29 03:03:27,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:28,184][root][INFO] - Training Epoch: 2/10, step 67/574 completed (loss: 2.9438815116882324, acc: 0.25)
[2024-11-29 03:03:28,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:28,774][root][INFO] - Training Epoch: 2/10, step 68/574 completed (loss: 1.7662357091903687, acc: 0.6399999856948853)
[2024-11-29 03:03:28,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:29,366][root][INFO] - Training Epoch: 2/10, step 69/574 completed (loss: 2.241898536682129, acc: 0.4444444477558136)
[2024-11-29 03:03:29,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:29,958][root][INFO] - Training Epoch: 2/10, step 70/574 completed (loss: 3.1679913997650146, acc: 0.27272728085517883)
[2024-11-29 03:03:30,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:30,576][root][INFO] - Training Epoch: 2/10, step 71/574 completed (loss: 3.0266048908233643, acc: 0.2720588147640228)
[2024-11-29 03:03:30,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:31,175][root][INFO] - Training Epoch: 2/10, step 72/574 completed (loss: 2.92448091506958, acc: 0.230158731341362)
[2024-11-29 03:03:31,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:31,789][root][INFO] - Training Epoch: 2/10, step 73/574 completed (loss: 3.224365234375, acc: 0.28205129504203796)
[2024-11-29 03:03:31,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:32,384][root][INFO] - Training Epoch: 2/10, step 74/574 completed (loss: 3.1608548164367676, acc: 0.2857142984867096)
[2024-11-29 03:03:32,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:32,981][root][INFO] - Training Epoch: 2/10, step 75/574 completed (loss: 3.2945377826690674, acc: 0.20895522832870483)
[2024-11-29 03:03:33,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:33,607][root][INFO] - Training Epoch: 2/10, step 76/574 completed (loss: 3.0929486751556396, acc: 0.31386861205101013)
[2024-11-29 03:03:33,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:34,193][root][INFO] - Training Epoch: 2/10, step 77/574 completed (loss: 1.990533709526062, acc: 0.4761904776096344)
[2024-11-29 03:03:34,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:34,785][root][INFO] - Training Epoch: 2/10, step 78/574 completed (loss: 1.7453027963638306, acc: 0.5)
[2024-11-29 03:03:34,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:35,376][root][INFO] - Training Epoch: 2/10, step 79/574 completed (loss: 2.3980424404144287, acc: 0.4545454680919647)
[2024-11-29 03:03:35,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:35,966][root][INFO] - Training Epoch: 2/10, step 80/574 completed (loss: 2.678159236907959, acc: 0.3461538553237915)
[2024-11-29 03:03:36,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:36,557][root][INFO] - Training Epoch: 2/10, step 81/574 completed (loss: 2.8744168281555176, acc: 0.25)
[2024-11-29 03:03:36,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:37,148][root][INFO] - Training Epoch: 2/10, step 82/574 completed (loss: 3.0765929222106934, acc: 0.2884615361690521)
[2024-11-29 03:03:37,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:37,735][root][INFO] - Training Epoch: 2/10, step 83/574 completed (loss: 2.4451756477355957, acc: 0.34375)
[2024-11-29 03:03:37,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:38,327][root][INFO] - Training Epoch: 2/10, step 84/574 completed (loss: 2.792060613632202, acc: 0.2753623127937317)
[2024-11-29 03:03:38,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:38,918][root][INFO] - Training Epoch: 2/10, step 85/574 completed (loss: 2.252748966217041, acc: 0.46000000834465027)
[2024-11-29 03:03:38,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:39,505][root][INFO] - Training Epoch: 2/10, step 86/574 completed (loss: 2.030296564102173, acc: 0.47826087474823)
[2024-11-29 03:03:39,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:40,099][root][INFO] - Training Epoch: 2/10, step 87/574 completed (loss: 2.747436285018921, acc: 0.3400000035762787)
[2024-11-29 03:03:40,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:40,695][root][INFO] - Training Epoch: 2/10, step 88/574 completed (loss: 2.5402233600616455, acc: 0.3689320385456085)
[2024-11-29 03:03:40,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:41,308][root][INFO] - Training Epoch: 2/10, step 89/574 completed (loss: 2.6767525672912598, acc: 0.3543689250946045)
[2024-11-29 03:03:41,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:41,924][root][INFO] - Training Epoch: 2/10, step 90/574 completed (loss: 2.891110420227051, acc: 0.32258063554763794)
[2024-11-29 03:03:42,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:42,547][root][INFO] - Training Epoch: 2/10, step 91/574 completed (loss: 2.529451847076416, acc: 0.4137931168079376)
[2024-11-29 03:03:42,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:43,144][root][INFO] - Training Epoch: 2/10, step 92/574 completed (loss: 2.5633416175842285, acc: 0.378947377204895)
[2024-11-29 03:03:43,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:43,758][root][INFO] - Training Epoch: 2/10, step 93/574 completed (loss: 3.1040618419647217, acc: 0.2673267424106598)
[2024-11-29 03:03:43,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:44,352][root][INFO] - Training Epoch: 2/10, step 94/574 completed (loss: 3.143139600753784, acc: 0.29032257199287415)
[2024-11-29 03:03:44,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:44,945][root][INFO] - Training Epoch: 2/10, step 95/574 completed (loss: 2.837306261062622, acc: 0.24637681245803833)
[2024-11-29 03:03:45,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:45,542][root][INFO] - Training Epoch: 2/10, step 96/574 completed (loss: 3.076350688934326, acc: 0.21008403599262238)
[2024-11-29 03:03:45,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:46,137][root][INFO] - Training Epoch: 2/10, step 97/574 completed (loss: 3.1632766723632812, acc: 0.20192307233810425)
[2024-11-29 03:03:46,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:46,744][root][INFO] - Training Epoch: 2/10, step 98/574 completed (loss: 2.971141815185547, acc: 0.29927006363868713)
[2024-11-29 03:03:46,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:47,333][root][INFO] - Training Epoch: 2/10, step 99/574 completed (loss: 3.2111318111419678, acc: 0.2238806039094925)
[2024-11-29 03:03:47,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:47,918][root][INFO] - Training Epoch: 2/10, step 100/574 completed (loss: 2.190091133117676, acc: 0.3499999940395355)
[2024-11-29 03:03:47,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:48,505][root][INFO] - Training Epoch: 2/10, step 101/574 completed (loss: 1.907544732093811, acc: 0.5)
[2024-11-29 03:03:48,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:49,091][root][INFO] - Training Epoch: 2/10, step 102/574 completed (loss: 1.746434211730957, acc: 0.52173912525177)
[2024-11-29 03:03:49,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:49,680][root][INFO] - Training Epoch: 2/10, step 103/574 completed (loss: 2.5377037525177, acc: 0.3636363744735718)
[2024-11-29 03:03:49,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:50,272][root][INFO] - Training Epoch: 2/10, step 104/574 completed (loss: 2.858564853668213, acc: 0.2931034564971924)
[2024-11-29 03:03:50,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:50,863][root][INFO] - Training Epoch: 2/10, step 105/574 completed (loss: 2.812087059020996, acc: 0.27906978130340576)
[2024-11-29 03:03:50,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:51,451][root][INFO] - Training Epoch: 2/10, step 106/574 completed (loss: 1.6715643405914307, acc: 0.6000000238418579)
[2024-11-29 03:03:51,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:52,039][root][INFO] - Training Epoch: 2/10, step 107/574 completed (loss: 1.3201971054077148, acc: 0.7647058963775635)
[2024-11-29 03:03:52,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:52,628][root][INFO] - Training Epoch: 2/10, step 108/574 completed (loss: 1.4442685842514038, acc: 0.6153846383094788)
[2024-11-29 03:03:52,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:53,221][root][INFO] - Training Epoch: 2/10, step 109/574 completed (loss: 2.780568838119507, acc: 0.261904776096344)
[2024-11-29 03:03:53,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:53,811][root][INFO] - Training Epoch: 2/10, step 110/574 completed (loss: 2.9323348999023438, acc: 0.3692307770252228)
[2024-11-29 03:03:53,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:54,404][root][INFO] - Training Epoch: 2/10, step 111/574 completed (loss: 2.875901937484741, acc: 0.31578946113586426)
[2024-11-29 03:03:54,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:54,994][root][INFO] - Training Epoch: 2/10, step 112/574 completed (loss: 2.605828046798706, acc: 0.35087719559669495)
[2024-11-29 03:03:55,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:55,586][root][INFO] - Training Epoch: 2/10, step 113/574 completed (loss: 2.9157917499542236, acc: 0.1794871836900711)
[2024-11-29 03:03:55,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:56,180][root][INFO] - Training Epoch: 2/10, step 114/574 completed (loss: 2.1567909717559814, acc: 0.4285714328289032)
[2024-11-29 03:03:56,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:56,769][root][INFO] - Training Epoch: 2/10, step 115/574 completed (loss: 1.7151201963424683, acc: 0.5909090638160706)
[2024-11-29 03:03:56,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:57,367][root][INFO] - Training Epoch: 2/10, step 116/574 completed (loss: 2.4493327140808105, acc: 0.3650793731212616)
[2024-11-29 03:03:57,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:57,960][root][INFO] - Training Epoch: 2/10, step 117/574 completed (loss: 2.764092206954956, acc: 0.3008130192756653)
[2024-11-29 03:03:58,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:58,552][root][INFO] - Training Epoch: 2/10, step 118/574 completed (loss: 2.7649505138397217, acc: 0.3870967626571655)
[2024-11-29 03:03:58,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:59,196][root][INFO] - Training Epoch: 2/10, step 119/574 completed (loss: 2.776641368865967, acc: 0.33840304613113403)
[2024-11-29 03:03:59,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:59,792][root][INFO] - Training Epoch: 2/10, step 120/574 completed (loss: 2.6432833671569824, acc: 0.3733333349227905)
[2024-11-29 03:03:59,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:00,385][root][INFO] - Training Epoch: 2/10, step 121/574 completed (loss: 2.503333806991577, acc: 0.4423076808452606)
[2024-11-29 03:04:00,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:00,971][root][INFO] - Training Epoch: 2/10, step 122/574 completed (loss: 1.5110722780227661, acc: 0.7083333134651184)
[2024-11-29 03:04:01,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:01,559][root][INFO] - Training Epoch: 2/10, step 123/574 completed (loss: 2.274171829223633, acc: 0.4736842215061188)
[2024-11-29 03:04:01,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:02,159][root][INFO] - Training Epoch: 2/10, step 124/574 completed (loss: 2.9829604625701904, acc: 0.25153374671936035)
[2024-11-29 03:04:02,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:02,774][root][INFO] - Training Epoch: 2/10, step 125/574 completed (loss: 2.61504864692688, acc: 0.3611111044883728)
[2024-11-29 03:04:02,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:03,370][root][INFO] - Training Epoch: 2/10, step 126/574 completed (loss: 2.90653133392334, acc: 0.28333333134651184)
[2024-11-29 03:04:03,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:03,990][root][INFO] - Training Epoch: 2/10, step 127/574 completed (loss: 2.834587335586548, acc: 0.255952388048172)
[2024-11-29 03:04:04,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:04,602][root][INFO] - Training Epoch: 2/10, step 128/574 completed (loss: 2.93002986907959, acc: 0.3076923191547394)
[2024-11-29 03:04:04,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:05,226][root][INFO] - Training Epoch: 2/10, step 129/574 completed (loss: 2.4651172161102295, acc: 0.40441176295280457)
[2024-11-29 03:04:05,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:05,815][root][INFO] - Training Epoch: 2/10, step 130/574 completed (loss: 1.843464970588684, acc: 0.38461539149284363)
[2024-11-29 03:04:05,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:06,402][root][INFO] - Training Epoch: 2/10, step 131/574 completed (loss: 1.4887195825576782, acc: 0.47826087474823)
[2024-11-29 03:04:06,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:06,990][root][INFO] - Training Epoch: 2/10, step 132/574 completed (loss: 2.9172658920288086, acc: 0.34375)
[2024-11-29 03:04:07,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:07,575][root][INFO] - Training Epoch: 2/10, step 133/574 completed (loss: 2.0348756313323975, acc: 0.43478259444236755)
[2024-11-29 03:04:07,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:08,163][root][INFO] - Training Epoch: 2/10, step 134/574 completed (loss: 2.394733428955078, acc: 0.34285715222358704)
[2024-11-29 03:04:08,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:08,751][root][INFO] - Training Epoch: 2/10, step 135/574 completed (loss: 2.2241110801696777, acc: 0.38461539149284363)
[2024-11-29 03:04:08,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:09,343][root][INFO] - Training Epoch: 2/10, step 136/574 completed (loss: 3.010615587234497, acc: 0.2857142984867096)
[2024-11-29 03:04:09,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:09,932][root][INFO] - Training Epoch: 2/10, step 137/574 completed (loss: 2.4402778148651123, acc: 0.30000001192092896)
[2024-11-29 03:04:10,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:10,520][root][INFO] - Training Epoch: 2/10, step 138/574 completed (loss: 1.96319580078125, acc: 0.47826087474823)
[2024-11-29 03:04:10,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:11,108][root][INFO] - Training Epoch: 2/10, step 139/574 completed (loss: 3.0787105560302734, acc: 0.2857142984867096)
[2024-11-29 03:04:11,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:11,696][root][INFO] - Training Epoch: 2/10, step 140/574 completed (loss: 2.499788999557495, acc: 0.38461539149284363)
[2024-11-29 03:04:12,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:12,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:13,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:14,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:14,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:15,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:15,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:16,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:16,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:17,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:17,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:18,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:18,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:19,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:19,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:20,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:20,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:21,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:21,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:22,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:22,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:23,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:23,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:24,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:25,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:25,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:26,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:26,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:27,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:27,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:28,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:28,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:29,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:29,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:30,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:30,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:31,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:31,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:32,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:32,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:33,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:33,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:34,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:35,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:35,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:36,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:36,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:37,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:37,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:38,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:38,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:39,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:39,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:40,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:40,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:41,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:41,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:42,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:42,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:43,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:43,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:44,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:45,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:45,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:46,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:46,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:47,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:47,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:48,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:48,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:49,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:49,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:50,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:50,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:51,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:51,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:52,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:53,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:53,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:54,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:54,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:55,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:55,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:56,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:56,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:57,512][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(14.2668, device='cuda:0') eval_epoch_loss=tensor(2.6579, device='cuda:0') eval_epoch_acc=tensor(0.3209, device='cuda:0')
[2024-11-29 03:04:57,513][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:04:57,513][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:04:57,785][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_2_step_141_loss_2.6579320430755615/model.pt
[2024-11-29 03:04:57,787][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 2.6579320430755615
[2024-11-29 03:04:57,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:58,389][root][INFO] - Training Epoch: 2/10, step 141/574 completed (loss: 2.7027969360351562, acc: 0.3870967626571655)
[2024-11-29 03:04:58,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:58,979][root][INFO] - Training Epoch: 2/10, step 142/574 completed (loss: 3.406883955001831, acc: 0.0810810774564743)
[2024-11-29 03:04:59,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:59,590][root][INFO] - Training Epoch: 2/10, step 143/574 completed (loss: 2.598790407180786, acc: 0.3947368562221527)
[2024-11-29 03:04:59,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:00,185][root][INFO] - Training Epoch: 2/10, step 144/574 completed (loss: 2.4689078330993652, acc: 0.3731343150138855)
[2024-11-29 03:05:00,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:00,785][root][INFO] - Training Epoch: 2/10, step 145/574 completed (loss: 2.8337576389312744, acc: 0.2551020383834839)
[2024-11-29 03:05:00,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:01,395][root][INFO] - Training Epoch: 2/10, step 146/574 completed (loss: 2.81215238571167, acc: 0.3191489279270172)
[2024-11-29 03:05:01,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:01,989][root][INFO] - Training Epoch: 2/10, step 147/574 completed (loss: 2.8340489864349365, acc: 0.37142857909202576)
[2024-11-29 03:05:02,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:02,575][root][INFO] - Training Epoch: 2/10, step 148/574 completed (loss: 3.035390615463257, acc: 0.3214285671710968)
[2024-11-29 03:05:02,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:03,160][root][INFO] - Training Epoch: 2/10, step 149/574 completed (loss: 2.382516860961914, acc: 0.3478260934352875)
[2024-11-29 03:05:03,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:03,746][root][INFO] - Training Epoch: 2/10, step 150/574 completed (loss: 2.8023600578308105, acc: 0.3103448152542114)
[2024-11-29 03:05:03,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:04,335][root][INFO] - Training Epoch: 2/10, step 151/574 completed (loss: 2.6753082275390625, acc: 0.3695652186870575)
[2024-11-29 03:05:04,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:04,933][root][INFO] - Training Epoch: 2/10, step 152/574 completed (loss: 2.4133572578430176, acc: 0.3050847351551056)
[2024-11-29 03:05:05,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:05,524][root][INFO] - Training Epoch: 2/10, step 153/574 completed (loss: 2.777660608291626, acc: 0.31578946113586426)
[2024-11-29 03:05:05,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:06,118][root][INFO] - Training Epoch: 2/10, step 154/574 completed (loss: 2.699707269668579, acc: 0.3378378450870514)
[2024-11-29 03:05:06,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:06,704][root][INFO] - Training Epoch: 2/10, step 155/574 completed (loss: 2.389768362045288, acc: 0.5714285969734192)
[2024-11-29 03:05:06,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:07,290][root][INFO] - Training Epoch: 2/10, step 156/574 completed (loss: 1.2559702396392822, acc: 0.695652186870575)
[2024-11-29 03:05:07,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:07,876][root][INFO] - Training Epoch: 2/10, step 157/574 completed (loss: 2.5708847045898438, acc: 0.31578946113586426)
[2024-11-29 03:05:07,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:08,467][root][INFO] - Training Epoch: 2/10, step 158/574 completed (loss: 2.989290714263916, acc: 0.36486485600471497)
[2024-11-29 03:05:08,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:09,058][root][INFO] - Training Epoch: 2/10, step 159/574 completed (loss: 2.8061068058013916, acc: 0.31481480598449707)
[2024-11-29 03:05:09,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:09,653][root][INFO] - Training Epoch: 2/10, step 160/574 completed (loss: 2.8732995986938477, acc: 0.3488371968269348)
[2024-11-29 03:05:09,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:10,247][root][INFO] - Training Epoch: 2/10, step 161/574 completed (loss: 2.6837518215179443, acc: 0.4000000059604645)
[2024-11-29 03:05:10,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:10,843][root][INFO] - Training Epoch: 2/10, step 162/574 completed (loss: 3.0053412914276123, acc: 0.2808988690376282)
[2024-11-29 03:05:10,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:11,434][root][INFO] - Training Epoch: 2/10, step 163/574 completed (loss: 2.2624452114105225, acc: 0.40909090638160706)
[2024-11-29 03:05:11,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:12,021][root][INFO] - Training Epoch: 2/10, step 164/574 completed (loss: 1.9161291122436523, acc: 0.2857142984867096)
[2024-11-29 03:05:12,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:12,607][root][INFO] - Training Epoch: 2/10, step 165/574 completed (loss: 2.446160316467285, acc: 0.27586206793785095)
[2024-11-29 03:05:12,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:13,197][root][INFO] - Training Epoch: 2/10, step 166/574 completed (loss: 1.991170883178711, acc: 0.44897958636283875)
[2024-11-29 03:05:13,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:13,784][root][INFO] - Training Epoch: 2/10, step 167/574 completed (loss: 2.4238462448120117, acc: 0.36000001430511475)
[2024-11-29 03:05:13,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:14,378][root][INFO] - Training Epoch: 2/10, step 168/574 completed (loss: 2.6417458057403564, acc: 0.3611111044883728)
[2024-11-29 03:05:14,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:14,973][root][INFO] - Training Epoch: 2/10, step 169/574 completed (loss: 2.5935728549957275, acc: 0.343137264251709)
[2024-11-29 03:05:15,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:15,596][root][INFO] - Training Epoch: 2/10, step 170/574 completed (loss: 3.1759274005889893, acc: 0.3219178020954132)
[2024-11-29 03:05:15,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:16,187][root][INFO] - Training Epoch: 2/10, step 171/574 completed (loss: 1.5684608221054077, acc: 0.625)
[2024-11-29 03:05:16,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:16,775][root][INFO] - Training Epoch: 2/10, step 172/574 completed (loss: 2.496680736541748, acc: 0.18518517911434174)
[2024-11-29 03:05:16,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:17,363][root][INFO] - Training Epoch: 2/10, step 173/574 completed (loss: 2.4594569206237793, acc: 0.3214285671710968)
[2024-11-29 03:05:17,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:17,974][root][INFO] - Training Epoch: 2/10, step 174/574 completed (loss: 2.700481414794922, acc: 0.36283186078071594)
[2024-11-29 03:05:18,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:18,567][root][INFO] - Training Epoch: 2/10, step 175/574 completed (loss: 3.014646530151367, acc: 0.24637681245803833)
[2024-11-29 03:05:18,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:19,162][root][INFO] - Training Epoch: 2/10, step 176/574 completed (loss: 2.729806423187256, acc: 0.27272728085517883)
[2024-11-29 03:05:19,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:19,774][root][INFO] - Training Epoch: 2/10, step 177/574 completed (loss: 3.0945792198181152, acc: 0.2748091518878937)
[2024-11-29 03:05:19,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:20,382][root][INFO] - Training Epoch: 2/10, step 178/574 completed (loss: 3.2092580795288086, acc: 0.21481481194496155)
[2024-11-29 03:05:20,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:20,974][root][INFO] - Training Epoch: 2/10, step 179/574 completed (loss: 2.576616048812866, acc: 0.4590163826942444)
[2024-11-29 03:05:21,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:21,560][root][INFO] - Training Epoch: 2/10, step 180/574 completed (loss: 1.532162070274353, acc: 0.5)
[2024-11-29 03:05:21,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:22,145][root][INFO] - Training Epoch: 2/10, step 181/574 completed (loss: 1.7162574529647827, acc: 0.6399999856948853)
[2024-11-29 03:05:22,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:22,733][root][INFO] - Training Epoch: 2/10, step 182/574 completed (loss: 2.289686441421509, acc: 0.5)
[2024-11-29 03:05:22,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:23,327][root][INFO] - Training Epoch: 2/10, step 183/574 completed (loss: 3.0725996494293213, acc: 0.19512194395065308)
[2024-11-29 03:05:23,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:23,951][root][INFO] - Training Epoch: 2/10, step 184/574 completed (loss: 3.1553726196289062, acc: 0.2386706918478012)
[2024-11-29 03:05:24,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:24,577][root][INFO] - Training Epoch: 2/10, step 185/574 completed (loss: 2.9687211513519287, acc: 0.24783861637115479)
[2024-11-29 03:05:24,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:25,200][root][INFO] - Training Epoch: 2/10, step 186/574 completed (loss: 3.138094663619995, acc: 0.2562499940395355)
[2024-11-29 03:05:25,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:25,857][root][INFO] - Training Epoch: 2/10, step 187/574 completed (loss: 3.0088956356048584, acc: 0.26266416907310486)
[2024-11-29 03:05:25,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:26,491][root][INFO] - Training Epoch: 2/10, step 188/574 completed (loss: 2.738931894302368, acc: 0.29537367820739746)
[2024-11-29 03:05:26,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:27,077][root][INFO] - Training Epoch: 2/10, step 189/574 completed (loss: 2.5839016437530518, acc: 0.47999998927116394)
[2024-11-29 03:05:27,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:27,674][root][INFO] - Training Epoch: 2/10, step 190/574 completed (loss: 2.6245501041412354, acc: 0.3720930218696594)
[2024-11-29 03:05:27,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:28,269][root][INFO] - Training Epoch: 2/10, step 191/574 completed (loss: 2.734243631362915, acc: 0.3650793731212616)
[2024-11-29 03:05:28,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:28,866][root][INFO] - Training Epoch: 2/10, step 192/574 completed (loss: 2.7601194381713867, acc: 0.3333333432674408)
[2024-11-29 03:05:28,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:29,461][root][INFO] - Training Epoch: 2/10, step 193/574 completed (loss: 2.293095588684082, acc: 0.4470588266849518)
[2024-11-29 03:05:29,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:30,075][root][INFO] - Training Epoch: 2/10, step 194/574 completed (loss: 2.4241158962249756, acc: 0.4135802388191223)
[2024-11-29 03:05:30,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:30,672][root][INFO] - Training Epoch: 2/10, step 195/574 completed (loss: 2.2213997840881348, acc: 0.4838709533214569)
[2024-11-29 03:05:30,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:31,259][root][INFO] - Training Epoch: 2/10, step 196/574 completed (loss: 2.197477102279663, acc: 0.5)
[2024-11-29 03:05:31,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:31,848][root][INFO] - Training Epoch: 2/10, step 197/574 completed (loss: 2.985621690750122, acc: 0.32499998807907104)
[2024-11-29 03:05:31,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:32,441][root][INFO] - Training Epoch: 2/10, step 198/574 completed (loss: 3.0959696769714355, acc: 0.2647058963775635)
[2024-11-29 03:05:32,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:33,037][root][INFO] - Training Epoch: 2/10, step 199/574 completed (loss: 2.8193986415863037, acc: 0.3382352888584137)
[2024-11-29 03:05:33,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:33,633][root][INFO] - Training Epoch: 2/10, step 200/574 completed (loss: 2.850994110107422, acc: 0.24576270580291748)
[2024-11-29 03:05:33,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:34,230][root][INFO] - Training Epoch: 2/10, step 201/574 completed (loss: 2.900343418121338, acc: 0.24626865983009338)
[2024-11-29 03:05:34,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:34,826][root][INFO] - Training Epoch: 2/10, step 202/574 completed (loss: 2.962153196334839, acc: 0.3106796145439148)
[2024-11-29 03:05:34,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:35,425][root][INFO] - Training Epoch: 2/10, step 203/574 completed (loss: 2.77886700630188, acc: 0.3174603283405304)
[2024-11-29 03:05:35,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:36,019][root][INFO] - Training Epoch: 2/10, step 204/574 completed (loss: 2.9662320613861084, acc: 0.21978022158145905)
[2024-11-29 03:05:36,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:36,639][root][INFO] - Training Epoch: 2/10, step 205/574 completed (loss: 2.8782145977020264, acc: 0.2735426127910614)
[2024-11-29 03:05:36,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:37,265][root][INFO] - Training Epoch: 2/10, step 206/574 completed (loss: 2.910114288330078, acc: 0.27165353298187256)
[2024-11-29 03:05:37,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:37,880][root][INFO] - Training Epoch: 2/10, step 207/574 completed (loss: 2.779005289077759, acc: 0.31896552443504333)
[2024-11-29 03:05:37,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:38,495][root][INFO] - Training Epoch: 2/10, step 208/574 completed (loss: 2.618137836456299, acc: 0.3478260934352875)
[2024-11-29 03:05:38,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:39,116][root][INFO] - Training Epoch: 2/10, step 209/574 completed (loss: 2.958432197570801, acc: 0.29182878136634827)
[2024-11-29 03:05:39,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:39,734][root][INFO] - Training Epoch: 2/10, step 210/574 completed (loss: 3.0195844173431396, acc: 0.29347825050354004)
[2024-11-29 03:05:39,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:40,323][root][INFO] - Training Epoch: 2/10, step 211/574 completed (loss: 2.390493392944336, acc: 0.260869562625885)
[2024-11-29 03:05:40,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:40,914][root][INFO] - Training Epoch: 2/10, step 212/574 completed (loss: 2.7801647186279297, acc: 0.2142857164144516)
[2024-11-29 03:05:40,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:41,506][root][INFO] - Training Epoch: 2/10, step 213/574 completed (loss: 2.194704294204712, acc: 0.40425533056259155)
[2024-11-29 03:05:41,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:42,113][root][INFO] - Training Epoch: 2/10, step 214/574 completed (loss: 2.630295991897583, acc: 0.3461538553237915)
[2024-11-29 03:05:42,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:42,704][root][INFO] - Training Epoch: 2/10, step 215/574 completed (loss: 2.4464597702026367, acc: 0.3918918967247009)
[2024-11-29 03:05:42,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:43,297][root][INFO] - Training Epoch: 2/10, step 216/574 completed (loss: 2.479456663131714, acc: 0.44186046719551086)
[2024-11-29 03:05:43,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:43,893][root][INFO] - Training Epoch: 2/10, step 217/574 completed (loss: 2.4632105827331543, acc: 0.37837839126586914)
[2024-11-29 03:05:43,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:44,487][root][INFO] - Training Epoch: 2/10, step 218/574 completed (loss: 2.382054090499878, acc: 0.36666667461395264)
[2024-11-29 03:05:44,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:45,075][root][INFO] - Training Epoch: 2/10, step 219/574 completed (loss: 1.3733692169189453, acc: 0.6969696879386902)
[2024-11-29 03:05:45,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:45,663][root][INFO] - Training Epoch: 2/10, step 220/574 completed (loss: 1.2503644227981567, acc: 0.7037037014961243)
[2024-11-29 03:05:45,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:46,250][root][INFO] - Training Epoch: 2/10, step 221/574 completed (loss: 1.4578770399093628, acc: 0.5600000023841858)
[2024-11-29 03:05:46,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:46,843][root][INFO] - Training Epoch: 2/10, step 222/574 completed (loss: 2.935899019241333, acc: 0.25)
[2024-11-29 03:05:46,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:47,458][root][INFO] - Training Epoch: 2/10, step 223/574 completed (loss: 2.699625253677368, acc: 0.3586956560611725)
[2024-11-29 03:05:47,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:48,069][root][INFO] - Training Epoch: 2/10, step 224/574 completed (loss: 2.724789619445801, acc: 0.28977271914482117)
[2024-11-29 03:05:48,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:48,680][root][INFO] - Training Epoch: 2/10, step 225/574 completed (loss: 2.7411274909973145, acc: 0.28723403811454773)
[2024-11-29 03:05:48,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:49,267][root][INFO] - Training Epoch: 2/10, step 226/574 completed (loss: 2.780026912689209, acc: 0.3207547068595886)
[2024-11-29 03:05:49,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:49,858][root][INFO] - Training Epoch: 2/10, step 227/574 completed (loss: 2.4307861328125, acc: 0.4000000059604645)
[2024-11-29 03:05:49,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:50,451][root][INFO] - Training Epoch: 2/10, step 228/574 completed (loss: 1.7211101055145264, acc: 0.5581395626068115)
[2024-11-29 03:05:50,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:51,038][root][INFO] - Training Epoch: 2/10, step 229/574 completed (loss: 2.3835995197296143, acc: 0.4333333373069763)
[2024-11-29 03:05:51,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:51,636][root][INFO] - Training Epoch: 2/10, step 230/574 completed (loss: 2.9963924884796143, acc: 0.28421053290367126)
[2024-11-29 03:05:51,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:52,228][root][INFO] - Training Epoch: 2/10, step 231/574 completed (loss: 2.3721303939819336, acc: 0.36666667461395264)
[2024-11-29 03:05:52,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:52,840][root][INFO] - Training Epoch: 2/10, step 232/574 completed (loss: 2.4982597827911377, acc: 0.33888888359069824)
[2024-11-29 03:05:52,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:53,452][root][INFO] - Training Epoch: 2/10, step 233/574 completed (loss: 2.618324041366577, acc: 0.3899082541465759)
[2024-11-29 03:05:53,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:54,064][root][INFO] - Training Epoch: 2/10, step 234/574 completed (loss: 2.638267755508423, acc: 0.38461539149284363)
[2024-11-29 03:05:54,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:54,651][root][INFO] - Training Epoch: 2/10, step 235/574 completed (loss: 1.387689471244812, acc: 0.6315789222717285)
[2024-11-29 03:05:54,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:55,236][root][INFO] - Training Epoch: 2/10, step 236/574 completed (loss: 1.7908817529678345, acc: 0.5)
[2024-11-29 03:05:55,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:55,821][root][INFO] - Training Epoch: 2/10, step 237/574 completed (loss: 2.1160871982574463, acc: 0.40909090638160706)
[2024-11-29 03:05:55,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:56,408][root][INFO] - Training Epoch: 2/10, step 238/574 completed (loss: 1.9446847438812256, acc: 0.4444444477558136)
[2024-11-29 03:05:56,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:56,999][root][INFO] - Training Epoch: 2/10, step 239/574 completed (loss: 2.0057902336120605, acc: 0.48571428656578064)
[2024-11-29 03:05:57,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:57,588][root][INFO] - Training Epoch: 2/10, step 240/574 completed (loss: 2.0720956325531006, acc: 0.4318181872367859)
[2024-11-29 03:05:57,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:58,179][root][INFO] - Training Epoch: 2/10, step 241/574 completed (loss: 2.156498432159424, acc: 0.47727271914482117)
[2024-11-29 03:05:58,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:58,778][root][INFO] - Training Epoch: 2/10, step 242/574 completed (loss: 2.4321963787078857, acc: 0.3870967626571655)
[2024-11-29 03:05:58,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:59,372][root][INFO] - Training Epoch: 2/10, step 243/574 completed (loss: 2.0491647720336914, acc: 0.4545454680919647)
[2024-11-29 03:05:59,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:59,961][root][INFO] - Training Epoch: 2/10, step 244/574 completed (loss: 0.9705734252929688, acc: 0.7142857313156128)
[2024-11-29 03:06:00,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:00,550][root][INFO] - Training Epoch: 2/10, step 245/574 completed (loss: 1.9167653322219849, acc: 0.5384615659713745)
[2024-11-29 03:06:00,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:01,137][root][INFO] - Training Epoch: 2/10, step 246/574 completed (loss: 2.8379790782928467, acc: 0.25806450843811035)
[2024-11-29 03:06:01,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:01,723][root][INFO] - Training Epoch: 2/10, step 247/574 completed (loss: 1.8916069269180298, acc: 0.44999998807907104)
[2024-11-29 03:06:01,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:02,316][root][INFO] - Training Epoch: 2/10, step 248/574 completed (loss: 2.6637771129608154, acc: 0.4864864945411682)
[2024-11-29 03:06:02,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:02,903][root][INFO] - Training Epoch: 2/10, step 249/574 completed (loss: 2.151425838470459, acc: 0.4324324429035187)
[2024-11-29 03:06:02,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:03,491][root][INFO] - Training Epoch: 2/10, step 250/574 completed (loss: 2.125861644744873, acc: 0.5675675868988037)
[2024-11-29 03:06:03,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:04,087][root][INFO] - Training Epoch: 2/10, step 251/574 completed (loss: 2.822305202484131, acc: 0.30882352590560913)
[2024-11-29 03:06:04,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:04,676][root][INFO] - Training Epoch: 2/10, step 252/574 completed (loss: 1.617458462715149, acc: 0.6341463327407837)
[2024-11-29 03:06:04,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:05,264][root][INFO] - Training Epoch: 2/10, step 253/574 completed (loss: 2.173551559448242, acc: 0.5199999809265137)
[2024-11-29 03:06:05,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:05,851][root][INFO] - Training Epoch: 2/10, step 254/574 completed (loss: 1.3493256568908691, acc: 0.6000000238418579)
[2024-11-29 03:06:05,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:06,437][root][INFO] - Training Epoch: 2/10, step 255/574 completed (loss: 2.1206581592559814, acc: 0.4516128897666931)
[2024-11-29 03:06:06,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:07,029][root][INFO] - Training Epoch: 2/10, step 256/574 completed (loss: 3.1025590896606445, acc: 0.2631579041481018)
[2024-11-29 03:06:07,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:07,618][root][INFO] - Training Epoch: 2/10, step 257/574 completed (loss: 2.6968417167663574, acc: 0.3571428656578064)
[2024-11-29 03:06:07,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:08,209][root][INFO] - Training Epoch: 2/10, step 258/574 completed (loss: 2.8839235305786133, acc: 0.3947368562221527)
[2024-11-29 03:06:08,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:08,818][root][INFO] - Training Epoch: 2/10, step 259/574 completed (loss: 2.614701509475708, acc: 0.33018869161605835)
[2024-11-29 03:06:08,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:09,433][root][INFO] - Training Epoch: 2/10, step 260/574 completed (loss: 2.8321878910064697, acc: 0.375)
[2024-11-29 03:06:09,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:10,021][root][INFO] - Training Epoch: 2/10, step 261/574 completed (loss: 2.4720752239227295, acc: 0.5277777910232544)
[2024-11-29 03:06:10,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:10,611][root][INFO] - Training Epoch: 2/10, step 262/574 completed (loss: 2.317229747772217, acc: 0.4516128897666931)
[2024-11-29 03:06:10,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:11,207][root][INFO] - Training Epoch: 2/10, step 263/574 completed (loss: 3.3615331649780273, acc: 0.18666666746139526)
[2024-11-29 03:06:11,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:11,796][root][INFO] - Training Epoch: 2/10, step 264/574 completed (loss: 2.675675630569458, acc: 0.2708333432674408)
[2024-11-29 03:06:11,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:12,411][root][INFO] - Training Epoch: 2/10, step 265/574 completed (loss: 2.8429880142211914, acc: 0.2800000011920929)
[2024-11-29 03:06:12,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:13,006][root][INFO] - Training Epoch: 2/10, step 266/574 completed (loss: 2.6181695461273193, acc: 0.33707866072654724)
[2024-11-29 03:06:13,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:13,598][root][INFO] - Training Epoch: 2/10, step 267/574 completed (loss: 3.1452949047088623, acc: 0.31081080436706543)
[2024-11-29 03:06:13,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:14,192][root][INFO] - Training Epoch: 2/10, step 268/574 completed (loss: 2.2013444900512695, acc: 0.3965517282485962)
[2024-11-29 03:06:14,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:14,779][root][INFO] - Training Epoch: 2/10, step 269/574 completed (loss: 1.692741870880127, acc: 0.4545454680919647)
[2024-11-29 03:06:14,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:15,365][root][INFO] - Training Epoch: 2/10, step 270/574 completed (loss: 1.3222123384475708, acc: 0.7272727489471436)
[2024-11-29 03:06:15,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:15,951][root][INFO] - Training Epoch: 2/10, step 271/574 completed (loss: 1.669852375984192, acc: 0.625)
[2024-11-29 03:06:16,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:16,542][root][INFO] - Training Epoch: 2/10, step 272/574 completed (loss: 1.7653076648712158, acc: 0.5)
[2024-11-29 03:06:16,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:17,136][root][INFO] - Training Epoch: 2/10, step 273/574 completed (loss: 2.2203614711761475, acc: 0.4166666567325592)
[2024-11-29 03:06:17,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:17,723][root][INFO] - Training Epoch: 2/10, step 274/574 completed (loss: 1.857983112335205, acc: 0.5625)
[2024-11-29 03:06:17,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:18,313][root][INFO] - Training Epoch: 2/10, step 275/574 completed (loss: 1.9947330951690674, acc: 0.5666666626930237)
[2024-11-29 03:06:18,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:18,901][root][INFO] - Training Epoch: 2/10, step 276/574 completed (loss: 1.5838602781295776, acc: 0.7241379022598267)
[2024-11-29 03:06:18,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:19,489][root][INFO] - Training Epoch: 2/10, step 277/574 completed (loss: 1.1203216314315796, acc: 0.6800000071525574)
[2024-11-29 03:06:19,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:20,080][root][INFO] - Training Epoch: 2/10, step 278/574 completed (loss: 2.7418313026428223, acc: 0.38297873735427856)
[2024-11-29 03:06:20,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:20,670][root][INFO] - Training Epoch: 2/10, step 279/574 completed (loss: 2.475583791732788, acc: 0.3958333432674408)
[2024-11-29 03:06:20,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:21,257][root][INFO] - Training Epoch: 2/10, step 280/574 completed (loss: 2.1875765323638916, acc: 0.47727271914482117)
[2024-11-29 03:06:21,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:21,853][root][INFO] - Training Epoch: 2/10, step 281/574 completed (loss: 2.7776787281036377, acc: 0.33734938502311707)
[2024-11-29 03:06:21,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:22,447][root][INFO] - Training Epoch: 2/10, step 282/574 completed (loss: 2.8201863765716553, acc: 0.34259259700775146)
[2024-11-29 03:06:22,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:23,033][root][INFO] - Training Epoch: 2/10, step 283/574 completed (loss: 2.3544273376464844, acc: 0.44736841320991516)
[2024-11-29 03:06:23,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:24,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:24,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:25,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:25,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:26,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:26,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:27,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:27,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:28,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:29,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:29,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:30,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:30,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:31,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:31,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:32,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:32,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:33,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:33,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:34,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:34,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:35,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:35,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:36,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:36,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:37,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:37,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:38,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:39,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:39,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:40,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:40,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:41,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:41,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:42,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:42,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:43,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:43,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:44,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:44,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:45,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:45,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:46,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:46,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:47,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:47,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:48,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:49,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:49,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:50,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:50,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:51,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:51,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:52,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:52,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:53,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:53,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:54,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:54,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:55,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:55,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:56,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:56,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:57,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:57,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:58,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:59,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:59,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:00,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:00,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:01,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:01,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:02,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:02,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:03,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:03,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:04,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:04,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:05,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:05,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:06,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:06,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:07,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:08,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:08,863][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(12.1149, device='cuda:0') eval_epoch_loss=tensor(2.4944, device='cuda:0') eval_epoch_acc=tensor(0.3807, device='cuda:0')
[2024-11-29 03:07:08,864][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:07:08,864][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:07:09,165][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_2_step_284_loss_2.494434118270874/model.pt
[2024-11-29 03:07:09,171][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 2.494434118270874
[2024-11-29 03:07:09,172][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.38065090775489807
[2024-11-29 03:07:09,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:09,771][root][INFO] - Training Epoch: 2/10, step 284/574 completed (loss: 2.2664031982421875, acc: 0.5)
[2024-11-29 03:07:09,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:10,361][root][INFO] - Training Epoch: 2/10, step 285/574 completed (loss: 2.3220973014831543, acc: 0.3499999940395355)
[2024-11-29 03:07:10,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:10,957][root][INFO] - Training Epoch: 2/10, step 286/574 completed (loss: 2.685297966003418, acc: 0.328125)
[2024-11-29 03:07:11,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:11,566][root][INFO] - Training Epoch: 2/10, step 287/574 completed (loss: 3.2016241550445557, acc: 0.23199999332427979)
[2024-11-29 03:07:11,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:12,162][root][INFO] - Training Epoch: 2/10, step 288/574 completed (loss: 2.6183390617370605, acc: 0.38461539149284363)
[2024-11-29 03:07:12,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:12,758][root][INFO] - Training Epoch: 2/10, step 289/574 completed (loss: 3.002664804458618, acc: 0.22981366515159607)
[2024-11-29 03:07:12,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:13,371][root][INFO] - Training Epoch: 2/10, step 290/574 completed (loss: 2.9189658164978027, acc: 0.3298968970775604)
[2024-11-29 03:07:13,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:13,957][root][INFO] - Training Epoch: 2/10, step 291/574 completed (loss: 1.6591626405715942, acc: 0.5)
[2024-11-29 03:07:14,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:14,546][root][INFO] - Training Epoch: 2/10, step 292/574 completed (loss: 2.738598585128784, acc: 0.3571428656578064)
[2024-11-29 03:07:14,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:15,140][root][INFO] - Training Epoch: 2/10, step 293/574 completed (loss: 2.685131549835205, acc: 0.43103447556495667)
[2024-11-29 03:07:15,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:15,734][root][INFO] - Training Epoch: 2/10, step 294/574 completed (loss: 1.8729146718978882, acc: 0.581818163394928)
[2024-11-29 03:07:15,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:16,359][root][INFO] - Training Epoch: 2/10, step 295/574 completed (loss: 2.533798933029175, acc: 0.4020618498325348)
[2024-11-29 03:07:16,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:16,954][root][INFO] - Training Epoch: 2/10, step 296/574 completed (loss: 2.78964900970459, acc: 0.27586206793785095)
[2024-11-29 03:07:17,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:17,544][root][INFO] - Training Epoch: 2/10, step 297/574 completed (loss: 1.962722659111023, acc: 0.5185185074806213)
[2024-11-29 03:07:17,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:18,133][root][INFO] - Training Epoch: 2/10, step 298/574 completed (loss: 2.047264814376831, acc: 0.44736841320991516)
[2024-11-29 03:07:18,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:18,725][root][INFO] - Training Epoch: 2/10, step 299/574 completed (loss: 2.567735195159912, acc: 0.3571428656578064)
[2024-11-29 03:07:18,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:19,316][root][INFO] - Training Epoch: 2/10, step 300/574 completed (loss: 2.0124759674072266, acc: 0.53125)
[2024-11-29 03:07:19,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:19,908][root][INFO] - Training Epoch: 2/10, step 301/574 completed (loss: 2.6437530517578125, acc: 0.37735849618911743)
[2024-11-29 03:07:19,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:20,499][root][INFO] - Training Epoch: 2/10, step 302/574 completed (loss: 2.017807960510254, acc: 0.5094339847564697)
[2024-11-29 03:07:20,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:21,088][root][INFO] - Training Epoch: 2/10, step 303/574 completed (loss: 1.8350917100906372, acc: 0.5882353186607361)
[2024-11-29 03:07:21,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:21,675][root][INFO] - Training Epoch: 2/10, step 304/574 completed (loss: 2.535365581512451, acc: 0.40625)
[2024-11-29 03:07:21,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:22,269][root][INFO] - Training Epoch: 2/10, step 305/574 completed (loss: 2.306975841522217, acc: 0.49180328845977783)
[2024-11-29 03:07:22,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:22,856][root][INFO] - Training Epoch: 2/10, step 306/574 completed (loss: 1.683349370956421, acc: 0.6000000238418579)
[2024-11-29 03:07:22,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:23,441][root][INFO] - Training Epoch: 2/10, step 307/574 completed (loss: 0.45759114623069763, acc: 0.9473684430122375)
[2024-11-29 03:07:23,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:24,034][root][INFO] - Training Epoch: 2/10, step 308/574 completed (loss: 2.602797269821167, acc: 0.2753623127937317)
[2024-11-29 03:07:24,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:24,632][root][INFO] - Training Epoch: 2/10, step 309/574 completed (loss: 2.3515665531158447, acc: 0.3888888955116272)
[2024-11-29 03:07:24,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:25,226][root][INFO] - Training Epoch: 2/10, step 310/574 completed (loss: 2.4154746532440186, acc: 0.39759036898612976)
[2024-11-29 03:07:25,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:25,823][root][INFO] - Training Epoch: 2/10, step 311/574 completed (loss: 2.561429262161255, acc: 0.3461538553237915)
[2024-11-29 03:07:25,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:26,431][root][INFO] - Training Epoch: 2/10, step 312/574 completed (loss: 2.671909809112549, acc: 0.30612245202064514)
[2024-11-29 03:07:26,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:27,016][root][INFO] - Training Epoch: 2/10, step 313/574 completed (loss: 0.8304757475852966, acc: 0.7916666865348816)
[2024-11-29 03:07:27,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:27,602][root][INFO] - Training Epoch: 2/10, step 314/574 completed (loss: 1.589099407196045, acc: 0.5)
[2024-11-29 03:07:27,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:28,189][root][INFO] - Training Epoch: 2/10, step 315/574 completed (loss: 1.6749359369277954, acc: 0.5806451439857483)
[2024-11-29 03:07:28,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:28,776][root][INFO] - Training Epoch: 2/10, step 316/574 completed (loss: 2.3117480278015137, acc: 0.4516128897666931)
[2024-11-29 03:07:28,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:29,369][root][INFO] - Training Epoch: 2/10, step 317/574 completed (loss: 2.221928834915161, acc: 0.46268656849861145)
[2024-11-29 03:07:29,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:29,965][root][INFO] - Training Epoch: 2/10, step 318/574 completed (loss: 2.048867702484131, acc: 0.4711538553237915)
[2024-11-29 03:07:30,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:30,555][root][INFO] - Training Epoch: 2/10, step 319/574 completed (loss: 2.3373849391937256, acc: 0.35555556416511536)
[2024-11-29 03:07:30,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:31,146][root][INFO] - Training Epoch: 2/10, step 320/574 completed (loss: 2.246190309524536, acc: 0.4677419364452362)
[2024-11-29 03:07:31,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:31,737][root][INFO] - Training Epoch: 2/10, step 321/574 completed (loss: 1.595544457435608, acc: 0.6600000262260437)
[2024-11-29 03:07:31,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:32,324][root][INFO] - Training Epoch: 2/10, step 322/574 completed (loss: 2.420915126800537, acc: 0.37037035822868347)
[2024-11-29 03:07:32,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:32,912][root][INFO] - Training Epoch: 2/10, step 323/574 completed (loss: 3.4339494705200195, acc: 0.22857142984867096)
[2024-11-29 03:07:32,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:33,498][root][INFO] - Training Epoch: 2/10, step 324/574 completed (loss: 2.7982051372528076, acc: 0.3076923191547394)
[2024-11-29 03:07:33,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:34,089][root][INFO] - Training Epoch: 2/10, step 325/574 completed (loss: 2.9995594024658203, acc: 0.26829269528388977)
[2024-11-29 03:07:34,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:34,680][root][INFO] - Training Epoch: 2/10, step 326/574 completed (loss: 2.544110059738159, acc: 0.3684210479259491)
[2024-11-29 03:07:34,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:35,268][root][INFO] - Training Epoch: 2/10, step 327/574 completed (loss: 1.1941903829574585, acc: 0.7894737124443054)
[2024-11-29 03:07:35,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:35,854][root][INFO] - Training Epoch: 2/10, step 328/574 completed (loss: 1.2351511716842651, acc: 0.6785714030265808)
[2024-11-29 03:07:35,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:36,440][root][INFO] - Training Epoch: 2/10, step 329/574 completed (loss: 1.9888601303100586, acc: 0.5185185074806213)
[2024-11-29 03:07:36,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:37,026][root][INFO] - Training Epoch: 2/10, step 330/574 completed (loss: 1.4511175155639648, acc: 0.65625)
[2024-11-29 03:07:37,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:37,617][root][INFO] - Training Epoch: 2/10, step 331/574 completed (loss: 2.422487735748291, acc: 0.4677419364452362)
[2024-11-29 03:07:37,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:38,210][root][INFO] - Training Epoch: 2/10, step 332/574 completed (loss: 1.832745909690857, acc: 0.5087719559669495)
[2024-11-29 03:07:38,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:38,799][root][INFO] - Training Epoch: 2/10, step 333/574 completed (loss: 2.7313308715820312, acc: 0.28125)
[2024-11-29 03:07:38,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:39,385][root][INFO] - Training Epoch: 2/10, step 334/574 completed (loss: 2.0406343936920166, acc: 0.46666666865348816)
[2024-11-29 03:07:39,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:39,971][root][INFO] - Training Epoch: 2/10, step 335/574 completed (loss: 2.0390825271606445, acc: 0.42105263471603394)
[2024-11-29 03:07:40,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:40,564][root][INFO] - Training Epoch: 2/10, step 336/574 completed (loss: 2.3658716678619385, acc: 0.3799999952316284)
[2024-11-29 03:07:40,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:41,162][root][INFO] - Training Epoch: 2/10, step 337/574 completed (loss: 2.877528190612793, acc: 0.3563218414783478)
[2024-11-29 03:07:41,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:41,756][root][INFO] - Training Epoch: 2/10, step 338/574 completed (loss: 2.8721067905426025, acc: 0.3297872245311737)
[2024-11-29 03:07:41,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:42,352][root][INFO] - Training Epoch: 2/10, step 339/574 completed (loss: 2.918095350265503, acc: 0.3012048304080963)
[2024-11-29 03:07:42,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:42,939][root][INFO] - Training Epoch: 2/10, step 340/574 completed (loss: 1.973602294921875, acc: 0.5652173757553101)
[2024-11-29 03:07:43,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:43,526][root][INFO] - Training Epoch: 2/10, step 341/574 completed (loss: 2.80240797996521, acc: 0.28205129504203796)
[2024-11-29 03:07:43,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:44,118][root][INFO] - Training Epoch: 2/10, step 342/574 completed (loss: 3.0692198276519775, acc: 0.2530120611190796)
[2024-11-29 03:07:44,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:44,712][root][INFO] - Training Epoch: 2/10, step 343/574 completed (loss: 2.5667197704315186, acc: 0.3962264060974121)
[2024-11-29 03:07:44,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:45,304][root][INFO] - Training Epoch: 2/10, step 344/574 completed (loss: 2.859187126159668, acc: 0.3164556920528412)
[2024-11-29 03:07:45,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:45,897][root][INFO] - Training Epoch: 2/10, step 345/574 completed (loss: 2.4291045665740967, acc: 0.3529411852359772)
[2024-11-29 03:07:45,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:46,490][root][INFO] - Training Epoch: 2/10, step 346/574 completed (loss: 2.803889751434326, acc: 0.31343284249305725)
[2024-11-29 03:07:46,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:47,079][root][INFO] - Training Epoch: 2/10, step 347/574 completed (loss: 1.2683583498001099, acc: 0.800000011920929)
[2024-11-29 03:07:47,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:47,665][root][INFO] - Training Epoch: 2/10, step 348/574 completed (loss: 1.9860808849334717, acc: 0.5600000023841858)
[2024-11-29 03:07:47,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:48,255][root][INFO] - Training Epoch: 2/10, step 349/574 completed (loss: 1.911908507347107, acc: 0.5)
[2024-11-29 03:07:48,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:48,843][root][INFO] - Training Epoch: 2/10, step 350/574 completed (loss: 2.2965848445892334, acc: 0.39534884691238403)
[2024-11-29 03:07:48,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:49,432][root][INFO] - Training Epoch: 2/10, step 351/574 completed (loss: 2.3690884113311768, acc: 0.3589743673801422)
[2024-11-29 03:07:49,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:50,022][root][INFO] - Training Epoch: 2/10, step 352/574 completed (loss: 2.6266939640045166, acc: 0.3333333432674408)
[2024-11-29 03:07:50,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:50,610][root][INFO] - Training Epoch: 2/10, step 353/574 completed (loss: 0.7979092597961426, acc: 0.782608687877655)
[2024-11-29 03:07:50,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:51,196][root][INFO] - Training Epoch: 2/10, step 354/574 completed (loss: 2.943652868270874, acc: 0.3076923191547394)
[2024-11-29 03:07:51,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:51,789][root][INFO] - Training Epoch: 2/10, step 355/574 completed (loss: 2.7643580436706543, acc: 0.2747252881526947)
[2024-11-29 03:07:51,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:52,399][root][INFO] - Training Epoch: 2/10, step 356/574 completed (loss: 2.4290332794189453, acc: 0.40869563817977905)
[2024-11-29 03:07:52,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:52,991][root][INFO] - Training Epoch: 2/10, step 357/574 completed (loss: 2.5015242099761963, acc: 0.31521740555763245)
[2024-11-29 03:07:53,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:53,581][root][INFO] - Training Epoch: 2/10, step 358/574 completed (loss: 2.542738914489746, acc: 0.3469387888908386)
[2024-11-29 03:07:53,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:54,168][root][INFO] - Training Epoch: 2/10, step 359/574 completed (loss: 0.5009090304374695, acc: 0.8333333134651184)
[2024-11-29 03:07:54,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:54,753][root][INFO] - Training Epoch: 2/10, step 360/574 completed (loss: 1.4353479146957397, acc: 0.5384615659713745)
[2024-11-29 03:07:54,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:55,341][root][INFO] - Training Epoch: 2/10, step 361/574 completed (loss: 2.2971346378326416, acc: 0.3658536672592163)
[2024-11-29 03:07:55,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:55,930][root][INFO] - Training Epoch: 2/10, step 362/574 completed (loss: 1.9549427032470703, acc: 0.4000000059604645)
[2024-11-29 03:07:56,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:56,529][root][INFO] - Training Epoch: 2/10, step 363/574 completed (loss: 2.632302761077881, acc: 0.32894736528396606)
[2024-11-29 03:07:56,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:57,120][root][INFO] - Training Epoch: 2/10, step 364/574 completed (loss: 2.6525142192840576, acc: 0.4146341383457184)
[2024-11-29 03:07:57,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:57,710][root][INFO] - Training Epoch: 2/10, step 365/574 completed (loss: 2.3324954509735107, acc: 0.3636363744735718)
[2024-11-29 03:07:57,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:58,296][root][INFO] - Training Epoch: 2/10, step 366/574 completed (loss: 1.3489317893981934, acc: 0.6666666865348816)
[2024-11-29 03:07:58,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:58,884][root][INFO] - Training Epoch: 2/10, step 367/574 completed (loss: 1.1757588386535645, acc: 0.739130437374115)
[2024-11-29 03:07:58,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:59,470][root][INFO] - Training Epoch: 2/10, step 368/574 completed (loss: 1.5812221765518188, acc: 0.5)
[2024-11-29 03:07:59,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:00,059][root][INFO] - Training Epoch: 2/10, step 369/574 completed (loss: 2.0100042819976807, acc: 0.5)
[2024-11-29 03:08:00,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:00,674][root][INFO] - Training Epoch: 2/10, step 370/574 completed (loss: 2.89532208442688, acc: 0.3333333432674408)
[2024-11-29 03:08:00,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:01,284][root][INFO] - Training Epoch: 2/10, step 371/574 completed (loss: 2.201697826385498, acc: 0.5)
[2024-11-29 03:08:01,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:01,877][root][INFO] - Training Epoch: 2/10, step 372/574 completed (loss: 2.21063494682312, acc: 0.46666666865348816)
[2024-11-29 03:08:01,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:02,468][root][INFO] - Training Epoch: 2/10, step 373/574 completed (loss: 2.3598272800445557, acc: 0.5)
[2024-11-29 03:08:02,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:03,061][root][INFO] - Training Epoch: 2/10, step 374/574 completed (loss: 1.1735401153564453, acc: 0.6571428775787354)
[2024-11-29 03:08:03,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:03,648][root][INFO] - Training Epoch: 2/10, step 375/574 completed (loss: 2.207641839981079, acc: 0.4000000059604645)
[2024-11-29 03:08:03,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:04,234][root][INFO] - Training Epoch: 2/10, step 376/574 completed (loss: 1.047083854675293, acc: 0.695652186870575)
[2024-11-29 03:08:04,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:04,824][root][INFO] - Training Epoch: 2/10, step 377/574 completed (loss: 2.534797430038452, acc: 0.3958333432674408)
[2024-11-29 03:08:04,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:05,419][root][INFO] - Training Epoch: 2/10, step 378/574 completed (loss: 2.5391275882720947, acc: 0.4000000059604645)
[2024-11-29 03:08:05,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:06,029][root][INFO] - Training Epoch: 2/10, step 379/574 completed (loss: 2.398530960083008, acc: 0.4071856141090393)
[2024-11-29 03:08:06,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:06,624][root][INFO] - Training Epoch: 2/10, step 380/574 completed (loss: 2.2648141384124756, acc: 0.4285714328289032)
[2024-11-29 03:08:06,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:07,243][root][INFO] - Training Epoch: 2/10, step 381/574 completed (loss: 2.4986934661865234, acc: 0.4064171016216278)
[2024-11-29 03:08:07,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:07,854][root][INFO] - Training Epoch: 2/10, step 382/574 completed (loss: 2.2227938175201416, acc: 0.4864864945411682)
[2024-11-29 03:08:07,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:08,439][root][INFO] - Training Epoch: 2/10, step 383/574 completed (loss: 2.1745691299438477, acc: 0.4285714328289032)
[2024-11-29 03:08:08,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:09,024][root][INFO] - Training Epoch: 2/10, step 384/574 completed (loss: 2.25675892829895, acc: 0.3571428656578064)
[2024-11-29 03:08:09,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:09,609][root][INFO] - Training Epoch: 2/10, step 385/574 completed (loss: 2.8032705783843994, acc: 0.25)
[2024-11-29 03:08:09,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:10,201][root][INFO] - Training Epoch: 2/10, step 386/574 completed (loss: 2.863886833190918, acc: 0.3611111044883728)
[2024-11-29 03:08:10,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:10,790][root][INFO] - Training Epoch: 2/10, step 387/574 completed (loss: 2.085705041885376, acc: 0.5263158082962036)
[2024-11-29 03:08:10,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:11,375][root][INFO] - Training Epoch: 2/10, step 388/574 completed (loss: 1.4154434204101562, acc: 0.6363636255264282)
[2024-11-29 03:08:11,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:11,960][root][INFO] - Training Epoch: 2/10, step 389/574 completed (loss: 1.6368465423583984, acc: 0.44999998807907104)
[2024-11-29 03:08:12,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:12,546][root][INFO] - Training Epoch: 2/10, step 390/574 completed (loss: 1.6828720569610596, acc: 0.4285714328289032)
[2024-11-29 03:08:12,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:13,134][root][INFO] - Training Epoch: 2/10, step 391/574 completed (loss: 2.644770383834839, acc: 0.4444444477558136)
[2024-11-29 03:08:13,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:13,729][root][INFO] - Training Epoch: 2/10, step 392/574 completed (loss: 3.0342822074890137, acc: 0.27184465527534485)
[2024-11-29 03:08:13,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:14,346][root][INFO] - Training Epoch: 2/10, step 393/574 completed (loss: 2.853821039199829, acc: 0.3235294222831726)
[2024-11-29 03:08:14,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:14,947][root][INFO] - Training Epoch: 2/10, step 394/574 completed (loss: 3.016113519668579, acc: 0.23333333432674408)
[2024-11-29 03:08:15,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:15,544][root][INFO] - Training Epoch: 2/10, step 395/574 completed (loss: 2.712153434753418, acc: 0.3333333432674408)
[2024-11-29 03:08:15,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:16,133][root][INFO] - Training Epoch: 2/10, step 396/574 completed (loss: 2.460191011428833, acc: 0.41860464215278625)
[2024-11-29 03:08:16,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:16,722][root][INFO] - Training Epoch: 2/10, step 397/574 completed (loss: 1.512031078338623, acc: 0.6666666865348816)
[2024-11-29 03:08:16,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:17,311][root][INFO] - Training Epoch: 2/10, step 398/574 completed (loss: 2.3584837913513184, acc: 0.3488371968269348)
[2024-11-29 03:08:17,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:17,898][root][INFO] - Training Epoch: 2/10, step 399/574 completed (loss: 1.9602068662643433, acc: 0.5199999809265137)
[2024-11-29 03:08:17,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:18,493][root][INFO] - Training Epoch: 2/10, step 400/574 completed (loss: 2.240978240966797, acc: 0.4117647111415863)
[2024-11-29 03:08:18,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:19,086][root][INFO] - Training Epoch: 2/10, step 401/574 completed (loss: 2.4166975021362305, acc: 0.4000000059604645)
[2024-11-29 03:08:19,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:19,674][root][INFO] - Training Epoch: 2/10, step 402/574 completed (loss: 1.4627326726913452, acc: 0.6363636255264282)
[2024-11-29 03:08:19,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:20,262][root][INFO] - Training Epoch: 2/10, step 403/574 completed (loss: 1.9235172271728516, acc: 0.6363636255264282)
[2024-11-29 03:08:20,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:20,848][root][INFO] - Training Epoch: 2/10, step 404/574 completed (loss: 1.6118031740188599, acc: 0.5161290168762207)
[2024-11-29 03:08:20,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:21,437][root][INFO] - Training Epoch: 2/10, step 405/574 completed (loss: 1.5565946102142334, acc: 0.6296296119689941)
[2024-11-29 03:08:21,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:22,024][root][INFO] - Training Epoch: 2/10, step 406/574 completed (loss: 1.380030870437622, acc: 0.7200000286102295)
[2024-11-29 03:08:22,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:22,610][root][INFO] - Training Epoch: 2/10, step 407/574 completed (loss: 1.3418406248092651, acc: 0.6388888955116272)
[2024-11-29 03:08:22,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:23,197][root][INFO] - Training Epoch: 2/10, step 408/574 completed (loss: 1.4212629795074463, acc: 0.7407407164573669)
[2024-11-29 03:08:23,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:23,784][root][INFO] - Training Epoch: 2/10, step 409/574 completed (loss: 1.4468028545379639, acc: 0.6153846383094788)
[2024-11-29 03:08:23,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:24,375][root][INFO] - Training Epoch: 2/10, step 410/574 completed (loss: 1.9770716428756714, acc: 0.5862069129943848)
[2024-11-29 03:08:24,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:24,963][root][INFO] - Training Epoch: 2/10, step 411/574 completed (loss: 1.5919826030731201, acc: 0.5357142686843872)
[2024-11-29 03:08:25,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:25,551][root][INFO] - Training Epoch: 2/10, step 412/574 completed (loss: 1.302619218826294, acc: 0.6333333253860474)
[2024-11-29 03:08:25,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:26,138][root][INFO] - Training Epoch: 2/10, step 413/574 completed (loss: 1.7520073652267456, acc: 0.5757575631141663)
[2024-11-29 03:08:26,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:26,726][root][INFO] - Training Epoch: 2/10, step 414/574 completed (loss: 1.8857449293136597, acc: 0.3636363744735718)
[2024-11-29 03:08:26,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:27,317][root][INFO] - Training Epoch: 2/10, step 415/574 completed (loss: 2.5427026748657227, acc: 0.47058823704719543)
[2024-11-29 03:08:27,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:27,905][root][INFO] - Training Epoch: 2/10, step 416/574 completed (loss: 2.148484945297241, acc: 0.42307692766189575)
[2024-11-29 03:08:27,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:28,491][root][INFO] - Training Epoch: 2/10, step 417/574 completed (loss: 1.4653162956237793, acc: 0.6111111044883728)
[2024-11-29 03:08:28,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:29,081][root][INFO] - Training Epoch: 2/10, step 418/574 completed (loss: 2.0365793704986572, acc: 0.550000011920929)
[2024-11-29 03:08:29,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:29,669][root][INFO] - Training Epoch: 2/10, step 419/574 completed (loss: 2.172318696975708, acc: 0.4000000059604645)
[2024-11-29 03:08:29,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:30,258][root][INFO] - Training Epoch: 2/10, step 420/574 completed (loss: 0.45629459619522095, acc: 0.8095238208770752)
[2024-11-29 03:08:30,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:30,844][root][INFO] - Training Epoch: 2/10, step 421/574 completed (loss: 1.4177014827728271, acc: 0.6000000238418579)
[2024-11-29 03:08:30,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:31,430][root][INFO] - Training Epoch: 2/10, step 422/574 completed (loss: 1.5634390115737915, acc: 0.5625)
[2024-11-29 03:08:31,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:32,018][root][INFO] - Training Epoch: 2/10, step 423/574 completed (loss: 2.2737019062042236, acc: 0.4722222089767456)
[2024-11-29 03:08:32,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:32,604][root][INFO] - Training Epoch: 2/10, step 424/574 completed (loss: 1.6125609874725342, acc: 0.7037037014961243)
[2024-11-29 03:08:32,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:33,192][root][INFO] - Training Epoch: 2/10, step 425/574 completed (loss: 1.0821911096572876, acc: 0.6363636255264282)
[2024-11-29 03:08:33,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:33,778][root][INFO] - Training Epoch: 2/10, step 426/574 completed (loss: 1.2203874588012695, acc: 0.6086956262588501)
[2024-11-29 03:08:34,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:35,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:35,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:36,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:36,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:37,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:37,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:38,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:38,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:39,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:39,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:40,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:40,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:41,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:41,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:42,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:43,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:43,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:44,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:44,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:45,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:45,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:46,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:46,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:47,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:47,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:48,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:49,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:49,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:50,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:50,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:51,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:51,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:52,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:52,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:53,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:53,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:54,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:54,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:55,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:55,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:56,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:57,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:57,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:58,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:58,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:59,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:59,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:00,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:00,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:01,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:01,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:02,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:02,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:03,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:03,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:04,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:05,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:05,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:06,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:06,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:07,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:07,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:08,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:08,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:09,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:09,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:10,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:10,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:11,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:11,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:12,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:12,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:13,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:14,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:14,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:15,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:15,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:16,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:16,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:17,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:17,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:18,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:18,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:19,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:20,109][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(10.1254, device='cuda:0') eval_epoch_loss=tensor(2.3151, device='cuda:0') eval_epoch_acc=tensor(0.4500, device='cuda:0')
[2024-11-29 03:09:20,110][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:09:20,111][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:09:20,343][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_2_step_427_loss_2.3150501251220703/model.pt
[2024-11-29 03:09:20,346][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 2.3150501251220703
[2024-11-29 03:09:20,346][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.44998520612716675
[2024-11-29 03:09:20,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:20,955][root][INFO] - Training Epoch: 2/10, step 427/574 completed (loss: 1.3585788011550903, acc: 0.6486486196517944)
[2024-11-29 03:09:21,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:21,542][root][INFO] - Training Epoch: 2/10, step 428/574 completed (loss: 1.5741846561431885, acc: 0.5925925970077515)
[2024-11-29 03:09:21,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:22,130][root][INFO] - Training Epoch: 2/10, step 429/574 completed (loss: 0.9856398105621338, acc: 0.695652186870575)
[2024-11-29 03:09:22,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:22,718][root][INFO] - Training Epoch: 2/10, step 430/574 completed (loss: 0.836231529712677, acc: 0.7407407164573669)
[2024-11-29 03:09:22,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:23,306][root][INFO] - Training Epoch: 2/10, step 431/574 completed (loss: 0.7931075692176819, acc: 0.7407407164573669)
[2024-11-29 03:09:23,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:23,893][root][INFO] - Training Epoch: 2/10, step 432/574 completed (loss: 1.881779432296753, acc: 0.47826087474823)
[2024-11-29 03:09:23,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:24,482][root][INFO] - Training Epoch: 2/10, step 433/574 completed (loss: 1.9243119955062866, acc: 0.5)
[2024-11-29 03:09:24,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:25,069][root][INFO] - Training Epoch: 2/10, step 434/574 completed (loss: 0.47584548592567444, acc: 0.8799999952316284)
[2024-11-29 03:09:25,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:25,657][root][INFO] - Training Epoch: 2/10, step 435/574 completed (loss: 1.475325345993042, acc: 0.5454545617103577)
[2024-11-29 03:09:25,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:26,246][root][INFO] - Training Epoch: 2/10, step 436/574 completed (loss: 1.4581974744796753, acc: 0.6388888955116272)
[2024-11-29 03:09:26,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:26,837][root][INFO] - Training Epoch: 2/10, step 437/574 completed (loss: 1.9452049732208252, acc: 0.5909090638160706)
[2024-11-29 03:09:26,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:27,422][root][INFO] - Training Epoch: 2/10, step 438/574 completed (loss: 0.4290142059326172, acc: 0.9047619104385376)
[2024-11-29 03:09:27,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:28,014][root][INFO] - Training Epoch: 2/10, step 439/574 completed (loss: 2.113626718521118, acc: 0.5384615659713745)
[2024-11-29 03:09:28,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:28,609][root][INFO] - Training Epoch: 2/10, step 440/574 completed (loss: 2.263400077819824, acc: 0.43939393758773804)
[2024-11-29 03:09:28,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:29,220][root][INFO] - Training Epoch: 2/10, step 441/574 completed (loss: 3.1342549324035645, acc: 0.29600000381469727)
[2024-11-29 03:09:29,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:29,817][root][INFO] - Training Epoch: 2/10, step 442/574 completed (loss: 2.559793710708618, acc: 0.39516130089759827)
[2024-11-29 03:09:29,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:30,428][root][INFO] - Training Epoch: 2/10, step 443/574 completed (loss: 2.7409937381744385, acc: 0.27363184094429016)
[2024-11-29 03:09:30,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:31,019][root][INFO] - Training Epoch: 2/10, step 444/574 completed (loss: 2.609269618988037, acc: 0.37735849618911743)
[2024-11-29 03:09:31,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:31,611][root][INFO] - Training Epoch: 2/10, step 445/574 completed (loss: 1.8287529945373535, acc: 0.5)
[2024-11-29 03:09:31,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:32,196][root][INFO] - Training Epoch: 2/10, step 446/574 completed (loss: 0.8906316161155701, acc: 0.695652186870575)
[2024-11-29 03:09:32,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:32,783][root][INFO] - Training Epoch: 2/10, step 447/574 completed (loss: 1.4528247117996216, acc: 0.5769230723381042)
[2024-11-29 03:09:32,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:33,371][root][INFO] - Training Epoch: 2/10, step 448/574 completed (loss: 1.4903333187103271, acc: 0.5357142686843872)
[2024-11-29 03:09:33,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:33,961][root][INFO] - Training Epoch: 2/10, step 449/574 completed (loss: 2.9211246967315674, acc: 0.38805970549583435)
[2024-11-29 03:09:34,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:34,552][root][INFO] - Training Epoch: 2/10, step 450/574 completed (loss: 2.4099600315093994, acc: 0.4305555522441864)
[2024-11-29 03:09:34,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:35,144][root][INFO] - Training Epoch: 2/10, step 451/574 completed (loss: 2.9337728023529053, acc: 0.29347825050354004)
[2024-11-29 03:09:35,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:35,735][root][INFO] - Training Epoch: 2/10, step 452/574 completed (loss: 2.89337420463562, acc: 0.3076923191547394)
[2024-11-29 03:09:35,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:36,328][root][INFO] - Training Epoch: 2/10, step 453/574 completed (loss: 2.861042022705078, acc: 0.34210526943206787)
[2024-11-29 03:09:36,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:36,917][root][INFO] - Training Epoch: 2/10, step 454/574 completed (loss: 2.0408618450164795, acc: 0.4897959232330322)
[2024-11-29 03:09:36,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:37,504][root][INFO] - Training Epoch: 2/10, step 455/574 completed (loss: 1.6698548793792725, acc: 0.5757575631141663)
[2024-11-29 03:09:37,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:38,100][root][INFO] - Training Epoch: 2/10, step 456/574 completed (loss: 2.4050025939941406, acc: 0.30927833914756775)
[2024-11-29 03:09:38,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:38,693][root][INFO] - Training Epoch: 2/10, step 457/574 completed (loss: 2.3801231384277344, acc: 0.37142857909202576)
[2024-11-29 03:09:38,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:39,311][root][INFO] - Training Epoch: 2/10, step 458/574 completed (loss: 2.774726390838623, acc: 0.29651162028312683)
[2024-11-29 03:09:39,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:39,902][root][INFO] - Training Epoch: 2/10, step 459/574 completed (loss: 2.639577865600586, acc: 0.2857142984867096)
[2024-11-29 03:09:39,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:40,498][root][INFO] - Training Epoch: 2/10, step 460/574 completed (loss: 2.508105516433716, acc: 0.34567901492118835)
[2024-11-29 03:09:40,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:41,087][root][INFO] - Training Epoch: 2/10, step 461/574 completed (loss: 1.435469388961792, acc: 0.6666666865348816)
[2024-11-29 03:09:41,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:41,674][root][INFO] - Training Epoch: 2/10, step 462/574 completed (loss: 1.750794529914856, acc: 0.59375)
[2024-11-29 03:09:41,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:42,261][root][INFO] - Training Epoch: 2/10, step 463/574 completed (loss: 1.486195683479309, acc: 0.5384615659713745)
[2024-11-29 03:09:42,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:42,853][root][INFO] - Training Epoch: 2/10, step 464/574 completed (loss: 2.4024159908294678, acc: 0.30434781312942505)
[2024-11-29 03:09:42,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:43,445][root][INFO] - Training Epoch: 2/10, step 465/574 completed (loss: 2.6395585536956787, acc: 0.3095238208770752)
[2024-11-29 03:09:43,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:44,039][root][INFO] - Training Epoch: 2/10, step 466/574 completed (loss: 2.5430848598480225, acc: 0.33734938502311707)
[2024-11-29 03:09:44,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:44,651][root][INFO] - Training Epoch: 2/10, step 467/574 completed (loss: 2.553440570831299, acc: 0.37837839126586914)
[2024-11-29 03:09:44,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:45,247][root][INFO] - Training Epoch: 2/10, step 468/574 completed (loss: 2.7174582481384277, acc: 0.3689320385456085)
[2024-11-29 03:09:45,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:45,860][root][INFO] - Training Epoch: 2/10, step 469/574 completed (loss: 2.588390827178955, acc: 0.3414634168148041)
[2024-11-29 03:09:45,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:46,447][root][INFO] - Training Epoch: 2/10, step 470/574 completed (loss: 1.596831202507019, acc: 0.5833333134651184)
[2024-11-29 03:09:46,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:47,035][root][INFO] - Training Epoch: 2/10, step 471/574 completed (loss: 2.1256062984466553, acc: 0.3928571343421936)
[2024-11-29 03:09:47,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:47,650][root][INFO] - Training Epoch: 2/10, step 472/574 completed (loss: 2.526815414428711, acc: 0.38235294818878174)
[2024-11-29 03:09:47,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:48,264][root][INFO] - Training Epoch: 2/10, step 473/574 completed (loss: 2.771433115005493, acc: 0.3449781537055969)
[2024-11-29 03:09:48,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:48,858][root][INFO] - Training Epoch: 2/10, step 474/574 completed (loss: 2.4435884952545166, acc: 0.375)
[2024-11-29 03:09:48,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:49,456][root][INFO] - Training Epoch: 2/10, step 475/574 completed (loss: 2.5333263874053955, acc: 0.3680981695652008)
[2024-11-29 03:09:49,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:50,052][root][INFO] - Training Epoch: 2/10, step 476/574 completed (loss: 2.7638142108917236, acc: 0.32374101877212524)
[2024-11-29 03:09:50,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:50,663][root][INFO] - Training Epoch: 2/10, step 477/574 completed (loss: 2.736903429031372, acc: 0.34170854091644287)
[2024-11-29 03:09:50,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:51,254][root][INFO] - Training Epoch: 2/10, step 478/574 completed (loss: 1.7447404861450195, acc: 0.4722222089767456)
[2024-11-29 03:09:51,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:51,841][root][INFO] - Training Epoch: 2/10, step 479/574 completed (loss: 1.507192611694336, acc: 0.6666666865348816)
[2024-11-29 03:09:51,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:52,429][root][INFO] - Training Epoch: 2/10, step 480/574 completed (loss: 1.4638714790344238, acc: 0.6666666865348816)
[2024-11-29 03:09:52,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:53,016][root][INFO] - Training Epoch: 2/10, step 481/574 completed (loss: 1.6716148853302002, acc: 0.6000000238418579)
[2024-11-29 03:09:53,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:53,604][root][INFO] - Training Epoch: 2/10, step 482/574 completed (loss: 1.1449944972991943, acc: 0.699999988079071)
[2024-11-29 03:09:53,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:54,200][root][INFO] - Training Epoch: 2/10, step 483/574 completed (loss: 2.0834295749664307, acc: 0.4655172526836395)
[2024-11-29 03:09:54,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:54,787][root][INFO] - Training Epoch: 2/10, step 484/574 completed (loss: 1.5401536226272583, acc: 0.7419354915618896)
[2024-11-29 03:09:54,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:55,379][root][INFO] - Training Epoch: 2/10, step 485/574 completed (loss: 1.2652058601379395, acc: 0.6842105388641357)
[2024-11-29 03:09:55,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:55,967][root][INFO] - Training Epoch: 2/10, step 486/574 completed (loss: 2.6052021980285645, acc: 0.3333333432674408)
[2024-11-29 03:09:56,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:56,557][root][INFO] - Training Epoch: 2/10, step 487/574 completed (loss: 2.4513652324676514, acc: 0.380952388048172)
[2024-11-29 03:09:56,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:57,144][root][INFO] - Training Epoch: 2/10, step 488/574 completed (loss: 2.056981086730957, acc: 0.5)
[2024-11-29 03:09:57,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:57,738][root][INFO] - Training Epoch: 2/10, step 489/574 completed (loss: 2.1944069862365723, acc: 0.38461539149284363)
[2024-11-29 03:09:57,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:58,325][root][INFO] - Training Epoch: 2/10, step 490/574 completed (loss: 1.807812213897705, acc: 0.5)
[2024-11-29 03:09:58,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:58,913][root][INFO] - Training Epoch: 2/10, step 491/574 completed (loss: 1.9534533023834229, acc: 0.517241358757019)
[2024-11-29 03:09:58,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:59,503][root][INFO] - Training Epoch: 2/10, step 492/574 completed (loss: 2.58567476272583, acc: 0.3333333432674408)
[2024-11-29 03:09:59,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:00,092][root][INFO] - Training Epoch: 2/10, step 493/574 completed (loss: 1.827046513557434, acc: 0.5862069129943848)
[2024-11-29 03:10:00,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:00,679][root][INFO] - Training Epoch: 2/10, step 494/574 completed (loss: 0.7979881167411804, acc: 0.8421052694320679)
[2024-11-29 03:10:00,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:01,267][root][INFO] - Training Epoch: 2/10, step 495/574 completed (loss: 2.6367764472961426, acc: 0.31578946113586426)
[2024-11-29 03:10:01,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:01,864][root][INFO] - Training Epoch: 2/10, step 496/574 completed (loss: 2.706338882446289, acc: 0.2946428656578064)
[2024-11-29 03:10:01,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:02,459][root][INFO] - Training Epoch: 2/10, step 497/574 completed (loss: 2.479099988937378, acc: 0.3820224702358246)
[2024-11-29 03:10:02,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:03,053][root][INFO] - Training Epoch: 2/10, step 498/574 completed (loss: 2.7096352577209473, acc: 0.3258427083492279)
[2024-11-29 03:10:03,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:03,660][root][INFO] - Training Epoch: 2/10, step 499/574 completed (loss: 2.809825897216797, acc: 0.3120567500591278)
[2024-11-29 03:10:03,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:04,256][root][INFO] - Training Epoch: 2/10, step 500/574 completed (loss: 2.5746138095855713, acc: 0.30434781312942505)
[2024-11-29 03:10:04,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:04,843][root][INFO] - Training Epoch: 2/10, step 501/574 completed (loss: 0.8970745801925659, acc: 0.8399999737739563)
[2024-11-29 03:10:04,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:05,431][root][INFO] - Training Epoch: 2/10, step 502/574 completed (loss: 1.0335416793823242, acc: 0.7692307829856873)
[2024-11-29 03:10:05,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:06,018][root][INFO] - Training Epoch: 2/10, step 503/574 completed (loss: 1.0705865621566772, acc: 0.7777777910232544)
[2024-11-29 03:10:06,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:06,608][root][INFO] - Training Epoch: 2/10, step 504/574 completed (loss: 1.9900037050247192, acc: 0.37037035822868347)
[2024-11-29 03:10:06,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:07,199][root][INFO] - Training Epoch: 2/10, step 505/574 completed (loss: 1.8976467847824097, acc: 0.5094339847564697)
[2024-11-29 03:10:07,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:07,784][root][INFO] - Training Epoch: 2/10, step 506/574 completed (loss: 1.3184977769851685, acc: 0.6551724076271057)
[2024-11-29 03:10:07,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:08,381][root][INFO] - Training Epoch: 2/10, step 507/574 completed (loss: 2.516836643218994, acc: 0.37837839126586914)
[2024-11-29 03:10:08,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:08,977][root][INFO] - Training Epoch: 2/10, step 508/574 completed (loss: 2.326061725616455, acc: 0.43661972880363464)
[2024-11-29 03:10:09,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:09,563][root][INFO] - Training Epoch: 2/10, step 509/574 completed (loss: 0.20364272594451904, acc: 0.949999988079071)
[2024-11-29 03:10:09,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:10,151][root][INFO] - Training Epoch: 2/10, step 510/574 completed (loss: 0.786735475063324, acc: 0.7333333492279053)
[2024-11-29 03:10:10,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:10,739][root][INFO] - Training Epoch: 2/10, step 511/574 completed (loss: 1.4895153045654297, acc: 0.6153846383094788)
[2024-11-29 03:10:10,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:11,373][root][INFO] - Training Epoch: 2/10, step 512/574 completed (loss: 2.723001003265381, acc: 0.37857142090797424)
[2024-11-29 03:10:11,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:11,985][root][INFO] - Training Epoch: 2/10, step 513/574 completed (loss: 2.8296046257019043, acc: 0.3333333432674408)
[2024-11-29 03:10:12,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:12,570][root][INFO] - Training Epoch: 2/10, step 514/574 completed (loss: 1.899893879890442, acc: 0.5714285969734192)
[2024-11-29 03:10:12,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:13,163][root][INFO] - Training Epoch: 2/10, step 515/574 completed (loss: 2.1296725273132324, acc: 0.4166666567325592)
[2024-11-29 03:10:13,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:13,760][root][INFO] - Training Epoch: 2/10, step 516/574 completed (loss: 2.7619993686676025, acc: 0.4583333432674408)
[2024-11-29 03:10:13,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:14,346][root][INFO] - Training Epoch: 2/10, step 517/574 completed (loss: 1.5334086418151855, acc: 0.5769230723381042)
[2024-11-29 03:10:14,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:14,934][root][INFO] - Training Epoch: 2/10, step 518/574 completed (loss: 2.4992237091064453, acc: 0.5161290168762207)
[2024-11-29 03:10:15,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:15,514][root][INFO] - Training Epoch: 2/10, step 519/574 completed (loss: 1.6971781253814697, acc: 0.5)
[2024-11-29 03:10:15,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:16,102][root][INFO] - Training Epoch: 2/10, step 520/574 completed (loss: 1.9631688594818115, acc: 0.48148149251937866)
[2024-11-29 03:10:16,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:16,808][root][INFO] - Training Epoch: 2/10, step 521/574 completed (loss: 2.8248465061187744, acc: 0.3093220293521881)
[2024-11-29 03:10:16,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:17,434][root][INFO] - Training Epoch: 2/10, step 522/574 completed (loss: 2.5295891761779785, acc: 0.41044774651527405)
[2024-11-29 03:10:17,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:18,028][root][INFO] - Training Epoch: 2/10, step 523/574 completed (loss: 2.6591436862945557, acc: 0.38686132431030273)
[2024-11-29 03:10:18,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:18,647][root][INFO] - Training Epoch: 2/10, step 524/574 completed (loss: 2.4288556575775146, acc: 0.4350000023841858)
[2024-11-29 03:10:18,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:19,237][root][INFO] - Training Epoch: 2/10, step 525/574 completed (loss: 2.845961332321167, acc: 0.29629629850387573)
[2024-11-29 03:10:19,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:19,829][root][INFO] - Training Epoch: 2/10, step 526/574 completed (loss: 2.028287649154663, acc: 0.48076921701431274)
[2024-11-29 03:10:19,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:20,415][root][INFO] - Training Epoch: 2/10, step 527/574 completed (loss: 1.9925203323364258, acc: 0.4761904776096344)
[2024-11-29 03:10:20,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:21,013][root][INFO] - Training Epoch: 2/10, step 528/574 completed (loss: 2.775683879852295, acc: 0.21311475336551666)
[2024-11-29 03:10:21,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:21,603][root][INFO] - Training Epoch: 2/10, step 529/574 completed (loss: 2.374631643295288, acc: 0.4067796468734741)
[2024-11-29 03:10:21,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:22,191][root][INFO] - Training Epoch: 2/10, step 530/574 completed (loss: 2.466151714324951, acc: 0.39534884691238403)
[2024-11-29 03:10:22,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:22,778][root][INFO] - Training Epoch: 2/10, step 531/574 completed (loss: 2.7107584476470947, acc: 0.3636363744735718)
[2024-11-29 03:10:22,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:23,371][root][INFO] - Training Epoch: 2/10, step 532/574 completed (loss: 2.6087474822998047, acc: 0.3396226465702057)
[2024-11-29 03:10:23,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:23,959][root][INFO] - Training Epoch: 2/10, step 533/574 completed (loss: 2.449713706970215, acc: 0.4318181872367859)
[2024-11-29 03:10:24,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:24,546][root][INFO] - Training Epoch: 2/10, step 534/574 completed (loss: 1.4140162467956543, acc: 0.7200000286102295)
[2024-11-29 03:10:24,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:25,134][root][INFO] - Training Epoch: 2/10, step 535/574 completed (loss: 1.5489753484725952, acc: 0.6000000238418579)
[2024-11-29 03:10:25,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:25,720][root][INFO] - Training Epoch: 2/10, step 536/574 completed (loss: 1.2657266855239868, acc: 0.6363636255264282)
[2024-11-29 03:10:25,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:26,313][root][INFO] - Training Epoch: 2/10, step 537/574 completed (loss: 2.11899733543396, acc: 0.5230769515037537)
[2024-11-29 03:10:26,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:26,905][root][INFO] - Training Epoch: 2/10, step 538/574 completed (loss: 2.3704304695129395, acc: 0.46875)
[2024-11-29 03:10:26,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:27,491][root][INFO] - Training Epoch: 2/10, step 539/574 completed (loss: 1.7301726341247559, acc: 0.59375)
[2024-11-29 03:10:27,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:28,080][root][INFO] - Training Epoch: 2/10, step 540/574 completed (loss: 2.3731300830841064, acc: 0.4545454680919647)
[2024-11-29 03:10:28,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:28,667][root][INFO] - Training Epoch: 2/10, step 541/574 completed (loss: 0.8446227312088013, acc: 0.75)
[2024-11-29 03:10:28,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:29,257][root][INFO] - Training Epoch: 2/10, step 542/574 completed (loss: 1.072513222694397, acc: 0.6451612710952759)
[2024-11-29 03:10:29,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:29,845][root][INFO] - Training Epoch: 2/10, step 543/574 completed (loss: 0.44195714592933655, acc: 0.95652174949646)
[2024-11-29 03:10:29,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:30,436][root][INFO] - Training Epoch: 2/10, step 544/574 completed (loss: 1.3357881307601929, acc: 0.699999988079071)
[2024-11-29 03:10:30,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:31,027][root][INFO] - Training Epoch: 2/10, step 545/574 completed (loss: 2.4693639278411865, acc: 0.4146341383457184)
[2024-11-29 03:10:31,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:31,618][root][INFO] - Training Epoch: 2/10, step 546/574 completed (loss: 1.602463960647583, acc: 0.48571428656578064)
[2024-11-29 03:10:31,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:32,207][root][INFO] - Training Epoch: 2/10, step 547/574 completed (loss: 1.8286411762237549, acc: 0.6052631735801697)
[2024-11-29 03:10:32,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:32,794][root][INFO] - Training Epoch: 2/10, step 548/574 completed (loss: 1.4007501602172852, acc: 0.6451612710952759)
[2024-11-29 03:10:32,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:33,382][root][INFO] - Training Epoch: 2/10, step 549/574 completed (loss: 0.8264225125312805, acc: 0.8399999737739563)
[2024-11-29 03:10:33,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:33,975][root][INFO] - Training Epoch: 2/10, step 550/574 completed (loss: 1.2105783224105835, acc: 0.5454545617103577)
[2024-11-29 03:10:34,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:34,567][root][INFO] - Training Epoch: 2/10, step 551/574 completed (loss: 1.6008307933807373, acc: 0.574999988079071)
[2024-11-29 03:10:34,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:35,160][root][INFO] - Training Epoch: 2/10, step 552/574 completed (loss: 2.1190757751464844, acc: 0.3857142925262451)
[2024-11-29 03:10:35,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:35,770][root][INFO] - Training Epoch: 2/10, step 553/574 completed (loss: 2.913069009780884, acc: 0.24817518889904022)
[2024-11-29 03:10:35,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:36,380][root][INFO] - Training Epoch: 2/10, step 554/574 completed (loss: 2.341615915298462, acc: 0.3931034505367279)
[2024-11-29 03:10:36,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:36,981][root][INFO] - Training Epoch: 2/10, step 555/574 completed (loss: 2.9074087142944336, acc: 0.2571428716182709)
[2024-11-29 03:10:37,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:37,581][root][INFO] - Training Epoch: 2/10, step 556/574 completed (loss: 2.961895227432251, acc: 0.21192052960395813)
[2024-11-29 03:10:37,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:38,176][root][INFO] - Training Epoch: 2/10, step 557/574 completed (loss: 2.6975085735321045, acc: 0.3076923191547394)
[2024-11-29 03:10:38,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:38,763][root][INFO] - Training Epoch: 2/10, step 558/574 completed (loss: 0.8273250460624695, acc: 0.800000011920929)
[2024-11-29 03:10:38,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:39,351][root][INFO] - Training Epoch: 2/10, step 559/574 completed (loss: 1.3421069383621216, acc: 0.5769230723381042)
[2024-11-29 03:10:39,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:39,942][root][INFO] - Training Epoch: 2/10, step 560/574 completed (loss: 1.1458015441894531, acc: 0.692307710647583)
[2024-11-29 03:10:40,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:40,535][root][INFO] - Training Epoch: 2/10, step 561/574 completed (loss: 2.194101333618164, acc: 0.5128205418586731)
[2024-11-29 03:10:40,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:41,142][root][INFO] - Training Epoch: 2/10, step 562/574 completed (loss: 2.267305850982666, acc: 0.4000000059604645)
[2024-11-29 03:10:41,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:41,732][root][INFO] - Training Epoch: 2/10, step 563/574 completed (loss: 2.388866662979126, acc: 0.350649356842041)
[2024-11-29 03:10:41,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:42,321][root][INFO] - Training Epoch: 2/10, step 564/574 completed (loss: 2.1497695446014404, acc: 0.4583333432674408)
[2024-11-29 03:10:42,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:42,917][root][INFO] - Training Epoch: 2/10, step 565/574 completed (loss: 2.425579786300659, acc: 0.43103447556495667)
[2024-11-29 03:10:42,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:43,516][root][INFO] - Training Epoch: 2/10, step 566/574 completed (loss: 2.3256516456604004, acc: 0.3571428656578064)
[2024-11-29 03:10:43,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:44,102][root][INFO] - Training Epoch: 2/10, step 567/574 completed (loss: 1.7979434728622437, acc: 0.5526315569877625)
[2024-11-29 03:10:44,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:44,693][root][INFO] - Training Epoch: 2/10, step 568/574 completed (loss: 1.6071562767028809, acc: 0.5925925970077515)
[2024-11-29 03:10:44,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:45,319][root][INFO] - Training Epoch: 2/10, step 569/574 completed (loss: 2.596026659011841, acc: 0.31550800800323486)
[2024-11-29 03:10:45,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:46,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:47,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:47,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:48,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:48,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:49,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:49,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:50,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:50,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:51,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:51,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:52,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:52,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:53,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:53,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:54,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:54,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:55,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:56,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:56,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:57,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:57,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:58,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:58,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:59,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:59,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:00,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:00,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:01,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:01,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:02,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:02,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:03,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:03,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:04,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:04,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:05,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:06,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:06,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:07,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:07,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:08,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:08,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:09,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:09,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:10,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:10,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:11,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:11,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:12,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:12,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:13,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:13,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:14,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:15,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:15,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:16,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:16,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:17,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:17,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:18,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:18,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:19,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:19,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:20,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:20,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:21,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:21,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:22,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:23,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:23,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:24,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:24,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:25,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:25,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:26,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:26,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:27,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:27,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:28,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:28,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:29,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:30,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:30,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:31,373][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.6218, device='cuda:0') eval_epoch_loss=tensor(2.0310, device='cuda:0') eval_epoch_acc=tensor(0.4853, device='cuda:0')
[2024-11-29 03:11:31,374][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:11:31,375][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:11:31,626][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_2_step_570_loss_2.0310187339782715/model.pt
[2024-11-29 03:11:31,628][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 2.0310187339782715
[2024-11-29 03:11:31,629][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.4852999150753021
[2024-11-29 03:11:31,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:32,247][root][INFO] - Training Epoch: 2/10, step 570/574 completed (loss: 1.9676055908203125, acc: 0.4516128897666931)
[2024-11-29 03:11:32,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:32,846][root][INFO] - Training Epoch: 2/10, step 571/574 completed (loss: 2.772726058959961, acc: 0.24786324799060822)
[2024-11-29 03:11:32,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:33,458][root][INFO] - Training Epoch: 2/10, step 572/574 completed (loss: 2.9070820808410645, acc: 0.26530611515045166)
[2024-11-29 03:11:33,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:34,070][root][INFO] - Training Epoch: 2/10, step 573/574 completed (loss: 2.7429966926574707, acc: 0.2830188572406769)
[2024-11-29 03:11:34,557][slam_llm.utils.train_utils][INFO] - Epoch 2: train_perplexity=9.9934, train_epoch_loss=2.3019, epoch time 527.3513013515621s
[2024-11-29 03:11:34,557][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 14 GB
[2024-11-29 03:11:34,557][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-29 03:11:34,557][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 14 GB
[2024-11-29 03:11:34,557][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 2
[2024-11-29 03:11:34,557][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-29 03:11:35,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:35,659][root][INFO] - Training Epoch: 3/10, step 0/574 completed (loss: 1.4613053798675537, acc: 0.6296296119689941)
[2024-11-29 03:11:35,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:36,251][root][INFO] - Training Epoch: 3/10, step 1/574 completed (loss: 1.4902129173278809, acc: 0.7599999904632568)
[2024-11-29 03:11:36,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:36,843][root][INFO] - Training Epoch: 3/10, step 2/574 completed (loss: 2.332683563232422, acc: 0.45945945382118225)
[2024-11-29 03:11:36,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:37,436][root][INFO] - Training Epoch: 3/10, step 3/574 completed (loss: 2.297565221786499, acc: 0.3684210479259491)
[2024-11-29 03:11:37,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:38,027][root][INFO] - Training Epoch: 3/10, step 4/574 completed (loss: 1.7311779260635376, acc: 0.5135135054588318)
[2024-11-29 03:11:38,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:38,622][root][INFO] - Training Epoch: 3/10, step 5/574 completed (loss: 1.7886601686477661, acc: 0.5714285969734192)
[2024-11-29 03:11:38,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:39,213][root][INFO] - Training Epoch: 3/10, step 6/574 completed (loss: 2.3439505100250244, acc: 0.36734694242477417)
[2024-11-29 03:11:39,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:39,800][root][INFO] - Training Epoch: 3/10, step 7/574 completed (loss: 1.408528208732605, acc: 0.6666666865348816)
[2024-11-29 03:11:39,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:40,392][root][INFO] - Training Epoch: 3/10, step 8/574 completed (loss: 0.16302210092544556, acc: 1.0)
[2024-11-29 03:11:40,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:40,982][root][INFO] - Training Epoch: 3/10, step 9/574 completed (loss: 0.5663299560546875, acc: 0.8461538553237915)
[2024-11-29 03:11:41,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:41,571][root][INFO] - Training Epoch: 3/10, step 10/574 completed (loss: 0.8211967349052429, acc: 0.7037037014961243)
[2024-11-29 03:11:41,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:42,160][root][INFO] - Training Epoch: 3/10, step 11/574 completed (loss: 2.3203980922698975, acc: 0.4615384638309479)
[2024-11-29 03:11:42,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:42,748][root][INFO] - Training Epoch: 3/10, step 12/574 completed (loss: 1.6485719680786133, acc: 0.4848484992980957)
[2024-11-29 03:11:42,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:43,338][root][INFO] - Training Epoch: 3/10, step 13/574 completed (loss: 1.891637921333313, acc: 0.45652174949645996)
[2024-11-29 03:11:43,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:43,929][root][INFO] - Training Epoch: 3/10, step 14/574 completed (loss: 2.267037868499756, acc: 0.3921568691730499)
[2024-11-29 03:11:44,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:44,521][root][INFO] - Training Epoch: 3/10, step 15/574 completed (loss: 1.9413293600082397, acc: 0.4897959232330322)
[2024-11-29 03:11:44,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:45,109][root][INFO] - Training Epoch: 3/10, step 16/574 completed (loss: 0.5074127912521362, acc: 0.8421052694320679)
[2024-11-29 03:11:45,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:45,695][root][INFO] - Training Epoch: 3/10, step 17/574 completed (loss: 1.0958828926086426, acc: 0.7916666865348816)
[2024-11-29 03:11:45,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:46,284][root][INFO] - Training Epoch: 3/10, step 18/574 completed (loss: 2.4387898445129395, acc: 0.3611111044883728)
[2024-11-29 03:11:46,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:46,874][root][INFO] - Training Epoch: 3/10, step 19/574 completed (loss: 0.767880916595459, acc: 0.7368420958518982)
[2024-11-29 03:11:46,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:47,463][root][INFO] - Training Epoch: 3/10, step 20/574 completed (loss: 1.9995745420455933, acc: 0.4615384638309479)
[2024-11-29 03:11:47,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:48,053][root][INFO] - Training Epoch: 3/10, step 21/574 completed (loss: 1.6278563737869263, acc: 0.5862069129943848)
[2024-11-29 03:11:48,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:48,641][root][INFO] - Training Epoch: 3/10, step 22/574 completed (loss: 2.134415626525879, acc: 0.5199999809265137)
[2024-11-29 03:11:48,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:49,229][root][INFO] - Training Epoch: 3/10, step 23/574 completed (loss: 1.1344581842422485, acc: 0.7142857313156128)
[2024-11-29 03:11:49,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:49,814][root][INFO] - Training Epoch: 3/10, step 24/574 completed (loss: 1.6996512413024902, acc: 0.5)
[2024-11-29 03:11:49,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:50,408][root][INFO] - Training Epoch: 3/10, step 25/574 completed (loss: 2.547773838043213, acc: 0.3207547068595886)
[2024-11-29 03:11:50,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:50,999][root][INFO] - Training Epoch: 3/10, step 26/574 completed (loss: 2.461484670639038, acc: 0.34246575832366943)
[2024-11-29 03:11:51,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:51,672][root][INFO] - Training Epoch: 3/10, step 27/574 completed (loss: 2.9293835163116455, acc: 0.25296443700790405)
[2024-11-29 03:11:51,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:52,262][root][INFO] - Training Epoch: 3/10, step 28/574 completed (loss: 2.5239293575286865, acc: 0.3255814015865326)
[2024-11-29 03:11:52,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:52,856][root][INFO] - Training Epoch: 3/10, step 29/574 completed (loss: 2.3867173194885254, acc: 0.3855421543121338)
[2024-11-29 03:11:52,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:53,456][root][INFO] - Training Epoch: 3/10, step 30/574 completed (loss: 2.43644380569458, acc: 0.3086419701576233)
[2024-11-29 03:11:53,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:54,049][root][INFO] - Training Epoch: 3/10, step 31/574 completed (loss: 1.9427566528320312, acc: 0.5714285969734192)
[2024-11-29 03:11:54,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:54,639][root][INFO] - Training Epoch: 3/10, step 32/574 completed (loss: 1.409600853919983, acc: 0.5185185074806213)
[2024-11-29 03:11:54,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:55,225][root][INFO] - Training Epoch: 3/10, step 33/574 completed (loss: 1.1490800380706787, acc: 0.739130437374115)
[2024-11-29 03:11:55,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:55,823][root][INFO] - Training Epoch: 3/10, step 34/574 completed (loss: 2.372807264328003, acc: 0.4117647111415863)
[2024-11-29 03:11:55,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:56,416][root][INFO] - Training Epoch: 3/10, step 35/574 completed (loss: 2.047656297683716, acc: 0.44262295961380005)
[2024-11-29 03:11:56,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:57,016][root][INFO] - Training Epoch: 3/10, step 36/574 completed (loss: 2.004502296447754, acc: 0.4126984179019928)
[2024-11-29 03:11:57,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:57,610][root][INFO] - Training Epoch: 3/10, step 37/574 completed (loss: 2.4086055755615234, acc: 0.37288135290145874)
[2024-11-29 03:11:57,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:58,204][root][INFO] - Training Epoch: 3/10, step 38/574 completed (loss: 1.9583539962768555, acc: 0.4482758641242981)
[2024-11-29 03:11:58,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:58,792][root][INFO] - Training Epoch: 3/10, step 39/574 completed (loss: 0.7349454164505005, acc: 0.9047619104385376)
[2024-11-29 03:11:58,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:59,378][root][INFO] - Training Epoch: 3/10, step 40/574 completed (loss: 1.816405177116394, acc: 0.5)
[2024-11-29 03:11:59,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:59,973][root][INFO] - Training Epoch: 3/10, step 41/574 completed (loss: 2.63077974319458, acc: 0.37837839126586914)
[2024-11-29 03:12:00,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:00,567][root][INFO] - Training Epoch: 3/10, step 42/574 completed (loss: 2.2165145874023438, acc: 0.4615384638309479)
[2024-11-29 03:12:00,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:01,164][root][INFO] - Training Epoch: 3/10, step 43/574 completed (loss: 2.655078649520874, acc: 0.31313130259513855)
[2024-11-29 03:12:01,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:01,766][root][INFO] - Training Epoch: 3/10, step 44/574 completed (loss: 2.247443437576294, acc: 0.47422680258750916)
[2024-11-29 03:12:01,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:02,365][root][INFO] - Training Epoch: 3/10, step 45/574 completed (loss: 2.5224080085754395, acc: 0.3970588147640228)
[2024-11-29 03:12:02,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:02,951][root][INFO] - Training Epoch: 3/10, step 46/574 completed (loss: 0.7358927130699158, acc: 0.7692307829856873)
[2024-11-29 03:12:03,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:03,538][root][INFO] - Training Epoch: 3/10, step 47/574 completed (loss: 0.5220575928688049, acc: 0.9259259104728699)
[2024-11-29 03:12:03,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:04,126][root][INFO] - Training Epoch: 3/10, step 48/574 completed (loss: 1.138727068901062, acc: 0.6785714030265808)
[2024-11-29 03:12:04,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:04,717][root][INFO] - Training Epoch: 3/10, step 49/574 completed (loss: 1.175546407699585, acc: 0.75)
[2024-11-29 03:12:04,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:05,310][root][INFO] - Training Epoch: 3/10, step 50/574 completed (loss: 1.6419371366500854, acc: 0.6140350699424744)
[2024-11-29 03:12:05,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:05,905][root][INFO] - Training Epoch: 3/10, step 51/574 completed (loss: 2.0961244106292725, acc: 0.4444444477558136)
[2024-11-29 03:12:05,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:06,500][root][INFO] - Training Epoch: 3/10, step 52/574 completed (loss: 2.2508628368377686, acc: 0.4084506928920746)
[2024-11-29 03:12:06,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:07,113][root][INFO] - Training Epoch: 3/10, step 53/574 completed (loss: 3.091604232788086, acc: 0.30666667222976685)
[2024-11-29 03:12:07,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:07,704][root][INFO] - Training Epoch: 3/10, step 54/574 completed (loss: 1.521887183189392, acc: 0.5945945978164673)
[2024-11-29 03:12:07,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:08,294][root][INFO] - Training Epoch: 3/10, step 55/574 completed (loss: 0.5600776672363281, acc: 0.9230769276618958)
[2024-11-29 03:12:08,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:08,995][root][INFO] - Training Epoch: 3/10, step 56/574 completed (loss: 2.492314338684082, acc: 0.42320817708969116)
[2024-11-29 03:12:09,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:09,649][root][INFO] - Training Epoch: 3/10, step 57/574 completed (loss: 2.869013786315918, acc: 0.32679739594459534)
[2024-11-29 03:12:09,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:10,266][root][INFO] - Training Epoch: 3/10, step 58/574 completed (loss: 2.383817195892334, acc: 0.3693181872367859)
[2024-11-29 03:12:10,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:10,862][root][INFO] - Training Epoch: 3/10, step 59/574 completed (loss: 2.8375980854034424, acc: 0.3382352888584137)
[2024-11-29 03:12:10,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:11,477][root][INFO] - Training Epoch: 3/10, step 60/574 completed (loss: 2.405700206756592, acc: 0.3478260934352875)
[2024-11-29 03:12:11,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:12,090][root][INFO] - Training Epoch: 3/10, step 61/574 completed (loss: 1.9182971715927124, acc: 0.550000011920929)
[2024-11-29 03:12:12,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:12,678][root][INFO] - Training Epoch: 3/10, step 62/574 completed (loss: 1.3778820037841797, acc: 0.6470588445663452)
[2024-11-29 03:12:12,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:13,266][root][INFO] - Training Epoch: 3/10, step 63/574 completed (loss: 1.87969970703125, acc: 0.5277777910232544)
[2024-11-29 03:12:13,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:13,860][root][INFO] - Training Epoch: 3/10, step 64/574 completed (loss: 1.8437869548797607, acc: 0.484375)
[2024-11-29 03:12:13,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:14,449][root][INFO] - Training Epoch: 3/10, step 65/574 completed (loss: 0.7795891165733337, acc: 0.7586206793785095)
[2024-11-29 03:12:14,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:15,041][root][INFO] - Training Epoch: 3/10, step 66/574 completed (loss: 2.2764627933502197, acc: 0.3214285671710968)
[2024-11-29 03:12:15,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:15,633][root][INFO] - Training Epoch: 3/10, step 67/574 completed (loss: 2.3794264793395996, acc: 0.3499999940395355)
[2024-11-29 03:12:15,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:16,219][root][INFO] - Training Epoch: 3/10, step 68/574 completed (loss: 0.8334893584251404, acc: 0.7200000286102295)
[2024-11-29 03:12:16,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:16,807][root][INFO] - Training Epoch: 3/10, step 69/574 completed (loss: 1.2323054075241089, acc: 0.6111111044883728)
[2024-11-29 03:12:16,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:17,398][root][INFO] - Training Epoch: 3/10, step 70/574 completed (loss: 2.020785331726074, acc: 0.6060606241226196)
[2024-11-29 03:12:17,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:18,010][root][INFO] - Training Epoch: 3/10, step 71/574 completed (loss: 2.6697094440460205, acc: 0.38235294818878174)
[2024-11-29 03:12:18,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:18,606][root][INFO] - Training Epoch: 3/10, step 72/574 completed (loss: 2.414857864379883, acc: 0.4126984179019928)
[2024-11-29 03:12:18,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:19,220][root][INFO] - Training Epoch: 3/10, step 73/574 completed (loss: 2.832221269607544, acc: 0.3282051384449005)
[2024-11-29 03:12:19,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:19,812][root][INFO] - Training Epoch: 3/10, step 74/574 completed (loss: 2.4787960052490234, acc: 0.36734694242477417)
[2024-11-29 03:12:19,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:20,408][root][INFO] - Training Epoch: 3/10, step 75/574 completed (loss: 2.9139087200164795, acc: 0.26865673065185547)
[2024-11-29 03:12:20,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:21,033][root][INFO] - Training Epoch: 3/10, step 76/574 completed (loss: 2.7166571617126465, acc: 0.3613138794898987)
[2024-11-29 03:12:21,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:21,622][root][INFO] - Training Epoch: 3/10, step 77/574 completed (loss: 0.6291659474372864, acc: 0.761904776096344)
[2024-11-29 03:12:21,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:22,208][root][INFO] - Training Epoch: 3/10, step 78/574 completed (loss: 0.6214196085929871, acc: 0.8333333134651184)
[2024-11-29 03:12:22,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:22,795][root][INFO] - Training Epoch: 3/10, step 79/574 completed (loss: 1.405844807624817, acc: 0.5757575631141663)
[2024-11-29 03:12:22,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:23,382][root][INFO] - Training Epoch: 3/10, step 80/574 completed (loss: 0.8854373693466187, acc: 0.6538461446762085)
[2024-11-29 03:12:23,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:23,974][root][INFO] - Training Epoch: 3/10, step 81/574 completed (loss: 2.354273557662964, acc: 0.4615384638309479)
[2024-11-29 03:12:24,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:24,566][root][INFO] - Training Epoch: 3/10, step 82/574 completed (loss: 2.5635619163513184, acc: 0.3461538553237915)
[2024-11-29 03:12:24,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:25,159][root][INFO] - Training Epoch: 3/10, step 83/574 completed (loss: 1.4101277589797974, acc: 0.65625)
[2024-11-29 03:12:25,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:25,751][root][INFO] - Training Epoch: 3/10, step 84/574 completed (loss: 2.063765287399292, acc: 0.4637681245803833)
[2024-11-29 03:12:25,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:26,344][root][INFO] - Training Epoch: 3/10, step 85/574 completed (loss: 1.8457123041152954, acc: 0.5799999833106995)
[2024-11-29 03:12:26,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:26,931][root][INFO] - Training Epoch: 3/10, step 86/574 completed (loss: 1.3019620180130005, acc: 0.6086956262588501)
[2024-11-29 03:12:27,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:27,523][root][INFO] - Training Epoch: 3/10, step 87/574 completed (loss: 2.3693337440490723, acc: 0.47999998927116394)
[2024-11-29 03:12:27,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:28,118][root][INFO] - Training Epoch: 3/10, step 88/574 completed (loss: 2.1351466178894043, acc: 0.4757281541824341)
[2024-11-29 03:12:28,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:28,729][root][INFO] - Training Epoch: 3/10, step 89/574 completed (loss: 2.355999231338501, acc: 0.4223301112651825)
[2024-11-29 03:12:28,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:29,343][root][INFO] - Training Epoch: 3/10, step 90/574 completed (loss: 2.554077386856079, acc: 0.36021506786346436)
[2024-11-29 03:12:29,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:29,966][root][INFO] - Training Epoch: 3/10, step 91/574 completed (loss: 2.231295347213745, acc: 0.4568965435028076)
[2024-11-29 03:12:30,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:30,561][root][INFO] - Training Epoch: 3/10, step 92/574 completed (loss: 2.012255907058716, acc: 0.5052631497383118)
[2024-11-29 03:12:30,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:31,173][root][INFO] - Training Epoch: 3/10, step 93/574 completed (loss: 2.7461788654327393, acc: 0.2970297038555145)
[2024-11-29 03:12:31,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:31,766][root][INFO] - Training Epoch: 3/10, step 94/574 completed (loss: 2.623948335647583, acc: 0.3709677457809448)
[2024-11-29 03:12:31,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:32,360][root][INFO] - Training Epoch: 3/10, step 95/574 completed (loss: 2.3830392360687256, acc: 0.36231884360313416)
[2024-11-29 03:12:32,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:32,956][root][INFO] - Training Epoch: 3/10, step 96/574 completed (loss: 2.734670877456665, acc: 0.27731093764305115)
[2024-11-29 03:12:33,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:33,552][root][INFO] - Training Epoch: 3/10, step 97/574 completed (loss: 2.8497159481048584, acc: 0.25961539149284363)
[2024-11-29 03:12:33,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:34,149][root][INFO] - Training Epoch: 3/10, step 98/574 completed (loss: 2.7278051376342773, acc: 0.31386861205101013)
[2024-11-29 03:12:34,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:34,740][root][INFO] - Training Epoch: 3/10, step 99/574 completed (loss: 2.7442126274108887, acc: 0.2985074520111084)
[2024-11-29 03:12:34,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:35,328][root][INFO] - Training Epoch: 3/10, step 100/574 completed (loss: 0.8533994555473328, acc: 0.75)
[2024-11-29 03:12:35,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:35,920][root][INFO] - Training Epoch: 3/10, step 101/574 completed (loss: 0.7201197147369385, acc: 0.8636363744735718)
[2024-11-29 03:12:36,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:36,505][root][INFO] - Training Epoch: 3/10, step 102/574 completed (loss: 0.8467584848403931, acc: 0.8260869383811951)
[2024-11-29 03:12:36,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:37,094][root][INFO] - Training Epoch: 3/10, step 103/574 completed (loss: 1.7597790956497192, acc: 0.5227272510528564)
[2024-11-29 03:12:37,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:37,686][root][INFO] - Training Epoch: 3/10, step 104/574 completed (loss: 2.2260186672210693, acc: 0.43103447556495667)
[2024-11-29 03:12:37,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:38,276][root][INFO] - Training Epoch: 3/10, step 105/574 completed (loss: 2.168102979660034, acc: 0.39534884691238403)
[2024-11-29 03:12:38,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:38,865][root][INFO] - Training Epoch: 3/10, step 106/574 completed (loss: 1.2868585586547852, acc: 0.7200000286102295)
[2024-11-29 03:12:38,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:39,450][root][INFO] - Training Epoch: 3/10, step 107/574 completed (loss: 0.2613333761692047, acc: 0.9411764740943909)
[2024-11-29 03:12:39,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:40,036][root][INFO] - Training Epoch: 3/10, step 108/574 completed (loss: 0.2898266911506653, acc: 0.9230769276618958)
[2024-11-29 03:12:40,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:40,636][root][INFO] - Training Epoch: 3/10, step 109/574 completed (loss: 2.0588438510894775, acc: 0.4047619104385376)
[2024-11-29 03:12:40,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:41,227][root][INFO] - Training Epoch: 3/10, step 110/574 completed (loss: 2.3332717418670654, acc: 0.4769230782985687)
[2024-11-29 03:12:41,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:41,819][root][INFO] - Training Epoch: 3/10, step 111/574 completed (loss: 2.3182735443115234, acc: 0.42105263471603394)
[2024-11-29 03:12:41,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:42,407][root][INFO] - Training Epoch: 3/10, step 112/574 completed (loss: 2.131787061691284, acc: 0.45614033937454224)
[2024-11-29 03:12:42,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:42,998][root][INFO] - Training Epoch: 3/10, step 113/574 completed (loss: 2.2804505825042725, acc: 0.25641027092933655)
[2024-11-29 03:12:43,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:43,588][root][INFO] - Training Epoch: 3/10, step 114/574 completed (loss: 1.7107354402542114, acc: 0.5510203838348389)
[2024-11-29 03:12:43,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:44,175][root][INFO] - Training Epoch: 3/10, step 115/574 completed (loss: 0.44093430042266846, acc: 0.8636363744735718)
[2024-11-29 03:12:44,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:44,771][root][INFO] - Training Epoch: 3/10, step 116/574 completed (loss: 2.1988418102264404, acc: 0.4444444477558136)
[2024-11-29 03:12:44,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:45,364][root][INFO] - Training Epoch: 3/10, step 117/574 completed (loss: 2.411775827407837, acc: 0.4065040647983551)
[2024-11-29 03:12:45,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:45,957][root][INFO] - Training Epoch: 3/10, step 118/574 completed (loss: 2.073822021484375, acc: 0.5483871102333069)
[2024-11-29 03:12:46,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:46,598][root][INFO] - Training Epoch: 3/10, step 119/574 completed (loss: 2.5738213062286377, acc: 0.34220531582832336)
[2024-11-29 03:12:46,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:47,194][root][INFO] - Training Epoch: 3/10, step 120/574 completed (loss: 2.072019577026367, acc: 0.5066666603088379)
[2024-11-29 03:12:47,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:47,786][root][INFO] - Training Epoch: 3/10, step 121/574 completed (loss: 1.610202670097351, acc: 0.5961538553237915)
[2024-11-29 03:12:47,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:48,375][root][INFO] - Training Epoch: 3/10, step 122/574 completed (loss: 0.577847421169281, acc: 0.875)
[2024-11-29 03:12:48,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:48,960][root][INFO] - Training Epoch: 3/10, step 123/574 completed (loss: 1.3370945453643799, acc: 0.6842105388641357)
[2024-11-29 03:12:49,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:49,557][root][INFO] - Training Epoch: 3/10, step 124/574 completed (loss: 2.46763277053833, acc: 0.33742332458496094)
[2024-11-29 03:12:49,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:50,170][root][INFO] - Training Epoch: 3/10, step 125/574 completed (loss: 2.3730669021606445, acc: 0.3680555522441864)
[2024-11-29 03:12:50,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:50,766][root][INFO] - Training Epoch: 3/10, step 126/574 completed (loss: 2.5094614028930664, acc: 0.3333333432674408)
[2024-11-29 03:12:50,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:51,387][root][INFO] - Training Epoch: 3/10, step 127/574 completed (loss: 2.466501235961914, acc: 0.3154761791229248)
[2024-11-29 03:12:51,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:51,999][root][INFO] - Training Epoch: 3/10, step 128/574 completed (loss: 2.5318400859832764, acc: 0.3948718011379242)
[2024-11-29 03:12:52,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:52,625][root][INFO] - Training Epoch: 3/10, step 129/574 completed (loss: 2.1130154132843018, acc: 0.49264705181121826)
[2024-11-29 03:12:52,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:53,212][root][INFO] - Training Epoch: 3/10, step 130/574 completed (loss: 0.7513593435287476, acc: 0.807692289352417)
[2024-11-29 03:12:53,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:53,799][root][INFO] - Training Epoch: 3/10, step 131/574 completed (loss: 0.3804877698421478, acc: 0.95652174949646)
[2024-11-29 03:12:53,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:54,385][root][INFO] - Training Epoch: 3/10, step 132/574 completed (loss: 2.0828070640563965, acc: 0.46875)
[2024-11-29 03:12:54,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:54,971][root][INFO] - Training Epoch: 3/10, step 133/574 completed (loss: 1.3082576990127563, acc: 0.6521739363670349)
[2024-11-29 03:12:55,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:55,559][root][INFO] - Training Epoch: 3/10, step 134/574 completed (loss: 1.682315468788147, acc: 0.5428571701049805)
[2024-11-29 03:12:55,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:56,145][root][INFO] - Training Epoch: 3/10, step 135/574 completed (loss: 1.258211374282837, acc: 0.7307692170143127)
[2024-11-29 03:12:56,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:56,733][root][INFO] - Training Epoch: 3/10, step 136/574 completed (loss: 2.1896610260009766, acc: 0.3095238208770752)
[2024-11-29 03:12:56,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:57,319][root][INFO] - Training Epoch: 3/10, step 137/574 completed (loss: 1.6108835935592651, acc: 0.6000000238418579)
[2024-11-29 03:12:57,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:57,904][root][INFO] - Training Epoch: 3/10, step 138/574 completed (loss: 1.0753653049468994, acc: 0.782608687877655)
[2024-11-29 03:12:58,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:59,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:59,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:00,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:00,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:01,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:01,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:02,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:02,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:03,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:03,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:04,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:04,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:05,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:06,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:06,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:07,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:07,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:08,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:08,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:09,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:09,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:10,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:10,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:11,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:11,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:12,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:12,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:13,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:13,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:14,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:15,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:15,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:16,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:16,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:17,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:17,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:18,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:18,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:19,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:19,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:20,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:20,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:21,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:21,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:22,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:22,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:23,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:24,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:24,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:25,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:25,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:26,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:26,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:27,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:27,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:28,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:28,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:29,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:29,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:30,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:30,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:31,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:32,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:32,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:33,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:33,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:34,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:34,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:35,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:35,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:36,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:36,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:37,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:37,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:38,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:38,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:39,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:40,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:40,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:41,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:41,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:42,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:42,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:43,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:44,122][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.3915, device='cuda:0') eval_epoch_loss=tensor(2.0003, device='cuda:0') eval_epoch_acc=tensor(0.4782, device='cuda:0')
[2024-11-29 03:13:44,124][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:13:44,124][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:13:44,457][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_3_step_139_loss_2.000331163406372/model.pt
[2024-11-29 03:13:44,463][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 2.000331163406372
[2024-11-29 03:13:44,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:45,065][root][INFO] - Training Epoch: 3/10, step 139/574 completed (loss: 1.9438025951385498, acc: 0.523809552192688)
[2024-11-29 03:13:45,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:45,653][root][INFO] - Training Epoch: 3/10, step 140/574 completed (loss: 1.833084225654602, acc: 0.5)
[2024-11-29 03:13:45,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:46,253][root][INFO] - Training Epoch: 3/10, step 141/574 completed (loss: 2.3545687198638916, acc: 0.32258063554763794)
[2024-11-29 03:13:46,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:46,842][root][INFO] - Training Epoch: 3/10, step 142/574 completed (loss: 2.251339912414551, acc: 0.3513513505458832)
[2024-11-29 03:13:46,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:47,455][root][INFO] - Training Epoch: 3/10, step 143/574 completed (loss: 2.0432868003845215, acc: 0.4736842215061188)
[2024-11-29 03:13:47,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:48,054][root][INFO] - Training Epoch: 3/10, step 144/574 completed (loss: 2.1272406578063965, acc: 0.48507463932037354)
[2024-11-29 03:13:48,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:48,654][root][INFO] - Training Epoch: 3/10, step 145/574 completed (loss: 2.462296485900879, acc: 0.33673468232154846)
[2024-11-29 03:13:48,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:49,263][root][INFO] - Training Epoch: 3/10, step 146/574 completed (loss: 2.2835116386413574, acc: 0.40425533056259155)
[2024-11-29 03:13:49,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:49,855][root][INFO] - Training Epoch: 3/10, step 147/574 completed (loss: 2.377201795578003, acc: 0.4285714328289032)
[2024-11-29 03:13:49,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:50,442][root][INFO] - Training Epoch: 3/10, step 148/574 completed (loss: 2.1911675930023193, acc: 0.3928571343421936)
[2024-11-29 03:13:50,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:51,032][root][INFO] - Training Epoch: 3/10, step 149/574 completed (loss: 1.1335735321044922, acc: 0.6521739363670349)
[2024-11-29 03:13:51,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:51,625][root][INFO] - Training Epoch: 3/10, step 150/574 completed (loss: 2.2992398738861084, acc: 0.3448275923728943)
[2024-11-29 03:13:51,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:52,215][root][INFO] - Training Epoch: 3/10, step 151/574 completed (loss: 2.298877239227295, acc: 0.45652174949645996)
[2024-11-29 03:13:52,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:52,810][root][INFO] - Training Epoch: 3/10, step 152/574 completed (loss: 2.185776948928833, acc: 0.47457626461982727)
[2024-11-29 03:13:52,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:53,402][root][INFO] - Training Epoch: 3/10, step 153/574 completed (loss: 2.862241268157959, acc: 0.35087719559669495)
[2024-11-29 03:13:53,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:53,999][root][INFO] - Training Epoch: 3/10, step 154/574 completed (loss: 2.1867423057556152, acc: 0.5)
[2024-11-29 03:13:54,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:54,589][root][INFO] - Training Epoch: 3/10, step 155/574 completed (loss: 1.7113877534866333, acc: 0.6428571343421936)
[2024-11-29 03:13:54,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:55,179][root][INFO] - Training Epoch: 3/10, step 156/574 completed (loss: 0.9629563689231873, acc: 0.739130437374115)
[2024-11-29 03:13:55,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:55,766][root][INFO] - Training Epoch: 3/10, step 157/574 completed (loss: 2.1100597381591797, acc: 0.4736842215061188)
[2024-11-29 03:13:55,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:56,361][root][INFO] - Training Epoch: 3/10, step 158/574 completed (loss: 2.335599422454834, acc: 0.47297295928001404)
[2024-11-29 03:13:56,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:56,952][root][INFO] - Training Epoch: 3/10, step 159/574 completed (loss: 2.3461806774139404, acc: 0.4444444477558136)
[2024-11-29 03:13:57,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:57,548][root][INFO] - Training Epoch: 3/10, step 160/574 completed (loss: 2.536398410797119, acc: 0.39534884691238403)
[2024-11-29 03:13:57,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:58,140][root][INFO] - Training Epoch: 3/10, step 161/574 completed (loss: 2.2770137786865234, acc: 0.48235294222831726)
[2024-11-29 03:13:58,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:58,742][root][INFO] - Training Epoch: 3/10, step 162/574 completed (loss: 2.517354965209961, acc: 0.33707866072654724)
[2024-11-29 03:13:58,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:59,338][root][INFO] - Training Epoch: 3/10, step 163/574 completed (loss: 1.7642842531204224, acc: 0.47727271914482117)
[2024-11-29 03:13:59,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:59,926][root][INFO] - Training Epoch: 3/10, step 164/574 completed (loss: 0.9676256775856018, acc: 0.761904776096344)
[2024-11-29 03:14:00,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:00,514][root][INFO] - Training Epoch: 3/10, step 165/574 completed (loss: 1.4776661396026611, acc: 0.5862069129943848)
[2024-11-29 03:14:00,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:01,105][root][INFO] - Training Epoch: 3/10, step 166/574 completed (loss: 1.5029630661010742, acc: 0.6122449040412903)
[2024-11-29 03:14:01,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:01,692][root][INFO] - Training Epoch: 3/10, step 167/574 completed (loss: 2.057147264480591, acc: 0.4399999976158142)
[2024-11-29 03:14:01,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:02,288][root][INFO] - Training Epoch: 3/10, step 168/574 completed (loss: 2.0275890827178955, acc: 0.4722222089767456)
[2024-11-29 03:14:02,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:02,882][root][INFO] - Training Epoch: 3/10, step 169/574 completed (loss: 2.413112163543701, acc: 0.37254902720451355)
[2024-11-29 03:14:02,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:03,505][root][INFO] - Training Epoch: 3/10, step 170/574 completed (loss: 2.763199806213379, acc: 0.36986300349235535)
[2024-11-29 03:14:03,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:04,094][root][INFO] - Training Epoch: 3/10, step 171/574 completed (loss: 0.7964198589324951, acc: 0.875)
[2024-11-29 03:14:04,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:04,680][root][INFO] - Training Epoch: 3/10, step 172/574 completed (loss: 0.6416798830032349, acc: 0.8148148059844971)
[2024-11-29 03:14:04,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:05,267][root][INFO] - Training Epoch: 3/10, step 173/574 completed (loss: 1.4793626070022583, acc: 0.6071428656578064)
[2024-11-29 03:14:05,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:05,880][root][INFO] - Training Epoch: 3/10, step 174/574 completed (loss: 2.182239055633545, acc: 0.48672565817832947)
[2024-11-29 03:14:05,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:06,475][root][INFO] - Training Epoch: 3/10, step 175/574 completed (loss: 2.0980732440948486, acc: 0.52173912525177)
[2024-11-29 03:14:06,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:07,072][root][INFO] - Training Epoch: 3/10, step 176/574 completed (loss: 2.2664568424224854, acc: 0.4318181872367859)
[2024-11-29 03:14:07,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:07,688][root][INFO] - Training Epoch: 3/10, step 177/574 completed (loss: 2.6285221576690674, acc: 0.3129771053791046)
[2024-11-29 03:14:07,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:08,297][root][INFO] - Training Epoch: 3/10, step 178/574 completed (loss: 2.7484662532806396, acc: 0.31111112236976624)
[2024-11-29 03:14:08,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:08,888][root][INFO] - Training Epoch: 3/10, step 179/574 completed (loss: 1.890634536743164, acc: 0.4754098355770111)
[2024-11-29 03:14:08,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:09,477][root][INFO] - Training Epoch: 3/10, step 180/574 completed (loss: 0.4833367168903351, acc: 0.7916666865348816)
[2024-11-29 03:14:09,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:10,063][root][INFO] - Training Epoch: 3/10, step 181/574 completed (loss: 0.9108403921127319, acc: 0.7200000286102295)
[2024-11-29 03:14:10,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:10,651][root][INFO] - Training Epoch: 3/10, step 182/574 completed (loss: 1.1462105512619019, acc: 0.7142857313156128)
[2024-11-29 03:14:10,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:11,243][root][INFO] - Training Epoch: 3/10, step 183/574 completed (loss: 2.3705880641937256, acc: 0.353658527135849)
[2024-11-29 03:14:11,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:11,871][root][INFO] - Training Epoch: 3/10, step 184/574 completed (loss: 2.9001593589782715, acc: 0.25075528025627136)
[2024-11-29 03:14:11,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:12,498][root][INFO] - Training Epoch: 3/10, step 185/574 completed (loss: 2.8699896335601807, acc: 0.2276657074689865)
[2024-11-29 03:14:12,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:13,120][root][INFO] - Training Epoch: 3/10, step 186/574 completed (loss: 2.8862414360046387, acc: 0.2750000059604645)
[2024-11-29 03:14:13,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:13,778][root][INFO] - Training Epoch: 3/10, step 187/574 completed (loss: 2.937596082687378, acc: 0.23639774322509766)
[2024-11-29 03:14:13,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:14,412][root][INFO] - Training Epoch: 3/10, step 188/574 completed (loss: 2.635838747024536, acc: 0.27402135729789734)
[2024-11-29 03:14:14,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:15,002][root][INFO] - Training Epoch: 3/10, step 189/574 completed (loss: 2.054884195327759, acc: 0.5600000023841858)
[2024-11-29 03:14:15,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:15,598][root][INFO] - Training Epoch: 3/10, step 190/574 completed (loss: 2.4183974266052246, acc: 0.302325576543808)
[2024-11-29 03:14:15,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:16,200][root][INFO] - Training Epoch: 3/10, step 191/574 completed (loss: 2.405749797821045, acc: 0.3888888955116272)
[2024-11-29 03:14:16,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:16,798][root][INFO] - Training Epoch: 3/10, step 192/574 completed (loss: 2.532879114151001, acc: 0.3712121248245239)
[2024-11-29 03:14:16,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:17,397][root][INFO] - Training Epoch: 3/10, step 193/574 completed (loss: 2.042400598526001, acc: 0.4941176474094391)
[2024-11-29 03:14:17,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:18,010][root][INFO] - Training Epoch: 3/10, step 194/574 completed (loss: 2.2696950435638428, acc: 0.4135802388191223)
[2024-11-29 03:14:18,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:18,606][root][INFO] - Training Epoch: 3/10, step 195/574 completed (loss: 1.7448285818099976, acc: 0.5645161271095276)
[2024-11-29 03:14:18,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:19,193][root][INFO] - Training Epoch: 3/10, step 196/574 completed (loss: 0.7970615029335022, acc: 0.8571428656578064)
[2024-11-29 03:14:19,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:19,783][root][INFO] - Training Epoch: 3/10, step 197/574 completed (loss: 2.2626051902770996, acc: 0.42500001192092896)
[2024-11-29 03:14:19,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:20,374][root][INFO] - Training Epoch: 3/10, step 198/574 completed (loss: 2.0999910831451416, acc: 0.44117647409439087)
[2024-11-29 03:14:20,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:20,973][root][INFO] - Training Epoch: 3/10, step 199/574 completed (loss: 2.490818500518799, acc: 0.41911765933036804)
[2024-11-29 03:14:21,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:21,569][root][INFO] - Training Epoch: 3/10, step 200/574 completed (loss: 2.390641212463379, acc: 0.33898305892944336)
[2024-11-29 03:14:21,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:22,168][root][INFO] - Training Epoch: 3/10, step 201/574 completed (loss: 2.572049379348755, acc: 0.3283582031726837)
[2024-11-29 03:14:22,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:22,764][root][INFO] - Training Epoch: 3/10, step 202/574 completed (loss: 2.625495672225952, acc: 0.35922330617904663)
[2024-11-29 03:14:22,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:23,363][root][INFO] - Training Epoch: 3/10, step 203/574 completed (loss: 2.300848960876465, acc: 0.4444444477558136)
[2024-11-29 03:14:23,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:23,958][root][INFO] - Training Epoch: 3/10, step 204/574 completed (loss: 2.324151039123535, acc: 0.37362638115882874)
[2024-11-29 03:14:24,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:24,579][root][INFO] - Training Epoch: 3/10, step 205/574 completed (loss: 2.677318572998047, acc: 0.3139013350009918)
[2024-11-29 03:14:24,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:25,205][root][INFO] - Training Epoch: 3/10, step 206/574 completed (loss: 2.724031686782837, acc: 0.31496062874794006)
[2024-11-29 03:14:25,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:25,819][root][INFO] - Training Epoch: 3/10, step 207/574 completed (loss: 2.472357749938965, acc: 0.3318965435028076)
[2024-11-29 03:14:25,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:26,436][root][INFO] - Training Epoch: 3/10, step 208/574 completed (loss: 2.4127981662750244, acc: 0.3840579688549042)
[2024-11-29 03:14:26,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:27,056][root][INFO] - Training Epoch: 3/10, step 209/574 completed (loss: 2.6655666828155518, acc: 0.3346303403377533)
[2024-11-29 03:14:27,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:27,672][root][INFO] - Training Epoch: 3/10, step 210/574 completed (loss: 2.5314888954162598, acc: 0.3913043439388275)
[2024-11-29 03:14:27,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:28,258][root][INFO] - Training Epoch: 3/10, step 211/574 completed (loss: 0.8775412440299988, acc: 0.782608687877655)
[2024-11-29 03:14:28,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:28,844][root][INFO] - Training Epoch: 3/10, step 212/574 completed (loss: 1.5561130046844482, acc: 0.5357142686843872)
[2024-11-29 03:14:28,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:29,437][root][INFO] - Training Epoch: 3/10, step 213/574 completed (loss: 1.7097868919372559, acc: 0.4893617033958435)
[2024-11-29 03:14:29,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:30,046][root][INFO] - Training Epoch: 3/10, step 214/574 completed (loss: 2.352876663208008, acc: 0.4076923131942749)
[2024-11-29 03:14:30,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:30,637][root][INFO] - Training Epoch: 3/10, step 215/574 completed (loss: 1.9527307748794556, acc: 0.5135135054588318)
[2024-11-29 03:14:30,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:31,232][root][INFO] - Training Epoch: 3/10, step 216/574 completed (loss: 2.015064239501953, acc: 0.5)
[2024-11-29 03:14:31,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:31,828][root][INFO] - Training Epoch: 3/10, step 217/574 completed (loss: 2.127250909805298, acc: 0.4234234094619751)
[2024-11-29 03:14:31,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:32,422][root][INFO] - Training Epoch: 3/10, step 218/574 completed (loss: 2.0303101539611816, acc: 0.42222222685813904)
[2024-11-29 03:14:32,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:33,011][root][INFO] - Training Epoch: 3/10, step 219/574 completed (loss: 0.8059368133544922, acc: 0.8181818127632141)
[2024-11-29 03:14:33,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:33,600][root][INFO] - Training Epoch: 3/10, step 220/574 completed (loss: 0.28864017128944397, acc: 0.9629629850387573)
[2024-11-29 03:14:33,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:34,185][root][INFO] - Training Epoch: 3/10, step 221/574 completed (loss: 0.7288225293159485, acc: 0.8399999737739563)
[2024-11-29 03:14:34,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:34,784][root][INFO] - Training Epoch: 3/10, step 222/574 completed (loss: 2.0360255241394043, acc: 0.4423076808452606)
[2024-11-29 03:14:34,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:35,399][root][INFO] - Training Epoch: 3/10, step 223/574 completed (loss: 2.292715072631836, acc: 0.41847825050354004)
[2024-11-29 03:14:35,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:36,012][root][INFO] - Training Epoch: 3/10, step 224/574 completed (loss: 2.307729721069336, acc: 0.3863636255264282)
[2024-11-29 03:14:36,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:36,625][root][INFO] - Training Epoch: 3/10, step 225/574 completed (loss: 2.359468460083008, acc: 0.38297873735427856)
[2024-11-29 03:14:36,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:37,213][root][INFO] - Training Epoch: 3/10, step 226/574 completed (loss: 1.747969388961792, acc: 0.5849056839942932)
[2024-11-29 03:14:37,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:37,805][root][INFO] - Training Epoch: 3/10, step 227/574 completed (loss: 2.001950263977051, acc: 0.4833333194255829)
[2024-11-29 03:14:37,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:38,403][root][INFO] - Training Epoch: 3/10, step 228/574 completed (loss: 1.0602409839630127, acc: 0.7441860437393188)
[2024-11-29 03:14:38,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:38,990][root][INFO] - Training Epoch: 3/10, step 229/574 completed (loss: 1.3278881311416626, acc: 0.7333333492279053)
[2024-11-29 03:14:39,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:39,588][root][INFO] - Training Epoch: 3/10, step 230/574 completed (loss: 2.504443407058716, acc: 0.410526305437088)
[2024-11-29 03:14:39,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:40,180][root][INFO] - Training Epoch: 3/10, step 231/574 completed (loss: 2.145127773284912, acc: 0.42222222685813904)
[2024-11-29 03:14:40,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:40,793][root][INFO] - Training Epoch: 3/10, step 232/574 completed (loss: 2.0650784969329834, acc: 0.4277777671813965)
[2024-11-29 03:14:40,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:41,408][root][INFO] - Training Epoch: 3/10, step 233/574 completed (loss: 2.238541603088379, acc: 0.4541284441947937)
[2024-11-29 03:14:41,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:42,020][root][INFO] - Training Epoch: 3/10, step 234/574 completed (loss: 2.1006853580474854, acc: 0.446153849363327)
[2024-11-29 03:14:42,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:42,606][root][INFO] - Training Epoch: 3/10, step 235/574 completed (loss: 0.7022284269332886, acc: 0.7368420958518982)
[2024-11-29 03:14:42,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:43,193][root][INFO] - Training Epoch: 3/10, step 236/574 completed (loss: 0.7815412878990173, acc: 0.7083333134651184)
[2024-11-29 03:14:43,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:43,781][root][INFO] - Training Epoch: 3/10, step 237/574 completed (loss: 1.6093662977218628, acc: 0.5)
[2024-11-29 03:14:43,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:44,370][root][INFO] - Training Epoch: 3/10, step 238/574 completed (loss: 1.481420636177063, acc: 0.5925925970077515)
[2024-11-29 03:14:44,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:44,961][root][INFO] - Training Epoch: 3/10, step 239/574 completed (loss: 1.4212003946304321, acc: 0.6285714507102966)
[2024-11-29 03:14:45,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:45,552][root][INFO] - Training Epoch: 3/10, step 240/574 completed (loss: 1.64594304561615, acc: 0.5227272510528564)
[2024-11-29 03:14:45,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:46,142][root][INFO] - Training Epoch: 3/10, step 241/574 completed (loss: 1.6131362915039062, acc: 0.6136363744735718)
[2024-11-29 03:14:46,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:46,735][root][INFO] - Training Epoch: 3/10, step 242/574 completed (loss: 1.9716020822525024, acc: 0.4354838728904724)
[2024-11-29 03:14:46,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:47,333][root][INFO] - Training Epoch: 3/10, step 243/574 completed (loss: 1.4369643926620483, acc: 0.5681818127632141)
[2024-11-29 03:14:47,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:47,919][root][INFO] - Training Epoch: 3/10, step 244/574 completed (loss: 0.1679507941007614, acc: 0.9523809552192688)
[2024-11-29 03:14:47,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:48,505][root][INFO] - Training Epoch: 3/10, step 245/574 completed (loss: 0.5684607625007629, acc: 0.9230769276618958)
[2024-11-29 03:14:48,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:49,092][root][INFO] - Training Epoch: 3/10, step 246/574 completed (loss: 1.2476638555526733, acc: 0.5806451439857483)
[2024-11-29 03:14:49,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:49,680][root][INFO] - Training Epoch: 3/10, step 247/574 completed (loss: 0.4192480146884918, acc: 0.8500000238418579)
[2024-11-29 03:14:49,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:50,273][root][INFO] - Training Epoch: 3/10, step 248/574 completed (loss: 1.93512761592865, acc: 0.45945945382118225)
[2024-11-29 03:14:50,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:50,862][root][INFO] - Training Epoch: 3/10, step 249/574 completed (loss: 1.6087970733642578, acc: 0.4864864945411682)
[2024-11-29 03:14:50,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:51,450][root][INFO] - Training Epoch: 3/10, step 250/574 completed (loss: 1.549726963043213, acc: 0.5945945978164673)
[2024-11-29 03:14:51,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:52,047][root][INFO] - Training Epoch: 3/10, step 251/574 completed (loss: 2.032522201538086, acc: 0.47058823704719543)
[2024-11-29 03:14:52,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:52,636][root][INFO] - Training Epoch: 3/10, step 252/574 completed (loss: 0.6788216829299927, acc: 0.8292682766914368)
[2024-11-29 03:14:52,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:53,225][root][INFO] - Training Epoch: 3/10, step 253/574 completed (loss: 0.48731938004493713, acc: 0.8399999737739563)
[2024-11-29 03:14:53,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:53,812][root][INFO] - Training Epoch: 3/10, step 254/574 completed (loss: 0.1685301959514618, acc: 1.0)
[2024-11-29 03:14:53,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:54,399][root][INFO] - Training Epoch: 3/10, step 255/574 completed (loss: 0.6758761405944824, acc: 0.8064516186714172)
[2024-11-29 03:14:54,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:54,989][root][INFO] - Training Epoch: 3/10, step 256/574 completed (loss: 2.1511497497558594, acc: 0.4912280738353729)
[2024-11-29 03:14:55,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:55,579][root][INFO] - Training Epoch: 3/10, step 257/574 completed (loss: 1.9020549058914185, acc: 0.5285714268684387)
[2024-11-29 03:14:55,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:56,170][root][INFO] - Training Epoch: 3/10, step 258/574 completed (loss: 1.86322820186615, acc: 0.6052631735801697)
[2024-11-29 03:14:56,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:56,781][root][INFO] - Training Epoch: 3/10, step 259/574 completed (loss: 2.0707294940948486, acc: 0.4528301954269409)
[2024-11-29 03:14:56,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:57,394][root][INFO] - Training Epoch: 3/10, step 260/574 completed (loss: 2.4045448303222656, acc: 0.4166666567325592)
[2024-11-29 03:14:57,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:57,984][root][INFO] - Training Epoch: 3/10, step 261/574 completed (loss: 1.3274102210998535, acc: 0.6666666865348816)
[2024-11-29 03:14:58,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:58,571][root][INFO] - Training Epoch: 3/10, step 262/574 completed (loss: 1.4697097539901733, acc: 0.5483871102333069)
[2024-11-29 03:14:58,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:59,167][root][INFO] - Training Epoch: 3/10, step 263/574 completed (loss: 2.634848117828369, acc: 0.3466666638851166)
[2024-11-29 03:14:59,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:59,756][root][INFO] - Training Epoch: 3/10, step 264/574 completed (loss: 2.1927268505096436, acc: 0.4375)
[2024-11-29 03:14:59,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:00,373][root][INFO] - Training Epoch: 3/10, step 265/574 completed (loss: 2.672273635864258, acc: 0.36000001430511475)
[2024-11-29 03:15:00,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:00,967][root][INFO] - Training Epoch: 3/10, step 266/574 completed (loss: 2.3177330493927, acc: 0.3820224702358246)
[2024-11-29 03:15:01,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:01,559][root][INFO] - Training Epoch: 3/10, step 267/574 completed (loss: 2.3280913829803467, acc: 0.4324324429035187)
[2024-11-29 03:15:01,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:02,154][root][INFO] - Training Epoch: 3/10, step 268/574 completed (loss: 1.533077359199524, acc: 0.5517241358757019)
[2024-11-29 03:15:02,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:02,742][root][INFO] - Training Epoch: 3/10, step 269/574 completed (loss: 0.4030567407608032, acc: 0.9090909361839294)
[2024-11-29 03:15:02,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:03,329][root][INFO] - Training Epoch: 3/10, step 270/574 completed (loss: 0.6554535031318665, acc: 0.7727272510528564)
[2024-11-29 03:15:03,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:03,917][root][INFO] - Training Epoch: 3/10, step 271/574 completed (loss: 0.7216742634773254, acc: 0.75)
[2024-11-29 03:15:03,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:04,505][root][INFO] - Training Epoch: 3/10, step 272/574 completed (loss: 0.6422616243362427, acc: 0.7333333492279053)
[2024-11-29 03:15:04,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:05,102][root][INFO] - Training Epoch: 3/10, step 273/574 completed (loss: 1.7797232866287231, acc: 0.550000011920929)
[2024-11-29 03:15:05,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:05,690][root][INFO] - Training Epoch: 3/10, step 274/574 completed (loss: 1.0619503259658813, acc: 0.71875)
[2024-11-29 03:15:05,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:06,277][root][INFO] - Training Epoch: 3/10, step 275/574 completed (loss: 0.9483797550201416, acc: 0.7666666507720947)
[2024-11-29 03:15:06,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:06,866][root][INFO] - Training Epoch: 3/10, step 276/574 completed (loss: 1.0411293506622314, acc: 0.7586206793785095)
[2024-11-29 03:15:06,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:07,452][root][INFO] - Training Epoch: 3/10, step 277/574 completed (loss: 0.8268895745277405, acc: 0.7599999904632568)
[2024-11-29 03:15:07,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:08,043][root][INFO] - Training Epoch: 3/10, step 278/574 completed (loss: 1.9433432817459106, acc: 0.5106382966041565)
[2024-11-29 03:15:08,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:08,634][root][INFO] - Training Epoch: 3/10, step 279/574 completed (loss: 1.6092828512191772, acc: 0.5625)
[2024-11-29 03:15:08,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:09,226][root][INFO] - Training Epoch: 3/10, step 280/574 completed (loss: 1.3270263671875, acc: 0.6590909361839294)
[2024-11-29 03:15:09,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:09,822][root][INFO] - Training Epoch: 3/10, step 281/574 completed (loss: 2.4395644664764404, acc: 0.3734939694404602)
[2024-11-29 03:15:10,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:11,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:11,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:12,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:12,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:13,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:13,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:14,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:14,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:15,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:15,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:16,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:16,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:17,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:17,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:18,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:19,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:19,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:20,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:20,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:21,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:21,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:22,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:22,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:23,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:23,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:24,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:24,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:25,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:25,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:26,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:26,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:27,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:28,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:28,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:29,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:29,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:30,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:30,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:31,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:31,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:32,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:32,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:33,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:33,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:34,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:35,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:35,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:36,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:36,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:37,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:37,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:38,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:38,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:39,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:39,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:40,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:40,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:41,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:41,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:42,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:42,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:43,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:43,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:44,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:45,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:45,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:46,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:46,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:47,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:47,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:48,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:48,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:49,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:49,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:50,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:50,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:51,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:51,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:52,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:52,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:53,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:54,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:54,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:55,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:55,912][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.4423, device='cuda:0') eval_epoch_loss=tensor(1.8629, device='cuda:0') eval_epoch_acc=tensor(0.5232, device='cuda:0')
[2024-11-29 03:15:55,914][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:15:55,914][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:15:56,146][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_3_step_282_loss_1.8628870248794556/model.pt
[2024-11-29 03:15:56,150][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.8628870248794556
[2024-11-29 03:15:56,150][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.523232638835907
[2024-11-29 03:15:56,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:56,762][root][INFO] - Training Epoch: 3/10, step 282/574 completed (loss: 2.474074363708496, acc: 0.43518519401550293)
[2024-11-29 03:15:56,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:57,350][root][INFO] - Training Epoch: 3/10, step 283/574 completed (loss: 1.8296728134155273, acc: 0.5263158082962036)
[2024-11-29 03:15:57,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:57,936][root][INFO] - Training Epoch: 3/10, step 284/574 completed (loss: 1.6611332893371582, acc: 0.47058823704719543)
[2024-11-29 03:15:58,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:58,525][root][INFO] - Training Epoch: 3/10, step 285/574 completed (loss: 1.658529281616211, acc: 0.5249999761581421)
[2024-11-29 03:15:58,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:59,121][root][INFO] - Training Epoch: 3/10, step 286/574 completed (loss: 2.290937900543213, acc: 0.3671875)
[2024-11-29 03:15:59,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:59,730][root][INFO] - Training Epoch: 3/10, step 287/574 completed (loss: 2.7457022666931152, acc: 0.2639999985694885)
[2024-11-29 03:15:59,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:00,324][root][INFO] - Training Epoch: 3/10, step 288/574 completed (loss: 2.071756601333618, acc: 0.4285714328289032)
[2024-11-29 03:16:00,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:00,921][root][INFO] - Training Epoch: 3/10, step 289/574 completed (loss: 2.7080636024475098, acc: 0.32919254899024963)
[2024-11-29 03:16:01,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:01,535][root][INFO] - Training Epoch: 3/10, step 290/574 completed (loss: 2.6522216796875, acc: 0.3350515365600586)
[2024-11-29 03:16:01,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:02,123][root][INFO] - Training Epoch: 3/10, step 291/574 completed (loss: 0.3466346859931946, acc: 0.9090909361839294)
[2024-11-29 03:16:02,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:02,713][root][INFO] - Training Epoch: 3/10, step 292/574 completed (loss: 2.060450315475464, acc: 0.5)
[2024-11-29 03:16:02,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:03,306][root][INFO] - Training Epoch: 3/10, step 293/574 completed (loss: 2.1600022315979004, acc: 0.5)
[2024-11-29 03:16:03,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:03,899][root][INFO] - Training Epoch: 3/10, step 294/574 completed (loss: 1.4801450967788696, acc: 0.6181818246841431)
[2024-11-29 03:16:03,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:04,521][root][INFO] - Training Epoch: 3/10, step 295/574 completed (loss: 2.30352783203125, acc: 0.469072163105011)
[2024-11-29 03:16:04,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:05,113][root][INFO] - Training Epoch: 3/10, step 296/574 completed (loss: 2.3615949153900146, acc: 0.36206895112991333)
[2024-11-29 03:16:05,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:05,700][root][INFO] - Training Epoch: 3/10, step 297/574 completed (loss: 1.2852709293365479, acc: 0.7037037014961243)
[2024-11-29 03:16:05,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:06,292][root][INFO] - Training Epoch: 3/10, step 298/574 completed (loss: 1.7444276809692383, acc: 0.5263158082962036)
[2024-11-29 03:16:06,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:06,883][root][INFO] - Training Epoch: 3/10, step 299/574 completed (loss: 2.325326442718506, acc: 0.3928571343421936)
[2024-11-29 03:16:06,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:07,470][root][INFO] - Training Epoch: 3/10, step 300/574 completed (loss: 1.3296743631362915, acc: 0.65625)
[2024-11-29 03:16:07,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:08,067][root][INFO] - Training Epoch: 3/10, step 301/574 completed (loss: 2.15356707572937, acc: 0.43396225571632385)
[2024-11-29 03:16:08,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:08,658][root][INFO] - Training Epoch: 3/10, step 302/574 completed (loss: 1.3655650615692139, acc: 0.698113203048706)
[2024-11-29 03:16:08,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:09,245][root][INFO] - Training Epoch: 3/10, step 303/574 completed (loss: 1.1279023885726929, acc: 0.6764705777168274)
[2024-11-29 03:16:09,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:09,831][root][INFO] - Training Epoch: 3/10, step 304/574 completed (loss: 1.8111987113952637, acc: 0.5)
[2024-11-29 03:16:09,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:10,426][root][INFO] - Training Epoch: 3/10, step 305/574 completed (loss: 1.8383735418319702, acc: 0.5409836173057556)
[2024-11-29 03:16:10,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:11,012][root][INFO] - Training Epoch: 3/10, step 306/574 completed (loss: 0.5798109769821167, acc: 0.8666666746139526)
[2024-11-29 03:16:11,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:11,598][root][INFO] - Training Epoch: 3/10, step 307/574 completed (loss: 0.153795063495636, acc: 0.9473684430122375)
[2024-11-29 03:16:11,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:12,191][root][INFO] - Training Epoch: 3/10, step 308/574 completed (loss: 2.4167075157165527, acc: 0.37681159377098083)
[2024-11-29 03:16:12,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:12,785][root][INFO] - Training Epoch: 3/10, step 309/574 completed (loss: 2.0629758834838867, acc: 0.5)
[2024-11-29 03:16:12,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:13,377][root][INFO] - Training Epoch: 3/10, step 310/574 completed (loss: 1.8961187601089478, acc: 0.4819277226924896)
[2024-11-29 03:16:13,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:13,971][root][INFO] - Training Epoch: 3/10, step 311/574 completed (loss: 2.344587802886963, acc: 0.41025641560554504)
[2024-11-29 03:16:14,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:14,580][root][INFO] - Training Epoch: 3/10, step 312/574 completed (loss: 2.336169481277466, acc: 0.3877550959587097)
[2024-11-29 03:16:14,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:15,165][root][INFO] - Training Epoch: 3/10, step 313/574 completed (loss: 0.05352482199668884, acc: 1.0)
[2024-11-29 03:16:15,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:15,751][root][INFO] - Training Epoch: 3/10, step 314/574 completed (loss: 0.5998743772506714, acc: 0.9166666865348816)
[2024-11-29 03:16:15,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:16,338][root][INFO] - Training Epoch: 3/10, step 315/574 completed (loss: 0.5313578844070435, acc: 0.9032257795333862)
[2024-11-29 03:16:16,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:16,925][root][INFO] - Training Epoch: 3/10, step 316/574 completed (loss: 0.9310906529426575, acc: 0.7419354915618896)
[2024-11-29 03:16:17,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:17,519][root][INFO] - Training Epoch: 3/10, step 317/574 completed (loss: 1.8162447214126587, acc: 0.5223880410194397)
[2024-11-29 03:16:17,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:18,117][root][INFO] - Training Epoch: 3/10, step 318/574 completed (loss: 1.742750644683838, acc: 0.5769230723381042)
[2024-11-29 03:16:18,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:18,705][root][INFO] - Training Epoch: 3/10, step 319/574 completed (loss: 1.4742858409881592, acc: 0.6000000238418579)
[2024-11-29 03:16:18,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:19,296][root][INFO] - Training Epoch: 3/10, step 320/574 completed (loss: 1.796404242515564, acc: 0.4838709533214569)
[2024-11-29 03:16:19,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:19,884][root][INFO] - Training Epoch: 3/10, step 321/574 completed (loss: 0.8940179347991943, acc: 0.7599999904632568)
[2024-11-29 03:16:19,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:20,471][root][INFO] - Training Epoch: 3/10, step 322/574 completed (loss: 1.477353572845459, acc: 0.5925925970077515)
[2024-11-29 03:16:20,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:21,059][root][INFO] - Training Epoch: 3/10, step 323/574 completed (loss: 2.6105544567108154, acc: 0.4000000059604645)
[2024-11-29 03:16:21,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:21,646][root][INFO] - Training Epoch: 3/10, step 324/574 completed (loss: 1.9340554475784302, acc: 0.43589743971824646)
[2024-11-29 03:16:21,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:22,237][root][INFO] - Training Epoch: 3/10, step 325/574 completed (loss: 2.5001401901245117, acc: 0.2926829159259796)
[2024-11-29 03:16:22,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:22,829][root][INFO] - Training Epoch: 3/10, step 326/574 completed (loss: 2.3619306087493896, acc: 0.34210526943206787)
[2024-11-29 03:16:22,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:23,415][root][INFO] - Training Epoch: 3/10, step 327/574 completed (loss: 0.5724336504936218, acc: 0.8421052694320679)
[2024-11-29 03:16:23,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:24,002][root][INFO] - Training Epoch: 3/10, step 328/574 completed (loss: 0.20995669066905975, acc: 0.9642857313156128)
[2024-11-29 03:16:24,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:24,589][root][INFO] - Training Epoch: 3/10, step 329/574 completed (loss: 1.3443987369537354, acc: 0.6666666865348816)
[2024-11-29 03:16:24,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:25,177][root][INFO] - Training Epoch: 3/10, step 330/574 completed (loss: 0.7814229130744934, acc: 0.8125)
[2024-11-29 03:16:25,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:25,768][root][INFO] - Training Epoch: 3/10, step 331/574 completed (loss: 1.9443795680999756, acc: 0.4516128897666931)
[2024-11-29 03:16:25,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:26,360][root][INFO] - Training Epoch: 3/10, step 332/574 completed (loss: 1.3908414840698242, acc: 0.5964912176132202)
[2024-11-29 03:16:26,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:26,947][root][INFO] - Training Epoch: 3/10, step 333/574 completed (loss: 1.5488815307617188, acc: 0.53125)
[2024-11-29 03:16:27,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:27,535][root][INFO] - Training Epoch: 3/10, step 334/574 completed (loss: 1.045386791229248, acc: 0.699999988079071)
[2024-11-29 03:16:27,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:28,123][root][INFO] - Training Epoch: 3/10, step 335/574 completed (loss: 0.9810911417007446, acc: 0.6842105388641357)
[2024-11-29 03:16:28,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:28,716][root][INFO] - Training Epoch: 3/10, step 336/574 completed (loss: 1.9915069341659546, acc: 0.47999998927116394)
[2024-11-29 03:16:28,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:29,310][root][INFO] - Training Epoch: 3/10, step 337/574 completed (loss: 2.337782859802246, acc: 0.37931033968925476)
[2024-11-29 03:16:29,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:29,903][root][INFO] - Training Epoch: 3/10, step 338/574 completed (loss: 2.475677013397217, acc: 0.3510638177394867)
[2024-11-29 03:16:29,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:30,497][root][INFO] - Training Epoch: 3/10, step 339/574 completed (loss: 2.4967362880706787, acc: 0.39759036898612976)
[2024-11-29 03:16:30,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:31,084][root][INFO] - Training Epoch: 3/10, step 340/574 completed (loss: 0.6741480231285095, acc: 0.8695651888847351)
[2024-11-29 03:16:31,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:31,672][root][INFO] - Training Epoch: 3/10, step 341/574 completed (loss: 1.3848984241485596, acc: 0.6153846383094788)
[2024-11-29 03:16:31,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:32,271][root][INFO] - Training Epoch: 3/10, step 342/574 completed (loss: 2.711332321166992, acc: 0.33734938502311707)
[2024-11-29 03:16:32,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:32,863][root][INFO] - Training Epoch: 3/10, step 343/574 completed (loss: 1.984542727470398, acc: 0.4528301954269409)
[2024-11-29 03:16:32,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:33,456][root][INFO] - Training Epoch: 3/10, step 344/574 completed (loss: 2.450045108795166, acc: 0.3291139304637909)
[2024-11-29 03:16:33,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:34,046][root][INFO] - Training Epoch: 3/10, step 345/574 completed (loss: 2.046769618988037, acc: 0.37254902720451355)
[2024-11-29 03:16:34,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:34,640][root][INFO] - Training Epoch: 3/10, step 346/574 completed (loss: 2.375962018966675, acc: 0.4029850661754608)
[2024-11-29 03:16:34,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:35,227][root][INFO] - Training Epoch: 3/10, step 347/574 completed (loss: 0.33036044239997864, acc: 0.8999999761581421)
[2024-11-29 03:16:35,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:35,814][root][INFO] - Training Epoch: 3/10, step 348/574 completed (loss: 1.0009151697158813, acc: 0.800000011920929)
[2024-11-29 03:16:35,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:36,403][root][INFO] - Training Epoch: 3/10, step 349/574 completed (loss: 1.212742805480957, acc: 0.6666666865348816)
[2024-11-29 03:16:36,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:36,992][root][INFO] - Training Epoch: 3/10, step 350/574 completed (loss: 1.761392593383789, acc: 0.5348837375640869)
[2024-11-29 03:16:37,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:37,581][root][INFO] - Training Epoch: 3/10, step 351/574 completed (loss: 1.7365844249725342, acc: 0.5641025900840759)
[2024-11-29 03:16:37,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:38,173][root][INFO] - Training Epoch: 3/10, step 352/574 completed (loss: 2.0260751247406006, acc: 0.4000000059604645)
[2024-11-29 03:16:38,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:38,759][root][INFO] - Training Epoch: 3/10, step 353/574 completed (loss: 0.2634349465370178, acc: 0.9130434989929199)
[2024-11-29 03:16:38,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:39,345][root][INFO] - Training Epoch: 3/10, step 354/574 completed (loss: 1.8587006330490112, acc: 0.5)
[2024-11-29 03:16:39,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:39,939][root][INFO] - Training Epoch: 3/10, step 355/574 completed (loss: 2.5297152996063232, acc: 0.2967033088207245)
[2024-11-29 03:16:40,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:40,550][root][INFO] - Training Epoch: 3/10, step 356/574 completed (loss: 2.2301862239837646, acc: 0.426086962223053)
[2024-11-29 03:16:40,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:41,143][root][INFO] - Training Epoch: 3/10, step 357/574 completed (loss: 2.145235300064087, acc: 0.42391303181648254)
[2024-11-29 03:16:41,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:41,735][root][INFO] - Training Epoch: 3/10, step 358/574 completed (loss: 2.0698304176330566, acc: 0.4285714328289032)
[2024-11-29 03:16:41,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:42,321][root][INFO] - Training Epoch: 3/10, step 359/574 completed (loss: 0.10103263705968857, acc: 0.9583333134651184)
[2024-11-29 03:16:42,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:42,908][root][INFO] - Training Epoch: 3/10, step 360/574 completed (loss: 0.4321996569633484, acc: 0.8846153616905212)
[2024-11-29 03:16:42,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:43,500][root][INFO] - Training Epoch: 3/10, step 361/574 completed (loss: 1.2985402345657349, acc: 0.6341463327407837)
[2024-11-29 03:16:43,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:44,090][root][INFO] - Training Epoch: 3/10, step 362/574 completed (loss: 1.5823793411254883, acc: 0.6000000238418579)
[2024-11-29 03:16:44,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:44,685][root][INFO] - Training Epoch: 3/10, step 363/574 completed (loss: 2.2955305576324463, acc: 0.42105263471603394)
[2024-11-29 03:16:44,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:45,275][root][INFO] - Training Epoch: 3/10, step 364/574 completed (loss: 1.994687557220459, acc: 0.46341463923454285)
[2024-11-29 03:16:45,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:45,864][root][INFO] - Training Epoch: 3/10, step 365/574 completed (loss: 1.5577044486999512, acc: 0.5454545617103577)
[2024-11-29 03:16:45,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:46,451][root][INFO] - Training Epoch: 3/10, step 366/574 completed (loss: 0.09922084957361221, acc: 1.0)
[2024-11-29 03:16:46,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:47,038][root][INFO] - Training Epoch: 3/10, step 367/574 completed (loss: 0.029146511107683182, acc: 1.0)
[2024-11-29 03:16:47,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:47,625][root][INFO] - Training Epoch: 3/10, step 368/574 completed (loss: 0.5672286748886108, acc: 0.7857142686843872)
[2024-11-29 03:16:47,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:48,213][root][INFO] - Training Epoch: 3/10, step 369/574 completed (loss: 1.0307707786560059, acc: 0.71875)
[2024-11-29 03:16:48,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:48,826][root][INFO] - Training Epoch: 3/10, step 370/574 completed (loss: 2.5253119468688965, acc: 0.39393940567970276)
[2024-11-29 03:16:48,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:49,439][root][INFO] - Training Epoch: 3/10, step 371/574 completed (loss: 1.7581837177276611, acc: 0.5754716992378235)
[2024-11-29 03:16:49,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:50,032][root][INFO] - Training Epoch: 3/10, step 372/574 completed (loss: 1.9262083768844604, acc: 0.4555555582046509)
[2024-11-29 03:16:50,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:50,623][root][INFO] - Training Epoch: 3/10, step 373/574 completed (loss: 1.6754655838012695, acc: 0.625)
[2024-11-29 03:16:50,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:51,213][root][INFO] - Training Epoch: 3/10, step 374/574 completed (loss: 0.8422086238861084, acc: 0.7714285850524902)
[2024-11-29 03:16:51,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:51,800][root][INFO] - Training Epoch: 3/10, step 375/574 completed (loss: 0.24060025811195374, acc: 0.9200000166893005)
[2024-11-29 03:16:51,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:52,386][root][INFO] - Training Epoch: 3/10, step 376/574 completed (loss: 0.4570602774620056, acc: 0.8695651888847351)
[2024-11-29 03:16:52,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:52,977][root][INFO] - Training Epoch: 3/10, step 377/574 completed (loss: 1.8677488565444946, acc: 0.4791666567325592)
[2024-11-29 03:16:53,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:53,570][root][INFO] - Training Epoch: 3/10, step 378/574 completed (loss: 1.9850258827209473, acc: 0.4421052634716034)
[2024-11-29 03:16:53,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:54,180][root][INFO] - Training Epoch: 3/10, step 379/574 completed (loss: 2.0050601959228516, acc: 0.455089807510376)
[2024-11-29 03:16:54,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:54,775][root][INFO] - Training Epoch: 3/10, step 380/574 completed (loss: 1.7928919792175293, acc: 0.48120301961898804)
[2024-11-29 03:16:54,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:55,395][root][INFO] - Training Epoch: 3/10, step 381/574 completed (loss: 2.0754752159118652, acc: 0.4545454680919647)
[2024-11-29 03:16:55,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:56,005][root][INFO] - Training Epoch: 3/10, step 382/574 completed (loss: 1.5693243741989136, acc: 0.5855855941772461)
[2024-11-29 03:16:56,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:56,593][root][INFO] - Training Epoch: 3/10, step 383/574 completed (loss: 1.1169500350952148, acc: 0.75)
[2024-11-29 03:16:56,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:57,183][root][INFO] - Training Epoch: 3/10, step 384/574 completed (loss: 0.5720681548118591, acc: 0.8928571343421936)
[2024-11-29 03:16:57,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:57,771][root][INFO] - Training Epoch: 3/10, step 385/574 completed (loss: 1.1509029865264893, acc: 0.71875)
[2024-11-29 03:16:57,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:58,358][root][INFO] - Training Epoch: 3/10, step 386/574 completed (loss: 1.4225401878356934, acc: 0.6388888955116272)
[2024-11-29 03:16:58,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:58,946][root][INFO] - Training Epoch: 3/10, step 387/574 completed (loss: 1.0343527793884277, acc: 0.6842105388641357)
[2024-11-29 03:16:59,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:59,532][root][INFO] - Training Epoch: 3/10, step 388/574 completed (loss: 0.21044960618019104, acc: 0.9545454382896423)
[2024-11-29 03:16:59,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:00,117][root][INFO] - Training Epoch: 3/10, step 389/574 completed (loss: 0.35334834456443787, acc: 0.8999999761581421)
[2024-11-29 03:17:00,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:00,703][root][INFO] - Training Epoch: 3/10, step 390/574 completed (loss: 0.6101126074790955, acc: 0.8571428656578064)
[2024-11-29 03:17:00,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:01,291][root][INFO] - Training Epoch: 3/10, step 391/574 completed (loss: 2.0604844093322754, acc: 0.46296295523643494)
[2024-11-29 03:17:01,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:01,885][root][INFO] - Training Epoch: 3/10, step 392/574 completed (loss: 2.7051455974578857, acc: 0.35922330617904663)
[2024-11-29 03:17:01,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:02,499][root][INFO] - Training Epoch: 3/10, step 393/574 completed (loss: 2.264164924621582, acc: 0.4632352888584137)
[2024-11-29 03:17:02,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:03,096][root][INFO] - Training Epoch: 3/10, step 394/574 completed (loss: 2.66011118888855, acc: 0.3199999928474426)
[2024-11-29 03:17:03,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:03,692][root][INFO] - Training Epoch: 3/10, step 395/574 completed (loss: 2.393616199493408, acc: 0.3819444477558136)
[2024-11-29 03:17:03,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:04,282][root][INFO] - Training Epoch: 3/10, step 396/574 completed (loss: 1.8413056135177612, acc: 0.5813953280448914)
[2024-11-29 03:17:04,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:04,869][root][INFO] - Training Epoch: 3/10, step 397/574 completed (loss: 0.5911024808883667, acc: 0.7916666865348816)
[2024-11-29 03:17:04,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:05,457][root][INFO] - Training Epoch: 3/10, step 398/574 completed (loss: 1.5562056303024292, acc: 0.604651153087616)
[2024-11-29 03:17:05,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:06,043][root][INFO] - Training Epoch: 3/10, step 399/574 completed (loss: 1.2406315803527832, acc: 0.6399999856948853)
[2024-11-29 03:17:06,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:06,639][root][INFO] - Training Epoch: 3/10, step 400/574 completed (loss: 2.0051562786102295, acc: 0.5441176295280457)
[2024-11-29 03:17:06,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:07,230][root][INFO] - Training Epoch: 3/10, step 401/574 completed (loss: 1.8016711473464966, acc: 0.4933333396911621)
[2024-11-29 03:17:07,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:07,817][root][INFO] - Training Epoch: 3/10, step 402/574 completed (loss: 1.0764178037643433, acc: 0.7575757503509521)
[2024-11-29 03:17:07,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:08,405][root][INFO] - Training Epoch: 3/10, step 403/574 completed (loss: 1.3773459196090698, acc: 0.7272727489471436)
[2024-11-29 03:17:08,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:08,991][root][INFO] - Training Epoch: 3/10, step 404/574 completed (loss: 0.6176791191101074, acc: 0.8709677457809448)
[2024-11-29 03:17:09,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:09,578][root][INFO] - Training Epoch: 3/10, step 405/574 completed (loss: 0.8730537295341492, acc: 0.7777777910232544)
[2024-11-29 03:17:09,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:10,164][root][INFO] - Training Epoch: 3/10, step 406/574 completed (loss: 0.45744597911834717, acc: 0.8399999737739563)
[2024-11-29 03:17:10,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:10,752][root][INFO] - Training Epoch: 3/10, step 407/574 completed (loss: 0.6315637230873108, acc: 0.8611111044883728)
[2024-11-29 03:17:10,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:11,341][root][INFO] - Training Epoch: 3/10, step 408/574 completed (loss: 0.4621577560901642, acc: 0.9259259104728699)
[2024-11-29 03:17:11,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:11,929][root][INFO] - Training Epoch: 3/10, step 409/574 completed (loss: 0.3962355852127075, acc: 0.8461538553237915)
[2024-11-29 03:17:12,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:12,522][root][INFO] - Training Epoch: 3/10, step 410/574 completed (loss: 1.3409440517425537, acc: 0.6551724076271057)
[2024-11-29 03:17:12,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:13,109][root][INFO] - Training Epoch: 3/10, step 411/574 completed (loss: 0.6019284129142761, acc: 0.8928571343421936)
[2024-11-29 03:17:13,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:13,697][root][INFO] - Training Epoch: 3/10, step 412/574 completed (loss: 0.82075434923172, acc: 0.7666666507720947)
[2024-11-29 03:17:13,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:14,284][root][INFO] - Training Epoch: 3/10, step 413/574 completed (loss: 0.8952856659889221, acc: 0.7575757503509521)
[2024-11-29 03:17:14,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:14,872][root][INFO] - Training Epoch: 3/10, step 414/574 completed (loss: 0.4778755307197571, acc: 0.8636363744735718)
[2024-11-29 03:17:14,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:15,464][root][INFO] - Training Epoch: 3/10, step 415/574 completed (loss: 1.8028255701065063, acc: 0.5686274766921997)
[2024-11-29 03:17:15,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:16,049][root][INFO] - Training Epoch: 3/10, step 416/574 completed (loss: 1.1489698886871338, acc: 0.6538461446762085)
[2024-11-29 03:17:16,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:16,634][root][INFO] - Training Epoch: 3/10, step 417/574 completed (loss: 0.9185023903846741, acc: 0.8333333134651184)
[2024-11-29 03:17:16,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:17,226][root][INFO] - Training Epoch: 3/10, step 418/574 completed (loss: 1.4878796339035034, acc: 0.6000000238418579)
[2024-11-29 03:17:17,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:17,813][root][INFO] - Training Epoch: 3/10, step 419/574 completed (loss: 0.8138834834098816, acc: 0.800000011920929)
[2024-11-29 03:17:17,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:18,400][root][INFO] - Training Epoch: 3/10, step 420/574 completed (loss: 0.20127201080322266, acc: 0.9523809552192688)
[2024-11-29 03:17:18,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:18,987][root][INFO] - Training Epoch: 3/10, step 421/574 completed (loss: 0.7521349191665649, acc: 0.8333333134651184)
[2024-11-29 03:17:19,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:19,576][root][INFO] - Training Epoch: 3/10, step 422/574 completed (loss: 0.9247617721557617, acc: 0.84375)
[2024-11-29 03:17:19,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:20,163][root][INFO] - Training Epoch: 3/10, step 423/574 completed (loss: 1.3454549312591553, acc: 0.5833333134651184)
[2024-11-29 03:17:20,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:20,750][root][INFO] - Training Epoch: 3/10, step 424/574 completed (loss: 1.0343706607818604, acc: 0.6666666865348816)
[2024-11-29 03:17:21,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:21,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:22,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:22,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:23,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:24,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:24,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:25,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:25,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:26,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:26,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:27,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:27,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:28,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:28,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:29,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:29,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:30,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:30,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:31,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:31,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:32,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:33,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:33,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:34,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:34,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:35,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:35,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:36,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:36,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:37,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:37,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:38,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:38,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:39,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:39,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:40,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:40,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:41,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:41,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:42,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:43,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:43,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:44,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:44,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:45,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:45,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:46,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:46,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:47,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:47,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:48,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:48,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:49,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:49,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:50,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:50,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:51,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:51,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:52,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:53,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:53,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:54,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:54,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:55,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:55,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:56,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:56,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:57,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:57,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:58,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:58,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:59,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:00,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:00,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:01,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:01,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:02,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:02,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:03,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:03,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:04,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:04,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:05,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:05,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:06,675][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.3792, device='cuda:0') eval_epoch_loss=tensor(1.9987, device='cuda:0') eval_epoch_acc=tensor(0.5111, device='cuda:0')
[2024-11-29 03:18:06,679][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:18:06,679][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:18:06,911][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_3_step_425_loss_1.998669147491455/model.pt
[2024-11-29 03:18:07,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:07,521][root][INFO] - Training Epoch: 3/10, step 425/574 completed (loss: 0.5667296648025513, acc: 0.7878788113594055)
[2024-11-29 03:18:07,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:08,110][root][INFO] - Training Epoch: 3/10, step 426/574 completed (loss: 0.3714999258518219, acc: 0.95652174949646)
[2024-11-29 03:18:08,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:08,699][root][INFO] - Training Epoch: 3/10, step 427/574 completed (loss: 0.7078641653060913, acc: 0.8108108043670654)
[2024-11-29 03:18:08,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:09,290][root][INFO] - Training Epoch: 3/10, step 428/574 completed (loss: 0.5898286700248718, acc: 0.8148148059844971)
[2024-11-29 03:18:09,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:09,886][root][INFO] - Training Epoch: 3/10, step 429/574 completed (loss: 0.7430957555770874, acc: 0.782608687877655)
[2024-11-29 03:18:09,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:10,473][root][INFO] - Training Epoch: 3/10, step 430/574 completed (loss: 0.14328578114509583, acc: 0.9629629850387573)
[2024-11-29 03:18:10,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:11,059][root][INFO] - Training Epoch: 3/10, step 431/574 completed (loss: 0.09558413922786713, acc: 1.0)
[2024-11-29 03:18:11,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:11,645][root][INFO] - Training Epoch: 3/10, step 432/574 completed (loss: 0.37429195642471313, acc: 0.8695651888847351)
[2024-11-29 03:18:11,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:12,235][root][INFO] - Training Epoch: 3/10, step 433/574 completed (loss: 1.4915021657943726, acc: 0.6111111044883728)
[2024-11-29 03:18:12,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:12,823][root][INFO] - Training Epoch: 3/10, step 434/574 completed (loss: 0.17357425391674042, acc: 0.9599999785423279)
[2024-11-29 03:18:12,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:13,410][root][INFO] - Training Epoch: 3/10, step 435/574 completed (loss: 1.0707957744598389, acc: 0.6666666865348816)
[2024-11-29 03:18:13,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:13,997][root][INFO] - Training Epoch: 3/10, step 436/574 completed (loss: 1.233964443206787, acc: 0.6944444179534912)
[2024-11-29 03:18:14,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:14,589][root][INFO] - Training Epoch: 3/10, step 437/574 completed (loss: 1.2408331632614136, acc: 0.7272727489471436)
[2024-11-29 03:18:14,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:15,176][root][INFO] - Training Epoch: 3/10, step 438/574 completed (loss: 0.07892148941755295, acc: 0.9523809552192688)
[2024-11-29 03:18:15,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:15,767][root][INFO] - Training Epoch: 3/10, step 439/574 completed (loss: 1.7885708808898926, acc: 0.43589743971824646)
[2024-11-29 03:18:15,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:16,366][root][INFO] - Training Epoch: 3/10, step 440/574 completed (loss: 1.8597644567489624, acc: 0.560606062412262)
[2024-11-29 03:18:16,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:16,981][root][INFO] - Training Epoch: 3/10, step 441/574 completed (loss: 2.7634317874908447, acc: 0.31200000643730164)
[2024-11-29 03:18:17,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:17,578][root][INFO] - Training Epoch: 3/10, step 442/574 completed (loss: 2.2554423809051514, acc: 0.39516130089759827)
[2024-11-29 03:18:17,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:18,192][root][INFO] - Training Epoch: 3/10, step 443/574 completed (loss: 2.470188617706299, acc: 0.3681592047214508)
[2024-11-29 03:18:18,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:18,785][root][INFO] - Training Epoch: 3/10, step 444/574 completed (loss: 2.062981128692627, acc: 0.5094339847564697)
[2024-11-29 03:18:18,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:19,376][root][INFO] - Training Epoch: 3/10, step 445/574 completed (loss: 1.4123080968856812, acc: 0.5681818127632141)
[2024-11-29 03:18:19,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:19,964][root][INFO] - Training Epoch: 3/10, step 446/574 completed (loss: 0.45444363355636597, acc: 0.9130434989929199)
[2024-11-29 03:18:20,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:20,549][root][INFO] - Training Epoch: 3/10, step 447/574 completed (loss: 0.8783296942710876, acc: 0.807692289352417)
[2024-11-29 03:18:20,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:21,135][root][INFO] - Training Epoch: 3/10, step 448/574 completed (loss: 0.5173966884613037, acc: 0.8571428656578064)
[2024-11-29 03:18:21,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:21,724][root][INFO] - Training Epoch: 3/10, step 449/574 completed (loss: 2.359699249267578, acc: 0.4776119291782379)
[2024-11-29 03:18:21,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:22,316][root][INFO] - Training Epoch: 3/10, step 450/574 completed (loss: 1.8893018960952759, acc: 0.5833333134651184)
[2024-11-29 03:18:22,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:22,908][root][INFO] - Training Epoch: 3/10, step 451/574 completed (loss: 2.2454235553741455, acc: 0.3695652186870575)
[2024-11-29 03:18:22,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:23,500][root][INFO] - Training Epoch: 3/10, step 452/574 completed (loss: 2.412649393081665, acc: 0.3333333432674408)
[2024-11-29 03:18:23,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:24,091][root][INFO] - Training Epoch: 3/10, step 453/574 completed (loss: 2.1576154232025146, acc: 0.44736841320991516)
[2024-11-29 03:18:24,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:24,682][root][INFO] - Training Epoch: 3/10, step 454/574 completed (loss: 1.4951889514923096, acc: 0.6326530575752258)
[2024-11-29 03:18:24,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:25,269][root][INFO] - Training Epoch: 3/10, step 455/574 completed (loss: 0.8802252411842346, acc: 0.6969696879386902)
[2024-11-29 03:18:25,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:25,867][root][INFO] - Training Epoch: 3/10, step 456/574 completed (loss: 2.215913772583008, acc: 0.3711340129375458)
[2024-11-29 03:18:25,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:26,459][root][INFO] - Training Epoch: 3/10, step 457/574 completed (loss: 2.0552260875701904, acc: 0.5)
[2024-11-29 03:18:26,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:27,080][root][INFO] - Training Epoch: 3/10, step 458/574 completed (loss: 2.5752696990966797, acc: 0.3139534890651703)
[2024-11-29 03:18:27,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:27,668][root][INFO] - Training Epoch: 3/10, step 459/574 completed (loss: 2.1679463386535645, acc: 0.4464285671710968)
[2024-11-29 03:18:27,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:28,266][root][INFO] - Training Epoch: 3/10, step 460/574 completed (loss: 2.2123868465423584, acc: 0.395061731338501)
[2024-11-29 03:18:28,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:28,856][root][INFO] - Training Epoch: 3/10, step 461/574 completed (loss: 1.0981707572937012, acc: 0.6388888955116272)
[2024-11-29 03:18:28,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:29,445][root][INFO] - Training Epoch: 3/10, step 462/574 completed (loss: 1.0581802129745483, acc: 0.6875)
[2024-11-29 03:18:29,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:30,031][root][INFO] - Training Epoch: 3/10, step 463/574 completed (loss: 0.739405632019043, acc: 0.7307692170143127)
[2024-11-29 03:18:30,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:30,621][root][INFO] - Training Epoch: 3/10, step 464/574 completed (loss: 1.8106977939605713, acc: 0.54347825050354)
[2024-11-29 03:18:30,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:31,215][root][INFO] - Training Epoch: 3/10, step 465/574 completed (loss: 2.069298028945923, acc: 0.4166666567325592)
[2024-11-29 03:18:31,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:31,808][root][INFO] - Training Epoch: 3/10, step 466/574 completed (loss: 2.2334742546081543, acc: 0.4457831382751465)
[2024-11-29 03:18:31,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:32,418][root][INFO] - Training Epoch: 3/10, step 467/574 completed (loss: 2.0877346992492676, acc: 0.5045045018196106)
[2024-11-29 03:18:32,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:33,011][root][INFO] - Training Epoch: 3/10, step 468/574 completed (loss: 2.2045111656188965, acc: 0.4757281541824341)
[2024-11-29 03:18:33,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:33,623][root][INFO] - Training Epoch: 3/10, step 469/574 completed (loss: 2.3059544563293457, acc: 0.3333333432674408)
[2024-11-29 03:18:33,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:34,209][root][INFO] - Training Epoch: 3/10, step 470/574 completed (loss: 0.5966501832008362, acc: 0.9166666865348816)
[2024-11-29 03:18:34,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:34,795][root][INFO] - Training Epoch: 3/10, step 471/574 completed (loss: 1.3752915859222412, acc: 0.6428571343421936)
[2024-11-29 03:18:34,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:35,408][root][INFO] - Training Epoch: 3/10, step 472/574 completed (loss: 2.202152729034424, acc: 0.4019607901573181)
[2024-11-29 03:18:35,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:36,020][root][INFO] - Training Epoch: 3/10, step 473/574 completed (loss: 2.5833632946014404, acc: 0.3711790442466736)
[2024-11-29 03:18:36,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:36,612][root][INFO] - Training Epoch: 3/10, step 474/574 completed (loss: 2.1371028423309326, acc: 0.3645833432674408)
[2024-11-29 03:18:36,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:37,209][root][INFO] - Training Epoch: 3/10, step 475/574 completed (loss: 2.3770861625671387, acc: 0.3987730145454407)
[2024-11-29 03:18:37,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:37,806][root][INFO] - Training Epoch: 3/10, step 476/574 completed (loss: 2.4743993282318115, acc: 0.35971224308013916)
[2024-11-29 03:18:37,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:38,416][root][INFO] - Training Epoch: 3/10, step 477/574 completed (loss: 2.439178466796875, acc: 0.37688443064689636)
[2024-11-29 03:18:38,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:39,004][root][INFO] - Training Epoch: 3/10, step 478/574 completed (loss: 1.3463549613952637, acc: 0.6111111044883728)
[2024-11-29 03:18:39,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:39,593][root][INFO] - Training Epoch: 3/10, step 479/574 completed (loss: 1.109259009361267, acc: 0.6666666865348816)
[2024-11-29 03:18:39,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:40,183][root][INFO] - Training Epoch: 3/10, step 480/574 completed (loss: 0.5825724005699158, acc: 0.8148148059844971)
[2024-11-29 03:18:40,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:40,768][root][INFO] - Training Epoch: 3/10, step 481/574 completed (loss: 0.6325880289077759, acc: 0.8999999761581421)
[2024-11-29 03:18:40,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:41,354][root][INFO] - Training Epoch: 3/10, step 482/574 completed (loss: 0.5867980718612671, acc: 0.800000011920929)
[2024-11-29 03:18:41,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:41,949][root][INFO] - Training Epoch: 3/10, step 483/574 completed (loss: 1.5639772415161133, acc: 0.568965494632721)
[2024-11-29 03:18:42,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:42,536][root][INFO] - Training Epoch: 3/10, step 484/574 completed (loss: 0.596329927444458, acc: 0.8709677457809448)
[2024-11-29 03:18:42,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:43,124][root][INFO] - Training Epoch: 3/10, step 485/574 completed (loss: 0.31018194556236267, acc: 1.0)
[2024-11-29 03:18:43,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:43,714][root][INFO] - Training Epoch: 3/10, step 486/574 completed (loss: 1.4336985349655151, acc: 0.6296296119689941)
[2024-11-29 03:18:43,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:44,299][root][INFO] - Training Epoch: 3/10, step 487/574 completed (loss: 0.7074732184410095, acc: 0.7142857313156128)
[2024-11-29 03:18:44,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:44,886][root][INFO] - Training Epoch: 3/10, step 488/574 completed (loss: 0.9773866534233093, acc: 0.7272727489471436)
[2024-11-29 03:18:44,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:45,477][root][INFO] - Training Epoch: 3/10, step 489/574 completed (loss: 1.8087794780731201, acc: 0.5076923370361328)
[2024-11-29 03:18:45,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:46,064][root][INFO] - Training Epoch: 3/10, step 490/574 completed (loss: 0.3890516459941864, acc: 0.800000011920929)
[2024-11-29 03:18:46,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:46,651][root][INFO] - Training Epoch: 3/10, step 491/574 completed (loss: 0.997130811214447, acc: 0.7586206793785095)
[2024-11-29 03:18:46,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:47,240][root][INFO] - Training Epoch: 3/10, step 492/574 completed (loss: 2.0458199977874756, acc: 0.45098039507865906)
[2024-11-29 03:18:47,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:47,826][root][INFO] - Training Epoch: 3/10, step 493/574 completed (loss: 1.4691001176834106, acc: 0.5862069129943848)
[2024-11-29 03:18:47,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:48,412][root][INFO] - Training Epoch: 3/10, step 494/574 completed (loss: 0.5879365801811218, acc: 0.8421052694320679)
[2024-11-29 03:18:48,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:48,999][root][INFO] - Training Epoch: 3/10, step 495/574 completed (loss: 1.8309296369552612, acc: 0.42105263471603394)
[2024-11-29 03:18:49,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:49,595][root][INFO] - Training Epoch: 3/10, step 496/574 completed (loss: 2.415264129638672, acc: 0.3392857015132904)
[2024-11-29 03:18:49,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:50,189][root][INFO] - Training Epoch: 3/10, step 497/574 completed (loss: 2.1485366821289062, acc: 0.43820226192474365)
[2024-11-29 03:18:50,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:50,785][root][INFO] - Training Epoch: 3/10, step 498/574 completed (loss: 2.4501516819000244, acc: 0.3932584226131439)
[2024-11-29 03:18:50,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:51,394][root][INFO] - Training Epoch: 3/10, step 499/574 completed (loss: 2.5975329875946045, acc: 0.368794322013855)
[2024-11-29 03:18:51,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:51,991][root][INFO] - Training Epoch: 3/10, step 500/574 completed (loss: 2.609989643096924, acc: 0.32608696818351746)
[2024-11-29 03:18:52,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:52,577][root][INFO] - Training Epoch: 3/10, step 501/574 completed (loss: 0.45552608370780945, acc: 0.9200000166893005)
[2024-11-29 03:18:52,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:53,164][root][INFO] - Training Epoch: 3/10, step 502/574 completed (loss: 0.7042238712310791, acc: 0.8461538553237915)
[2024-11-29 03:18:53,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:53,750][root][INFO] - Training Epoch: 3/10, step 503/574 completed (loss: 0.49838337302207947, acc: 0.8888888955116272)
[2024-11-29 03:18:53,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:54,337][root][INFO] - Training Epoch: 3/10, step 504/574 completed (loss: 1.255773663520813, acc: 0.5925925970077515)
[2024-11-29 03:18:54,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:54,927][root][INFO] - Training Epoch: 3/10, step 505/574 completed (loss: 1.6606757640838623, acc: 0.5471698045730591)
[2024-11-29 03:18:55,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:55,515][root][INFO] - Training Epoch: 3/10, step 506/574 completed (loss: 0.8155120611190796, acc: 0.7931034564971924)
[2024-11-29 03:18:55,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:56,111][root][INFO] - Training Epoch: 3/10, step 507/574 completed (loss: 2.353255271911621, acc: 0.4144144058227539)
[2024-11-29 03:18:56,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:56,707][root][INFO] - Training Epoch: 3/10, step 508/574 completed (loss: 1.9795923233032227, acc: 0.5211267471313477)
[2024-11-29 03:18:56,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:57,292][root][INFO] - Training Epoch: 3/10, step 509/574 completed (loss: 0.14296409487724304, acc: 0.949999988079071)
[2024-11-29 03:18:57,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:57,879][root][INFO] - Training Epoch: 3/10, step 510/574 completed (loss: 0.33851709961891174, acc: 0.9333333373069763)
[2024-11-29 03:18:57,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:58,464][root][INFO] - Training Epoch: 3/10, step 511/574 completed (loss: 0.5780343413352966, acc: 0.807692289352417)
[2024-11-29 03:18:58,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:59,097][root][INFO] - Training Epoch: 3/10, step 512/574 completed (loss: 2.5210466384887695, acc: 0.3928571343421936)
[2024-11-29 03:18:59,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:59,708][root][INFO] - Training Epoch: 3/10, step 513/574 completed (loss: 2.389739513397217, acc: 0.3253968358039856)
[2024-11-29 03:18:59,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:00,297][root][INFO] - Training Epoch: 3/10, step 514/574 completed (loss: 0.7962493300437927, acc: 0.75)
[2024-11-29 03:19:00,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:00,890][root][INFO] - Training Epoch: 3/10, step 515/574 completed (loss: 1.6817281246185303, acc: 0.6000000238418579)
[2024-11-29 03:19:00,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:01,488][root][INFO] - Training Epoch: 3/10, step 516/574 completed (loss: 2.266650915145874, acc: 0.4305555522441864)
[2024-11-29 03:19:01,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:02,075][root][INFO] - Training Epoch: 3/10, step 517/574 completed (loss: 0.286042720079422, acc: 0.9230769276618958)
[2024-11-29 03:19:02,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:02,662][root][INFO] - Training Epoch: 3/10, step 518/574 completed (loss: 1.066674828529358, acc: 0.6451612710952759)
[2024-11-29 03:19:02,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:03,244][root][INFO] - Training Epoch: 3/10, step 519/574 completed (loss: 0.9394828677177429, acc: 0.75)
[2024-11-29 03:19:03,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:03,832][root][INFO] - Training Epoch: 3/10, step 520/574 completed (loss: 1.4406877756118774, acc: 0.5555555820465088)
[2024-11-29 03:19:03,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:04,581][root][INFO] - Training Epoch: 3/10, step 521/574 completed (loss: 2.6540842056274414, acc: 0.347457617521286)
[2024-11-29 03:19:04,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:05,207][root][INFO] - Training Epoch: 3/10, step 522/574 completed (loss: 2.1324024200439453, acc: 0.4776119291782379)
[2024-11-29 03:19:05,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:05,804][root][INFO] - Training Epoch: 3/10, step 523/574 completed (loss: 2.5056028366088867, acc: 0.41605839133262634)
[2024-11-29 03:19:05,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:06,425][root][INFO] - Training Epoch: 3/10, step 524/574 completed (loss: 2.322794198989868, acc: 0.4449999928474426)
[2024-11-29 03:19:06,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:07,018][root][INFO] - Training Epoch: 3/10, step 525/574 completed (loss: 2.050243616104126, acc: 0.5)
[2024-11-29 03:19:07,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:07,612][root][INFO] - Training Epoch: 3/10, step 526/574 completed (loss: 1.6730090379714966, acc: 0.5)
[2024-11-29 03:19:07,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:08,198][root][INFO] - Training Epoch: 3/10, step 527/574 completed (loss: 1.0174336433410645, acc: 0.6666666865348816)
[2024-11-29 03:19:08,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:08,793][root][INFO] - Training Epoch: 3/10, step 528/574 completed (loss: 2.579420566558838, acc: 0.26229506731033325)
[2024-11-29 03:19:08,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:09,384][root][INFO] - Training Epoch: 3/10, step 529/574 completed (loss: 1.8393399715423584, acc: 0.5423728823661804)
[2024-11-29 03:19:09,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:09,974][root][INFO] - Training Epoch: 3/10, step 530/574 completed (loss: 2.0692977905273438, acc: 0.4883720874786377)
[2024-11-29 03:19:10,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:10,563][root][INFO] - Training Epoch: 3/10, step 531/574 completed (loss: 2.07022762298584, acc: 0.40909090638160706)
[2024-11-29 03:19:10,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:11,156][root][INFO] - Training Epoch: 3/10, step 532/574 completed (loss: 2.0547618865966797, acc: 0.4528301954269409)
[2024-11-29 03:19:11,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:11,745][root][INFO] - Training Epoch: 3/10, step 533/574 completed (loss: 1.7832611799240112, acc: 0.6136363744735718)
[2024-11-29 03:19:11,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:12,335][root][INFO] - Training Epoch: 3/10, step 534/574 completed (loss: 0.9589211344718933, acc: 0.7200000286102295)
[2024-11-29 03:19:12,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:12,922][root][INFO] - Training Epoch: 3/10, step 535/574 completed (loss: 1.0865517854690552, acc: 0.800000011920929)
[2024-11-29 03:19:13,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:13,508][root][INFO] - Training Epoch: 3/10, step 536/574 completed (loss: 0.589743971824646, acc: 0.8181818127632141)
[2024-11-29 03:19:13,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:14,101][root][INFO] - Training Epoch: 3/10, step 537/574 completed (loss: 1.7847217321395874, acc: 0.5230769515037537)
[2024-11-29 03:19:14,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:14,696][root][INFO] - Training Epoch: 3/10, step 538/574 completed (loss: 1.985305905342102, acc: 0.46875)
[2024-11-29 03:19:14,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:15,284][root][INFO] - Training Epoch: 3/10, step 539/574 completed (loss: 1.254388689994812, acc: 0.5625)
[2024-11-29 03:19:15,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:15,873][root][INFO] - Training Epoch: 3/10, step 540/574 completed (loss: 1.425622582435608, acc: 0.6060606241226196)
[2024-11-29 03:19:15,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:16,458][root][INFO] - Training Epoch: 3/10, step 541/574 completed (loss: 0.49205639958381653, acc: 0.875)
[2024-11-29 03:19:16,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:17,045][root][INFO] - Training Epoch: 3/10, step 542/574 completed (loss: 0.5385350584983826, acc: 0.8064516186714172)
[2024-11-29 03:19:17,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:17,631][root][INFO] - Training Epoch: 3/10, step 543/574 completed (loss: 0.2189684510231018, acc: 0.9130434989929199)
[2024-11-29 03:19:17,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:18,218][root][INFO] - Training Epoch: 3/10, step 544/574 completed (loss: 0.8949695825576782, acc: 0.6666666865348816)
[2024-11-29 03:19:18,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:18,806][root][INFO] - Training Epoch: 3/10, step 545/574 completed (loss: 1.2086544036865234, acc: 0.5853658318519592)
[2024-11-29 03:19:18,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:19,398][root][INFO] - Training Epoch: 3/10, step 546/574 completed (loss: 1.121301531791687, acc: 0.6571428775787354)
[2024-11-29 03:19:19,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:19,992][root][INFO] - Training Epoch: 3/10, step 547/574 completed (loss: 1.2579809427261353, acc: 0.6842105388641357)
[2024-11-29 03:19:20,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:20,580][root][INFO] - Training Epoch: 3/10, step 548/574 completed (loss: 0.9066203236579895, acc: 0.7419354915618896)
[2024-11-29 03:19:20,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:21,165][root][INFO] - Training Epoch: 3/10, step 549/574 completed (loss: 0.6793816089630127, acc: 0.7599999904632568)
[2024-11-29 03:19:21,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:21,753][root][INFO] - Training Epoch: 3/10, step 550/574 completed (loss: 0.6608767509460449, acc: 0.8484848737716675)
[2024-11-29 03:19:21,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:22,343][root][INFO] - Training Epoch: 3/10, step 551/574 completed (loss: 1.0031702518463135, acc: 0.6000000238418579)
[2024-11-29 03:19:22,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:22,936][root][INFO] - Training Epoch: 3/10, step 552/574 completed (loss: 1.3361976146697998, acc: 0.5857142806053162)
[2024-11-29 03:19:23,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:23,545][root][INFO] - Training Epoch: 3/10, step 553/574 completed (loss: 2.4799416065216064, acc: 0.32116788625717163)
[2024-11-29 03:19:23,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:24,154][root][INFO] - Training Epoch: 3/10, step 554/574 completed (loss: 2.1389641761779785, acc: 0.40689656138420105)
[2024-11-29 03:19:24,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:24,750][root][INFO] - Training Epoch: 3/10, step 555/574 completed (loss: 2.796149730682373, acc: 0.2571428716182709)
[2024-11-29 03:19:24,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:25,346][root][INFO] - Training Epoch: 3/10, step 556/574 completed (loss: 2.7143442630767822, acc: 0.21854305267333984)
[2024-11-29 03:19:25,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:25,942][root][INFO] - Training Epoch: 3/10, step 557/574 completed (loss: 2.3340516090393066, acc: 0.3504273593425751)
[2024-11-29 03:19:26,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:26,529][root][INFO] - Training Epoch: 3/10, step 558/574 completed (loss: 0.3178500831127167, acc: 0.8799999952316284)
[2024-11-29 03:19:26,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:27,116][root][INFO] - Training Epoch: 3/10, step 559/574 completed (loss: 0.7563819289207458, acc: 0.807692289352417)
[2024-11-29 03:19:27,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:27,702][root][INFO] - Training Epoch: 3/10, step 560/574 completed (loss: 0.7727091312408447, acc: 0.7692307829856873)
[2024-11-29 03:19:27,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:28,293][root][INFO] - Training Epoch: 3/10, step 561/574 completed (loss: 1.5622756481170654, acc: 0.5384615659713745)
[2024-11-29 03:19:28,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:28,901][root][INFO] - Training Epoch: 3/10, step 562/574 completed (loss: 1.943092703819275, acc: 0.4888888895511627)
[2024-11-29 03:19:28,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:29,492][root][INFO] - Training Epoch: 3/10, step 563/574 completed (loss: 2.0489096641540527, acc: 0.4025973975658417)
[2024-11-29 03:19:29,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:30,080][root][INFO] - Training Epoch: 3/10, step 564/574 completed (loss: 1.7328171730041504, acc: 0.6041666865348816)
[2024-11-29 03:19:30,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:30,670][root][INFO] - Training Epoch: 3/10, step 565/574 completed (loss: 1.8281760215759277, acc: 0.48275861144065857)
[2024-11-29 03:19:30,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:31,265][root][INFO] - Training Epoch: 3/10, step 566/574 completed (loss: 1.9989620447158813, acc: 0.4404761791229248)
[2024-11-29 03:19:31,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:31,852][root][INFO] - Training Epoch: 3/10, step 567/574 completed (loss: 1.0599066019058228, acc: 0.6842105388641357)
[2024-11-29 03:19:32,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:33,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:33,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:34,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:34,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:35,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:35,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:36,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:36,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:37,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:37,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:38,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:39,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:39,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:40,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:40,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:41,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:41,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:42,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:42,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:43,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:43,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:44,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:44,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:45,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:45,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:46,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:46,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:47,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:47,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:48,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:49,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:49,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:50,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:50,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:51,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:51,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:52,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:52,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:53,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:53,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:54,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:54,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:55,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:55,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:56,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:57,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:57,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:58,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:58,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:59,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:59,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:00,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:00,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:01,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:01,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:02,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:02,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:03,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:03,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:04,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:05,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:05,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:06,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:06,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:07,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:07,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:08,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:08,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:09,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:09,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:10,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:10,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:11,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:11,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:12,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:12,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:13,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:14,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:14,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:15,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:15,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:16,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:16,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:17,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:17,972][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.7195, device='cuda:0') eval_epoch_loss=tensor(1.7439, device='cuda:0') eval_epoch_acc=tensor(0.5489, device='cuda:0')
[2024-11-29 03:20:17,973][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:20:17,973][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:20:18,184][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_3_step_568_loss_1.743873953819275/model.pt
[2024-11-29 03:20:18,189][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.743873953819275
[2024-11-29 03:20:18,189][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.5488764047622681
[2024-11-29 03:20:18,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:18,793][root][INFO] - Training Epoch: 3/10, step 568/574 completed (loss: 0.7714523077011108, acc: 0.8148148059844971)
[2024-11-29 03:20:18,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:19,418][root][INFO] - Training Epoch: 3/10, step 569/574 completed (loss: 2.3857626914978027, acc: 0.4010695219039917)
[2024-11-29 03:20:19,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:20,010][root][INFO] - Training Epoch: 3/10, step 570/574 completed (loss: 1.4732898473739624, acc: 0.5806451439857483)
[2024-11-29 03:20:20,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:20,607][root][INFO] - Training Epoch: 3/10, step 571/574 completed (loss: 2.40683913230896, acc: 0.3504273593425751)
[2024-11-29 03:20:20,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:21,218][root][INFO] - Training Epoch: 3/10, step 572/574 completed (loss: 2.7769508361816406, acc: 0.25)
[2024-11-29 03:20:21,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:21,830][root][INFO] - Training Epoch: 3/10, step 573/574 completed (loss: 2.508946418762207, acc: 0.29559749364852905)
[2024-11-29 03:20:22,146][slam_llm.utils.train_utils][INFO] - Epoch 3: train_perplexity=5.2605, train_epoch_loss=1.6602, epoch time 527.5871797483414s
[2024-11-29 03:20:22,146][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 15 GB
[2024-11-29 03:20:22,146][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-29 03:20:22,146][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 15 GB
[2024-11-29 03:20:22,146][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 3
[2024-11-29 03:20:22,146][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-29 03:20:22,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:23,141][root][INFO] - Training Epoch: 4/10, step 0/574 completed (loss: 1.14530611038208, acc: 0.6666666865348816)
[2024-11-29 03:20:23,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:23,727][root][INFO] - Training Epoch: 4/10, step 1/574 completed (loss: 1.4604806900024414, acc: 0.7200000286102295)
[2024-11-29 03:20:23,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:24,315][root][INFO] - Training Epoch: 4/10, step 2/574 completed (loss: 1.6568429470062256, acc: 0.5945945978164673)
[2024-11-29 03:20:24,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:24,903][root][INFO] - Training Epoch: 4/10, step 3/574 completed (loss: 1.740639567375183, acc: 0.5263158082962036)
[2024-11-29 03:20:24,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:25,490][root][INFO] - Training Epoch: 4/10, step 4/574 completed (loss: 1.5639439821243286, acc: 0.6756756901741028)
[2024-11-29 03:20:25,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:26,078][root][INFO] - Training Epoch: 4/10, step 5/574 completed (loss: 1.0897536277770996, acc: 0.6428571343421936)
[2024-11-29 03:20:26,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:26,667][root][INFO] - Training Epoch: 4/10, step 6/574 completed (loss: 1.8429900407791138, acc: 0.5510203838348389)
[2024-11-29 03:20:26,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:27,254][root][INFO] - Training Epoch: 4/10, step 7/574 completed (loss: 1.007171392440796, acc: 0.7333333492279053)
[2024-11-29 03:20:27,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:27,841][root][INFO] - Training Epoch: 4/10, step 8/574 completed (loss: 0.06532730907201767, acc: 1.0)
[2024-11-29 03:20:27,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:28,428][root][INFO] - Training Epoch: 4/10, step 9/574 completed (loss: 0.28243526816368103, acc: 0.9615384340286255)
[2024-11-29 03:20:28,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:29,016][root][INFO] - Training Epoch: 4/10, step 10/574 completed (loss: 0.4198320209980011, acc: 0.8518518805503845)
[2024-11-29 03:20:29,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:29,605][root][INFO] - Training Epoch: 4/10, step 11/574 completed (loss: 1.8036450147628784, acc: 0.5128205418586731)
[2024-11-29 03:20:29,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:30,192][root][INFO] - Training Epoch: 4/10, step 12/574 completed (loss: 0.9887362122535706, acc: 0.6969696879386902)
[2024-11-29 03:20:30,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:30,780][root][INFO] - Training Epoch: 4/10, step 13/574 completed (loss: 1.4874534606933594, acc: 0.54347825050354)
[2024-11-29 03:20:30,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:31,368][root][INFO] - Training Epoch: 4/10, step 14/574 completed (loss: 1.664675235748291, acc: 0.5686274766921997)
[2024-11-29 03:20:31,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:31,960][root][INFO] - Training Epoch: 4/10, step 15/574 completed (loss: 1.5201634168624878, acc: 0.5306122303009033)
[2024-11-29 03:20:32,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:32,546][root][INFO] - Training Epoch: 4/10, step 16/574 completed (loss: 0.11897547543048859, acc: 1.0)
[2024-11-29 03:20:32,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:33,134][root][INFO] - Training Epoch: 4/10, step 17/574 completed (loss: 0.6047255992889404, acc: 0.8333333134651184)
[2024-11-29 03:20:33,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:33,721][root][INFO] - Training Epoch: 4/10, step 18/574 completed (loss: 1.6477856636047363, acc: 0.5277777910232544)
[2024-11-29 03:20:33,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:34,309][root][INFO] - Training Epoch: 4/10, step 19/574 completed (loss: 0.5831964612007141, acc: 0.8421052694320679)
[2024-11-29 03:20:34,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:34,895][root][INFO] - Training Epoch: 4/10, step 20/574 completed (loss: 0.7529872059822083, acc: 0.8461538553237915)
[2024-11-29 03:20:34,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:35,482][root][INFO] - Training Epoch: 4/10, step 21/574 completed (loss: 1.1265699863433838, acc: 0.6206896305084229)
[2024-11-29 03:20:35,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:36,070][root][INFO] - Training Epoch: 4/10, step 22/574 completed (loss: 0.9316038489341736, acc: 0.7200000286102295)
[2024-11-29 03:20:36,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:36,656][root][INFO] - Training Epoch: 4/10, step 23/574 completed (loss: 0.7475926876068115, acc: 0.761904776096344)
[2024-11-29 03:20:36,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:37,241][root][INFO] - Training Epoch: 4/10, step 24/574 completed (loss: 0.5506797432899475, acc: 0.8125)
[2024-11-29 03:20:37,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:37,833][root][INFO] - Training Epoch: 4/10, step 25/574 completed (loss: 2.0375025272369385, acc: 0.4528301954269409)
[2024-11-29 03:20:37,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:38,421][root][INFO] - Training Epoch: 4/10, step 26/574 completed (loss: 2.307983875274658, acc: 0.39726027846336365)
[2024-11-29 03:20:38,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:39,093][root][INFO] - Training Epoch: 4/10, step 27/574 completed (loss: 2.715515375137329, acc: 0.2924901247024536)
[2024-11-29 03:20:39,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:39,682][root][INFO] - Training Epoch: 4/10, step 28/574 completed (loss: 2.116685628890991, acc: 0.39534884691238403)
[2024-11-29 03:20:39,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:40,275][root][INFO] - Training Epoch: 4/10, step 29/574 completed (loss: 2.0802290439605713, acc: 0.46987950801849365)
[2024-11-29 03:20:40,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:40,873][root][INFO] - Training Epoch: 4/10, step 30/574 completed (loss: 2.157811403274536, acc: 0.37037035822868347)
[2024-11-29 03:20:40,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:41,461][root][INFO] - Training Epoch: 4/10, step 31/574 completed (loss: 1.641422152519226, acc: 0.5714285969734192)
[2024-11-29 03:20:41,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:42,047][root][INFO] - Training Epoch: 4/10, step 32/574 completed (loss: 0.6704218983650208, acc: 0.8148148059844971)
[2024-11-29 03:20:42,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:42,635][root][INFO] - Training Epoch: 4/10, step 33/574 completed (loss: 0.6672042012214661, acc: 0.8260869383811951)
[2024-11-29 03:20:42,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:43,232][root][INFO] - Training Epoch: 4/10, step 34/574 completed (loss: 2.167771339416504, acc: 0.4285714328289032)
[2024-11-29 03:20:43,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:43,823][root][INFO] - Training Epoch: 4/10, step 35/574 completed (loss: 1.8811191320419312, acc: 0.5245901346206665)
[2024-11-29 03:20:43,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:44,416][root][INFO] - Training Epoch: 4/10, step 36/574 completed (loss: 1.737251877784729, acc: 0.523809552192688)
[2024-11-29 03:20:44,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:45,004][root][INFO] - Training Epoch: 4/10, step 37/574 completed (loss: 2.0770506858825684, acc: 0.4576271176338196)
[2024-11-29 03:20:45,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:45,597][root][INFO] - Training Epoch: 4/10, step 38/574 completed (loss: 1.821507453918457, acc: 0.49425286054611206)
[2024-11-29 03:20:45,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:46,185][root][INFO] - Training Epoch: 4/10, step 39/574 completed (loss: 0.359351247549057, acc: 0.9523809552192688)
[2024-11-29 03:20:46,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:46,773][root][INFO] - Training Epoch: 4/10, step 40/574 completed (loss: 0.9852247834205627, acc: 0.7692307829856873)
[2024-11-29 03:20:46,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:47,368][root][INFO] - Training Epoch: 4/10, step 41/574 completed (loss: 2.3555073738098145, acc: 0.45945945382118225)
[2024-11-29 03:20:47,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:47,959][root][INFO] - Training Epoch: 4/10, step 42/574 completed (loss: 1.7372090816497803, acc: 0.6307692527770996)
[2024-11-29 03:20:48,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:48,558][root][INFO] - Training Epoch: 4/10, step 43/574 completed (loss: 2.225665807723999, acc: 0.46464645862579346)
[2024-11-29 03:20:48,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:49,153][root][INFO] - Training Epoch: 4/10, step 44/574 completed (loss: 1.871005654335022, acc: 0.5773195624351501)
[2024-11-29 03:20:49,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:49,752][root][INFO] - Training Epoch: 4/10, step 45/574 completed (loss: 2.276308059692383, acc: 0.40441176295280457)
[2024-11-29 03:20:49,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:50,337][root][INFO] - Training Epoch: 4/10, step 46/574 completed (loss: 0.27363353967666626, acc: 0.9230769276618958)
[2024-11-29 03:20:50,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:50,923][root][INFO] - Training Epoch: 4/10, step 47/574 completed (loss: 0.1890123337507248, acc: 0.9629629850387573)
[2024-11-29 03:20:51,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:51,509][root][INFO] - Training Epoch: 4/10, step 48/574 completed (loss: 0.7831206917762756, acc: 0.7142857313156128)
[2024-11-29 03:20:51,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:52,096][root][INFO] - Training Epoch: 4/10, step 49/574 completed (loss: 0.7906177639961243, acc: 0.8055555820465088)
[2024-11-29 03:20:52,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:52,685][root][INFO] - Training Epoch: 4/10, step 50/574 completed (loss: 1.4015438556671143, acc: 0.5964912176132202)
[2024-11-29 03:20:52,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:53,280][root][INFO] - Training Epoch: 4/10, step 51/574 completed (loss: 1.6321660280227661, acc: 0.4920634925365448)
[2024-11-29 03:20:53,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:53,874][root][INFO] - Training Epoch: 4/10, step 52/574 completed (loss: 1.9404109716415405, acc: 0.4647887349128723)
[2024-11-29 03:20:53,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:54,486][root][INFO] - Training Epoch: 4/10, step 53/574 completed (loss: 2.760249137878418, acc: 0.3466666638851166)
[2024-11-29 03:20:54,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:55,071][root][INFO] - Training Epoch: 4/10, step 54/574 completed (loss: 1.046633243560791, acc: 0.7567567825317383)
[2024-11-29 03:20:55,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:55,658][root][INFO] - Training Epoch: 4/10, step 55/574 completed (loss: 0.26191040873527527, acc: 0.9230769276618958)
[2024-11-29 03:20:55,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:56,360][root][INFO] - Training Epoch: 4/10, step 56/574 completed (loss: 2.3892385959625244, acc: 0.4266211688518524)
[2024-11-29 03:20:56,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:57,013][root][INFO] - Training Epoch: 4/10, step 57/574 completed (loss: 2.769353151321411, acc: 0.3311546742916107)
[2024-11-29 03:20:57,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:57,629][root][INFO] - Training Epoch: 4/10, step 58/574 completed (loss: 2.174410343170166, acc: 0.4375)
[2024-11-29 03:20:57,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:58,225][root][INFO] - Training Epoch: 4/10, step 59/574 completed (loss: 2.6071436405181885, acc: 0.375)
[2024-11-29 03:20:58,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:58,838][root][INFO] - Training Epoch: 4/10, step 60/574 completed (loss: 2.2407989501953125, acc: 0.3840579688549042)
[2024-11-29 03:20:58,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:59,447][root][INFO] - Training Epoch: 4/10, step 61/574 completed (loss: 1.8720972537994385, acc: 0.5625)
[2024-11-29 03:20:59,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:00,034][root][INFO] - Training Epoch: 4/10, step 62/574 completed (loss: 1.06899893283844, acc: 0.7352941036224365)
[2024-11-29 03:21:00,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:00,622][root][INFO] - Training Epoch: 4/10, step 63/574 completed (loss: 1.2458029985427856, acc: 0.6111111044883728)
[2024-11-29 03:21:00,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:01,221][root][INFO] - Training Epoch: 4/10, step 64/574 completed (loss: 1.5974862575531006, acc: 0.578125)
[2024-11-29 03:21:01,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:01,808][root][INFO] - Training Epoch: 4/10, step 65/574 completed (loss: 0.5151551365852356, acc: 0.8620689511299133)
[2024-11-29 03:21:01,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:02,399][root][INFO] - Training Epoch: 4/10, step 66/574 completed (loss: 1.7585020065307617, acc: 0.5)
[2024-11-29 03:21:02,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:02,988][root][INFO] - Training Epoch: 4/10, step 67/574 completed (loss: 1.9354382753372192, acc: 0.44999998807907104)
[2024-11-29 03:21:03,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:03,575][root][INFO] - Training Epoch: 4/10, step 68/574 completed (loss: 0.3954923748970032, acc: 0.8399999737739563)
[2024-11-29 03:21:03,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:04,163][root][INFO] - Training Epoch: 4/10, step 69/574 completed (loss: 0.878197968006134, acc: 0.75)
[2024-11-29 03:21:04,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:04,751][root][INFO] - Training Epoch: 4/10, step 70/574 completed (loss: 1.0524752140045166, acc: 0.7878788113594055)
[2024-11-29 03:21:04,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:05,361][root][INFO] - Training Epoch: 4/10, step 71/574 completed (loss: 2.31245493888855, acc: 0.4117647111415863)
[2024-11-29 03:21:05,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:05,956][root][INFO] - Training Epoch: 4/10, step 72/574 completed (loss: 2.154627561569214, acc: 0.4126984179019928)
[2024-11-29 03:21:06,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:06,569][root][INFO] - Training Epoch: 4/10, step 73/574 completed (loss: 2.6136181354522705, acc: 0.34358975291252136)
[2024-11-29 03:21:06,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:07,164][root][INFO] - Training Epoch: 4/10, step 74/574 completed (loss: 2.0514118671417236, acc: 0.4591836631298065)
[2024-11-29 03:21:07,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:07,761][root][INFO] - Training Epoch: 4/10, step 75/574 completed (loss: 2.585026264190674, acc: 0.29104477167129517)
[2024-11-29 03:21:07,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:08,386][root][INFO] - Training Epoch: 4/10, step 76/574 completed (loss: 2.5691111087799072, acc: 0.3759123980998993)
[2024-11-29 03:21:08,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:08,971][root][INFO] - Training Epoch: 4/10, step 77/574 completed (loss: 0.2784448266029358, acc: 0.9523809552192688)
[2024-11-29 03:21:09,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:09,557][root][INFO] - Training Epoch: 4/10, step 78/574 completed (loss: 0.16659694910049438, acc: 1.0)
[2024-11-29 03:21:09,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:10,144][root][INFO] - Training Epoch: 4/10, step 79/574 completed (loss: 0.6274350881576538, acc: 0.8787878751754761)
[2024-11-29 03:21:10,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:10,731][root][INFO] - Training Epoch: 4/10, step 80/574 completed (loss: 0.20976904034614563, acc: 0.9230769276618958)
[2024-11-29 03:21:10,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:11,323][root][INFO] - Training Epoch: 4/10, step 81/574 completed (loss: 1.8928083181381226, acc: 0.5384615659713745)
[2024-11-29 03:21:11,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:11,916][root][INFO] - Training Epoch: 4/10, step 82/574 completed (loss: 2.1267526149749756, acc: 0.4615384638309479)
[2024-11-29 03:21:11,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:12,502][root][INFO] - Training Epoch: 4/10, step 83/574 completed (loss: 0.8702244758605957, acc: 0.78125)
[2024-11-29 03:21:12,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:13,094][root][INFO] - Training Epoch: 4/10, step 84/574 completed (loss: 1.6094660758972168, acc: 0.5942028760910034)
[2024-11-29 03:21:13,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:13,685][root][INFO] - Training Epoch: 4/10, step 85/574 completed (loss: 1.3475403785705566, acc: 0.6600000262260437)
[2024-11-29 03:21:13,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:14,272][root][INFO] - Training Epoch: 4/10, step 86/574 completed (loss: 0.5027469396591187, acc: 0.8260869383811951)
[2024-11-29 03:21:14,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:14,865][root][INFO] - Training Epoch: 4/10, step 87/574 completed (loss: 1.7734814882278442, acc: 0.5600000023841858)
[2024-11-29 03:21:14,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:15,462][root][INFO] - Training Epoch: 4/10, step 88/574 completed (loss: 1.939928412437439, acc: 0.5145630836486816)
[2024-11-29 03:21:15,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:16,074][root][INFO] - Training Epoch: 4/10, step 89/574 completed (loss: 2.168546676635742, acc: 0.446601927280426)
[2024-11-29 03:21:16,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:16,687][root][INFO] - Training Epoch: 4/10, step 90/574 completed (loss: 2.3921353816986084, acc: 0.3978494703769684)
[2024-11-29 03:21:16,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:17,308][root][INFO] - Training Epoch: 4/10, step 91/574 completed (loss: 2.132058620452881, acc: 0.5)
[2024-11-29 03:21:17,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:17,905][root][INFO] - Training Epoch: 4/10, step 92/574 completed (loss: 1.8396555185317993, acc: 0.5052631497383118)
[2024-11-29 03:21:17,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:18,522][root][INFO] - Training Epoch: 4/10, step 93/574 completed (loss: 2.5250184535980225, acc: 0.3366336524486542)
[2024-11-29 03:21:18,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:19,117][root][INFO] - Training Epoch: 4/10, step 94/574 completed (loss: 2.151778221130371, acc: 0.4354838728904724)
[2024-11-29 03:21:19,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:19,709][root][INFO] - Training Epoch: 4/10, step 95/574 completed (loss: 1.898436427116394, acc: 0.4492753744125366)
[2024-11-29 03:21:19,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:20,306][root][INFO] - Training Epoch: 4/10, step 96/574 completed (loss: 2.3681797981262207, acc: 0.3529411852359772)
[2024-11-29 03:21:20,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:20,901][root][INFO] - Training Epoch: 4/10, step 97/574 completed (loss: 2.3839335441589355, acc: 0.4134615361690521)
[2024-11-29 03:21:20,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:21,499][root][INFO] - Training Epoch: 4/10, step 98/574 completed (loss: 2.4914042949676514, acc: 0.32846716046333313)
[2024-11-29 03:21:21,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:22,095][root][INFO] - Training Epoch: 4/10, step 99/574 completed (loss: 2.2809219360351562, acc: 0.41791045665740967)
[2024-11-29 03:21:22,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:22,682][root][INFO] - Training Epoch: 4/10, step 100/574 completed (loss: 0.5650539994239807, acc: 0.800000011920929)
[2024-11-29 03:21:22,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:23,267][root][INFO] - Training Epoch: 4/10, step 101/574 completed (loss: 0.06242493540048599, acc: 1.0)
[2024-11-29 03:21:23,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:23,854][root][INFO] - Training Epoch: 4/10, step 102/574 completed (loss: 0.33814775943756104, acc: 0.9130434989929199)
[2024-11-29 03:21:23,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:24,442][root][INFO] - Training Epoch: 4/10, step 103/574 completed (loss: 0.795240581035614, acc: 0.75)
[2024-11-29 03:21:24,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:25,034][root][INFO] - Training Epoch: 4/10, step 104/574 completed (loss: 1.7019076347351074, acc: 0.517241358757019)
[2024-11-29 03:21:25,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:25,623][root][INFO] - Training Epoch: 4/10, step 105/574 completed (loss: 1.137260913848877, acc: 0.6511628031730652)
[2024-11-29 03:21:25,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:26,210][root][INFO] - Training Epoch: 4/10, step 106/574 completed (loss: 0.41689664125442505, acc: 0.8399999737739563)
[2024-11-29 03:21:26,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:26,794][root][INFO] - Training Epoch: 4/10, step 107/574 completed (loss: 0.024166565388441086, acc: 1.0)
[2024-11-29 03:21:26,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:27,380][root][INFO] - Training Epoch: 4/10, step 108/574 completed (loss: 0.045588694512844086, acc: 1.0)
[2024-11-29 03:21:27,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:27,969][root][INFO] - Training Epoch: 4/10, step 109/574 completed (loss: 1.2314454317092896, acc: 0.5952380895614624)
[2024-11-29 03:21:28,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:28,559][root][INFO] - Training Epoch: 4/10, step 110/574 completed (loss: 1.8552591800689697, acc: 0.5076923370361328)
[2024-11-29 03:21:28,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:29,149][root][INFO] - Training Epoch: 4/10, step 111/574 completed (loss: 2.0301177501678467, acc: 0.45614033937454224)
[2024-11-29 03:21:29,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:29,740][root][INFO] - Training Epoch: 4/10, step 112/574 completed (loss: 1.8330786228179932, acc: 0.5087719559669495)
[2024-11-29 03:21:29,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:30,327][root][INFO] - Training Epoch: 4/10, step 113/574 completed (loss: 1.4728933572769165, acc: 0.5641025900840759)
[2024-11-29 03:21:30,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:30,918][root][INFO] - Training Epoch: 4/10, step 114/574 completed (loss: 1.4100301265716553, acc: 0.6122449040412903)
[2024-11-29 03:21:30,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:31,503][root][INFO] - Training Epoch: 4/10, step 115/574 completed (loss: 0.06687337905168533, acc: 1.0)
[2024-11-29 03:21:31,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:32,099][root][INFO] - Training Epoch: 4/10, step 116/574 completed (loss: 1.8753498792648315, acc: 0.5555555820465088)
[2024-11-29 03:21:32,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:32,691][root][INFO] - Training Epoch: 4/10, step 117/574 completed (loss: 2.1450388431549072, acc: 0.49593496322631836)
[2024-11-29 03:21:32,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:33,285][root][INFO] - Training Epoch: 4/10, step 118/574 completed (loss: 1.7775862216949463, acc: 0.6129032373428345)
[2024-11-29 03:21:33,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:33,924][root][INFO] - Training Epoch: 4/10, step 119/574 completed (loss: 2.514906167984009, acc: 0.3764258623123169)
[2024-11-29 03:21:34,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:34,518][root][INFO] - Training Epoch: 4/10, step 120/574 completed (loss: 1.5440837144851685, acc: 0.5733333230018616)
[2024-11-29 03:21:34,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:35,112][root][INFO] - Training Epoch: 4/10, step 121/574 completed (loss: 1.4470022916793823, acc: 0.5769230723381042)
[2024-11-29 03:21:35,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:35,697][root][INFO] - Training Epoch: 4/10, step 122/574 completed (loss: 0.37856248021125793, acc: 0.9166666865348816)
[2024-11-29 03:21:35,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:36,282][root][INFO] - Training Epoch: 4/10, step 123/574 completed (loss: 0.3035159707069397, acc: 0.9473684430122375)
[2024-11-29 03:21:36,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:36,880][root][INFO] - Training Epoch: 4/10, step 124/574 completed (loss: 2.338189125061035, acc: 0.349693238735199)
[2024-11-29 03:21:36,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:37,493][root][INFO] - Training Epoch: 4/10, step 125/574 completed (loss: 2.183849811553955, acc: 0.4097222089767456)
[2024-11-29 03:21:37,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:38,088][root][INFO] - Training Epoch: 4/10, step 126/574 completed (loss: 2.35481595993042, acc: 0.36666667461395264)
[2024-11-29 03:21:38,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:38,710][root][INFO] - Training Epoch: 4/10, step 127/574 completed (loss: 2.2787508964538574, acc: 0.369047611951828)
[2024-11-29 03:21:38,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:39,324][root][INFO] - Training Epoch: 4/10, step 128/574 completed (loss: 2.309004306793213, acc: 0.4256410300731659)
[2024-11-29 03:21:39,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:39,947][root][INFO] - Training Epoch: 4/10, step 129/574 completed (loss: 2.0284929275512695, acc: 0.4852941036224365)
[2024-11-29 03:21:40,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:40,534][root][INFO] - Training Epoch: 4/10, step 130/574 completed (loss: 0.39257797598838806, acc: 0.8846153616905212)
[2024-11-29 03:21:40,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:41,119][root][INFO] - Training Epoch: 4/10, step 131/574 completed (loss: 0.1455674171447754, acc: 0.95652174949646)
[2024-11-29 03:21:41,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:41,706][root][INFO] - Training Epoch: 4/10, step 132/574 completed (loss: 0.8864890336990356, acc: 0.75)
[2024-11-29 03:21:41,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:42,292][root][INFO] - Training Epoch: 4/10, step 133/574 completed (loss: 0.607803463935852, acc: 0.739130437374115)
[2024-11-29 03:21:42,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:42,881][root][INFO] - Training Epoch: 4/10, step 134/574 completed (loss: 0.8156110644340515, acc: 0.800000011920929)
[2024-11-29 03:21:42,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:43,470][root][INFO] - Training Epoch: 4/10, step 135/574 completed (loss: 0.630828857421875, acc: 0.8846153616905212)
[2024-11-29 03:21:43,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:44,060][root][INFO] - Training Epoch: 4/10, step 136/574 completed (loss: 1.56269109249115, acc: 0.5714285969734192)
[2024-11-29 03:21:44,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:45,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:45,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:46,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:47,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:47,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:48,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:48,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:49,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:49,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:50,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:50,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:51,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:51,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:52,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:52,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:53,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:53,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:54,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:54,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:55,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:56,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:56,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:57,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:57,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:58,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:58,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:59,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:59,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:00,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:00,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:01,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:01,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:02,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:02,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:03,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:04,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:04,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:05,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:05,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:06,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:06,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:07,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:07,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:08,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:08,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:09,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:09,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:10,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:10,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:11,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:11,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:12,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:13,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:13,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:14,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:14,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:15,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:15,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:16,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:16,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:17,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:17,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:18,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:18,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:19,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:19,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:20,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:21,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:21,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:22,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:22,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:23,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:23,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:24,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:24,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:25,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:25,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:26,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:26,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:27,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:27,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:28,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:29,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:29,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:30,341][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.5535, device='cuda:0') eval_epoch_loss=tensor(1.7144, device='cuda:0') eval_epoch_acc=tensor(0.5680, device='cuda:0')
[2024-11-29 03:22:30,343][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:22:30,343][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:22:30,573][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_4_step_137_loss_1.7144362926483154/model.pt
[2024-11-29 03:22:30,576][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 4 is 1.7144362926483154
[2024-11-29 03:22:30,576][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 4 is 0.567963182926178
[2024-11-29 03:22:30,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:31,186][root][INFO] - Training Epoch: 4/10, step 137/574 completed (loss: 0.8265052437782288, acc: 0.7333333492279053)
[2024-11-29 03:22:31,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:31,774][root][INFO] - Training Epoch: 4/10, step 138/574 completed (loss: 0.5810551047325134, acc: 0.8260869383811951)
[2024-11-29 03:22:31,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:32,360][root][INFO] - Training Epoch: 4/10, step 139/574 completed (loss: 0.5338032841682434, acc: 0.9047619104385376)
[2024-11-29 03:22:32,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:32,948][root][INFO] - Training Epoch: 4/10, step 140/574 completed (loss: 0.47453001141548157, acc: 0.807692289352417)
[2024-11-29 03:22:33,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:33,535][root][INFO] - Training Epoch: 4/10, step 141/574 completed (loss: 1.937625527381897, acc: 0.4516128897666931)
[2024-11-29 03:22:33,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:34,128][root][INFO] - Training Epoch: 4/10, step 142/574 completed (loss: 1.4832791090011597, acc: 0.5135135054588318)
[2024-11-29 03:22:34,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:34,741][root][INFO] - Training Epoch: 4/10, step 143/574 completed (loss: 1.7219756841659546, acc: 0.5526315569877625)
[2024-11-29 03:22:34,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:35,338][root][INFO] - Training Epoch: 4/10, step 144/574 completed (loss: 1.8261566162109375, acc: 0.5597015023231506)
[2024-11-29 03:22:35,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:35,941][root][INFO] - Training Epoch: 4/10, step 145/574 completed (loss: 2.149597406387329, acc: 0.37755101919174194)
[2024-11-29 03:22:36,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:36,553][root][INFO] - Training Epoch: 4/10, step 146/574 completed (loss: 2.057978630065918, acc: 0.478723406791687)
[2024-11-29 03:22:36,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:37,147][root][INFO] - Training Epoch: 4/10, step 147/574 completed (loss: 1.8951486349105835, acc: 0.5857142806053162)
[2024-11-29 03:22:37,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:37,735][root][INFO] - Training Epoch: 4/10, step 148/574 completed (loss: 1.2260504961013794, acc: 0.6785714030265808)
[2024-11-29 03:22:37,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:38,323][root][INFO] - Training Epoch: 4/10, step 149/574 completed (loss: 1.102218508720398, acc: 0.695652186870575)
[2024-11-29 03:22:38,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:38,910][root][INFO] - Training Epoch: 4/10, step 150/574 completed (loss: 1.8327409029006958, acc: 0.4137931168079376)
[2024-11-29 03:22:38,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:39,499][root][INFO] - Training Epoch: 4/10, step 151/574 completed (loss: 2.0046169757843018, acc: 0.54347825050354)
[2024-11-29 03:22:39,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:40,092][root][INFO] - Training Epoch: 4/10, step 152/574 completed (loss: 1.7716654539108276, acc: 0.5254237055778503)
[2024-11-29 03:22:40,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:40,683][root][INFO] - Training Epoch: 4/10, step 153/574 completed (loss: 2.1679437160491943, acc: 0.4912280738353729)
[2024-11-29 03:22:40,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:41,277][root][INFO] - Training Epoch: 4/10, step 154/574 completed (loss: 1.6528904438018799, acc: 0.5675675868988037)
[2024-11-29 03:22:41,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:41,869][root][INFO] - Training Epoch: 4/10, step 155/574 completed (loss: 1.1155604124069214, acc: 0.8214285969734192)
[2024-11-29 03:22:41,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:42,456][root][INFO] - Training Epoch: 4/10, step 156/574 completed (loss: 0.43756812810897827, acc: 0.8695651888847351)
[2024-11-29 03:22:42,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:43,043][root][INFO] - Training Epoch: 4/10, step 157/574 completed (loss: 1.091761589050293, acc: 0.6842105388641357)
[2024-11-29 03:22:43,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:43,635][root][INFO] - Training Epoch: 4/10, step 158/574 completed (loss: 1.8555736541748047, acc: 0.44594594836235046)
[2024-11-29 03:22:43,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:44,227][root][INFO] - Training Epoch: 4/10, step 159/574 completed (loss: 1.9694671630859375, acc: 0.46296295523643494)
[2024-11-29 03:22:44,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:44,821][root][INFO] - Training Epoch: 4/10, step 160/574 completed (loss: 2.149228572845459, acc: 0.44186046719551086)
[2024-11-29 03:22:44,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:45,415][root][INFO] - Training Epoch: 4/10, step 161/574 completed (loss: 1.9193732738494873, acc: 0.48235294222831726)
[2024-11-29 03:22:45,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:46,009][root][INFO] - Training Epoch: 4/10, step 162/574 completed (loss: 2.231534719467163, acc: 0.4606741666793823)
[2024-11-29 03:22:46,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:46,603][root][INFO] - Training Epoch: 4/10, step 163/574 completed (loss: 1.5626784563064575, acc: 0.6363636255264282)
[2024-11-29 03:22:46,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:47,191][root][INFO] - Training Epoch: 4/10, step 164/574 completed (loss: 0.7628263831138611, acc: 0.7142857313156128)
[2024-11-29 03:22:47,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:47,778][root][INFO] - Training Epoch: 4/10, step 165/574 completed (loss: 1.1160799264907837, acc: 0.7241379022598267)
[2024-11-29 03:22:47,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:48,370][root][INFO] - Training Epoch: 4/10, step 166/574 completed (loss: 0.9412953853607178, acc: 0.7142857313156128)
[2024-11-29 03:22:48,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:48,959][root][INFO] - Training Epoch: 4/10, step 167/574 completed (loss: 1.6654837131500244, acc: 0.5799999833106995)
[2024-11-29 03:22:49,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:49,554][root][INFO] - Training Epoch: 4/10, step 168/574 completed (loss: 1.7892956733703613, acc: 0.5)
[2024-11-29 03:22:49,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:50,151][root][INFO] - Training Epoch: 4/10, step 169/574 completed (loss: 2.1093499660491943, acc: 0.4313725531101227)
[2024-11-29 03:22:50,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:50,775][root][INFO] - Training Epoch: 4/10, step 170/574 completed (loss: 2.529740333557129, acc: 0.3767123222351074)
[2024-11-29 03:22:50,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:51,361][root][INFO] - Training Epoch: 4/10, step 171/574 completed (loss: 0.40395280718803406, acc: 0.875)
[2024-11-29 03:22:51,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:51,949][root][INFO] - Training Epoch: 4/10, step 172/574 completed (loss: 0.31105971336364746, acc: 0.9259259104728699)
[2024-11-29 03:22:52,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:52,534][root][INFO] - Training Epoch: 4/10, step 173/574 completed (loss: 1.030093789100647, acc: 0.6785714030265808)
[2024-11-29 03:22:52,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:53,145][root][INFO] - Training Epoch: 4/10, step 174/574 completed (loss: 2.058396100997925, acc: 0.5221238732337952)
[2024-11-29 03:22:53,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:53,735][root][INFO] - Training Epoch: 4/10, step 175/574 completed (loss: 1.65524423122406, acc: 0.5942028760910034)
[2024-11-29 03:22:53,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:54,330][root][INFO] - Training Epoch: 4/10, step 176/574 completed (loss: 1.897046685218811, acc: 0.5113636255264282)
[2024-11-29 03:22:54,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:54,943][root][INFO] - Training Epoch: 4/10, step 177/574 completed (loss: 2.462141990661621, acc: 0.32824426889419556)
[2024-11-29 03:22:55,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:55,552][root][INFO] - Training Epoch: 4/10, step 178/574 completed (loss: 2.603102445602417, acc: 0.37037035822868347)
[2024-11-29 03:22:55,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:56,143][root][INFO] - Training Epoch: 4/10, step 179/574 completed (loss: 1.4557784795761108, acc: 0.6065573692321777)
[2024-11-29 03:22:56,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:56,730][root][INFO] - Training Epoch: 4/10, step 180/574 completed (loss: 0.20025356113910675, acc: 0.9166666865348816)
[2024-11-29 03:22:56,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:57,318][root][INFO] - Training Epoch: 4/10, step 181/574 completed (loss: 0.4507448971271515, acc: 0.8399999737739563)
[2024-11-29 03:22:57,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:57,906][root][INFO] - Training Epoch: 4/10, step 182/574 completed (loss: 0.488704115152359, acc: 0.8571428656578064)
[2024-11-29 03:22:57,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:58,504][root][INFO] - Training Epoch: 4/10, step 183/574 completed (loss: 1.9840887784957886, acc: 0.4268292784690857)
[2024-11-29 03:22:58,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:59,133][root][INFO] - Training Epoch: 4/10, step 184/574 completed (loss: 2.7093403339385986, acc: 0.2930513620376587)
[2024-11-29 03:22:59,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:59,761][root][INFO] - Training Epoch: 4/10, step 185/574 completed (loss: 2.6868503093719482, acc: 0.2910662889480591)
[2024-11-29 03:22:59,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:00,387][root][INFO] - Training Epoch: 4/10, step 186/574 completed (loss: 2.7753398418426514, acc: 0.296875)
[2024-11-29 03:23:00,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:01,043][root][INFO] - Training Epoch: 4/10, step 187/574 completed (loss: 2.786999464035034, acc: 0.25328329205513)
[2024-11-29 03:23:01,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:01,678][root][INFO] - Training Epoch: 4/10, step 188/574 completed (loss: 2.4318666458129883, acc: 0.35587188601493835)
[2024-11-29 03:23:01,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:02,268][root][INFO] - Training Epoch: 4/10, step 189/574 completed (loss: 1.2123578786849976, acc: 0.7599999904632568)
[2024-11-29 03:23:02,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:02,863][root][INFO] - Training Epoch: 4/10, step 190/574 completed (loss: 2.1938750743865967, acc: 0.3720930218696594)
[2024-11-29 03:23:02,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:03,460][root][INFO] - Training Epoch: 4/10, step 191/574 completed (loss: 2.294699192047119, acc: 0.4285714328289032)
[2024-11-29 03:23:03,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:04,058][root][INFO] - Training Epoch: 4/10, step 192/574 completed (loss: 2.4567086696624756, acc: 0.3787878751754761)
[2024-11-29 03:23:04,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:04,650][root][INFO] - Training Epoch: 4/10, step 193/574 completed (loss: 1.7959647178649902, acc: 0.5176470875740051)
[2024-11-29 03:23:04,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:05,262][root][INFO] - Training Epoch: 4/10, step 194/574 completed (loss: 2.0785129070281982, acc: 0.4506172835826874)
[2024-11-29 03:23:05,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:05,858][root][INFO] - Training Epoch: 4/10, step 195/574 completed (loss: 1.6190613508224487, acc: 0.5967742204666138)
[2024-11-29 03:23:05,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:06,447][root][INFO] - Training Epoch: 4/10, step 196/574 completed (loss: 0.3239106237888336, acc: 0.9285714030265808)
[2024-11-29 03:23:06,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:07,036][root][INFO] - Training Epoch: 4/10, step 197/574 completed (loss: 1.2525050640106201, acc: 0.6000000238418579)
[2024-11-29 03:23:07,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:07,630][root][INFO] - Training Epoch: 4/10, step 198/574 completed (loss: 1.8428394794464111, acc: 0.5147058963775635)
[2024-11-29 03:23:07,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:08,227][root][INFO] - Training Epoch: 4/10, step 199/574 completed (loss: 2.2391185760498047, acc: 0.43382352590560913)
[2024-11-29 03:23:08,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:08,823][root][INFO] - Training Epoch: 4/10, step 200/574 completed (loss: 2.1273398399353027, acc: 0.41525423526763916)
[2024-11-29 03:23:08,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:09,422][root][INFO] - Training Epoch: 4/10, step 201/574 completed (loss: 2.388864755630493, acc: 0.38805970549583435)
[2024-11-29 03:23:09,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:10,019][root][INFO] - Training Epoch: 4/10, step 202/574 completed (loss: 2.2366344928741455, acc: 0.446601927280426)
[2024-11-29 03:23:10,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:10,618][root][INFO] - Training Epoch: 4/10, step 203/574 completed (loss: 1.8413435220718384, acc: 0.5396825671195984)
[2024-11-29 03:23:10,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:11,212][root][INFO] - Training Epoch: 4/10, step 204/574 completed (loss: 2.044353485107422, acc: 0.4175824224948883)
[2024-11-29 03:23:11,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:11,839][root][INFO] - Training Epoch: 4/10, step 205/574 completed (loss: 2.414616823196411, acc: 0.35426008701324463)
[2024-11-29 03:23:11,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:12,464][root][INFO] - Training Epoch: 4/10, step 206/574 completed (loss: 2.421809196472168, acc: 0.3858267664909363)
[2024-11-29 03:23:12,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:13,079][root][INFO] - Training Epoch: 4/10, step 207/574 completed (loss: 2.268467664718628, acc: 0.3965517282485962)
[2024-11-29 03:23:13,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:13,693][root][INFO] - Training Epoch: 4/10, step 208/574 completed (loss: 2.2210206985473633, acc: 0.42391303181648254)
[2024-11-29 03:23:13,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:14,314][root][INFO] - Training Epoch: 4/10, step 209/574 completed (loss: 2.587141752243042, acc: 0.31128403544425964)
[2024-11-29 03:23:14,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:14,929][root][INFO] - Training Epoch: 4/10, step 210/574 completed (loss: 2.38006329536438, acc: 0.3804347813129425)
[2024-11-29 03:23:15,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:15,515][root][INFO] - Training Epoch: 4/10, step 211/574 completed (loss: 0.33356642723083496, acc: 0.9130434989929199)
[2024-11-29 03:23:15,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:16,103][root][INFO] - Training Epoch: 4/10, step 212/574 completed (loss: 0.7478961944580078, acc: 0.7857142686843872)
[2024-11-29 03:23:16,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:16,698][root][INFO] - Training Epoch: 4/10, step 213/574 completed (loss: 1.1566160917282104, acc: 0.6382978558540344)
[2024-11-29 03:23:16,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:17,308][root][INFO] - Training Epoch: 4/10, step 214/574 completed (loss: 1.990791916847229, acc: 0.4615384638309479)
[2024-11-29 03:23:17,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:17,900][root][INFO] - Training Epoch: 4/10, step 215/574 completed (loss: 1.5348743200302124, acc: 0.5540540814399719)
[2024-11-29 03:23:17,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:18,494][root][INFO] - Training Epoch: 4/10, step 216/574 completed (loss: 1.6446243524551392, acc: 0.5581395626068115)
[2024-11-29 03:23:18,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:19,092][root][INFO] - Training Epoch: 4/10, step 217/574 completed (loss: 1.7473350763320923, acc: 0.5045045018196106)
[2024-11-29 03:23:19,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:19,689][root][INFO] - Training Epoch: 4/10, step 218/574 completed (loss: 1.5501601696014404, acc: 0.5555555820465088)
[2024-11-29 03:23:19,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:20,278][root][INFO] - Training Epoch: 4/10, step 219/574 completed (loss: 0.5000660419464111, acc: 0.8787878751754761)
[2024-11-29 03:23:20,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:20,865][root][INFO] - Training Epoch: 4/10, step 220/574 completed (loss: 0.030189694836735725, acc: 1.0)
[2024-11-29 03:23:20,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:21,452][root][INFO] - Training Epoch: 4/10, step 221/574 completed (loss: 0.30837997794151306, acc: 0.9200000166893005)
[2024-11-29 03:23:21,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:22,045][root][INFO] - Training Epoch: 4/10, step 222/574 completed (loss: 1.6282824277877808, acc: 0.4615384638309479)
[2024-11-29 03:23:22,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:22,659][root][INFO] - Training Epoch: 4/10, step 223/574 completed (loss: 2.190751791000366, acc: 0.39673912525177)
[2024-11-29 03:23:22,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:23,271][root][INFO] - Training Epoch: 4/10, step 224/574 completed (loss: 2.3610143661499023, acc: 0.375)
[2024-11-29 03:23:23,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:23,884][root][INFO] - Training Epoch: 4/10, step 225/574 completed (loss: 2.2524397373199463, acc: 0.38297873735427856)
[2024-11-29 03:23:23,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:24,476][root][INFO] - Training Epoch: 4/10, step 226/574 completed (loss: 1.3940832614898682, acc: 0.6226415038108826)
[2024-11-29 03:23:24,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:25,067][root][INFO] - Training Epoch: 4/10, step 227/574 completed (loss: 1.490605115890503, acc: 0.5666666626930237)
[2024-11-29 03:23:25,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:25,660][root][INFO] - Training Epoch: 4/10, step 228/574 completed (loss: 0.8328158259391785, acc: 0.7906976938247681)
[2024-11-29 03:23:25,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:26,248][root][INFO] - Training Epoch: 4/10, step 229/574 completed (loss: 0.7443563342094421, acc: 0.800000011920929)
[2024-11-29 03:23:26,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:26,846][root][INFO] - Training Epoch: 4/10, step 230/574 completed (loss: 2.325364351272583, acc: 0.46315789222717285)
[2024-11-29 03:23:26,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:27,438][root][INFO] - Training Epoch: 4/10, step 231/574 completed (loss: 1.7967839241027832, acc: 0.5)
[2024-11-29 03:23:27,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:28,053][root][INFO] - Training Epoch: 4/10, step 232/574 completed (loss: 1.91586434841156, acc: 0.49444442987442017)
[2024-11-29 03:23:28,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:28,666][root][INFO] - Training Epoch: 4/10, step 233/574 completed (loss: 2.1161839962005615, acc: 0.5)
[2024-11-29 03:23:28,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:29,281][root][INFO] - Training Epoch: 4/10, step 234/574 completed (loss: 1.9431474208831787, acc: 0.4923076927661896)
[2024-11-29 03:23:29,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:29,870][root][INFO] - Training Epoch: 4/10, step 235/574 completed (loss: 0.7902646660804749, acc: 0.8947368264198303)
[2024-11-29 03:23:29,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:30,456][root][INFO] - Training Epoch: 4/10, step 236/574 completed (loss: 0.29960405826568604, acc: 0.9166666865348816)
[2024-11-29 03:23:30,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:31,041][root][INFO] - Training Epoch: 4/10, step 237/574 completed (loss: 0.881324052810669, acc: 0.7272727489471436)
[2024-11-29 03:23:31,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:31,629][root][INFO] - Training Epoch: 4/10, step 238/574 completed (loss: 0.8027229309082031, acc: 0.8148148059844971)
[2024-11-29 03:23:31,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:32,219][root][INFO] - Training Epoch: 4/10, step 239/574 completed (loss: 1.073756217956543, acc: 0.7142857313156128)
[2024-11-29 03:23:32,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:32,807][root][INFO] - Training Epoch: 4/10, step 240/574 completed (loss: 1.213637113571167, acc: 0.7045454382896423)
[2024-11-29 03:23:32,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:33,395][root][INFO] - Training Epoch: 4/10, step 241/574 completed (loss: 1.193464756011963, acc: 0.6136363744735718)
[2024-11-29 03:23:33,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:33,987][root][INFO] - Training Epoch: 4/10, step 242/574 completed (loss: 1.8079994916915894, acc: 0.4838709533214569)
[2024-11-29 03:23:34,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:34,577][root][INFO] - Training Epoch: 4/10, step 243/574 completed (loss: 0.932380735874176, acc: 0.6590909361839294)
[2024-11-29 03:23:34,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:35,165][root][INFO] - Training Epoch: 4/10, step 244/574 completed (loss: 0.05735822021961212, acc: 1.0)
[2024-11-29 03:23:35,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:35,752][root][INFO] - Training Epoch: 4/10, step 245/574 completed (loss: 0.1756719946861267, acc: 1.0)
[2024-11-29 03:23:35,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:36,337][root][INFO] - Training Epoch: 4/10, step 246/574 completed (loss: 0.6119070649147034, acc: 0.774193525314331)
[2024-11-29 03:23:36,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:36,923][root][INFO] - Training Epoch: 4/10, step 247/574 completed (loss: 0.32886844873428345, acc: 0.8500000238418579)
[2024-11-29 03:23:37,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:37,516][root][INFO] - Training Epoch: 4/10, step 248/574 completed (loss: 1.1649597883224487, acc: 0.7297297120094299)
[2024-11-29 03:23:37,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:38,103][root][INFO] - Training Epoch: 4/10, step 249/574 completed (loss: 0.7274484634399414, acc: 0.8108108043670654)
[2024-11-29 03:23:38,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:38,690][root][INFO] - Training Epoch: 4/10, step 250/574 completed (loss: 0.9600208401679993, acc: 0.7837837934494019)
[2024-11-29 03:23:38,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:39,285][root][INFO] - Training Epoch: 4/10, step 251/574 completed (loss: 1.7381904125213623, acc: 0.5588235259056091)
[2024-11-29 03:23:39,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:39,873][root][INFO] - Training Epoch: 4/10, step 252/574 completed (loss: 0.4336797297000885, acc: 0.9024389982223511)
[2024-11-29 03:23:39,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:40,459][root][INFO] - Training Epoch: 4/10, step 253/574 completed (loss: 0.1145334541797638, acc: 0.9599999785423279)
[2024-11-29 03:23:40,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:41,046][root][INFO] - Training Epoch: 4/10, step 254/574 completed (loss: 0.058715611696243286, acc: 1.0)
[2024-11-29 03:23:41,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:41,636][root][INFO] - Training Epoch: 4/10, step 255/574 completed (loss: 0.3006032109260559, acc: 0.8709677457809448)
[2024-11-29 03:23:41,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:42,230][root][INFO] - Training Epoch: 4/10, step 256/574 completed (loss: 1.311077356338501, acc: 0.6842105388641357)
[2024-11-29 03:23:42,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:42,820][root][INFO] - Training Epoch: 4/10, step 257/574 completed (loss: 1.5358896255493164, acc: 0.6285714507102966)
[2024-11-29 03:23:42,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:43,413][root][INFO] - Training Epoch: 4/10, step 258/574 completed (loss: 1.6768487691879272, acc: 0.5)
[2024-11-29 03:23:43,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:44,022][root][INFO] - Training Epoch: 4/10, step 259/574 completed (loss: 1.8602890968322754, acc: 0.5188679099082947)
[2024-11-29 03:23:44,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:44,636][root][INFO] - Training Epoch: 4/10, step 260/574 completed (loss: 2.362212657928467, acc: 0.4166666567325592)
[2024-11-29 03:23:44,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:45,225][root][INFO] - Training Epoch: 4/10, step 261/574 completed (loss: 0.7343470454216003, acc: 0.75)
[2024-11-29 03:23:45,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:45,813][root][INFO] - Training Epoch: 4/10, step 262/574 completed (loss: 0.9069548845291138, acc: 0.774193525314331)
[2024-11-29 03:23:45,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:46,408][root][INFO] - Training Epoch: 4/10, step 263/574 completed (loss: 2.4008703231811523, acc: 0.4000000059604645)
[2024-11-29 03:23:46,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:46,998][root][INFO] - Training Epoch: 4/10, step 264/574 completed (loss: 1.6766599416732788, acc: 0.5625)
[2024-11-29 03:23:47,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:47,615][root][INFO] - Training Epoch: 4/10, step 265/574 completed (loss: 2.399402379989624, acc: 0.3919999897480011)
[2024-11-29 03:23:47,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:48,208][root][INFO] - Training Epoch: 4/10, step 266/574 completed (loss: 2.0756025314331055, acc: 0.4157303273677826)
[2024-11-29 03:23:48,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:48,802][root][INFO] - Training Epoch: 4/10, step 267/574 completed (loss: 2.16099214553833, acc: 0.4324324429035187)
[2024-11-29 03:23:48,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:49,396][root][INFO] - Training Epoch: 4/10, step 268/574 completed (loss: 1.4438942670822144, acc: 0.5862069129943848)
[2024-11-29 03:23:49,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:49,986][root][INFO] - Training Epoch: 4/10, step 269/574 completed (loss: 0.46104317903518677, acc: 0.8636363744735718)
[2024-11-29 03:23:50,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:50,573][root][INFO] - Training Epoch: 4/10, step 270/574 completed (loss: 0.31959545612335205, acc: 0.9090909361839294)
[2024-11-29 03:23:50,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:51,161][root][INFO] - Training Epoch: 4/10, step 271/574 completed (loss: 0.6097361445426941, acc: 0.78125)
[2024-11-29 03:23:51,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:51,749][root][INFO] - Training Epoch: 4/10, step 272/574 completed (loss: 0.3605028986930847, acc: 0.8666666746139526)
[2024-11-29 03:23:51,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:52,342][root][INFO] - Training Epoch: 4/10, step 273/574 completed (loss: 1.3700567483901978, acc: 0.6333333253860474)
[2024-11-29 03:23:52,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:52,931][root][INFO] - Training Epoch: 4/10, step 274/574 completed (loss: 0.713345468044281, acc: 0.75)
[2024-11-29 03:23:53,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:53,518][root][INFO] - Training Epoch: 4/10, step 275/574 completed (loss: 0.5016962885856628, acc: 0.8666666746139526)
[2024-11-29 03:23:53,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:54,106][root][INFO] - Training Epoch: 4/10, step 276/574 completed (loss: 0.8299610018730164, acc: 0.8620689511299133)
[2024-11-29 03:23:54,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:54,693][root][INFO] - Training Epoch: 4/10, step 277/574 completed (loss: 0.3528047502040863, acc: 0.8799999952316284)
[2024-11-29 03:23:54,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:55,282][root][INFO] - Training Epoch: 4/10, step 278/574 completed (loss: 1.7830443382263184, acc: 0.5106382966041565)
[2024-11-29 03:23:55,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:55,873][root][INFO] - Training Epoch: 4/10, step 279/574 completed (loss: 1.3091951608657837, acc: 0.6666666865348816)
[2024-11-29 03:23:56,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:57,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:57,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:58,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:58,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:59,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:59,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:00,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:00,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:01,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:01,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:02,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:02,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:03,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:03,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:04,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:04,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:05,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:06,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:06,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:07,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:07,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:08,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:08,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:09,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:09,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:10,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:10,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:11,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:11,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:12,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:12,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:13,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:14,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:14,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:15,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:15,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:16,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:16,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:17,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:17,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:18,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:18,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:19,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:19,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:20,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:20,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:21,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:21,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:22,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:22,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:23,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:24,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:24,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:25,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:25,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:26,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:26,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:27,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:27,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:28,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:28,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:29,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:29,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:30,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:30,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:31,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:32,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:32,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:33,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:33,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:34,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:34,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:35,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:35,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:36,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:36,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:37,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:37,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:38,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:38,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:39,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:39,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:40,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:40,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:41,821][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.4444, device='cuda:0') eval_epoch_loss=tensor(1.6946, device='cuda:0') eval_epoch_acc=tensor(0.5661, device='cuda:0')
[2024-11-29 03:24:41,822][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:24:41,822][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:24:42,088][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_4_step_280_loss_1.694582223892212/model.pt
[2024-11-29 03:24:42,092][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 4 is 1.694582223892212
[2024-11-29 03:24:42,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:42,698][root][INFO] - Training Epoch: 4/10, step 280/574 completed (loss: 0.9857373833656311, acc: 0.6590909361839294)
[2024-11-29 03:24:42,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:43,294][root][INFO] - Training Epoch: 4/10, step 281/574 completed (loss: 2.1281580924987793, acc: 0.46987950801849365)
[2024-11-29 03:24:43,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:43,889][root][INFO] - Training Epoch: 4/10, step 282/574 completed (loss: 2.198002815246582, acc: 0.46296295523643494)
[2024-11-29 03:24:43,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:44,476][root][INFO] - Training Epoch: 4/10, step 283/574 completed (loss: 1.1718584299087524, acc: 0.6052631735801697)
[2024-11-29 03:24:44,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:45,063][root][INFO] - Training Epoch: 4/10, step 284/574 completed (loss: 1.1542925834655762, acc: 0.7058823704719543)
[2024-11-29 03:24:45,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:45,651][root][INFO] - Training Epoch: 4/10, step 285/574 completed (loss: 0.9534207582473755, acc: 0.7749999761581421)
[2024-11-29 03:24:45,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:46,245][root][INFO] - Training Epoch: 4/10, step 286/574 completed (loss: 2.1022932529449463, acc: 0.390625)
[2024-11-29 03:24:46,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:46,854][root][INFO] - Training Epoch: 4/10, step 287/574 completed (loss: 2.4852993488311768, acc: 0.3199999928474426)
[2024-11-29 03:24:46,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:47,448][root][INFO] - Training Epoch: 4/10, step 288/574 completed (loss: 1.7164826393127441, acc: 0.5164835453033447)
[2024-11-29 03:24:47,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:48,046][root][INFO] - Training Epoch: 4/10, step 289/574 completed (loss: 2.3700578212738037, acc: 0.35403725504875183)
[2024-11-29 03:24:48,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:48,661][root][INFO] - Training Epoch: 4/10, step 290/574 completed (loss: 2.521991491317749, acc: 0.3505154550075531)
[2024-11-29 03:24:48,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:49,247][root][INFO] - Training Epoch: 4/10, step 291/574 completed (loss: 0.20687435567378998, acc: 0.9545454382896423)
[2024-11-29 03:24:49,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:49,834][root][INFO] - Training Epoch: 4/10, step 292/574 completed (loss: 1.4709508419036865, acc: 0.5952380895614624)
[2024-11-29 03:24:49,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:50,428][root][INFO] - Training Epoch: 4/10, step 293/574 completed (loss: 1.4255293607711792, acc: 0.6206896305084229)
[2024-11-29 03:24:50,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:51,022][root][INFO] - Training Epoch: 4/10, step 294/574 completed (loss: 1.305191159248352, acc: 0.6545454263687134)
[2024-11-29 03:24:51,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:51,645][root][INFO] - Training Epoch: 4/10, step 295/574 completed (loss: 2.0402207374572754, acc: 0.4793814420700073)
[2024-11-29 03:24:51,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:52,239][root][INFO] - Training Epoch: 4/10, step 296/574 completed (loss: 1.8770383596420288, acc: 0.43103447556495667)
[2024-11-29 03:24:52,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:52,827][root][INFO] - Training Epoch: 4/10, step 297/574 completed (loss: 0.9585816860198975, acc: 0.7407407164573669)
[2024-11-29 03:24:52,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:53,417][root][INFO] - Training Epoch: 4/10, step 298/574 completed (loss: 1.3637508153915405, acc: 0.6052631735801697)
[2024-11-29 03:24:53,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:54,009][root][INFO] - Training Epoch: 4/10, step 299/574 completed (loss: 1.991991639137268, acc: 0.5178571343421936)
[2024-11-29 03:24:54,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:54,596][root][INFO] - Training Epoch: 4/10, step 300/574 completed (loss: 0.9305552840232849, acc: 0.71875)
[2024-11-29 03:24:54,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:55,189][root][INFO] - Training Epoch: 4/10, step 301/574 completed (loss: 2.0920960903167725, acc: 0.4716981053352356)
[2024-11-29 03:24:55,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:55,779][root][INFO] - Training Epoch: 4/10, step 302/574 completed (loss: 0.9012905359268188, acc: 0.698113203048706)
[2024-11-29 03:24:55,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:56,364][root][INFO] - Training Epoch: 4/10, step 303/574 completed (loss: 0.6333442330360413, acc: 0.7941176295280457)
[2024-11-29 03:24:56,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:56,952][root][INFO] - Training Epoch: 4/10, step 304/574 completed (loss: 1.27242112159729, acc: 0.6875)
[2024-11-29 03:24:57,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:57,545][root][INFO] - Training Epoch: 4/10, step 305/574 completed (loss: 1.425415277481079, acc: 0.6557376980781555)
[2024-11-29 03:24:57,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:58,133][root][INFO] - Training Epoch: 4/10, step 306/574 completed (loss: 0.45846128463745117, acc: 0.800000011920929)
[2024-11-29 03:24:58,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:58,718][root][INFO] - Training Epoch: 4/10, step 307/574 completed (loss: 0.17528179287910461, acc: 0.9473684430122375)
[2024-11-29 03:24:58,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:59,311][root][INFO] - Training Epoch: 4/10, step 308/574 completed (loss: 2.1197779178619385, acc: 0.43478259444236755)
[2024-11-29 03:24:59,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:59,908][root][INFO] - Training Epoch: 4/10, step 309/574 completed (loss: 1.78537118434906, acc: 0.5277777910232544)
[2024-11-29 03:24:59,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:00,502][root][INFO] - Training Epoch: 4/10, step 310/574 completed (loss: 1.5650608539581299, acc: 0.6024096608161926)
[2024-11-29 03:25:00,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:01,098][root][INFO] - Training Epoch: 4/10, step 311/574 completed (loss: 1.8963403701782227, acc: 0.43589743971824646)
[2024-11-29 03:25:01,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:01,707][root][INFO] - Training Epoch: 4/10, step 312/574 completed (loss: 2.1372814178466797, acc: 0.43877550959587097)
[2024-11-29 03:25:01,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:02,297][root][INFO] - Training Epoch: 4/10, step 313/574 completed (loss: 0.03296009451150894, acc: 1.0)
[2024-11-29 03:25:02,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:02,883][root][INFO] - Training Epoch: 4/10, step 314/574 completed (loss: 0.3718891143798828, acc: 0.875)
[2024-11-29 03:25:02,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:03,471][root][INFO] - Training Epoch: 4/10, step 315/574 completed (loss: 0.20286892354488373, acc: 0.9354838728904724)
[2024-11-29 03:25:03,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:04,057][root][INFO] - Training Epoch: 4/10, step 316/574 completed (loss: 0.2980932891368866, acc: 0.9354838728904724)
[2024-11-29 03:25:04,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:04,650][root][INFO] - Training Epoch: 4/10, step 317/574 completed (loss: 1.5419275760650635, acc: 0.5522388219833374)
[2024-11-29 03:25:04,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:05,251][root][INFO] - Training Epoch: 4/10, step 318/574 completed (loss: 1.530596375465393, acc: 0.5961538553237915)
[2024-11-29 03:25:05,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:05,840][root][INFO] - Training Epoch: 4/10, step 319/574 completed (loss: 1.0651788711547852, acc: 0.6888889074325562)
[2024-11-29 03:25:05,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:06,432][root][INFO] - Training Epoch: 4/10, step 320/574 completed (loss: 1.3909629583358765, acc: 0.6129032373428345)
[2024-11-29 03:25:06,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:07,022][root][INFO] - Training Epoch: 4/10, step 321/574 completed (loss: 0.5993839502334595, acc: 0.8199999928474426)
[2024-11-29 03:25:07,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:07,610][root][INFO] - Training Epoch: 4/10, step 322/574 completed (loss: 1.1138200759887695, acc: 0.6666666865348816)
[2024-11-29 03:25:07,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:08,199][root][INFO] - Training Epoch: 4/10, step 323/574 completed (loss: 2.1763980388641357, acc: 0.4285714328289032)
[2024-11-29 03:25:08,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:08,787][root][INFO] - Training Epoch: 4/10, step 324/574 completed (loss: 1.3306981325149536, acc: 0.5641025900840759)
[2024-11-29 03:25:08,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:09,379][root][INFO] - Training Epoch: 4/10, step 325/574 completed (loss: 1.86397385597229, acc: 0.4146341383457184)
[2024-11-29 03:25:09,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:09,970][root][INFO] - Training Epoch: 4/10, step 326/574 completed (loss: 1.5667065382003784, acc: 0.5263158082962036)
[2024-11-29 03:25:10,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:10,557][root][INFO] - Training Epoch: 4/10, step 327/574 completed (loss: 0.3993013799190521, acc: 0.8947368264198303)
[2024-11-29 03:25:10,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:11,142][root][INFO] - Training Epoch: 4/10, step 328/574 completed (loss: 0.10351701080799103, acc: 0.9642857313156128)
[2024-11-29 03:25:11,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:11,728][root][INFO] - Training Epoch: 4/10, step 329/574 completed (loss: 0.9923624396324158, acc: 0.7777777910232544)
[2024-11-29 03:25:11,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:12,315][root][INFO] - Training Epoch: 4/10, step 330/574 completed (loss: 0.41687944531440735, acc: 0.875)
[2024-11-29 03:25:12,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:12,906][root][INFO] - Training Epoch: 4/10, step 331/574 completed (loss: 1.4381922483444214, acc: 0.5806451439857483)
[2024-11-29 03:25:12,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:13,502][root][INFO] - Training Epoch: 4/10, step 332/574 completed (loss: 1.2433580160140991, acc: 0.6315789222717285)
[2024-11-29 03:25:13,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:14,088][root][INFO] - Training Epoch: 4/10, step 333/574 completed (loss: 1.0888328552246094, acc: 0.65625)
[2024-11-29 03:25:14,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:14,675][root][INFO] - Training Epoch: 4/10, step 334/574 completed (loss: 0.7638291120529175, acc: 0.800000011920929)
[2024-11-29 03:25:14,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:15,260][root][INFO] - Training Epoch: 4/10, step 335/574 completed (loss: 0.3459901809692383, acc: 0.9473684430122375)
[2024-11-29 03:25:15,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:15,854][root][INFO] - Training Epoch: 4/10, step 336/574 completed (loss: 1.714382290840149, acc: 0.5600000023841858)
[2024-11-29 03:25:15,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:16,450][root][INFO] - Training Epoch: 4/10, step 337/574 completed (loss: 2.2071566581726074, acc: 0.36781609058380127)
[2024-11-29 03:25:16,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:17,044][root][INFO] - Training Epoch: 4/10, step 338/574 completed (loss: 2.199106454849243, acc: 0.478723406791687)
[2024-11-29 03:25:17,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:17,638][root][INFO] - Training Epoch: 4/10, step 339/574 completed (loss: 2.3741543292999268, acc: 0.34939759969711304)
[2024-11-29 03:25:17,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:18,226][root][INFO] - Training Epoch: 4/10, step 340/574 completed (loss: 0.2021862119436264, acc: 0.95652174949646)
[2024-11-29 03:25:18,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:18,813][root][INFO] - Training Epoch: 4/10, step 341/574 completed (loss: 1.2354859113693237, acc: 0.6153846383094788)
[2024-11-29 03:25:18,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:19,405][root][INFO] - Training Epoch: 4/10, step 342/574 completed (loss: 2.5669937133789062, acc: 0.28915661573410034)
[2024-11-29 03:25:19,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:20,001][root][INFO] - Training Epoch: 4/10, step 343/574 completed (loss: 1.589190125465393, acc: 0.5094339847564697)
[2024-11-29 03:25:20,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:20,594][root][INFO] - Training Epoch: 4/10, step 344/574 completed (loss: 2.087218761444092, acc: 0.4177215099334717)
[2024-11-29 03:25:20,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:21,183][root][INFO] - Training Epoch: 4/10, step 345/574 completed (loss: 1.6364152431488037, acc: 0.5490196347236633)
[2024-11-29 03:25:21,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:21,778][root][INFO] - Training Epoch: 4/10, step 346/574 completed (loss: 2.1791739463806152, acc: 0.35820895433425903)
[2024-11-29 03:25:21,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:22,364][root][INFO] - Training Epoch: 4/10, step 347/574 completed (loss: 0.2729613482952118, acc: 0.8999999761581421)
[2024-11-29 03:25:22,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:22,949][root][INFO] - Training Epoch: 4/10, step 348/574 completed (loss: 0.6370231509208679, acc: 0.8399999737739563)
[2024-11-29 03:25:23,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:23,538][root][INFO] - Training Epoch: 4/10, step 349/574 completed (loss: 1.0527167320251465, acc: 0.7222222089767456)
[2024-11-29 03:25:23,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:24,128][root][INFO] - Training Epoch: 4/10, step 350/574 completed (loss: 1.834234595298767, acc: 0.5116279125213623)
[2024-11-29 03:25:24,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:24,719][root][INFO] - Training Epoch: 4/10, step 351/574 completed (loss: 1.283694863319397, acc: 0.5897436141967773)
[2024-11-29 03:25:24,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:25,310][root][INFO] - Training Epoch: 4/10, step 352/574 completed (loss: 1.7891849279403687, acc: 0.5555555820465088)
[2024-11-29 03:25:25,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:25,897][root][INFO] - Training Epoch: 4/10, step 353/574 completed (loss: 0.041930537670850754, acc: 1.0)
[2024-11-29 03:25:25,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:26,483][root][INFO] - Training Epoch: 4/10, step 354/574 completed (loss: 1.2351658344268799, acc: 0.5769230723381042)
[2024-11-29 03:25:26,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:27,076][root][INFO] - Training Epoch: 4/10, step 355/574 completed (loss: 2.4397878646850586, acc: 0.3186813294887543)
[2024-11-29 03:25:27,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:27,691][root][INFO] - Training Epoch: 4/10, step 356/574 completed (loss: 2.063234329223633, acc: 0.4521739184856415)
[2024-11-29 03:25:27,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:28,284][root][INFO] - Training Epoch: 4/10, step 357/574 completed (loss: 2.1863303184509277, acc: 0.3913043439388275)
[2024-11-29 03:25:28,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:28,874][root][INFO] - Training Epoch: 4/10, step 358/574 completed (loss: 1.7640089988708496, acc: 0.5306122303009033)
[2024-11-29 03:25:28,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:29,461][root][INFO] - Training Epoch: 4/10, step 359/574 completed (loss: 0.030980415642261505, acc: 1.0)
[2024-11-29 03:25:29,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:30,047][root][INFO] - Training Epoch: 4/10, step 360/574 completed (loss: 0.3383198082447052, acc: 0.9615384340286255)
[2024-11-29 03:25:30,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:30,638][root][INFO] - Training Epoch: 4/10, step 361/574 completed (loss: 0.9945406913757324, acc: 0.7317073345184326)
[2024-11-29 03:25:30,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:31,227][root][INFO] - Training Epoch: 4/10, step 362/574 completed (loss: 1.1960283517837524, acc: 0.644444465637207)
[2024-11-29 03:25:31,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:31,822][root][INFO] - Training Epoch: 4/10, step 363/574 completed (loss: 1.9700140953063965, acc: 0.4736842215061188)
[2024-11-29 03:25:31,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:32,412][root][INFO] - Training Epoch: 4/10, step 364/574 completed (loss: 1.4036312103271484, acc: 0.6097561120986938)
[2024-11-29 03:25:32,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:33,001][root][INFO] - Training Epoch: 4/10, step 365/574 completed (loss: 1.1316781044006348, acc: 0.6969696879386902)
[2024-11-29 03:25:33,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:33,586][root][INFO] - Training Epoch: 4/10, step 366/574 completed (loss: 0.07815300673246384, acc: 1.0)
[2024-11-29 03:25:33,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:34,172][root][INFO] - Training Epoch: 4/10, step 367/574 completed (loss: 0.014211027882993221, acc: 1.0)
[2024-11-29 03:25:34,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:34,758][root][INFO] - Training Epoch: 4/10, step 368/574 completed (loss: 0.43889549374580383, acc: 0.8571428656578064)
[2024-11-29 03:25:34,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:35,346][root][INFO] - Training Epoch: 4/10, step 369/574 completed (loss: 0.7720959186553955, acc: 0.875)
[2024-11-29 03:25:35,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:35,959][root][INFO] - Training Epoch: 4/10, step 370/574 completed (loss: 2.417080879211426, acc: 0.38181817531585693)
[2024-11-29 03:25:36,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:36,570][root][INFO] - Training Epoch: 4/10, step 371/574 completed (loss: 1.6154048442840576, acc: 0.5377358198165894)
[2024-11-29 03:25:36,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:37,164][root][INFO] - Training Epoch: 4/10, step 372/574 completed (loss: 1.6678951978683472, acc: 0.5444444417953491)
[2024-11-29 03:25:37,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:37,757][root][INFO] - Training Epoch: 4/10, step 373/574 completed (loss: 1.478948950767517, acc: 0.6964285969734192)
[2024-11-29 03:25:37,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:38,348][root][INFO] - Training Epoch: 4/10, step 374/574 completed (loss: 0.8105316758155823, acc: 0.7714285850524902)
[2024-11-29 03:25:38,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:38,935][root][INFO] - Training Epoch: 4/10, step 375/574 completed (loss: 0.06880788505077362, acc: 1.0)
[2024-11-29 03:25:39,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:39,521][root][INFO] - Training Epoch: 4/10, step 376/574 completed (loss: 0.26800957322120667, acc: 0.9130434989929199)
[2024-11-29 03:25:39,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:40,111][root][INFO] - Training Epoch: 4/10, step 377/574 completed (loss: 1.2966700792312622, acc: 0.625)
[2024-11-29 03:25:40,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:40,706][root][INFO] - Training Epoch: 4/10, step 378/574 completed (loss: 1.5534981489181519, acc: 0.557894766330719)
[2024-11-29 03:25:40,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:41,317][root][INFO] - Training Epoch: 4/10, step 379/574 completed (loss: 1.91780686378479, acc: 0.485029935836792)
[2024-11-29 03:25:41,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:41,914][root][INFO] - Training Epoch: 4/10, step 380/574 completed (loss: 1.7006813287734985, acc: 0.5413534045219421)
[2024-11-29 03:25:41,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:42,534][root][INFO] - Training Epoch: 4/10, step 381/574 completed (loss: 1.9579792022705078, acc: 0.51871657371521)
[2024-11-29 03:25:42,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:43,151][root][INFO] - Training Epoch: 4/10, step 382/574 completed (loss: 1.4618690013885498, acc: 0.5945945978164673)
[2024-11-29 03:25:43,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:43,738][root][INFO] - Training Epoch: 4/10, step 383/574 completed (loss: 0.7696006894111633, acc: 0.8214285969734192)
[2024-11-29 03:25:43,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:44,325][root][INFO] - Training Epoch: 4/10, step 384/574 completed (loss: 0.162435382604599, acc: 0.9285714030265808)
[2024-11-29 03:25:44,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:44,913][root][INFO] - Training Epoch: 4/10, step 385/574 completed (loss: 0.6561351418495178, acc: 0.75)
[2024-11-29 03:25:44,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:45,500][root][INFO] - Training Epoch: 4/10, step 386/574 completed (loss: 0.6270090341567993, acc: 0.7777777910232544)
[2024-11-29 03:25:45,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:46,087][root][INFO] - Training Epoch: 4/10, step 387/574 completed (loss: 0.48904624581336975, acc: 0.8157894611358643)
[2024-11-29 03:25:46,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:46,673][root][INFO] - Training Epoch: 4/10, step 388/574 completed (loss: 0.0823899433016777, acc: 1.0)
[2024-11-29 03:25:46,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:47,258][root][INFO] - Training Epoch: 4/10, step 389/574 completed (loss: 0.11296401172876358, acc: 0.949999988079071)
[2024-11-29 03:25:47,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:47,844][root][INFO] - Training Epoch: 4/10, step 390/574 completed (loss: 0.08006779849529266, acc: 1.0)
[2024-11-29 03:25:47,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:48,432][root][INFO] - Training Epoch: 4/10, step 391/574 completed (loss: 1.6297063827514648, acc: 0.5740740895271301)
[2024-11-29 03:25:48,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:49,026][root][INFO] - Training Epoch: 4/10, step 392/574 completed (loss: 2.3869099617004395, acc: 0.446601927280426)
[2024-11-29 03:25:49,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:49,639][root][INFO] - Training Epoch: 4/10, step 393/574 completed (loss: 2.015702962875366, acc: 0.5220588445663452)
[2024-11-29 03:25:49,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:50,237][root][INFO] - Training Epoch: 4/10, step 394/574 completed (loss: 2.478801727294922, acc: 0.40666666626930237)
[2024-11-29 03:25:50,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:50,835][root][INFO] - Training Epoch: 4/10, step 395/574 completed (loss: 2.2131335735321045, acc: 0.4513888955116272)
[2024-11-29 03:25:50,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:51,425][root][INFO] - Training Epoch: 4/10, step 396/574 completed (loss: 1.3790079355239868, acc: 0.6511628031730652)
[2024-11-29 03:25:51,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:52,014][root][INFO] - Training Epoch: 4/10, step 397/574 completed (loss: 0.25368714332580566, acc: 0.875)
[2024-11-29 03:25:52,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:52,605][root][INFO] - Training Epoch: 4/10, step 398/574 completed (loss: 1.0526520013809204, acc: 0.6976743936538696)
[2024-11-29 03:25:52,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:53,191][root][INFO] - Training Epoch: 4/10, step 399/574 completed (loss: 0.4798281490802765, acc: 0.8799999952316284)
[2024-11-29 03:25:53,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:53,791][root][INFO] - Training Epoch: 4/10, step 400/574 completed (loss: 1.6721644401550293, acc: 0.5882353186607361)
[2024-11-29 03:25:53,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:54,384][root][INFO] - Training Epoch: 4/10, step 401/574 completed (loss: 1.424302339553833, acc: 0.5600000023841858)
[2024-11-29 03:25:54,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:54,972][root][INFO] - Training Epoch: 4/10, step 402/574 completed (loss: 0.5761499404907227, acc: 0.8484848737716675)
[2024-11-29 03:25:55,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:55,559][root][INFO] - Training Epoch: 4/10, step 403/574 completed (loss: 0.6603290438652039, acc: 0.8181818127632141)
[2024-11-29 03:25:55,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:56,145][root][INFO] - Training Epoch: 4/10, step 404/574 completed (loss: 0.14354604482650757, acc: 0.9677419066429138)
[2024-11-29 03:25:56,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:56,732][root][INFO] - Training Epoch: 4/10, step 405/574 completed (loss: 0.23240910470485687, acc: 0.9259259104728699)
[2024-11-29 03:25:56,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:57,318][root][INFO] - Training Epoch: 4/10, step 406/574 completed (loss: 0.2300437092781067, acc: 0.9200000166893005)
[2024-11-29 03:25:57,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:57,906][root][INFO] - Training Epoch: 4/10, step 407/574 completed (loss: 0.3679720461368561, acc: 0.9166666865348816)
[2024-11-29 03:25:57,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:58,494][root][INFO] - Training Epoch: 4/10, step 408/574 completed (loss: 0.21830926835536957, acc: 0.9629629850387573)
[2024-11-29 03:25:58,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:59,081][root][INFO] - Training Epoch: 4/10, step 409/574 completed (loss: 0.6226494312286377, acc: 0.8461538553237915)
[2024-11-29 03:25:59,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:59,672][root][INFO] - Training Epoch: 4/10, step 410/574 completed (loss: 0.9233555793762207, acc: 0.7068965435028076)
[2024-11-29 03:25:59,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:00,258][root][INFO] - Training Epoch: 4/10, step 411/574 completed (loss: 0.4249984622001648, acc: 0.8571428656578064)
[2024-11-29 03:26:00,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:00,846][root][INFO] - Training Epoch: 4/10, step 412/574 completed (loss: 0.6744306087493896, acc: 0.8666666746139526)
[2024-11-29 03:26:00,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:01,433][root][INFO] - Training Epoch: 4/10, step 413/574 completed (loss: 0.37505030632019043, acc: 0.939393937587738)
[2024-11-29 03:26:01,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:02,019][root][INFO] - Training Epoch: 4/10, step 414/574 completed (loss: 0.22525449097156525, acc: 0.9090909361839294)
[2024-11-29 03:26:02,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:02,611][root][INFO] - Training Epoch: 4/10, step 415/574 completed (loss: 1.5865517854690552, acc: 0.5882353186607361)
[2024-11-29 03:26:02,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:03,200][root][INFO] - Training Epoch: 4/10, step 416/574 completed (loss: 0.6793294548988342, acc: 0.7692307829856873)
[2024-11-29 03:26:03,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:03,785][root][INFO] - Training Epoch: 4/10, step 417/574 completed (loss: 0.5583707094192505, acc: 0.7777777910232544)
[2024-11-29 03:26:03,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:04,376][root][INFO] - Training Epoch: 4/10, step 418/574 completed (loss: 1.2041898965835571, acc: 0.675000011920929)
[2024-11-29 03:26:04,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:04,963][root][INFO] - Training Epoch: 4/10, step 419/574 completed (loss: 0.3184092938899994, acc: 1.0)
[2024-11-29 03:26:05,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:05,549][root][INFO] - Training Epoch: 4/10, step 420/574 completed (loss: 0.1773190051317215, acc: 0.9523809552192688)
[2024-11-29 03:26:05,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:06,135][root][INFO] - Training Epoch: 4/10, step 421/574 completed (loss: 0.5617279410362244, acc: 0.8999999761581421)
[2024-11-29 03:26:06,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:06,722][root][INFO] - Training Epoch: 4/10, step 422/574 completed (loss: 0.9604867696762085, acc: 0.78125)
[2024-11-29 03:26:07,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:08,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:08,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:09,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:09,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:10,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:10,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:11,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:11,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:12,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:12,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:13,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:13,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:14,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:14,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:15,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:15,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:16,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:16,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:17,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:18,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:18,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:19,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:19,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:20,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:20,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:21,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:21,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:22,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:22,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:23,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:23,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:24,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:24,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:25,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:26,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:26,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:27,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:27,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:28,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:28,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:29,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:29,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:30,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:30,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:31,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:31,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:32,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:32,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:33,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:34,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:34,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:35,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:35,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:36,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:36,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:37,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:37,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:38,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:38,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:39,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:39,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:40,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:40,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:41,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:42,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:42,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:43,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:43,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:44,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:44,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:45,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:45,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:46,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:46,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:47,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:47,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:48,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:48,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:49,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:49,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:50,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:51,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:51,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:52,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:52,913][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.7336, device='cuda:0') eval_epoch_loss=tensor(1.9071, device='cuda:0') eval_epoch_acc=tensor(0.5290, device='cuda:0')
[2024-11-29 03:26:52,914][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:26:52,914][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:26:53,257][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_4_step_423_loss_1.9071077108383179/model.pt
[2024-11-29 03:26:53,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:53,871][root][INFO] - Training Epoch: 4/10, step 423/574 completed (loss: 0.8443645238876343, acc: 0.75)
[2024-11-29 03:26:53,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:54,459][root][INFO] - Training Epoch: 4/10, step 424/574 completed (loss: 0.4631936550140381, acc: 0.8518518805503845)
[2024-11-29 03:26:54,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:55,045][root][INFO] - Training Epoch: 4/10, step 425/574 completed (loss: 0.3751392662525177, acc: 0.9090909361839294)
[2024-11-29 03:26:55,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:55,632][root][INFO] - Training Epoch: 4/10, step 426/574 completed (loss: 0.2836531698703766, acc: 0.8260869383811951)
[2024-11-29 03:26:55,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:56,222][root][INFO] - Training Epoch: 4/10, step 427/574 completed (loss: 0.7352800369262695, acc: 0.7567567825317383)
[2024-11-29 03:26:56,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:56,813][root][INFO] - Training Epoch: 4/10, step 428/574 completed (loss: 0.4463982880115509, acc: 0.8148148059844971)
[2024-11-29 03:26:56,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:57,399][root][INFO] - Training Epoch: 4/10, step 429/574 completed (loss: 0.36139023303985596, acc: 0.8695651888847351)
[2024-11-29 03:26:57,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:57,987][root][INFO] - Training Epoch: 4/10, step 430/574 completed (loss: 0.21755479276180267, acc: 0.8888888955116272)
[2024-11-29 03:26:58,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:58,573][root][INFO] - Training Epoch: 4/10, step 431/574 completed (loss: 0.07405020296573639, acc: 1.0)
[2024-11-29 03:26:58,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:59,160][root][INFO] - Training Epoch: 4/10, step 432/574 completed (loss: 0.21002371609210968, acc: 0.9130434989929199)
[2024-11-29 03:26:59,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:59,749][root][INFO] - Training Epoch: 4/10, step 433/574 completed (loss: 1.2311511039733887, acc: 0.6944444179534912)
[2024-11-29 03:26:59,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:00,337][root][INFO] - Training Epoch: 4/10, step 434/574 completed (loss: 0.09706990420818329, acc: 0.9599999785423279)
[2024-11-29 03:27:00,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:00,929][root][INFO] - Training Epoch: 4/10, step 435/574 completed (loss: 1.3190693855285645, acc: 0.6363636255264282)
[2024-11-29 03:27:01,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:01,517][root][INFO] - Training Epoch: 4/10, step 436/574 completed (loss: 0.9147524237632751, acc: 0.75)
[2024-11-29 03:27:01,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:02,108][root][INFO] - Training Epoch: 4/10, step 437/574 completed (loss: 1.1525866985321045, acc: 0.75)
[2024-11-29 03:27:02,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:02,694][root][INFO] - Training Epoch: 4/10, step 438/574 completed (loss: 0.35378631949424744, acc: 0.9523809552192688)
[2024-11-29 03:27:02,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:03,283][root][INFO] - Training Epoch: 4/10, step 439/574 completed (loss: 1.438891887664795, acc: 0.5897436141967773)
[2024-11-29 03:27:03,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:03,879][root][INFO] - Training Epoch: 4/10, step 440/574 completed (loss: 1.5939176082611084, acc: 0.6212121248245239)
[2024-11-29 03:27:03,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:04,490][root][INFO] - Training Epoch: 4/10, step 441/574 completed (loss: 2.559659004211426, acc: 0.335999995470047)
[2024-11-29 03:27:04,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:05,086][root][INFO] - Training Epoch: 4/10, step 442/574 completed (loss: 2.2640225887298584, acc: 0.3629032373428345)
[2024-11-29 03:27:05,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:05,699][root][INFO] - Training Epoch: 4/10, step 443/574 completed (loss: 2.473496437072754, acc: 0.35323384404182434)
[2024-11-29 03:27:05,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:06,289][root][INFO] - Training Epoch: 4/10, step 444/574 completed (loss: 1.9213422536849976, acc: 0.4716981053352356)
[2024-11-29 03:27:06,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:06,880][root][INFO] - Training Epoch: 4/10, step 445/574 completed (loss: 1.1517679691314697, acc: 0.6590909361839294)
[2024-11-29 03:27:06,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:07,467][root][INFO] - Training Epoch: 4/10, step 446/574 completed (loss: 0.9799056053161621, acc: 0.739130437374115)
[2024-11-29 03:27:07,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:08,052][root][INFO] - Training Epoch: 4/10, step 447/574 completed (loss: 0.695676863193512, acc: 0.807692289352417)
[2024-11-29 03:27:08,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:08,638][root][INFO] - Training Epoch: 4/10, step 448/574 completed (loss: 0.6320003271102905, acc: 0.7857142686843872)
[2024-11-29 03:27:08,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:09,228][root][INFO] - Training Epoch: 4/10, step 449/574 completed (loss: 2.007415771484375, acc: 0.49253731966018677)
[2024-11-29 03:27:09,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:09,820][root][INFO] - Training Epoch: 4/10, step 450/574 completed (loss: 1.6000008583068848, acc: 0.6111111044883728)
[2024-11-29 03:27:09,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:10,411][root][INFO] - Training Epoch: 4/10, step 451/574 completed (loss: 2.1244614124298096, acc: 0.44565218687057495)
[2024-11-29 03:27:10,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:11,004][root][INFO] - Training Epoch: 4/10, step 452/574 completed (loss: 2.144996166229248, acc: 0.41025641560554504)
[2024-11-29 03:27:11,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:11,595][root][INFO] - Training Epoch: 4/10, step 453/574 completed (loss: 1.843239188194275, acc: 0.4868420958518982)
[2024-11-29 03:27:11,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:12,183][root][INFO] - Training Epoch: 4/10, step 454/574 completed (loss: 1.513063907623291, acc: 0.5714285969734192)
[2024-11-29 03:27:12,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:12,771][root][INFO] - Training Epoch: 4/10, step 455/574 completed (loss: 1.0892301797866821, acc: 0.6363636255264282)
[2024-11-29 03:27:12,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:13,366][root][INFO] - Training Epoch: 4/10, step 456/574 completed (loss: 2.205911636352539, acc: 0.34020617604255676)
[2024-11-29 03:27:13,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:13,960][root][INFO] - Training Epoch: 4/10, step 457/574 completed (loss: 1.6109849214553833, acc: 0.5428571701049805)
[2024-11-29 03:27:14,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:14,581][root][INFO] - Training Epoch: 4/10, step 458/574 completed (loss: 2.436810255050659, acc: 0.36627906560897827)
[2024-11-29 03:27:14,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:15,171][root][INFO] - Training Epoch: 4/10, step 459/574 completed (loss: 1.6518570184707642, acc: 0.5714285969734192)
[2024-11-29 03:27:15,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:15,767][root][INFO] - Training Epoch: 4/10, step 460/574 completed (loss: 2.0589523315429688, acc: 0.4691357910633087)
[2024-11-29 03:27:15,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:16,356][root][INFO] - Training Epoch: 4/10, step 461/574 completed (loss: 0.847091794013977, acc: 0.75)
[2024-11-29 03:27:16,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:16,946][root][INFO] - Training Epoch: 4/10, step 462/574 completed (loss: 0.7514711618423462, acc: 0.75)
[2024-11-29 03:27:17,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:17,532][root][INFO] - Training Epoch: 4/10, step 463/574 completed (loss: 0.5218179225921631, acc: 0.8846153616905212)
[2024-11-29 03:27:17,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:18,123][root][INFO] - Training Epoch: 4/10, step 464/574 completed (loss: 1.534645915031433, acc: 0.5869565010070801)
[2024-11-29 03:27:18,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:18,717][root][INFO] - Training Epoch: 4/10, step 465/574 completed (loss: 1.8856862783432007, acc: 0.4642857015132904)
[2024-11-29 03:27:18,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:19,311][root][INFO] - Training Epoch: 4/10, step 466/574 completed (loss: 1.8294651508331299, acc: 0.5180723071098328)
[2024-11-29 03:27:19,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:19,921][root][INFO] - Training Epoch: 4/10, step 467/574 completed (loss: 1.9424887895584106, acc: 0.477477490901947)
[2024-11-29 03:27:20,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:20,515][root][INFO] - Training Epoch: 4/10, step 468/574 completed (loss: 1.9620929956436157, acc: 0.4660194218158722)
[2024-11-29 03:27:20,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:21,128][root][INFO] - Training Epoch: 4/10, step 469/574 completed (loss: 2.087249755859375, acc: 0.45528456568717957)
[2024-11-29 03:27:21,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:21,722][root][INFO] - Training Epoch: 4/10, step 470/574 completed (loss: 0.2683532238006592, acc: 0.9166666865348816)
[2024-11-29 03:27:21,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:22,316][root][INFO] - Training Epoch: 4/10, step 471/574 completed (loss: 0.6447758078575134, acc: 0.7857142686843872)
[2024-11-29 03:27:22,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:22,929][root][INFO] - Training Epoch: 4/10, step 472/574 completed (loss: 2.0363473892211914, acc: 0.3529411852359772)
[2024-11-29 03:27:23,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:23,543][root][INFO] - Training Epoch: 4/10, step 473/574 completed (loss: 2.442793607711792, acc: 0.3930130898952484)
[2024-11-29 03:27:23,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:24,138][root][INFO] - Training Epoch: 4/10, step 474/574 completed (loss: 2.149761199951172, acc: 0.46875)
[2024-11-29 03:27:24,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:24,736][root][INFO] - Training Epoch: 4/10, step 475/574 completed (loss: 2.2777936458587646, acc: 0.44171780347824097)
[2024-11-29 03:27:24,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:25,341][root][INFO] - Training Epoch: 4/10, step 476/574 completed (loss: 2.297799825668335, acc: 0.4100719392299652)
[2024-11-29 03:27:25,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:25,954][root][INFO] - Training Epoch: 4/10, step 477/574 completed (loss: 2.337102174758911, acc: 0.43718594312667847)
[2024-11-29 03:27:26,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:26,543][root][INFO] - Training Epoch: 4/10, step 478/574 completed (loss: 1.1265348196029663, acc: 0.7777777910232544)
[2024-11-29 03:27:26,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:27,130][root][INFO] - Training Epoch: 4/10, step 479/574 completed (loss: 0.6950460076332092, acc: 0.8181818127632141)
[2024-11-29 03:27:27,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:27,719][root][INFO] - Training Epoch: 4/10, step 480/574 completed (loss: 0.43346717953681946, acc: 0.8148148059844971)
[2024-11-29 03:27:27,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:28,305][root][INFO] - Training Epoch: 4/10, step 481/574 completed (loss: 0.2300967276096344, acc: 0.949999988079071)
[2024-11-29 03:27:28,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:28,891][root][INFO] - Training Epoch: 4/10, step 482/574 completed (loss: 0.19208450615406036, acc: 1.0)
[2024-11-29 03:27:28,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:29,487][root][INFO] - Training Epoch: 4/10, step 483/574 completed (loss: 1.3613371849060059, acc: 0.6551724076271057)
[2024-11-29 03:27:29,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:30,075][root][INFO] - Training Epoch: 4/10, step 484/574 completed (loss: 0.5222575664520264, acc: 0.8387096524238586)
[2024-11-29 03:27:30,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:30,664][root][INFO] - Training Epoch: 4/10, step 485/574 completed (loss: 0.37800440192222595, acc: 0.9473684430122375)
[2024-11-29 03:27:30,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:31,252][root][INFO] - Training Epoch: 4/10, step 486/574 completed (loss: 0.6033879518508911, acc: 0.8518518805503845)
[2024-11-29 03:27:31,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:31,840][root][INFO] - Training Epoch: 4/10, step 487/574 completed (loss: 0.35312703251838684, acc: 0.9047619104385376)
[2024-11-29 03:27:31,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:32,429][root][INFO] - Training Epoch: 4/10, step 488/574 completed (loss: 0.3649146258831024, acc: 0.9545454382896423)
[2024-11-29 03:27:32,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:33,021][root][INFO] - Training Epoch: 4/10, step 489/574 completed (loss: 1.6265583038330078, acc: 0.5230769515037537)
[2024-11-29 03:27:33,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:33,609][root][INFO] - Training Epoch: 4/10, step 490/574 completed (loss: 0.20188800990581512, acc: 0.9666666388511658)
[2024-11-29 03:27:33,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:34,196][root][INFO] - Training Epoch: 4/10, step 491/574 completed (loss: 0.5297777056694031, acc: 0.8965517282485962)
[2024-11-29 03:27:34,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:34,784][root][INFO] - Training Epoch: 4/10, step 492/574 completed (loss: 1.6931442022323608, acc: 0.4313725531101227)
[2024-11-29 03:27:34,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:35,371][root][INFO] - Training Epoch: 4/10, step 493/574 completed (loss: 0.7467563152313232, acc: 0.7241379022598267)
[2024-11-29 03:27:35,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:35,956][root][INFO] - Training Epoch: 4/10, step 494/574 completed (loss: 0.06222156435251236, acc: 1.0)
[2024-11-29 03:27:36,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:36,550][root][INFO] - Training Epoch: 4/10, step 495/574 completed (loss: 0.6233917474746704, acc: 0.6842105388641357)
[2024-11-29 03:27:36,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:37,148][root][INFO] - Training Epoch: 4/10, step 496/574 completed (loss: 2.0408060550689697, acc: 0.4553571343421936)
[2024-11-29 03:27:37,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:37,747][root][INFO] - Training Epoch: 4/10, step 497/574 completed (loss: 1.7704120874404907, acc: 0.483146071434021)
[2024-11-29 03:27:37,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:38,342][root][INFO] - Training Epoch: 4/10, step 498/574 completed (loss: 2.3765997886657715, acc: 0.3932584226131439)
[2024-11-29 03:27:38,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:38,952][root][INFO] - Training Epoch: 4/10, step 499/574 completed (loss: 2.573512554168701, acc: 0.39007091522216797)
[2024-11-29 03:27:39,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:39,550][root][INFO] - Training Epoch: 4/10, step 500/574 completed (loss: 2.0797371864318848, acc: 0.44565218687057495)
[2024-11-29 03:27:39,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:40,142][root][INFO] - Training Epoch: 4/10, step 501/574 completed (loss: 0.24353264272212982, acc: 0.9599999785423279)
[2024-11-29 03:27:40,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:40,729][root][INFO] - Training Epoch: 4/10, step 502/574 completed (loss: 0.2476429045200348, acc: 0.9615384340286255)
[2024-11-29 03:27:40,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:41,315][root][INFO] - Training Epoch: 4/10, step 503/574 completed (loss: 0.06775910407304764, acc: 1.0)
[2024-11-29 03:27:41,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:41,902][root][INFO] - Training Epoch: 4/10, step 504/574 completed (loss: 0.6267216801643372, acc: 0.8518518805503845)
[2024-11-29 03:27:41,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:42,495][root][INFO] - Training Epoch: 4/10, step 505/574 completed (loss: 0.9735584855079651, acc: 0.8113207817077637)
[2024-11-29 03:27:42,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:43,091][root][INFO] - Training Epoch: 4/10, step 506/574 completed (loss: 0.5206159353256226, acc: 0.8275862336158752)
[2024-11-29 03:27:43,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:43,691][root][INFO] - Training Epoch: 4/10, step 507/574 completed (loss: 2.0623104572296143, acc: 0.4954954981803894)
[2024-11-29 03:27:43,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:44,286][root][INFO] - Training Epoch: 4/10, step 508/574 completed (loss: 1.7223113775253296, acc: 0.5492957830429077)
[2024-11-29 03:27:44,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:44,873][root][INFO] - Training Epoch: 4/10, step 509/574 completed (loss: 0.010403787717223167, acc: 1.0)
[2024-11-29 03:27:44,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:45,462][root][INFO] - Training Epoch: 4/10, step 510/574 completed (loss: 0.1120481789112091, acc: 0.9666666388511658)
[2024-11-29 03:27:45,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:46,052][root][INFO] - Training Epoch: 4/10, step 511/574 completed (loss: 0.23763801157474518, acc: 0.9230769276618958)
[2024-11-29 03:27:46,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:46,688][root][INFO] - Training Epoch: 4/10, step 512/574 completed (loss: 2.3058950901031494, acc: 0.4714285731315613)
[2024-11-29 03:27:46,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:47,306][root][INFO] - Training Epoch: 4/10, step 513/574 completed (loss: 2.155766010284424, acc: 0.4365079402923584)
[2024-11-29 03:27:47,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:47,895][root][INFO] - Training Epoch: 4/10, step 514/574 completed (loss: 0.698386549949646, acc: 0.75)
[2024-11-29 03:27:47,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:48,495][root][INFO] - Training Epoch: 4/10, step 515/574 completed (loss: 1.257643461227417, acc: 0.6499999761581421)
[2024-11-29 03:27:48,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:49,105][root][INFO] - Training Epoch: 4/10, step 516/574 completed (loss: 1.798195719718933, acc: 0.5694444179534912)
[2024-11-29 03:27:49,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:49,699][root][INFO] - Training Epoch: 4/10, step 517/574 completed (loss: 0.10267525166273117, acc: 1.0)
[2024-11-29 03:27:49,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:50,287][root][INFO] - Training Epoch: 4/10, step 518/574 completed (loss: 0.5470043420791626, acc: 0.8387096524238586)
[2024-11-29 03:27:50,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:50,869][root][INFO] - Training Epoch: 4/10, step 519/574 completed (loss: 0.5463960766792297, acc: 0.8500000238418579)
[2024-11-29 03:27:50,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:51,458][root][INFO] - Training Epoch: 4/10, step 520/574 completed (loss: 0.6889618039131165, acc: 0.8148148059844971)
[2024-11-29 03:27:51,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:52,163][root][INFO] - Training Epoch: 4/10, step 521/574 completed (loss: 2.428988456726074, acc: 0.347457617521286)
[2024-11-29 03:27:52,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:52,788][root][INFO] - Training Epoch: 4/10, step 522/574 completed (loss: 2.007514238357544, acc: 0.46268656849861145)
[2024-11-29 03:27:52,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:53,387][root][INFO] - Training Epoch: 4/10, step 523/574 completed (loss: 2.17134428024292, acc: 0.40875911712646484)
[2024-11-29 03:27:53,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:54,014][root][INFO] - Training Epoch: 4/10, step 524/574 completed (loss: 2.0675394535064697, acc: 0.46000000834465027)
[2024-11-29 03:27:54,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:54,609][root][INFO] - Training Epoch: 4/10, step 525/574 completed (loss: 1.4098855257034302, acc: 0.6111111044883728)
[2024-11-29 03:27:54,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:55,200][root][INFO] - Training Epoch: 4/10, step 526/574 completed (loss: 1.3509129285812378, acc: 0.6346153616905212)
[2024-11-29 03:27:55,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:55,786][root][INFO] - Training Epoch: 4/10, step 527/574 completed (loss: 0.5799432396888733, acc: 0.8571428656578064)
[2024-11-29 03:27:55,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:56,386][root][INFO] - Training Epoch: 4/10, step 528/574 completed (loss: 2.399991989135742, acc: 0.31147539615631104)
[2024-11-29 03:27:56,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:56,977][root][INFO] - Training Epoch: 4/10, step 529/574 completed (loss: 1.4636032581329346, acc: 0.6101694703102112)
[2024-11-29 03:27:57,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:57,568][root][INFO] - Training Epoch: 4/10, step 530/574 completed (loss: 1.4561595916748047, acc: 0.6976743936538696)
[2024-11-29 03:27:57,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:58,154][root][INFO] - Training Epoch: 4/10, step 531/574 completed (loss: 1.2190725803375244, acc: 0.6363636255264282)
[2024-11-29 03:27:58,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:58,746][root][INFO] - Training Epoch: 4/10, step 532/574 completed (loss: 1.5267127752304077, acc: 0.49056604504585266)
[2024-11-29 03:27:58,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:59,336][root][INFO] - Training Epoch: 4/10, step 533/574 completed (loss: 1.1439433097839355, acc: 0.7272727489471436)
[2024-11-29 03:27:59,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:59,925][root][INFO] - Training Epoch: 4/10, step 534/574 completed (loss: 0.47482678294181824, acc: 0.8799999952316284)
[2024-11-29 03:28:00,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:00,516][root][INFO] - Training Epoch: 4/10, step 535/574 completed (loss: 0.7264400720596313, acc: 0.800000011920929)
[2024-11-29 03:28:00,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:01,109][root][INFO] - Training Epoch: 4/10, step 536/574 completed (loss: 0.56972736120224, acc: 0.8636363744735718)
[2024-11-29 03:28:01,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:01,705][root][INFO] - Training Epoch: 4/10, step 537/574 completed (loss: 1.4821194410324097, acc: 0.6000000238418579)
[2024-11-29 03:28:01,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:02,301][root][INFO] - Training Epoch: 4/10, step 538/574 completed (loss: 1.6542246341705322, acc: 0.546875)
[2024-11-29 03:28:02,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:02,895][root][INFO] - Training Epoch: 4/10, step 539/574 completed (loss: 0.8765951991081238, acc: 0.75)
[2024-11-29 03:28:02,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:03,495][root][INFO] - Training Epoch: 4/10, step 540/574 completed (loss: 0.9438101649284363, acc: 0.6666666865348816)
[2024-11-29 03:28:03,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:04,083][root][INFO] - Training Epoch: 4/10, step 541/574 completed (loss: 0.0911303162574768, acc: 1.0)
[2024-11-29 03:28:04,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:04,671][root][INFO] - Training Epoch: 4/10, step 542/574 completed (loss: 0.32151031494140625, acc: 0.9354838728904724)
[2024-11-29 03:28:04,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:05,259][root][INFO] - Training Epoch: 4/10, step 543/574 completed (loss: 0.06548182666301727, acc: 1.0)
[2024-11-29 03:28:05,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:05,847][root][INFO] - Training Epoch: 4/10, step 544/574 completed (loss: 0.6158129572868347, acc: 0.800000011920929)
[2024-11-29 03:28:05,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:06,441][root][INFO] - Training Epoch: 4/10, step 545/574 completed (loss: 1.1489663124084473, acc: 0.6585366129875183)
[2024-11-29 03:28:06,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:07,033][root][INFO] - Training Epoch: 4/10, step 546/574 completed (loss: 0.714876651763916, acc: 0.800000011920929)
[2024-11-29 03:28:07,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:07,623][root][INFO] - Training Epoch: 4/10, step 547/574 completed (loss: 0.9593459963798523, acc: 0.7631579041481018)
[2024-11-29 03:28:07,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:08,217][root][INFO] - Training Epoch: 4/10, step 548/574 completed (loss: 0.7370755672454834, acc: 0.8064516186714172)
[2024-11-29 03:28:08,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:08,812][root][INFO] - Training Epoch: 4/10, step 549/574 completed (loss: 0.11807059496641159, acc: 0.9599999785423279)
[2024-11-29 03:28:08,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:09,411][root][INFO] - Training Epoch: 4/10, step 550/574 completed (loss: 0.4554099142551422, acc: 0.8484848737716675)
[2024-11-29 03:28:09,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:10,000][root][INFO] - Training Epoch: 4/10, step 551/574 completed (loss: 0.6308442950248718, acc: 0.824999988079071)
[2024-11-29 03:28:10,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:10,603][root][INFO] - Training Epoch: 4/10, step 552/574 completed (loss: 1.057775855064392, acc: 0.7428571581840515)
[2024-11-29 03:28:10,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:11,214][root][INFO] - Training Epoch: 4/10, step 553/574 completed (loss: 2.3427751064300537, acc: 0.37956205010414124)
[2024-11-29 03:28:11,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:11,823][root][INFO] - Training Epoch: 4/10, step 554/574 completed (loss: 1.8168258666992188, acc: 0.517241358757019)
[2024-11-29 03:28:11,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:12,428][root][INFO] - Training Epoch: 4/10, step 555/574 completed (loss: 2.5009748935699463, acc: 0.2785714268684387)
[2024-11-29 03:28:12,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:13,023][root][INFO] - Training Epoch: 4/10, step 556/574 completed (loss: 2.4250080585479736, acc: 0.30463576316833496)
[2024-11-29 03:28:13,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:13,617][root][INFO] - Training Epoch: 4/10, step 557/574 completed (loss: 1.938551664352417, acc: 0.4444444477558136)
[2024-11-29 03:28:13,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:14,209][root][INFO] - Training Epoch: 4/10, step 558/574 completed (loss: 0.07332943379878998, acc: 1.0)
[2024-11-29 03:28:14,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:14,799][root][INFO] - Training Epoch: 4/10, step 559/574 completed (loss: 0.4032747447490692, acc: 0.8846153616905212)
[2024-11-29 03:28:14,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:15,386][root][INFO] - Training Epoch: 4/10, step 560/574 completed (loss: 0.5605946779251099, acc: 0.8846153616905212)
[2024-11-29 03:28:15,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:15,976][root][INFO] - Training Epoch: 4/10, step 561/574 completed (loss: 1.205843448638916, acc: 0.692307710647583)
[2024-11-29 03:28:16,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:16,585][root][INFO] - Training Epoch: 4/10, step 562/574 completed (loss: 1.7378007173538208, acc: 0.5222222208976746)
[2024-11-29 03:28:16,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:17,178][root][INFO] - Training Epoch: 4/10, step 563/574 completed (loss: 1.6265902519226074, acc: 0.5324675440788269)
[2024-11-29 03:28:17,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:17,768][root][INFO] - Training Epoch: 4/10, step 564/574 completed (loss: 1.0580021142959595, acc: 0.7291666865348816)
[2024-11-29 03:28:17,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:18,357][root][INFO] - Training Epoch: 4/10, step 565/574 completed (loss: 1.0963610410690308, acc: 0.6724137663841248)
[2024-11-29 03:28:19,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:19,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:20,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:20,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:21,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:21,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:22,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:22,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:23,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:23,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:24,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:24,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:25,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:25,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:26,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:26,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:27,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:27,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:28,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:29,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:29,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:30,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:30,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:31,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:31,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:32,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:32,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:33,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:33,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:34,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:34,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:35,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:35,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:36,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:36,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:37,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:37,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:38,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:39,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:39,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:40,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:40,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:41,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:41,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:42,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:42,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:43,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:43,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:44,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:44,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:45,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:45,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:46,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:47,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:47,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:48,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:48,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:49,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:49,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:50,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:50,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:51,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:51,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:52,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:52,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:53,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:53,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:54,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:54,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:55,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:56,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:56,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:57,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:57,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:58,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:58,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:59,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:59,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:00,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:00,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:01,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:01,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:02,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:02,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:03,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:04,246][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(4.9428, device='cuda:0') eval_epoch_loss=tensor(1.5979, device='cuda:0') eval_epoch_acc=tensor(0.5784, device='cuda:0')
[2024-11-29 03:29:04,247][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:29:04,248][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:29:04,519][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_4_step_566_loss_1.5979268550872803/model.pt
[2024-11-29 03:29:04,524][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 4 is 1.5979268550872803
[2024-11-29 03:29:04,525][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 4 is 0.5784463882446289
[2024-11-29 03:29:04,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:05,145][root][INFO] - Training Epoch: 4/10, step 566/574 completed (loss: 1.6298984289169312, acc: 0.5595238208770752)
[2024-11-29 03:29:05,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:05,741][root][INFO] - Training Epoch: 4/10, step 567/574 completed (loss: 0.6322700381278992, acc: 0.7631579041481018)
[2024-11-29 03:29:05,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:06,329][root][INFO] - Training Epoch: 4/10, step 568/574 completed (loss: 0.3208412826061249, acc: 0.9259259104728699)
[2024-11-29 03:29:06,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:06,955][root][INFO] - Training Epoch: 4/10, step 569/574 completed (loss: 2.2181951999664307, acc: 0.3957219123840332)
[2024-11-29 03:29:07,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:07,547][root][INFO] - Training Epoch: 4/10, step 570/574 completed (loss: 1.0533965826034546, acc: 0.6451612710952759)
[2024-11-29 03:29:07,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:08,146][root][INFO] - Training Epoch: 4/10, step 571/574 completed (loss: 2.040198802947998, acc: 0.41025641560554504)
[2024-11-29 03:29:08,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:08,759][root][INFO] - Training Epoch: 4/10, step 572/574 completed (loss: 2.56205677986145, acc: 0.29591837525367737)
[2024-11-29 03:29:08,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:09,371][root][INFO] - Training Epoch: 4/10, step 573/574 completed (loss: 2.205068826675415, acc: 0.3836477994918823)
[2024-11-29 03:29:09,825][slam_llm.utils.train_utils][INFO] - Epoch 4: train_perplexity=3.7183, train_epoch_loss=1.3133, epoch time 527.6775951720774s
[2024-11-29 03:29:09,825][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 15 GB
[2024-11-29 03:29:09,825][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-29 03:29:09,825][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 15 GB
[2024-11-29 03:29:09,825][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 4
[2024-11-29 03:29:09,825][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-29 03:29:10,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:10,882][root][INFO] - Training Epoch: 5/10, step 0/574 completed (loss: 0.5341313481330872, acc: 0.8518518805503845)
[2024-11-29 03:29:10,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:11,468][root][INFO] - Training Epoch: 5/10, step 1/574 completed (loss: 1.0968223810195923, acc: 0.6800000071525574)
[2024-11-29 03:29:11,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:12,056][root][INFO] - Training Epoch: 5/10, step 2/574 completed (loss: 1.4835010766983032, acc: 0.5675675868988037)
[2024-11-29 03:29:12,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:12,645][root][INFO] - Training Epoch: 5/10, step 3/574 completed (loss: 1.1463489532470703, acc: 0.6578947305679321)
[2024-11-29 03:29:12,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:13,235][root][INFO] - Training Epoch: 5/10, step 4/574 completed (loss: 1.06267511844635, acc: 0.7567567825317383)
[2024-11-29 03:29:13,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:13,830][root][INFO] - Training Epoch: 5/10, step 5/574 completed (loss: 0.8212973475456238, acc: 0.7142857313156128)
[2024-11-29 03:29:13,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:14,421][root][INFO] - Training Epoch: 5/10, step 6/574 completed (loss: 1.4758564233779907, acc: 0.6530612111091614)
[2024-11-29 03:29:14,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:15,008][root][INFO] - Training Epoch: 5/10, step 7/574 completed (loss: 0.5773022770881653, acc: 0.800000011920929)
[2024-11-29 03:29:15,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:15,593][root][INFO] - Training Epoch: 5/10, step 8/574 completed (loss: 0.03325023874640465, acc: 1.0)
[2024-11-29 03:29:15,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:16,182][root][INFO] - Training Epoch: 5/10, step 9/574 completed (loss: 0.08687480539083481, acc: 1.0)
[2024-11-29 03:29:16,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:16,770][root][INFO] - Training Epoch: 5/10, step 10/574 completed (loss: 0.21106235682964325, acc: 0.9259259104728699)
[2024-11-29 03:29:16,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:17,360][root][INFO] - Training Epoch: 5/10, step 11/574 completed (loss: 1.5923291444778442, acc: 0.6666666865348816)
[2024-11-29 03:29:17,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:17,947][root][INFO] - Training Epoch: 5/10, step 12/574 completed (loss: 0.6329741477966309, acc: 0.7878788113594055)
[2024-11-29 03:29:18,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:18,536][root][INFO] - Training Epoch: 5/10, step 13/574 completed (loss: 1.2221733331680298, acc: 0.6304348111152649)
[2024-11-29 03:29:18,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:19,125][root][INFO] - Training Epoch: 5/10, step 14/574 completed (loss: 1.33623468875885, acc: 0.5882353186607361)
[2024-11-29 03:29:19,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:19,717][root][INFO] - Training Epoch: 5/10, step 15/574 completed (loss: 1.18808114528656, acc: 0.7142857313156128)
[2024-11-29 03:29:19,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:20,304][root][INFO] - Training Epoch: 5/10, step 16/574 completed (loss: 0.041235219687223434, acc: 1.0)
[2024-11-29 03:29:20,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:20,891][root][INFO] - Training Epoch: 5/10, step 17/574 completed (loss: 0.334209680557251, acc: 0.875)
[2024-11-29 03:29:20,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:21,479][root][INFO] - Training Epoch: 5/10, step 18/574 completed (loss: 1.1218308210372925, acc: 0.6944444179534912)
[2024-11-29 03:29:21,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:22,064][root][INFO] - Training Epoch: 5/10, step 19/574 completed (loss: 0.30263274908065796, acc: 0.8421052694320679)
[2024-11-29 03:29:22,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:22,651][root][INFO] - Training Epoch: 5/10, step 20/574 completed (loss: 0.3824191689491272, acc: 0.9615384340286255)
[2024-11-29 03:29:22,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:23,238][root][INFO] - Training Epoch: 5/10, step 21/574 completed (loss: 0.8001157641410828, acc: 0.6896551847457886)
[2024-11-29 03:29:23,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:23,826][root][INFO] - Training Epoch: 5/10, step 22/574 completed (loss: 0.31016749143600464, acc: 0.8799999952316284)
[2024-11-29 03:29:23,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:24,413][root][INFO] - Training Epoch: 5/10, step 23/574 completed (loss: 0.24634721875190735, acc: 0.9047619104385376)
[2024-11-29 03:29:24,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:24,999][root][INFO] - Training Epoch: 5/10, step 24/574 completed (loss: 0.2286505550146103, acc: 0.9375)
[2024-11-29 03:29:25,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:25,593][root][INFO] - Training Epoch: 5/10, step 25/574 completed (loss: 1.7675981521606445, acc: 0.4716981053352356)
[2024-11-29 03:29:25,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:26,182][root][INFO] - Training Epoch: 5/10, step 26/574 completed (loss: 1.7159173488616943, acc: 0.4931506812572479)
[2024-11-29 03:29:26,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:26,857][root][INFO] - Training Epoch: 5/10, step 27/574 completed (loss: 2.666433811187744, acc: 0.2924901247024536)
[2024-11-29 03:29:26,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:27,445][root][INFO] - Training Epoch: 5/10, step 28/574 completed (loss: 1.657360553741455, acc: 0.5116279125213623)
[2024-11-29 03:29:27,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:28,038][root][INFO] - Training Epoch: 5/10, step 29/574 completed (loss: 1.803432583808899, acc: 0.46987950801849365)
[2024-11-29 03:29:28,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:28,635][root][INFO] - Training Epoch: 5/10, step 30/574 completed (loss: 1.8656774759292603, acc: 0.395061731338501)
[2024-11-29 03:29:28,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:29,223][root][INFO] - Training Epoch: 5/10, step 31/574 completed (loss: 0.9969592094421387, acc: 0.75)
[2024-11-29 03:29:29,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:29,811][root][INFO] - Training Epoch: 5/10, step 32/574 completed (loss: 0.3682997524738312, acc: 0.8888888955116272)
[2024-11-29 03:29:29,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:30,397][root][INFO] - Training Epoch: 5/10, step 33/574 completed (loss: 0.2889816462993622, acc: 0.9130434989929199)
[2024-11-29 03:29:30,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:30,996][root][INFO] - Training Epoch: 5/10, step 34/574 completed (loss: 1.9906558990478516, acc: 0.462184876203537)
[2024-11-29 03:29:31,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:31,592][root][INFO] - Training Epoch: 5/10, step 35/574 completed (loss: 1.4483251571655273, acc: 0.5737704634666443)
[2024-11-29 03:29:31,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:32,187][root][INFO] - Training Epoch: 5/10, step 36/574 completed (loss: 1.4958629608154297, acc: 0.6349206566810608)
[2024-11-29 03:29:32,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:32,777][root][INFO] - Training Epoch: 5/10, step 37/574 completed (loss: 1.6355098485946655, acc: 0.6440678238868713)
[2024-11-29 03:29:32,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:33,369][root][INFO] - Training Epoch: 5/10, step 38/574 completed (loss: 1.5214430093765259, acc: 0.5977011322975159)
[2024-11-29 03:29:33,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:33,956][root][INFO] - Training Epoch: 5/10, step 39/574 completed (loss: 0.07004062086343765, acc: 1.0)
[2024-11-29 03:29:34,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:34,543][root][INFO] - Training Epoch: 5/10, step 40/574 completed (loss: 0.8336356282234192, acc: 0.6153846383094788)
[2024-11-29 03:29:34,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:35,136][root][INFO] - Training Epoch: 5/10, step 41/574 completed (loss: 2.0963075160980225, acc: 0.4864864945411682)
[2024-11-29 03:29:35,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:35,726][root][INFO] - Training Epoch: 5/10, step 42/574 completed (loss: 1.396893858909607, acc: 0.6153846383094788)
[2024-11-29 03:29:35,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:36,319][root][INFO] - Training Epoch: 5/10, step 43/574 completed (loss: 2.057927370071411, acc: 0.49494948983192444)
[2024-11-29 03:29:36,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:36,914][root][INFO] - Training Epoch: 5/10, step 44/574 completed (loss: 1.8162288665771484, acc: 0.5463917255401611)
[2024-11-29 03:29:36,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:37,513][root][INFO] - Training Epoch: 5/10, step 45/574 completed (loss: 2.177037477493286, acc: 0.41911765933036804)
[2024-11-29 03:29:37,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:38,100][root][INFO] - Training Epoch: 5/10, step 46/574 completed (loss: 0.21277903020381927, acc: 0.9230769276618958)
[2024-11-29 03:29:38,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:38,688][root][INFO] - Training Epoch: 5/10, step 47/574 completed (loss: 0.27740007638931274, acc: 0.8888888955116272)
[2024-11-29 03:29:38,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:39,275][root][INFO] - Training Epoch: 5/10, step 48/574 completed (loss: 0.8338221311569214, acc: 0.7857142686843872)
[2024-11-29 03:29:39,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:39,861][root][INFO] - Training Epoch: 5/10, step 49/574 completed (loss: 0.5799824595451355, acc: 0.8055555820465088)
[2024-11-29 03:29:39,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:40,451][root][INFO] - Training Epoch: 5/10, step 50/574 completed (loss: 1.030470848083496, acc: 0.6842105388641357)
[2024-11-29 03:29:40,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:41,047][root][INFO] - Training Epoch: 5/10, step 51/574 completed (loss: 1.4032155275344849, acc: 0.6349206566810608)
[2024-11-29 03:29:41,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:41,640][root][INFO] - Training Epoch: 5/10, step 52/574 completed (loss: 1.667327880859375, acc: 0.5211267471313477)
[2024-11-29 03:29:41,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:42,254][root][INFO] - Training Epoch: 5/10, step 53/574 completed (loss: 2.664062023162842, acc: 0.4333333373069763)
[2024-11-29 03:29:42,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:42,842][root][INFO] - Training Epoch: 5/10, step 54/574 completed (loss: 0.5789655447006226, acc: 0.837837815284729)
[2024-11-29 03:29:42,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:43,428][root][INFO] - Training Epoch: 5/10, step 55/574 completed (loss: 0.40581566095352173, acc: 0.8461538553237915)
[2024-11-29 03:29:43,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:44,129][root][INFO] - Training Epoch: 5/10, step 56/574 completed (loss: 2.261910915374756, acc: 0.467576801776886)
[2024-11-29 03:29:44,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:44,786][root][INFO] - Training Epoch: 5/10, step 57/574 completed (loss: 2.6018927097320557, acc: 0.37472766637802124)
[2024-11-29 03:29:44,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:45,400][root][INFO] - Training Epoch: 5/10, step 58/574 completed (loss: 2.0213263034820557, acc: 0.4886363744735718)
[2024-11-29 03:29:45,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:45,997][root][INFO] - Training Epoch: 5/10, step 59/574 completed (loss: 2.330320358276367, acc: 0.4264705777168274)
[2024-11-29 03:29:46,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:46,608][root][INFO] - Training Epoch: 5/10, step 60/574 completed (loss: 2.1098248958587646, acc: 0.41304346919059753)
[2024-11-29 03:29:46,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:47,215][root][INFO] - Training Epoch: 5/10, step 61/574 completed (loss: 1.7814359664916992, acc: 0.5375000238418579)
[2024-11-29 03:29:47,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:47,801][root][INFO] - Training Epoch: 5/10, step 62/574 completed (loss: 0.9472672939300537, acc: 0.7941176295280457)
[2024-11-29 03:29:47,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:48,391][root][INFO] - Training Epoch: 5/10, step 63/574 completed (loss: 0.8758840560913086, acc: 0.75)
[2024-11-29 03:29:48,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:48,986][root][INFO] - Training Epoch: 5/10, step 64/574 completed (loss: 1.3282819986343384, acc: 0.640625)
[2024-11-29 03:29:49,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:49,574][root][INFO] - Training Epoch: 5/10, step 65/574 completed (loss: 0.26621147990226746, acc: 0.8965517282485962)
[2024-11-29 03:29:49,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:50,165][root][INFO] - Training Epoch: 5/10, step 66/574 completed (loss: 1.3974369764328003, acc: 0.6428571343421936)
[2024-11-29 03:29:50,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:50,756][root][INFO] - Training Epoch: 5/10, step 67/574 completed (loss: 1.4879311323165894, acc: 0.6333333253860474)
[2024-11-29 03:29:50,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:51,344][root][INFO] - Training Epoch: 5/10, step 68/574 completed (loss: 0.08428414165973663, acc: 1.0)
[2024-11-29 03:29:51,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:51,932][root][INFO] - Training Epoch: 5/10, step 69/574 completed (loss: 0.6799733638763428, acc: 0.8055555820465088)
[2024-11-29 03:29:52,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:52,521][root][INFO] - Training Epoch: 5/10, step 70/574 completed (loss: 0.4452400207519531, acc: 0.9090909361839294)
[2024-11-29 03:29:52,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:53,131][root][INFO] - Training Epoch: 5/10, step 71/574 completed (loss: 2.1468911170959473, acc: 0.41911765933036804)
[2024-11-29 03:29:53,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:53,730][root][INFO] - Training Epoch: 5/10, step 72/574 completed (loss: 2.051572561264038, acc: 0.420634925365448)
[2024-11-29 03:29:53,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:54,343][root][INFO] - Training Epoch: 5/10, step 73/574 completed (loss: 2.4594991207122803, acc: 0.4153846204280853)
[2024-11-29 03:29:54,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:54,939][root][INFO] - Training Epoch: 5/10, step 74/574 completed (loss: 1.775126576423645, acc: 0.5102040767669678)
[2024-11-29 03:29:55,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:55,537][root][INFO] - Training Epoch: 5/10, step 75/574 completed (loss: 2.3922860622406006, acc: 0.36567163467407227)
[2024-11-29 03:29:55,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:56,162][root][INFO] - Training Epoch: 5/10, step 76/574 completed (loss: 2.493373394012451, acc: 0.37956205010414124)
[2024-11-29 03:29:56,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:56,747][root][INFO] - Training Epoch: 5/10, step 77/574 completed (loss: 0.020985808223485947, acc: 1.0)
[2024-11-29 03:29:56,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:57,333][root][INFO] - Training Epoch: 5/10, step 78/574 completed (loss: 0.023838726803660393, acc: 1.0)
[2024-11-29 03:29:57,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:57,920][root][INFO] - Training Epoch: 5/10, step 79/574 completed (loss: 0.2649824321269989, acc: 0.9696969985961914)
[2024-11-29 03:29:57,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:58,505][root][INFO] - Training Epoch: 5/10, step 80/574 completed (loss: 0.07310421764850616, acc: 1.0)
[2024-11-29 03:29:58,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:59,096][root][INFO] - Training Epoch: 5/10, step 81/574 completed (loss: 1.5680228471755981, acc: 0.6153846383094788)
[2024-11-29 03:29:59,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:59,688][root][INFO] - Training Epoch: 5/10, step 82/574 completed (loss: 1.5105643272399902, acc: 0.5961538553237915)
[2024-11-29 03:29:59,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:00,274][root][INFO] - Training Epoch: 5/10, step 83/574 completed (loss: 0.497367262840271, acc: 0.90625)
[2024-11-29 03:30:00,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:00,866][root][INFO] - Training Epoch: 5/10, step 84/574 completed (loss: 1.280410647392273, acc: 0.5942028760910034)
[2024-11-29 03:30:00,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:01,457][root][INFO] - Training Epoch: 5/10, step 85/574 completed (loss: 1.2658230066299438, acc: 0.699999988079071)
[2024-11-29 03:30:01,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:02,046][root][INFO] - Training Epoch: 5/10, step 86/574 completed (loss: 0.2996078431606293, acc: 0.9130434989929199)
[2024-11-29 03:30:02,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:02,639][root][INFO] - Training Epoch: 5/10, step 87/574 completed (loss: 1.654962420463562, acc: 0.5600000023841858)
[2024-11-29 03:30:02,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:03,238][root][INFO] - Training Epoch: 5/10, step 88/574 completed (loss: 1.5571832656860352, acc: 0.582524299621582)
[2024-11-29 03:30:03,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:03,850][root][INFO] - Training Epoch: 5/10, step 89/574 completed (loss: 1.9527190923690796, acc: 0.5145630836486816)
[2024-11-29 03:30:03,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:04,464][root][INFO] - Training Epoch: 5/10, step 90/574 completed (loss: 2.1518752574920654, acc: 0.4301075339317322)
[2024-11-29 03:30:04,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:05,085][root][INFO] - Training Epoch: 5/10, step 91/574 completed (loss: 2.004666566848755, acc: 0.5043103694915771)
[2024-11-29 03:30:05,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:05,684][root][INFO] - Training Epoch: 5/10, step 92/574 completed (loss: 1.6418977975845337, acc: 0.5368421077728271)
[2024-11-29 03:30:05,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:06,302][root][INFO] - Training Epoch: 5/10, step 93/574 completed (loss: 2.350123405456543, acc: 0.40594059228897095)
[2024-11-29 03:30:06,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:06,893][root][INFO] - Training Epoch: 5/10, step 94/574 completed (loss: 1.8514434099197388, acc: 0.4516128897666931)
[2024-11-29 03:30:06,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:07,484][root][INFO] - Training Epoch: 5/10, step 95/574 completed (loss: 1.4695181846618652, acc: 0.5507246255874634)
[2024-11-29 03:30:07,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:08,080][root][INFO] - Training Epoch: 5/10, step 96/574 completed (loss: 2.1835877895355225, acc: 0.4117647111415863)
[2024-11-29 03:30:08,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:08,675][root][INFO] - Training Epoch: 5/10, step 97/574 completed (loss: 2.1234869956970215, acc: 0.38461539149284363)
[2024-11-29 03:30:08,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:09,272][root][INFO] - Training Epoch: 5/10, step 98/574 completed (loss: 2.3521008491516113, acc: 0.37956205010414124)
[2024-11-29 03:30:09,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:09,860][root][INFO] - Training Epoch: 5/10, step 99/574 completed (loss: 1.7635414600372314, acc: 0.49253731966018677)
[2024-11-29 03:30:09,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:10,453][root][INFO] - Training Epoch: 5/10, step 100/574 completed (loss: 0.08177827298641205, acc: 1.0)
[2024-11-29 03:30:10,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:11,039][root][INFO] - Training Epoch: 5/10, step 101/574 completed (loss: 0.04713154211640358, acc: 1.0)
[2024-11-29 03:30:11,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:11,624][root][INFO] - Training Epoch: 5/10, step 102/574 completed (loss: 0.1467331349849701, acc: 0.95652174949646)
[2024-11-29 03:30:11,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:12,214][root][INFO] - Training Epoch: 5/10, step 103/574 completed (loss: 0.47620251774787903, acc: 0.8863636255264282)
[2024-11-29 03:30:12,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:12,806][root][INFO] - Training Epoch: 5/10, step 104/574 completed (loss: 1.2676208019256592, acc: 0.6379310488700867)
[2024-11-29 03:30:12,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:13,395][root][INFO] - Training Epoch: 5/10, step 105/574 completed (loss: 0.6049278378486633, acc: 0.7906976938247681)
[2024-11-29 03:30:13,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:13,981][root][INFO] - Training Epoch: 5/10, step 106/574 completed (loss: 0.2896341383457184, acc: 0.8799999952316284)
[2024-11-29 03:30:14,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:14,568][root][INFO] - Training Epoch: 5/10, step 107/574 completed (loss: 0.010360888205468655, acc: 1.0)
[2024-11-29 03:30:14,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:15,154][root][INFO] - Training Epoch: 5/10, step 108/574 completed (loss: 0.020895281806588173, acc: 1.0)
[2024-11-29 03:30:15,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:15,742][root][INFO] - Training Epoch: 5/10, step 109/574 completed (loss: 0.8727368116378784, acc: 0.738095223903656)
[2024-11-29 03:30:15,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:16,334][root][INFO] - Training Epoch: 5/10, step 110/574 completed (loss: 1.634277582168579, acc: 0.5538461804389954)
[2024-11-29 03:30:16,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:16,925][root][INFO] - Training Epoch: 5/10, step 111/574 completed (loss: 1.5990310907363892, acc: 0.5438596606254578)
[2024-11-29 03:30:17,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:17,516][root][INFO] - Training Epoch: 5/10, step 112/574 completed (loss: 1.4730876684188843, acc: 0.5614035129547119)
[2024-11-29 03:30:17,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:18,102][root][INFO] - Training Epoch: 5/10, step 113/574 completed (loss: 0.8504589796066284, acc: 0.7435897588729858)
[2024-11-29 03:30:18,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:18,693][root][INFO] - Training Epoch: 5/10, step 114/574 completed (loss: 0.9193031787872314, acc: 0.7142857313156128)
[2024-11-29 03:30:18,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:19,278][root][INFO] - Training Epoch: 5/10, step 115/574 completed (loss: 0.019008858129382133, acc: 1.0)
[2024-11-29 03:30:19,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:19,872][root][INFO] - Training Epoch: 5/10, step 116/574 completed (loss: 1.7237578630447388, acc: 0.5714285969734192)
[2024-11-29 03:30:19,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:20,465][root][INFO] - Training Epoch: 5/10, step 117/574 completed (loss: 1.813485026359558, acc: 0.5609756112098694)
[2024-11-29 03:30:20,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:21,057][root][INFO] - Training Epoch: 5/10, step 118/574 completed (loss: 1.6097626686096191, acc: 0.6612903475761414)
[2024-11-29 03:30:21,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:21,695][root][INFO] - Training Epoch: 5/10, step 119/574 completed (loss: 2.3640379905700684, acc: 0.3916349709033966)
[2024-11-29 03:30:21,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:22,289][root][INFO] - Training Epoch: 5/10, step 120/574 completed (loss: 1.0985512733459473, acc: 0.6800000071525574)
[2024-11-29 03:30:22,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:22,883][root][INFO] - Training Epoch: 5/10, step 121/574 completed (loss: 1.1927564144134521, acc: 0.7307692170143127)
[2024-11-29 03:30:22,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:23,468][root][INFO] - Training Epoch: 5/10, step 122/574 completed (loss: 0.26961562037467957, acc: 0.9583333134651184)
[2024-11-29 03:30:23,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:24,053][root][INFO] - Training Epoch: 5/10, step 123/574 completed (loss: 0.18374653160572052, acc: 0.9473684430122375)
[2024-11-29 03:30:24,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:24,651][root][INFO] - Training Epoch: 5/10, step 124/574 completed (loss: 2.2726690769195557, acc: 0.42944785952568054)
[2024-11-29 03:30:24,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:25,264][root][INFO] - Training Epoch: 5/10, step 125/574 completed (loss: 1.9465222358703613, acc: 0.4861111044883728)
[2024-11-29 03:30:25,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:25,864][root][INFO] - Training Epoch: 5/10, step 126/574 completed (loss: 2.117177724838257, acc: 0.46666666865348816)
[2024-11-29 03:30:25,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:26,493][root][INFO] - Training Epoch: 5/10, step 127/574 completed (loss: 2.1469790935516357, acc: 0.4226190447807312)
[2024-11-29 03:30:26,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:27,110][root][INFO] - Training Epoch: 5/10, step 128/574 completed (loss: 2.085768222808838, acc: 0.446153849363327)
[2024-11-29 03:30:27,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:27,733][root][INFO] - Training Epoch: 5/10, step 129/574 completed (loss: 1.941516637802124, acc: 0.4852941036224365)
[2024-11-29 03:30:27,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:28,321][root][INFO] - Training Epoch: 5/10, step 130/574 completed (loss: 0.17683567106723785, acc: 0.9615384340286255)
[2024-11-29 03:30:28,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:28,907][root][INFO] - Training Epoch: 5/10, step 131/574 completed (loss: 0.08377784490585327, acc: 1.0)
[2024-11-29 03:30:28,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:29,493][root][INFO] - Training Epoch: 5/10, step 132/574 completed (loss: 0.5978705286979675, acc: 0.84375)
[2024-11-29 03:30:29,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:30,079][root][INFO] - Training Epoch: 5/10, step 133/574 completed (loss: 0.86052405834198, acc: 0.8695651888847351)
[2024-11-29 03:30:30,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:30,667][root][INFO] - Training Epoch: 5/10, step 134/574 completed (loss: 0.4338666498661041, acc: 0.8857142925262451)
[2024-11-29 03:30:31,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:31,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:32,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:33,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:33,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:34,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:34,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:35,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:35,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:36,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:36,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:37,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:37,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:38,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:38,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:39,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:39,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:40,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:40,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:41,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:41,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:42,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:42,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:43,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:43,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:44,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:45,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:45,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:46,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:46,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:47,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:47,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:48,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:48,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:49,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:49,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:50,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:50,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:51,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:51,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:52,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:52,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:53,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:54,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:54,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:55,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:55,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:56,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:56,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:57,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:57,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:58,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:58,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:59,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:59,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:00,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:00,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:01,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:01,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:02,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:03,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:03,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:04,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:04,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:05,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:05,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:06,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:06,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:07,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:07,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:08,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:08,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:09,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:09,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:10,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:11,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:11,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:12,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:12,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:13,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:13,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:14,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:14,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:15,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:15,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:16,552][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(4.5844, device='cuda:0') eval_epoch_loss=tensor(1.5227, device='cuda:0') eval_epoch_acc=tensor(0.6096, device='cuda:0')
[2024-11-29 03:31:16,553][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:31:16,554][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:31:17,023][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_5_step_135_loss_1.5226589441299438/model.pt
[2024-11-29 03:31:17,026][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 5 is 1.5226589441299438
[2024-11-29 03:31:17,026][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 5 is 0.609586238861084
[2024-11-29 03:31:17,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:17,632][root][INFO] - Training Epoch: 5/10, step 135/574 completed (loss: 0.4223203659057617, acc: 0.8846153616905212)
[2024-11-29 03:31:17,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:18,221][root][INFO] - Training Epoch: 5/10, step 136/574 completed (loss: 1.1099599599838257, acc: 0.738095223903656)
[2024-11-29 03:31:18,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:18,808][root][INFO] - Training Epoch: 5/10, step 137/574 completed (loss: 0.3860122859477997, acc: 0.9333333373069763)
[2024-11-29 03:31:18,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:19,398][root][INFO] - Training Epoch: 5/10, step 138/574 completed (loss: 0.41895148158073425, acc: 0.8695651888847351)
[2024-11-29 03:31:19,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:19,984][root][INFO] - Training Epoch: 5/10, step 139/574 completed (loss: 0.3184524178504944, acc: 0.9047619104385376)
[2024-11-29 03:31:20,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:20,570][root][INFO] - Training Epoch: 5/10, step 140/574 completed (loss: 0.21528838574886322, acc: 0.9230769276618958)
[2024-11-29 03:31:20,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:21,155][root][INFO] - Training Epoch: 5/10, step 141/574 completed (loss: 0.9282966256141663, acc: 0.7096773982048035)
[2024-11-29 03:31:21,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:21,742][root][INFO] - Training Epoch: 5/10, step 142/574 completed (loss: 1.0245928764343262, acc: 0.6756756901741028)
[2024-11-29 03:31:21,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:22,355][root][INFO] - Training Epoch: 5/10, step 143/574 completed (loss: 1.5663436651229858, acc: 0.6052631735801697)
[2024-11-29 03:31:22,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:22,951][root][INFO] - Training Epoch: 5/10, step 144/574 completed (loss: 1.5400387048721313, acc: 0.5820895433425903)
[2024-11-29 03:31:23,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:23,551][root][INFO] - Training Epoch: 5/10, step 145/574 completed (loss: 1.9913733005523682, acc: 0.4183673560619354)
[2024-11-29 03:31:23,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:24,159][root][INFO] - Training Epoch: 5/10, step 146/574 completed (loss: 1.9663766622543335, acc: 0.43617022037506104)
[2024-11-29 03:31:24,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:24,752][root][INFO] - Training Epoch: 5/10, step 147/574 completed (loss: 1.4973100423812866, acc: 0.6571428775787354)
[2024-11-29 03:31:24,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:25,339][root][INFO] - Training Epoch: 5/10, step 148/574 completed (loss: 0.8840003609657288, acc: 0.7142857313156128)
[2024-11-29 03:31:25,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:25,923][root][INFO] - Training Epoch: 5/10, step 149/574 completed (loss: 0.3502615690231323, acc: 0.8260869383811951)
[2024-11-29 03:31:26,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:26,510][root][INFO] - Training Epoch: 5/10, step 150/574 completed (loss: 0.9794392585754395, acc: 0.6896551847457886)
[2024-11-29 03:31:26,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:27,099][root][INFO] - Training Epoch: 5/10, step 151/574 completed (loss: 1.4508275985717773, acc: 0.5652173757553101)
[2024-11-29 03:31:27,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:27,693][root][INFO] - Training Epoch: 5/10, step 152/574 completed (loss: 1.5349661111831665, acc: 0.508474588394165)
[2024-11-29 03:31:27,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:28,285][root][INFO] - Training Epoch: 5/10, step 153/574 completed (loss: 1.875718355178833, acc: 0.4736842215061188)
[2024-11-29 03:31:28,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:28,882][root][INFO] - Training Epoch: 5/10, step 154/574 completed (loss: 1.401408314704895, acc: 0.662162184715271)
[2024-11-29 03:31:28,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:29,470][root][INFO] - Training Epoch: 5/10, step 155/574 completed (loss: 0.5135357975959778, acc: 0.8571428656578064)
[2024-11-29 03:31:29,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:30,057][root][INFO] - Training Epoch: 5/10, step 156/574 completed (loss: 0.28139182925224304, acc: 0.9130434989929199)
[2024-11-29 03:31:30,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:30,644][root][INFO] - Training Epoch: 5/10, step 157/574 completed (loss: 0.5028745532035828, acc: 0.9473684430122375)
[2024-11-29 03:31:30,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:31,236][root][INFO] - Training Epoch: 5/10, step 158/574 completed (loss: 1.377704381942749, acc: 0.6216216087341309)
[2024-11-29 03:31:31,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:31,827][root][INFO] - Training Epoch: 5/10, step 159/574 completed (loss: 1.6889358758926392, acc: 0.48148149251937866)
[2024-11-29 03:31:31,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:32,421][root][INFO] - Training Epoch: 5/10, step 160/574 completed (loss: 1.8460537195205688, acc: 0.5)
[2024-11-29 03:31:32,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:33,013][root][INFO] - Training Epoch: 5/10, step 161/574 completed (loss: 1.4793384075164795, acc: 0.6235294342041016)
[2024-11-29 03:31:33,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:33,615][root][INFO] - Training Epoch: 5/10, step 162/574 completed (loss: 1.9532145261764526, acc: 0.516853928565979)
[2024-11-29 03:31:33,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:34,206][root][INFO] - Training Epoch: 5/10, step 163/574 completed (loss: 1.3831106424331665, acc: 0.6590909361839294)
[2024-11-29 03:31:34,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:34,793][root][INFO] - Training Epoch: 5/10, step 164/574 completed (loss: 0.1761140674352646, acc: 0.9523809552192688)
[2024-11-29 03:31:34,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:35,380][root][INFO] - Training Epoch: 5/10, step 165/574 completed (loss: 0.5948724150657654, acc: 0.8275862336158752)
[2024-11-29 03:31:35,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:35,971][root][INFO] - Training Epoch: 5/10, step 166/574 completed (loss: 0.6334852576255798, acc: 0.795918345451355)
[2024-11-29 03:31:36,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:36,560][root][INFO] - Training Epoch: 5/10, step 167/574 completed (loss: 0.9969825744628906, acc: 0.7400000095367432)
[2024-11-29 03:31:36,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:37,155][root][INFO] - Training Epoch: 5/10, step 168/574 completed (loss: 1.3695036172866821, acc: 0.6527777910232544)
[2024-11-29 03:31:37,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:37,751][root][INFO] - Training Epoch: 5/10, step 169/574 completed (loss: 1.8198769092559814, acc: 0.5)
[2024-11-29 03:31:37,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:38,375][root][INFO] - Training Epoch: 5/10, step 170/574 completed (loss: 2.475050926208496, acc: 0.39726027846336365)
[2024-11-29 03:31:38,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:38,964][root][INFO] - Training Epoch: 5/10, step 171/574 completed (loss: 0.29008740186691284, acc: 0.9166666865348816)
[2024-11-29 03:31:39,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:39,550][root][INFO] - Training Epoch: 5/10, step 172/574 completed (loss: 0.27840009331703186, acc: 0.9259259104728699)
[2024-11-29 03:31:39,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:40,136][root][INFO] - Training Epoch: 5/10, step 173/574 completed (loss: 0.7183151245117188, acc: 0.75)
[2024-11-29 03:31:40,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:40,746][root][INFO] - Training Epoch: 5/10, step 174/574 completed (loss: 1.8597828149795532, acc: 0.5398229956626892)
[2024-11-29 03:31:40,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:41,337][root][INFO] - Training Epoch: 5/10, step 175/574 completed (loss: 1.2607053518295288, acc: 0.6521739363670349)
[2024-11-29 03:31:41,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:41,934][root][INFO] - Training Epoch: 5/10, step 176/574 completed (loss: 1.5853949785232544, acc: 0.5909090638160706)
[2024-11-29 03:31:42,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:42,547][root][INFO] - Training Epoch: 5/10, step 177/574 completed (loss: 2.3673930168151855, acc: 0.35114502906799316)
[2024-11-29 03:31:42,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:43,157][root][INFO] - Training Epoch: 5/10, step 178/574 completed (loss: 2.4172558784484863, acc: 0.39259257912635803)
[2024-11-29 03:31:43,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:43,749][root][INFO] - Training Epoch: 5/10, step 179/574 completed (loss: 1.1167075634002686, acc: 0.6721311211585999)
[2024-11-29 03:31:43,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:44,339][root][INFO] - Training Epoch: 5/10, step 180/574 completed (loss: 0.16716039180755615, acc: 0.9583333134651184)
[2024-11-29 03:31:44,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:44,924][root][INFO] - Training Epoch: 5/10, step 181/574 completed (loss: 0.4367481470108032, acc: 0.8799999952316284)
[2024-11-29 03:31:45,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:45,510][root][INFO] - Training Epoch: 5/10, step 182/574 completed (loss: 0.22620785236358643, acc: 0.8571428656578064)
[2024-11-29 03:31:45,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:46,103][root][INFO] - Training Epoch: 5/10, step 183/574 completed (loss: 1.583757758140564, acc: 0.5975610017776489)
[2024-11-29 03:31:46,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:46,729][root][INFO] - Training Epoch: 5/10, step 184/574 completed (loss: 2.4744341373443604, acc: 0.35347431898117065)
[2024-11-29 03:31:46,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:47,353][root][INFO] - Training Epoch: 5/10, step 185/574 completed (loss: 2.540166139602661, acc: 0.3083573579788208)
[2024-11-29 03:31:47,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:47,973][root][INFO] - Training Epoch: 5/10, step 186/574 completed (loss: 2.6679611206054688, acc: 0.35624998807907104)
[2024-11-29 03:31:48,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:48,629][root][INFO] - Training Epoch: 5/10, step 187/574 completed (loss: 2.6833813190460205, acc: 0.31144464015960693)
[2024-11-29 03:31:48,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:49,262][root][INFO] - Training Epoch: 5/10, step 188/574 completed (loss: 2.3010740280151367, acc: 0.38078293204307556)
[2024-11-29 03:31:49,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:49,848][root][INFO] - Training Epoch: 5/10, step 189/574 completed (loss: 0.7464910745620728, acc: 0.8399999737739563)
[2024-11-29 03:31:49,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:50,441][root][INFO] - Training Epoch: 5/10, step 190/574 completed (loss: 2.0695595741271973, acc: 0.41860464215278625)
[2024-11-29 03:31:50,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:51,038][root][INFO] - Training Epoch: 5/10, step 191/574 completed (loss: 2.0442283153533936, acc: 0.460317462682724)
[2024-11-29 03:31:51,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:51,635][root][INFO] - Training Epoch: 5/10, step 192/574 completed (loss: 2.2502565383911133, acc: 0.4015151560306549)
[2024-11-29 03:31:51,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:52,231][root][INFO] - Training Epoch: 5/10, step 193/574 completed (loss: 1.5276665687561035, acc: 0.5882353186607361)
[2024-11-29 03:31:52,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:52,843][root][INFO] - Training Epoch: 5/10, step 194/574 completed (loss: 1.8727468252182007, acc: 0.4938271641731262)
[2024-11-29 03:31:52,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:53,439][root][INFO] - Training Epoch: 5/10, step 195/574 completed (loss: 1.2720896005630493, acc: 0.6290322542190552)
[2024-11-29 03:31:53,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:54,027][root][INFO] - Training Epoch: 5/10, step 196/574 completed (loss: 0.2715168595314026, acc: 0.9285714030265808)
[2024-11-29 03:31:54,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:54,615][root][INFO] - Training Epoch: 5/10, step 197/574 completed (loss: 0.9132461547851562, acc: 0.75)
[2024-11-29 03:31:54,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:55,207][root][INFO] - Training Epoch: 5/10, step 198/574 completed (loss: 1.3242629766464233, acc: 0.6764705777168274)
[2024-11-29 03:31:55,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:55,803][root][INFO] - Training Epoch: 5/10, step 199/574 completed (loss: 2.019043207168579, acc: 0.5367646813392639)
[2024-11-29 03:31:55,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:56,399][root][INFO] - Training Epoch: 5/10, step 200/574 completed (loss: 1.9788933992385864, acc: 0.4406779706478119)
[2024-11-29 03:31:56,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:56,997][root][INFO] - Training Epoch: 5/10, step 201/574 completed (loss: 2.1325645446777344, acc: 0.4701492488384247)
[2024-11-29 03:31:57,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:57,592][root][INFO] - Training Epoch: 5/10, step 202/574 completed (loss: 2.0562660694122314, acc: 0.43689319491386414)
[2024-11-29 03:31:57,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:58,186][root][INFO] - Training Epoch: 5/10, step 203/574 completed (loss: 1.5955915451049805, acc: 0.5714285969734192)
[2024-11-29 03:31:58,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:58,783][root][INFO] - Training Epoch: 5/10, step 204/574 completed (loss: 1.6092233657836914, acc: 0.6153846383094788)
[2024-11-29 03:31:58,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:59,404][root][INFO] - Training Epoch: 5/10, step 205/574 completed (loss: 2.2416348457336426, acc: 0.36771300435066223)
[2024-11-29 03:31:59,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:00,030][root][INFO] - Training Epoch: 5/10, step 206/574 completed (loss: 2.2321937084198, acc: 0.3937007784843445)
[2024-11-29 03:32:00,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:00,644][root][INFO] - Training Epoch: 5/10, step 207/574 completed (loss: 2.1340525150299072, acc: 0.4612068831920624)
[2024-11-29 03:32:00,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:01,259][root][INFO] - Training Epoch: 5/10, step 208/574 completed (loss: 2.0845718383789062, acc: 0.4528985619544983)
[2024-11-29 03:32:01,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:01,878][root][INFO] - Training Epoch: 5/10, step 209/574 completed (loss: 2.2716927528381348, acc: 0.4124513566493988)
[2024-11-29 03:32:01,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:02,492][root][INFO] - Training Epoch: 5/10, step 210/574 completed (loss: 2.2127716541290283, acc: 0.3913043439388275)
[2024-11-29 03:32:02,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:03,077][root][INFO] - Training Epoch: 5/10, step 211/574 completed (loss: 0.05918525159358978, acc: 1.0)
[2024-11-29 03:32:03,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:03,663][root][INFO] - Training Epoch: 5/10, step 212/574 completed (loss: 0.1812065988779068, acc: 0.9285714030265808)
[2024-11-29 03:32:03,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:04,253][root][INFO] - Training Epoch: 5/10, step 213/574 completed (loss: 0.9092965722084045, acc: 0.7021276354789734)
[2024-11-29 03:32:04,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:04,861][root][INFO] - Training Epoch: 5/10, step 214/574 completed (loss: 1.7546261548995972, acc: 0.4923076927661896)
[2024-11-29 03:32:04,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:05,452][root][INFO] - Training Epoch: 5/10, step 215/574 completed (loss: 0.9597272872924805, acc: 0.7297297120094299)
[2024-11-29 03:32:05,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:06,046][root][INFO] - Training Epoch: 5/10, step 216/574 completed (loss: 1.2346827983856201, acc: 0.604651153087616)
[2024-11-29 03:32:06,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:06,643][root][INFO] - Training Epoch: 5/10, step 217/574 completed (loss: 1.4517265558242798, acc: 0.5945945978164673)
[2024-11-29 03:32:06,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:07,238][root][INFO] - Training Epoch: 5/10, step 218/574 completed (loss: 1.1992987394332886, acc: 0.6666666865348816)
[2024-11-29 03:32:07,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:07,825][root][INFO] - Training Epoch: 5/10, step 219/574 completed (loss: 0.3074517250061035, acc: 0.9090909361839294)
[2024-11-29 03:32:07,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:08,413][root][INFO] - Training Epoch: 5/10, step 220/574 completed (loss: 0.19913358986377716, acc: 0.9629629850387573)
[2024-11-29 03:32:08,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:08,998][root][INFO] - Training Epoch: 5/10, step 221/574 completed (loss: 0.3918129801750183, acc: 0.9599999785423279)
[2024-11-29 03:32:09,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:09,592][root][INFO] - Training Epoch: 5/10, step 222/574 completed (loss: 1.4225177764892578, acc: 0.5961538553237915)
[2024-11-29 03:32:09,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:10,207][root][INFO] - Training Epoch: 5/10, step 223/574 completed (loss: 1.7555025815963745, acc: 0.5489130616188049)
[2024-11-29 03:32:10,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:10,824][root][INFO] - Training Epoch: 5/10, step 224/574 completed (loss: 1.820287823677063, acc: 0.4829545319080353)
[2024-11-29 03:32:10,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:11,437][root][INFO] - Training Epoch: 5/10, step 225/574 completed (loss: 1.9911714792251587, acc: 0.478723406791687)
[2024-11-29 03:32:11,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:12,026][root][INFO] - Training Epoch: 5/10, step 226/574 completed (loss: 0.8926238417625427, acc: 0.7547169923782349)
[2024-11-29 03:32:12,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:12,618][root][INFO] - Training Epoch: 5/10, step 227/574 completed (loss: 1.1174818277359009, acc: 0.6499999761581421)
[2024-11-29 03:32:12,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:13,213][root][INFO] - Training Epoch: 5/10, step 228/574 completed (loss: 0.9588194489479065, acc: 0.7674418687820435)
[2024-11-29 03:32:13,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:13,800][root][INFO] - Training Epoch: 5/10, step 229/574 completed (loss: 0.6714192032814026, acc: 0.8333333134651184)
[2024-11-29 03:32:13,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:14,396][root][INFO] - Training Epoch: 5/10, step 230/574 completed (loss: 2.2737350463867188, acc: 0.4000000059604645)
[2024-11-29 03:32:14,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:14,987][root][INFO] - Training Epoch: 5/10, step 231/574 completed (loss: 1.4383231401443481, acc: 0.6555555462837219)
[2024-11-29 03:32:15,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:15,600][root][INFO] - Training Epoch: 5/10, step 232/574 completed (loss: 1.8114291429519653, acc: 0.5222222208976746)
[2024-11-29 03:32:15,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:16,214][root][INFO] - Training Epoch: 5/10, step 233/574 completed (loss: 1.9488604068756104, acc: 0.5550458431243896)
[2024-11-29 03:32:16,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:16,826][root][INFO] - Training Epoch: 5/10, step 234/574 completed (loss: 1.8576791286468506, acc: 0.5076923370361328)
[2024-11-29 03:32:16,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:17,416][root][INFO] - Training Epoch: 5/10, step 235/574 completed (loss: 0.4267377257347107, acc: 0.8947368264198303)
[2024-11-29 03:32:17,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:18,006][root][INFO] - Training Epoch: 5/10, step 236/574 completed (loss: 0.404937744140625, acc: 0.7916666865348816)
[2024-11-29 03:32:18,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:18,592][root][INFO] - Training Epoch: 5/10, step 237/574 completed (loss: 0.5114352107048035, acc: 0.9090909361839294)
[2024-11-29 03:32:18,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:19,178][root][INFO] - Training Epoch: 5/10, step 238/574 completed (loss: 0.6656073331832886, acc: 0.8888888955116272)
[2024-11-29 03:32:19,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:19,767][root][INFO] - Training Epoch: 5/10, step 239/574 completed (loss: 1.080108642578125, acc: 0.6571428775787354)
[2024-11-29 03:32:19,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:20,356][root][INFO] - Training Epoch: 5/10, step 240/574 completed (loss: 0.7618249654769897, acc: 0.7954545617103577)
[2024-11-29 03:32:20,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:20,944][root][INFO] - Training Epoch: 5/10, step 241/574 completed (loss: 0.7588905096054077, acc: 0.8636363744735718)
[2024-11-29 03:32:21,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:21,536][root][INFO] - Training Epoch: 5/10, step 242/574 completed (loss: 1.6137341260910034, acc: 0.5483871102333069)
[2024-11-29 03:32:21,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:22,129][root][INFO] - Training Epoch: 5/10, step 243/574 completed (loss: 0.8195374011993408, acc: 0.7727272510528564)
[2024-11-29 03:32:22,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:22,716][root][INFO] - Training Epoch: 5/10, step 244/574 completed (loss: 0.032678645104169846, acc: 1.0)
[2024-11-29 03:32:22,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:23,305][root][INFO] - Training Epoch: 5/10, step 245/574 completed (loss: 0.14935670793056488, acc: 0.9230769276618958)
[2024-11-29 03:32:23,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:23,893][root][INFO] - Training Epoch: 5/10, step 246/574 completed (loss: 0.2636594772338867, acc: 0.9354838728904724)
[2024-11-29 03:32:23,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:24,478][root][INFO] - Training Epoch: 5/10, step 247/574 completed (loss: 0.12746423482894897, acc: 0.949999988079071)
[2024-11-29 03:32:24,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:25,068][root][INFO] - Training Epoch: 5/10, step 248/574 completed (loss: 0.894496738910675, acc: 0.6756756901741028)
[2024-11-29 03:32:25,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:25,657][root][INFO] - Training Epoch: 5/10, step 249/574 completed (loss: 0.4731382429599762, acc: 0.8108108043670654)
[2024-11-29 03:32:25,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:26,246][root][INFO] - Training Epoch: 5/10, step 250/574 completed (loss: 0.8979966640472412, acc: 0.7837837934494019)
[2024-11-29 03:32:26,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:26,845][root][INFO] - Training Epoch: 5/10, step 251/574 completed (loss: 1.2918939590454102, acc: 0.6470588445663452)
[2024-11-29 03:32:26,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:27,436][root][INFO] - Training Epoch: 5/10, step 252/574 completed (loss: 0.2563904821872711, acc: 0.9024389982223511)
[2024-11-29 03:32:27,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:28,024][root][INFO] - Training Epoch: 5/10, step 253/574 completed (loss: 0.1450517326593399, acc: 0.9599999785423279)
[2024-11-29 03:32:28,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:28,609][root][INFO] - Training Epoch: 5/10, step 254/574 completed (loss: 0.015802999958395958, acc: 1.0)
[2024-11-29 03:32:28,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:29,196][root][INFO] - Training Epoch: 5/10, step 255/574 completed (loss: 0.18518681824207306, acc: 0.9032257795333862)
[2024-11-29 03:32:29,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:29,788][root][INFO] - Training Epoch: 5/10, step 256/574 completed (loss: 1.0506263971328735, acc: 0.7543859481811523)
[2024-11-29 03:32:29,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:30,382][root][INFO] - Training Epoch: 5/10, step 257/574 completed (loss: 1.2369080781936646, acc: 0.6714285612106323)
[2024-11-29 03:32:30,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:30,975][root][INFO] - Training Epoch: 5/10, step 258/574 completed (loss: 1.0902053117752075, acc: 0.7368420958518982)
[2024-11-29 03:32:31,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:31,586][root][INFO] - Training Epoch: 5/10, step 259/574 completed (loss: 1.4247719049453735, acc: 0.6132075190544128)
[2024-11-29 03:32:31,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:32,200][root][INFO] - Training Epoch: 5/10, step 260/574 completed (loss: 2.003526210784912, acc: 0.5083333253860474)
[2024-11-29 03:32:32,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:32,789][root][INFO] - Training Epoch: 5/10, step 261/574 completed (loss: 0.3900861144065857, acc: 0.8888888955116272)
[2024-11-29 03:32:32,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:33,376][root][INFO] - Training Epoch: 5/10, step 262/574 completed (loss: 0.6618365049362183, acc: 0.8064516186714172)
[2024-11-29 03:32:33,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:33,969][root][INFO] - Training Epoch: 5/10, step 263/574 completed (loss: 2.0187950134277344, acc: 0.46666666865348816)
[2024-11-29 03:32:34,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:34,557][root][INFO] - Training Epoch: 5/10, step 264/574 completed (loss: 1.4432439804077148, acc: 0.6041666865348816)
[2024-11-29 03:32:34,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:35,172][root][INFO] - Training Epoch: 5/10, step 265/574 completed (loss: 2.240838050842285, acc: 0.47999998927116394)
[2024-11-29 03:32:35,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:35,766][root][INFO] - Training Epoch: 5/10, step 266/574 completed (loss: 1.9486713409423828, acc: 0.47191011905670166)
[2024-11-29 03:32:35,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:36,359][root][INFO] - Training Epoch: 5/10, step 267/574 completed (loss: 1.6542882919311523, acc: 0.5540540814399719)
[2024-11-29 03:32:36,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:36,954][root][INFO] - Training Epoch: 5/10, step 268/574 completed (loss: 1.2486720085144043, acc: 0.6034482717514038)
[2024-11-29 03:32:37,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:37,542][root][INFO] - Training Epoch: 5/10, step 269/574 completed (loss: 0.2615620493888855, acc: 0.9545454382896423)
[2024-11-29 03:32:37,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:38,130][root][INFO] - Training Epoch: 5/10, step 270/574 completed (loss: 0.11905591934919357, acc: 0.9545454382896423)
[2024-11-29 03:32:38,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:38,718][root][INFO] - Training Epoch: 5/10, step 271/574 completed (loss: 0.36094605922698975, acc: 0.84375)
[2024-11-29 03:32:38,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:39,306][root][INFO] - Training Epoch: 5/10, step 272/574 completed (loss: 0.3537624180316925, acc: 0.9333333373069763)
[2024-11-29 03:32:39,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:39,900][root][INFO] - Training Epoch: 5/10, step 273/574 completed (loss: 1.4576852321624756, acc: 0.6333333253860474)
[2024-11-29 03:32:39,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:40,489][root][INFO] - Training Epoch: 5/10, step 274/574 completed (loss: 0.46858102083206177, acc: 0.8125)
[2024-11-29 03:32:40,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:41,075][root][INFO] - Training Epoch: 5/10, step 275/574 completed (loss: 0.27425432205200195, acc: 0.9333333373069763)
[2024-11-29 03:32:41,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:41,662][root][INFO] - Training Epoch: 5/10, step 276/574 completed (loss: 0.43578165769577026, acc: 0.931034505367279)
[2024-11-29 03:32:41,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:42,247][root][INFO] - Training Epoch: 5/10, step 277/574 completed (loss: 0.270113080739975, acc: 0.9200000166893005)
[2024-11-29 03:32:42,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:43,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:44,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:44,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:45,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:45,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:46,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:46,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:47,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:47,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:48,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:48,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:49,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:49,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:50,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:50,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:51,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:51,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:52,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:52,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:53,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:53,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:54,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:54,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:55,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:56,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:56,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:57,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:57,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:58,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:58,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:59,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:59,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:00,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:00,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:01,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:01,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:02,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:02,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:03,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:03,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:04,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:04,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:05,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:06,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:06,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:07,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:07,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:08,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:08,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:09,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:09,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:10,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:10,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:11,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:11,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:12,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:12,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:13,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:13,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:14,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:14,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:15,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:15,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:16,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:16,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:17,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:17,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:18,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:19,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:19,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:20,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:20,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:21,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:21,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:22,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:22,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:23,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:23,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:24,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:24,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:25,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:25,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:26,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:26,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:27,594][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(4.7721, device='cuda:0') eval_epoch_loss=tensor(1.5628, device='cuda:0') eval_epoch_acc=tensor(0.5773, device='cuda:0')
[2024-11-29 03:33:27,595][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:33:27,595][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:33:27,809][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_5_step_278_loss_1.5627915859222412/model.pt
[2024-11-29 03:33:27,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:28,424][root][INFO] - Training Epoch: 5/10, step 278/574 completed (loss: 1.528594970703125, acc: 0.5106382966041565)
[2024-11-29 03:33:28,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:29,016][root][INFO] - Training Epoch: 5/10, step 279/574 completed (loss: 0.9839686751365662, acc: 0.6666666865348816)
[2024-11-29 03:33:29,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:29,604][root][INFO] - Training Epoch: 5/10, step 280/574 completed (loss: 0.6714159250259399, acc: 0.7727272510528564)
[2024-11-29 03:33:29,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:30,201][root][INFO] - Training Epoch: 5/10, step 281/574 completed (loss: 1.9214149713516235, acc: 0.46987950801849365)
[2024-11-29 03:33:30,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:30,796][root][INFO] - Training Epoch: 5/10, step 282/574 completed (loss: 1.9625449180603027, acc: 0.5)
[2024-11-29 03:33:30,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:31,384][root][INFO] - Training Epoch: 5/10, step 283/574 completed (loss: 0.6335046887397766, acc: 0.8421052694320679)
[2024-11-29 03:33:31,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:31,972][root][INFO] - Training Epoch: 5/10, step 284/574 completed (loss: 0.7434915900230408, acc: 0.7941176295280457)
[2024-11-29 03:33:32,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:32,563][root][INFO] - Training Epoch: 5/10, step 285/574 completed (loss: 0.6451674699783325, acc: 0.824999988079071)
[2024-11-29 03:33:32,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:33,159][root][INFO] - Training Epoch: 5/10, step 286/574 completed (loss: 1.7808717489242554, acc: 0.4921875)
[2024-11-29 03:33:33,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:33,769][root][INFO] - Training Epoch: 5/10, step 287/574 completed (loss: 2.1376638412475586, acc: 0.4320000112056732)
[2024-11-29 03:33:33,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:34,365][root][INFO] - Training Epoch: 5/10, step 288/574 completed (loss: 1.3359116315841675, acc: 0.6593406796455383)
[2024-11-29 03:33:34,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:34,962][root][INFO] - Training Epoch: 5/10, step 289/574 completed (loss: 2.2100305557250977, acc: 0.4285714328289032)
[2024-11-29 03:33:35,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:35,576][root][INFO] - Training Epoch: 5/10, step 290/574 completed (loss: 2.286012887954712, acc: 0.40721648931503296)
[2024-11-29 03:33:35,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:36,162][root][INFO] - Training Epoch: 5/10, step 291/574 completed (loss: 0.5644546151161194, acc: 0.9090909361839294)
[2024-11-29 03:33:36,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:36,753][root][INFO] - Training Epoch: 5/10, step 292/574 completed (loss: 1.0398128032684326, acc: 0.6904761791229248)
[2024-11-29 03:33:36,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:37,347][root][INFO] - Training Epoch: 5/10, step 293/574 completed (loss: 1.0348107814788818, acc: 0.7068965435028076)
[2024-11-29 03:33:37,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:37,940][root][INFO] - Training Epoch: 5/10, step 294/574 completed (loss: 1.0844640731811523, acc: 0.6545454263687134)
[2024-11-29 03:33:38,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:38,563][root][INFO] - Training Epoch: 5/10, step 295/574 completed (loss: 1.9032806158065796, acc: 0.45876288414001465)
[2024-11-29 03:33:38,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:39,158][root][INFO] - Training Epoch: 5/10, step 296/574 completed (loss: 1.5795714855194092, acc: 0.5517241358757019)
[2024-11-29 03:33:39,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:39,746][root][INFO] - Training Epoch: 5/10, step 297/574 completed (loss: 0.5572417378425598, acc: 0.8518518805503845)
[2024-11-29 03:33:39,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:40,338][root][INFO] - Training Epoch: 5/10, step 298/574 completed (loss: 1.0495799779891968, acc: 0.6842105388641357)
[2024-11-29 03:33:40,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:40,930][root][INFO] - Training Epoch: 5/10, step 299/574 completed (loss: 1.5162827968597412, acc: 0.5714285969734192)
[2024-11-29 03:33:41,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:41,519][root][INFO] - Training Epoch: 5/10, step 300/574 completed (loss: 0.5980061888694763, acc: 0.84375)
[2024-11-29 03:33:41,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:42,113][root][INFO] - Training Epoch: 5/10, step 301/574 completed (loss: 1.4046353101730347, acc: 0.5849056839942932)
[2024-11-29 03:33:42,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:42,705][root][INFO] - Training Epoch: 5/10, step 302/574 completed (loss: 0.7088824510574341, acc: 0.7358490824699402)
[2024-11-29 03:33:42,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:43,293][root][INFO] - Training Epoch: 5/10, step 303/574 completed (loss: 0.3855682909488678, acc: 0.8235294222831726)
[2024-11-29 03:33:43,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:43,881][root][INFO] - Training Epoch: 5/10, step 304/574 completed (loss: 0.8534789681434631, acc: 0.78125)
[2024-11-29 03:33:43,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:44,475][root][INFO] - Training Epoch: 5/10, step 305/574 completed (loss: 0.9691749811172485, acc: 0.7213114500045776)
[2024-11-29 03:33:44,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:45,061][root][INFO] - Training Epoch: 5/10, step 306/574 completed (loss: 0.18367761373519897, acc: 0.9333333373069763)
[2024-11-29 03:33:45,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:45,649][root][INFO] - Training Epoch: 5/10, step 307/574 completed (loss: 0.021676888689398766, acc: 1.0)
[2024-11-29 03:33:45,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:46,244][root][INFO] - Training Epoch: 5/10, step 308/574 completed (loss: 1.613012433052063, acc: 0.5507246255874634)
[2024-11-29 03:33:46,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:46,841][root][INFO] - Training Epoch: 5/10, step 309/574 completed (loss: 1.5847268104553223, acc: 0.5416666865348816)
[2024-11-29 03:33:46,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:47,436][root][INFO] - Training Epoch: 5/10, step 310/574 completed (loss: 1.1976470947265625, acc: 0.6265060305595398)
[2024-11-29 03:33:47,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:48,032][root][INFO] - Training Epoch: 5/10, step 311/574 completed (loss: 1.5896661281585693, acc: 0.5)
[2024-11-29 03:33:48,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:48,641][root][INFO] - Training Epoch: 5/10, step 312/574 completed (loss: 1.8525681495666504, acc: 0.5306122303009033)
[2024-11-29 03:33:48,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:49,228][root][INFO] - Training Epoch: 5/10, step 313/574 completed (loss: 0.018228106200695038, acc: 1.0)
[2024-11-29 03:33:49,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:49,816][root][INFO] - Training Epoch: 5/10, step 314/574 completed (loss: 0.09773498773574829, acc: 0.9583333134651184)
[2024-11-29 03:33:49,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:50,405][root][INFO] - Training Epoch: 5/10, step 315/574 completed (loss: 0.2083585560321808, acc: 0.9032257795333862)
[2024-11-29 03:33:50,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:50,994][root][INFO] - Training Epoch: 5/10, step 316/574 completed (loss: 0.22047701478004456, acc: 0.9354838728904724)
[2024-11-29 03:33:51,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:51,590][root][INFO] - Training Epoch: 5/10, step 317/574 completed (loss: 1.3782461881637573, acc: 0.5970149040222168)
[2024-11-29 03:33:51,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:52,186][root][INFO] - Training Epoch: 5/10, step 318/574 completed (loss: 1.2803152799606323, acc: 0.6057692170143127)
[2024-11-29 03:33:52,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:52,774][root][INFO] - Training Epoch: 5/10, step 319/574 completed (loss: 0.7747637629508972, acc: 0.7777777910232544)
[2024-11-29 03:33:52,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:53,366][root][INFO] - Training Epoch: 5/10, step 320/574 completed (loss: 1.0233718156814575, acc: 0.6774193644523621)
[2024-11-29 03:33:53,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:53,957][root][INFO] - Training Epoch: 5/10, step 321/574 completed (loss: 0.19362469017505646, acc: 0.9399999976158142)
[2024-11-29 03:33:54,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:54,547][root][INFO] - Training Epoch: 5/10, step 322/574 completed (loss: 0.8176518678665161, acc: 0.7777777910232544)
[2024-11-29 03:33:54,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:55,137][root][INFO] - Training Epoch: 5/10, step 323/574 completed (loss: 1.3699308633804321, acc: 0.5714285969734192)
[2024-11-29 03:33:55,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:55,724][root][INFO] - Training Epoch: 5/10, step 324/574 completed (loss: 1.12173330783844, acc: 0.692307710647583)
[2024-11-29 03:33:55,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:56,316][root][INFO] - Training Epoch: 5/10, step 325/574 completed (loss: 1.7844297885894775, acc: 0.4878048896789551)
[2024-11-29 03:33:56,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:56,907][root][INFO] - Training Epoch: 5/10, step 326/574 completed (loss: 1.3673089742660522, acc: 0.6052631735801697)
[2024-11-29 03:33:56,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:57,494][root][INFO] - Training Epoch: 5/10, step 327/574 completed (loss: 0.1318041980266571, acc: 0.9473684430122375)
[2024-11-29 03:33:57,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:58,082][root][INFO] - Training Epoch: 5/10, step 328/574 completed (loss: 0.015346667729318142, acc: 1.0)
[2024-11-29 03:33:58,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:58,670][root][INFO] - Training Epoch: 5/10, step 329/574 completed (loss: 0.46137213706970215, acc: 0.8148148059844971)
[2024-11-29 03:33:58,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:59,257][root][INFO] - Training Epoch: 5/10, step 330/574 completed (loss: 0.32248032093048096, acc: 0.875)
[2024-11-29 03:33:59,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:59,849][root][INFO] - Training Epoch: 5/10, step 331/574 completed (loss: 1.239113450050354, acc: 0.6290322542190552)
[2024-11-29 03:33:59,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:00,441][root][INFO] - Training Epoch: 5/10, step 332/574 completed (loss: 1.0241007804870605, acc: 0.7017543911933899)
[2024-11-29 03:34:00,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:01,029][root][INFO] - Training Epoch: 5/10, step 333/574 completed (loss: 0.8728391528129578, acc: 0.75)
[2024-11-29 03:34:01,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:01,618][root][INFO] - Training Epoch: 5/10, step 334/574 completed (loss: 0.5810648798942566, acc: 0.8666666746139526)
[2024-11-29 03:34:01,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:02,206][root][INFO] - Training Epoch: 5/10, step 335/574 completed (loss: 0.42514947056770325, acc: 0.8421052694320679)
[2024-11-29 03:34:02,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:02,800][root][INFO] - Training Epoch: 5/10, step 336/574 completed (loss: 1.4646183252334595, acc: 0.5799999833106995)
[2024-11-29 03:34:02,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:03,396][root][INFO] - Training Epoch: 5/10, step 337/574 completed (loss: 1.958451747894287, acc: 0.4367816150188446)
[2024-11-29 03:34:03,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:03,990][root][INFO] - Training Epoch: 5/10, step 338/574 completed (loss: 2.119216203689575, acc: 0.41489362716674805)
[2024-11-29 03:34:04,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:04,584][root][INFO] - Training Epoch: 5/10, step 339/574 completed (loss: 2.2258710861206055, acc: 0.4457831382751465)
[2024-11-29 03:34:04,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:05,173][root][INFO] - Training Epoch: 5/10, step 340/574 completed (loss: 0.08159200102090836, acc: 1.0)
[2024-11-29 03:34:05,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:05,762][root][INFO] - Training Epoch: 5/10, step 341/574 completed (loss: 0.6825470924377441, acc: 0.7948718070983887)
[2024-11-29 03:34:05,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:06,354][root][INFO] - Training Epoch: 5/10, step 342/574 completed (loss: 1.982358455657959, acc: 0.46987950801849365)
[2024-11-29 03:34:06,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:06,947][root][INFO] - Training Epoch: 5/10, step 343/574 completed (loss: 1.269688606262207, acc: 0.6415094137191772)
[2024-11-29 03:34:07,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:07,539][root][INFO] - Training Epoch: 5/10, step 344/574 completed (loss: 1.369062066078186, acc: 0.6202531456947327)
[2024-11-29 03:34:07,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:08,128][root][INFO] - Training Epoch: 5/10, step 345/574 completed (loss: 1.0588055849075317, acc: 0.7058823704719543)
[2024-11-29 03:34:08,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:08,722][root][INFO] - Training Epoch: 5/10, step 346/574 completed (loss: 1.785820484161377, acc: 0.5074626803398132)
[2024-11-29 03:34:08,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:09,309][root][INFO] - Training Epoch: 5/10, step 347/574 completed (loss: 0.18277932703495026, acc: 0.949999988079071)
[2024-11-29 03:34:09,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:09,896][root][INFO] - Training Epoch: 5/10, step 348/574 completed (loss: 0.45808470249176025, acc: 0.800000011920929)
[2024-11-29 03:34:09,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:10,485][root][INFO] - Training Epoch: 5/10, step 349/574 completed (loss: 0.9286754131317139, acc: 0.6944444179534912)
[2024-11-29 03:34:10,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:11,075][root][INFO] - Training Epoch: 5/10, step 350/574 completed (loss: 1.2889142036437988, acc: 0.5348837375640869)
[2024-11-29 03:34:11,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:11,665][root][INFO] - Training Epoch: 5/10, step 351/574 completed (loss: 1.0032542943954468, acc: 0.7179487347602844)
[2024-11-29 03:34:11,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:12,257][root][INFO] - Training Epoch: 5/10, step 352/574 completed (loss: 1.66597318649292, acc: 0.6222222447395325)
[2024-11-29 03:34:12,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:12,844][root][INFO] - Training Epoch: 5/10, step 353/574 completed (loss: 0.0635819211602211, acc: 0.95652174949646)
[2024-11-29 03:34:12,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:13,431][root][INFO] - Training Epoch: 5/10, step 354/574 completed (loss: 0.9431586861610413, acc: 0.6153846383094788)
[2024-11-29 03:34:13,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:14,025][root][INFO] - Training Epoch: 5/10, step 355/574 completed (loss: 2.1209053993225098, acc: 0.38461539149284363)
[2024-11-29 03:34:14,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:14,636][root][INFO] - Training Epoch: 5/10, step 356/574 completed (loss: 1.9061274528503418, acc: 0.4956521689891815)
[2024-11-29 03:34:14,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:15,228][root][INFO] - Training Epoch: 5/10, step 357/574 completed (loss: 1.8275665044784546, acc: 0.44565218687057495)
[2024-11-29 03:34:15,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:15,817][root][INFO] - Training Epoch: 5/10, step 358/574 completed (loss: 1.1937719583511353, acc: 0.6734693646430969)
[2024-11-29 03:34:15,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:16,405][root][INFO] - Training Epoch: 5/10, step 359/574 completed (loss: 0.07191073894500732, acc: 0.9583333134651184)
[2024-11-29 03:34:16,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:16,993][root][INFO] - Training Epoch: 5/10, step 360/574 completed (loss: 0.33347177505493164, acc: 0.8461538553237915)
[2024-11-29 03:34:17,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:17,582][root][INFO] - Training Epoch: 5/10, step 361/574 completed (loss: 0.7260857820510864, acc: 0.7317073345184326)
[2024-11-29 03:34:17,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:18,171][root][INFO] - Training Epoch: 5/10, step 362/574 completed (loss: 0.8982045650482178, acc: 0.7111111283302307)
[2024-11-29 03:34:18,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:18,766][root][INFO] - Training Epoch: 5/10, step 363/574 completed (loss: 1.6594536304473877, acc: 0.5131579041481018)
[2024-11-29 03:34:18,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:19,357][root][INFO] - Training Epoch: 5/10, step 364/574 completed (loss: 1.1461373567581177, acc: 0.6585366129875183)
[2024-11-29 03:34:19,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:19,947][root][INFO] - Training Epoch: 5/10, step 365/574 completed (loss: 0.7928206324577332, acc: 0.7878788113594055)
[2024-11-29 03:34:20,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:20,534][root][INFO] - Training Epoch: 5/10, step 366/574 completed (loss: 0.039514269679784775, acc: 1.0)
[2024-11-29 03:34:20,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:21,122][root][INFO] - Training Epoch: 5/10, step 367/574 completed (loss: 0.016739962622523308, acc: 1.0)
[2024-11-29 03:34:21,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:21,710][root][INFO] - Training Epoch: 5/10, step 368/574 completed (loss: 0.271145224571228, acc: 0.9642857313156128)
[2024-11-29 03:34:21,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:22,299][root][INFO] - Training Epoch: 5/10, step 369/574 completed (loss: 0.5326904058456421, acc: 0.8125)
[2024-11-29 03:34:22,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:22,914][root][INFO] - Training Epoch: 5/10, step 370/574 completed (loss: 2.2232494354248047, acc: 0.43030303716659546)
[2024-11-29 03:34:22,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:23,525][root][INFO] - Training Epoch: 5/10, step 371/574 completed (loss: 1.514022707939148, acc: 0.6132075190544128)
[2024-11-29 03:34:23,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:24,119][root][INFO] - Training Epoch: 5/10, step 372/574 completed (loss: 1.2268484830856323, acc: 0.6666666865348816)
[2024-11-29 03:34:24,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:24,710][root][INFO] - Training Epoch: 5/10, step 373/574 completed (loss: 1.1160662174224854, acc: 0.6964285969734192)
[2024-11-29 03:34:24,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:25,300][root][INFO] - Training Epoch: 5/10, step 374/574 completed (loss: 0.7293511033058167, acc: 0.7428571581840515)
[2024-11-29 03:34:25,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:25,887][root][INFO] - Training Epoch: 5/10, step 375/574 completed (loss: 0.015633976086974144, acc: 1.0)
[2024-11-29 03:34:25,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:26,474][root][INFO] - Training Epoch: 5/10, step 376/574 completed (loss: 0.1947137862443924, acc: 0.9130434989929199)
[2024-11-29 03:34:26,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:27,065][root][INFO] - Training Epoch: 5/10, step 377/574 completed (loss: 1.0900272130966187, acc: 0.5625)
[2024-11-29 03:34:27,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:27,659][root][INFO] - Training Epoch: 5/10, step 378/574 completed (loss: 1.4555392265319824, acc: 0.6421052813529968)
[2024-11-29 03:34:27,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:28,270][root][INFO] - Training Epoch: 5/10, step 379/574 completed (loss: 1.6944841146469116, acc: 0.5628742575645447)
[2024-11-29 03:34:28,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:28,873][root][INFO] - Training Epoch: 5/10, step 380/574 completed (loss: 1.4137951135635376, acc: 0.6315789222717285)
[2024-11-29 03:34:28,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:29,491][root][INFO] - Training Epoch: 5/10, step 381/574 completed (loss: 1.7305591106414795, acc: 0.5508021116256714)
[2024-11-29 03:34:29,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:30,103][root][INFO] - Training Epoch: 5/10, step 382/574 completed (loss: 1.190838098526001, acc: 0.684684693813324)
[2024-11-29 03:34:30,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:30,689][root][INFO] - Training Epoch: 5/10, step 383/574 completed (loss: 0.3366892635822296, acc: 0.9285714030265808)
[2024-11-29 03:34:30,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:31,277][root][INFO] - Training Epoch: 5/10, step 384/574 completed (loss: 0.034714438021183014, acc: 1.0)
[2024-11-29 03:34:31,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:31,866][root][INFO] - Training Epoch: 5/10, step 385/574 completed (loss: 0.5034365653991699, acc: 0.9375)
[2024-11-29 03:34:31,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:32,454][root][INFO] - Training Epoch: 5/10, step 386/574 completed (loss: 0.4436323940753937, acc: 0.8611111044883728)
[2024-11-29 03:34:32,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:33,046][root][INFO] - Training Epoch: 5/10, step 387/574 completed (loss: 0.23619666695594788, acc: 0.8947368264198303)
[2024-11-29 03:34:33,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:33,633][root][INFO] - Training Epoch: 5/10, step 388/574 completed (loss: 0.024361105635762215, acc: 1.0)
[2024-11-29 03:34:33,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:34,221][root][INFO] - Training Epoch: 5/10, step 389/574 completed (loss: 0.03457972779870033, acc: 1.0)
[2024-11-29 03:34:34,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:34,810][root][INFO] - Training Epoch: 5/10, step 390/574 completed (loss: 0.15897919237613678, acc: 0.9047619104385376)
[2024-11-29 03:34:34,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:35,400][root][INFO] - Training Epoch: 5/10, step 391/574 completed (loss: 1.2486183643341064, acc: 0.6481481194496155)
[2024-11-29 03:34:35,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:36,000][root][INFO] - Training Epoch: 5/10, step 392/574 completed (loss: 2.0474977493286133, acc: 0.5048543810844421)
[2024-11-29 03:34:36,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:36,619][root][INFO] - Training Epoch: 5/10, step 393/574 completed (loss: 1.8694615364074707, acc: 0.5220588445663452)
[2024-11-29 03:34:36,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:37,218][root][INFO] - Training Epoch: 5/10, step 394/574 completed (loss: 2.198028564453125, acc: 0.4399999976158142)
[2024-11-29 03:34:37,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:37,821][root][INFO] - Training Epoch: 5/10, step 395/574 completed (loss: 2.054053783416748, acc: 0.4930555522441864)
[2024-11-29 03:34:37,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:38,411][root][INFO] - Training Epoch: 5/10, step 396/574 completed (loss: 0.8015536069869995, acc: 0.7674418687820435)
[2024-11-29 03:34:38,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:39,000][root][INFO] - Training Epoch: 5/10, step 397/574 completed (loss: 0.09423204511404037, acc: 1.0)
[2024-11-29 03:34:39,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:39,592][root][INFO] - Training Epoch: 5/10, step 398/574 completed (loss: 0.8415420055389404, acc: 0.7906976938247681)
[2024-11-29 03:34:39,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:40,182][root][INFO] - Training Epoch: 5/10, step 399/574 completed (loss: 0.199523463845253, acc: 0.9599999785423279)
[2024-11-29 03:34:40,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:40,779][root][INFO] - Training Epoch: 5/10, step 400/574 completed (loss: 1.4565212726593018, acc: 0.6029411554336548)
[2024-11-29 03:34:40,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:41,373][root][INFO] - Training Epoch: 5/10, step 401/574 completed (loss: 1.1829816102981567, acc: 0.6000000238418579)
[2024-11-29 03:34:41,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:41,967][root][INFO] - Training Epoch: 5/10, step 402/574 completed (loss: 0.3424670994281769, acc: 0.8484848737716675)
[2024-11-29 03:34:42,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:42,556][root][INFO] - Training Epoch: 5/10, step 403/574 completed (loss: 0.39547064900398254, acc: 0.8484848737716675)
[2024-11-29 03:34:42,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:43,144][root][INFO] - Training Epoch: 5/10, step 404/574 completed (loss: 0.22189542651176453, acc: 0.9677419066429138)
[2024-11-29 03:34:43,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:43,733][root][INFO] - Training Epoch: 5/10, step 405/574 completed (loss: 0.08495529741048813, acc: 1.0)
[2024-11-29 03:34:43,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:44,325][root][INFO] - Training Epoch: 5/10, step 406/574 completed (loss: 0.1396898329257965, acc: 0.9599999785423279)
[2024-11-29 03:34:44,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:44,915][root][INFO] - Training Epoch: 5/10, step 407/574 completed (loss: 0.206256702542305, acc: 0.9444444179534912)
[2024-11-29 03:34:44,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:45,503][root][INFO] - Training Epoch: 5/10, step 408/574 completed (loss: 0.09613823145627975, acc: 0.9629629850387573)
[2024-11-29 03:34:45,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:46,092][root][INFO] - Training Epoch: 5/10, step 409/574 completed (loss: 0.2252553254365921, acc: 0.8846153616905212)
[2024-11-29 03:34:46,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:46,686][root][INFO] - Training Epoch: 5/10, step 410/574 completed (loss: 0.6710363030433655, acc: 0.8448275923728943)
[2024-11-29 03:34:46,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:47,273][root][INFO] - Training Epoch: 5/10, step 411/574 completed (loss: 0.20297323167324066, acc: 0.8928571343421936)
[2024-11-29 03:34:47,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:47,865][root][INFO] - Training Epoch: 5/10, step 412/574 completed (loss: 0.33643531799316406, acc: 0.8999999761581421)
[2024-11-29 03:34:47,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:48,454][root][INFO] - Training Epoch: 5/10, step 413/574 completed (loss: 0.3187951147556305, acc: 0.9090909361839294)
[2024-11-29 03:34:48,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:49,042][root][INFO] - Training Epoch: 5/10, step 414/574 completed (loss: 0.10976550728082657, acc: 0.9545454382896423)
[2024-11-29 03:34:49,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:49,636][root][INFO] - Training Epoch: 5/10, step 415/574 completed (loss: 1.2544622421264648, acc: 0.6470588445663452)
[2024-11-29 03:34:49,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:50,226][root][INFO] - Training Epoch: 5/10, step 416/574 completed (loss: 0.9104204177856445, acc: 0.7307692170143127)
[2024-11-29 03:34:50,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:50,813][root][INFO] - Training Epoch: 5/10, step 417/574 completed (loss: 0.40951550006866455, acc: 0.8888888955116272)
[2024-11-29 03:34:50,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:51,405][root][INFO] - Training Epoch: 5/10, step 418/574 completed (loss: 0.9165542721748352, acc: 0.75)
[2024-11-29 03:34:51,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:51,991][root][INFO] - Training Epoch: 5/10, step 419/574 completed (loss: 0.4808533191680908, acc: 0.8999999761581421)
[2024-11-29 03:34:52,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:52,578][root][INFO] - Training Epoch: 5/10, step 420/574 completed (loss: 0.026982687413692474, acc: 1.0)
[2024-11-29 03:34:53,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:53,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:54,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:54,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:55,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:55,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:56,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:56,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:57,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:57,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:58,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:59,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:59,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:00,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:00,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:01,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:01,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:02,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:02,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:03,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:03,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:04,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:04,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:05,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:05,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:06,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:06,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:07,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:07,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:08,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:08,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:09,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:10,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:10,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:11,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:11,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:12,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:12,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:13,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:13,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:14,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:14,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:15,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:15,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:16,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:16,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:17,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:17,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:18,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:19,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:19,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:20,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:20,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:21,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:21,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:22,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:22,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:23,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:23,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:24,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:24,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:25,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:25,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:26,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:27,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:27,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:28,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:28,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:29,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:29,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:30,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:30,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:31,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:31,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:32,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:32,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:33,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:33,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:34,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:34,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:35,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:35,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:36,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:37,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:37,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:38,420][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.5346, device='cuda:0') eval_epoch_loss=tensor(1.7110, device='cuda:0') eval_epoch_acc=tensor(0.5890, device='cuda:0')
[2024-11-29 03:35:38,421][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:35:38,422][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:35:38,649][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_5_step_421_loss_1.7110120058059692/model.pt
[2024-11-29 03:35:38,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:39,260][root][INFO] - Training Epoch: 5/10, step 421/574 completed (loss: 0.5381648540496826, acc: 0.9333333373069763)
[2024-11-29 03:35:39,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:39,848][root][INFO] - Training Epoch: 5/10, step 422/574 completed (loss: 0.5310736894607544, acc: 0.8125)
[2024-11-29 03:35:39,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:40,437][root][INFO] - Training Epoch: 5/10, step 423/574 completed (loss: 0.3483922779560089, acc: 0.8611111044883728)
[2024-11-29 03:35:40,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:41,023][root][INFO] - Training Epoch: 5/10, step 424/574 completed (loss: 0.14756032824516296, acc: 0.9629629850387573)
[2024-11-29 03:35:41,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:41,611][root][INFO] - Training Epoch: 5/10, step 425/574 completed (loss: 0.3984529376029968, acc: 0.8181818127632141)
[2024-11-29 03:35:41,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:42,196][root][INFO] - Training Epoch: 5/10, step 426/574 completed (loss: 0.06887187063694, acc: 1.0)
[2024-11-29 03:35:42,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:42,786][root][INFO] - Training Epoch: 5/10, step 427/574 completed (loss: 0.6086724400520325, acc: 0.8108108043670654)
[2024-11-29 03:35:42,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:43,371][root][INFO] - Training Epoch: 5/10, step 428/574 completed (loss: 0.4087194502353668, acc: 0.8888888955116272)
[2024-11-29 03:35:43,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:43,958][root][INFO] - Training Epoch: 5/10, step 429/574 completed (loss: 0.6466882824897766, acc: 0.8695651888847351)
[2024-11-29 03:35:44,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:44,547][root][INFO] - Training Epoch: 5/10, step 430/574 completed (loss: 0.08372419327497482, acc: 0.9629629850387573)
[2024-11-29 03:35:44,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:45,134][root][INFO] - Training Epoch: 5/10, step 431/574 completed (loss: 0.07063796371221542, acc: 1.0)
[2024-11-29 03:35:45,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:45,720][root][INFO] - Training Epoch: 5/10, step 432/574 completed (loss: 0.19020304083824158, acc: 0.95652174949646)
[2024-11-29 03:35:45,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:46,310][root][INFO] - Training Epoch: 5/10, step 433/574 completed (loss: 0.9495012760162354, acc: 0.6666666865348816)
[2024-11-29 03:35:46,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:46,897][root][INFO] - Training Epoch: 5/10, step 434/574 completed (loss: 0.02659142017364502, acc: 1.0)
[2024-11-29 03:35:46,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:47,485][root][INFO] - Training Epoch: 5/10, step 435/574 completed (loss: 0.2850249111652374, acc: 0.9090909361839294)
[2024-11-29 03:35:47,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:48,074][root][INFO] - Training Epoch: 5/10, step 436/574 completed (loss: 0.6996290683746338, acc: 0.7222222089767456)
[2024-11-29 03:35:48,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:49,353][root][INFO] - Training Epoch: 5/10, step 437/574 completed (loss: 0.6131075024604797, acc: 0.8636363744735718)
[2024-11-29 03:35:49,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:49,940][root][INFO] - Training Epoch: 5/10, step 438/574 completed (loss: 0.04039767384529114, acc: 1.0)
[2024-11-29 03:35:50,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:50,531][root][INFO] - Training Epoch: 5/10, step 439/574 completed (loss: 1.1362106800079346, acc: 0.6410256624221802)
[2024-11-29 03:35:50,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:51,126][root][INFO] - Training Epoch: 5/10, step 440/574 completed (loss: 1.3875356912612915, acc: 0.6363636255264282)
[2024-11-29 03:35:51,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:51,738][root][INFO] - Training Epoch: 5/10, step 441/574 completed (loss: 2.480963945388794, acc: 0.3840000033378601)
[2024-11-29 03:35:51,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:52,335][root][INFO] - Training Epoch: 5/10, step 442/574 completed (loss: 2.0139880180358887, acc: 0.4354838728904724)
[2024-11-29 03:35:52,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:52,949][root][INFO] - Training Epoch: 5/10, step 443/574 completed (loss: 2.2667248249053955, acc: 0.39303481578826904)
[2024-11-29 03:35:53,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:53,543][root][INFO] - Training Epoch: 5/10, step 444/574 completed (loss: 1.1493185758590698, acc: 0.6415094137191772)
[2024-11-29 03:35:53,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:54,136][root][INFO] - Training Epoch: 5/10, step 445/574 completed (loss: 0.9603635668754578, acc: 0.75)
[2024-11-29 03:35:54,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:54,722][root][INFO] - Training Epoch: 5/10, step 446/574 completed (loss: 0.06482893228530884, acc: 1.0)
[2024-11-29 03:35:54,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:55,308][root][INFO] - Training Epoch: 5/10, step 447/574 completed (loss: 0.27954715490341187, acc: 0.8846153616905212)
[2024-11-29 03:35:55,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:55,895][root][INFO] - Training Epoch: 5/10, step 448/574 completed (loss: 0.14412255585193634, acc: 0.9642857313156128)
[2024-11-29 03:35:55,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:56,483][root][INFO] - Training Epoch: 5/10, step 449/574 completed (loss: 1.6154428720474243, acc: 0.5820895433425903)
[2024-11-29 03:35:56,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:57,074][root][INFO] - Training Epoch: 5/10, step 450/574 completed (loss: 1.3355474472045898, acc: 0.6388888955116272)
[2024-11-29 03:35:57,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:57,665][root][INFO] - Training Epoch: 5/10, step 451/574 completed (loss: 1.5613189935684204, acc: 0.5652173757553101)
[2024-11-29 03:35:57,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:58,255][root][INFO] - Training Epoch: 5/10, step 452/574 completed (loss: 1.5029029846191406, acc: 0.5256410241127014)
[2024-11-29 03:35:58,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:58,848][root][INFO] - Training Epoch: 5/10, step 453/574 completed (loss: 1.4500072002410889, acc: 0.6052631735801697)
[2024-11-29 03:35:58,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:59,435][root][INFO] - Training Epoch: 5/10, step 454/574 completed (loss: 0.8909085988998413, acc: 0.7346938848495483)
[2024-11-29 03:35:59,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:00,024][root][INFO] - Training Epoch: 5/10, step 455/574 completed (loss: 0.38201186060905457, acc: 0.9696969985961914)
[2024-11-29 03:36:00,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:00,619][root][INFO] - Training Epoch: 5/10, step 456/574 completed (loss: 1.8063843250274658, acc: 0.5360824465751648)
[2024-11-29 03:36:00,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:01,210][root][INFO] - Training Epoch: 5/10, step 457/574 completed (loss: 1.1555474996566772, acc: 0.6714285612106323)
[2024-11-29 03:36:01,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:01,829][root][INFO] - Training Epoch: 5/10, step 458/574 completed (loss: 2.351762056350708, acc: 0.39534884691238403)
[2024-11-29 03:36:01,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:02,418][root][INFO] - Training Epoch: 5/10, step 459/574 completed (loss: 1.1748144626617432, acc: 0.6607142686843872)
[2024-11-29 03:36:02,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:03,015][root][INFO] - Training Epoch: 5/10, step 460/574 completed (loss: 1.6052035093307495, acc: 0.5308641791343689)
[2024-11-29 03:36:03,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:03,604][root][INFO] - Training Epoch: 5/10, step 461/574 completed (loss: 0.6282373070716858, acc: 0.8055555820465088)
[2024-11-29 03:36:03,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:04,192][root][INFO] - Training Epoch: 5/10, step 462/574 completed (loss: 0.5729488730430603, acc: 0.84375)
[2024-11-29 03:36:04,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:04,777][root][INFO] - Training Epoch: 5/10, step 463/574 completed (loss: 0.4285529553890228, acc: 0.9230769276618958)
[2024-11-29 03:36:04,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:05,371][root][INFO] - Training Epoch: 5/10, step 464/574 completed (loss: 1.0336412191390991, acc: 0.739130437374115)
[2024-11-29 03:36:05,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:05,963][root][INFO] - Training Epoch: 5/10, step 465/574 completed (loss: 1.390568733215332, acc: 0.5833333134651184)
[2024-11-29 03:36:06,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:06,555][root][INFO] - Training Epoch: 5/10, step 466/574 completed (loss: 1.4498281478881836, acc: 0.6385542154312134)
[2024-11-29 03:36:06,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:07,166][root][INFO] - Training Epoch: 5/10, step 467/574 completed (loss: 1.7738279104232788, acc: 0.5585585832595825)
[2024-11-29 03:36:07,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:07,761][root][INFO] - Training Epoch: 5/10, step 468/574 completed (loss: 1.6206754446029663, acc: 0.5242718458175659)
[2024-11-29 03:36:07,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:08,373][root][INFO] - Training Epoch: 5/10, step 469/574 completed (loss: 1.7349793910980225, acc: 0.4796747863292694)
[2024-11-29 03:36:08,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:08,960][root][INFO] - Training Epoch: 5/10, step 470/574 completed (loss: 0.0802411213517189, acc: 1.0)
[2024-11-29 03:36:09,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:09,546][root][INFO] - Training Epoch: 5/10, step 471/574 completed (loss: 0.4799153506755829, acc: 0.8214285969734192)
[2024-11-29 03:36:09,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:10,158][root][INFO] - Training Epoch: 5/10, step 472/574 completed (loss: 1.818341612815857, acc: 0.45098039507865906)
[2024-11-29 03:36:10,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:10,773][root][INFO] - Training Epoch: 5/10, step 473/574 completed (loss: 2.183394432067871, acc: 0.4410480260848999)
[2024-11-29 03:36:10,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:11,364][root][INFO] - Training Epoch: 5/10, step 474/574 completed (loss: 1.693793773651123, acc: 0.5625)
[2024-11-29 03:36:11,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:11,962][root][INFO] - Training Epoch: 5/10, step 475/574 completed (loss: 1.9608170986175537, acc: 0.4907975494861603)
[2024-11-29 03:36:12,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:12,560][root][INFO] - Training Epoch: 5/10, step 476/574 completed (loss: 1.8954764604568481, acc: 0.49640288949012756)
[2024-11-29 03:36:12,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:13,171][root][INFO] - Training Epoch: 5/10, step 477/574 completed (loss: 2.207024097442627, acc: 0.42211055755615234)
[2024-11-29 03:36:13,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:13,757][root][INFO] - Training Epoch: 5/10, step 478/574 completed (loss: 0.9003171920776367, acc: 0.6944444179534912)
[2024-11-29 03:36:13,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:14,344][root][INFO] - Training Epoch: 5/10, step 479/574 completed (loss: 0.3952086567878723, acc: 0.8787878751754761)
[2024-11-29 03:36:14,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:14,929][root][INFO] - Training Epoch: 5/10, step 480/574 completed (loss: 0.10928405821323395, acc: 0.9629629850387573)
[2024-11-29 03:36:15,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:15,514][root][INFO] - Training Epoch: 5/10, step 481/574 completed (loss: 0.08753857761621475, acc: 0.949999988079071)
[2024-11-29 03:36:15,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:16,099][root][INFO] - Training Epoch: 5/10, step 482/574 completed (loss: 0.16927668452262878, acc: 1.0)
[2024-11-29 03:36:16,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:16,694][root][INFO] - Training Epoch: 5/10, step 483/574 completed (loss: 1.3627245426177979, acc: 0.6896551847457886)
[2024-11-29 03:36:16,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:17,280][root][INFO] - Training Epoch: 5/10, step 484/574 completed (loss: 0.21812531352043152, acc: 0.9354838728904724)
[2024-11-29 03:36:17,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:17,866][root][INFO] - Training Epoch: 5/10, step 485/574 completed (loss: 0.2078786939382553, acc: 0.8947368264198303)
[2024-11-29 03:36:17,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:18,454][root][INFO] - Training Epoch: 5/10, step 486/574 completed (loss: 0.4017878770828247, acc: 0.8888888955116272)
[2024-11-29 03:36:18,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:19,043][root][INFO] - Training Epoch: 5/10, step 487/574 completed (loss: 0.2952651381492615, acc: 1.0)
[2024-11-29 03:36:19,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:19,631][root][INFO] - Training Epoch: 5/10, step 488/574 completed (loss: 0.04820401966571808, acc: 1.0)
[2024-11-29 03:36:19,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:20,224][root][INFO] - Training Epoch: 5/10, step 489/574 completed (loss: 1.3026275634765625, acc: 0.6153846383094788)
[2024-11-29 03:36:20,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:20,811][root][INFO] - Training Epoch: 5/10, step 490/574 completed (loss: 0.21403934061527252, acc: 0.9666666388511658)
[2024-11-29 03:36:20,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:21,399][root][INFO] - Training Epoch: 5/10, step 491/574 completed (loss: 0.48403260111808777, acc: 0.8620689511299133)
[2024-11-29 03:36:21,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:21,986][root][INFO] - Training Epoch: 5/10, step 492/574 completed (loss: 1.0797382593154907, acc: 0.6666666865348816)
[2024-11-29 03:36:22,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:22,571][root][INFO] - Training Epoch: 5/10, step 493/574 completed (loss: 0.5825244784355164, acc: 0.8620689511299133)
[2024-11-29 03:36:22,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:23,156][root][INFO] - Training Epoch: 5/10, step 494/574 completed (loss: 0.003679188434034586, acc: 1.0)
[2024-11-29 03:36:23,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:23,745][root][INFO] - Training Epoch: 5/10, step 495/574 completed (loss: 1.0336865186691284, acc: 0.7368420958518982)
[2024-11-29 03:36:23,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:24,343][root][INFO] - Training Epoch: 5/10, step 496/574 completed (loss: 1.6838371753692627, acc: 0.5803571343421936)
[2024-11-29 03:36:24,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:24,940][root][INFO] - Training Epoch: 5/10, step 497/574 completed (loss: 1.4728991985321045, acc: 0.584269642829895)
[2024-11-29 03:36:25,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:25,537][root][INFO] - Training Epoch: 5/10, step 498/574 completed (loss: 1.7548619508743286, acc: 0.516853928565979)
[2024-11-29 03:36:25,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:26,144][root][INFO] - Training Epoch: 5/10, step 499/574 completed (loss: 2.1606287956237793, acc: 0.42553192377090454)
[2024-11-29 03:36:26,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:26,742][root][INFO] - Training Epoch: 5/10, step 500/574 completed (loss: 1.8288556337356567, acc: 0.47826087474823)
[2024-11-29 03:36:26,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:27,328][root][INFO] - Training Epoch: 5/10, step 501/574 completed (loss: 0.06912104785442352, acc: 1.0)
[2024-11-29 03:36:27,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:27,915][root][INFO] - Training Epoch: 5/10, step 502/574 completed (loss: 0.04584592208266258, acc: 1.0)
[2024-11-29 03:36:27,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:28,503][root][INFO] - Training Epoch: 5/10, step 503/574 completed (loss: 0.022445563226938248, acc: 1.0)
[2024-11-29 03:36:28,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:29,090][root][INFO] - Training Epoch: 5/10, step 504/574 completed (loss: 0.7192918062210083, acc: 0.6666666865348816)
[2024-11-29 03:36:29,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:29,679][root][INFO] - Training Epoch: 5/10, step 505/574 completed (loss: 0.755931556224823, acc: 0.7735849022865295)
[2024-11-29 03:36:29,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:30,265][root][INFO] - Training Epoch: 5/10, step 506/574 completed (loss: 0.41556718945503235, acc: 0.8620689511299133)
[2024-11-29 03:36:30,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:30,862][root][INFO] - Training Epoch: 5/10, step 507/574 completed (loss: 1.9670008420944214, acc: 0.46846845746040344)
[2024-11-29 03:36:30,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:31,459][root][INFO] - Training Epoch: 5/10, step 508/574 completed (loss: 1.3722894191741943, acc: 0.591549277305603)
[2024-11-29 03:36:31,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:32,044][root][INFO] - Training Epoch: 5/10, step 509/574 completed (loss: 0.03039763867855072, acc: 1.0)
[2024-11-29 03:36:32,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:32,634][root][INFO] - Training Epoch: 5/10, step 510/574 completed (loss: 0.08366511762142181, acc: 0.9666666388511658)
[2024-11-29 03:36:32,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:33,222][root][INFO] - Training Epoch: 5/10, step 511/574 completed (loss: 0.11147182434797287, acc: 0.9615384340286255)
[2024-11-29 03:36:33,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:33,856][root][INFO] - Training Epoch: 5/10, step 512/574 completed (loss: 2.3847973346710205, acc: 0.48571428656578064)
[2024-11-29 03:36:33,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:34,467][root][INFO] - Training Epoch: 5/10, step 513/574 completed (loss: 1.9518053531646729, acc: 0.4523809552192688)
[2024-11-29 03:36:34,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:35,053][root][INFO] - Training Epoch: 5/10, step 514/574 completed (loss: 0.6115029454231262, acc: 0.8214285969734192)
[2024-11-29 03:36:35,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:35,643][root][INFO] - Training Epoch: 5/10, step 515/574 completed (loss: 0.9284799695014954, acc: 0.6666666865348816)
[2024-11-29 03:36:35,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:36,239][root][INFO] - Training Epoch: 5/10, step 516/574 completed (loss: 1.5667482614517212, acc: 0.5833333134651184)
[2024-11-29 03:36:36,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:36,824][root][INFO] - Training Epoch: 5/10, step 517/574 completed (loss: 0.01705503650009632, acc: 1.0)
[2024-11-29 03:36:36,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:37,411][root][INFO] - Training Epoch: 5/10, step 518/574 completed (loss: 0.4327804744243622, acc: 0.8387096524238586)
[2024-11-29 03:36:37,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:37,989][root][INFO] - Training Epoch: 5/10, step 519/574 completed (loss: 0.3441731035709381, acc: 0.8500000238418579)
[2024-11-29 03:36:38,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:38,577][root][INFO] - Training Epoch: 5/10, step 520/574 completed (loss: 0.3803688585758209, acc: 0.8888888955116272)
[2024-11-29 03:36:38,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:39,322][root][INFO] - Training Epoch: 5/10, step 521/574 completed (loss: 2.3469302654266357, acc: 0.3855932056903839)
[2024-11-29 03:36:39,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:39,942][root][INFO] - Training Epoch: 5/10, step 522/574 completed (loss: 1.7103995084762573, acc: 0.5447761416435242)
[2024-11-29 03:36:40,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:40,537][root][INFO] - Training Epoch: 5/10, step 523/574 completed (loss: 2.0059351921081543, acc: 0.48175182938575745)
[2024-11-29 03:36:40,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:41,159][root][INFO] - Training Epoch: 5/10, step 524/574 completed (loss: 1.9957836866378784, acc: 0.47999998927116394)
[2024-11-29 03:36:41,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:41,751][root][INFO] - Training Epoch: 5/10, step 525/574 completed (loss: 0.9798038005828857, acc: 0.7592592835426331)
[2024-11-29 03:36:41,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:42,342][root][INFO] - Training Epoch: 5/10, step 526/574 completed (loss: 1.0858211517333984, acc: 0.7115384340286255)
[2024-11-29 03:36:42,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:42,928][root][INFO] - Training Epoch: 5/10, step 527/574 completed (loss: 0.7083490490913391, acc: 0.761904776096344)
[2024-11-29 03:36:43,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:43,523][root][INFO] - Training Epoch: 5/10, step 528/574 completed (loss: 1.9747045040130615, acc: 0.4590163826942444)
[2024-11-29 03:36:43,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:44,113][root][INFO] - Training Epoch: 5/10, step 529/574 completed (loss: 1.155900478363037, acc: 0.5932203531265259)
[2024-11-29 03:36:44,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:44,701][root][INFO] - Training Epoch: 5/10, step 530/574 completed (loss: 0.8856266140937805, acc: 0.7674418687820435)
[2024-11-29 03:36:44,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:45,288][root][INFO] - Training Epoch: 5/10, step 531/574 completed (loss: 0.9346098303794861, acc: 0.7272727489471436)
[2024-11-29 03:36:45,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:45,878][root][INFO] - Training Epoch: 5/10, step 532/574 completed (loss: 1.4233883619308472, acc: 0.5471698045730591)
[2024-11-29 03:36:45,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:46,466][root][INFO] - Training Epoch: 5/10, step 533/574 completed (loss: 0.7515832781791687, acc: 0.7954545617103577)
[2024-11-29 03:36:46,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:47,053][root][INFO] - Training Epoch: 5/10, step 534/574 completed (loss: 0.16784243285655975, acc: 0.9599999785423279)
[2024-11-29 03:36:47,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:47,640][root][INFO] - Training Epoch: 5/10, step 535/574 completed (loss: 0.3095558285713196, acc: 0.8999999761581421)
[2024-11-29 03:36:47,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:48,229][root][INFO] - Training Epoch: 5/10, step 536/574 completed (loss: 0.25818932056427, acc: 0.9545454382896423)
[2024-11-29 03:36:48,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:48,825][root][INFO] - Training Epoch: 5/10, step 537/574 completed (loss: 1.1636282205581665, acc: 0.6769230961799622)
[2024-11-29 03:36:48,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:49,422][root][INFO] - Training Epoch: 5/10, step 538/574 completed (loss: 1.2805302143096924, acc: 0.59375)
[2024-11-29 03:36:49,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:50,012][root][INFO] - Training Epoch: 5/10, step 539/574 completed (loss: 0.7094077467918396, acc: 0.78125)
[2024-11-29 03:36:50,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:50,600][root][INFO] - Training Epoch: 5/10, step 540/574 completed (loss: 0.7269207835197449, acc: 0.8181818127632141)
[2024-11-29 03:36:50,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:51,185][root][INFO] - Training Epoch: 5/10, step 541/574 completed (loss: 0.09857179969549179, acc: 1.0)
[2024-11-29 03:36:51,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:51,777][root][INFO] - Training Epoch: 5/10, step 542/574 completed (loss: 0.3679584860801697, acc: 0.9354838728904724)
[2024-11-29 03:36:51,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:52,364][root][INFO] - Training Epoch: 5/10, step 543/574 completed (loss: 0.02466697059571743, acc: 1.0)
[2024-11-29 03:36:52,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:52,951][root][INFO] - Training Epoch: 5/10, step 544/574 completed (loss: 0.326003760099411, acc: 0.8999999761581421)
[2024-11-29 03:36:53,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:53,541][root][INFO] - Training Epoch: 5/10, step 545/574 completed (loss: 0.6672834157943726, acc: 0.7804877758026123)
[2024-11-29 03:36:53,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:54,129][root][INFO] - Training Epoch: 5/10, step 546/574 completed (loss: 0.5490619540214539, acc: 0.8285714387893677)
[2024-11-29 03:36:54,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:54,722][root][INFO] - Training Epoch: 5/10, step 547/574 completed (loss: 0.9183903932571411, acc: 0.7105262875556946)
[2024-11-29 03:36:54,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:55,310][root][INFO] - Training Epoch: 5/10, step 548/574 completed (loss: 0.4697335958480835, acc: 0.8709677457809448)
[2024-11-29 03:36:55,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:55,897][root][INFO] - Training Epoch: 5/10, step 549/574 completed (loss: 0.06923244893550873, acc: 1.0)
[2024-11-29 03:36:55,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:56,488][root][INFO] - Training Epoch: 5/10, step 550/574 completed (loss: 0.3826937675476074, acc: 0.9090909361839294)
[2024-11-29 03:36:56,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:57,076][root][INFO] - Training Epoch: 5/10, step 551/574 completed (loss: 0.4518154263496399, acc: 0.875)
[2024-11-29 03:36:57,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:57,667][root][INFO] - Training Epoch: 5/10, step 552/574 completed (loss: 0.790253221988678, acc: 0.7857142686843872)
[2024-11-29 03:36:57,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:58,275][root][INFO] - Training Epoch: 5/10, step 553/574 completed (loss: 1.9399839639663696, acc: 0.44525548815727234)
[2024-11-29 03:36:58,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:58,884][root][INFO] - Training Epoch: 5/10, step 554/574 completed (loss: 1.5687958002090454, acc: 0.5724138021469116)
[2024-11-29 03:36:58,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:59,484][root][INFO] - Training Epoch: 5/10, step 555/574 completed (loss: 2.2945568561553955, acc: 0.34285715222358704)
[2024-11-29 03:36:59,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:00,078][root][INFO] - Training Epoch: 5/10, step 556/574 completed (loss: 2.216337203979492, acc: 0.3907284736633301)
[2024-11-29 03:37:00,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:00,674][root][INFO] - Training Epoch: 5/10, step 557/574 completed (loss: 1.529414415359497, acc: 0.6153846383094788)
[2024-11-29 03:37:00,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:01,261][root][INFO] - Training Epoch: 5/10, step 558/574 completed (loss: 0.04424704611301422, acc: 1.0)
[2024-11-29 03:37:01,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:01,848][root][INFO] - Training Epoch: 5/10, step 559/574 completed (loss: 0.4587823748588562, acc: 0.8461538553237915)
[2024-11-29 03:37:01,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:02,437][root][INFO] - Training Epoch: 5/10, step 560/574 completed (loss: 0.4576503336429596, acc: 0.8461538553237915)
[2024-11-29 03:37:02,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:03,031][root][INFO] - Training Epoch: 5/10, step 561/574 completed (loss: 0.7117051482200623, acc: 0.8205128312110901)
[2024-11-29 03:37:03,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:03,639][root][INFO] - Training Epoch: 5/10, step 562/574 completed (loss: 1.3780304193496704, acc: 0.6000000238418579)
[2024-11-29 03:37:03,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:04,230][root][INFO] - Training Epoch: 5/10, step 563/574 completed (loss: 1.1183172464370728, acc: 0.6753246784210205)
[2024-11-29 03:37:04,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:05,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:05,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:06,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:07,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:07,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:08,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:08,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:09,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:09,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:10,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:10,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:11,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:11,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:12,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:12,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:13,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:13,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:14,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:14,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:15,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:16,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:16,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:17,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:17,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:18,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:18,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:19,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:19,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:20,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:20,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:21,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:21,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:22,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:22,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:23,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:23,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:24,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:24,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:25,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:26,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:26,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:27,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:27,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:28,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:28,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:29,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:29,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:30,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:30,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:31,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:31,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:32,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:32,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:33,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:33,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:34,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:34,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:35,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:36,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:36,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:37,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:37,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:38,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:38,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:39,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:39,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:40,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:40,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:41,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:41,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:42,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:42,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:43,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:44,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:44,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:45,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:45,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:46,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:46,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:47,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:47,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:48,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:48,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:49,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:50,119][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(4.3302, device='cuda:0') eval_epoch_loss=tensor(1.4656, device='cuda:0') eval_epoch_acc=tensor(0.6292, device='cuda:0')
[2024-11-29 03:37:50,120][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:37:50,121][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:37:50,357][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_5_step_564_loss_1.465623378753662/model.pt
[2024-11-29 03:37:50,359][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 5 is 1.465623378753662
[2024-11-29 03:37:50,360][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 5 is 0.6291511058807373
[2024-11-29 03:37:50,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:50,965][root][INFO] - Training Epoch: 5/10, step 564/574 completed (loss: 0.7516994476318359, acc: 0.75)
[2024-11-29 03:37:51,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:51,555][root][INFO] - Training Epoch: 5/10, step 565/574 completed (loss: 0.645382821559906, acc: 0.8103448152542114)
[2024-11-29 03:37:51,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:52,151][root][INFO] - Training Epoch: 5/10, step 566/574 completed (loss: 1.2581287622451782, acc: 0.6785714030265808)
[2024-11-29 03:37:52,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:52,739][root][INFO] - Training Epoch: 5/10, step 567/574 completed (loss: 0.2685043215751648, acc: 0.9473684430122375)
[2024-11-29 03:37:52,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:53,325][root][INFO] - Training Epoch: 5/10, step 568/574 completed (loss: 0.24199286103248596, acc: 0.9259259104728699)
[2024-11-29 03:37:53,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:53,949][root][INFO] - Training Epoch: 5/10, step 569/574 completed (loss: 1.9184092283248901, acc: 0.49732619524002075)
[2024-11-29 03:37:54,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:54,538][root][INFO] - Training Epoch: 5/10, step 570/574 completed (loss: 0.7374966740608215, acc: 0.7903226017951965)
[2024-11-29 03:37:54,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:55,134][root][INFO] - Training Epoch: 5/10, step 571/574 completed (loss: 1.6876509189605713, acc: 0.5470085740089417)
[2024-11-29 03:37:55,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:55,745][root][INFO] - Training Epoch: 5/10, step 572/574 completed (loss: 2.4295692443847656, acc: 0.33673468232154846)
[2024-11-29 03:37:55,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:56,358][root][INFO] - Training Epoch: 5/10, step 573/574 completed (loss: 2.043844699859619, acc: 0.43396225571632385)
[2024-11-29 03:37:56,668][slam_llm.utils.train_utils][INFO] - Epoch 5: train_perplexity=2.8820, train_epoch_loss=1.0585, epoch time 526.8415495734662s
[2024-11-29 03:37:56,668][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 15 GB
[2024-11-29 03:37:56,668][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-29 03:37:56,668][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 15 GB
[2024-11-29 03:37:56,668][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 5
[2024-11-29 03:37:56,669][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-29 03:37:57,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:57,687][root][INFO] - Training Epoch: 6/10, step 0/574 completed (loss: 0.6875450611114502, acc: 0.8148148059844971)
[2024-11-29 03:37:57,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:58,275][root][INFO] - Training Epoch: 6/10, step 1/574 completed (loss: 0.4218255877494812, acc: 0.8799999952316284)
[2024-11-29 03:37:58,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:58,863][root][INFO] - Training Epoch: 6/10, step 2/574 completed (loss: 0.7219663858413696, acc: 0.7567567825317383)
[2024-11-29 03:37:58,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:59,451][root][INFO] - Training Epoch: 6/10, step 3/574 completed (loss: 0.6094875931739807, acc: 0.8157894611358643)
[2024-11-29 03:37:59,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:00,040][root][INFO] - Training Epoch: 6/10, step 4/574 completed (loss: 0.7991507053375244, acc: 0.837837815284729)
[2024-11-29 03:38:00,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:00,628][root][INFO] - Training Epoch: 6/10, step 5/574 completed (loss: 0.5074726343154907, acc: 0.8928571343421936)
[2024-11-29 03:38:00,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:01,221][root][INFO] - Training Epoch: 6/10, step 6/574 completed (loss: 1.1976288557052612, acc: 0.7346938848495483)
[2024-11-29 03:38:01,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:01,809][root][INFO] - Training Epoch: 6/10, step 7/574 completed (loss: 0.3216739296913147, acc: 0.8999999761581421)
[2024-11-29 03:38:01,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:02,397][root][INFO] - Training Epoch: 6/10, step 8/574 completed (loss: 0.039545223116874695, acc: 1.0)
[2024-11-29 03:38:02,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:02,984][root][INFO] - Training Epoch: 6/10, step 9/574 completed (loss: 0.06443621218204498, acc: 1.0)
[2024-11-29 03:38:03,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:03,573][root][INFO] - Training Epoch: 6/10, step 10/574 completed (loss: 0.12972469627857208, acc: 0.9629629850387573)
[2024-11-29 03:38:03,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:04,163][root][INFO] - Training Epoch: 6/10, step 11/574 completed (loss: 0.9807548522949219, acc: 0.7948718070983887)
[2024-11-29 03:38:04,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:04,751][root][INFO] - Training Epoch: 6/10, step 12/574 completed (loss: 0.6573784947395325, acc: 0.8484848737716675)
[2024-11-29 03:38:04,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:05,339][root][INFO] - Training Epoch: 6/10, step 13/574 completed (loss: 0.8719963431358337, acc: 0.739130437374115)
[2024-11-29 03:38:05,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:05,926][root][INFO] - Training Epoch: 6/10, step 14/574 completed (loss: 0.9102107882499695, acc: 0.7843137383460999)
[2024-11-29 03:38:06,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:06,517][root][INFO] - Training Epoch: 6/10, step 15/574 completed (loss: 0.8779240846633911, acc: 0.7755101919174194)
[2024-11-29 03:38:06,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:07,104][root][INFO] - Training Epoch: 6/10, step 16/574 completed (loss: 0.018475037068128586, acc: 1.0)
[2024-11-29 03:38:07,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:07,693][root][INFO] - Training Epoch: 6/10, step 17/574 completed (loss: 0.22392673790454865, acc: 0.9166666865348816)
[2024-11-29 03:38:07,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:08,284][root][INFO] - Training Epoch: 6/10, step 18/574 completed (loss: 0.7258487343788147, acc: 0.8055555820465088)
[2024-11-29 03:38:08,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:08,871][root][INFO] - Training Epoch: 6/10, step 19/574 completed (loss: 0.0902034267783165, acc: 1.0)
[2024-11-29 03:38:08,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:09,459][root][INFO] - Training Epoch: 6/10, step 20/574 completed (loss: 0.25272443890571594, acc: 0.9230769276618958)
[2024-11-29 03:38:09,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:10,046][root][INFO] - Training Epoch: 6/10, step 21/574 completed (loss: 0.36050546169281006, acc: 0.8965517282485962)
[2024-11-29 03:38:10,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:10,633][root][INFO] - Training Epoch: 6/10, step 22/574 completed (loss: 0.1967313140630722, acc: 1.0)
[2024-11-29 03:38:10,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:11,222][root][INFO] - Training Epoch: 6/10, step 23/574 completed (loss: 0.21121294796466827, acc: 0.9047619104385376)
[2024-11-29 03:38:11,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:11,811][root][INFO] - Training Epoch: 6/10, step 24/574 completed (loss: 0.21083538234233856, acc: 0.875)
[2024-11-29 03:38:11,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:12,406][root][INFO] - Training Epoch: 6/10, step 25/574 completed (loss: 1.5510313510894775, acc: 0.4716981053352356)
[2024-11-29 03:38:12,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:13,004][root][INFO] - Training Epoch: 6/10, step 26/574 completed (loss: 1.542115569114685, acc: 0.5753424763679504)
[2024-11-29 03:38:13,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:13,679][root][INFO] - Training Epoch: 6/10, step 27/574 completed (loss: 2.637186050415039, acc: 0.3478260934352875)
[2024-11-29 03:38:13,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:14,272][root][INFO] - Training Epoch: 6/10, step 28/574 completed (loss: 0.928712785243988, acc: 0.7441860437393188)
[2024-11-29 03:38:14,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:14,869][root][INFO] - Training Epoch: 6/10, step 29/574 completed (loss: 1.4094775915145874, acc: 0.6024096608161926)
[2024-11-29 03:38:14,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:15,471][root][INFO] - Training Epoch: 6/10, step 30/574 completed (loss: 1.6200587749481201, acc: 0.5555555820465088)
[2024-11-29 03:38:15,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:16,064][root][INFO] - Training Epoch: 6/10, step 31/574 completed (loss: 0.5039628744125366, acc: 0.8214285969734192)
[2024-11-29 03:38:16,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:16,651][root][INFO] - Training Epoch: 6/10, step 32/574 completed (loss: 0.13299086689949036, acc: 0.9629629850387573)
[2024-11-29 03:38:16,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:17,239][root][INFO] - Training Epoch: 6/10, step 33/574 completed (loss: 0.05764329805970192, acc: 1.0)
[2024-11-29 03:38:17,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:17,839][root][INFO] - Training Epoch: 6/10, step 34/574 completed (loss: 1.6740001440048218, acc: 0.5546218752861023)
[2024-11-29 03:38:17,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:18,435][root][INFO] - Training Epoch: 6/10, step 35/574 completed (loss: 1.0007436275482178, acc: 0.6557376980781555)
[2024-11-29 03:38:18,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:19,030][root][INFO] - Training Epoch: 6/10, step 36/574 completed (loss: 1.2855563163757324, acc: 0.6349206566810608)
[2024-11-29 03:38:19,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:19,621][root][INFO] - Training Epoch: 6/10, step 37/574 completed (loss: 1.0877249240875244, acc: 0.7288135886192322)
[2024-11-29 03:38:19,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:20,227][root][INFO] - Training Epoch: 6/10, step 38/574 completed (loss: 1.3204060792922974, acc: 0.6321839094161987)
[2024-11-29 03:38:20,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:20,817][root][INFO] - Training Epoch: 6/10, step 39/574 completed (loss: 0.028327632695436478, acc: 1.0)
[2024-11-29 03:38:20,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:21,406][root][INFO] - Training Epoch: 6/10, step 40/574 completed (loss: 0.6332947015762329, acc: 0.8461538553237915)
[2024-11-29 03:38:21,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:22,004][root][INFO] - Training Epoch: 6/10, step 41/574 completed (loss: 1.6790199279785156, acc: 0.5810810923576355)
[2024-11-29 03:38:22,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:22,597][root][INFO] - Training Epoch: 6/10, step 42/574 completed (loss: 1.201859474182129, acc: 0.6461538672447205)
[2024-11-29 03:38:22,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:23,190][root][INFO] - Training Epoch: 6/10, step 43/574 completed (loss: 1.5495754480361938, acc: 0.6161616444587708)
[2024-11-29 03:38:23,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:23,784][root][INFO] - Training Epoch: 6/10, step 44/574 completed (loss: 1.6157557964324951, acc: 0.5257731676101685)
[2024-11-29 03:38:23,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:24,386][root][INFO] - Training Epoch: 6/10, step 45/574 completed (loss: 2.005937099456787, acc: 0.47058823704719543)
[2024-11-29 03:38:24,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:24,972][root][INFO] - Training Epoch: 6/10, step 46/574 completed (loss: 0.042306941002607346, acc: 1.0)
[2024-11-29 03:38:25,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:25,563][root][INFO] - Training Epoch: 6/10, step 47/574 completed (loss: 0.12971360981464386, acc: 0.9629629850387573)
[2024-11-29 03:38:25,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:26,154][root][INFO] - Training Epoch: 6/10, step 48/574 completed (loss: 0.2544163763523102, acc: 0.9285714030265808)
[2024-11-29 03:38:26,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:26,744][root][INFO] - Training Epoch: 6/10, step 49/574 completed (loss: 0.5440014600753784, acc: 0.8611111044883728)
[2024-11-29 03:38:26,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:27,335][root][INFO] - Training Epoch: 6/10, step 50/574 completed (loss: 0.682776153087616, acc: 0.7543859481811523)
[2024-11-29 03:38:27,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:27,930][root][INFO] - Training Epoch: 6/10, step 51/574 completed (loss: 1.1808457374572754, acc: 0.6666666865348816)
[2024-11-29 03:38:28,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:28,525][root][INFO] - Training Epoch: 6/10, step 52/574 completed (loss: 1.4981523752212524, acc: 0.591549277305603)
[2024-11-29 03:38:28,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:29,138][root][INFO] - Training Epoch: 6/10, step 53/574 completed (loss: 2.3619258403778076, acc: 0.41999998688697815)
[2024-11-29 03:38:29,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:29,725][root][INFO] - Training Epoch: 6/10, step 54/574 completed (loss: 0.3564339280128479, acc: 0.9459459185600281)
[2024-11-29 03:38:29,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:30,313][root][INFO] - Training Epoch: 6/10, step 55/574 completed (loss: 0.3050330877304077, acc: 0.9615384340286255)
[2024-11-29 03:38:30,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:31,019][root][INFO] - Training Epoch: 6/10, step 56/574 completed (loss: 2.196906089782715, acc: 0.49146756529808044)
[2024-11-29 03:38:31,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:31,675][root][INFO] - Training Epoch: 6/10, step 57/574 completed (loss: 2.622856616973877, acc: 0.3812636137008667)
[2024-11-29 03:38:31,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:32,293][root][INFO] - Training Epoch: 6/10, step 58/574 completed (loss: 1.9218186140060425, acc: 0.5)
[2024-11-29 03:38:32,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:32,890][root][INFO] - Training Epoch: 6/10, step 59/574 completed (loss: 2.071598768234253, acc: 0.47058823704719543)
[2024-11-29 03:38:32,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:33,505][root][INFO] - Training Epoch: 6/10, step 60/574 completed (loss: 2.00003981590271, acc: 0.4420289993286133)
[2024-11-29 03:38:33,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:34,114][root][INFO] - Training Epoch: 6/10, step 61/574 completed (loss: 1.5256503820419312, acc: 0.625)
[2024-11-29 03:38:34,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:34,700][root][INFO] - Training Epoch: 6/10, step 62/574 completed (loss: 0.4743991196155548, acc: 0.8529411554336548)
[2024-11-29 03:38:34,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:35,292][root][INFO] - Training Epoch: 6/10, step 63/574 completed (loss: 0.8954365253448486, acc: 0.6944444179534912)
[2024-11-29 03:38:35,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:35,887][root][INFO] - Training Epoch: 6/10, step 64/574 completed (loss: 0.94752037525177, acc: 0.703125)
[2024-11-29 03:38:35,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:36,475][root][INFO] - Training Epoch: 6/10, step 65/574 completed (loss: 0.21571512520313263, acc: 0.931034505367279)
[2024-11-29 03:38:36,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:37,064][root][INFO] - Training Epoch: 6/10, step 66/574 completed (loss: 1.0780013799667358, acc: 0.6785714030265808)
[2024-11-29 03:38:37,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:37,654][root][INFO] - Training Epoch: 6/10, step 67/574 completed (loss: 1.2402160167694092, acc: 0.6833333373069763)
[2024-11-29 03:38:37,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:38,240][root][INFO] - Training Epoch: 6/10, step 68/574 completed (loss: 0.035010501742362976, acc: 1.0)
[2024-11-29 03:38:38,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:38,829][root][INFO] - Training Epoch: 6/10, step 69/574 completed (loss: 0.42573654651641846, acc: 0.8333333134651184)
[2024-11-29 03:38:38,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:39,416][root][INFO] - Training Epoch: 6/10, step 70/574 completed (loss: 0.27234846353530884, acc: 0.8787878751754761)
[2024-11-29 03:38:39,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:40,027][root][INFO] - Training Epoch: 6/10, step 71/574 completed (loss: 2.064446449279785, acc: 0.40441176295280457)
[2024-11-29 03:38:40,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:40,625][root][INFO] - Training Epoch: 6/10, step 72/574 completed (loss: 1.5033336877822876, acc: 0.5634920597076416)
[2024-11-29 03:38:40,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:41,243][root][INFO] - Training Epoch: 6/10, step 73/574 completed (loss: 2.261017084121704, acc: 0.43589743971824646)
[2024-11-29 03:38:41,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:41,837][root][INFO] - Training Epoch: 6/10, step 74/574 completed (loss: 1.460423469543457, acc: 0.6530612111091614)
[2024-11-29 03:38:41,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:42,434][root][INFO] - Training Epoch: 6/10, step 75/574 completed (loss: 2.0528342723846436, acc: 0.447761207818985)
[2024-11-29 03:38:42,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:43,059][root][INFO] - Training Epoch: 6/10, step 76/574 completed (loss: 2.410609722137451, acc: 0.37956205010414124)
[2024-11-29 03:38:43,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:43,646][root][INFO] - Training Epoch: 6/10, step 77/574 completed (loss: 0.026784908026456833, acc: 1.0)
[2024-11-29 03:38:43,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:44,234][root][INFO] - Training Epoch: 6/10, step 78/574 completed (loss: 0.060414206236600876, acc: 1.0)
[2024-11-29 03:38:44,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:44,821][root][INFO] - Training Epoch: 6/10, step 79/574 completed (loss: 0.44622114300727844, acc: 0.8787878751754761)
[2024-11-29 03:38:44,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:45,408][root][INFO] - Training Epoch: 6/10, step 80/574 completed (loss: 0.22432270646095276, acc: 0.9615384340286255)
[2024-11-29 03:38:45,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:46,000][root][INFO] - Training Epoch: 6/10, step 81/574 completed (loss: 1.2454752922058105, acc: 0.6538461446762085)
[2024-11-29 03:38:46,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:46,593][root][INFO] - Training Epoch: 6/10, step 82/574 completed (loss: 1.131697654724121, acc: 0.6153846383094788)
[2024-11-29 03:38:46,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:47,181][root][INFO] - Training Epoch: 6/10, step 83/574 completed (loss: 0.3648686707019806, acc: 0.90625)
[2024-11-29 03:38:47,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:47,772][root][INFO] - Training Epoch: 6/10, step 84/574 completed (loss: 0.9766234159469604, acc: 0.7246376872062683)
[2024-11-29 03:38:47,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:48,365][root][INFO] - Training Epoch: 6/10, step 85/574 completed (loss: 0.9153884649276733, acc: 0.7200000286102295)
[2024-11-29 03:38:48,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:48,952][root][INFO] - Training Epoch: 6/10, step 86/574 completed (loss: 0.3568006157875061, acc: 0.9130434989929199)
[2024-11-29 03:38:49,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:49,546][root][INFO] - Training Epoch: 6/10, step 87/574 completed (loss: 1.0682978630065918, acc: 0.7400000095367432)
[2024-11-29 03:38:49,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:50,142][root][INFO] - Training Epoch: 6/10, step 88/574 completed (loss: 1.2980091571807861, acc: 0.6699029207229614)
[2024-11-29 03:38:50,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:50,752][root][INFO] - Training Epoch: 6/10, step 89/574 completed (loss: 1.7869035005569458, acc: 0.5631067752838135)
[2024-11-29 03:38:50,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:51,368][root][INFO] - Training Epoch: 6/10, step 90/574 completed (loss: 1.9822410345077515, acc: 0.4516128897666931)
[2024-11-29 03:38:51,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:51,991][root][INFO] - Training Epoch: 6/10, step 91/574 completed (loss: 1.9402894973754883, acc: 0.5387930870056152)
[2024-11-29 03:38:52,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:52,587][root][INFO] - Training Epoch: 6/10, step 92/574 completed (loss: 1.4649643898010254, acc: 0.5684210658073425)
[2024-11-29 03:38:52,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:53,202][root][INFO] - Training Epoch: 6/10, step 93/574 completed (loss: 1.9804199934005737, acc: 0.4455445408821106)
[2024-11-29 03:38:53,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:53,792][root][INFO] - Training Epoch: 6/10, step 94/574 completed (loss: 1.4996004104614258, acc: 0.5483871102333069)
[2024-11-29 03:38:53,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:54,384][root][INFO] - Training Epoch: 6/10, step 95/574 completed (loss: 1.262613296508789, acc: 0.6666666865348816)
[2024-11-29 03:38:54,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:54,981][root][INFO] - Training Epoch: 6/10, step 96/574 completed (loss: 1.919372320175171, acc: 0.42016807198524475)
[2024-11-29 03:38:55,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:55,576][root][INFO] - Training Epoch: 6/10, step 97/574 completed (loss: 1.7652647495269775, acc: 0.5384615659713745)
[2024-11-29 03:38:55,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:56,176][root][INFO] - Training Epoch: 6/10, step 98/574 completed (loss: 2.1506354808807373, acc: 0.38686132431030273)
[2024-11-29 03:38:56,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:56,767][root][INFO] - Training Epoch: 6/10, step 99/574 completed (loss: 1.506656527519226, acc: 0.49253731966018677)
[2024-11-29 03:38:56,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:57,353][root][INFO] - Training Epoch: 6/10, step 100/574 completed (loss: 0.08094247430562973, acc: 1.0)
[2024-11-29 03:38:57,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:57,945][root][INFO] - Training Epoch: 6/10, step 101/574 completed (loss: 0.01742243580520153, acc: 1.0)
[2024-11-29 03:38:58,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:58,533][root][INFO] - Training Epoch: 6/10, step 102/574 completed (loss: 0.23515911400318146, acc: 0.9130434989929199)
[2024-11-29 03:38:58,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:59,122][root][INFO] - Training Epoch: 6/10, step 103/574 completed (loss: 0.25062310695648193, acc: 0.9545454382896423)
[2024-11-29 03:38:59,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:59,715][root][INFO] - Training Epoch: 6/10, step 104/574 completed (loss: 1.0766164064407349, acc: 0.6034482717514038)
[2024-11-29 03:38:59,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:00,306][root][INFO] - Training Epoch: 6/10, step 105/574 completed (loss: 0.5714868307113647, acc: 0.7674418687820435)
[2024-11-29 03:39:00,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:00,893][root][INFO] - Training Epoch: 6/10, step 106/574 completed (loss: 0.06323347985744476, acc: 1.0)
[2024-11-29 03:39:00,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:01,481][root][INFO] - Training Epoch: 6/10, step 107/574 completed (loss: 0.020692843943834305, acc: 1.0)
[2024-11-29 03:39:01,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:02,067][root][INFO] - Training Epoch: 6/10, step 108/574 completed (loss: 0.014224429614841938, acc: 1.0)
[2024-11-29 03:39:02,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:02,655][root][INFO] - Training Epoch: 6/10, step 109/574 completed (loss: 0.6109673380851746, acc: 0.7857142686843872)
[2024-11-29 03:39:02,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:03,247][root][INFO] - Training Epoch: 6/10, step 110/574 completed (loss: 1.175218105316162, acc: 0.6461538672447205)
[2024-11-29 03:39:03,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:03,842][root][INFO] - Training Epoch: 6/10, step 111/574 completed (loss: 1.266006350517273, acc: 0.5614035129547119)
[2024-11-29 03:39:03,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:04,430][root][INFO] - Training Epoch: 6/10, step 112/574 completed (loss: 1.3324031829833984, acc: 0.6491228342056274)
[2024-11-29 03:39:04,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:05,019][root][INFO] - Training Epoch: 6/10, step 113/574 completed (loss: 0.8430144190788269, acc: 0.7692307829856873)
[2024-11-29 03:39:05,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:05,612][root][INFO] - Training Epoch: 6/10, step 114/574 completed (loss: 0.6423717141151428, acc: 0.795918345451355)
[2024-11-29 03:39:05,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:06,198][root][INFO] - Training Epoch: 6/10, step 115/574 completed (loss: 0.024875681847333908, acc: 1.0)
[2024-11-29 03:39:06,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:06,795][root][INFO] - Training Epoch: 6/10, step 116/574 completed (loss: 1.5219327211380005, acc: 0.5714285969734192)
[2024-11-29 03:39:06,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:07,388][root][INFO] - Training Epoch: 6/10, step 117/574 completed (loss: 1.2788572311401367, acc: 0.6504064798355103)
[2024-11-29 03:39:07,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:07,980][root][INFO] - Training Epoch: 6/10, step 118/574 completed (loss: 1.2341134548187256, acc: 0.6935483813285828)
[2024-11-29 03:39:08,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:08,620][root][INFO] - Training Epoch: 6/10, step 119/574 completed (loss: 2.218717575073242, acc: 0.42965778708457947)
[2024-11-29 03:39:08,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:09,212][root][INFO] - Training Epoch: 6/10, step 120/574 completed (loss: 0.8718488812446594, acc: 0.7333333492279053)
[2024-11-29 03:39:09,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:09,806][root][INFO] - Training Epoch: 6/10, step 121/574 completed (loss: 1.107412338256836, acc: 0.7692307829856873)
[2024-11-29 03:39:09,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:10,392][root][INFO] - Training Epoch: 6/10, step 122/574 completed (loss: 0.12833765149116516, acc: 0.9583333134651184)
[2024-11-29 03:39:10,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:10,980][root][INFO] - Training Epoch: 6/10, step 123/574 completed (loss: 0.2584861218929291, acc: 0.9473684430122375)
[2024-11-29 03:39:11,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:11,579][root][INFO] - Training Epoch: 6/10, step 124/574 completed (loss: 2.100700616836548, acc: 0.4171779155731201)
[2024-11-29 03:39:11,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:12,195][root][INFO] - Training Epoch: 6/10, step 125/574 completed (loss: 1.7980436086654663, acc: 0.4791666567325592)
[2024-11-29 03:39:12,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:12,790][root][INFO] - Training Epoch: 6/10, step 126/574 completed (loss: 1.9399054050445557, acc: 0.5)
[2024-11-29 03:39:12,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:13,412][root][INFO] - Training Epoch: 6/10, step 127/574 completed (loss: 2.0522947311401367, acc: 0.4583333432674408)
[2024-11-29 03:39:13,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:14,025][root][INFO] - Training Epoch: 6/10, step 128/574 completed (loss: 1.9587291479110718, acc: 0.47179487347602844)
[2024-11-29 03:39:14,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:14,648][root][INFO] - Training Epoch: 6/10, step 129/574 completed (loss: 1.7676434516906738, acc: 0.529411792755127)
[2024-11-29 03:39:14,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:15,235][root][INFO] - Training Epoch: 6/10, step 130/574 completed (loss: 0.31379273533821106, acc: 0.9230769276618958)
[2024-11-29 03:39:15,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:15,822][root][INFO] - Training Epoch: 6/10, step 131/574 completed (loss: 0.09147679060697556, acc: 0.95652174949646)
[2024-11-29 03:39:15,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:16,410][root][INFO] - Training Epoch: 6/10, step 132/574 completed (loss: 0.49525874853134155, acc: 0.96875)
[2024-11-29 03:39:17,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:17,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:18,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:18,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:19,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:19,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:20,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:20,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:21,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:21,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:22,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:22,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:23,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:23,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:24,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:25,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:25,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:26,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:26,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:27,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:27,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:28,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:28,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:29,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:29,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:30,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:30,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:31,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:31,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:32,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:32,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:33,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:34,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:34,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:35,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:35,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:36,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:36,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:37,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:37,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:38,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:38,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:39,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:39,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:40,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:40,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:41,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:41,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:42,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:43,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:43,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:44,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:44,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:45,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:45,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:46,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:46,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:47,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:47,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:48,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:48,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:49,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:49,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:50,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:50,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:51,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:51,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:52,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:53,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:53,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:54,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:54,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:55,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:55,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:56,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:56,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:57,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:57,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:58,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:58,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:59,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:59,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:00,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:01,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:01,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:02,305][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(4.2608, device='cuda:0') eval_epoch_loss=tensor(1.4495, device='cuda:0') eval_epoch_acc=tensor(0.6292, device='cuda:0')
[2024-11-29 03:40:02,307][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:40:02,307][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:40:02,561][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_6_step_133_loss_1.449458360671997/model.pt
[2024-11-29 03:40:02,566][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 6 is 1.449458360671997
[2024-11-29 03:40:02,566][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 6 is 0.6292098760604858
[2024-11-29 03:40:02,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:03,174][root][INFO] - Training Epoch: 6/10, step 133/574 completed (loss: 0.6030324697494507, acc: 0.782608687877655)
[2024-11-29 03:40:03,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:03,761][root][INFO] - Training Epoch: 6/10, step 134/574 completed (loss: 0.4656416177749634, acc: 0.8571428656578064)
[2024-11-29 03:40:03,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:04,350][root][INFO] - Training Epoch: 6/10, step 135/574 completed (loss: 0.5011231303215027, acc: 0.8461538553237915)
[2024-11-29 03:40:04,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:04,939][root][INFO] - Training Epoch: 6/10, step 136/574 completed (loss: 0.867286205291748, acc: 0.738095223903656)
[2024-11-29 03:40:05,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:05,525][root][INFO] - Training Epoch: 6/10, step 137/574 completed (loss: 0.22983810305595398, acc: 0.9333333373069763)
[2024-11-29 03:40:05,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:06,111][root][INFO] - Training Epoch: 6/10, step 138/574 completed (loss: 0.16911247372627258, acc: 1.0)
[2024-11-29 03:40:06,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:06,697][root][INFO] - Training Epoch: 6/10, step 139/574 completed (loss: 0.3499271869659424, acc: 0.9047619104385376)
[2024-11-29 03:40:06,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:07,285][root][INFO] - Training Epoch: 6/10, step 140/574 completed (loss: 0.192221537232399, acc: 0.9615384340286255)
[2024-11-29 03:40:07,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:07,873][root][INFO] - Training Epoch: 6/10, step 141/574 completed (loss: 0.7446705102920532, acc: 0.7419354915618896)
[2024-11-29 03:40:07,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:08,460][root][INFO] - Training Epoch: 6/10, step 142/574 completed (loss: 0.7395305633544922, acc: 0.7567567825317383)
[2024-11-29 03:40:08,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:09,072][root][INFO] - Training Epoch: 6/10, step 143/574 completed (loss: 1.424558162689209, acc: 0.5614035129547119)
[2024-11-29 03:40:09,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:09,667][root][INFO] - Training Epoch: 6/10, step 144/574 completed (loss: 1.3950830698013306, acc: 0.6343283653259277)
[2024-11-29 03:40:09,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:10,268][root][INFO] - Training Epoch: 6/10, step 145/574 completed (loss: 1.8349132537841797, acc: 0.44897958636283875)
[2024-11-29 03:40:10,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:10,877][root][INFO] - Training Epoch: 6/10, step 146/574 completed (loss: 1.71979820728302, acc: 0.542553186416626)
[2024-11-29 03:40:10,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:11,472][root][INFO] - Training Epoch: 6/10, step 147/574 completed (loss: 1.2586051225662231, acc: 0.699999988079071)
[2024-11-29 03:40:11,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:12,061][root][INFO] - Training Epoch: 6/10, step 148/574 completed (loss: 0.3848789632320404, acc: 0.8928571343421936)
[2024-11-29 03:40:12,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:12,650][root][INFO] - Training Epoch: 6/10, step 149/574 completed (loss: 0.4023023247718811, acc: 0.8695651888847351)
[2024-11-29 03:40:12,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:13,240][root][INFO] - Training Epoch: 6/10, step 150/574 completed (loss: 0.7242840528488159, acc: 0.8275862336158752)
[2024-11-29 03:40:13,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:13,830][root][INFO] - Training Epoch: 6/10, step 151/574 completed (loss: 0.9071264863014221, acc: 0.739130437374115)
[2024-11-29 03:40:13,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:14,422][root][INFO] - Training Epoch: 6/10, step 152/574 completed (loss: 1.3480126857757568, acc: 0.6610169410705566)
[2024-11-29 03:40:14,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:15,012][root][INFO] - Training Epoch: 6/10, step 153/574 completed (loss: 1.4229810237884521, acc: 0.5964912176132202)
[2024-11-29 03:40:15,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:15,606][root][INFO] - Training Epoch: 6/10, step 154/574 completed (loss: 1.2598108053207397, acc: 0.6891891956329346)
[2024-11-29 03:40:15,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:16,193][root][INFO] - Training Epoch: 6/10, step 155/574 completed (loss: 0.17754587531089783, acc: 1.0)
[2024-11-29 03:40:16,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:16,783][root][INFO] - Training Epoch: 6/10, step 156/574 completed (loss: 0.34362417459487915, acc: 0.8695651888847351)
[2024-11-29 03:40:16,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:17,372][root][INFO] - Training Epoch: 6/10, step 157/574 completed (loss: 0.2790006995201111, acc: 0.9473684430122375)
[2024-11-29 03:40:17,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:17,966][root][INFO] - Training Epoch: 6/10, step 158/574 completed (loss: 1.2295416593551636, acc: 0.6756756901741028)
[2024-11-29 03:40:18,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:18,558][root][INFO] - Training Epoch: 6/10, step 159/574 completed (loss: 1.4139580726623535, acc: 0.5740740895271301)
[2024-11-29 03:40:18,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:19,152][root][INFO] - Training Epoch: 6/10, step 160/574 completed (loss: 1.6971298456192017, acc: 0.5232558250427246)
[2024-11-29 03:40:19,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:19,744][root][INFO] - Training Epoch: 6/10, step 161/574 completed (loss: 1.0944725275039673, acc: 0.6941176652908325)
[2024-11-29 03:40:19,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:20,340][root][INFO] - Training Epoch: 6/10, step 162/574 completed (loss: 1.7205491065979004, acc: 0.5056179761886597)
[2024-11-29 03:40:20,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:20,930][root][INFO] - Training Epoch: 6/10, step 163/574 completed (loss: 0.8231719732284546, acc: 0.7727272510528564)
[2024-11-29 03:40:21,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:21,516][root][INFO] - Training Epoch: 6/10, step 164/574 completed (loss: 0.2014859914779663, acc: 0.9047619104385376)
[2024-11-29 03:40:21,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:22,103][root][INFO] - Training Epoch: 6/10, step 165/574 completed (loss: 0.23824633657932281, acc: 0.9655172228813171)
[2024-11-29 03:40:22,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:22,695][root][INFO] - Training Epoch: 6/10, step 166/574 completed (loss: 0.49414923787117004, acc: 0.8979591727256775)
[2024-11-29 03:40:22,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:23,282][root][INFO] - Training Epoch: 6/10, step 167/574 completed (loss: 0.6267918944358826, acc: 0.8199999928474426)
[2024-11-29 03:40:23,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:23,878][root][INFO] - Training Epoch: 6/10, step 168/574 completed (loss: 1.1575459241867065, acc: 0.6527777910232544)
[2024-11-29 03:40:23,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:24,472][root][INFO] - Training Epoch: 6/10, step 169/574 completed (loss: 1.9488648176193237, acc: 0.529411792755127)
[2024-11-29 03:40:24,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:25,099][root][INFO] - Training Epoch: 6/10, step 170/574 completed (loss: 2.3468263149261475, acc: 0.43150684237480164)
[2024-11-29 03:40:25,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:25,687][root][INFO] - Training Epoch: 6/10, step 171/574 completed (loss: 0.04870044067502022, acc: 1.0)
[2024-11-29 03:40:25,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:26,274][root][INFO] - Training Epoch: 6/10, step 172/574 completed (loss: 0.1430225521326065, acc: 0.9629629850387573)
[2024-11-29 03:40:26,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:26,861][root][INFO] - Training Epoch: 6/10, step 173/574 completed (loss: 0.28547656536102295, acc: 0.8928571343421936)
[2024-11-29 03:40:26,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:27,475][root][INFO] - Training Epoch: 6/10, step 174/574 completed (loss: 1.9891573190689087, acc: 0.5486725568771362)
[2024-11-29 03:40:27,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:28,068][root][INFO] - Training Epoch: 6/10, step 175/574 completed (loss: 1.0771169662475586, acc: 0.6811594367027283)
[2024-11-29 03:40:28,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:28,667][root][INFO] - Training Epoch: 6/10, step 176/574 completed (loss: 1.4155150651931763, acc: 0.6704545617103577)
[2024-11-29 03:40:28,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:29,278][root][INFO] - Training Epoch: 6/10, step 177/574 completed (loss: 2.3314435482025146, acc: 0.3664122223854065)
[2024-11-29 03:40:29,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:29,888][root][INFO] - Training Epoch: 6/10, step 178/574 completed (loss: 2.2360541820526123, acc: 0.4000000059604645)
[2024-11-29 03:40:29,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:30,480][root][INFO] - Training Epoch: 6/10, step 179/574 completed (loss: 0.8915277719497681, acc: 0.7213114500045776)
[2024-11-29 03:40:30,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:31,067][root][INFO] - Training Epoch: 6/10, step 180/574 completed (loss: 0.2727165222167969, acc: 0.9583333134651184)
[2024-11-29 03:40:31,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:31,656][root][INFO] - Training Epoch: 6/10, step 181/574 completed (loss: 0.13645590841770172, acc: 0.9599999785423279)
[2024-11-29 03:40:31,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:32,243][root][INFO] - Training Epoch: 6/10, step 182/574 completed (loss: 0.06943786889314651, acc: 1.0)
[2024-11-29 03:40:32,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:32,840][root][INFO] - Training Epoch: 6/10, step 183/574 completed (loss: 1.5222581624984741, acc: 0.5853658318519592)
[2024-11-29 03:40:32,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:33,467][root][INFO] - Training Epoch: 6/10, step 184/574 completed (loss: 2.4800148010253906, acc: 0.32930514216423035)
[2024-11-29 03:40:33,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:34,093][root][INFO] - Training Epoch: 6/10, step 185/574 completed (loss: 2.5499043464660645, acc: 0.3458213210105896)
[2024-11-29 03:40:34,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:34,712][root][INFO] - Training Epoch: 6/10, step 186/574 completed (loss: 2.5880162715911865, acc: 0.33125001192092896)
[2024-11-29 03:40:34,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:35,369][root][INFO] - Training Epoch: 6/10, step 187/574 completed (loss: 2.6274712085723877, acc: 0.30393996834754944)
[2024-11-29 03:40:35,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:36,002][root][INFO] - Training Epoch: 6/10, step 188/574 completed (loss: 2.2122209072113037, acc: 0.38434162735939026)
[2024-11-29 03:40:36,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:36,588][root][INFO] - Training Epoch: 6/10, step 189/574 completed (loss: 0.4849439859390259, acc: 0.8399999737739563)
[2024-11-29 03:40:36,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:37,183][root][INFO] - Training Epoch: 6/10, step 190/574 completed (loss: 2.020327091217041, acc: 0.4883720874786377)
[2024-11-29 03:40:37,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:37,779][root][INFO] - Training Epoch: 6/10, step 191/574 completed (loss: 1.9866160154342651, acc: 0.4761904776096344)
[2024-11-29 03:40:37,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:38,377][root][INFO] - Training Epoch: 6/10, step 192/574 completed (loss: 2.313764810562134, acc: 0.40909090638160706)
[2024-11-29 03:40:38,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:38,974][root][INFO] - Training Epoch: 6/10, step 193/574 completed (loss: 1.3610464334487915, acc: 0.5647059082984924)
[2024-11-29 03:40:39,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:39,587][root][INFO] - Training Epoch: 6/10, step 194/574 completed (loss: 1.830622673034668, acc: 0.5)
[2024-11-29 03:40:39,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:40,184][root][INFO] - Training Epoch: 6/10, step 195/574 completed (loss: 1.2703591585159302, acc: 0.6290322542190552)
[2024-11-29 03:40:40,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:40,770][root][INFO] - Training Epoch: 6/10, step 196/574 completed (loss: 0.12835188210010529, acc: 0.9642857313156128)
[2024-11-29 03:40:40,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:41,359][root][INFO] - Training Epoch: 6/10, step 197/574 completed (loss: 0.7940061688423157, acc: 0.75)
[2024-11-29 03:40:41,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:41,952][root][INFO] - Training Epoch: 6/10, step 198/574 completed (loss: 0.9870654940605164, acc: 0.7352941036224365)
[2024-11-29 03:40:42,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:42,551][root][INFO] - Training Epoch: 6/10, step 199/574 completed (loss: 1.8504825830459595, acc: 0.5588235259056091)
[2024-11-29 03:40:42,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:43,147][root][INFO] - Training Epoch: 6/10, step 200/574 completed (loss: 1.833821177482605, acc: 0.4576271176338196)
[2024-11-29 03:40:43,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:43,747][root][INFO] - Training Epoch: 6/10, step 201/574 completed (loss: 2.0404205322265625, acc: 0.41791045665740967)
[2024-11-29 03:40:43,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:44,342][root][INFO] - Training Epoch: 6/10, step 202/574 completed (loss: 1.923721432685852, acc: 0.446601927280426)
[2024-11-29 03:40:44,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:44,937][root][INFO] - Training Epoch: 6/10, step 203/574 completed (loss: 1.334816813468933, acc: 0.5714285969734192)
[2024-11-29 03:40:45,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:45,535][root][INFO] - Training Epoch: 6/10, step 204/574 completed (loss: 1.168657660484314, acc: 0.6703296899795532)
[2024-11-29 03:40:45,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:46,153][root][INFO] - Training Epoch: 6/10, step 205/574 completed (loss: 1.9761701822280884, acc: 0.4663677215576172)
[2024-11-29 03:40:46,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:46,778][root][INFO] - Training Epoch: 6/10, step 206/574 completed (loss: 1.9642491340637207, acc: 0.5)
[2024-11-29 03:40:46,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:47,391][root][INFO] - Training Epoch: 6/10, step 207/574 completed (loss: 1.8774282932281494, acc: 0.5086206793785095)
[2024-11-29 03:40:47,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:48,006][root][INFO] - Training Epoch: 6/10, step 208/574 completed (loss: 2.0232458114624023, acc: 0.49637681245803833)
[2024-11-29 03:40:48,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:48,625][root][INFO] - Training Epoch: 6/10, step 209/574 completed (loss: 2.1541850566864014, acc: 0.42023345828056335)
[2024-11-29 03:40:48,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:49,237][root][INFO] - Training Epoch: 6/10, step 210/574 completed (loss: 2.0669782161712646, acc: 0.43478259444236755)
[2024-11-29 03:40:49,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:49,822][root][INFO] - Training Epoch: 6/10, step 211/574 completed (loss: 0.10089098662137985, acc: 1.0)
[2024-11-29 03:40:49,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:50,408][root][INFO] - Training Epoch: 6/10, step 212/574 completed (loss: 0.3128393590450287, acc: 0.8571428656578064)
[2024-11-29 03:40:50,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:51,001][root][INFO] - Training Epoch: 6/10, step 213/574 completed (loss: 0.7241364121437073, acc: 0.7872340679168701)
[2024-11-29 03:40:51,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:51,613][root][INFO] - Training Epoch: 6/10, step 214/574 completed (loss: 1.5972769260406494, acc: 0.5307692289352417)
[2024-11-29 03:40:51,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:52,205][root][INFO] - Training Epoch: 6/10, step 215/574 completed (loss: 0.8180227875709534, acc: 0.7567567825317383)
[2024-11-29 03:40:52,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:52,798][root][INFO] - Training Epoch: 6/10, step 216/574 completed (loss: 0.8723551630973816, acc: 0.7093023061752319)
[2024-11-29 03:40:52,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:53,393][root][INFO] - Training Epoch: 6/10, step 217/574 completed (loss: 1.2589575052261353, acc: 0.6486486196517944)
[2024-11-29 03:40:53,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:53,990][root][INFO] - Training Epoch: 6/10, step 218/574 completed (loss: 1.0297636985778809, acc: 0.699999988079071)
[2024-11-29 03:40:54,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:54,577][root][INFO] - Training Epoch: 6/10, step 219/574 completed (loss: 0.32812875509262085, acc: 0.9090909361839294)
[2024-11-29 03:40:54,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:55,162][root][INFO] - Training Epoch: 6/10, step 220/574 completed (loss: 0.008515632711350918, acc: 1.0)
[2024-11-29 03:40:55,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:55,750][root][INFO] - Training Epoch: 6/10, step 221/574 completed (loss: 0.17848114669322968, acc: 0.9599999785423279)
[2024-11-29 03:40:55,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:56,346][root][INFO] - Training Epoch: 6/10, step 222/574 completed (loss: 1.1163958311080933, acc: 0.6538461446762085)
[2024-11-29 03:40:56,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:56,959][root][INFO] - Training Epoch: 6/10, step 223/574 completed (loss: 1.626249074935913, acc: 0.5597826242446899)
[2024-11-29 03:40:57,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:57,577][root][INFO] - Training Epoch: 6/10, step 224/574 completed (loss: 1.7939116954803467, acc: 0.4829545319080353)
[2024-11-29 03:40:57,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:58,189][root][INFO] - Training Epoch: 6/10, step 225/574 completed (loss: 1.9938284158706665, acc: 0.4680851101875305)
[2024-11-29 03:40:58,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:58,781][root][INFO] - Training Epoch: 6/10, step 226/574 completed (loss: 0.9291378855705261, acc: 0.7358490824699402)
[2024-11-29 03:40:58,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:59,372][root][INFO] - Training Epoch: 6/10, step 227/574 completed (loss: 0.9907969236373901, acc: 0.7333333492279053)
[2024-11-29 03:40:59,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:59,965][root][INFO] - Training Epoch: 6/10, step 228/574 completed (loss: 0.44633418321609497, acc: 0.8604651093482971)
[2024-11-29 03:41:00,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:00,550][root][INFO] - Training Epoch: 6/10, step 229/574 completed (loss: 0.40180540084838867, acc: 0.800000011920929)
[2024-11-29 03:41:00,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:01,147][root][INFO] - Training Epoch: 6/10, step 230/574 completed (loss: 2.023416757583618, acc: 0.49473685026168823)
[2024-11-29 03:41:01,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:01,738][root][INFO] - Training Epoch: 6/10, step 231/574 completed (loss: 1.278977394104004, acc: 0.6555555462837219)
[2024-11-29 03:41:01,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:02,351][root][INFO] - Training Epoch: 6/10, step 232/574 completed (loss: 1.596550464630127, acc: 0.5444444417953491)
[2024-11-29 03:41:02,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:02,964][root][INFO] - Training Epoch: 6/10, step 233/574 completed (loss: 1.9613696336746216, acc: 0.5)
[2024-11-29 03:41:03,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:03,577][root][INFO] - Training Epoch: 6/10, step 234/574 completed (loss: 1.6361804008483887, acc: 0.5307692289352417)
[2024-11-29 03:41:03,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:04,163][root][INFO] - Training Epoch: 6/10, step 235/574 completed (loss: 0.3595735728740692, acc: 0.8947368264198303)
[2024-11-29 03:41:04,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:04,750][root][INFO] - Training Epoch: 6/10, step 236/574 completed (loss: 0.16033945977687836, acc: 0.9166666865348816)
[2024-11-29 03:41:04,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:05,337][root][INFO] - Training Epoch: 6/10, step 237/574 completed (loss: 0.273078054189682, acc: 0.8636363744735718)
[2024-11-29 03:41:05,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:05,925][root][INFO] - Training Epoch: 6/10, step 238/574 completed (loss: 0.33580315113067627, acc: 0.8888888955116272)
[2024-11-29 03:41:06,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:06,515][root][INFO] - Training Epoch: 6/10, step 239/574 completed (loss: 0.697476327419281, acc: 0.8571428656578064)
[2024-11-29 03:41:06,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:07,105][root][INFO] - Training Epoch: 6/10, step 240/574 completed (loss: 0.5037500858306885, acc: 0.8409090638160706)
[2024-11-29 03:41:07,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:07,691][root][INFO] - Training Epoch: 6/10, step 241/574 completed (loss: 0.6500942707061768, acc: 0.8409090638160706)
[2024-11-29 03:41:07,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:08,288][root][INFO] - Training Epoch: 6/10, step 242/574 completed (loss: 1.5350744724273682, acc: 0.5806451439857483)
[2024-11-29 03:41:08,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:08,880][root][INFO] - Training Epoch: 6/10, step 243/574 completed (loss: 0.7105029821395874, acc: 0.7954545617103577)
[2024-11-29 03:41:08,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:09,466][root][INFO] - Training Epoch: 6/10, step 244/574 completed (loss: 0.008020899258553982, acc: 1.0)
[2024-11-29 03:41:09,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:10,054][root][INFO] - Training Epoch: 6/10, step 245/574 completed (loss: 0.06413397192955017, acc: 1.0)
[2024-11-29 03:41:10,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:10,641][root][INFO] - Training Epoch: 6/10, step 246/574 completed (loss: 0.10882295668125153, acc: 0.9677419066429138)
[2024-11-29 03:41:10,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:11,229][root][INFO] - Training Epoch: 6/10, step 247/574 completed (loss: 0.03068254515528679, acc: 1.0)
[2024-11-29 03:41:11,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:11,821][root][INFO] - Training Epoch: 6/10, step 248/574 completed (loss: 0.4480725824832916, acc: 0.837837815284729)
[2024-11-29 03:41:11,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:12,409][root][INFO] - Training Epoch: 6/10, step 249/574 completed (loss: 0.2457968294620514, acc: 0.9459459185600281)
[2024-11-29 03:41:12,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:12,998][root][INFO] - Training Epoch: 6/10, step 250/574 completed (loss: 0.3805604875087738, acc: 0.9189189076423645)
[2024-11-29 03:41:13,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:13,593][root][INFO] - Training Epoch: 6/10, step 251/574 completed (loss: 1.1209044456481934, acc: 0.6176470518112183)
[2024-11-29 03:41:13,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:14,181][root][INFO] - Training Epoch: 6/10, step 252/574 completed (loss: 0.15191550552845, acc: 0.9512194991111755)
[2024-11-29 03:41:14,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:14,771][root][INFO] - Training Epoch: 6/10, step 253/574 completed (loss: 0.2229081690311432, acc: 0.9599999785423279)
[2024-11-29 03:41:14,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:15,363][root][INFO] - Training Epoch: 6/10, step 254/574 completed (loss: 0.05666030943393707, acc: 1.0)
[2024-11-29 03:41:15,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:15,951][root][INFO] - Training Epoch: 6/10, step 255/574 completed (loss: 0.0769454687833786, acc: 0.9677419066429138)
[2024-11-29 03:41:16,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:16,543][root][INFO] - Training Epoch: 6/10, step 256/574 completed (loss: 0.9963483810424805, acc: 0.7017543911933899)
[2024-11-29 03:41:16,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:17,133][root][INFO] - Training Epoch: 6/10, step 257/574 completed (loss: 0.7457864880561829, acc: 0.7714285850524902)
[2024-11-29 03:41:17,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:17,725][root][INFO] - Training Epoch: 6/10, step 258/574 completed (loss: 0.6290729641914368, acc: 0.8157894611358643)
[2024-11-29 03:41:17,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:18,336][root][INFO] - Training Epoch: 6/10, step 259/574 completed (loss: 1.1658995151519775, acc: 0.650943398475647)
[2024-11-29 03:41:18,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:18,954][root][INFO] - Training Epoch: 6/10, step 260/574 completed (loss: 1.6957849264144897, acc: 0.550000011920929)
[2024-11-29 03:41:19,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:19,544][root][INFO] - Training Epoch: 6/10, step 261/574 completed (loss: 0.22826358675956726, acc: 0.8888888955116272)
[2024-11-29 03:41:19,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:20,133][root][INFO] - Training Epoch: 6/10, step 262/574 completed (loss: 0.3095771372318268, acc: 0.9354838728904724)
[2024-11-29 03:41:20,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:20,729][root][INFO] - Training Epoch: 6/10, step 263/574 completed (loss: 1.8584271669387817, acc: 0.5066666603088379)
[2024-11-29 03:41:20,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:21,318][root][INFO] - Training Epoch: 6/10, step 264/574 completed (loss: 1.0814374685287476, acc: 0.6666666865348816)
[2024-11-29 03:41:21,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:21,934][root][INFO] - Training Epoch: 6/10, step 265/574 completed (loss: 2.085099935531616, acc: 0.5120000243186951)
[2024-11-29 03:41:22,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:22,528][root][INFO] - Training Epoch: 6/10, step 266/574 completed (loss: 1.5395127534866333, acc: 0.5617977380752563)
[2024-11-29 03:41:22,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:23,124][root][INFO] - Training Epoch: 6/10, step 267/574 completed (loss: 1.5278528928756714, acc: 0.5405405163764954)
[2024-11-29 03:41:23,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:23,719][root][INFO] - Training Epoch: 6/10, step 268/574 completed (loss: 1.0674148797988892, acc: 0.6896551847457886)
[2024-11-29 03:41:23,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:24,304][root][INFO] - Training Epoch: 6/10, step 269/574 completed (loss: 0.13723744451999664, acc: 0.9090909361839294)
[2024-11-29 03:41:24,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:24,891][root][INFO] - Training Epoch: 6/10, step 270/574 completed (loss: 0.04708993434906006, acc: 1.0)
[2024-11-29 03:41:24,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:25,479][root][INFO] - Training Epoch: 6/10, step 271/574 completed (loss: 0.23225194215774536, acc: 0.875)
[2024-11-29 03:41:25,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:26,068][root][INFO] - Training Epoch: 6/10, step 272/574 completed (loss: 0.05481266230344772, acc: 1.0)
[2024-11-29 03:41:26,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:26,662][root][INFO] - Training Epoch: 6/10, step 273/574 completed (loss: 1.0948113203048706, acc: 0.699999988079071)
[2024-11-29 03:41:26,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:27,249][root][INFO] - Training Epoch: 6/10, step 274/574 completed (loss: 0.3264337182044983, acc: 0.90625)
[2024-11-29 03:41:27,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:27,838][root][INFO] - Training Epoch: 6/10, step 275/574 completed (loss: 0.11449180543422699, acc: 1.0)
[2024-11-29 03:41:28,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:29,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:29,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:30,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:30,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:31,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:31,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:32,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:32,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:33,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:33,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:34,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:35,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:35,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:36,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:36,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:37,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:37,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:38,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:38,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:39,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:39,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:40,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:40,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:41,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:41,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:42,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:42,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:43,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:43,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:44,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:45,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:45,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:46,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:46,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:47,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:47,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:48,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:48,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:49,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:49,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:50,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:50,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:51,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:51,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:52,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:53,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:53,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:54,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:54,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:55,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:55,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:56,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:56,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:57,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:57,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:58,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:58,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:59,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:59,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:00,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:00,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:01,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:02,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:02,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:03,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:03,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:04,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:04,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:05,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:05,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:06,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:06,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:07,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:07,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:08,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:08,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:09,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:09,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:10,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:10,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:11,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:11,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:12,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:13,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:13,784][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(4.4537, device='cuda:0') eval_epoch_loss=tensor(1.4937, device='cuda:0') eval_epoch_acc=tensor(0.6386, device='cuda:0')
[2024-11-29 03:42:13,785][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:42:13,785][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:42:13,997][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_6_step_276_loss_1.4937283992767334/model.pt
[2024-11-29 03:42:14,001][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 6 is 0.6385501027107239
[2024-11-29 03:42:14,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:14,607][root][INFO] - Training Epoch: 6/10, step 276/574 completed (loss: 0.15194714069366455, acc: 0.9655172228813171)
[2024-11-29 03:42:14,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:15,194][root][INFO] - Training Epoch: 6/10, step 277/574 completed (loss: 0.03721975162625313, acc: 1.0)
[2024-11-29 03:42:15,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:15,788][root][INFO] - Training Epoch: 6/10, step 278/574 completed (loss: 1.1999139785766602, acc: 0.6170212626457214)
[2024-11-29 03:42:15,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:16,381][root][INFO] - Training Epoch: 6/10, step 279/574 completed (loss: 0.8520979285240173, acc: 0.75)
[2024-11-29 03:42:16,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:16,976][root][INFO] - Training Epoch: 6/10, step 280/574 completed (loss: 0.4223800599575043, acc: 0.8181818127632141)
[2024-11-29 03:42:17,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:17,570][root][INFO] - Training Epoch: 6/10, step 281/574 completed (loss: 1.688355803489685, acc: 0.5542168617248535)
[2024-11-29 03:42:17,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:18,165][root][INFO] - Training Epoch: 6/10, step 282/574 completed (loss: 1.5410988330841064, acc: 0.6018518805503845)
[2024-11-29 03:42:18,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:18,752][root][INFO] - Training Epoch: 6/10, step 283/574 completed (loss: 0.4793756902217865, acc: 0.8421052694320679)
[2024-11-29 03:42:18,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:19,340][root][INFO] - Training Epoch: 6/10, step 284/574 completed (loss: 0.6121363043785095, acc: 0.8529411554336548)
[2024-11-29 03:42:19,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:19,930][root][INFO] - Training Epoch: 6/10, step 285/574 completed (loss: 0.2433718740940094, acc: 0.949999988079071)
[2024-11-29 03:42:20,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:20,527][root][INFO] - Training Epoch: 6/10, step 286/574 completed (loss: 1.7327219247817993, acc: 0.4921875)
[2024-11-29 03:42:20,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:21,139][root][INFO] - Training Epoch: 6/10, step 287/574 completed (loss: 1.8348612785339355, acc: 0.47200000286102295)
[2024-11-29 03:42:21,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:21,733][root][INFO] - Training Epoch: 6/10, step 288/574 completed (loss: 1.143674612045288, acc: 0.7032967209815979)
[2024-11-29 03:42:21,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:22,333][root][INFO] - Training Epoch: 6/10, step 289/574 completed (loss: 1.976033329963684, acc: 0.44720497727394104)
[2024-11-29 03:42:22,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:22,946][root][INFO] - Training Epoch: 6/10, step 290/574 completed (loss: 2.135343313217163, acc: 0.4175257682800293)
[2024-11-29 03:42:23,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:23,532][root][INFO] - Training Epoch: 6/10, step 291/574 completed (loss: 0.05082930624485016, acc: 1.0)
[2024-11-29 03:42:23,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:24,121][root][INFO] - Training Epoch: 6/10, step 292/574 completed (loss: 0.8507758378982544, acc: 0.7857142686843872)
[2024-11-29 03:42:24,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:24,714][root][INFO] - Training Epoch: 6/10, step 293/574 completed (loss: 0.845808207988739, acc: 0.7586206793785095)
[2024-11-29 03:42:24,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:25,309][root][INFO] - Training Epoch: 6/10, step 294/574 completed (loss: 0.7705415487289429, acc: 0.7454545497894287)
[2024-11-29 03:42:25,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:25,933][root][INFO] - Training Epoch: 6/10, step 295/574 completed (loss: 1.7512747049331665, acc: 0.5463917255401611)
[2024-11-29 03:42:26,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:26,524][root][INFO] - Training Epoch: 6/10, step 296/574 completed (loss: 1.2874096632003784, acc: 0.6206896305084229)
[2024-11-29 03:42:26,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:27,109][root][INFO] - Training Epoch: 6/10, step 297/574 completed (loss: 0.2849319279193878, acc: 0.9259259104728699)
[2024-11-29 03:42:27,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:27,700][root][INFO] - Training Epoch: 6/10, step 298/574 completed (loss: 0.8427814841270447, acc: 0.7631579041481018)
[2024-11-29 03:42:27,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:28,291][root][INFO] - Training Epoch: 6/10, step 299/574 completed (loss: 1.1284949779510498, acc: 0.7321428656578064)
[2024-11-29 03:42:28,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:28,881][root][INFO] - Training Epoch: 6/10, step 300/574 completed (loss: 0.48347434401512146, acc: 0.875)
[2024-11-29 03:42:28,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:29,472][root][INFO] - Training Epoch: 6/10, step 301/574 completed (loss: 1.006066918373108, acc: 0.7735849022865295)
[2024-11-29 03:42:29,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:30,064][root][INFO] - Training Epoch: 6/10, step 302/574 completed (loss: 0.3018815517425537, acc: 0.8867924809455872)
[2024-11-29 03:42:30,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:30,650][root][INFO] - Training Epoch: 6/10, step 303/574 completed (loss: 0.07585704326629639, acc: 0.970588207244873)
[2024-11-29 03:42:30,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:31,238][root][INFO] - Training Epoch: 6/10, step 304/574 completed (loss: 0.6926463842391968, acc: 0.8125)
[2024-11-29 03:42:31,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:31,830][root][INFO] - Training Epoch: 6/10, step 305/574 completed (loss: 0.6264607906341553, acc: 0.8360655903816223)
[2024-11-29 03:42:31,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:32,420][root][INFO] - Training Epoch: 6/10, step 306/574 completed (loss: 0.1396220326423645, acc: 0.9666666388511658)
[2024-11-29 03:42:32,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:33,005][root][INFO] - Training Epoch: 6/10, step 307/574 completed (loss: 0.006265353411436081, acc: 1.0)
[2024-11-29 03:42:33,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:33,600][root][INFO] - Training Epoch: 6/10, step 308/574 completed (loss: 1.315070629119873, acc: 0.5942028760910034)
[2024-11-29 03:42:33,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:34,199][root][INFO] - Training Epoch: 6/10, step 309/574 completed (loss: 1.373525619506836, acc: 0.6111111044883728)
[2024-11-29 03:42:34,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:34,794][root][INFO] - Training Epoch: 6/10, step 310/574 completed (loss: 1.2016736268997192, acc: 0.6626505851745605)
[2024-11-29 03:42:34,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:35,389][root][INFO] - Training Epoch: 6/10, step 311/574 completed (loss: 1.2546857595443726, acc: 0.6538461446762085)
[2024-11-29 03:42:35,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:36,000][root][INFO] - Training Epoch: 6/10, step 312/574 completed (loss: 1.5743647813796997, acc: 0.581632673740387)
[2024-11-29 03:42:36,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:36,585][root][INFO] - Training Epoch: 6/10, step 313/574 completed (loss: 0.01323362160474062, acc: 1.0)
[2024-11-29 03:42:36,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:37,172][root][INFO] - Training Epoch: 6/10, step 314/574 completed (loss: 0.09550517052412033, acc: 1.0)
[2024-11-29 03:42:37,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:37,759][root][INFO] - Training Epoch: 6/10, step 315/574 completed (loss: 0.06547623127698898, acc: 1.0)
[2024-11-29 03:42:37,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:38,345][root][INFO] - Training Epoch: 6/10, step 316/574 completed (loss: 0.060442958027124405, acc: 0.9677419066429138)
[2024-11-29 03:42:38,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:38,939][root][INFO] - Training Epoch: 6/10, step 317/574 completed (loss: 1.163459300994873, acc: 0.7014925479888916)
[2024-11-29 03:42:39,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:39,536][root][INFO] - Training Epoch: 6/10, step 318/574 completed (loss: 1.024522066116333, acc: 0.6634615659713745)
[2024-11-29 03:42:39,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:40,126][root][INFO] - Training Epoch: 6/10, step 319/574 completed (loss: 0.41710716485977173, acc: 0.8222222328186035)
[2024-11-29 03:42:40,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:40,718][root][INFO] - Training Epoch: 6/10, step 320/574 completed (loss: 0.6856397390365601, acc: 0.7580645084381104)
[2024-11-29 03:42:40,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:41,307][root][INFO] - Training Epoch: 6/10, step 321/574 completed (loss: 0.06411635875701904, acc: 1.0)
[2024-11-29 03:42:41,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:41,894][root][INFO] - Training Epoch: 6/10, step 322/574 completed (loss: 0.7233761548995972, acc: 0.8148148059844971)
[2024-11-29 03:42:41,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:42,483][root][INFO] - Training Epoch: 6/10, step 323/574 completed (loss: 1.1353881359100342, acc: 0.6857143044471741)
[2024-11-29 03:42:42,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:43,072][root][INFO] - Training Epoch: 6/10, step 324/574 completed (loss: 0.7589717507362366, acc: 0.8205128312110901)
[2024-11-29 03:42:43,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:43,668][root][INFO] - Training Epoch: 6/10, step 325/574 completed (loss: 1.0107324123382568, acc: 0.707317054271698)
[2024-11-29 03:42:43,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:44,262][root][INFO] - Training Epoch: 6/10, step 326/574 completed (loss: 0.7396401166915894, acc: 0.8421052694320679)
[2024-11-29 03:42:44,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:44,848][root][INFO] - Training Epoch: 6/10, step 327/574 completed (loss: 0.13012045621871948, acc: 0.9473684430122375)
[2024-11-29 03:42:44,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:45,435][root][INFO] - Training Epoch: 6/10, step 328/574 completed (loss: 0.10313747823238373, acc: 0.9285714030265808)
[2024-11-29 03:42:45,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:46,023][root][INFO] - Training Epoch: 6/10, step 329/574 completed (loss: 0.37168481945991516, acc: 0.8888888955116272)
[2024-11-29 03:42:46,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:46,612][root][INFO] - Training Epoch: 6/10, step 330/574 completed (loss: 0.2488030046224594, acc: 0.9375)
[2024-11-29 03:42:46,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:47,203][root][INFO] - Training Epoch: 6/10, step 331/574 completed (loss: 0.9998742938041687, acc: 0.7096773982048035)
[2024-11-29 03:42:47,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:47,798][root][INFO] - Training Epoch: 6/10, step 332/574 completed (loss: 0.7417780160903931, acc: 0.7368420958518982)
[2024-11-29 03:42:47,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:48,385][root][INFO] - Training Epoch: 6/10, step 333/574 completed (loss: 0.5258582830429077, acc: 0.84375)
[2024-11-29 03:42:48,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:48,972][root][INFO] - Training Epoch: 6/10, step 334/574 completed (loss: 0.2947230041027069, acc: 0.8999999761581421)
[2024-11-29 03:42:49,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:49,558][root][INFO] - Training Epoch: 6/10, step 335/574 completed (loss: 0.3566456437110901, acc: 0.8421052694320679)
[2024-11-29 03:42:49,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:50,150][root][INFO] - Training Epoch: 6/10, step 336/574 completed (loss: 1.7078454494476318, acc: 0.5199999809265137)
[2024-11-29 03:42:50,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:50,747][root][INFO] - Training Epoch: 6/10, step 337/574 completed (loss: 2.1112585067749023, acc: 0.5057471394538879)
[2024-11-29 03:42:50,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:51,342][root][INFO] - Training Epoch: 6/10, step 338/574 completed (loss: 1.9293482303619385, acc: 0.44680851697921753)
[2024-11-29 03:42:51,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:51,938][root][INFO] - Training Epoch: 6/10, step 339/574 completed (loss: 1.8833431005477905, acc: 0.5180723071098328)
[2024-11-29 03:42:52,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:52,527][root][INFO] - Training Epoch: 6/10, step 340/574 completed (loss: 0.10611867904663086, acc: 0.95652174949646)
[2024-11-29 03:42:52,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:53,116][root][INFO] - Training Epoch: 6/10, step 341/574 completed (loss: 0.8066590428352356, acc: 0.8461538553237915)
[2024-11-29 03:42:53,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:53,710][root][INFO] - Training Epoch: 6/10, step 342/574 completed (loss: 1.8384912014007568, acc: 0.5301204919815063)
[2024-11-29 03:42:53,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:54,305][root][INFO] - Training Epoch: 6/10, step 343/574 completed (loss: 0.9971252083778381, acc: 0.7358490824699402)
[2024-11-29 03:42:54,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:54,897][root][INFO] - Training Epoch: 6/10, step 344/574 completed (loss: 1.3473167419433594, acc: 0.6202531456947327)
[2024-11-29 03:42:54,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:55,486][root][INFO] - Training Epoch: 6/10, step 345/574 completed (loss: 0.9848888516426086, acc: 0.6470588445663452)
[2024-11-29 03:42:55,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:56,082][root][INFO] - Training Epoch: 6/10, step 346/574 completed (loss: 1.6080995798110962, acc: 0.5522388219833374)
[2024-11-29 03:42:56,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:56,670][root][INFO] - Training Epoch: 6/10, step 347/574 completed (loss: 0.14346861839294434, acc: 0.949999988079071)
[2024-11-29 03:42:56,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:57,256][root][INFO] - Training Epoch: 6/10, step 348/574 completed (loss: 0.4640575349330902, acc: 0.9200000166893005)
[2024-11-29 03:42:57,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:57,844][root][INFO] - Training Epoch: 6/10, step 349/574 completed (loss: 0.7227129340171814, acc: 0.7777777910232544)
[2024-11-29 03:42:57,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:58,438][root][INFO] - Training Epoch: 6/10, step 350/574 completed (loss: 1.3283734321594238, acc: 0.6744186282157898)
[2024-11-29 03:42:58,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:59,026][root][INFO] - Training Epoch: 6/10, step 351/574 completed (loss: 0.9685049653053284, acc: 0.6666666865348816)
[2024-11-29 03:42:59,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:59,618][root][INFO] - Training Epoch: 6/10, step 352/574 completed (loss: 1.3937329053878784, acc: 0.6222222447395325)
[2024-11-29 03:42:59,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:00,204][root][INFO] - Training Epoch: 6/10, step 353/574 completed (loss: 0.07933175563812256, acc: 0.95652174949646)
[2024-11-29 03:43:00,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:00,791][root][INFO] - Training Epoch: 6/10, step 354/574 completed (loss: 0.8683392405509949, acc: 0.807692289352417)
[2024-11-29 03:43:00,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:01,385][root][INFO] - Training Epoch: 6/10, step 355/574 completed (loss: 2.0138165950775146, acc: 0.4175824224948883)
[2024-11-29 03:43:01,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:01,995][root][INFO] - Training Epoch: 6/10, step 356/574 completed (loss: 1.782028079032898, acc: 0.5478261113166809)
[2024-11-29 03:43:02,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:02,586][root][INFO] - Training Epoch: 6/10, step 357/574 completed (loss: 1.5277502536773682, acc: 0.5869565010070801)
[2024-11-29 03:43:02,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:03,178][root][INFO] - Training Epoch: 6/10, step 358/574 completed (loss: 0.9009795188903809, acc: 0.7755101919174194)
[2024-11-29 03:43:03,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:03,764][root][INFO] - Training Epoch: 6/10, step 359/574 completed (loss: 0.05802605673670769, acc: 1.0)
[2024-11-29 03:43:03,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:04,350][root][INFO] - Training Epoch: 6/10, step 360/574 completed (loss: 0.21284164488315582, acc: 0.9615384340286255)
[2024-11-29 03:43:04,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:04,938][root][INFO] - Training Epoch: 6/10, step 361/574 completed (loss: 0.5299311876296997, acc: 0.7804877758026123)
[2024-11-29 03:43:05,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:05,527][root][INFO] - Training Epoch: 6/10, step 362/574 completed (loss: 0.7401173114776611, acc: 0.7555555701255798)
[2024-11-29 03:43:05,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:06,121][root][INFO] - Training Epoch: 6/10, step 363/574 completed (loss: 1.3192939758300781, acc: 0.6315789222717285)
[2024-11-29 03:43:06,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:06,714][root][INFO] - Training Epoch: 6/10, step 364/574 completed (loss: 0.772807240486145, acc: 0.7317073345184326)
[2024-11-29 03:43:06,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:07,307][root][INFO] - Training Epoch: 6/10, step 365/574 completed (loss: 0.5126245021820068, acc: 0.9090909361839294)
[2024-11-29 03:43:07,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:07,894][root][INFO] - Training Epoch: 6/10, step 366/574 completed (loss: 0.011205706745386124, acc: 1.0)
[2024-11-29 03:43:07,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:08,481][root][INFO] - Training Epoch: 6/10, step 367/574 completed (loss: 0.008047386072576046, acc: 1.0)
[2024-11-29 03:43:08,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:09,073][root][INFO] - Training Epoch: 6/10, step 368/574 completed (loss: 0.1136900782585144, acc: 1.0)
[2024-11-29 03:43:09,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:09,663][root][INFO] - Training Epoch: 6/10, step 369/574 completed (loss: 0.495496928691864, acc: 0.8125)
[2024-11-29 03:43:09,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:10,278][root][INFO] - Training Epoch: 6/10, step 370/574 completed (loss: 1.9935104846954346, acc: 0.5090909004211426)
[2024-11-29 03:43:10,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:10,889][root][INFO] - Training Epoch: 6/10, step 371/574 completed (loss: 1.3993909358978271, acc: 0.6415094137191772)
[2024-11-29 03:43:10,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:11,483][root][INFO] - Training Epoch: 6/10, step 372/574 completed (loss: 1.0518462657928467, acc: 0.7111111283302307)
[2024-11-29 03:43:11,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:12,075][root][INFO] - Training Epoch: 6/10, step 373/574 completed (loss: 0.8041992783546448, acc: 0.8035714030265808)
[2024-11-29 03:43:12,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:12,671][root][INFO] - Training Epoch: 6/10, step 374/574 completed (loss: 0.44741034507751465, acc: 0.8285714387893677)
[2024-11-29 03:43:12,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:13,259][root][INFO] - Training Epoch: 6/10, step 375/574 completed (loss: 0.04158749431371689, acc: 1.0)
[2024-11-29 03:43:13,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:13,845][root][INFO] - Training Epoch: 6/10, step 376/574 completed (loss: 0.01254576351493597, acc: 1.0)
[2024-11-29 03:43:13,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:14,436][root][INFO] - Training Epoch: 6/10, step 377/574 completed (loss: 0.47885385155677795, acc: 0.7916666865348816)
[2024-11-29 03:43:14,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:15,032][root][INFO] - Training Epoch: 6/10, step 378/574 completed (loss: 0.9192178249359131, acc: 0.7368420958518982)
[2024-11-29 03:43:15,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:15,642][root][INFO] - Training Epoch: 6/10, step 379/574 completed (loss: 1.6157866716384888, acc: 0.5808383226394653)
[2024-11-29 03:43:15,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:16,237][root][INFO] - Training Epoch: 6/10, step 380/574 completed (loss: 1.377375841140747, acc: 0.646616518497467)
[2024-11-29 03:43:16,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:16,857][root][INFO] - Training Epoch: 6/10, step 381/574 completed (loss: 1.5954337120056152, acc: 0.5454545617103577)
[2024-11-29 03:43:16,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:17,472][root][INFO] - Training Epoch: 6/10, step 382/574 completed (loss: 1.0268570184707642, acc: 0.7477477192878723)
[2024-11-29 03:43:17,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:18,058][root][INFO] - Training Epoch: 6/10, step 383/574 completed (loss: 0.07316870242357254, acc: 1.0)
[2024-11-29 03:43:18,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:18,647][root][INFO] - Training Epoch: 6/10, step 384/574 completed (loss: 0.02321179211139679, acc: 1.0)
[2024-11-29 03:43:18,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:19,234][root][INFO] - Training Epoch: 6/10, step 385/574 completed (loss: 0.3744776248931885, acc: 0.84375)
[2024-11-29 03:43:19,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:19,820][root][INFO] - Training Epoch: 6/10, step 386/574 completed (loss: 0.1448250561952591, acc: 0.9722222089767456)
[2024-11-29 03:43:19,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:20,411][root][INFO] - Training Epoch: 6/10, step 387/574 completed (loss: 0.07945317029953003, acc: 0.9736841917037964)
[2024-11-29 03:43:20,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:20,998][root][INFO] - Training Epoch: 6/10, step 388/574 completed (loss: 0.018428796902298927, acc: 1.0)
[2024-11-29 03:43:21,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:21,583][root][INFO] - Training Epoch: 6/10, step 389/574 completed (loss: 0.013516870327293873, acc: 1.0)
[2024-11-29 03:43:21,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:22,169][root][INFO] - Training Epoch: 6/10, step 390/574 completed (loss: 0.09061277657747269, acc: 0.9523809552192688)
[2024-11-29 03:43:22,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:22,759][root][INFO] - Training Epoch: 6/10, step 391/574 completed (loss: 1.075823187828064, acc: 0.7037037014961243)
[2024-11-29 03:43:22,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:23,355][root][INFO] - Training Epoch: 6/10, step 392/574 completed (loss: 1.8178797960281372, acc: 0.5048543810844421)
[2024-11-29 03:43:23,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:23,970][root][INFO] - Training Epoch: 6/10, step 393/574 completed (loss: 1.6513606309890747, acc: 0.5808823704719543)
[2024-11-29 03:43:24,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:24,572][root][INFO] - Training Epoch: 6/10, step 394/574 completed (loss: 2.1001641750335693, acc: 0.46000000834465027)
[2024-11-29 03:43:24,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:25,171][root][INFO] - Training Epoch: 6/10, step 395/574 completed (loss: 1.7727313041687012, acc: 0.5416666865348816)
[2024-11-29 03:43:25,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:25,760][root][INFO] - Training Epoch: 6/10, step 396/574 completed (loss: 0.885370671749115, acc: 0.7906976938247681)
[2024-11-29 03:43:25,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:26,347][root][INFO] - Training Epoch: 6/10, step 397/574 completed (loss: 0.07496892660856247, acc: 1.0)
[2024-11-29 03:43:26,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:26,940][root][INFO] - Training Epoch: 6/10, step 398/574 completed (loss: 0.8820877075195312, acc: 0.7674418687820435)
[2024-11-29 03:43:27,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:27,526][root][INFO] - Training Epoch: 6/10, step 399/574 completed (loss: 0.15827330946922302, acc: 0.9200000166893005)
[2024-11-29 03:43:27,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:28,121][root][INFO] - Training Epoch: 6/10, step 400/574 completed (loss: 1.1890469789505005, acc: 0.6764705777168274)
[2024-11-29 03:43:28,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:28,715][root][INFO] - Training Epoch: 6/10, step 401/574 completed (loss: 1.0943489074707031, acc: 0.6800000071525574)
[2024-11-29 03:43:28,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:29,304][root][INFO] - Training Epoch: 6/10, step 402/574 completed (loss: 0.5122995972633362, acc: 0.8181818127632141)
[2024-11-29 03:43:29,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:29,890][root][INFO] - Training Epoch: 6/10, step 403/574 completed (loss: 0.19962312281131744, acc: 0.9696969985961914)
[2024-11-29 03:43:29,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:30,479][root][INFO] - Training Epoch: 6/10, step 404/574 completed (loss: 0.05421138182282448, acc: 1.0)
[2024-11-29 03:43:30,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:31,067][root][INFO] - Training Epoch: 6/10, step 405/574 completed (loss: 0.03602309897542, acc: 1.0)
[2024-11-29 03:43:31,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:31,651][root][INFO] - Training Epoch: 6/10, step 406/574 completed (loss: 0.09566274285316467, acc: 0.9599999785423279)
[2024-11-29 03:43:31,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:32,238][root][INFO] - Training Epoch: 6/10, step 407/574 completed (loss: 0.070111945271492, acc: 1.0)
[2024-11-29 03:43:32,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:32,829][root][INFO] - Training Epoch: 6/10, step 408/574 completed (loss: 0.23206737637519836, acc: 0.9259259104728699)
[2024-11-29 03:43:32,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:33,416][root][INFO] - Training Epoch: 6/10, step 409/574 completed (loss: 0.04061182960867882, acc: 1.0)
[2024-11-29 03:43:33,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:34,006][root][INFO] - Training Epoch: 6/10, step 410/574 completed (loss: 0.4328221380710602, acc: 0.931034505367279)
[2024-11-29 03:43:34,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:34,594][root][INFO] - Training Epoch: 6/10, step 411/574 completed (loss: 0.09297381341457367, acc: 0.9642857313156128)
[2024-11-29 03:43:34,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:35,182][root][INFO] - Training Epoch: 6/10, step 412/574 completed (loss: 0.5291701555252075, acc: 0.8999999761581421)
[2024-11-29 03:43:35,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:35,768][root][INFO] - Training Epoch: 6/10, step 413/574 completed (loss: 0.288756400346756, acc: 0.9090909361839294)
[2024-11-29 03:43:35,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:36,355][root][INFO] - Training Epoch: 6/10, step 414/574 completed (loss: 0.056043002754449844, acc: 1.0)
[2024-11-29 03:43:36,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:36,947][root][INFO] - Training Epoch: 6/10, step 415/574 completed (loss: 1.2284467220306396, acc: 0.686274528503418)
[2024-11-29 03:43:37,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:37,536][root][INFO] - Training Epoch: 6/10, step 416/574 completed (loss: 0.5832556486129761, acc: 0.8461538553237915)
[2024-11-29 03:43:37,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:38,123][root][INFO] - Training Epoch: 6/10, step 417/574 completed (loss: 0.41548123955726624, acc: 0.8333333134651184)
[2024-11-29 03:43:38,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:38,714][root][INFO] - Training Epoch: 6/10, step 418/574 completed (loss: 0.7928688526153564, acc: 0.7749999761581421)
[2024-11-29 03:43:39,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:39,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:40,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:40,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:41,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:41,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:42,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:43,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:43,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:44,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:44,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:45,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:45,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:46,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:46,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:47,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:47,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:48,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:48,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:49,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:49,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:50,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:50,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:51,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:51,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:52,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:52,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:53,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:53,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:54,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:55,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:55,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:56,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:56,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:57,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:57,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:58,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:58,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:59,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:59,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:00,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:00,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:01,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:01,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:02,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:02,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:03,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:03,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:04,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:04,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:05,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:06,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:06,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:07,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:07,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:08,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:08,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:09,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:09,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:10,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:10,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:11,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:11,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:12,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:12,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:13,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:13,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:14,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:14,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:15,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:16,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:16,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:17,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:17,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:18,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:18,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:19,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:19,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:20,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:20,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:21,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:21,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:22,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:22,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:23,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:24,054][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(4.1871, device='cuda:0') eval_epoch_loss=tensor(1.4320, device='cuda:0') eval_epoch_acc=tensor(0.6484, device='cuda:0')
[2024-11-29 03:44:24,056][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:44:24,056][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:44:24,307][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_6_step_419_loss_1.4319969415664673/model.pt
[2024-11-29 03:44:24,311][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 6 is 1.4319969415664673
[2024-11-29 03:44:24,312][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 6 is 0.6484436988830566
[2024-11-29 03:44:24,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:24,914][root][INFO] - Training Epoch: 6/10, step 419/574 completed (loss: 0.27509602904319763, acc: 0.949999988079071)
[2024-11-29 03:44:24,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:25,500][root][INFO] - Training Epoch: 6/10, step 420/574 completed (loss: 0.12087284028530121, acc: 0.9523809552192688)
[2024-11-29 03:44:25,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:26,088][root][INFO] - Training Epoch: 6/10, step 421/574 completed (loss: 0.2815619707107544, acc: 0.9333333373069763)
[2024-11-29 03:44:26,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:26,677][root][INFO] - Training Epoch: 6/10, step 422/574 completed (loss: 0.3566931486129761, acc: 0.875)
[2024-11-29 03:44:26,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:27,264][root][INFO] - Training Epoch: 6/10, step 423/574 completed (loss: 1.0436148643493652, acc: 0.7222222089767456)
[2024-11-29 03:44:27,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:27,852][root][INFO] - Training Epoch: 6/10, step 424/574 completed (loss: 0.05124134197831154, acc: 1.0)
[2024-11-29 03:44:27,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:28,439][root][INFO] - Training Epoch: 6/10, step 425/574 completed (loss: 0.7426334619522095, acc: 0.8484848737716675)
[2024-11-29 03:44:28,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:29,027][root][INFO] - Training Epoch: 6/10, step 426/574 completed (loss: 0.06501341611146927, acc: 1.0)
[2024-11-29 03:44:29,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:29,616][root][INFO] - Training Epoch: 6/10, step 427/574 completed (loss: 0.37877264618873596, acc: 0.9189189076423645)
[2024-11-29 03:44:29,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:30,204][root][INFO] - Training Epoch: 6/10, step 428/574 completed (loss: 0.17516262829303741, acc: 0.9259259104728699)
[2024-11-29 03:44:30,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:30,790][root][INFO] - Training Epoch: 6/10, step 429/574 completed (loss: 0.41661643981933594, acc: 0.9130434989929199)
[2024-11-29 03:44:30,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:31,377][root][INFO] - Training Epoch: 6/10, step 430/574 completed (loss: 0.08117488026618958, acc: 0.9629629850387573)
[2024-11-29 03:44:31,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:31,963][root][INFO] - Training Epoch: 6/10, step 431/574 completed (loss: 0.023829149082303047, acc: 1.0)
[2024-11-29 03:44:32,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:32,550][root][INFO] - Training Epoch: 6/10, step 432/574 completed (loss: 0.07349691540002823, acc: 1.0)
[2024-11-29 03:44:32,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:33,137][root][INFO] - Training Epoch: 6/10, step 433/574 completed (loss: 0.5213191509246826, acc: 0.8611111044883728)
[2024-11-29 03:44:33,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:33,724][root][INFO] - Training Epoch: 6/10, step 434/574 completed (loss: 0.21754713356494904, acc: 0.9599999785423279)
[2024-11-29 03:44:33,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:34,313][root][INFO] - Training Epoch: 6/10, step 435/574 completed (loss: 0.26538750529289246, acc: 0.939393937587738)
[2024-11-29 03:44:34,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:34,902][root][INFO] - Training Epoch: 6/10, step 436/574 completed (loss: 0.9193634390830994, acc: 0.75)
[2024-11-29 03:44:34,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:35,493][root][INFO] - Training Epoch: 6/10, step 437/574 completed (loss: 0.46269723773002625, acc: 0.8863636255264282)
[2024-11-29 03:44:35,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:36,079][root][INFO] - Training Epoch: 6/10, step 438/574 completed (loss: 0.04059688001871109, acc: 1.0)
[2024-11-29 03:44:36,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:36,667][root][INFO] - Training Epoch: 6/10, step 439/574 completed (loss: 0.9376799464225769, acc: 0.7179487347602844)
[2024-11-29 03:44:36,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:37,261][root][INFO] - Training Epoch: 6/10, step 440/574 completed (loss: 1.0565680265426636, acc: 0.6818181872367859)
[2024-11-29 03:44:37,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:37,873][root][INFO] - Training Epoch: 6/10, step 441/574 completed (loss: 2.3676600456237793, acc: 0.4000000059604645)
[2024-11-29 03:44:37,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:38,470][root][INFO] - Training Epoch: 6/10, step 442/574 completed (loss: 1.8139560222625732, acc: 0.5)
[2024-11-29 03:44:38,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:39,082][root][INFO] - Training Epoch: 6/10, step 443/574 completed (loss: 2.098766565322876, acc: 0.42288556694984436)
[2024-11-29 03:44:39,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:39,675][root][INFO] - Training Epoch: 6/10, step 444/574 completed (loss: 0.9578999876976013, acc: 0.7358490824699402)
[2024-11-29 03:44:39,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:40,265][root][INFO] - Training Epoch: 6/10, step 445/574 completed (loss: 0.7312142848968506, acc: 0.8409090638160706)
[2024-11-29 03:44:40,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:40,853][root][INFO] - Training Epoch: 6/10, step 446/574 completed (loss: 0.0635191947221756, acc: 1.0)
[2024-11-29 03:44:40,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:41,441][root][INFO] - Training Epoch: 6/10, step 447/574 completed (loss: 0.27361026406288147, acc: 0.8846153616905212)
[2024-11-29 03:44:41,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:42,028][root][INFO] - Training Epoch: 6/10, step 448/574 completed (loss: 0.2951194941997528, acc: 0.9285714030265808)
[2024-11-29 03:44:42,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:42,618][root][INFO] - Training Epoch: 6/10, step 449/574 completed (loss: 1.0985450744628906, acc: 0.6716417670249939)
[2024-11-29 03:44:42,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:43,210][root][INFO] - Training Epoch: 6/10, step 450/574 completed (loss: 0.9300439357757568, acc: 0.7361111044883728)
[2024-11-29 03:44:43,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:43,802][root][INFO] - Training Epoch: 6/10, step 451/574 completed (loss: 1.2937312126159668, acc: 0.6086956262588501)
[2024-11-29 03:44:43,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:44,393][root][INFO] - Training Epoch: 6/10, step 452/574 completed (loss: 1.0215257406234741, acc: 0.6794871687889099)
[2024-11-29 03:44:44,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:44,986][root][INFO] - Training Epoch: 6/10, step 453/574 completed (loss: 1.1446839570999146, acc: 0.6973684430122375)
[2024-11-29 03:44:45,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:45,574][root][INFO] - Training Epoch: 6/10, step 454/574 completed (loss: 0.5284541249275208, acc: 0.8775510191917419)
[2024-11-29 03:44:45,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:46,163][root][INFO] - Training Epoch: 6/10, step 455/574 completed (loss: 0.17789992690086365, acc: 0.939393937587738)
[2024-11-29 03:44:46,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:46,758][root][INFO] - Training Epoch: 6/10, step 456/574 completed (loss: 1.5236707925796509, acc: 0.5979381203651428)
[2024-11-29 03:44:46,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:47,348][root][INFO] - Training Epoch: 6/10, step 457/574 completed (loss: 0.8470123410224915, acc: 0.7285714149475098)
[2024-11-29 03:44:47,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:47,967][root][INFO] - Training Epoch: 6/10, step 458/574 completed (loss: 2.055340528488159, acc: 0.47093021869659424)
[2024-11-29 03:44:48,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:48,555][root][INFO] - Training Epoch: 6/10, step 459/574 completed (loss: 0.7091301679611206, acc: 0.8571428656578064)
[2024-11-29 03:44:48,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:49,152][root][INFO] - Training Epoch: 6/10, step 460/574 completed (loss: 1.1681020259857178, acc: 0.6666666865348816)
[2024-11-29 03:44:49,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:49,740][root][INFO] - Training Epoch: 6/10, step 461/574 completed (loss: 0.5364560484886169, acc: 0.8055555820465088)
[2024-11-29 03:44:49,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:50,328][root][INFO] - Training Epoch: 6/10, step 462/574 completed (loss: 0.16513049602508545, acc: 0.96875)
[2024-11-29 03:44:50,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:50,914][root][INFO] - Training Epoch: 6/10, step 463/574 completed (loss: 0.1620183289051056, acc: 0.9615384340286255)
[2024-11-29 03:44:50,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:51,506][root][INFO] - Training Epoch: 6/10, step 464/574 completed (loss: 0.6148597598075867, acc: 0.8260869383811951)
[2024-11-29 03:44:51,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:52,098][root][INFO] - Training Epoch: 6/10, step 465/574 completed (loss: 0.9766916632652283, acc: 0.7142857313156128)
[2024-11-29 03:44:52,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:52,691][root][INFO] - Training Epoch: 6/10, step 466/574 completed (loss: 1.1821186542510986, acc: 0.7228915691375732)
[2024-11-29 03:44:52,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:53,302][root][INFO] - Training Epoch: 6/10, step 467/574 completed (loss: 1.4875422716140747, acc: 0.5945945978164673)
[2024-11-29 03:44:53,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:53,894][root][INFO] - Training Epoch: 6/10, step 468/574 completed (loss: 1.4326088428497314, acc: 0.5922330021858215)
[2024-11-29 03:44:53,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:54,506][root][INFO] - Training Epoch: 6/10, step 469/574 completed (loss: 1.6397041082382202, acc: 0.5609756112098694)
[2024-11-29 03:44:54,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:55,094][root][INFO] - Training Epoch: 6/10, step 470/574 completed (loss: 0.049156758934259415, acc: 1.0)
[2024-11-29 03:44:55,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:55,682][root][INFO] - Training Epoch: 6/10, step 471/574 completed (loss: 0.2683805525302887, acc: 0.8928571343421936)
[2024-11-29 03:44:55,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:56,294][root][INFO] - Training Epoch: 6/10, step 472/574 completed (loss: 1.65369713306427, acc: 0.45098039507865906)
[2024-11-29 03:44:56,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:56,909][root][INFO] - Training Epoch: 6/10, step 473/574 completed (loss: 2.0050761699676514, acc: 0.46724891662597656)
[2024-11-29 03:44:56,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:57,499][root][INFO] - Training Epoch: 6/10, step 474/574 completed (loss: 1.3722529411315918, acc: 0.6145833134651184)
[2024-11-29 03:44:57,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:58,096][root][INFO] - Training Epoch: 6/10, step 475/574 completed (loss: 1.6626105308532715, acc: 0.5276073813438416)
[2024-11-29 03:44:58,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:58,691][root][INFO] - Training Epoch: 6/10, step 476/574 completed (loss: 1.5181961059570312, acc: 0.5755395889282227)
[2024-11-29 03:44:58,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:59,301][root][INFO] - Training Epoch: 6/10, step 477/574 completed (loss: 1.9473363161087036, acc: 0.5226130485534668)
[2024-11-29 03:44:59,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:59,888][root][INFO] - Training Epoch: 6/10, step 478/574 completed (loss: 0.5083085298538208, acc: 0.8888888955116272)
[2024-11-29 03:44:59,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:00,475][root][INFO] - Training Epoch: 6/10, step 479/574 completed (loss: 0.37812352180480957, acc: 0.8787878751754761)
[2024-11-29 03:45:00,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:01,062][root][INFO] - Training Epoch: 6/10, step 480/574 completed (loss: 0.12080501765012741, acc: 0.9629629850387573)
[2024-11-29 03:45:01,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:01,646][root][INFO] - Training Epoch: 6/10, step 481/574 completed (loss: 0.15385480225086212, acc: 0.949999988079071)
[2024-11-29 03:45:01,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:02,232][root][INFO] - Training Epoch: 6/10, step 482/574 completed (loss: 0.0684022530913353, acc: 1.0)
[2024-11-29 03:45:02,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:02,829][root][INFO] - Training Epoch: 6/10, step 483/574 completed (loss: 1.0493483543395996, acc: 0.7931034564971924)
[2024-11-29 03:45:02,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:03,416][root][INFO] - Training Epoch: 6/10, step 484/574 completed (loss: 0.1231890469789505, acc: 0.9354838728904724)
[2024-11-29 03:45:03,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:04,003][root][INFO] - Training Epoch: 6/10, step 485/574 completed (loss: 0.18857084214687347, acc: 0.8947368264198303)
[2024-11-29 03:45:04,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:04,589][root][INFO] - Training Epoch: 6/10, step 486/574 completed (loss: 0.5292301774024963, acc: 0.8888888955116272)
[2024-11-29 03:45:04,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:05,174][root][INFO] - Training Epoch: 6/10, step 487/574 completed (loss: 0.19842694699764252, acc: 0.9047619104385376)
[2024-11-29 03:45:05,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:05,760][root][INFO] - Training Epoch: 6/10, step 488/574 completed (loss: 0.12646721303462982, acc: 0.9545454382896423)
[2024-11-29 03:45:05,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:06,353][root][INFO] - Training Epoch: 6/10, step 489/574 completed (loss: 1.1821156740188599, acc: 0.6153846383094788)
[2024-11-29 03:45:06,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:06,940][root][INFO] - Training Epoch: 6/10, step 490/574 completed (loss: 0.1450778692960739, acc: 0.9333333373069763)
[2024-11-29 03:45:07,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:07,526][root][INFO] - Training Epoch: 6/10, step 491/574 completed (loss: 0.34162360429763794, acc: 0.8965517282485962)
[2024-11-29 03:45:07,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:08,118][root][INFO] - Training Epoch: 6/10, step 492/574 completed (loss: 0.6074341535568237, acc: 0.8039215803146362)
[2024-11-29 03:45:08,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:08,709][root][INFO] - Training Epoch: 6/10, step 493/574 completed (loss: 0.2607380151748657, acc: 0.931034505367279)
[2024-11-29 03:45:08,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:09,296][root][INFO] - Training Epoch: 6/10, step 494/574 completed (loss: 0.01365964487195015, acc: 1.0)
[2024-11-29 03:45:09,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:09,883][root][INFO] - Training Epoch: 6/10, step 495/574 completed (loss: 0.21388962864875793, acc: 1.0)
[2024-11-29 03:45:09,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:10,479][root][INFO] - Training Epoch: 6/10, step 496/574 completed (loss: 1.475932240486145, acc: 0.5892857313156128)
[2024-11-29 03:45:10,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:11,074][root][INFO] - Training Epoch: 6/10, step 497/574 completed (loss: 1.2504854202270508, acc: 0.7078651785850525)
[2024-11-29 03:45:11,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:11,670][root][INFO] - Training Epoch: 6/10, step 498/574 completed (loss: 1.386606216430664, acc: 0.6404494643211365)
[2024-11-29 03:45:11,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:12,279][root][INFO] - Training Epoch: 6/10, step 499/574 completed (loss: 1.935091495513916, acc: 0.5177304744720459)
[2024-11-29 03:45:12,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:12,878][root][INFO] - Training Epoch: 6/10, step 500/574 completed (loss: 1.5436054468154907, acc: 0.554347813129425)
[2024-11-29 03:45:12,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:13,464][root][INFO] - Training Epoch: 6/10, step 501/574 completed (loss: 0.08930862694978714, acc: 0.9599999785423279)
[2024-11-29 03:45:13,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:14,057][root][INFO] - Training Epoch: 6/10, step 502/574 completed (loss: 0.006050494033843279, acc: 1.0)
[2024-11-29 03:45:14,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:14,642][root][INFO] - Training Epoch: 6/10, step 503/574 completed (loss: 0.021572349593043327, acc: 1.0)
[2024-11-29 03:45:14,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:15,231][root][INFO] - Training Epoch: 6/10, step 504/574 completed (loss: 0.1044723317027092, acc: 0.9629629850387573)
[2024-11-29 03:45:15,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:15,819][root][INFO] - Training Epoch: 6/10, step 505/574 completed (loss: 0.3825111985206604, acc: 0.8867924809455872)
[2024-11-29 03:45:15,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:16,407][root][INFO] - Training Epoch: 6/10, step 506/574 completed (loss: 0.19669196009635925, acc: 0.931034505367279)
[2024-11-29 03:45:16,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:17,002][root][INFO] - Training Epoch: 6/10, step 507/574 completed (loss: 1.3276137113571167, acc: 0.6486486196517944)
[2024-11-29 03:45:17,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:17,598][root][INFO] - Training Epoch: 6/10, step 508/574 completed (loss: 0.7723668813705444, acc: 0.7605633735656738)
[2024-11-29 03:45:17,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:18,185][root][INFO] - Training Epoch: 6/10, step 509/574 completed (loss: 0.007261960301548243, acc: 1.0)
[2024-11-29 03:45:18,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:18,773][root][INFO] - Training Epoch: 6/10, step 510/574 completed (loss: 0.024212481454014778, acc: 1.0)
[2024-11-29 03:45:18,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:19,359][root][INFO] - Training Epoch: 6/10, step 511/574 completed (loss: 0.10582328587770462, acc: 0.9615384340286255)
[2024-11-29 03:45:19,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:19,993][root][INFO] - Training Epoch: 6/10, step 512/574 completed (loss: 2.2332303524017334, acc: 0.4714285731315613)
[2024-11-29 03:45:20,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:20,604][root][INFO] - Training Epoch: 6/10, step 513/574 completed (loss: 1.4990205764770508, acc: 0.6190476417541504)
[2024-11-29 03:45:20,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:21,189][root][INFO] - Training Epoch: 6/10, step 514/574 completed (loss: 0.4758662283420563, acc: 0.8214285969734192)
[2024-11-29 03:45:21,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:21,782][root][INFO] - Training Epoch: 6/10, step 515/574 completed (loss: 0.5767531991004944, acc: 0.8666666746139526)
[2024-11-29 03:45:21,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:22,379][root][INFO] - Training Epoch: 6/10, step 516/574 completed (loss: 1.2034380435943604, acc: 0.6805555820465088)
[2024-11-29 03:45:22,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:22,963][root][INFO] - Training Epoch: 6/10, step 517/574 completed (loss: 0.007966911420226097, acc: 1.0)
[2024-11-29 03:45:23,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:23,551][root][INFO] - Training Epoch: 6/10, step 518/574 completed (loss: 0.20383092761039734, acc: 0.9032257795333862)
[2024-11-29 03:45:23,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:24,130][root][INFO] - Training Epoch: 6/10, step 519/574 completed (loss: 0.2978969216346741, acc: 0.949999988079071)
[2024-11-29 03:45:24,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:24,717][root][INFO] - Training Epoch: 6/10, step 520/574 completed (loss: 0.29246440529823303, acc: 0.9259259104728699)
[2024-11-29 03:45:24,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:25,513][root][INFO] - Training Epoch: 6/10, step 521/574 completed (loss: 2.223754644393921, acc: 0.402542382478714)
[2024-11-29 03:45:25,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:26,133][root][INFO] - Training Epoch: 6/10, step 522/574 completed (loss: 1.4174498319625854, acc: 0.6194030046463013)
[2024-11-29 03:45:26,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:26,727][root][INFO] - Training Epoch: 6/10, step 523/574 completed (loss: 1.6205896139144897, acc: 0.5766423344612122)
[2024-11-29 03:45:26,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:27,350][root][INFO] - Training Epoch: 6/10, step 524/574 completed (loss: 1.8053218126296997, acc: 0.5049999952316284)
[2024-11-29 03:45:27,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:27,941][root][INFO] - Training Epoch: 6/10, step 525/574 completed (loss: 0.6634555459022522, acc: 0.8333333134651184)
[2024-11-29 03:45:28,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:28,531][root][INFO] - Training Epoch: 6/10, step 526/574 completed (loss: 0.8089331984519958, acc: 0.75)
[2024-11-29 03:45:28,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:29,116][root][INFO] - Training Epoch: 6/10, step 527/574 completed (loss: 0.12924028933048248, acc: 0.9523809552192688)
[2024-11-29 03:45:29,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:29,711][root][INFO] - Training Epoch: 6/10, step 528/574 completed (loss: 1.6761420965194702, acc: 0.44262295961380005)
[2024-11-29 03:45:29,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:30,299][root][INFO] - Training Epoch: 6/10, step 529/574 completed (loss: 0.9150323271751404, acc: 0.694915235042572)
[2024-11-29 03:45:30,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:30,888][root][INFO] - Training Epoch: 6/10, step 530/574 completed (loss: 0.5293181538581848, acc: 0.8604651093482971)
[2024-11-29 03:45:30,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:31,475][root][INFO] - Training Epoch: 6/10, step 531/574 completed (loss: 0.736948549747467, acc: 0.8181818127632141)
[2024-11-29 03:45:31,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:32,067][root][INFO] - Training Epoch: 6/10, step 532/574 completed (loss: 0.9487229585647583, acc: 0.698113203048706)
[2024-11-29 03:45:32,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:32,655][root][INFO] - Training Epoch: 6/10, step 533/574 completed (loss: 0.5600395202636719, acc: 0.8863636255264282)
[2024-11-29 03:45:32,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:33,241][root][INFO] - Training Epoch: 6/10, step 534/574 completed (loss: 0.14174231886863708, acc: 0.9599999785423279)
[2024-11-29 03:45:33,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:33,826][root][INFO] - Training Epoch: 6/10, step 535/574 completed (loss: 0.1680137813091278, acc: 0.8999999761581421)
[2024-11-29 03:45:33,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:34,411][root][INFO] - Training Epoch: 6/10, step 536/574 completed (loss: 0.1680944859981537, acc: 0.9545454382896423)
[2024-11-29 03:45:34,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:35,002][root][INFO] - Training Epoch: 6/10, step 537/574 completed (loss: 0.8135501146316528, acc: 0.7384615540504456)
[2024-11-29 03:45:35,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:35,593][root][INFO] - Training Epoch: 6/10, step 538/574 completed (loss: 0.9193652272224426, acc: 0.71875)
[2024-11-29 03:45:35,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:36,180][root][INFO] - Training Epoch: 6/10, step 539/574 completed (loss: 0.3470596969127655, acc: 0.875)
[2024-11-29 03:45:36,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:36,768][root][INFO] - Training Epoch: 6/10, step 540/574 completed (loss: 0.25357016921043396, acc: 0.939393937587738)
[2024-11-29 03:45:36,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:37,352][root][INFO] - Training Epoch: 6/10, step 541/574 completed (loss: 0.02353578992187977, acc: 1.0)
[2024-11-29 03:45:37,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:37,938][root][INFO] - Training Epoch: 6/10, step 542/574 completed (loss: 0.18370628356933594, acc: 0.9354838728904724)
[2024-11-29 03:45:38,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:38,522][root][INFO] - Training Epoch: 6/10, step 543/574 completed (loss: 0.026917574927210808, acc: 1.0)
[2024-11-29 03:45:38,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:39,108][root][INFO] - Training Epoch: 6/10, step 544/574 completed (loss: 0.7193949222564697, acc: 0.8333333134651184)
[2024-11-29 03:45:39,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:39,695][root][INFO] - Training Epoch: 6/10, step 545/574 completed (loss: 0.3672686815261841, acc: 0.8780487775802612)
[2024-11-29 03:45:39,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:40,284][root][INFO] - Training Epoch: 6/10, step 546/574 completed (loss: 0.2738901674747467, acc: 0.8857142925262451)
[2024-11-29 03:45:40,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:40,870][root][INFO] - Training Epoch: 6/10, step 547/574 completed (loss: 0.4799956679344177, acc: 0.8421052694320679)
[2024-11-29 03:45:40,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:41,457][root][INFO] - Training Epoch: 6/10, step 548/574 completed (loss: 0.2620316445827484, acc: 0.9354838728904724)
[2024-11-29 03:45:41,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:42,041][root][INFO] - Training Epoch: 6/10, step 549/574 completed (loss: 0.022018378600478172, acc: 1.0)
[2024-11-29 03:45:42,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:42,631][root][INFO] - Training Epoch: 6/10, step 550/574 completed (loss: 0.31742849946022034, acc: 0.9090909361839294)
[2024-11-29 03:45:42,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:43,217][root][INFO] - Training Epoch: 6/10, step 551/574 completed (loss: 0.3810431659221649, acc: 0.8999999761581421)
[2024-11-29 03:45:43,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:43,809][root][INFO] - Training Epoch: 6/10, step 552/574 completed (loss: 0.7244276404380798, acc: 0.7714285850524902)
[2024-11-29 03:45:43,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:44,417][root][INFO] - Training Epoch: 6/10, step 553/574 completed (loss: 1.7610617876052856, acc: 0.5182482004165649)
[2024-11-29 03:45:44,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:45,026][root][INFO] - Training Epoch: 6/10, step 554/574 completed (loss: 1.2285197973251343, acc: 0.6482758522033691)
[2024-11-29 03:45:45,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:45,624][root][INFO] - Training Epoch: 6/10, step 555/574 completed (loss: 1.890323281288147, acc: 0.47857141494750977)
[2024-11-29 03:45:45,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:46,219][root][INFO] - Training Epoch: 6/10, step 556/574 completed (loss: 1.7847604751586914, acc: 0.49668875336647034)
[2024-11-29 03:45:46,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:46,812][root][INFO] - Training Epoch: 6/10, step 557/574 completed (loss: 1.148131012916565, acc: 0.7179487347602844)
[2024-11-29 03:45:46,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:47,397][root][INFO] - Training Epoch: 6/10, step 558/574 completed (loss: 0.0441584587097168, acc: 1.0)
[2024-11-29 03:45:47,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:47,983][root][INFO] - Training Epoch: 6/10, step 559/574 completed (loss: 0.13867498934268951, acc: 0.9615384340286255)
[2024-11-29 03:45:48,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:48,567][root][INFO] - Training Epoch: 6/10, step 560/574 completed (loss: 0.2152811586856842, acc: 0.9230769276618958)
[2024-11-29 03:45:48,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:49,157][root][INFO] - Training Epoch: 6/10, step 561/574 completed (loss: 0.610646665096283, acc: 0.8717948794364929)
[2024-11-29 03:45:49,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:50,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:50,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:51,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:51,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:52,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:52,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:53,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:54,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:54,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:55,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:55,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:56,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:56,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:57,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:57,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:58,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:58,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:59,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:59,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:00,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:00,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:01,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:01,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:02,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:02,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:03,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:04,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:04,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:05,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:05,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:06,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:06,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:07,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:07,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:08,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:08,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:09,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:09,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:10,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:10,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:11,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:11,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:12,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:13,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:13,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:14,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:14,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:15,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:15,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:16,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:16,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:17,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:17,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:18,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:18,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:19,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:19,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:20,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:20,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:21,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:21,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:22,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:23,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:23,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:24,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:24,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:25,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:25,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:26,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:26,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:27,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:27,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:28,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:28,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:29,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:29,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:30,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:30,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:31,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:32,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:32,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:33,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:33,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:34,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:34,885][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(4.0279, device='cuda:0') eval_epoch_loss=tensor(1.3932, device='cuda:0') eval_epoch_acc=tensor(0.6584, device='cuda:0')
[2024-11-29 03:46:34,886][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:46:34,887][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:46:35,092][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_6_step_562_loss_1.3932451009750366/model.pt
[2024-11-29 03:46:35,095][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 6 is 1.3932451009750366
[2024-11-29 03:46:35,095][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 6 is 0.6584479808807373
[2024-11-29 03:46:35,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:35,720][root][INFO] - Training Epoch: 6/10, step 562/574 completed (loss: 1.1731411218643188, acc: 0.7333333492279053)
[2024-11-29 03:46:35,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:36,311][root][INFO] - Training Epoch: 6/10, step 563/574 completed (loss: 0.8878051042556763, acc: 0.7402597665786743)
[2024-11-29 03:46:36,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:36,898][root][INFO] - Training Epoch: 6/10, step 564/574 completed (loss: 0.45093926787376404, acc: 0.875)
[2024-11-29 03:46:36,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:37,486][root][INFO] - Training Epoch: 6/10, step 565/574 completed (loss: 0.3392104208469391, acc: 0.8965517282485962)
[2024-11-29 03:46:37,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:38,080][root][INFO] - Training Epoch: 6/10, step 566/574 completed (loss: 1.074399709701538, acc: 0.726190447807312)
[2024-11-29 03:46:38,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:38,666][root][INFO] - Training Epoch: 6/10, step 567/574 completed (loss: 0.09741272777318954, acc: 0.9736841917037964)
[2024-11-29 03:46:38,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:39,251][root][INFO] - Training Epoch: 6/10, step 568/574 completed (loss: 0.25296875834465027, acc: 0.9629629850387573)
[2024-11-29 03:46:39,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:39,874][root][INFO] - Training Epoch: 6/10, step 569/574 completed (loss: 1.7436429262161255, acc: 0.529411792755127)
[2024-11-29 03:46:39,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:40,467][root][INFO] - Training Epoch: 6/10, step 570/574 completed (loss: 0.5224975943565369, acc: 0.8709677457809448)
[2024-11-29 03:46:40,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:41,063][root][INFO] - Training Epoch: 6/10, step 571/574 completed (loss: 1.4583754539489746, acc: 0.632478654384613)
[2024-11-29 03:46:41,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:41,674][root][INFO] - Training Epoch: 6/10, step 572/574 completed (loss: 2.0722784996032715, acc: 0.43877550959587097)
[2024-11-29 03:46:41,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:42,286][root][INFO] - Training Epoch: 6/10, step 573/574 completed (loss: 1.818321704864502, acc: 0.5345911979675293)
[2024-11-29 03:46:42,579][slam_llm.utils.train_utils][INFO] - Epoch 6: train_perplexity=2.3877, train_epoch_loss=0.8703, epoch time 525.9093442335725s
[2024-11-29 03:46:42,579][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 15 GB
[2024-11-29 03:46:42,579][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-29 03:46:42,579][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 15 GB
[2024-11-29 03:46:42,579][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 6
[2024-11-29 03:46:42,579][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-29 03:46:43,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:43,582][root][INFO] - Training Epoch: 7/10, step 0/574 completed (loss: 0.5005506873130798, acc: 0.8518518805503845)
[2024-11-29 03:46:43,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:44,173][root][INFO] - Training Epoch: 7/10, step 1/574 completed (loss: 0.22198909521102905, acc: 0.9200000166893005)
[2024-11-29 03:46:44,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:44,762][root][INFO] - Training Epoch: 7/10, step 2/574 completed (loss: 0.7526909112930298, acc: 0.837837815284729)
[2024-11-29 03:46:44,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:45,351][root][INFO] - Training Epoch: 7/10, step 3/574 completed (loss: 0.399788498878479, acc: 0.8947368264198303)
[2024-11-29 03:46:45,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:45,941][root][INFO] - Training Epoch: 7/10, step 4/574 completed (loss: 0.5322783589363098, acc: 0.8108108043670654)
[2024-11-29 03:46:46,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:46,529][root][INFO] - Training Epoch: 7/10, step 5/574 completed (loss: 0.29256096482276917, acc: 0.9285714030265808)
[2024-11-29 03:46:46,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:47,119][root][INFO] - Training Epoch: 7/10, step 6/574 completed (loss: 1.1917028427124023, acc: 0.6734693646430969)
[2024-11-29 03:46:47,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:47,707][root][INFO] - Training Epoch: 7/10, step 7/574 completed (loss: 0.2914552688598633, acc: 0.9333333373069763)
[2024-11-29 03:46:47,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:48,293][root][INFO] - Training Epoch: 7/10, step 8/574 completed (loss: 0.013744216412305832, acc: 1.0)
[2024-11-29 03:46:48,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:48,880][root][INFO] - Training Epoch: 7/10, step 9/574 completed (loss: 0.01415338460355997, acc: 1.0)
[2024-11-29 03:46:48,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:49,469][root][INFO] - Training Epoch: 7/10, step 10/574 completed (loss: 0.17034094035625458, acc: 0.9259259104728699)
[2024-11-29 03:46:49,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:50,057][root][INFO] - Training Epoch: 7/10, step 11/574 completed (loss: 0.7076095342636108, acc: 0.7948718070983887)
[2024-11-29 03:46:50,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:50,645][root][INFO] - Training Epoch: 7/10, step 12/574 completed (loss: 0.5669616460800171, acc: 0.8181818127632141)
[2024-11-29 03:46:50,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:51,233][root][INFO] - Training Epoch: 7/10, step 13/574 completed (loss: 0.38088271021842957, acc: 0.8913043737411499)
[2024-11-29 03:46:51,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:51,824][root][INFO] - Training Epoch: 7/10, step 14/574 completed (loss: 0.45151063799858093, acc: 0.8627451062202454)
[2024-11-29 03:46:51,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:52,418][root][INFO] - Training Epoch: 7/10, step 15/574 completed (loss: 0.8614434003829956, acc: 0.7346938848495483)
[2024-11-29 03:46:52,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:53,007][root][INFO] - Training Epoch: 7/10, step 16/574 completed (loss: 0.3407313823699951, acc: 0.8947368264198303)
[2024-11-29 03:46:53,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:53,594][root][INFO] - Training Epoch: 7/10, step 17/574 completed (loss: 0.16739195585250854, acc: 0.9583333134651184)
[2024-11-29 03:46:53,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:54,181][root][INFO] - Training Epoch: 7/10, step 18/574 completed (loss: 0.4633106589317322, acc: 0.8055555820465088)
[2024-11-29 03:46:54,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:54,767][root][INFO] - Training Epoch: 7/10, step 19/574 completed (loss: 0.008394247852265835, acc: 1.0)
[2024-11-29 03:46:54,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:55,355][root][INFO] - Training Epoch: 7/10, step 20/574 completed (loss: 0.09035707265138626, acc: 1.0)
[2024-11-29 03:46:55,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:55,942][root][INFO] - Training Epoch: 7/10, step 21/574 completed (loss: 0.14988262951374054, acc: 0.9655172228813171)
[2024-11-29 03:46:56,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:56,528][root][INFO] - Training Epoch: 7/10, step 22/574 completed (loss: 0.15924303233623505, acc: 0.9599999785423279)
[2024-11-29 03:46:56,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:57,114][root][INFO] - Training Epoch: 7/10, step 23/574 completed (loss: 0.12181102484464645, acc: 0.9523809552192688)
[2024-11-29 03:46:57,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:57,702][root][INFO] - Training Epoch: 7/10, step 24/574 completed (loss: 0.1396424025297165, acc: 0.9375)
[2024-11-29 03:46:57,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:58,295][root][INFO] - Training Epoch: 7/10, step 25/574 completed (loss: 1.4496610164642334, acc: 0.6037735939025879)
[2024-11-29 03:46:58,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:58,888][root][INFO] - Training Epoch: 7/10, step 26/574 completed (loss: 1.542011022567749, acc: 0.6164383292198181)
[2024-11-29 03:46:58,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:59,564][root][INFO] - Training Epoch: 7/10, step 27/574 completed (loss: 2.5011017322540283, acc: 0.38339921832084656)
[2024-11-29 03:46:59,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:00,153][root][INFO] - Training Epoch: 7/10, step 28/574 completed (loss: 0.8196863532066345, acc: 0.7441860437393188)
[2024-11-29 03:47:00,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:00,748][root][INFO] - Training Epoch: 7/10, step 29/574 completed (loss: 1.016785979270935, acc: 0.7469879388809204)
[2024-11-29 03:47:00,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:01,350][root][INFO] - Training Epoch: 7/10, step 30/574 completed (loss: 1.3090624809265137, acc: 0.5679012537002563)
[2024-11-29 03:47:01,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:01,938][root][INFO] - Training Epoch: 7/10, step 31/574 completed (loss: 0.5640556216239929, acc: 0.8214285969734192)
[2024-11-29 03:47:02,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:02,524][root][INFO] - Training Epoch: 7/10, step 32/574 completed (loss: 0.3569943606853485, acc: 0.9629629850387573)
[2024-11-29 03:47:02,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:03,110][root][INFO] - Training Epoch: 7/10, step 33/574 completed (loss: 0.040648452937603, acc: 1.0)
[2024-11-29 03:47:03,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:03,707][root][INFO] - Training Epoch: 7/10, step 34/574 completed (loss: 1.4728951454162598, acc: 0.6554622054100037)
[2024-11-29 03:47:03,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:04,300][root][INFO] - Training Epoch: 7/10, step 35/574 completed (loss: 0.7251949906349182, acc: 0.8196721076965332)
[2024-11-29 03:47:04,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:04,896][root][INFO] - Training Epoch: 7/10, step 36/574 completed (loss: 1.170755386352539, acc: 0.6984127163887024)
[2024-11-29 03:47:04,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:05,485][root][INFO] - Training Epoch: 7/10, step 37/574 completed (loss: 1.2016628980636597, acc: 0.7288135886192322)
[2024-11-29 03:47:05,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:06,082][root][INFO] - Training Epoch: 7/10, step 38/574 completed (loss: 1.0706349611282349, acc: 0.7356321811676025)
[2024-11-29 03:47:06,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:06,670][root][INFO] - Training Epoch: 7/10, step 39/574 completed (loss: 0.1931447982788086, acc: 0.9047619104385376)
[2024-11-29 03:47:06,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:07,260][root][INFO] - Training Epoch: 7/10, step 40/574 completed (loss: 0.7034687399864197, acc: 0.8461538553237915)
[2024-11-29 03:47:07,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:07,856][root][INFO] - Training Epoch: 7/10, step 41/574 completed (loss: 1.6394805908203125, acc: 0.5945945978164673)
[2024-11-29 03:47:07,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:08,451][root][INFO] - Training Epoch: 7/10, step 42/574 completed (loss: 1.1325626373291016, acc: 0.6615384817123413)
[2024-11-29 03:47:08,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:09,044][root][INFO] - Training Epoch: 7/10, step 43/574 completed (loss: 1.3379757404327393, acc: 0.6767676472663879)
[2024-11-29 03:47:09,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:09,642][root][INFO] - Training Epoch: 7/10, step 44/574 completed (loss: 1.3676657676696777, acc: 0.6082473993301392)
[2024-11-29 03:47:09,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:10,241][root][INFO] - Training Epoch: 7/10, step 45/574 completed (loss: 1.8869619369506836, acc: 0.5)
[2024-11-29 03:47:10,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:10,828][root][INFO] - Training Epoch: 7/10, step 46/574 completed (loss: 0.06885058432817459, acc: 1.0)
[2024-11-29 03:47:10,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:11,415][root][INFO] - Training Epoch: 7/10, step 47/574 completed (loss: 0.0948675274848938, acc: 0.9629629850387573)
[2024-11-29 03:47:11,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:12,002][root][INFO] - Training Epoch: 7/10, step 48/574 completed (loss: 0.17836090922355652, acc: 0.9285714030265808)
[2024-11-29 03:47:12,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:12,591][root][INFO] - Training Epoch: 7/10, step 49/574 completed (loss: 0.26787272095680237, acc: 0.8888888955116272)
[2024-11-29 03:47:12,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:13,182][root][INFO] - Training Epoch: 7/10, step 50/574 completed (loss: 0.6382771134376526, acc: 0.8070175647735596)
[2024-11-29 03:47:13,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:13,778][root][INFO] - Training Epoch: 7/10, step 51/574 completed (loss: 1.1526020765304565, acc: 0.6984127163887024)
[2024-11-29 03:47:13,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:14,375][root][INFO] - Training Epoch: 7/10, step 52/574 completed (loss: 1.35971999168396, acc: 0.6197183132171631)
[2024-11-29 03:47:14,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:14,988][root][INFO] - Training Epoch: 7/10, step 53/574 completed (loss: 2.3200929164886475, acc: 0.4266666769981384)
[2024-11-29 03:47:15,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:15,575][root][INFO] - Training Epoch: 7/10, step 54/574 completed (loss: 0.32548707723617554, acc: 0.8648648858070374)
[2024-11-29 03:47:15,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:16,162][root][INFO] - Training Epoch: 7/10, step 55/574 completed (loss: 0.04111762344837189, acc: 1.0)
[2024-11-29 03:47:16,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:16,863][root][INFO] - Training Epoch: 7/10, step 56/574 completed (loss: 2.128453016281128, acc: 0.46416381001472473)
[2024-11-29 03:47:16,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:17,517][root][INFO] - Training Epoch: 7/10, step 57/574 completed (loss: 2.5104591846466064, acc: 0.40740740299224854)
[2024-11-29 03:47:17,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:18,132][root][INFO] - Training Epoch: 7/10, step 58/574 completed (loss: 1.7035491466522217, acc: 0.5568181872367859)
[2024-11-29 03:47:18,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:18,729][root][INFO] - Training Epoch: 7/10, step 59/574 completed (loss: 1.806155800819397, acc: 0.5588235259056091)
[2024-11-29 03:47:18,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:19,343][root][INFO] - Training Epoch: 7/10, step 60/574 completed (loss: 1.7580909729003906, acc: 0.5072463750839233)
[2024-11-29 03:47:19,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:19,953][root][INFO] - Training Epoch: 7/10, step 61/574 completed (loss: 1.3578999042510986, acc: 0.637499988079071)
[2024-11-29 03:47:20,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:20,540][root][INFO] - Training Epoch: 7/10, step 62/574 completed (loss: 0.395916223526001, acc: 0.8529411554336548)
[2024-11-29 03:47:20,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:21,130][root][INFO] - Training Epoch: 7/10, step 63/574 completed (loss: 0.5222141742706299, acc: 0.8611111044883728)
[2024-11-29 03:47:21,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:21,725][root][INFO] - Training Epoch: 7/10, step 64/574 completed (loss: 0.8403545022010803, acc: 0.796875)
[2024-11-29 03:47:21,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:22,315][root][INFO] - Training Epoch: 7/10, step 65/574 completed (loss: 0.21849875152111053, acc: 0.8965517282485962)
[2024-11-29 03:47:22,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:22,905][root][INFO] - Training Epoch: 7/10, step 66/574 completed (loss: 0.707844614982605, acc: 0.8214285969734192)
[2024-11-29 03:47:22,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:23,497][root][INFO] - Training Epoch: 7/10, step 67/574 completed (loss: 1.0180901288986206, acc: 0.7333333492279053)
[2024-11-29 03:47:23,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:24,085][root][INFO] - Training Epoch: 7/10, step 68/574 completed (loss: 0.046609193086624146, acc: 1.0)
[2024-11-29 03:47:24,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:24,673][root][INFO] - Training Epoch: 7/10, step 69/574 completed (loss: 0.8447378873825073, acc: 0.8055555820465088)
[2024-11-29 03:47:24,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:25,262][root][INFO] - Training Epoch: 7/10, step 70/574 completed (loss: 0.1469738632440567, acc: 0.9696969985961914)
[2024-11-29 03:47:25,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:25,872][root][INFO] - Training Epoch: 7/10, step 71/574 completed (loss: 1.8078832626342773, acc: 0.5514705777168274)
[2024-11-29 03:47:25,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:26,470][root][INFO] - Training Epoch: 7/10, step 72/574 completed (loss: 1.362799048423767, acc: 0.5634920597076416)
[2024-11-29 03:47:26,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:27,084][root][INFO] - Training Epoch: 7/10, step 73/574 completed (loss: 2.1348023414611816, acc: 0.4307692348957062)
[2024-11-29 03:47:27,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:27,677][root][INFO] - Training Epoch: 7/10, step 74/574 completed (loss: 1.484055757522583, acc: 0.6020408272743225)
[2024-11-29 03:47:27,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:28,273][root][INFO] - Training Epoch: 7/10, step 75/574 completed (loss: 1.7566828727722168, acc: 0.5149253606796265)
[2024-11-29 03:47:28,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:28,900][root][INFO] - Training Epoch: 7/10, step 76/574 completed (loss: 2.3300528526306152, acc: 0.4051094949245453)
[2024-11-29 03:47:28,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:29,484][root][INFO] - Training Epoch: 7/10, step 77/574 completed (loss: 0.022900385782122612, acc: 1.0)
[2024-11-29 03:47:29,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:30,070][root][INFO] - Training Epoch: 7/10, step 78/574 completed (loss: 0.01090915035456419, acc: 1.0)
[2024-11-29 03:47:30,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:30,658][root][INFO] - Training Epoch: 7/10, step 79/574 completed (loss: 0.18733933568000793, acc: 0.9696969985961914)
[2024-11-29 03:47:30,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:31,245][root][INFO] - Training Epoch: 7/10, step 80/574 completed (loss: 0.08786186575889587, acc: 0.9615384340286255)
[2024-11-29 03:47:31,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:31,841][root][INFO] - Training Epoch: 7/10, step 81/574 completed (loss: 0.863772988319397, acc: 0.75)
[2024-11-29 03:47:31,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:32,432][root][INFO] - Training Epoch: 7/10, step 82/574 completed (loss: 0.6605291962623596, acc: 0.7884615659713745)
[2024-11-29 03:47:32,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:33,021][root][INFO] - Training Epoch: 7/10, step 83/574 completed (loss: 0.5254974961280823, acc: 0.875)
[2024-11-29 03:47:33,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:33,613][root][INFO] - Training Epoch: 7/10, step 84/574 completed (loss: 0.6306495666503906, acc: 0.8260869383811951)
[2024-11-29 03:47:33,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:34,208][root][INFO] - Training Epoch: 7/10, step 85/574 completed (loss: 0.7581048011779785, acc: 0.7599999904632568)
[2024-11-29 03:47:34,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:34,796][root][INFO] - Training Epoch: 7/10, step 86/574 completed (loss: 0.09913520514965057, acc: 1.0)
[2024-11-29 03:47:34,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:35,390][root][INFO] - Training Epoch: 7/10, step 87/574 completed (loss: 0.9266489148139954, acc: 0.7200000286102295)
[2024-11-29 03:47:35,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:35,990][root][INFO] - Training Epoch: 7/10, step 88/574 completed (loss: 1.0864362716674805, acc: 0.6893203854560852)
[2024-11-29 03:47:36,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:36,604][root][INFO] - Training Epoch: 7/10, step 89/574 completed (loss: 1.591543197631836, acc: 0.5873786211013794)
[2024-11-29 03:47:36,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:37,217][root][INFO] - Training Epoch: 7/10, step 90/574 completed (loss: 1.8093892335891724, acc: 0.5161290168762207)
[2024-11-29 03:47:37,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:37,841][root][INFO] - Training Epoch: 7/10, step 91/574 completed (loss: 1.7963790893554688, acc: 0.5258620977401733)
[2024-11-29 03:47:37,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:38,436][root][INFO] - Training Epoch: 7/10, step 92/574 completed (loss: 1.3342293500900269, acc: 0.6105263233184814)
[2024-11-29 03:47:38,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:39,051][root][INFO] - Training Epoch: 7/10, step 93/574 completed (loss: 1.8673206567764282, acc: 0.4653465449810028)
[2024-11-29 03:47:39,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:39,642][root][INFO] - Training Epoch: 7/10, step 94/574 completed (loss: 1.047197937965393, acc: 0.7096773982048035)
[2024-11-29 03:47:39,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:40,237][root][INFO] - Training Epoch: 7/10, step 95/574 completed (loss: 0.824252724647522, acc: 0.7101449370384216)
[2024-11-29 03:47:40,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:40,834][root][INFO] - Training Epoch: 7/10, step 96/574 completed (loss: 1.5630780458450317, acc: 0.462184876203537)
[2024-11-29 03:47:40,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:41,432][root][INFO] - Training Epoch: 7/10, step 97/574 completed (loss: 1.4210158586502075, acc: 0.557692289352417)
[2024-11-29 03:47:41,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:42,031][root][INFO] - Training Epoch: 7/10, step 98/574 completed (loss: 1.9511041641235352, acc: 0.48175182938575745)
[2024-11-29 03:47:42,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:42,623][root][INFO] - Training Epoch: 7/10, step 99/574 completed (loss: 1.0694358348846436, acc: 0.7313432693481445)
[2024-11-29 03:47:42,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:43,211][root][INFO] - Training Epoch: 7/10, step 100/574 completed (loss: 0.038323432207107544, acc: 1.0)
[2024-11-29 03:47:43,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:43,797][root][INFO] - Training Epoch: 7/10, step 101/574 completed (loss: 0.009285475127398968, acc: 1.0)
[2024-11-29 03:47:43,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:44,384][root][INFO] - Training Epoch: 7/10, step 102/574 completed (loss: 0.048095569014549255, acc: 1.0)
[2024-11-29 03:47:44,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:44,973][root][INFO] - Training Epoch: 7/10, step 103/574 completed (loss: 0.2111697793006897, acc: 0.9090909361839294)
[2024-11-29 03:47:45,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:45,564][root][INFO] - Training Epoch: 7/10, step 104/574 completed (loss: 0.7220292091369629, acc: 0.7586206793785095)
[2024-11-29 03:47:45,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:46,153][root][INFO] - Training Epoch: 7/10, step 105/574 completed (loss: 0.20883910357952118, acc: 0.9069767594337463)
[2024-11-29 03:47:46,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:46,743][root][INFO] - Training Epoch: 7/10, step 106/574 completed (loss: 0.10534949600696564, acc: 1.0)
[2024-11-29 03:47:46,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:47,328][root][INFO] - Training Epoch: 7/10, step 107/574 completed (loss: 0.0073319547809660435, acc: 1.0)
[2024-11-29 03:47:47,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:47,916][root][INFO] - Training Epoch: 7/10, step 108/574 completed (loss: 0.014157076366245747, acc: 1.0)
[2024-11-29 03:47:47,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:48,506][root][INFO] - Training Epoch: 7/10, step 109/574 completed (loss: 0.45665088295936584, acc: 0.8571428656578064)
[2024-11-29 03:47:48,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:49,098][root][INFO] - Training Epoch: 7/10, step 110/574 completed (loss: 0.8598190546035767, acc: 0.7692307829856873)
[2024-11-29 03:47:49,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:49,691][root][INFO] - Training Epoch: 7/10, step 111/574 completed (loss: 0.8639358878135681, acc: 0.6666666865348816)
[2024-11-29 03:47:49,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:50,281][root][INFO] - Training Epoch: 7/10, step 112/574 completed (loss: 0.9754393696784973, acc: 0.7719298005104065)
[2024-11-29 03:47:50,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:50,870][root][INFO] - Training Epoch: 7/10, step 113/574 completed (loss: 0.517848551273346, acc: 0.8461538553237915)
[2024-11-29 03:47:50,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:51,461][root][INFO] - Training Epoch: 7/10, step 114/574 completed (loss: 0.4199235141277313, acc: 0.8775510191917419)
[2024-11-29 03:47:51,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:52,049][root][INFO] - Training Epoch: 7/10, step 115/574 completed (loss: 0.007529676426202059, acc: 1.0)
[2024-11-29 03:47:52,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:52,645][root][INFO] - Training Epoch: 7/10, step 116/574 completed (loss: 1.4102778434753418, acc: 0.6507936716079712)
[2024-11-29 03:47:52,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:53,240][root][INFO] - Training Epoch: 7/10, step 117/574 completed (loss: 1.3078056573867798, acc: 0.6178861856460571)
[2024-11-29 03:47:53,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:53,834][root][INFO] - Training Epoch: 7/10, step 118/574 completed (loss: 0.907616138458252, acc: 0.725806474685669)
[2024-11-29 03:47:53,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:54,478][root][INFO] - Training Epoch: 7/10, step 119/574 completed (loss: 2.0902035236358643, acc: 0.48288974165916443)
[2024-11-29 03:47:54,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:55,073][root][INFO] - Training Epoch: 7/10, step 120/574 completed (loss: 0.6670199036598206, acc: 0.8133333325386047)
[2024-11-29 03:47:55,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:55,668][root][INFO] - Training Epoch: 7/10, step 121/574 completed (loss: 0.9491676688194275, acc: 0.7307692170143127)
[2024-11-29 03:47:55,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:56,257][root][INFO] - Training Epoch: 7/10, step 122/574 completed (loss: 0.03668854758143425, acc: 1.0)
[2024-11-29 03:47:56,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:56,844][root][INFO] - Training Epoch: 7/10, step 123/574 completed (loss: 0.043275147676467896, acc: 1.0)
[2024-11-29 03:47:56,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:57,446][root][INFO] - Training Epoch: 7/10, step 124/574 completed (loss: 2.039280891418457, acc: 0.453987717628479)
[2024-11-29 03:47:57,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:58,059][root][INFO] - Training Epoch: 7/10, step 125/574 completed (loss: 1.7062572240829468, acc: 0.5486111044883728)
[2024-11-29 03:47:58,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:58,654][root][INFO] - Training Epoch: 7/10, step 126/574 completed (loss: 1.6867378950119019, acc: 0.5583333373069763)
[2024-11-29 03:47:58,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:59,279][root][INFO] - Training Epoch: 7/10, step 127/574 completed (loss: 1.963090419769287, acc: 0.4821428656578064)
[2024-11-29 03:47:59,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:59,891][root][INFO] - Training Epoch: 7/10, step 128/574 completed (loss: 1.8028709888458252, acc: 0.5128205418586731)
[2024-11-29 03:47:59,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:00,518][root][INFO] - Training Epoch: 7/10, step 129/574 completed (loss: 1.7276898622512817, acc: 0.529411792755127)
[2024-11-29 03:48:00,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:01,105][root][INFO] - Training Epoch: 7/10, step 130/574 completed (loss: 0.18844188749790192, acc: 0.9615384340286255)
[2024-11-29 03:48:01,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:02,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:02,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:03,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:03,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:04,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:04,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:05,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:05,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:06,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:07,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:07,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:08,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:08,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:09,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:09,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:10,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:10,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:11,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:11,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:12,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:12,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:13,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:13,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:14,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:14,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:15,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:16,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:16,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:17,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:17,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:18,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:18,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:19,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:19,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:20,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:20,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:21,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:21,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:22,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:22,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:23,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:23,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:24,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:25,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:25,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:26,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:26,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:27,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:27,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:28,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:28,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:29,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:29,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:30,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:30,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:31,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:31,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:32,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:32,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:33,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:33,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:34,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:35,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:35,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:36,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:36,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:37,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:37,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:38,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:38,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:39,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:39,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:40,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:40,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:41,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:41,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:42,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:42,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:43,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:43,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:44,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:45,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:45,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:46,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:46,921][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.5354, device='cuda:0') eval_epoch_loss=tensor(1.2628, device='cuda:0') eval_epoch_acc=tensor(0.6832, device='cuda:0')
[2024-11-29 03:48:46,922][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:48:46,922][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:48:47,201][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_7_step_131_loss_1.2628272771835327/model.pt
[2024-11-29 03:48:47,204][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 7 is 1.2628272771835327
[2024-11-29 03:48:47,205][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 7 is 0.6832391619682312
[2024-11-29 03:48:47,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:47,806][root][INFO] - Training Epoch: 7/10, step 131/574 completed (loss: 0.027069509029388428, acc: 1.0)
[2024-11-29 03:48:47,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:48,395][root][INFO] - Training Epoch: 7/10, step 132/574 completed (loss: 0.28670692443847656, acc: 0.9375)
[2024-11-29 03:48:48,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:48,986][root][INFO] - Training Epoch: 7/10, step 133/574 completed (loss: 0.23016920685768127, acc: 0.95652174949646)
[2024-11-29 03:48:49,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:49,576][root][INFO] - Training Epoch: 7/10, step 134/574 completed (loss: 0.3486911356449127, acc: 0.8571428656578064)
[2024-11-29 03:48:49,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:50,162][root][INFO] - Training Epoch: 7/10, step 135/574 completed (loss: 0.09702028334140778, acc: 1.0)
[2024-11-29 03:48:50,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:50,752][root][INFO] - Training Epoch: 7/10, step 136/574 completed (loss: 0.6252546906471252, acc: 0.8571428656578064)
[2024-11-29 03:48:50,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:51,339][root][INFO] - Training Epoch: 7/10, step 137/574 completed (loss: 0.16597066819667816, acc: 0.9666666388511658)
[2024-11-29 03:48:51,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:51,925][root][INFO] - Training Epoch: 7/10, step 138/574 completed (loss: 0.1940922737121582, acc: 0.95652174949646)
[2024-11-29 03:48:52,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:52,513][root][INFO] - Training Epoch: 7/10, step 139/574 completed (loss: 0.18904434144496918, acc: 0.9523809552192688)
[2024-11-29 03:48:52,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:53,102][root][INFO] - Training Epoch: 7/10, step 140/574 completed (loss: 0.13336385786533356, acc: 1.0)
[2024-11-29 03:48:53,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:53,689][root][INFO] - Training Epoch: 7/10, step 141/574 completed (loss: 0.4837774634361267, acc: 0.8387096524238586)
[2024-11-29 03:48:53,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:54,279][root][INFO] - Training Epoch: 7/10, step 142/574 completed (loss: 0.5212510228157043, acc: 0.837837815284729)
[2024-11-29 03:48:54,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:54,890][root][INFO] - Training Epoch: 7/10, step 143/574 completed (loss: 1.2731400728225708, acc: 0.6578947305679321)
[2024-11-29 03:48:54,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:55,486][root][INFO] - Training Epoch: 7/10, step 144/574 completed (loss: 1.2035537958145142, acc: 0.6194030046463013)
[2024-11-29 03:48:55,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:56,084][root][INFO] - Training Epoch: 7/10, step 145/574 completed (loss: 1.7276103496551514, acc: 0.5204081535339355)
[2024-11-29 03:48:56,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:56,691][root][INFO] - Training Epoch: 7/10, step 146/574 completed (loss: 1.3764280080795288, acc: 0.6702127456665039)
[2024-11-29 03:48:56,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:57,284][root][INFO] - Training Epoch: 7/10, step 147/574 completed (loss: 0.973102867603302, acc: 0.7571428418159485)
[2024-11-29 03:48:57,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:57,873][root][INFO] - Training Epoch: 7/10, step 148/574 completed (loss: 0.35068249702453613, acc: 0.8571428656578064)
[2024-11-29 03:48:57,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:58,459][root][INFO] - Training Epoch: 7/10, step 149/574 completed (loss: 0.38208314776420593, acc: 0.9130434989929199)
[2024-11-29 03:48:58,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:59,047][root][INFO] - Training Epoch: 7/10, step 150/574 completed (loss: 0.22378073632717133, acc: 0.9655172228813171)
[2024-11-29 03:48:59,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:59,636][root][INFO] - Training Epoch: 7/10, step 151/574 completed (loss: 0.6720356345176697, acc: 0.8478260636329651)
[2024-11-29 03:48:59,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:00,229][root][INFO] - Training Epoch: 7/10, step 152/574 completed (loss: 0.8334949016571045, acc: 0.7796609997749329)
[2024-11-29 03:49:00,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:00,822][root][INFO] - Training Epoch: 7/10, step 153/574 completed (loss: 0.7852513790130615, acc: 0.719298243522644)
[2024-11-29 03:49:00,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:01,414][root][INFO] - Training Epoch: 7/10, step 154/574 completed (loss: 0.9277878999710083, acc: 0.7432432174682617)
[2024-11-29 03:49:01,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:02,003][root][INFO] - Training Epoch: 7/10, step 155/574 completed (loss: 0.24497874081134796, acc: 0.8928571343421936)
[2024-11-29 03:49:02,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:02,594][root][INFO] - Training Epoch: 7/10, step 156/574 completed (loss: 0.2725285291671753, acc: 0.9130434989929199)
[2024-11-29 03:49:02,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:03,181][root][INFO] - Training Epoch: 7/10, step 157/574 completed (loss: 0.49191945791244507, acc: 0.8421052694320679)
[2024-11-29 03:49:03,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:03,773][root][INFO] - Training Epoch: 7/10, step 158/574 completed (loss: 0.9996984601020813, acc: 0.7297297120094299)
[2024-11-29 03:49:03,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:04,366][root][INFO] - Training Epoch: 7/10, step 159/574 completed (loss: 0.8551002144813538, acc: 0.6666666865348816)
[2024-11-29 03:49:04,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:04,958][root][INFO] - Training Epoch: 7/10, step 160/574 completed (loss: 1.2011127471923828, acc: 0.6162790656089783)
[2024-11-29 03:49:05,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:05,553][root][INFO] - Training Epoch: 7/10, step 161/574 completed (loss: 0.8206274509429932, acc: 0.7882353067398071)
[2024-11-29 03:49:05,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:06,149][root][INFO] - Training Epoch: 7/10, step 162/574 completed (loss: 1.5153073072433472, acc: 0.617977499961853)
[2024-11-29 03:49:06,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:06,740][root][INFO] - Training Epoch: 7/10, step 163/574 completed (loss: 0.4257792532444, acc: 0.9090909361839294)
[2024-11-29 03:49:06,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:07,331][root][INFO] - Training Epoch: 7/10, step 164/574 completed (loss: 0.09741927683353424, acc: 1.0)
[2024-11-29 03:49:07,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:07,922][root][INFO] - Training Epoch: 7/10, step 165/574 completed (loss: 0.22156588733196259, acc: 0.931034505367279)
[2024-11-29 03:49:08,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:08,517][root][INFO] - Training Epoch: 7/10, step 166/574 completed (loss: 0.4846448302268982, acc: 0.795918345451355)
[2024-11-29 03:49:08,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:09,108][root][INFO] - Training Epoch: 7/10, step 167/574 completed (loss: 0.4173612892627716, acc: 0.8799999952316284)
[2024-11-29 03:49:09,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:09,701][root][INFO] - Training Epoch: 7/10, step 168/574 completed (loss: 0.8808023929595947, acc: 0.7222222089767456)
[2024-11-29 03:49:09,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:10,298][root][INFO] - Training Epoch: 7/10, step 169/574 completed (loss: 1.585443139076233, acc: 0.6274510025978088)
[2024-11-29 03:49:10,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:10,918][root][INFO] - Training Epoch: 7/10, step 170/574 completed (loss: 2.1658236980438232, acc: 0.4726027250289917)
[2024-11-29 03:49:10,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:11,506][root][INFO] - Training Epoch: 7/10, step 171/574 completed (loss: 0.2791341543197632, acc: 0.9583333134651184)
[2024-11-29 03:49:11,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:12,094][root][INFO] - Training Epoch: 7/10, step 172/574 completed (loss: 0.30363088846206665, acc: 0.8888888955116272)
[2024-11-29 03:49:12,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:12,681][root][INFO] - Training Epoch: 7/10, step 173/574 completed (loss: 0.45865800976753235, acc: 0.8928571343421936)
[2024-11-29 03:49:12,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:13,292][root][INFO] - Training Epoch: 7/10, step 174/574 completed (loss: 1.4347950220108032, acc: 0.6725663542747498)
[2024-11-29 03:49:13,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:13,883][root][INFO] - Training Epoch: 7/10, step 175/574 completed (loss: 0.8547301888465881, acc: 0.7971014380455017)
[2024-11-29 03:49:13,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:14,478][root][INFO] - Training Epoch: 7/10, step 176/574 completed (loss: 1.2250465154647827, acc: 0.6818181872367859)
[2024-11-29 03:49:14,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:15,095][root][INFO] - Training Epoch: 7/10, step 177/574 completed (loss: 2.2988128662109375, acc: 0.39694657921791077)
[2024-11-29 03:49:15,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:15,707][root][INFO] - Training Epoch: 7/10, step 178/574 completed (loss: 2.249720573425293, acc: 0.4000000059604645)
[2024-11-29 03:49:15,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:16,298][root][INFO] - Training Epoch: 7/10, step 179/574 completed (loss: 0.7870131134986877, acc: 0.7868852615356445)
[2024-11-29 03:49:16,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:16,884][root][INFO] - Training Epoch: 7/10, step 180/574 completed (loss: 0.0589216910302639, acc: 0.9583333134651184)
[2024-11-29 03:49:16,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:17,470][root][INFO] - Training Epoch: 7/10, step 181/574 completed (loss: 0.15255004167556763, acc: 0.9599999785423279)
[2024-11-29 03:49:17,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:18,057][root][INFO] - Training Epoch: 7/10, step 182/574 completed (loss: 0.29162201285362244, acc: 0.8571428656578064)
[2024-11-29 03:49:18,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:18,652][root][INFO] - Training Epoch: 7/10, step 183/574 completed (loss: 1.2305502891540527, acc: 0.6585366129875183)
[2024-11-29 03:49:18,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:19,276][root][INFO] - Training Epoch: 7/10, step 184/574 completed (loss: 2.162776231765747, acc: 0.38368579745292664)
[2024-11-29 03:49:19,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:19,905][root][INFO] - Training Epoch: 7/10, step 185/574 completed (loss: 2.2787351608276367, acc: 0.38040345907211304)
[2024-11-29 03:49:19,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:20,532][root][INFO] - Training Epoch: 7/10, step 186/574 completed (loss: 2.335613965988159, acc: 0.40625)
[2024-11-29 03:49:20,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:21,194][root][INFO] - Training Epoch: 7/10, step 187/574 completed (loss: 2.4898500442504883, acc: 0.34896811842918396)
[2024-11-29 03:49:21,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:21,830][root][INFO] - Training Epoch: 7/10, step 188/574 completed (loss: 2.022928237915039, acc: 0.4555160105228424)
[2024-11-29 03:49:21,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:22,418][root][INFO] - Training Epoch: 7/10, step 189/574 completed (loss: 0.3335472047328949, acc: 0.8799999952316284)
[2024-11-29 03:49:22,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:23,017][root][INFO] - Training Epoch: 7/10, step 190/574 completed (loss: 1.623400092124939, acc: 0.5232558250427246)
[2024-11-29 03:49:23,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:23,613][root][INFO] - Training Epoch: 7/10, step 191/574 completed (loss: 1.7391207218170166, acc: 0.5476190447807312)
[2024-11-29 03:49:23,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:24,211][root][INFO] - Training Epoch: 7/10, step 192/574 completed (loss: 2.2875618934631348, acc: 0.4015151560306549)
[2024-11-29 03:49:24,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:24,803][root][INFO] - Training Epoch: 7/10, step 193/574 completed (loss: 1.1848219633102417, acc: 0.6000000238418579)
[2024-11-29 03:49:24,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:25,416][root][INFO] - Training Epoch: 7/10, step 194/574 completed (loss: 1.7419291734695435, acc: 0.5432098507881165)
[2024-11-29 03:49:25,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:26,012][root][INFO] - Training Epoch: 7/10, step 195/574 completed (loss: 1.0459576845169067, acc: 0.6774193644523621)
[2024-11-29 03:49:26,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:26,597][root][INFO] - Training Epoch: 7/10, step 196/574 completed (loss: 0.19202446937561035, acc: 0.9285714030265808)
[2024-11-29 03:49:26,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:27,185][root][INFO] - Training Epoch: 7/10, step 197/574 completed (loss: 0.4820651113986969, acc: 0.8999999761581421)
[2024-11-29 03:49:27,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:27,778][root][INFO] - Training Epoch: 7/10, step 198/574 completed (loss: 0.8549613356590271, acc: 0.7647058963775635)
[2024-11-29 03:49:27,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:28,374][root][INFO] - Training Epoch: 7/10, step 199/574 completed (loss: 1.565021276473999, acc: 0.6397058963775635)
[2024-11-29 03:49:28,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:28,969][root][INFO] - Training Epoch: 7/10, step 200/574 completed (loss: 1.541560411453247, acc: 0.5677965879440308)
[2024-11-29 03:49:29,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:29,567][root][INFO] - Training Epoch: 7/10, step 201/574 completed (loss: 1.5471261739730835, acc: 0.5597015023231506)
[2024-11-29 03:49:29,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:30,164][root][INFO] - Training Epoch: 7/10, step 202/574 completed (loss: 1.5363874435424805, acc: 0.5922330021858215)
[2024-11-29 03:49:30,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:30,760][root][INFO] - Training Epoch: 7/10, step 203/574 completed (loss: 1.2863608598709106, acc: 0.6349206566810608)
[2024-11-29 03:49:30,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:31,354][root][INFO] - Training Epoch: 7/10, step 204/574 completed (loss: 0.9513095617294312, acc: 0.7252747416496277)
[2024-11-29 03:49:31,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:31,975][root][INFO] - Training Epoch: 7/10, step 205/574 completed (loss: 1.614742398262024, acc: 0.5470852255821228)
[2024-11-29 03:49:32,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:32,603][root][INFO] - Training Epoch: 7/10, step 206/574 completed (loss: 1.835923671722412, acc: 0.5236220359802246)
[2024-11-29 03:49:32,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:33,216][root][INFO] - Training Epoch: 7/10, step 207/574 completed (loss: 1.515893816947937, acc: 0.5732758641242981)
[2024-11-29 03:49:33,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:33,831][root][INFO] - Training Epoch: 7/10, step 208/574 completed (loss: 1.8115663528442383, acc: 0.5760869383811951)
[2024-11-29 03:49:33,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:34,454][root][INFO] - Training Epoch: 7/10, step 209/574 completed (loss: 1.8955150842666626, acc: 0.505836546421051)
[2024-11-29 03:49:34,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:35,070][root][INFO] - Training Epoch: 7/10, step 210/574 completed (loss: 1.931631326675415, acc: 0.47826087474823)
[2024-11-29 03:49:35,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:35,657][root][INFO] - Training Epoch: 7/10, step 211/574 completed (loss: 0.13086174428462982, acc: 0.95652174949646)
[2024-11-29 03:49:35,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:36,244][root][INFO] - Training Epoch: 7/10, step 212/574 completed (loss: 0.06765612214803696, acc: 1.0)
[2024-11-29 03:49:36,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:36,838][root][INFO] - Training Epoch: 7/10, step 213/574 completed (loss: 0.5068672299385071, acc: 0.8936170339584351)
[2024-11-29 03:49:36,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:37,448][root][INFO] - Training Epoch: 7/10, step 214/574 completed (loss: 1.2466291189193726, acc: 0.6692307591438293)
[2024-11-29 03:49:37,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:38,038][root][INFO] - Training Epoch: 7/10, step 215/574 completed (loss: 0.5725885629653931, acc: 0.837837815284729)
[2024-11-29 03:49:38,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:38,632][root][INFO] - Training Epoch: 7/10, step 216/574 completed (loss: 0.6132858395576477, acc: 0.8255813717842102)
[2024-11-29 03:49:38,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:39,231][root][INFO] - Training Epoch: 7/10, step 217/574 completed (loss: 0.8873770236968994, acc: 0.7387387156486511)
[2024-11-29 03:49:39,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:39,824][root][INFO] - Training Epoch: 7/10, step 218/574 completed (loss: 0.7135618329048157, acc: 0.855555534362793)
[2024-11-29 03:49:39,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:40,413][root][INFO] - Training Epoch: 7/10, step 219/574 completed (loss: 0.26811978220939636, acc: 0.9090909361839294)
[2024-11-29 03:49:40,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:40,998][root][INFO] - Training Epoch: 7/10, step 220/574 completed (loss: 0.00891925860196352, acc: 1.0)
[2024-11-29 03:49:41,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:41,585][root][INFO] - Training Epoch: 7/10, step 221/574 completed (loss: 0.02553926222026348, acc: 1.0)
[2024-11-29 03:49:41,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:42,180][root][INFO] - Training Epoch: 7/10, step 222/574 completed (loss: 1.1452504396438599, acc: 0.6346153616905212)
[2024-11-29 03:49:42,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:42,796][root][INFO] - Training Epoch: 7/10, step 223/574 completed (loss: 1.4823638200759888, acc: 0.614130437374115)
[2024-11-29 03:49:42,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:43,409][root][INFO] - Training Epoch: 7/10, step 224/574 completed (loss: 1.4758318662643433, acc: 0.5965909361839294)
[2024-11-29 03:49:43,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:44,023][root][INFO] - Training Epoch: 7/10, step 225/574 completed (loss: 1.5902208089828491, acc: 0.5744680762290955)
[2024-11-29 03:49:44,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:44,613][root][INFO] - Training Epoch: 7/10, step 226/574 completed (loss: 0.48078760504722595, acc: 0.8113207817077637)
[2024-11-29 03:49:44,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:45,207][root][INFO] - Training Epoch: 7/10, step 227/574 completed (loss: 0.5359318852424622, acc: 0.8166666626930237)
[2024-11-29 03:49:45,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:45,798][root][INFO] - Training Epoch: 7/10, step 228/574 completed (loss: 0.3493883013725281, acc: 0.8837209343910217)
[2024-11-29 03:49:45,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:46,386][root][INFO] - Training Epoch: 7/10, step 229/574 completed (loss: 0.11765957623720169, acc: 0.9666666388511658)
[2024-11-29 03:49:46,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:46,986][root][INFO] - Training Epoch: 7/10, step 230/574 completed (loss: 1.8466569185256958, acc: 0.4736842215061188)
[2024-11-29 03:49:47,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:47,578][root][INFO] - Training Epoch: 7/10, step 231/574 completed (loss: 1.0689572095870972, acc: 0.7222222089767456)
[2024-11-29 03:49:47,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:48,192][root][INFO] - Training Epoch: 7/10, step 232/574 completed (loss: 1.4546175003051758, acc: 0.5722222328186035)
[2024-11-29 03:49:48,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:48,803][root][INFO] - Training Epoch: 7/10, step 233/574 completed (loss: 1.946966290473938, acc: 0.4724770784378052)
[2024-11-29 03:49:48,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:49,415][root][INFO] - Training Epoch: 7/10, step 234/574 completed (loss: 1.4150786399841309, acc: 0.607692301273346)
[2024-11-29 03:49:49,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:50,001][root][INFO] - Training Epoch: 7/10, step 235/574 completed (loss: 0.05204050987958908, acc: 1.0)
[2024-11-29 03:49:50,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:50,588][root][INFO] - Training Epoch: 7/10, step 236/574 completed (loss: 0.024784455075860023, acc: 1.0)
[2024-11-29 03:49:50,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:51,175][root][INFO] - Training Epoch: 7/10, step 237/574 completed (loss: 0.07726804167032242, acc: 1.0)
[2024-11-29 03:49:51,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:51,764][root][INFO] - Training Epoch: 7/10, step 238/574 completed (loss: 0.1320376843214035, acc: 1.0)
[2024-11-29 03:49:51,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:52,355][root][INFO] - Training Epoch: 7/10, step 239/574 completed (loss: 0.4736979305744171, acc: 0.8857142925262451)
[2024-11-29 03:49:52,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:52,945][root][INFO] - Training Epoch: 7/10, step 240/574 completed (loss: 0.3232531249523163, acc: 0.8863636255264282)
[2024-11-29 03:49:53,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:53,532][root][INFO] - Training Epoch: 7/10, step 241/574 completed (loss: 0.37808430194854736, acc: 0.9090909361839294)
[2024-11-29 03:49:53,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:54,125][root][INFO] - Training Epoch: 7/10, step 242/574 completed (loss: 1.2302523851394653, acc: 0.5967742204666138)
[2024-11-29 03:49:54,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:54,717][root][INFO] - Training Epoch: 7/10, step 243/574 completed (loss: 0.5286923050880432, acc: 0.8636363744735718)
[2024-11-29 03:49:54,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:55,305][root][INFO] - Training Epoch: 7/10, step 244/574 completed (loss: 0.0032269989605993032, acc: 1.0)
[2024-11-29 03:49:55,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:55,893][root][INFO] - Training Epoch: 7/10, step 245/574 completed (loss: 0.09246217459440231, acc: 0.9615384340286255)
[2024-11-29 03:49:55,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:56,481][root][INFO] - Training Epoch: 7/10, step 246/574 completed (loss: 0.053858380764722824, acc: 1.0)
[2024-11-29 03:49:56,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:57,068][root][INFO] - Training Epoch: 7/10, step 247/574 completed (loss: 0.08429344743490219, acc: 1.0)
[2024-11-29 03:49:57,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:57,660][root][INFO] - Training Epoch: 7/10, step 248/574 completed (loss: 0.4331384599208832, acc: 0.8108108043670654)
[2024-11-29 03:49:57,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:58,247][root][INFO] - Training Epoch: 7/10, step 249/574 completed (loss: 0.2252642959356308, acc: 0.9459459185600281)
[2024-11-29 03:49:58,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:58,837][root][INFO] - Training Epoch: 7/10, step 250/574 completed (loss: 0.2345249056816101, acc: 0.9459459185600281)
[2024-11-29 03:49:58,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:59,433][root][INFO] - Training Epoch: 7/10, step 251/574 completed (loss: 1.0382457971572876, acc: 0.6911764740943909)
[2024-11-29 03:49:59,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:00,023][root][INFO] - Training Epoch: 7/10, step 252/574 completed (loss: 0.07081464678049088, acc: 1.0)
[2024-11-29 03:50:00,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:00,609][root][INFO] - Training Epoch: 7/10, step 253/574 completed (loss: 0.015077101066708565, acc: 1.0)
[2024-11-29 03:50:00,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:01,197][root][INFO] - Training Epoch: 7/10, step 254/574 completed (loss: 0.00926349125802517, acc: 1.0)
[2024-11-29 03:50:01,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:01,785][root][INFO] - Training Epoch: 7/10, step 255/574 completed (loss: 0.020750992000102997, acc: 1.0)
[2024-11-29 03:50:01,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:02,378][root][INFO] - Training Epoch: 7/10, step 256/574 completed (loss: 0.4821566939353943, acc: 0.8421052694320679)
[2024-11-29 03:50:02,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:02,967][root][INFO] - Training Epoch: 7/10, step 257/574 completed (loss: 0.35641324520111084, acc: 0.8857142925262451)
[2024-11-29 03:50:03,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:03,560][root][INFO] - Training Epoch: 7/10, step 258/574 completed (loss: 0.424771249294281, acc: 0.8815789222717285)
[2024-11-29 03:50:03,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:04,169][root][INFO] - Training Epoch: 7/10, step 259/574 completed (loss: 0.9446403980255127, acc: 0.7452830076217651)
[2024-11-29 03:50:04,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:04,783][root][INFO] - Training Epoch: 7/10, step 260/574 completed (loss: 1.5307328701019287, acc: 0.5916666388511658)
[2024-11-29 03:50:04,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:05,372][root][INFO] - Training Epoch: 7/10, step 261/574 completed (loss: 0.2340475469827652, acc: 0.9166666865348816)
[2024-11-29 03:50:05,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:05,960][root][INFO] - Training Epoch: 7/10, step 262/574 completed (loss: 0.26915276050567627, acc: 0.9354838728904724)
[2024-11-29 03:50:06,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:06,555][root][INFO] - Training Epoch: 7/10, step 263/574 completed (loss: 1.5380464792251587, acc: 0.54666668176651)
[2024-11-29 03:50:06,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:07,145][root][INFO] - Training Epoch: 7/10, step 264/574 completed (loss: 0.8851813673973083, acc: 0.7291666865348816)
[2024-11-29 03:50:07,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:07,761][root][INFO] - Training Epoch: 7/10, step 265/574 completed (loss: 2.027846097946167, acc: 0.4399999976158142)
[2024-11-29 03:50:07,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:08,354][root][INFO] - Training Epoch: 7/10, step 266/574 completed (loss: 1.4138063192367554, acc: 0.584269642829895)
[2024-11-29 03:50:08,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:08,949][root][INFO] - Training Epoch: 7/10, step 267/574 completed (loss: 1.24247407913208, acc: 0.6216216087341309)
[2024-11-29 03:50:09,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:09,547][root][INFO] - Training Epoch: 7/10, step 268/574 completed (loss: 0.9695493578910828, acc: 0.6379310488700867)
[2024-11-29 03:50:09,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:10,135][root][INFO] - Training Epoch: 7/10, step 269/574 completed (loss: 0.018915502354502678, acc: 1.0)
[2024-11-29 03:50:10,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:10,724][root][INFO] - Training Epoch: 7/10, step 270/574 completed (loss: 0.016190478578209877, acc: 1.0)
[2024-11-29 03:50:10,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:11,312][root][INFO] - Training Epoch: 7/10, step 271/574 completed (loss: 0.1136799305677414, acc: 0.96875)
[2024-11-29 03:50:11,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:11,899][root][INFO] - Training Epoch: 7/10, step 272/574 completed (loss: 0.06518061459064484, acc: 1.0)
[2024-11-29 03:50:11,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:12,493][root][INFO] - Training Epoch: 7/10, step 273/574 completed (loss: 1.1755839586257935, acc: 0.6499999761581421)
[2024-11-29 03:50:13,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:13,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:14,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:14,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:15,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:15,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:16,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:16,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:17,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:17,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:18,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:18,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:19,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:20,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:20,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:21,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:21,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:22,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:22,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:23,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:23,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:24,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:24,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:25,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:25,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:26,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:26,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:27,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:27,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:28,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:28,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:29,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:29,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:30,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:30,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:31,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:31,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:32,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:33,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:33,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:34,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:34,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:35,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:35,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:36,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:36,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:37,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:37,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:38,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:38,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:39,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:39,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:40,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:40,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:41,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:41,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:42,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:42,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:43,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:43,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:44,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:45,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:45,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:46,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:46,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:47,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:47,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:48,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:48,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:49,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:49,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:50,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:50,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:51,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:51,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:52,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:52,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:53,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:54,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:54,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:55,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:55,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:56,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:56,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:57,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:57,974][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(4.0927, device='cuda:0') eval_epoch_loss=tensor(1.4092, device='cuda:0') eval_epoch_acc=tensor(0.6717, device='cuda:0')
[2024-11-29 03:50:57,975][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:50:57,976][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:50:58,179][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_7_step_274_loss_1.4092048406600952/model.pt
[2024-11-29 03:50:58,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:58,794][root][INFO] - Training Epoch: 7/10, step 274/574 completed (loss: 0.13492073118686676, acc: 0.9375)
[2024-11-29 03:50:58,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:59,380][root][INFO] - Training Epoch: 7/10, step 275/574 completed (loss: 0.05197363346815109, acc: 1.0)
[2024-11-29 03:50:59,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:59,968][root][INFO] - Training Epoch: 7/10, step 276/574 completed (loss: 0.2528989911079407, acc: 0.8620689511299133)
[2024-11-29 03:51:00,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:00,552][root][INFO] - Training Epoch: 7/10, step 277/574 completed (loss: 0.07182130217552185, acc: 1.0)
[2024-11-29 03:51:00,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:01,142][root][INFO] - Training Epoch: 7/10, step 278/574 completed (loss: 0.8339237570762634, acc: 0.7234042286872864)
[2024-11-29 03:51:01,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:01,733][root][INFO] - Training Epoch: 7/10, step 279/574 completed (loss: 0.5219002366065979, acc: 0.8541666865348816)
[2024-11-29 03:51:01,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:02,322][root][INFO] - Training Epoch: 7/10, step 280/574 completed (loss: 0.3585096597671509, acc: 0.9090909361839294)
[2024-11-29 03:51:02,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:02,916][root][INFO] - Training Epoch: 7/10, step 281/574 completed (loss: 1.4169615507125854, acc: 0.6626505851745605)
[2024-11-29 03:51:02,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:03,512][root][INFO] - Training Epoch: 7/10, step 282/574 completed (loss: 1.2571519613265991, acc: 0.6759259104728699)
[2024-11-29 03:51:03,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:04,098][root][INFO] - Training Epoch: 7/10, step 283/574 completed (loss: 0.4086342751979828, acc: 0.8157894611358643)
[2024-11-29 03:51:04,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:04,685][root][INFO] - Training Epoch: 7/10, step 284/574 completed (loss: 0.45170021057128906, acc: 0.8529411554336548)
[2024-11-29 03:51:04,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:05,274][root][INFO] - Training Epoch: 7/10, step 285/574 completed (loss: 0.279893696308136, acc: 0.925000011920929)
[2024-11-29 03:51:05,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:05,874][root][INFO] - Training Epoch: 7/10, step 286/574 completed (loss: 1.471937894821167, acc: 0.6015625)
[2024-11-29 03:51:05,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:06,485][root][INFO] - Training Epoch: 7/10, step 287/574 completed (loss: 1.4973573684692383, acc: 0.5600000023841858)
[2024-11-29 03:51:06,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:07,085][root][INFO] - Training Epoch: 7/10, step 288/574 completed (loss: 0.9534865021705627, acc: 0.7362637519836426)
[2024-11-29 03:51:07,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:07,682][root][INFO] - Training Epoch: 7/10, step 289/574 completed (loss: 1.6990247964859009, acc: 0.5590062141418457)
[2024-11-29 03:51:07,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:08,296][root][INFO] - Training Epoch: 7/10, step 290/574 completed (loss: 1.9215106964111328, acc: 0.4845360815525055)
[2024-11-29 03:51:08,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:08,882][root][INFO] - Training Epoch: 7/10, step 291/574 completed (loss: 0.012923097237944603, acc: 1.0)
[2024-11-29 03:51:08,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:09,471][root][INFO] - Training Epoch: 7/10, step 292/574 completed (loss: 0.6187858581542969, acc: 0.738095223903656)
[2024-11-29 03:51:09,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:10,064][root][INFO] - Training Epoch: 7/10, step 293/574 completed (loss: 0.5194017291069031, acc: 0.8103448152542114)
[2024-11-29 03:51:10,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:10,663][root][INFO] - Training Epoch: 7/10, step 294/574 completed (loss: 0.7295336127281189, acc: 0.7454545497894287)
[2024-11-29 03:51:10,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:11,285][root][INFO] - Training Epoch: 7/10, step 295/574 completed (loss: 1.6178717613220215, acc: 0.5824742317199707)
[2024-11-29 03:51:11,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:11,881][root][INFO] - Training Epoch: 7/10, step 296/574 completed (loss: 0.7975712418556213, acc: 0.7586206793785095)
[2024-11-29 03:51:11,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:12,470][root][INFO] - Training Epoch: 7/10, step 297/574 completed (loss: 0.10175848752260208, acc: 1.0)
[2024-11-29 03:51:12,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:13,060][root][INFO] - Training Epoch: 7/10, step 298/574 completed (loss: 0.4802863895893097, acc: 0.8421052694320679)
[2024-11-29 03:51:13,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:13,651][root][INFO] - Training Epoch: 7/10, step 299/574 completed (loss: 0.6449341177940369, acc: 0.8035714030265808)
[2024-11-29 03:51:13,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:14,241][root][INFO] - Training Epoch: 7/10, step 300/574 completed (loss: 0.1401045024394989, acc: 1.0)
[2024-11-29 03:51:14,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:14,832][root][INFO] - Training Epoch: 7/10, step 301/574 completed (loss: 0.6151773929595947, acc: 0.849056601524353)
[2024-11-29 03:51:14,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:15,424][root][INFO] - Training Epoch: 7/10, step 302/574 completed (loss: 0.16343219578266144, acc: 0.9433962106704712)
[2024-11-29 03:51:15,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:16,010][root][INFO] - Training Epoch: 7/10, step 303/574 completed (loss: 0.08526913821697235, acc: 0.970588207244873)
[2024-11-29 03:51:16,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:16,596][root][INFO] - Training Epoch: 7/10, step 304/574 completed (loss: 0.3544744551181793, acc: 0.9375)
[2024-11-29 03:51:16,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:17,188][root][INFO] - Training Epoch: 7/10, step 305/574 completed (loss: 0.8042832612991333, acc: 0.7377049326896667)
[2024-11-29 03:51:17,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:17,776][root][INFO] - Training Epoch: 7/10, step 306/574 completed (loss: 0.03997688740491867, acc: 1.0)
[2024-11-29 03:51:17,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:18,361][root][INFO] - Training Epoch: 7/10, step 307/574 completed (loss: 0.060748886317014694, acc: 0.9473684430122375)
[2024-11-29 03:51:18,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:18,953][root][INFO] - Training Epoch: 7/10, step 308/574 completed (loss: 0.9066981673240662, acc: 0.739130437374115)
[2024-11-29 03:51:19,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:19,549][root][INFO] - Training Epoch: 7/10, step 309/574 completed (loss: 1.0723812580108643, acc: 0.7083333134651184)
[2024-11-29 03:51:19,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:20,143][root][INFO] - Training Epoch: 7/10, step 310/574 completed (loss: 0.9151352047920227, acc: 0.7469879388809204)
[2024-11-29 03:51:20,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:20,738][root][INFO] - Training Epoch: 7/10, step 311/574 completed (loss: 1.0284042358398438, acc: 0.692307710647583)
[2024-11-29 03:51:20,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:21,349][root][INFO] - Training Epoch: 7/10, step 312/574 completed (loss: 1.449210286140442, acc: 0.6224489808082581)
[2024-11-29 03:51:21,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:21,936][root][INFO] - Training Epoch: 7/10, step 313/574 completed (loss: 0.0053476146422326565, acc: 1.0)
[2024-11-29 03:51:22,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:22,522][root][INFO] - Training Epoch: 7/10, step 314/574 completed (loss: 0.03968813270330429, acc: 1.0)
[2024-11-29 03:51:22,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:23,108][root][INFO] - Training Epoch: 7/10, step 315/574 completed (loss: 0.11668544262647629, acc: 0.9354838728904724)
[2024-11-29 03:51:23,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:23,694][root][INFO] - Training Epoch: 7/10, step 316/574 completed (loss: 0.14652299880981445, acc: 0.9677419066429138)
[2024-11-29 03:51:23,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:24,288][root][INFO] - Training Epoch: 7/10, step 317/574 completed (loss: 0.6826367378234863, acc: 0.8208954930305481)
[2024-11-29 03:51:24,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:24,886][root][INFO] - Training Epoch: 7/10, step 318/574 completed (loss: 0.7912765145301819, acc: 0.7403846383094788)
[2024-11-29 03:51:24,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:25,474][root][INFO] - Training Epoch: 7/10, step 319/574 completed (loss: 0.3877425789833069, acc: 0.8888888955116272)
[2024-11-29 03:51:25,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:26,066][root][INFO] - Training Epoch: 7/10, step 320/574 completed (loss: 0.2901581823825836, acc: 0.9032257795333862)
[2024-11-29 03:51:26,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:26,654][root][INFO] - Training Epoch: 7/10, step 321/574 completed (loss: 0.1028229147195816, acc: 0.9599999785423279)
[2024-11-29 03:51:26,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:27,241][root][INFO] - Training Epoch: 7/10, step 322/574 completed (loss: 0.31525543332099915, acc: 0.8888888955116272)
[2024-11-29 03:51:27,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:27,829][root][INFO] - Training Epoch: 7/10, step 323/574 completed (loss: 0.937495231628418, acc: 0.7428571581840515)
[2024-11-29 03:51:27,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:28,416][root][INFO] - Training Epoch: 7/10, step 324/574 completed (loss: 0.9807724356651306, acc: 0.7435897588729858)
[2024-11-29 03:51:28,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:29,008][root][INFO] - Training Epoch: 7/10, step 325/574 completed (loss: 0.6444312930107117, acc: 0.7804877758026123)
[2024-11-29 03:51:29,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:29,603][root][INFO] - Training Epoch: 7/10, step 326/574 completed (loss: 0.541192352771759, acc: 0.8157894611358643)
[2024-11-29 03:51:29,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:30,189][root][INFO] - Training Epoch: 7/10, step 327/574 completed (loss: 0.4841395318508148, acc: 0.7894737124443054)
[2024-11-29 03:51:30,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:30,775][root][INFO] - Training Epoch: 7/10, step 328/574 completed (loss: 0.026059670373797417, acc: 1.0)
[2024-11-29 03:51:30,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:31,362][root][INFO] - Training Epoch: 7/10, step 329/574 completed (loss: 0.19354407489299774, acc: 0.9629629850387573)
[2024-11-29 03:51:31,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:31,948][root][INFO] - Training Epoch: 7/10, step 330/574 completed (loss: 0.062169574201107025, acc: 0.96875)
[2024-11-29 03:51:32,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:32,540][root][INFO] - Training Epoch: 7/10, step 331/574 completed (loss: 0.942093014717102, acc: 0.725806474685669)
[2024-11-29 03:51:32,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:33,134][root][INFO] - Training Epoch: 7/10, step 332/574 completed (loss: 0.59832364320755, acc: 0.7894737124443054)
[2024-11-29 03:51:33,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:33,721][root][INFO] - Training Epoch: 7/10, step 333/574 completed (loss: 0.369936466217041, acc: 0.84375)
[2024-11-29 03:51:33,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:34,308][root][INFO] - Training Epoch: 7/10, step 334/574 completed (loss: 0.15012292563915253, acc: 0.9333333373069763)
[2024-11-29 03:51:34,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:34,895][root][INFO] - Training Epoch: 7/10, step 335/574 completed (loss: 0.303931325674057, acc: 0.8947368264198303)
[2024-11-29 03:51:34,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:35,488][root][INFO] - Training Epoch: 7/10, step 336/574 completed (loss: 0.9094222784042358, acc: 0.7200000286102295)
[2024-11-29 03:51:35,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:36,083][root][INFO] - Training Epoch: 7/10, step 337/574 completed (loss: 1.6896969079971313, acc: 0.5862069129943848)
[2024-11-29 03:51:36,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:36,679][root][INFO] - Training Epoch: 7/10, step 338/574 completed (loss: 1.6371572017669678, acc: 0.4893617033958435)
[2024-11-29 03:51:36,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:37,274][root][INFO] - Training Epoch: 7/10, step 339/574 completed (loss: 1.8313063383102417, acc: 0.5421686768531799)
[2024-11-29 03:51:37,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:37,863][root][INFO] - Training Epoch: 7/10, step 340/574 completed (loss: 0.16875284910202026, acc: 0.95652174949646)
[2024-11-29 03:51:37,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:38,450][root][INFO] - Training Epoch: 7/10, step 341/574 completed (loss: 1.1017121076583862, acc: 0.7435897588729858)
[2024-11-29 03:51:38,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:39,040][root][INFO] - Training Epoch: 7/10, step 342/574 completed (loss: 1.8423689603805542, acc: 0.5542168617248535)
[2024-11-29 03:51:39,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:39,632][root][INFO] - Training Epoch: 7/10, step 343/574 completed (loss: 0.7068089246749878, acc: 0.8113207817077637)
[2024-11-29 03:51:39,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:40,224][root][INFO] - Training Epoch: 7/10, step 344/574 completed (loss: 1.1966712474822998, acc: 0.6202531456947327)
[2024-11-29 03:51:40,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:40,812][root][INFO] - Training Epoch: 7/10, step 345/574 completed (loss: 0.7031030654907227, acc: 0.7843137383460999)
[2024-11-29 03:51:40,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:41,405][root][INFO] - Training Epoch: 7/10, step 346/574 completed (loss: 1.1752979755401611, acc: 0.6567164063453674)
[2024-11-29 03:51:41,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:41,991][root][INFO] - Training Epoch: 7/10, step 347/574 completed (loss: 0.28627121448516846, acc: 0.949999988079071)
[2024-11-29 03:51:42,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:42,577][root][INFO] - Training Epoch: 7/10, step 348/574 completed (loss: 0.8000134825706482, acc: 0.8399999737739563)
[2024-11-29 03:51:42,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:43,166][root][INFO] - Training Epoch: 7/10, step 349/574 completed (loss: 0.6075667142868042, acc: 0.8333333134651184)
[2024-11-29 03:51:43,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:43,754][root][INFO] - Training Epoch: 7/10, step 350/574 completed (loss: 0.9110761284828186, acc: 0.7674418687820435)
[2024-11-29 03:51:43,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:44,342][root][INFO] - Training Epoch: 7/10, step 351/574 completed (loss: 0.7489097118377686, acc: 0.7692307829856873)
[2024-11-29 03:51:44,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:44,933][root][INFO] - Training Epoch: 7/10, step 352/574 completed (loss: 1.038495421409607, acc: 0.6888889074325562)
[2024-11-29 03:51:45,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:45,518][root][INFO] - Training Epoch: 7/10, step 353/574 completed (loss: 0.030956752598285675, acc: 1.0)
[2024-11-29 03:51:45,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:46,105][root][INFO] - Training Epoch: 7/10, step 354/574 completed (loss: 0.8498228788375854, acc: 0.7307692170143127)
[2024-11-29 03:51:46,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:46,698][root][INFO] - Training Epoch: 7/10, step 355/574 completed (loss: 1.9334865808486938, acc: 0.4395604431629181)
[2024-11-29 03:51:46,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:47,311][root][INFO] - Training Epoch: 7/10, step 356/574 completed (loss: 1.6576905250549316, acc: 0.5478261113166809)
[2024-11-29 03:51:47,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:47,904][root][INFO] - Training Epoch: 7/10, step 357/574 completed (loss: 1.3529386520385742, acc: 0.5652173757553101)
[2024-11-29 03:51:47,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:48,497][root][INFO] - Training Epoch: 7/10, step 358/574 completed (loss: 0.8020220398902893, acc: 0.7346938848495483)
[2024-11-29 03:51:48,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:49,083][root][INFO] - Training Epoch: 7/10, step 359/574 completed (loss: 0.06292978674173355, acc: 1.0)
[2024-11-29 03:51:49,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:49,670][root][INFO] - Training Epoch: 7/10, step 360/574 completed (loss: 0.08701275289058685, acc: 1.0)
[2024-11-29 03:51:49,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:50,258][root][INFO] - Training Epoch: 7/10, step 361/574 completed (loss: 0.5742130875587463, acc: 0.8048780560493469)
[2024-11-29 03:51:50,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:50,847][root][INFO] - Training Epoch: 7/10, step 362/574 completed (loss: 0.6012493968009949, acc: 0.8444444537162781)
[2024-11-29 03:51:50,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:51,441][root][INFO] - Training Epoch: 7/10, step 363/574 completed (loss: 1.147356629371643, acc: 0.7368420958518982)
[2024-11-29 03:51:51,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:52,033][root][INFO] - Training Epoch: 7/10, step 364/574 completed (loss: 0.6118490099906921, acc: 0.8292682766914368)
[2024-11-29 03:51:52,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:52,622][root][INFO] - Training Epoch: 7/10, step 365/574 completed (loss: 0.38033267855644226, acc: 0.8787878751754761)
[2024-11-29 03:51:52,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:53,209][root][INFO] - Training Epoch: 7/10, step 366/574 completed (loss: 0.021689115092158318, acc: 1.0)
[2024-11-29 03:51:53,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:53,796][root][INFO] - Training Epoch: 7/10, step 367/574 completed (loss: 0.005917312577366829, acc: 1.0)
[2024-11-29 03:51:53,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:54,382][root][INFO] - Training Epoch: 7/10, step 368/574 completed (loss: 0.14541001617908478, acc: 0.9642857313156128)
[2024-11-29 03:51:54,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:54,971][root][INFO] - Training Epoch: 7/10, step 369/574 completed (loss: 0.256671279668808, acc: 0.9375)
[2024-11-29 03:51:55,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:55,586][root][INFO] - Training Epoch: 7/10, step 370/574 completed (loss: 1.986562967300415, acc: 0.46060606837272644)
[2024-11-29 03:51:55,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:56,196][root][INFO] - Training Epoch: 7/10, step 371/574 completed (loss: 1.1717110872268677, acc: 0.7169811129570007)
[2024-11-29 03:51:56,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:56,789][root][INFO] - Training Epoch: 7/10, step 372/574 completed (loss: 0.7307848334312439, acc: 0.800000011920929)
[2024-11-29 03:51:56,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:57,384][root][INFO] - Training Epoch: 7/10, step 373/574 completed (loss: 0.6086756587028503, acc: 0.8035714030265808)
[2024-11-29 03:51:57,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:57,975][root][INFO] - Training Epoch: 7/10, step 374/574 completed (loss: 0.4751683473587036, acc: 0.8571428656578064)
[2024-11-29 03:51:58,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:58,564][root][INFO] - Training Epoch: 7/10, step 375/574 completed (loss: 0.016964279115200043, acc: 1.0)
[2024-11-29 03:51:58,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:59,159][root][INFO] - Training Epoch: 7/10, step 376/574 completed (loss: 0.01736585423350334, acc: 1.0)
[2024-11-29 03:51:59,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:59,751][root][INFO] - Training Epoch: 7/10, step 377/574 completed (loss: 0.5441706776618958, acc: 0.8958333134651184)
[2024-11-29 03:51:59,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:00,346][root][INFO] - Training Epoch: 7/10, step 378/574 completed (loss: 0.926389753818512, acc: 0.7473683953285217)
[2024-11-29 03:52:00,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:00,958][root][INFO] - Training Epoch: 7/10, step 379/574 completed (loss: 1.3903387784957886, acc: 0.688622772693634)
[2024-11-29 03:52:01,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:01,556][root][INFO] - Training Epoch: 7/10, step 380/574 completed (loss: 1.2006027698516846, acc: 0.6616541147232056)
[2024-11-29 03:52:01,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:02,178][root][INFO] - Training Epoch: 7/10, step 381/574 completed (loss: 1.3861217498779297, acc: 0.625668466091156)
[2024-11-29 03:52:02,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:02,789][root][INFO] - Training Epoch: 7/10, step 382/574 completed (loss: 0.9096746444702148, acc: 0.7747747898101807)
[2024-11-29 03:52:02,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:03,374][root][INFO] - Training Epoch: 7/10, step 383/574 completed (loss: 0.10664444416761398, acc: 0.9642857313156128)
[2024-11-29 03:52:03,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:03,960][root][INFO] - Training Epoch: 7/10, step 384/574 completed (loss: 0.013574845157563686, acc: 1.0)
[2024-11-29 03:52:04,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:04,550][root][INFO] - Training Epoch: 7/10, step 385/574 completed (loss: 0.31559866666793823, acc: 0.90625)
[2024-11-29 03:52:04,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:05,136][root][INFO] - Training Epoch: 7/10, step 386/574 completed (loss: 0.1376773864030838, acc: 0.9444444179534912)
[2024-11-29 03:52:05,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:05,723][root][INFO] - Training Epoch: 7/10, step 387/574 completed (loss: 0.07118064910173416, acc: 0.9736841917037964)
[2024-11-29 03:52:05,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:06,309][root][INFO] - Training Epoch: 7/10, step 388/574 completed (loss: 0.03725415840744972, acc: 1.0)
[2024-11-29 03:52:06,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:06,894][root][INFO] - Training Epoch: 7/10, step 389/574 completed (loss: 0.011369377374649048, acc: 1.0)
[2024-11-29 03:52:06,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:07,480][root][INFO] - Training Epoch: 7/10, step 390/574 completed (loss: 0.4066685736179352, acc: 0.9047619104385376)
[2024-11-29 03:52:07,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:08,067][root][INFO] - Training Epoch: 7/10, step 391/574 completed (loss: 0.743898868560791, acc: 0.7037037014961243)
[2024-11-29 03:52:08,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:08,660][root][INFO] - Training Epoch: 7/10, step 392/574 completed (loss: 1.6501137018203735, acc: 0.5631067752838135)
[2024-11-29 03:52:08,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:09,274][root][INFO] - Training Epoch: 7/10, step 393/574 completed (loss: 1.49248468875885, acc: 0.6323529481887817)
[2024-11-29 03:52:09,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:09,872][root][INFO] - Training Epoch: 7/10, step 394/574 completed (loss: 1.819541573524475, acc: 0.5333333611488342)
[2024-11-29 03:52:09,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:10,469][root][INFO] - Training Epoch: 7/10, step 395/574 completed (loss: 1.614250659942627, acc: 0.5972222089767456)
[2024-11-29 03:52:10,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:11,060][root][INFO] - Training Epoch: 7/10, step 396/574 completed (loss: 0.5954530835151672, acc: 0.8372092843055725)
[2024-11-29 03:52:11,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:11,646][root][INFO] - Training Epoch: 7/10, step 397/574 completed (loss: 0.025745222344994545, acc: 1.0)
[2024-11-29 03:52:11,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:12,235][root][INFO] - Training Epoch: 7/10, step 398/574 completed (loss: 1.0380260944366455, acc: 0.6976743936538696)
[2024-11-29 03:52:12,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:12,822][root][INFO] - Training Epoch: 7/10, step 399/574 completed (loss: 0.31019139289855957, acc: 0.8799999952316284)
[2024-11-29 03:52:12,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:13,420][root][INFO] - Training Epoch: 7/10, step 400/574 completed (loss: 0.9647813439369202, acc: 0.7058823704719543)
[2024-11-29 03:52:13,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:14,014][root][INFO] - Training Epoch: 7/10, step 401/574 completed (loss: 0.7152554392814636, acc: 0.7866666913032532)
[2024-11-29 03:52:14,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:14,605][root][INFO] - Training Epoch: 7/10, step 402/574 completed (loss: 0.14837586879730225, acc: 0.939393937587738)
[2024-11-29 03:52:14,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:15,192][root][INFO] - Training Epoch: 7/10, step 403/574 completed (loss: 0.25894761085510254, acc: 0.939393937587738)
[2024-11-29 03:52:15,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:15,780][root][INFO] - Training Epoch: 7/10, step 404/574 completed (loss: 0.04797085002064705, acc: 1.0)
[2024-11-29 03:52:15,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:16,367][root][INFO] - Training Epoch: 7/10, step 405/574 completed (loss: 0.312187135219574, acc: 0.9259259104728699)
[2024-11-29 03:52:16,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:16,953][root][INFO] - Training Epoch: 7/10, step 406/574 completed (loss: 0.010566375218331814, acc: 1.0)
[2024-11-29 03:52:17,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:17,542][root][INFO] - Training Epoch: 7/10, step 407/574 completed (loss: 0.17194746434688568, acc: 0.9444444179534912)
[2024-11-29 03:52:17,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:18,129][root][INFO] - Training Epoch: 7/10, step 408/574 completed (loss: 0.09435726702213287, acc: 0.9629629850387573)
[2024-11-29 03:52:18,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:18,715][root][INFO] - Training Epoch: 7/10, step 409/574 completed (loss: 0.03833397850394249, acc: 1.0)
[2024-11-29 03:52:18,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:19,307][root][INFO] - Training Epoch: 7/10, step 410/574 completed (loss: 0.3584856390953064, acc: 0.8793103694915771)
[2024-11-29 03:52:19,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:19,894][root][INFO] - Training Epoch: 7/10, step 411/574 completed (loss: 0.2952100336551666, acc: 0.9642857313156128)
[2024-11-29 03:52:19,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:20,482][root][INFO] - Training Epoch: 7/10, step 412/574 completed (loss: 0.3952398896217346, acc: 0.8666666746139526)
[2024-11-29 03:52:20,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:21,068][root][INFO] - Training Epoch: 7/10, step 413/574 completed (loss: 0.24427641928195953, acc: 0.939393937587738)
[2024-11-29 03:52:21,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:21,654][root][INFO] - Training Epoch: 7/10, step 414/574 completed (loss: 0.06649370491504669, acc: 1.0)
[2024-11-29 03:52:21,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:22,243][root][INFO] - Training Epoch: 7/10, step 415/574 completed (loss: 0.833791196346283, acc: 0.7450980544090271)
[2024-11-29 03:52:22,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:22,832][root][INFO] - Training Epoch: 7/10, step 416/574 completed (loss: 0.1380261331796646, acc: 0.9615384340286255)
[2024-11-29 03:52:23,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:24,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:24,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:25,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:25,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:26,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:26,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:27,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:27,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:28,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:28,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:29,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:29,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:30,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:30,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:31,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:31,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:32,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:32,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:33,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:34,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:34,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:35,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:35,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:36,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:36,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:37,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:37,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:38,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:38,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:39,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:39,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:40,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:40,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:41,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:41,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:42,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:43,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:43,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:44,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:44,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:45,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:45,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:46,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:46,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:47,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:47,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:48,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:48,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:49,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:49,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:50,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:50,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:51,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:52,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:52,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:53,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:53,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:54,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:54,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:55,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:55,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:56,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:56,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:57,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:57,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:58,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:58,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:59,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:59,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:00,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:01,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:01,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:02,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:02,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:03,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:03,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:04,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:04,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:05,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:05,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:06,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:06,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:07,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:07,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:08,679][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.7841, device='cuda:0') eval_epoch_loss=tensor(1.3308, device='cuda:0') eval_epoch_acc=tensor(0.6651, device='cuda:0')
[2024-11-29 03:53:08,680][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:53:08,680][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:53:08,934][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_7_step_417_loss_1.330804705619812/model.pt
[2024-11-29 03:53:09,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:09,539][root][INFO] - Training Epoch: 7/10, step 417/574 completed (loss: 0.6398764848709106, acc: 0.8888888955116272)
[2024-11-29 03:53:09,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:10,131][root][INFO] - Training Epoch: 7/10, step 418/574 completed (loss: 0.4065823554992676, acc: 0.925000011920929)
[2024-11-29 03:53:10,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:10,717][root][INFO] - Training Epoch: 7/10, step 419/574 completed (loss: 0.6250146627426147, acc: 0.8999999761581421)
[2024-11-29 03:53:10,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:11,306][root][INFO] - Training Epoch: 7/10, step 420/574 completed (loss: 0.012051680125296116, acc: 1.0)
[2024-11-29 03:53:11,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:11,894][root][INFO] - Training Epoch: 7/10, step 421/574 completed (loss: 0.27035099267959595, acc: 0.8999999761581421)
[2024-11-29 03:53:11,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:12,483][root][INFO] - Training Epoch: 7/10, step 422/574 completed (loss: 0.5287455320358276, acc: 0.875)
[2024-11-29 03:53:12,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:13,073][root][INFO] - Training Epoch: 7/10, step 423/574 completed (loss: 0.4051547646522522, acc: 0.9166666865348816)
[2024-11-29 03:53:13,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:13,661][root][INFO] - Training Epoch: 7/10, step 424/574 completed (loss: 0.12789160013198853, acc: 0.9629629850387573)
[2024-11-29 03:53:13,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:14,251][root][INFO] - Training Epoch: 7/10, step 425/574 completed (loss: 0.09003953635692596, acc: 0.9696969985961914)
[2024-11-29 03:53:14,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:14,839][root][INFO] - Training Epoch: 7/10, step 426/574 completed (loss: 0.030031990259885788, acc: 1.0)
[2024-11-29 03:53:14,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:15,429][root][INFO] - Training Epoch: 7/10, step 427/574 completed (loss: 0.17731748521327972, acc: 0.9459459185600281)
[2024-11-29 03:53:15,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:16,017][root][INFO] - Training Epoch: 7/10, step 428/574 completed (loss: 0.08891864120960236, acc: 0.9629629850387573)
[2024-11-29 03:53:16,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:16,605][root][INFO] - Training Epoch: 7/10, step 429/574 completed (loss: 0.19908612966537476, acc: 0.9130434989929199)
[2024-11-29 03:53:16,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:17,194][root][INFO] - Training Epoch: 7/10, step 430/574 completed (loss: 0.010162918828427792, acc: 1.0)
[2024-11-29 03:53:17,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:17,783][root][INFO] - Training Epoch: 7/10, step 431/574 completed (loss: 0.016278909519314766, acc: 1.0)
[2024-11-29 03:53:17,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:18,370][root][INFO] - Training Epoch: 7/10, step 432/574 completed (loss: 0.03978550434112549, acc: 1.0)
[2024-11-29 03:53:18,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:18,959][root][INFO] - Training Epoch: 7/10, step 433/574 completed (loss: 0.27450165152549744, acc: 0.9444444179534912)
[2024-11-29 03:53:19,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:19,547][root][INFO] - Training Epoch: 7/10, step 434/574 completed (loss: 0.037495627999305725, acc: 1.0)
[2024-11-29 03:53:19,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:20,136][root][INFO] - Training Epoch: 7/10, step 435/574 completed (loss: 0.11979472637176514, acc: 1.0)
[2024-11-29 03:53:20,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:20,724][root][INFO] - Training Epoch: 7/10, step 436/574 completed (loss: 0.7265105247497559, acc: 0.8055555820465088)
[2024-11-29 03:53:20,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:21,318][root][INFO] - Training Epoch: 7/10, step 437/574 completed (loss: 0.28371497988700867, acc: 0.9090909361839294)
[2024-11-29 03:53:21,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:21,904][root][INFO] - Training Epoch: 7/10, step 438/574 completed (loss: 0.026172388345003128, acc: 1.0)
[2024-11-29 03:53:21,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:22,497][root][INFO] - Training Epoch: 7/10, step 439/574 completed (loss: 0.5285022258758545, acc: 0.8461538553237915)
[2024-11-29 03:53:22,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:23,092][root][INFO] - Training Epoch: 7/10, step 440/574 completed (loss: 0.9472120404243469, acc: 0.7424242496490479)
[2024-11-29 03:53:23,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:23,704][root][INFO] - Training Epoch: 7/10, step 441/574 completed (loss: 2.1556007862091064, acc: 0.4399999976158142)
[2024-11-29 03:53:23,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:24,301][root][INFO] - Training Epoch: 7/10, step 442/574 completed (loss: 1.5498958826065063, acc: 0.5483871102333069)
[2024-11-29 03:53:24,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:24,915][root][INFO] - Training Epoch: 7/10, step 443/574 completed (loss: 1.9120540618896484, acc: 0.46766167879104614)
[2024-11-29 03:53:24,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:25,510][root][INFO] - Training Epoch: 7/10, step 444/574 completed (loss: 0.5256026387214661, acc: 0.8679245114326477)
[2024-11-29 03:53:25,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:26,102][root][INFO] - Training Epoch: 7/10, step 445/574 completed (loss: 0.473614901304245, acc: 0.8181818127632141)
[2024-11-29 03:53:26,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:26,689][root][INFO] - Training Epoch: 7/10, step 446/574 completed (loss: 0.02833414264023304, acc: 1.0)
[2024-11-29 03:53:26,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:27,277][root][INFO] - Training Epoch: 7/10, step 447/574 completed (loss: 0.14983674883842468, acc: 0.9615384340286255)
[2024-11-29 03:53:27,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:27,867][root][INFO] - Training Epoch: 7/10, step 448/574 completed (loss: 0.0811847671866417, acc: 1.0)
[2024-11-29 03:53:27,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:28,458][root][INFO] - Training Epoch: 7/10, step 449/574 completed (loss: 0.6857254505157471, acc: 0.8358209133148193)
[2024-11-29 03:53:28,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:29,050][root][INFO] - Training Epoch: 7/10, step 450/574 completed (loss: 0.6134805083274841, acc: 0.7638888955116272)
[2024-11-29 03:53:29,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:29,642][root][INFO] - Training Epoch: 7/10, step 451/574 completed (loss: 0.7708397507667542, acc: 0.782608687877655)
[2024-11-29 03:53:29,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:30,233][root][INFO] - Training Epoch: 7/10, step 452/574 completed (loss: 0.6267045140266418, acc: 0.807692289352417)
[2024-11-29 03:53:30,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:30,826][root][INFO] - Training Epoch: 7/10, step 453/574 completed (loss: 0.8123587965965271, acc: 0.7763158082962036)
[2024-11-29 03:53:30,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:31,414][root][INFO] - Training Epoch: 7/10, step 454/574 completed (loss: 0.23253004252910614, acc: 0.9591836929321289)
[2024-11-29 03:53:31,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:32,002][root][INFO] - Training Epoch: 7/10, step 455/574 completed (loss: 0.10319963097572327, acc: 0.9696969985961914)
[2024-11-29 03:53:32,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:32,598][root][INFO] - Training Epoch: 7/10, step 456/574 completed (loss: 1.4145901203155518, acc: 0.5979381203651428)
[2024-11-29 03:53:32,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:33,189][root][INFO] - Training Epoch: 7/10, step 457/574 completed (loss: 0.5881718397140503, acc: 0.800000011920929)
[2024-11-29 03:53:33,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:33,811][root][INFO] - Training Epoch: 7/10, step 458/574 completed (loss: 1.782383918762207, acc: 0.5406976938247681)
[2024-11-29 03:53:33,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:34,402][root][INFO] - Training Epoch: 7/10, step 459/574 completed (loss: 0.4130111038684845, acc: 0.875)
[2024-11-29 03:53:34,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:34,998][root][INFO] - Training Epoch: 7/10, step 460/574 completed (loss: 0.8276612162590027, acc: 0.7777777910232544)
[2024-11-29 03:53:35,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:35,585][root][INFO] - Training Epoch: 7/10, step 461/574 completed (loss: 0.6242508292198181, acc: 0.8055555820465088)
[2024-11-29 03:53:35,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:36,173][root][INFO] - Training Epoch: 7/10, step 462/574 completed (loss: 0.19394569098949432, acc: 0.96875)
[2024-11-29 03:53:36,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:36,761][root][INFO] - Training Epoch: 7/10, step 463/574 completed (loss: 0.31205350160598755, acc: 0.807692289352417)
[2024-11-29 03:53:36,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:37,354][root][INFO] - Training Epoch: 7/10, step 464/574 completed (loss: 0.36085179448127747, acc: 0.8913043737411499)
[2024-11-29 03:53:37,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:37,946][root][INFO] - Training Epoch: 7/10, step 465/574 completed (loss: 0.6311320066452026, acc: 0.8095238208770752)
[2024-11-29 03:53:38,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:38,539][root][INFO] - Training Epoch: 7/10, step 466/574 completed (loss: 0.8919593095779419, acc: 0.8072289228439331)
[2024-11-29 03:53:38,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:39,150][root][INFO] - Training Epoch: 7/10, step 467/574 completed (loss: 1.0973979234695435, acc: 0.7117117047309875)
[2024-11-29 03:53:39,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:39,744][root][INFO] - Training Epoch: 7/10, step 468/574 completed (loss: 1.091784119606018, acc: 0.6407766938209534)
[2024-11-29 03:53:39,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:40,356][root][INFO] - Training Epoch: 7/10, step 469/574 completed (loss: 1.3240569829940796, acc: 0.6178861856460571)
[2024-11-29 03:53:40,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:40,945][root][INFO] - Training Epoch: 7/10, step 470/574 completed (loss: 0.021850474178791046, acc: 1.0)
[2024-11-29 03:53:41,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:41,534][root][INFO] - Training Epoch: 7/10, step 471/574 completed (loss: 0.2550618350505829, acc: 0.8928571343421936)
[2024-11-29 03:53:41,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:42,150][root][INFO] - Training Epoch: 7/10, step 472/574 completed (loss: 1.4661449193954468, acc: 0.5686274766921997)
[2024-11-29 03:53:42,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:42,765][root][INFO] - Training Epoch: 7/10, step 473/574 completed (loss: 1.8914991617202759, acc: 0.5196506381034851)
[2024-11-29 03:53:42,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:43,360][root][INFO] - Training Epoch: 7/10, step 474/574 completed (loss: 0.989919126033783, acc: 0.7083333134651184)
[2024-11-29 03:53:43,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:43,957][root][INFO] - Training Epoch: 7/10, step 475/574 completed (loss: 1.3873554468154907, acc: 0.5828220844268799)
[2024-11-29 03:53:44,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:44,554][root][INFO] - Training Epoch: 7/10, step 476/574 completed (loss: 1.2073781490325928, acc: 0.7122302055358887)
[2024-11-29 03:53:44,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:45,165][root][INFO] - Training Epoch: 7/10, step 477/574 completed (loss: 1.7503865957260132, acc: 0.5577889680862427)
[2024-11-29 03:53:45,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:45,753][root][INFO] - Training Epoch: 7/10, step 478/574 completed (loss: 0.26388663053512573, acc: 0.9444444179534912)
[2024-11-29 03:53:45,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:46,341][root][INFO] - Training Epoch: 7/10, step 479/574 completed (loss: 0.3772026300430298, acc: 0.8787878751754761)
[2024-11-29 03:53:46,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:46,929][root][INFO] - Training Epoch: 7/10, step 480/574 completed (loss: 0.09991039335727692, acc: 0.9629629850387573)
[2024-11-29 03:53:47,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:47,517][root][INFO] - Training Epoch: 7/10, step 481/574 completed (loss: 0.09468117356300354, acc: 0.949999988079071)
[2024-11-29 03:53:47,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:48,104][root][INFO] - Training Epoch: 7/10, step 482/574 completed (loss: 0.039072535932064056, acc: 1.0)
[2024-11-29 03:53:48,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:48,701][root][INFO] - Training Epoch: 7/10, step 483/574 completed (loss: 0.9998544454574585, acc: 0.7586206793785095)
[2024-11-29 03:53:48,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:49,289][root][INFO] - Training Epoch: 7/10, step 484/574 completed (loss: 0.26564666628837585, acc: 0.9354838728904724)
[2024-11-29 03:53:49,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:49,877][root][INFO] - Training Epoch: 7/10, step 485/574 completed (loss: 0.14432522654533386, acc: 0.9473684430122375)
[2024-11-29 03:53:49,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:50,467][root][INFO] - Training Epoch: 7/10, step 486/574 completed (loss: 0.48431396484375, acc: 0.8888888955116272)
[2024-11-29 03:53:50,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:51,056][root][INFO] - Training Epoch: 7/10, step 487/574 completed (loss: 0.30056095123291016, acc: 0.9047619104385376)
[2024-11-29 03:53:51,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:51,644][root][INFO] - Training Epoch: 7/10, step 488/574 completed (loss: 0.12441767007112503, acc: 1.0)
[2024-11-29 03:53:51,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:52,237][root][INFO] - Training Epoch: 7/10, step 489/574 completed (loss: 1.0264203548431396, acc: 0.6461538672447205)
[2024-11-29 03:53:52,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:52,825][root][INFO] - Training Epoch: 7/10, step 490/574 completed (loss: 0.19765134155750275, acc: 0.9333333373069763)
[2024-11-29 03:53:52,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:53,413][root][INFO] - Training Epoch: 7/10, step 491/574 completed (loss: 0.12048006802797318, acc: 0.9655172228813171)
[2024-11-29 03:53:53,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:54,005][root][INFO] - Training Epoch: 7/10, step 492/574 completed (loss: 0.3650960624217987, acc: 0.9215686321258545)
[2024-11-29 03:53:54,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:54,593][root][INFO] - Training Epoch: 7/10, step 493/574 completed (loss: 0.2262578010559082, acc: 0.9655172228813171)
[2024-11-29 03:53:54,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:55,180][root][INFO] - Training Epoch: 7/10, step 494/574 completed (loss: 0.016170278191566467, acc: 1.0)
[2024-11-29 03:53:55,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:55,776][root][INFO] - Training Epoch: 7/10, step 495/574 completed (loss: 0.3483717739582062, acc: 0.9473684430122375)
[2024-11-29 03:53:55,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:56,375][root][INFO] - Training Epoch: 7/10, step 496/574 completed (loss: 1.2758944034576416, acc: 0.6964285969734192)
[2024-11-29 03:53:56,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:56,971][root][INFO] - Training Epoch: 7/10, step 497/574 completed (loss: 1.0782628059387207, acc: 0.6404494643211365)
[2024-11-29 03:53:57,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:57,566][root][INFO] - Training Epoch: 7/10, step 498/574 completed (loss: 1.1424368619918823, acc: 0.6741573214530945)
[2024-11-29 03:53:57,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:58,175][root][INFO] - Training Epoch: 7/10, step 499/574 completed (loss: 1.7331792116165161, acc: 0.4893617033958435)
[2024-11-29 03:53:58,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:58,774][root][INFO] - Training Epoch: 7/10, step 500/574 completed (loss: 1.2680941820144653, acc: 0.5760869383811951)
[2024-11-29 03:53:58,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:59,361][root][INFO] - Training Epoch: 7/10, step 501/574 completed (loss: 0.14651915431022644, acc: 0.9599999785423279)
[2024-11-29 03:53:59,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:59,950][root][INFO] - Training Epoch: 7/10, step 502/574 completed (loss: 0.00642580958083272, acc: 1.0)
[2024-11-29 03:54:00,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:00,537][root][INFO] - Training Epoch: 7/10, step 503/574 completed (loss: 0.0233681108802557, acc: 1.0)
[2024-11-29 03:54:00,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:01,126][root][INFO] - Training Epoch: 7/10, step 504/574 completed (loss: 0.12205944210290909, acc: 0.9629629850387573)
[2024-11-29 03:54:01,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:01,716][root][INFO] - Training Epoch: 7/10, step 505/574 completed (loss: 0.6053927540779114, acc: 0.8679245114326477)
[2024-11-29 03:54:01,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:02,303][root][INFO] - Training Epoch: 7/10, step 506/574 completed (loss: 0.14204460382461548, acc: 0.9655172228813171)
[2024-11-29 03:54:02,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:02,901][root][INFO] - Training Epoch: 7/10, step 507/574 completed (loss: 1.2936642169952393, acc: 0.6036036014556885)
[2024-11-29 03:54:02,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:03,496][root][INFO] - Training Epoch: 7/10, step 508/574 completed (loss: 0.5526092052459717, acc: 0.8591549396514893)
[2024-11-29 03:54:03,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:04,082][root][INFO] - Training Epoch: 7/10, step 509/574 completed (loss: 0.007848914712667465, acc: 1.0)
[2024-11-29 03:54:04,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:04,671][root][INFO] - Training Epoch: 7/10, step 510/574 completed (loss: 0.023965734988451004, acc: 1.0)
[2024-11-29 03:54:04,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:05,259][root][INFO] - Training Epoch: 7/10, step 511/574 completed (loss: 0.09721265733242035, acc: 1.0)
[2024-11-29 03:54:05,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:05,894][root][INFO] - Training Epoch: 7/10, step 512/574 completed (loss: 2.0070877075195312, acc: 0.5214285850524902)
[2024-11-29 03:54:05,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:06,505][root][INFO] - Training Epoch: 7/10, step 513/574 completed (loss: 1.419642448425293, acc: 0.5873016119003296)
[2024-11-29 03:54:06,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:07,094][root][INFO] - Training Epoch: 7/10, step 514/574 completed (loss: 0.41188427805900574, acc: 0.8928571343421936)
[2024-11-29 03:54:07,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:07,686][root][INFO] - Training Epoch: 7/10, step 515/574 completed (loss: 0.45883333683013916, acc: 0.8833333253860474)
[2024-11-29 03:54:07,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:08,283][root][INFO] - Training Epoch: 7/10, step 516/574 completed (loss: 1.1701546907424927, acc: 0.6111111044883728)
[2024-11-29 03:54:08,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:08,870][root][INFO] - Training Epoch: 7/10, step 517/574 completed (loss: 0.010888173244893551, acc: 1.0)
[2024-11-29 03:54:08,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:09,459][root][INFO] - Training Epoch: 7/10, step 518/574 completed (loss: 0.2684931457042694, acc: 0.9032257795333862)
[2024-11-29 03:54:09,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:10,044][root][INFO] - Training Epoch: 7/10, step 519/574 completed (loss: 0.044465307146310806, acc: 1.0)
[2024-11-29 03:54:10,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:10,633][root][INFO] - Training Epoch: 7/10, step 520/574 completed (loss: 0.20954710245132446, acc: 0.9629629850387573)
[2024-11-29 03:54:10,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:11,292][root][INFO] - Training Epoch: 7/10, step 521/574 completed (loss: 2.0503363609313965, acc: 0.4576271176338196)
[2024-11-29 03:54:11,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:11,902][root][INFO] - Training Epoch: 7/10, step 522/574 completed (loss: 1.1824616193771362, acc: 0.7014925479888916)
[2024-11-29 03:54:11,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:12,500][root][INFO] - Training Epoch: 7/10, step 523/574 completed (loss: 1.2635436058044434, acc: 0.6277372241020203)
[2024-11-29 03:54:12,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:13,123][root][INFO] - Training Epoch: 7/10, step 524/574 completed (loss: 1.4540104866027832, acc: 0.6100000143051147)
[2024-11-29 03:54:13,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:13,717][root][INFO] - Training Epoch: 7/10, step 525/574 completed (loss: 0.3040013015270233, acc: 0.9074074029922485)
[2024-11-29 03:54:13,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:14,310][root][INFO] - Training Epoch: 7/10, step 526/574 completed (loss: 0.5615575313568115, acc: 0.8461538553237915)
[2024-11-29 03:54:14,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:14,898][root][INFO] - Training Epoch: 7/10, step 527/574 completed (loss: 0.11725939810276031, acc: 0.9523809552192688)
[2024-11-29 03:54:14,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:15,494][root][INFO] - Training Epoch: 7/10, step 528/574 completed (loss: 1.1515308618545532, acc: 0.6721311211585999)
[2024-11-29 03:54:15,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:16,086][root][INFO] - Training Epoch: 7/10, step 529/574 completed (loss: 0.47984760999679565, acc: 0.8305084705352783)
[2024-11-29 03:54:16,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:16,676][root][INFO] - Training Epoch: 7/10, step 530/574 completed (loss: 0.4145900309085846, acc: 0.8837209343910217)
[2024-11-29 03:54:16,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:17,266][root][INFO] - Training Epoch: 7/10, step 531/574 completed (loss: 0.6039143204689026, acc: 0.8409090638160706)
[2024-11-29 03:54:17,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:17,858][root][INFO] - Training Epoch: 7/10, step 532/574 completed (loss: 0.8159588575363159, acc: 0.7358490824699402)
[2024-11-29 03:54:17,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:18,445][root][INFO] - Training Epoch: 7/10, step 533/574 completed (loss: 0.4794953167438507, acc: 0.8181818127632141)
[2024-11-29 03:54:18,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:19,035][root][INFO] - Training Epoch: 7/10, step 534/574 completed (loss: 0.04854016751050949, acc: 1.0)
[2024-11-29 03:54:19,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:19,623][root][INFO] - Training Epoch: 7/10, step 535/574 completed (loss: 0.2330673187971115, acc: 0.949999988079071)
[2024-11-29 03:54:19,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:20,210][root][INFO] - Training Epoch: 7/10, step 536/574 completed (loss: 0.04976062476634979, acc: 1.0)
[2024-11-29 03:54:20,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:20,806][root][INFO] - Training Epoch: 7/10, step 537/574 completed (loss: 0.5666983723640442, acc: 0.8615384697914124)
[2024-11-29 03:54:20,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:21,400][root][INFO] - Training Epoch: 7/10, step 538/574 completed (loss: 0.6860498785972595, acc: 0.8125)
[2024-11-29 03:54:21,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:21,989][root][INFO] - Training Epoch: 7/10, step 539/574 completed (loss: 0.24380770325660706, acc: 0.96875)
[2024-11-29 03:54:22,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:22,578][root][INFO] - Training Epoch: 7/10, step 540/574 completed (loss: 0.22169829905033112, acc: 0.939393937587738)
[2024-11-29 03:54:22,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:23,165][root][INFO] - Training Epoch: 7/10, step 541/574 completed (loss: 0.025357108563184738, acc: 1.0)
[2024-11-29 03:54:23,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:23,754][root][INFO] - Training Epoch: 7/10, step 542/574 completed (loss: 0.03192340210080147, acc: 1.0)
[2024-11-29 03:54:23,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:24,341][root][INFO] - Training Epoch: 7/10, step 543/574 completed (loss: 0.133154034614563, acc: 0.95652174949646)
[2024-11-29 03:54:24,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:24,931][root][INFO] - Training Epoch: 7/10, step 544/574 completed (loss: 0.18380619585514069, acc: 0.9666666388511658)
[2024-11-29 03:54:25,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:25,522][root][INFO] - Training Epoch: 7/10, step 545/574 completed (loss: 0.33928465843200684, acc: 0.9268292784690857)
[2024-11-29 03:54:25,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:26,112][root][INFO] - Training Epoch: 7/10, step 546/574 completed (loss: 0.16019298136234283, acc: 0.9428571462631226)
[2024-11-29 03:54:26,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:26,702][root][INFO] - Training Epoch: 7/10, step 547/574 completed (loss: 0.29107165336608887, acc: 0.9473684430122375)
[2024-11-29 03:54:26,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:27,289][root][INFO] - Training Epoch: 7/10, step 548/574 completed (loss: 0.04276885837316513, acc: 1.0)
[2024-11-29 03:54:27,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:27,878][root][INFO] - Training Epoch: 7/10, step 549/574 completed (loss: 0.06800536811351776, acc: 0.9599999785423279)
[2024-11-29 03:54:27,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:28,469][root][INFO] - Training Epoch: 7/10, step 550/574 completed (loss: 0.3435489535331726, acc: 0.8484848737716675)
[2024-11-29 03:54:28,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:29,059][root][INFO] - Training Epoch: 7/10, step 551/574 completed (loss: 0.17489004135131836, acc: 0.9750000238418579)
[2024-11-29 03:54:29,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:29,651][root][INFO] - Training Epoch: 7/10, step 552/574 completed (loss: 0.35843947529792786, acc: 0.9142857193946838)
[2024-11-29 03:54:29,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:30,261][root][INFO] - Training Epoch: 7/10, step 553/574 completed (loss: 1.5040483474731445, acc: 0.55474454164505)
[2024-11-29 03:54:30,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:30,870][root][INFO] - Training Epoch: 7/10, step 554/574 completed (loss: 1.0999890565872192, acc: 0.7379310131072998)
[2024-11-29 03:54:30,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:31,470][root][INFO] - Training Epoch: 7/10, step 555/574 completed (loss: 1.622118592262268, acc: 0.5642856955528259)
[2024-11-29 03:54:31,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:32,067][root][INFO] - Training Epoch: 7/10, step 556/574 completed (loss: 1.275913119316101, acc: 0.6357616186141968)
[2024-11-29 03:54:32,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:32,662][root][INFO] - Training Epoch: 7/10, step 557/574 completed (loss: 0.8554771542549133, acc: 0.7777777910232544)
[2024-11-29 03:54:32,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:33,249][root][INFO] - Training Epoch: 7/10, step 558/574 completed (loss: 0.027158167213201523, acc: 1.0)
[2024-11-29 03:54:33,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:33,838][root][INFO] - Training Epoch: 7/10, step 559/574 completed (loss: 0.0506201907992363, acc: 1.0)
[2024-11-29 03:54:34,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:35,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:35,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:36,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:36,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:37,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:37,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:38,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:38,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:39,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:39,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:40,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:40,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:41,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:41,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:42,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:42,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:43,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:43,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:44,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:44,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:45,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:46,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:46,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:47,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:47,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:48,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:48,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:49,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:49,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:50,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:50,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:51,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:51,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:52,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:52,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:53,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:53,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:54,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:54,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:55,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:55,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:56,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:57,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:57,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:58,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:58,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:59,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:59,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:00,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:00,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:01,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:01,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:02,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:02,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:03,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:03,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:04,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:05,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:05,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:06,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:06,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:07,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:07,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:08,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:08,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:09,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:09,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:10,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:10,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:11,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:11,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:12,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:12,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:13,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:13,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:14,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:15,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:15,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:16,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:16,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:17,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:17,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:18,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:18,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:19,483][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.7794, device='cuda:0') eval_epoch_loss=tensor(1.3296, device='cuda:0') eval_epoch_acc=tensor(0.6685, device='cuda:0')
[2024-11-29 03:55:19,485][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:55:19,485][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:55:19,742][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_7_step_560_loss_1.3295598030090332/model.pt
[2024-11-29 03:55:19,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:20,362][root][INFO] - Training Epoch: 7/10, step 560/574 completed (loss: 0.013925492763519287, acc: 1.0)
[2024-11-29 03:55:20,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:20,952][root][INFO] - Training Epoch: 7/10, step 561/574 completed (loss: 0.5327250957489014, acc: 0.8974359035491943)
[2024-11-29 03:55:21,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:21,560][root][INFO] - Training Epoch: 7/10, step 562/574 completed (loss: 1.0189043283462524, acc: 0.6888889074325562)
[2024-11-29 03:55:21,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:22,152][root][INFO] - Training Epoch: 7/10, step 563/574 completed (loss: 0.7222790122032166, acc: 0.7922077775001526)
[2024-11-29 03:55:22,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:22,740][root][INFO] - Training Epoch: 7/10, step 564/574 completed (loss: 0.3658849895000458, acc: 0.9166666865348816)
[2024-11-29 03:55:22,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:23,331][root][INFO] - Training Epoch: 7/10, step 565/574 completed (loss: 0.29422110319137573, acc: 0.8620689511299133)
[2024-11-29 03:55:23,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:23,930][root][INFO] - Training Epoch: 7/10, step 566/574 completed (loss: 0.8580658435821533, acc: 0.7142857313156128)
[2024-11-29 03:55:24,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:24,519][root][INFO] - Training Epoch: 7/10, step 567/574 completed (loss: 0.1704941987991333, acc: 0.9736841917037964)
[2024-11-29 03:55:24,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:25,109][root][INFO] - Training Epoch: 7/10, step 568/574 completed (loss: 0.10995923727750778, acc: 0.9629629850387573)
[2024-11-29 03:55:25,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:25,735][root][INFO] - Training Epoch: 7/10, step 569/574 completed (loss: 1.57793390750885, acc: 0.5614973306655884)
[2024-11-29 03:55:25,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:26,324][root][INFO] - Training Epoch: 7/10, step 570/574 completed (loss: 0.33403903245925903, acc: 0.8870967626571655)
[2024-11-29 03:55:26,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:26,921][root][INFO] - Training Epoch: 7/10, step 571/574 completed (loss: 1.1074352264404297, acc: 0.7350427508354187)
[2024-11-29 03:55:27,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:27,532][root][INFO] - Training Epoch: 7/10, step 572/574 completed (loss: 1.9001623392105103, acc: 0.5102040767669678)
[2024-11-29 03:55:27,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:28,144][root][INFO] - Training Epoch: 7/10, step 573/574 completed (loss: 1.7368639707565308, acc: 0.49685534834861755)
[2024-11-29 03:55:28,456][slam_llm.utils.train_utils][INFO] - Epoch 7: train_perplexity=2.0533, train_epoch_loss=0.7194, epoch time 525.8757535256445s
[2024-11-29 03:55:28,456][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 15 GB
[2024-11-29 03:55:28,456][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-29 03:55:28,457][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 15 GB
[2024-11-29 03:55:28,457][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 6
[2024-11-29 03:55:28,457][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-29 03:55:28,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:29,507][root][INFO] - Training Epoch: 8/10, step 0/574 completed (loss: 0.30271849036216736, acc: 0.9259259104728699)
[2024-11-29 03:55:29,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:30,093][root][INFO] - Training Epoch: 8/10, step 1/574 completed (loss: 0.06846357136964798, acc: 0.9599999785423279)
[2024-11-29 03:55:30,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:30,681][root][INFO] - Training Epoch: 8/10, step 2/574 completed (loss: 0.26119527220726013, acc: 0.9189189076423645)
[2024-11-29 03:55:30,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:31,270][root][INFO] - Training Epoch: 8/10, step 3/574 completed (loss: 0.19217082858085632, acc: 0.9736841917037964)
[2024-11-29 03:55:31,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:31,859][root][INFO] - Training Epoch: 8/10, step 4/574 completed (loss: 0.2648623585700989, acc: 0.9189189076423645)
[2024-11-29 03:55:31,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:32,447][root][INFO] - Training Epoch: 8/10, step 5/574 completed (loss: 0.19131256639957428, acc: 0.9285714030265808)
[2024-11-29 03:55:32,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:33,035][root][INFO] - Training Epoch: 8/10, step 6/574 completed (loss: 0.6095722913742065, acc: 0.8571428656578064)
[2024-11-29 03:55:33,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:33,623][root][INFO] - Training Epoch: 8/10, step 7/574 completed (loss: 0.11040015518665314, acc: 0.9666666388511658)
[2024-11-29 03:55:33,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:34,212][root][INFO] - Training Epoch: 8/10, step 8/574 completed (loss: 0.005121794994920492, acc: 1.0)
[2024-11-29 03:55:34,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:34,800][root][INFO] - Training Epoch: 8/10, step 9/574 completed (loss: 0.009930768050253391, acc: 1.0)
[2024-11-29 03:55:34,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:35,387][root][INFO] - Training Epoch: 8/10, step 10/574 completed (loss: 0.037268154323101044, acc: 1.0)
[2024-11-29 03:55:35,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:35,974][root][INFO] - Training Epoch: 8/10, step 11/574 completed (loss: 0.4663708508014679, acc: 0.8974359035491943)
[2024-11-29 03:55:36,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:36,562][root][INFO] - Training Epoch: 8/10, step 12/574 completed (loss: 0.5371442437171936, acc: 0.8484848737716675)
[2024-11-29 03:55:36,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:37,152][root][INFO] - Training Epoch: 8/10, step 13/574 completed (loss: 0.45391708612442017, acc: 0.8913043737411499)
[2024-11-29 03:55:37,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:37,741][root][INFO] - Training Epoch: 8/10, step 14/574 completed (loss: 0.2864739000797272, acc: 0.9215686321258545)
[2024-11-29 03:55:37,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:38,330][root][INFO] - Training Epoch: 8/10, step 15/574 completed (loss: 0.6283305883407593, acc: 0.8775510191917419)
[2024-11-29 03:55:38,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:38,914][root][INFO] - Training Epoch: 8/10, step 16/574 completed (loss: 0.04267608001828194, acc: 1.0)
[2024-11-29 03:55:38,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:39,499][root][INFO] - Training Epoch: 8/10, step 17/574 completed (loss: 0.20677225291728973, acc: 0.9583333134651184)
[2024-11-29 03:55:39,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:40,085][root][INFO] - Training Epoch: 8/10, step 18/574 completed (loss: 0.2621976137161255, acc: 0.9166666865348816)
[2024-11-29 03:55:40,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:40,672][root][INFO] - Training Epoch: 8/10, step 19/574 completed (loss: 0.007956120185554028, acc: 1.0)
[2024-11-29 03:55:40,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:41,259][root][INFO] - Training Epoch: 8/10, step 20/574 completed (loss: 0.2176520824432373, acc: 0.8846153616905212)
[2024-11-29 03:55:41,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:41,846][root][INFO] - Training Epoch: 8/10, step 21/574 completed (loss: 0.3710513710975647, acc: 0.8275862336158752)
[2024-11-29 03:55:41,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:42,432][root][INFO] - Training Epoch: 8/10, step 22/574 completed (loss: 0.22143962979316711, acc: 0.9200000166893005)
[2024-11-29 03:55:42,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:43,018][root][INFO] - Training Epoch: 8/10, step 23/574 completed (loss: 0.13238875567913055, acc: 0.9523809552192688)
[2024-11-29 03:55:43,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:43,603][root][INFO] - Training Epoch: 8/10, step 24/574 completed (loss: 0.07413670420646667, acc: 0.9375)
[2024-11-29 03:55:43,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:44,195][root][INFO] - Training Epoch: 8/10, step 25/574 completed (loss: 1.0274360179901123, acc: 0.7358490824699402)
[2024-11-29 03:55:44,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:44,785][root][INFO] - Training Epoch: 8/10, step 26/574 completed (loss: 1.0101152658462524, acc: 0.7123287916183472)
[2024-11-29 03:55:44,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:45,459][root][INFO] - Training Epoch: 8/10, step 27/574 completed (loss: 2.413123369216919, acc: 0.4466403126716614)
[2024-11-29 03:55:45,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:46,047][root][INFO] - Training Epoch: 8/10, step 28/574 completed (loss: 0.7694796323776245, acc: 0.7441860437393188)
[2024-11-29 03:55:46,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:46,640][root][INFO] - Training Epoch: 8/10, step 29/574 completed (loss: 1.0088218450546265, acc: 0.7831325531005859)
[2024-11-29 03:55:46,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:47,236][root][INFO] - Training Epoch: 8/10, step 30/574 completed (loss: 1.2935140132904053, acc: 0.6790123581886292)
[2024-11-29 03:55:47,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:47,822][root][INFO] - Training Epoch: 8/10, step 31/574 completed (loss: 0.46020394563674927, acc: 0.8571428656578064)
[2024-11-29 03:55:47,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:48,406][root][INFO] - Training Epoch: 8/10, step 32/574 completed (loss: 0.22734838724136353, acc: 0.9259259104728699)
[2024-11-29 03:55:48,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:48,990][root][INFO] - Training Epoch: 8/10, step 33/574 completed (loss: 0.06772736459970474, acc: 1.0)
[2024-11-29 03:55:49,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:49,587][root][INFO] - Training Epoch: 8/10, step 34/574 completed (loss: 1.1623821258544922, acc: 0.7310924530029297)
[2024-11-29 03:55:49,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:50,179][root][INFO] - Training Epoch: 8/10, step 35/574 completed (loss: 0.9327393770217896, acc: 0.7704917788505554)
[2024-11-29 03:55:50,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:50,773][root][INFO] - Training Epoch: 8/10, step 36/574 completed (loss: 0.7458004355430603, acc: 0.761904776096344)
[2024-11-29 03:55:50,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:51,364][root][INFO] - Training Epoch: 8/10, step 37/574 completed (loss: 0.6751096844673157, acc: 0.7966101765632629)
[2024-11-29 03:55:51,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:51,957][root][INFO] - Training Epoch: 8/10, step 38/574 completed (loss: 0.7390151023864746, acc: 0.7356321811676025)
[2024-11-29 03:55:52,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:52,546][root][INFO] - Training Epoch: 8/10, step 39/574 completed (loss: 0.023170992732048035, acc: 1.0)
[2024-11-29 03:55:52,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:53,133][root][INFO] - Training Epoch: 8/10, step 40/574 completed (loss: 0.14176997542381287, acc: 0.9615384340286255)
[2024-11-29 03:55:53,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:53,727][root][INFO] - Training Epoch: 8/10, step 41/574 completed (loss: 1.2807931900024414, acc: 0.6891891956329346)
[2024-11-29 03:55:53,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:54,317][root][INFO] - Training Epoch: 8/10, step 42/574 completed (loss: 0.784045398235321, acc: 0.7846153974533081)
[2024-11-29 03:55:54,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:54,911][root][INFO] - Training Epoch: 8/10, step 43/574 completed (loss: 1.172669529914856, acc: 0.6969696879386902)
[2024-11-29 03:55:54,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:55,505][root][INFO] - Training Epoch: 8/10, step 44/574 completed (loss: 1.1518468856811523, acc: 0.6804123520851135)
[2024-11-29 03:55:55,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:56,104][root][INFO] - Training Epoch: 8/10, step 45/574 completed (loss: 1.6923271417617798, acc: 0.5661764740943909)
[2024-11-29 03:55:56,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:56,689][root][INFO] - Training Epoch: 8/10, step 46/574 completed (loss: 0.01582462340593338, acc: 1.0)
[2024-11-29 03:55:56,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:57,276][root][INFO] - Training Epoch: 8/10, step 47/574 completed (loss: 0.12930269539356232, acc: 0.9629629850387573)
[2024-11-29 03:55:57,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:57,864][root][INFO] - Training Epoch: 8/10, step 48/574 completed (loss: 0.07536322623491287, acc: 1.0)
[2024-11-29 03:55:57,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:58,451][root][INFO] - Training Epoch: 8/10, step 49/574 completed (loss: 0.14967979490756989, acc: 0.9722222089767456)
[2024-11-29 03:55:58,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:59,042][root][INFO] - Training Epoch: 8/10, step 50/574 completed (loss: 0.41870516538619995, acc: 0.8771929740905762)
[2024-11-29 03:55:59,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:59,638][root][INFO] - Training Epoch: 8/10, step 51/574 completed (loss: 0.8112632632255554, acc: 0.761904776096344)
[2024-11-29 03:55:59,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:00,232][root][INFO] - Training Epoch: 8/10, step 52/574 completed (loss: 0.8533422350883484, acc: 0.8169013857841492)
[2024-11-29 03:56:00,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:00,846][root][INFO] - Training Epoch: 8/10, step 53/574 completed (loss: 2.1612277030944824, acc: 0.4933333396911621)
[2024-11-29 03:56:00,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:01,432][root][INFO] - Training Epoch: 8/10, step 54/574 completed (loss: 0.2038227617740631, acc: 0.9729729890823364)
[2024-11-29 03:56:01,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:02,016][root][INFO] - Training Epoch: 8/10, step 55/574 completed (loss: 0.10271680355072021, acc: 1.0)
[2024-11-29 03:56:02,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:02,714][root][INFO] - Training Epoch: 8/10, step 56/574 completed (loss: 2.078705072402954, acc: 0.4778156876564026)
[2024-11-29 03:56:02,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:03,368][root][INFO] - Training Epoch: 8/10, step 57/574 completed (loss: 2.5412657260894775, acc: 0.4095860421657562)
[2024-11-29 03:56:03,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:03,981][root][INFO] - Training Epoch: 8/10, step 58/574 completed (loss: 1.6578770875930786, acc: 0.5625)
[2024-11-29 03:56:04,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:04,578][root][INFO] - Training Epoch: 8/10, step 59/574 completed (loss: 1.7046128511428833, acc: 0.5808823704719543)
[2024-11-29 03:56:04,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:05,191][root][INFO] - Training Epoch: 8/10, step 60/574 completed (loss: 1.682557463645935, acc: 0.52173912525177)
[2024-11-29 03:56:05,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:05,799][root][INFO] - Training Epoch: 8/10, step 61/574 completed (loss: 1.269923448562622, acc: 0.675000011920929)
[2024-11-29 03:56:05,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:06,384][root][INFO] - Training Epoch: 8/10, step 62/574 completed (loss: 0.3340618908405304, acc: 0.9117646813392639)
[2024-11-29 03:56:06,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:06,972][root][INFO] - Training Epoch: 8/10, step 63/574 completed (loss: 0.6164787411689758, acc: 0.7777777910232544)
[2024-11-29 03:56:07,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:07,568][root][INFO] - Training Epoch: 8/10, step 64/574 completed (loss: 0.5770415663719177, acc: 0.84375)
[2024-11-29 03:56:07,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:08,154][root][INFO] - Training Epoch: 8/10, step 65/574 completed (loss: 0.10464486479759216, acc: 0.9655172228813171)
[2024-11-29 03:56:08,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:08,745][root][INFO] - Training Epoch: 8/10, step 66/574 completed (loss: 0.5246607065200806, acc: 0.8214285969734192)
[2024-11-29 03:56:08,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:09,338][root][INFO] - Training Epoch: 8/10, step 67/574 completed (loss: 0.6064823269844055, acc: 0.7833333611488342)
[2024-11-29 03:56:09,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:09,926][root][INFO] - Training Epoch: 8/10, step 68/574 completed (loss: 0.02310345321893692, acc: 1.0)
[2024-11-29 03:56:10,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:10,514][root][INFO] - Training Epoch: 8/10, step 69/574 completed (loss: 0.6261504292488098, acc: 0.8055555820465088)
[2024-11-29 03:56:10,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:11,102][root][INFO] - Training Epoch: 8/10, step 70/574 completed (loss: 0.13534216582775116, acc: 0.9696969985961914)
[2024-11-29 03:56:11,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:11,712][root][INFO] - Training Epoch: 8/10, step 71/574 completed (loss: 1.7578551769256592, acc: 0.5220588445663452)
[2024-11-29 03:56:11,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:12,306][root][INFO] - Training Epoch: 8/10, step 72/574 completed (loss: 1.1568692922592163, acc: 0.6746031641960144)
[2024-11-29 03:56:12,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:12,919][root][INFO] - Training Epoch: 8/10, step 73/574 completed (loss: 2.105372190475464, acc: 0.4871794879436493)
[2024-11-29 03:56:12,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:13,514][root][INFO] - Training Epoch: 8/10, step 74/574 completed (loss: 1.189560055732727, acc: 0.6020408272743225)
[2024-11-29 03:56:13,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:14,112][root][INFO] - Training Epoch: 8/10, step 75/574 completed (loss: 1.574893593788147, acc: 0.5820895433425903)
[2024-11-29 03:56:14,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:14,738][root][INFO] - Training Epoch: 8/10, step 76/574 completed (loss: 2.225031852722168, acc: 0.4051094949245453)
[2024-11-29 03:56:14,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:15,323][root][INFO] - Training Epoch: 8/10, step 77/574 completed (loss: 0.013611851260066032, acc: 1.0)
[2024-11-29 03:56:15,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:15,908][root][INFO] - Training Epoch: 8/10, step 78/574 completed (loss: 0.006919535342603922, acc: 1.0)
[2024-11-29 03:56:15,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:16,494][root][INFO] - Training Epoch: 8/10, step 79/574 completed (loss: 0.10169760882854462, acc: 0.9696969985961914)
[2024-11-29 03:56:16,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:17,081][root][INFO] - Training Epoch: 8/10, step 80/574 completed (loss: 0.06474459171295166, acc: 0.9615384340286255)
[2024-11-29 03:56:17,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:17,672][root][INFO] - Training Epoch: 8/10, step 81/574 completed (loss: 0.5269472002983093, acc: 0.8461538553237915)
[2024-11-29 03:56:17,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:18,265][root][INFO] - Training Epoch: 8/10, step 82/574 completed (loss: 0.35954511165618896, acc: 0.9230769276618958)
[2024-11-29 03:56:18,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:18,853][root][INFO] - Training Epoch: 8/10, step 83/574 completed (loss: 0.36019206047058105, acc: 0.84375)
[2024-11-29 03:56:18,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:19,445][root][INFO] - Training Epoch: 8/10, step 84/574 completed (loss: 0.5342903137207031, acc: 0.8550724387168884)
[2024-11-29 03:56:19,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:20,037][root][INFO] - Training Epoch: 8/10, step 85/574 completed (loss: 0.5145043730735779, acc: 0.8600000143051147)
[2024-11-29 03:56:20,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:20,628][root][INFO] - Training Epoch: 8/10, step 86/574 completed (loss: 0.15458564460277557, acc: 0.95652174949646)
[2024-11-29 03:56:20,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:21,222][root][INFO] - Training Epoch: 8/10, step 87/574 completed (loss: 0.5744892954826355, acc: 0.8600000143051147)
[2024-11-29 03:56:21,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:21,819][root][INFO] - Training Epoch: 8/10, step 88/574 completed (loss: 0.9370058178901672, acc: 0.7475728392601013)
[2024-11-29 03:56:21,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:22,428][root][INFO] - Training Epoch: 8/10, step 89/574 completed (loss: 1.2880573272705078, acc: 0.6747573018074036)
[2024-11-29 03:56:22,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:23,041][root][INFO] - Training Epoch: 8/10, step 90/574 completed (loss: 1.6387686729431152, acc: 0.5268816947937012)
[2024-11-29 03:56:23,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:23,663][root][INFO] - Training Epoch: 8/10, step 91/574 completed (loss: 1.5508553981781006, acc: 0.6034482717514038)
[2024-11-29 03:56:23,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:24,259][root][INFO] - Training Epoch: 8/10, step 92/574 completed (loss: 1.2450330257415771, acc: 0.6526315808296204)
[2024-11-29 03:56:24,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:24,872][root][INFO] - Training Epoch: 8/10, step 93/574 completed (loss: 1.8089923858642578, acc: 0.5148515105247498)
[2024-11-29 03:56:24,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:25,463][root][INFO] - Training Epoch: 8/10, step 94/574 completed (loss: 0.8975681066513062, acc: 0.725806474685669)
[2024-11-29 03:56:25,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:26,053][root][INFO] - Training Epoch: 8/10, step 95/574 completed (loss: 0.5691729784011841, acc: 0.8405796885490417)
[2024-11-29 03:56:26,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:26,649][root][INFO] - Training Epoch: 8/10, step 96/574 completed (loss: 1.4276659488677979, acc: 0.5546218752861023)
[2024-11-29 03:56:26,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:27,244][root][INFO] - Training Epoch: 8/10, step 97/574 completed (loss: 1.3390920162200928, acc: 0.5384615659713745)
[2024-11-29 03:56:27,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:27,842][root][INFO] - Training Epoch: 8/10, step 98/574 completed (loss: 1.748176097869873, acc: 0.525547444820404)
[2024-11-29 03:56:27,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:28,432][root][INFO] - Training Epoch: 8/10, step 99/574 completed (loss: 0.7349064946174622, acc: 0.8208954930305481)
[2024-11-29 03:56:28,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:29,020][root][INFO] - Training Epoch: 8/10, step 100/574 completed (loss: 0.05848618596792221, acc: 1.0)
[2024-11-29 03:56:29,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:29,604][root][INFO] - Training Epoch: 8/10, step 101/574 completed (loss: 0.11427044123411179, acc: 0.9545454382896423)
[2024-11-29 03:56:29,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:30,189][root][INFO] - Training Epoch: 8/10, step 102/574 completed (loss: 0.012006141245365143, acc: 1.0)
[2024-11-29 03:56:30,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:30,778][root][INFO] - Training Epoch: 8/10, step 103/574 completed (loss: 0.30281785130500793, acc: 0.8863636255264282)
[2024-11-29 03:56:30,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:31,370][root][INFO] - Training Epoch: 8/10, step 104/574 completed (loss: 0.5385860800743103, acc: 0.8275862336158752)
[2024-11-29 03:56:31,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:31,958][root][INFO] - Training Epoch: 8/10, step 105/574 completed (loss: 0.12378998845815659, acc: 0.9767441749572754)
[2024-11-29 03:56:32,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:32,548][root][INFO] - Training Epoch: 8/10, step 106/574 completed (loss: 0.015283023938536644, acc: 1.0)
[2024-11-29 03:56:32,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:33,136][root][INFO] - Training Epoch: 8/10, step 107/574 completed (loss: 0.005290401168167591, acc: 1.0)
[2024-11-29 03:56:33,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:33,722][root][INFO] - Training Epoch: 8/10, step 108/574 completed (loss: 0.005489355884492397, acc: 1.0)
[2024-11-29 03:56:33,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:34,311][root][INFO] - Training Epoch: 8/10, step 109/574 completed (loss: 0.3091966509819031, acc: 0.8571428656578064)
[2024-11-29 03:56:34,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:34,904][root][INFO] - Training Epoch: 8/10, step 110/574 completed (loss: 0.5926621556282043, acc: 0.800000011920929)
[2024-11-29 03:56:34,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:35,494][root][INFO] - Training Epoch: 8/10, step 111/574 completed (loss: 0.8260650038719177, acc: 0.7543859481811523)
[2024-11-29 03:56:35,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:36,085][root][INFO] - Training Epoch: 8/10, step 112/574 completed (loss: 0.6375420689582825, acc: 0.8070175647735596)
[2024-11-29 03:56:36,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:36,672][root][INFO] - Training Epoch: 8/10, step 113/574 completed (loss: 0.2998872399330139, acc: 0.9230769276618958)
[2024-11-29 03:56:36,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:37,267][root][INFO] - Training Epoch: 8/10, step 114/574 completed (loss: 0.5470202565193176, acc: 0.8979591727256775)
[2024-11-29 03:56:37,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:37,851][root][INFO] - Training Epoch: 8/10, step 115/574 completed (loss: 0.007858123630285263, acc: 1.0)
[2024-11-29 03:56:37,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:38,447][root][INFO] - Training Epoch: 8/10, step 116/574 completed (loss: 0.995780348777771, acc: 0.682539701461792)
[2024-11-29 03:56:38,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:39,040][root][INFO] - Training Epoch: 8/10, step 117/574 completed (loss: 0.8562174439430237, acc: 0.8048780560493469)
[2024-11-29 03:56:39,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:39,633][root][INFO] - Training Epoch: 8/10, step 118/574 completed (loss: 0.651252031326294, acc: 0.8387096524238586)
[2024-11-29 03:56:39,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:40,272][root][INFO] - Training Epoch: 8/10, step 119/574 completed (loss: 1.8415828943252563, acc: 0.5589353442192078)
[2024-11-29 03:56:40,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:40,865][root][INFO] - Training Epoch: 8/10, step 120/574 completed (loss: 0.4803414046764374, acc: 0.8266666531562805)
[2024-11-29 03:56:40,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:41,458][root][INFO] - Training Epoch: 8/10, step 121/574 completed (loss: 0.5542795658111572, acc: 0.8269230723381042)
[2024-11-29 03:56:41,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:42,042][root][INFO] - Training Epoch: 8/10, step 122/574 completed (loss: 0.009306075982749462, acc: 1.0)
[2024-11-29 03:56:42,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:42,627][root][INFO] - Training Epoch: 8/10, step 123/574 completed (loss: 0.060625407844781876, acc: 1.0)
[2024-11-29 03:56:42,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:43,223][root][INFO] - Training Epoch: 8/10, step 124/574 completed (loss: 1.598610758781433, acc: 0.5521472096443176)
[2024-11-29 03:56:43,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:43,837][root][INFO] - Training Epoch: 8/10, step 125/574 completed (loss: 1.4430487155914307, acc: 0.5902777910232544)
[2024-11-29 03:56:43,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:44,432][root][INFO] - Training Epoch: 8/10, step 126/574 completed (loss: 1.267586350440979, acc: 0.6416666507720947)
[2024-11-29 03:56:44,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:45,052][root][INFO] - Training Epoch: 8/10, step 127/574 completed (loss: 1.8497511148452759, acc: 0.5)
[2024-11-29 03:56:45,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:45,663][root][INFO] - Training Epoch: 8/10, step 128/574 completed (loss: 1.5514391660690308, acc: 0.5538461804389954)
[2024-11-29 03:56:46,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:47,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:47,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:48,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:48,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:49,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:49,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:50,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:50,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:51,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:51,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:52,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:52,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:53,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:53,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:54,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:54,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:55,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:55,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:56,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:57,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:57,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:58,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:58,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:59,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:59,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:00,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:00,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:01,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:01,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:02,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:02,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:03,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:03,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:04,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:04,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:05,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:06,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:06,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:07,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:07,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:08,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:08,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:09,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:09,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:10,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:10,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:11,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:11,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:12,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:12,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:13,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:13,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:14,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:14,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:15,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:16,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:16,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:17,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:17,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:18,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:18,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:19,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:19,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:20,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:20,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:21,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:21,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:22,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:23,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:23,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:24,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:24,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:25,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:25,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:26,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:26,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:27,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:27,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:28,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:28,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:29,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:29,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:30,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:31,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:31,802][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.5625, device='cuda:0') eval_epoch_loss=tensor(1.2705, device='cuda:0') eval_epoch_acc=tensor(0.6996, device='cuda:0')
[2024-11-29 03:57:31,803][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:57:31,803][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:57:32,081][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_8_step_129_loss_1.2704648971557617/model.pt
[2024-11-29 03:57:32,089][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 8 is 0.6996281743049622
[2024-11-29 03:57:32,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:32,731][root][INFO] - Training Epoch: 8/10, step 129/574 completed (loss: 1.4655134677886963, acc: 0.5882353186607361)
[2024-11-29 03:57:32,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:33,319][root][INFO] - Training Epoch: 8/10, step 130/574 completed (loss: 0.059890732169151306, acc: 1.0)
[2024-11-29 03:57:33,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:33,904][root][INFO] - Training Epoch: 8/10, step 131/574 completed (loss: 0.04955369979143143, acc: 1.0)
[2024-11-29 03:57:33,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:34,492][root][INFO] - Training Epoch: 8/10, step 132/574 completed (loss: 0.20865151286125183, acc: 0.96875)
[2024-11-29 03:57:34,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:35,077][root][INFO] - Training Epoch: 8/10, step 133/574 completed (loss: 0.2440056949853897, acc: 0.8695651888847351)
[2024-11-29 03:57:35,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:35,667][root][INFO] - Training Epoch: 8/10, step 134/574 completed (loss: 0.24442557990550995, acc: 0.9714285731315613)
[2024-11-29 03:57:35,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:36,253][root][INFO] - Training Epoch: 8/10, step 135/574 completed (loss: 0.030034264549613, acc: 1.0)
[2024-11-29 03:57:36,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:36,843][root][INFO] - Training Epoch: 8/10, step 136/574 completed (loss: 0.352226197719574, acc: 0.9285714030265808)
[2024-11-29 03:57:36,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:37,430][root][INFO] - Training Epoch: 8/10, step 137/574 completed (loss: 0.2684684097766876, acc: 0.9333333373069763)
[2024-11-29 03:57:37,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:38,017][root][INFO] - Training Epoch: 8/10, step 138/574 completed (loss: 0.1208474338054657, acc: 0.9130434989929199)
[2024-11-29 03:57:38,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:38,601][root][INFO] - Training Epoch: 8/10, step 139/574 completed (loss: 0.1450711041688919, acc: 0.9523809552192688)
[2024-11-29 03:57:38,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:39,188][root][INFO] - Training Epoch: 8/10, step 140/574 completed (loss: 0.19536207616329193, acc: 0.8461538553237915)
[2024-11-29 03:57:39,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:39,775][root][INFO] - Training Epoch: 8/10, step 141/574 completed (loss: 0.2682144045829773, acc: 0.8709677457809448)
[2024-11-29 03:57:39,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:40,363][root][INFO] - Training Epoch: 8/10, step 142/574 completed (loss: 0.7672557830810547, acc: 0.837837815284729)
[2024-11-29 03:57:40,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:40,973][root][INFO] - Training Epoch: 8/10, step 143/574 completed (loss: 1.0513582229614258, acc: 0.6929824352264404)
[2024-11-29 03:57:41,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:41,570][root][INFO] - Training Epoch: 8/10, step 144/574 completed (loss: 1.0148645639419556, acc: 0.7388059496879578)
[2024-11-29 03:57:41,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:42,168][root][INFO] - Training Epoch: 8/10, step 145/574 completed (loss: 1.314868688583374, acc: 0.6224489808082581)
[2024-11-29 03:57:42,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:42,777][root][INFO] - Training Epoch: 8/10, step 146/574 completed (loss: 1.3769118785858154, acc: 0.5744680762290955)
[2024-11-29 03:57:42,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:43,368][root][INFO] - Training Epoch: 8/10, step 147/574 completed (loss: 0.7012444138526917, acc: 0.7428571581840515)
[2024-11-29 03:57:43,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:43,954][root][INFO] - Training Epoch: 8/10, step 148/574 completed (loss: 0.2667190432548523, acc: 0.9285714030265808)
[2024-11-29 03:57:44,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:44,542][root][INFO] - Training Epoch: 8/10, step 149/574 completed (loss: 0.522742748260498, acc: 0.9130434989929199)
[2024-11-29 03:57:44,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:45,128][root][INFO] - Training Epoch: 8/10, step 150/574 completed (loss: 0.42055466771125793, acc: 0.8965517282485962)
[2024-11-29 03:57:45,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:45,718][root][INFO] - Training Epoch: 8/10, step 151/574 completed (loss: 0.5190923810005188, acc: 0.8913043737411499)
[2024-11-29 03:57:45,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:46,311][root][INFO] - Training Epoch: 8/10, step 152/574 completed (loss: 0.7379147410392761, acc: 0.7966101765632629)
[2024-11-29 03:57:46,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:46,902][root][INFO] - Training Epoch: 8/10, step 153/574 completed (loss: 0.5517274141311646, acc: 0.8070175647735596)
[2024-11-29 03:57:46,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:47,495][root][INFO] - Training Epoch: 8/10, step 154/574 completed (loss: 0.6500093936920166, acc: 0.8243243098258972)
[2024-11-29 03:57:47,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:48,082][root][INFO] - Training Epoch: 8/10, step 155/574 completed (loss: 0.05393095687031746, acc: 1.0)
[2024-11-29 03:57:48,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:48,669][root][INFO] - Training Epoch: 8/10, step 156/574 completed (loss: 0.1393556445837021, acc: 0.95652174949646)
[2024-11-29 03:57:48,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:49,257][root][INFO] - Training Epoch: 8/10, step 157/574 completed (loss: 0.33652085065841675, acc: 0.8421052694320679)
[2024-11-29 03:57:49,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:49,849][root][INFO] - Training Epoch: 8/10, step 158/574 completed (loss: 0.7736595273017883, acc: 0.7567567825317383)
[2024-11-29 03:57:49,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:50,440][root][INFO] - Training Epoch: 8/10, step 159/574 completed (loss: 0.6127928495407104, acc: 0.7962962985038757)
[2024-11-29 03:57:50,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:51,033][root][INFO] - Training Epoch: 8/10, step 160/574 completed (loss: 1.0291720628738403, acc: 0.6744186282157898)
[2024-11-29 03:57:51,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:51,625][root][INFO] - Training Epoch: 8/10, step 161/574 completed (loss: 0.49723514914512634, acc: 0.8588235378265381)
[2024-11-29 03:57:51,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:52,220][root][INFO] - Training Epoch: 8/10, step 162/574 completed (loss: 1.141395092010498, acc: 0.7078651785850525)
[2024-11-29 03:57:52,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:52,811][root][INFO] - Training Epoch: 8/10, step 163/574 completed (loss: 0.3991861045360565, acc: 0.9090909361839294)
[2024-11-29 03:57:52,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:53,397][root][INFO] - Training Epoch: 8/10, step 164/574 completed (loss: 0.563565731048584, acc: 0.9047619104385376)
[2024-11-29 03:57:53,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:53,985][root][INFO] - Training Epoch: 8/10, step 165/574 completed (loss: 0.17265278100967407, acc: 0.9655172228813171)
[2024-11-29 03:57:54,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:54,577][root][INFO] - Training Epoch: 8/10, step 166/574 completed (loss: 0.18212884664535522, acc: 0.9387755393981934)
[2024-11-29 03:57:54,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:55,169][root][INFO] - Training Epoch: 8/10, step 167/574 completed (loss: 0.17430797219276428, acc: 0.9399999976158142)
[2024-11-29 03:57:55,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:55,762][root][INFO] - Training Epoch: 8/10, step 168/574 completed (loss: 0.8653067350387573, acc: 0.7222222089767456)
[2024-11-29 03:57:55,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:56,358][root][INFO] - Training Epoch: 8/10, step 169/574 completed (loss: 1.5776584148406982, acc: 0.6176470518112183)
[2024-11-29 03:57:56,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:56,980][root][INFO] - Training Epoch: 8/10, step 170/574 completed (loss: 2.249845266342163, acc: 0.4452054798603058)
[2024-11-29 03:57:57,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:57,566][root][INFO] - Training Epoch: 8/10, step 171/574 completed (loss: 0.7791236042976379, acc: 0.9166666865348816)
[2024-11-29 03:57:57,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:58,155][root][INFO] - Training Epoch: 8/10, step 172/574 completed (loss: 0.2625117599964142, acc: 0.9259259104728699)
[2024-11-29 03:57:58,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:58,741][root][INFO] - Training Epoch: 8/10, step 173/574 completed (loss: 0.3454670011997223, acc: 0.9285714030265808)
[2024-11-29 03:57:58,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:59,359][root][INFO] - Training Epoch: 8/10, step 174/574 completed (loss: 1.3402177095413208, acc: 0.6637167930603027)
[2024-11-29 03:57:59,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:59,952][root][INFO] - Training Epoch: 8/10, step 175/574 completed (loss: 0.6660893559455872, acc: 0.782608687877655)
[2024-11-29 03:58:00,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:00,547][root][INFO] - Training Epoch: 8/10, step 176/574 completed (loss: 0.940665066242218, acc: 0.7613636255264282)
[2024-11-29 03:58:00,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:01,160][root][INFO] - Training Epoch: 8/10, step 177/574 completed (loss: 1.921987533569336, acc: 0.442748099565506)
[2024-11-29 03:58:01,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:01,771][root][INFO] - Training Epoch: 8/10, step 178/574 completed (loss: 1.903060793876648, acc: 0.4592592716217041)
[2024-11-29 03:58:01,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:02,365][root][INFO] - Training Epoch: 8/10, step 179/574 completed (loss: 0.6100211143493652, acc: 0.7704917788505554)
[2024-11-29 03:58:02,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:02,955][root][INFO] - Training Epoch: 8/10, step 180/574 completed (loss: 0.06644291430711746, acc: 0.9583333134651184)
[2024-11-29 03:58:03,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:03,545][root][INFO] - Training Epoch: 8/10, step 181/574 completed (loss: 0.04026104882359505, acc: 1.0)
[2024-11-29 03:58:03,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:04,132][root][INFO] - Training Epoch: 8/10, step 182/574 completed (loss: 0.058465007692575455, acc: 1.0)
[2024-11-29 03:58:04,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:04,729][root][INFO] - Training Epoch: 8/10, step 183/574 completed (loss: 0.9713929295539856, acc: 0.7439024448394775)
[2024-11-29 03:58:04,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:05,356][root][INFO] - Training Epoch: 8/10, step 184/574 completed (loss: 1.9681146144866943, acc: 0.4864048361778259)
[2024-11-29 03:58:05,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:05,983][root][INFO] - Training Epoch: 8/10, step 185/574 completed (loss: 2.191958427429199, acc: 0.409221887588501)
[2024-11-29 03:58:06,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:06,606][root][INFO] - Training Epoch: 8/10, step 186/574 completed (loss: 2.220526695251465, acc: 0.4312500059604645)
[2024-11-29 03:58:06,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:07,271][root][INFO] - Training Epoch: 8/10, step 187/574 completed (loss: 2.3620853424072266, acc: 0.38461539149284363)
[2024-11-29 03:58:07,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:07,905][root][INFO] - Training Epoch: 8/10, step 188/574 completed (loss: 1.877686858177185, acc: 0.4839857518672943)
[2024-11-29 03:58:07,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:08,494][root][INFO] - Training Epoch: 8/10, step 189/574 completed (loss: 0.5449865460395813, acc: 0.9200000166893005)
[2024-11-29 03:58:08,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:09,089][root][INFO] - Training Epoch: 8/10, step 190/574 completed (loss: 1.5054808855056763, acc: 0.5813953280448914)
[2024-11-29 03:58:09,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:09,685][root][INFO] - Training Epoch: 8/10, step 191/574 completed (loss: 1.5405274629592896, acc: 0.6269841194152832)
[2024-11-29 03:58:09,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:10,283][root][INFO] - Training Epoch: 8/10, step 192/574 completed (loss: 1.9250742197036743, acc: 0.46212121844291687)
[2024-11-29 03:58:10,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:10,878][root][INFO] - Training Epoch: 8/10, step 193/574 completed (loss: 0.9523625373840332, acc: 0.6705882549285889)
[2024-11-29 03:58:10,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:11,491][root][INFO] - Training Epoch: 8/10, step 194/574 completed (loss: 1.5662569999694824, acc: 0.5617284178733826)
[2024-11-29 03:58:11,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:12,089][root][INFO] - Training Epoch: 8/10, step 195/574 completed (loss: 0.9245629906654358, acc: 0.6774193644523621)
[2024-11-29 03:58:12,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:12,678][root][INFO] - Training Epoch: 8/10, step 196/574 completed (loss: 0.13929307460784912, acc: 0.9642857313156128)
[2024-11-29 03:58:12,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:13,267][root][INFO] - Training Epoch: 8/10, step 197/574 completed (loss: 0.366081178188324, acc: 0.875)
[2024-11-29 03:58:13,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:13,859][root][INFO] - Training Epoch: 8/10, step 198/574 completed (loss: 0.8519677519798279, acc: 0.7352941036224365)
[2024-11-29 03:58:13,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:14,460][root][INFO] - Training Epoch: 8/10, step 199/574 completed (loss: 1.5298359394073486, acc: 0.5808823704719543)
[2024-11-29 03:58:14,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:15,055][root][INFO] - Training Epoch: 8/10, step 200/574 completed (loss: 1.2244282960891724, acc: 0.6101694703102112)
[2024-11-29 03:58:15,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:15,654][root][INFO] - Training Epoch: 8/10, step 201/574 completed (loss: 1.3674434423446655, acc: 0.6343283653259277)
[2024-11-29 03:58:15,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:16,250][root][INFO] - Training Epoch: 8/10, step 202/574 completed (loss: 1.067042350769043, acc: 0.6601941585540771)
[2024-11-29 03:58:16,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:16,846][root][INFO] - Training Epoch: 8/10, step 203/574 completed (loss: 1.1694910526275635, acc: 0.7301587462425232)
[2024-11-29 03:58:16,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:17,440][root][INFO] - Training Epoch: 8/10, step 204/574 completed (loss: 0.6296588182449341, acc: 0.8021978139877319)
[2024-11-29 03:58:17,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:18,060][root][INFO] - Training Epoch: 8/10, step 205/574 completed (loss: 1.5147322416305542, acc: 0.5829596519470215)
[2024-11-29 03:58:18,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:18,686][root][INFO] - Training Epoch: 8/10, step 206/574 completed (loss: 1.6824592351913452, acc: 0.5433070659637451)
[2024-11-29 03:58:18,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:19,304][root][INFO] - Training Epoch: 8/10, step 207/574 completed (loss: 1.456968903541565, acc: 0.6034482717514038)
[2024-11-29 03:58:19,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:19,920][root][INFO] - Training Epoch: 8/10, step 208/574 completed (loss: 1.6902186870574951, acc: 0.5507246255874634)
[2024-11-29 03:58:19,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:20,539][root][INFO] - Training Epoch: 8/10, step 209/574 completed (loss: 1.7151421308517456, acc: 0.5214007496833801)
[2024-11-29 03:58:20,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:21,154][root][INFO] - Training Epoch: 8/10, step 210/574 completed (loss: 1.7055214643478394, acc: 0.5)
[2024-11-29 03:58:21,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:21,744][root][INFO] - Training Epoch: 8/10, step 211/574 completed (loss: 0.11874399334192276, acc: 1.0)
[2024-11-29 03:58:21,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:22,329][root][INFO] - Training Epoch: 8/10, step 212/574 completed (loss: 0.10859847068786621, acc: 0.9642857313156128)
[2024-11-29 03:58:22,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:22,923][root][INFO] - Training Epoch: 8/10, step 213/574 completed (loss: 0.5345243811607361, acc: 0.8936170339584351)
[2024-11-29 03:58:23,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:23,532][root][INFO] - Training Epoch: 8/10, step 214/574 completed (loss: 1.1591671705245972, acc: 0.6846153736114502)
[2024-11-29 03:58:23,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:24,124][root][INFO] - Training Epoch: 8/10, step 215/574 completed (loss: 0.3211629092693329, acc: 0.8783783912658691)
[2024-11-29 03:58:24,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:24,717][root][INFO] - Training Epoch: 8/10, step 216/574 completed (loss: 0.33739814162254333, acc: 0.8720930218696594)
[2024-11-29 03:58:24,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:25,314][root][INFO] - Training Epoch: 8/10, step 217/574 completed (loss: 0.8710487484931946, acc: 0.7567567825317383)
[2024-11-29 03:58:25,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:25,910][root][INFO] - Training Epoch: 8/10, step 218/574 completed (loss: 0.6852632164955139, acc: 0.8666666746139526)
[2024-11-29 03:58:25,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:26,498][root][INFO] - Training Epoch: 8/10, step 219/574 completed (loss: 0.12935316562652588, acc: 0.939393937587738)
[2024-11-29 03:58:26,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:27,086][root][INFO] - Training Epoch: 8/10, step 220/574 completed (loss: 0.008325469680130482, acc: 1.0)
[2024-11-29 03:58:27,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:27,673][root][INFO] - Training Epoch: 8/10, step 221/574 completed (loss: 0.03277292847633362, acc: 1.0)
[2024-11-29 03:58:27,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:28,266][root][INFO] - Training Epoch: 8/10, step 222/574 completed (loss: 0.7883192300796509, acc: 0.7884615659713745)
[2024-11-29 03:58:28,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:28,879][root][INFO] - Training Epoch: 8/10, step 223/574 completed (loss: 1.3861199617385864, acc: 0.6847826242446899)
[2024-11-29 03:58:28,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:29,490][root][INFO] - Training Epoch: 8/10, step 224/574 completed (loss: 1.405651569366455, acc: 0.5965909361839294)
[2024-11-29 03:58:29,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:30,104][root][INFO] - Training Epoch: 8/10, step 225/574 completed (loss: 1.483960747718811, acc: 0.5957446694374084)
[2024-11-29 03:58:30,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:30,692][root][INFO] - Training Epoch: 8/10, step 226/574 completed (loss: 0.29819732904434204, acc: 0.9622641801834106)
[2024-11-29 03:58:30,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:31,284][root][INFO] - Training Epoch: 8/10, step 227/574 completed (loss: 0.577206552028656, acc: 0.800000011920929)
[2024-11-29 03:58:31,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:31,876][root][INFO] - Training Epoch: 8/10, step 228/574 completed (loss: 0.2889629304409027, acc: 0.9069767594337463)
[2024-11-29 03:58:31,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:32,463][root][INFO] - Training Epoch: 8/10, step 229/574 completed (loss: 0.04967343434691429, acc: 1.0)
[2024-11-29 03:58:32,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:33,065][root][INFO] - Training Epoch: 8/10, step 230/574 completed (loss: 1.6173306703567505, acc: 0.5684210658073425)
[2024-11-29 03:58:33,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:33,656][root][INFO] - Training Epoch: 8/10, step 231/574 completed (loss: 0.8124215006828308, acc: 0.7555555701255798)
[2024-11-29 03:58:33,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:34,267][root][INFO] - Training Epoch: 8/10, step 232/574 completed (loss: 1.2588396072387695, acc: 0.6333333253860474)
[2024-11-29 03:58:34,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:34,880][root][INFO] - Training Epoch: 8/10, step 233/574 completed (loss: 1.8058353662490845, acc: 0.5045871734619141)
[2024-11-29 03:58:34,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:35,493][root][INFO] - Training Epoch: 8/10, step 234/574 completed (loss: 1.2870020866394043, acc: 0.6615384817123413)
[2024-11-29 03:58:35,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:36,078][root][INFO] - Training Epoch: 8/10, step 235/574 completed (loss: 0.26908057928085327, acc: 0.8947368264198303)
[2024-11-29 03:58:36,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:36,664][root][INFO] - Training Epoch: 8/10, step 236/574 completed (loss: 0.013995383866131306, acc: 1.0)
[2024-11-29 03:58:36,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:37,251][root][INFO] - Training Epoch: 8/10, step 237/574 completed (loss: 0.12965311110019684, acc: 0.9090909361839294)
[2024-11-29 03:58:37,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:37,838][root][INFO] - Training Epoch: 8/10, step 238/574 completed (loss: 0.17705701291561127, acc: 0.9259259104728699)
[2024-11-29 03:58:37,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:38,430][root][INFO] - Training Epoch: 8/10, step 239/574 completed (loss: 0.28587010502815247, acc: 0.9428571462631226)
[2024-11-29 03:58:38,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:39,019][root][INFO] - Training Epoch: 8/10, step 240/574 completed (loss: 0.18737941980361938, acc: 0.9545454382896423)
[2024-11-29 03:58:39,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:39,609][root][INFO] - Training Epoch: 8/10, step 241/574 completed (loss: 0.18701685965061188, acc: 0.9545454382896423)
[2024-11-29 03:58:39,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:40,199][root][INFO] - Training Epoch: 8/10, step 242/574 completed (loss: 1.1627367734909058, acc: 0.6451612710952759)
[2024-11-29 03:58:40,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:40,791][root][INFO] - Training Epoch: 8/10, step 243/574 completed (loss: 0.30890166759490967, acc: 0.8863636255264282)
[2024-11-29 03:58:40,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:41,378][root][INFO] - Training Epoch: 8/10, step 244/574 completed (loss: 0.005407651420682669, acc: 1.0)
[2024-11-29 03:58:41,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:41,967][root][INFO] - Training Epoch: 8/10, step 245/574 completed (loss: 0.0038797680754214525, acc: 1.0)
[2024-11-29 03:58:42,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:42,555][root][INFO] - Training Epoch: 8/10, step 246/574 completed (loss: 0.023748556151986122, acc: 1.0)
[2024-11-29 03:58:42,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:43,142][root][INFO] - Training Epoch: 8/10, step 247/574 completed (loss: 0.24881260097026825, acc: 0.8999999761581421)
[2024-11-29 03:58:43,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:43,732][root][INFO] - Training Epoch: 8/10, step 248/574 completed (loss: 0.29207292199134827, acc: 0.8918918967247009)
[2024-11-29 03:58:43,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:44,320][root][INFO] - Training Epoch: 8/10, step 249/574 completed (loss: 0.076238714158535, acc: 1.0)
[2024-11-29 03:58:44,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:44,908][root][INFO] - Training Epoch: 8/10, step 250/574 completed (loss: 0.1512318253517151, acc: 0.9459459185600281)
[2024-11-29 03:58:44,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:45,504][root][INFO] - Training Epoch: 8/10, step 251/574 completed (loss: 0.7502449154853821, acc: 0.779411792755127)
[2024-11-29 03:58:45,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:46,093][root][INFO] - Training Epoch: 8/10, step 252/574 completed (loss: 0.06515368819236755, acc: 0.9756097793579102)
[2024-11-29 03:58:46,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:46,681][root][INFO] - Training Epoch: 8/10, step 253/574 completed (loss: 0.24681492149829865, acc: 0.8799999952316284)
[2024-11-29 03:58:46,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:47,267][root][INFO] - Training Epoch: 8/10, step 254/574 completed (loss: 0.011874625459313393, acc: 1.0)
[2024-11-29 03:58:47,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:47,855][root][INFO] - Training Epoch: 8/10, step 255/574 completed (loss: 0.03048151172697544, acc: 1.0)
[2024-11-29 03:58:47,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:48,446][root][INFO] - Training Epoch: 8/10, step 256/574 completed (loss: 0.36275172233581543, acc: 0.8771929740905762)
[2024-11-29 03:58:48,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:49,041][root][INFO] - Training Epoch: 8/10, step 257/574 completed (loss: 0.28864049911499023, acc: 0.9142857193946838)
[2024-11-29 03:58:49,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:49,632][root][INFO] - Training Epoch: 8/10, step 258/574 completed (loss: 0.2634837031364441, acc: 0.9078947305679321)
[2024-11-29 03:58:49,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:50,242][root][INFO] - Training Epoch: 8/10, step 259/574 completed (loss: 0.8757539987564087, acc: 0.7264150977134705)
[2024-11-29 03:58:50,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:50,854][root][INFO] - Training Epoch: 8/10, step 260/574 completed (loss: 1.3436986207962036, acc: 0.6499999761581421)
[2024-11-29 03:58:50,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:51,441][root][INFO] - Training Epoch: 8/10, step 261/574 completed (loss: 0.0978974997997284, acc: 0.9722222089767456)
[2024-11-29 03:58:51,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:52,028][root][INFO] - Training Epoch: 8/10, step 262/574 completed (loss: 0.23871950805187225, acc: 0.9677419066429138)
[2024-11-29 03:58:52,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:52,623][root][INFO] - Training Epoch: 8/10, step 263/574 completed (loss: 1.2997925281524658, acc: 0.6000000238418579)
[2024-11-29 03:58:52,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:53,212][root][INFO] - Training Epoch: 8/10, step 264/574 completed (loss: 0.6786372661590576, acc: 0.8333333134651184)
[2024-11-29 03:58:53,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:53,828][root][INFO] - Training Epoch: 8/10, step 265/574 completed (loss: 1.777609944343567, acc: 0.527999997138977)
[2024-11-29 03:58:53,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:54,421][root][INFO] - Training Epoch: 8/10, step 266/574 completed (loss: 1.0874851942062378, acc: 0.6853932738304138)
[2024-11-29 03:58:54,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:55,014][root][INFO] - Training Epoch: 8/10, step 267/574 completed (loss: 0.9518686532974243, acc: 0.7027027010917664)
[2024-11-29 03:58:55,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:55,609][root][INFO] - Training Epoch: 8/10, step 268/574 completed (loss: 0.8841243982315063, acc: 0.7241379022598267)
[2024-11-29 03:58:55,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:56,196][root][INFO] - Training Epoch: 8/10, step 269/574 completed (loss: 0.035131558775901794, acc: 1.0)
[2024-11-29 03:58:56,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:56,784][root][INFO] - Training Epoch: 8/10, step 270/574 completed (loss: 0.05221076309680939, acc: 1.0)
[2024-11-29 03:58:56,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:57,374][root][INFO] - Training Epoch: 8/10, step 271/574 completed (loss: 0.10340625792741776, acc: 0.9375)
[2024-11-29 03:58:58,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:58,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:59,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:58:59,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:00,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:00,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:01,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:01,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:02,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:02,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:03,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:03,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:04,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:04,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:05,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:06,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:06,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:07,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:07,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:08,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:08,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:09,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:09,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:10,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:10,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:11,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:11,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:12,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:12,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:13,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:13,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:14,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:14,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:15,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:16,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:16,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:17,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:17,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:18,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:18,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:19,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:19,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:20,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:20,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:21,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:21,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:22,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:22,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:23,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:23,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:24,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:25,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:25,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:26,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:26,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:27,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:27,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:28,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:28,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:29,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:29,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:30,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:30,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:31,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:32,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:32,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:33,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:33,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:34,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:34,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:35,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:35,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:36,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:36,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:37,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:37,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:38,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:38,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:39,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:39,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:40,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:40,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:41,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:42,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:42,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:43,310][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.9260, device='cuda:0') eval_epoch_loss=tensor(1.3676, device='cuda:0') eval_epoch_acc=tensor(0.6837, device='cuda:0')
[2024-11-29 03:59:43,311][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:59:43,312][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:59:43,560][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_8_step_272_loss_1.3676146268844604/model.pt
[2024-11-29 03:59:43,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:44,171][root][INFO] - Training Epoch: 8/10, step 272/574 completed (loss: 0.012842736206948757, acc: 1.0)
[2024-11-29 03:59:44,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:44,764][root][INFO] - Training Epoch: 8/10, step 273/574 completed (loss: 0.6673916578292847, acc: 0.8166666626930237)
[2024-11-29 03:59:44,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:45,354][root][INFO] - Training Epoch: 8/10, step 274/574 completed (loss: 0.11333104968070984, acc: 0.9375)
[2024-11-29 03:59:45,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:45,943][root][INFO] - Training Epoch: 8/10, step 275/574 completed (loss: 0.035829562693834305, acc: 1.0)
[2024-11-29 03:59:46,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:46,530][root][INFO] - Training Epoch: 8/10, step 276/574 completed (loss: 0.18843168020248413, acc: 0.9655172228813171)
[2024-11-29 03:59:46,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:47,116][root][INFO] - Training Epoch: 8/10, step 277/574 completed (loss: 0.03353336825966835, acc: 1.0)
[2024-11-29 03:59:47,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:47,705][root][INFO] - Training Epoch: 8/10, step 278/574 completed (loss: 0.6779479384422302, acc: 0.8297872543334961)
[2024-11-29 03:59:47,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:48,297][root][INFO] - Training Epoch: 8/10, step 279/574 completed (loss: 0.7100181579589844, acc: 0.8333333134651184)
[2024-11-29 03:59:48,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:48,886][root][INFO] - Training Epoch: 8/10, step 280/574 completed (loss: 0.25200119614601135, acc: 0.9090909361839294)
[2024-11-29 03:59:48,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:49,485][root][INFO] - Training Epoch: 8/10, step 281/574 completed (loss: 1.248626947402954, acc: 0.650602400302887)
[2024-11-29 03:59:49,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:50,083][root][INFO] - Training Epoch: 8/10, step 282/574 completed (loss: 1.5495116710662842, acc: 0.5925925970077515)
[2024-11-29 03:59:50,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:50,671][root][INFO] - Training Epoch: 8/10, step 283/574 completed (loss: 0.3954651355743408, acc: 0.8421052694320679)
[2024-11-29 03:59:50,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:51,256][root][INFO] - Training Epoch: 8/10, step 284/574 completed (loss: 0.28129684925079346, acc: 0.9117646813392639)
[2024-11-29 03:59:51,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:51,845][root][INFO] - Training Epoch: 8/10, step 285/574 completed (loss: 0.18181870877742767, acc: 0.925000011920929)
[2024-11-29 03:59:51,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:52,439][root][INFO] - Training Epoch: 8/10, step 286/574 completed (loss: 1.1391304731369019, acc: 0.6875)
[2024-11-29 03:59:52,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:53,050][root][INFO] - Training Epoch: 8/10, step 287/574 completed (loss: 1.3117707967758179, acc: 0.6480000019073486)
[2024-11-29 03:59:53,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:53,644][root][INFO] - Training Epoch: 8/10, step 288/574 completed (loss: 0.6362388134002686, acc: 0.8241758346557617)
[2024-11-29 03:59:53,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:54,242][root][INFO] - Training Epoch: 8/10, step 289/574 completed (loss: 1.3938695192337036, acc: 0.6211180090904236)
[2024-11-29 03:59:54,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:54,856][root][INFO] - Training Epoch: 8/10, step 290/574 completed (loss: 1.768904685974121, acc: 0.5463917255401611)
[2024-11-29 03:59:54,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:55,442][root][INFO] - Training Epoch: 8/10, step 291/574 completed (loss: 0.008427589200437069, acc: 1.0)
[2024-11-29 03:59:55,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:56,029][root][INFO] - Training Epoch: 8/10, step 292/574 completed (loss: 0.3982672393321991, acc: 0.8571428656578064)
[2024-11-29 03:59:56,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:56,622][root][INFO] - Training Epoch: 8/10, step 293/574 completed (loss: 0.3398004174232483, acc: 0.8965517282485962)
[2024-11-29 03:59:56,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:57,219][root][INFO] - Training Epoch: 8/10, step 294/574 completed (loss: 0.5026987195014954, acc: 0.8545454740524292)
[2024-11-29 03:59:57,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:57,844][root][INFO] - Training Epoch: 8/10, step 295/574 completed (loss: 1.4131070375442505, acc: 0.6082473993301392)
[2024-11-29 03:59:57,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:58,436][root][INFO] - Training Epoch: 8/10, step 296/574 completed (loss: 0.45841819047927856, acc: 0.8448275923728943)
[2024-11-29 03:59:58,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:59,023][root][INFO] - Training Epoch: 8/10, step 297/574 completed (loss: 0.06731938570737839, acc: 1.0)
[2024-11-29 03:59:59,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:59:59,614][root][INFO] - Training Epoch: 8/10, step 298/574 completed (loss: 0.5955275297164917, acc: 0.8684210777282715)
[2024-11-29 03:59:59,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:00,207][root][INFO] - Training Epoch: 8/10, step 299/574 completed (loss: 0.5200453996658325, acc: 0.8392857313156128)
[2024-11-29 04:00:00,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:00,795][root][INFO] - Training Epoch: 8/10, step 300/574 completed (loss: 0.23278038203716278, acc: 0.90625)
[2024-11-29 04:00:00,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:01,388][root][INFO] - Training Epoch: 8/10, step 301/574 completed (loss: 0.8927356600761414, acc: 0.7358490824699402)
[2024-11-29 04:00:01,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:01,978][root][INFO] - Training Epoch: 8/10, step 302/574 completed (loss: 0.18619796633720398, acc: 0.9622641801834106)
[2024-11-29 04:00:02,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:02,565][root][INFO] - Training Epoch: 8/10, step 303/574 completed (loss: 0.10847300291061401, acc: 0.9411764740943909)
[2024-11-29 04:00:02,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:03,151][root][INFO] - Training Epoch: 8/10, step 304/574 completed (loss: 0.28912922739982605, acc: 0.90625)
[2024-11-29 04:00:03,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:03,745][root][INFO] - Training Epoch: 8/10, step 305/574 completed (loss: 0.4249829947948456, acc: 0.9016393423080444)
[2024-11-29 04:00:03,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:04,334][root][INFO] - Training Epoch: 8/10, step 306/574 completed (loss: 0.050853386521339417, acc: 1.0)
[2024-11-29 04:00:04,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:04,918][root][INFO] - Training Epoch: 8/10, step 307/574 completed (loss: 0.006597085390239954, acc: 1.0)
[2024-11-29 04:00:04,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:05,511][root][INFO] - Training Epoch: 8/10, step 308/574 completed (loss: 0.700141429901123, acc: 0.782608687877655)
[2024-11-29 04:00:05,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:06,108][root][INFO] - Training Epoch: 8/10, step 309/574 completed (loss: 1.0913875102996826, acc: 0.7222222089767456)
[2024-11-29 04:00:06,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:06,703][root][INFO] - Training Epoch: 8/10, step 310/574 completed (loss: 0.7018347382545471, acc: 0.8072289228439331)
[2024-11-29 04:00:06,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:07,301][root][INFO] - Training Epoch: 8/10, step 311/574 completed (loss: 0.8397039771080017, acc: 0.7564102411270142)
[2024-11-29 04:00:07,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:07,913][root][INFO] - Training Epoch: 8/10, step 312/574 completed (loss: 1.3900800943374634, acc: 0.6530612111091614)
[2024-11-29 04:00:07,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:08,500][root][INFO] - Training Epoch: 8/10, step 313/574 completed (loss: 0.006519918795675039, acc: 1.0)
[2024-11-29 04:00:08,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:09,086][root][INFO] - Training Epoch: 8/10, step 314/574 completed (loss: 0.056653931736946106, acc: 1.0)
[2024-11-29 04:00:09,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:09,672][root][INFO] - Training Epoch: 8/10, step 315/574 completed (loss: 0.41566869616508484, acc: 0.9354838728904724)
[2024-11-29 04:00:09,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:10,257][root][INFO] - Training Epoch: 8/10, step 316/574 completed (loss: 0.05542721971869469, acc: 1.0)
[2024-11-29 04:00:10,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:10,850][root][INFO] - Training Epoch: 8/10, step 317/574 completed (loss: 0.6472241282463074, acc: 0.7761194109916687)
[2024-11-29 04:00:10,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:11,448][root][INFO] - Training Epoch: 8/10, step 318/574 completed (loss: 0.6871607303619385, acc: 0.7884615659713745)
[2024-11-29 04:00:11,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:12,037][root][INFO] - Training Epoch: 8/10, step 319/574 completed (loss: 0.41066423058509827, acc: 0.8666666746139526)
[2024-11-29 04:00:12,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:12,627][root][INFO] - Training Epoch: 8/10, step 320/574 completed (loss: 0.379539430141449, acc: 0.9193548560142517)
[2024-11-29 04:00:12,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:13,215][root][INFO] - Training Epoch: 8/10, step 321/574 completed (loss: 0.08077321201562881, acc: 0.9800000190734863)
[2024-11-29 04:00:13,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:13,802][root][INFO] - Training Epoch: 8/10, step 322/574 completed (loss: 0.393167644739151, acc: 0.9259259104728699)
[2024-11-29 04:00:13,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:14,390][root][INFO] - Training Epoch: 8/10, step 323/574 completed (loss: 0.9974158406257629, acc: 0.7142857313156128)
[2024-11-29 04:00:14,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:14,978][root][INFO] - Training Epoch: 8/10, step 324/574 completed (loss: 1.2023895978927612, acc: 0.7179487347602844)
[2024-11-29 04:00:15,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:15,570][root][INFO] - Training Epoch: 8/10, step 325/574 completed (loss: 0.5825888514518738, acc: 0.8780487775802612)
[2024-11-29 04:00:15,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:16,162][root][INFO] - Training Epoch: 8/10, step 326/574 completed (loss: 0.376844197511673, acc: 0.8684210777282715)
[2024-11-29 04:00:16,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:16,749][root][INFO] - Training Epoch: 8/10, step 327/574 completed (loss: 0.11314782500267029, acc: 0.9473684430122375)
[2024-11-29 04:00:16,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:17,335][root][INFO] - Training Epoch: 8/10, step 328/574 completed (loss: 0.017118629068136215, acc: 1.0)
[2024-11-29 04:00:17,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:17,921][root][INFO] - Training Epoch: 8/10, step 329/574 completed (loss: 0.10288674384355545, acc: 1.0)
[2024-11-29 04:00:18,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:18,510][root][INFO] - Training Epoch: 8/10, step 330/574 completed (loss: 0.050203029066324234, acc: 0.96875)
[2024-11-29 04:00:18,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:19,100][root][INFO] - Training Epoch: 8/10, step 331/574 completed (loss: 0.6646470427513123, acc: 0.8064516186714172)
[2024-11-29 04:00:19,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:19,694][root][INFO] - Training Epoch: 8/10, step 332/574 completed (loss: 0.6242715716362, acc: 0.7894737124443054)
[2024-11-29 04:00:19,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:20,290][root][INFO] - Training Epoch: 8/10, step 333/574 completed (loss: 0.19000354409217834, acc: 0.9375)
[2024-11-29 04:00:20,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:20,878][root][INFO] - Training Epoch: 8/10, step 334/574 completed (loss: 0.14501900970935822, acc: 0.9666666388511658)
[2024-11-29 04:00:20,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:21,466][root][INFO] - Training Epoch: 8/10, step 335/574 completed (loss: 0.09228935092687607, acc: 0.9473684430122375)
[2024-11-29 04:00:21,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:22,057][root][INFO] - Training Epoch: 8/10, step 336/574 completed (loss: 0.5314738154411316, acc: 0.8999999761581421)
[2024-11-29 04:00:22,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:22,655][root][INFO] - Training Epoch: 8/10, step 337/574 completed (loss: 1.279537320137024, acc: 0.6666666865348816)
[2024-11-29 04:00:22,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:23,250][root][INFO] - Training Epoch: 8/10, step 338/574 completed (loss: 1.3152031898498535, acc: 0.6382978558540344)
[2024-11-29 04:00:23,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:23,851][root][INFO] - Training Epoch: 8/10, step 339/574 completed (loss: 1.54888916015625, acc: 0.5421686768531799)
[2024-11-29 04:00:23,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:24,439][root][INFO] - Training Epoch: 8/10, step 340/574 completed (loss: 0.012135460041463375, acc: 1.0)
[2024-11-29 04:00:24,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:25,026][root][INFO] - Training Epoch: 8/10, step 341/574 completed (loss: 0.4799862802028656, acc: 0.8717948794364929)
[2024-11-29 04:00:25,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:25,618][root][INFO] - Training Epoch: 8/10, step 342/574 completed (loss: 1.4658446311950684, acc: 0.6144578456878662)
[2024-11-29 04:00:25,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:26,212][root][INFO] - Training Epoch: 8/10, step 343/574 completed (loss: 0.4673779010772705, acc: 0.8301886916160583)
[2024-11-29 04:00:26,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:26,815][root][INFO] - Training Epoch: 8/10, step 344/574 completed (loss: 0.7279558181762695, acc: 0.7848101258277893)
[2024-11-29 04:00:26,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:27,405][root][INFO] - Training Epoch: 8/10, step 345/574 completed (loss: 0.4479624330997467, acc: 0.843137264251709)
[2024-11-29 04:00:27,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:28,001][root][INFO] - Training Epoch: 8/10, step 346/574 completed (loss: 0.8867168426513672, acc: 0.7611940503120422)
[2024-11-29 04:00:28,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:28,592][root][INFO] - Training Epoch: 8/10, step 347/574 completed (loss: 0.010936031118035316, acc: 1.0)
[2024-11-29 04:00:28,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:29,179][root][INFO] - Training Epoch: 8/10, step 348/574 completed (loss: 0.07786739617586136, acc: 1.0)
[2024-11-29 04:00:29,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:29,768][root][INFO] - Training Epoch: 8/10, step 349/574 completed (loss: 0.4944036304950714, acc: 0.8611111044883728)
[2024-11-29 04:00:29,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:30,358][root][INFO] - Training Epoch: 8/10, step 350/574 completed (loss: 0.39594948291778564, acc: 0.8604651093482971)
[2024-11-29 04:00:30,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:30,947][root][INFO] - Training Epoch: 8/10, step 351/574 completed (loss: 0.3849368095397949, acc: 0.8461538553237915)
[2024-11-29 04:00:31,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:31,538][root][INFO] - Training Epoch: 8/10, step 352/574 completed (loss: 0.7343782186508179, acc: 0.7555555701255798)
[2024-11-29 04:00:31,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:32,126][root][INFO] - Training Epoch: 8/10, step 353/574 completed (loss: 0.01903015933930874, acc: 1.0)
[2024-11-29 04:00:32,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:32,712][root][INFO] - Training Epoch: 8/10, step 354/574 completed (loss: 0.4738873839378357, acc: 0.8461538553237915)
[2024-11-29 04:00:32,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:33,305][root][INFO] - Training Epoch: 8/10, step 355/574 completed (loss: 1.5605599880218506, acc: 0.593406617641449)
[2024-11-29 04:00:33,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:33,924][root][INFO] - Training Epoch: 8/10, step 356/574 completed (loss: 1.3760889768600464, acc: 0.6173912882804871)
[2024-11-29 04:00:34,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:34,515][root][INFO] - Training Epoch: 8/10, step 357/574 completed (loss: 1.0361969470977783, acc: 0.75)
[2024-11-29 04:00:34,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:35,110][root][INFO] - Training Epoch: 8/10, step 358/574 completed (loss: 0.6132726073265076, acc: 0.8367347121238708)
[2024-11-29 04:00:35,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:35,699][root][INFO] - Training Epoch: 8/10, step 359/574 completed (loss: 0.0031168488785624504, acc: 1.0)
[2024-11-29 04:00:35,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:36,286][root][INFO] - Training Epoch: 8/10, step 360/574 completed (loss: 0.040777988731861115, acc: 0.9615384340286255)
[2024-11-29 04:00:36,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:36,874][root][INFO] - Training Epoch: 8/10, step 361/574 completed (loss: 0.27426356077194214, acc: 0.8780487775802612)
[2024-11-29 04:00:36,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:37,462][root][INFO] - Training Epoch: 8/10, step 362/574 completed (loss: 0.37018096446990967, acc: 0.8888888955116272)
[2024-11-29 04:00:37,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:38,057][root][INFO] - Training Epoch: 8/10, step 363/574 completed (loss: 0.9159992337226868, acc: 0.7631579041481018)
[2024-11-29 04:00:38,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:38,651][root][INFO] - Training Epoch: 8/10, step 364/574 completed (loss: 0.41711536049842834, acc: 0.8780487775802612)
[2024-11-29 04:00:38,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:39,240][root][INFO] - Training Epoch: 8/10, step 365/574 completed (loss: 0.2028675079345703, acc: 0.9090909361839294)
[2024-11-29 04:00:39,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:39,825][root][INFO] - Training Epoch: 8/10, step 366/574 completed (loss: 0.0033774429466575384, acc: 1.0)
[2024-11-29 04:00:39,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:40,411][root][INFO] - Training Epoch: 8/10, step 367/574 completed (loss: 0.0008316455641761422, acc: 1.0)
[2024-11-29 04:00:40,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:40,996][root][INFO] - Training Epoch: 8/10, step 368/574 completed (loss: 0.05086107179522514, acc: 0.9642857313156128)
[2024-11-29 04:00:41,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:41,584][root][INFO] - Training Epoch: 8/10, step 369/574 completed (loss: 0.18513593077659607, acc: 0.9375)
[2024-11-29 04:00:41,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:42,197][root][INFO] - Training Epoch: 8/10, step 370/574 completed (loss: 1.9201549291610718, acc: 0.5151515007019043)
[2024-11-29 04:00:42,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:42,807][root][INFO] - Training Epoch: 8/10, step 371/574 completed (loss: 1.2468546628952026, acc: 0.650943398475647)
[2024-11-29 04:00:42,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:43,401][root][INFO] - Training Epoch: 8/10, step 372/574 completed (loss: 0.6357300281524658, acc: 0.8222222328186035)
[2024-11-29 04:00:43,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:43,994][root][INFO] - Training Epoch: 8/10, step 373/574 completed (loss: 0.4866197407245636, acc: 0.9107142686843872)
[2024-11-29 04:00:44,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:44,588][root][INFO] - Training Epoch: 8/10, step 374/574 completed (loss: 0.5599669814109802, acc: 0.8571428656578064)
[2024-11-29 04:00:44,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:45,176][root][INFO] - Training Epoch: 8/10, step 375/574 completed (loss: 0.0032683322206139565, acc: 1.0)
[2024-11-29 04:00:45,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:45,762][root][INFO] - Training Epoch: 8/10, step 376/574 completed (loss: 0.042379774153232574, acc: 1.0)
[2024-11-29 04:00:45,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:46,352][root][INFO] - Training Epoch: 8/10, step 377/574 completed (loss: 0.30325713753700256, acc: 0.8958333134651184)
[2024-11-29 04:00:46,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:46,946][root][INFO] - Training Epoch: 8/10, step 378/574 completed (loss: 0.6806501150131226, acc: 0.8421052694320679)
[2024-11-29 04:00:47,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:47,557][root][INFO] - Training Epoch: 8/10, step 379/574 completed (loss: 1.273122787475586, acc: 0.6706587076187134)
[2024-11-29 04:00:47,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:48,152][root][INFO] - Training Epoch: 8/10, step 380/574 completed (loss: 0.8602989315986633, acc: 0.7669172883033752)
[2024-11-29 04:00:48,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:48,774][root][INFO] - Training Epoch: 8/10, step 381/574 completed (loss: 1.1711746454238892, acc: 0.6898396015167236)
[2024-11-29 04:00:48,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:49,384][root][INFO] - Training Epoch: 8/10, step 382/574 completed (loss: 0.6469091176986694, acc: 0.8648648858070374)
[2024-11-29 04:00:49,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:49,970][root][INFO] - Training Epoch: 8/10, step 383/574 completed (loss: 0.05888742581009865, acc: 1.0)
[2024-11-29 04:00:50,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:50,555][root][INFO] - Training Epoch: 8/10, step 384/574 completed (loss: 0.004895505961030722, acc: 1.0)
[2024-11-29 04:00:50,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:51,143][root][INFO] - Training Epoch: 8/10, step 385/574 completed (loss: 0.05213502421975136, acc: 1.0)
[2024-11-29 04:00:51,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:51,730][root][INFO] - Training Epoch: 8/10, step 386/574 completed (loss: 0.10665950179100037, acc: 0.9722222089767456)
[2024-11-29 04:00:51,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:52,318][root][INFO] - Training Epoch: 8/10, step 387/574 completed (loss: 0.02486487478017807, acc: 1.0)
[2024-11-29 04:00:52,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:52,903][root][INFO] - Training Epoch: 8/10, step 388/574 completed (loss: 0.0020274659618735313, acc: 1.0)
[2024-11-29 04:00:52,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:53,487][root][INFO] - Training Epoch: 8/10, step 389/574 completed (loss: 0.002141414675861597, acc: 1.0)
[2024-11-29 04:00:53,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:54,077][root][INFO] - Training Epoch: 8/10, step 390/574 completed (loss: 0.3408530652523041, acc: 0.9523809552192688)
[2024-11-29 04:00:54,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:54,666][root][INFO] - Training Epoch: 8/10, step 391/574 completed (loss: 0.5413358211517334, acc: 0.8518518805503845)
[2024-11-29 04:00:54,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:55,261][root][INFO] - Training Epoch: 8/10, step 392/574 completed (loss: 1.2998703718185425, acc: 0.6407766938209534)
[2024-11-29 04:00:55,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:55,879][root][INFO] - Training Epoch: 8/10, step 393/574 completed (loss: 1.3341312408447266, acc: 0.6470588445663452)
[2024-11-29 04:00:55,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:56,477][root][INFO] - Training Epoch: 8/10, step 394/574 completed (loss: 1.5953243970870972, acc: 0.5933333039283752)
[2024-11-29 04:00:56,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:57,077][root][INFO] - Training Epoch: 8/10, step 395/574 completed (loss: 1.3267221450805664, acc: 0.6666666865348816)
[2024-11-29 04:00:57,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:57,667][root][INFO] - Training Epoch: 8/10, step 396/574 completed (loss: 0.3139781355857849, acc: 0.9069767594337463)
[2024-11-29 04:00:57,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:58,254][root][INFO] - Training Epoch: 8/10, step 397/574 completed (loss: 0.020358311012387276, acc: 1.0)
[2024-11-29 04:00:58,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:58,843][root][INFO] - Training Epoch: 8/10, step 398/574 completed (loss: 0.5518995523452759, acc: 0.8372092843055725)
[2024-11-29 04:00:58,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:00:59,430][root][INFO] - Training Epoch: 8/10, step 399/574 completed (loss: 0.03653062507510185, acc: 1.0)
[2024-11-29 04:00:59,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:00,026][root][INFO] - Training Epoch: 8/10, step 400/574 completed (loss: 0.6992895007133484, acc: 0.8088235259056091)
[2024-11-29 04:01:00,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:00,620][root][INFO] - Training Epoch: 8/10, step 401/574 completed (loss: 0.5074076056480408, acc: 0.8533333539962769)
[2024-11-29 04:01:00,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:01,209][root][INFO] - Training Epoch: 8/10, step 402/574 completed (loss: 0.06945764273405075, acc: 1.0)
[2024-11-29 04:01:01,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:01,796][root][INFO] - Training Epoch: 8/10, step 403/574 completed (loss: 0.31464657187461853, acc: 0.9090909361839294)
[2024-11-29 04:01:01,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:02,383][root][INFO] - Training Epoch: 8/10, step 404/574 completed (loss: 0.03237396851181984, acc: 1.0)
[2024-11-29 04:01:02,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:02,970][root][INFO] - Training Epoch: 8/10, step 405/574 completed (loss: 0.007317515090107918, acc: 1.0)
[2024-11-29 04:01:03,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:03,556][root][INFO] - Training Epoch: 8/10, step 406/574 completed (loss: 0.0197899229824543, acc: 1.0)
[2024-11-29 04:01:03,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:04,143][root][INFO] - Training Epoch: 8/10, step 407/574 completed (loss: 0.06755610555410385, acc: 0.9722222089767456)
[2024-11-29 04:01:04,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:04,733][root][INFO] - Training Epoch: 8/10, step 408/574 completed (loss: 0.017123399302363396, acc: 1.0)
[2024-11-29 04:01:04,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:05,318][root][INFO] - Training Epoch: 8/10, step 409/574 completed (loss: 0.07459966838359833, acc: 0.9615384340286255)
[2024-11-29 04:01:05,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:05,908][root][INFO] - Training Epoch: 8/10, step 410/574 completed (loss: 0.15642346441745758, acc: 0.9482758641242981)
[2024-11-29 04:01:05,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:06,495][root][INFO] - Training Epoch: 8/10, step 411/574 completed (loss: 0.15302936732769012, acc: 0.8928571343421936)
[2024-11-29 04:01:06,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:07,083][root][INFO] - Training Epoch: 8/10, step 412/574 completed (loss: 0.19943419098854065, acc: 0.9333333373069763)
[2024-11-29 04:01:07,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:07,670][root][INFO] - Training Epoch: 8/10, step 413/574 completed (loss: 0.0906989723443985, acc: 0.9696969985961914)
[2024-11-29 04:01:07,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:08,256][root][INFO] - Training Epoch: 8/10, step 414/574 completed (loss: 0.021107889711856842, acc: 1.0)
[2024-11-29 04:01:08,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:09,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:09,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:10,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:11,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:11,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:12,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:12,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:13,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:13,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:14,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:14,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:15,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:15,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:16,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:16,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:17,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:17,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:18,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:18,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:19,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:19,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:20,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:20,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:21,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:22,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:22,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:23,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:23,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:24,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:24,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:25,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:25,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:26,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:26,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:27,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:27,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:28,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:28,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:29,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:29,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:30,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:30,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:31,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:31,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:32,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:32,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:33,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:33,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:34,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:35,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:35,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:36,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:36,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:37,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:37,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:38,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:38,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:39,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:39,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:40,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:40,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:41,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:41,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:42,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:42,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:43,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:43,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:44,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:44,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:45,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:45,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:46,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:47,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:47,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:48,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:48,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:49,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:49,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:50,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:50,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:51,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:51,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:52,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:52,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:53,588][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.6148, device='cuda:0') eval_epoch_loss=tensor(1.2850, device='cuda:0') eval_epoch_acc=tensor(0.6980, device='cuda:0')
[2024-11-29 04:01:53,589][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 04:01:53,590][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 04:01:53,825][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_8_step_415_loss_1.28502357006073/model.pt
[2024-11-29 04:01:53,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:54,439][root][INFO] - Training Epoch: 8/10, step 415/574 completed (loss: 0.5417236089706421, acc: 0.7843137383460999)
[2024-11-29 04:01:54,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:55,028][root][INFO] - Training Epoch: 8/10, step 416/574 completed (loss: 0.01862424425780773, acc: 1.0)
[2024-11-29 04:01:55,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:55,615][root][INFO] - Training Epoch: 8/10, step 417/574 completed (loss: 0.08154452592134476, acc: 1.0)
[2024-11-29 04:01:55,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:56,207][root][INFO] - Training Epoch: 8/10, step 418/574 completed (loss: 0.34913599491119385, acc: 0.925000011920929)
[2024-11-29 04:01:56,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:56,794][root][INFO] - Training Epoch: 8/10, step 419/574 completed (loss: 0.21424655616283417, acc: 0.8500000238418579)
[2024-11-29 04:01:56,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:57,381][root][INFO] - Training Epoch: 8/10, step 420/574 completed (loss: 0.016565613448619843, acc: 1.0)
[2024-11-29 04:01:57,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:57,968][root][INFO] - Training Epoch: 8/10, step 421/574 completed (loss: 0.15509454905986786, acc: 0.9666666388511658)
[2024-11-29 04:01:58,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:58,556][root][INFO] - Training Epoch: 8/10, step 422/574 completed (loss: 0.2511900067329407, acc: 0.96875)
[2024-11-29 04:01:58,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:59,146][root][INFO] - Training Epoch: 8/10, step 423/574 completed (loss: 0.10204695910215378, acc: 0.9722222089767456)
[2024-11-29 04:01:59,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:01:59,733][root][INFO] - Training Epoch: 8/10, step 424/574 completed (loss: 0.17324770987033844, acc: 0.9259259104728699)
[2024-11-29 04:01:59,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:00,322][root][INFO] - Training Epoch: 8/10, step 425/574 completed (loss: 0.1160094141960144, acc: 0.9090909361839294)
[2024-11-29 04:02:00,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:00,908][root][INFO] - Training Epoch: 8/10, step 426/574 completed (loss: 0.017208542674779892, acc: 1.0)
[2024-11-29 04:02:00,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:01,498][root][INFO] - Training Epoch: 8/10, step 427/574 completed (loss: 0.08355336636304855, acc: 0.9729729890823364)
[2024-11-29 04:02:01,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:02,083][root][INFO] - Training Epoch: 8/10, step 428/574 completed (loss: 0.19257014989852905, acc: 0.9259259104728699)
[2024-11-29 04:02:02,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:02,670][root][INFO] - Training Epoch: 8/10, step 429/574 completed (loss: 0.09293434023857117, acc: 0.95652174949646)
[2024-11-29 04:02:02,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:03,256][root][INFO] - Training Epoch: 8/10, step 430/574 completed (loss: 0.04230242595076561, acc: 0.9629629850387573)
[2024-11-29 04:02:03,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:03,844][root][INFO] - Training Epoch: 8/10, step 431/574 completed (loss: 0.01712782494723797, acc: 1.0)
[2024-11-29 04:02:03,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:04,431][root][INFO] - Training Epoch: 8/10, step 432/574 completed (loss: 0.0041200811974704266, acc: 1.0)
[2024-11-29 04:02:04,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:05,019][root][INFO] - Training Epoch: 8/10, step 433/574 completed (loss: 0.18551471829414368, acc: 0.9444444179534912)
[2024-11-29 04:02:05,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:05,606][root][INFO] - Training Epoch: 8/10, step 434/574 completed (loss: 0.060388583689928055, acc: 0.9599999785423279)
[2024-11-29 04:02:05,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:06,194][root][INFO] - Training Epoch: 8/10, step 435/574 completed (loss: 0.01976349949836731, acc: 1.0)
[2024-11-29 04:02:06,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:06,781][root][INFO] - Training Epoch: 8/10, step 436/574 completed (loss: 0.4873890280723572, acc: 0.9166666865348816)
[2024-11-29 04:02:06,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:07,373][root][INFO] - Training Epoch: 8/10, step 437/574 completed (loss: 0.15109772980213165, acc: 0.9545454382896423)
[2024-11-29 04:02:07,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:07,959][root][INFO] - Training Epoch: 8/10, step 438/574 completed (loss: 0.004078589845448732, acc: 1.0)
[2024-11-29 04:02:08,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:08,549][root][INFO] - Training Epoch: 8/10, step 439/574 completed (loss: 0.5463637113571167, acc: 0.7948718070983887)
[2024-11-29 04:02:08,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:09,148][root][INFO] - Training Epoch: 8/10, step 440/574 completed (loss: 0.9476518630981445, acc: 0.7121211886405945)
[2024-11-29 04:02:09,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:09,759][root][INFO] - Training Epoch: 8/10, step 441/574 completed (loss: 2.1523818969726562, acc: 0.4320000112056732)
[2024-11-29 04:02:09,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:10,356][root][INFO] - Training Epoch: 8/10, step 442/574 completed (loss: 1.3644102811813354, acc: 0.5725806355476379)
[2024-11-29 04:02:10,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:10,969][root][INFO] - Training Epoch: 8/10, step 443/574 completed (loss: 1.6989952325820923, acc: 0.5572139024734497)
[2024-11-29 04:02:11,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:11,562][root][INFO] - Training Epoch: 8/10, step 444/574 completed (loss: 0.3619537949562073, acc: 0.9245283007621765)
[2024-11-29 04:02:11,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:12,155][root][INFO] - Training Epoch: 8/10, step 445/574 completed (loss: 0.2213829606771469, acc: 0.9772727489471436)
[2024-11-29 04:02:12,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:12,740][root][INFO] - Training Epoch: 8/10, step 446/574 completed (loss: 0.006070418283343315, acc: 1.0)
[2024-11-29 04:02:12,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:13,328][root][INFO] - Training Epoch: 8/10, step 447/574 completed (loss: 0.0677715316414833, acc: 1.0)
[2024-11-29 04:02:13,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:13,914][root][INFO] - Training Epoch: 8/10, step 448/574 completed (loss: 0.011852845549583435, acc: 1.0)
[2024-11-29 04:02:13,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:14,504][root][INFO] - Training Epoch: 8/10, step 449/574 completed (loss: 0.6391578316688538, acc: 0.8208954930305481)
[2024-11-29 04:02:14,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:15,094][root][INFO] - Training Epoch: 8/10, step 450/574 completed (loss: 0.43585073947906494, acc: 0.875)
[2024-11-29 04:02:15,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:15,688][root][INFO] - Training Epoch: 8/10, step 451/574 completed (loss: 0.5628750324249268, acc: 0.8695651888847351)
[2024-11-29 04:02:15,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:16,280][root][INFO] - Training Epoch: 8/10, step 452/574 completed (loss: 0.46681997179985046, acc: 0.8974359035491943)
[2024-11-29 04:02:16,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:16,873][root][INFO] - Training Epoch: 8/10, step 453/574 completed (loss: 0.7429754137992859, acc: 0.7894737124443054)
[2024-11-29 04:02:16,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:17,461][root][INFO] - Training Epoch: 8/10, step 454/574 completed (loss: 0.18960528075695038, acc: 0.9591836929321289)
[2024-11-29 04:02:17,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:18,050][root][INFO] - Training Epoch: 8/10, step 455/574 completed (loss: 0.05110599845647812, acc: 1.0)
[2024-11-29 04:02:18,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:18,645][root][INFO] - Training Epoch: 8/10, step 456/574 completed (loss: 1.0261716842651367, acc: 0.7731958627700806)
[2024-11-29 04:02:18,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:19,236][root][INFO] - Training Epoch: 8/10, step 457/574 completed (loss: 0.37347590923309326, acc: 0.8571428656578064)
[2024-11-29 04:02:19,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:19,856][root][INFO] - Training Epoch: 8/10, step 458/574 completed (loss: 1.5326672792434692, acc: 0.5988371968269348)
[2024-11-29 04:02:19,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:20,447][root][INFO] - Training Epoch: 8/10, step 459/574 completed (loss: 0.39723750948905945, acc: 0.875)
[2024-11-29 04:02:20,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:21,045][root][INFO] - Training Epoch: 8/10, step 460/574 completed (loss: 0.6567761301994324, acc: 0.8024691343307495)
[2024-11-29 04:02:21,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:21,632][root][INFO] - Training Epoch: 8/10, step 461/574 completed (loss: 0.5758395195007324, acc: 0.8055555820465088)
[2024-11-29 04:02:21,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:22,221][root][INFO] - Training Epoch: 8/10, step 462/574 completed (loss: 0.5802019834518433, acc: 0.9375)
[2024-11-29 04:02:22,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:22,807][root][INFO] - Training Epoch: 8/10, step 463/574 completed (loss: 0.27990978956222534, acc: 0.9230769276618958)
[2024-11-29 04:02:22,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:23,399][root][INFO] - Training Epoch: 8/10, step 464/574 completed (loss: 0.4911022484302521, acc: 0.8478260636329651)
[2024-11-29 04:02:23,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:23,992][root][INFO] - Training Epoch: 8/10, step 465/574 completed (loss: 0.523912787437439, acc: 0.8571428656578064)
[2024-11-29 04:02:24,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:24,584][root][INFO] - Training Epoch: 8/10, step 466/574 completed (loss: 0.6733100414276123, acc: 0.8433734774589539)
[2024-11-29 04:02:24,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:25,194][root][INFO] - Training Epoch: 8/10, step 467/574 completed (loss: 1.0105286836624146, acc: 0.684684693813324)
[2024-11-29 04:02:25,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:25,788][root][INFO] - Training Epoch: 8/10, step 468/574 completed (loss: 1.171165943145752, acc: 0.6699029207229614)
[2024-11-29 04:02:25,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:26,399][root][INFO] - Training Epoch: 8/10, step 469/574 completed (loss: 1.2211765050888062, acc: 0.6260162591934204)
[2024-11-29 04:02:26,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:26,986][root][INFO] - Training Epoch: 8/10, step 470/574 completed (loss: 0.14963556826114655, acc: 0.9166666865348816)
[2024-11-29 04:02:27,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:27,573][root][INFO] - Training Epoch: 8/10, step 471/574 completed (loss: 0.12401209026575089, acc: 0.9642857313156128)
[2024-11-29 04:02:27,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:28,189][root][INFO] - Training Epoch: 8/10, step 472/574 completed (loss: 1.433353304862976, acc: 0.5588235259056091)
[2024-11-29 04:02:28,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:28,802][root][INFO] - Training Epoch: 8/10, step 473/574 completed (loss: 1.8165462017059326, acc: 0.4978165924549103)
[2024-11-29 04:02:28,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:29,395][root][INFO] - Training Epoch: 8/10, step 474/574 completed (loss: 1.076748013496399, acc: 0.7291666865348816)
[2024-11-29 04:02:29,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:29,992][root][INFO] - Training Epoch: 8/10, step 475/574 completed (loss: 1.2213852405548096, acc: 0.6441717743873596)
[2024-11-29 04:02:30,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:30,589][root][INFO] - Training Epoch: 8/10, step 476/574 completed (loss: 1.002665400505066, acc: 0.7338129281997681)
[2024-11-29 04:02:30,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:31,200][root][INFO] - Training Epoch: 8/10, step 477/574 completed (loss: 1.6851699352264404, acc: 0.552763819694519)
[2024-11-29 04:02:31,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:31,790][root][INFO] - Training Epoch: 8/10, step 478/574 completed (loss: 0.18580426275730133, acc: 0.9722222089767456)
[2024-11-29 04:02:31,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:32,377][root][INFO] - Training Epoch: 8/10, step 479/574 completed (loss: 0.4036690294742584, acc: 0.8787878751754761)
[2024-11-29 04:02:32,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:32,964][root][INFO] - Training Epoch: 8/10, step 480/574 completed (loss: 0.02469109371304512, acc: 1.0)
[2024-11-29 04:02:33,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:33,551][root][INFO] - Training Epoch: 8/10, step 481/574 completed (loss: 0.09528958797454834, acc: 1.0)
[2024-11-29 04:02:33,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:34,138][root][INFO] - Training Epoch: 8/10, step 482/574 completed (loss: 0.10949443280696869, acc: 0.949999988079071)
[2024-11-29 04:02:34,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:34,735][root][INFO] - Training Epoch: 8/10, step 483/574 completed (loss: 0.8544116020202637, acc: 0.7931034564971924)
[2024-11-29 04:02:34,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:35,321][root][INFO] - Training Epoch: 8/10, step 484/574 completed (loss: 0.08382758498191833, acc: 1.0)
[2024-11-29 04:02:35,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:35,908][root][INFO] - Training Epoch: 8/10, step 485/574 completed (loss: 0.043967291712760925, acc: 1.0)
[2024-11-29 04:02:35,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:36,494][root][INFO] - Training Epoch: 8/10, step 486/574 completed (loss: 0.10709656774997711, acc: 1.0)
[2024-11-29 04:02:36,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:37,082][root][INFO] - Training Epoch: 8/10, step 487/574 completed (loss: 0.11440148949623108, acc: 0.9523809552192688)
[2024-11-29 04:02:37,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:37,669][root][INFO] - Training Epoch: 8/10, step 488/574 completed (loss: 0.11480459570884705, acc: 0.9545454382896423)
[2024-11-29 04:02:37,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:38,261][root][INFO] - Training Epoch: 8/10, step 489/574 completed (loss: 0.8992275595664978, acc: 0.7384615540504456)
[2024-11-29 04:02:38,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:38,847][root][INFO] - Training Epoch: 8/10, step 490/574 completed (loss: 0.03427246958017349, acc: 1.0)
[2024-11-29 04:02:38,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:39,434][root][INFO] - Training Epoch: 8/10, step 491/574 completed (loss: 0.15912649035453796, acc: 0.931034505367279)
[2024-11-29 04:02:39,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:40,022][root][INFO] - Training Epoch: 8/10, step 492/574 completed (loss: 0.3464941084384918, acc: 0.8627451062202454)
[2024-11-29 04:02:40,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:40,611][root][INFO] - Training Epoch: 8/10, step 493/574 completed (loss: 0.16871365904808044, acc: 0.9655172228813171)
[2024-11-29 04:02:40,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:41,197][root][INFO] - Training Epoch: 8/10, step 494/574 completed (loss: 0.004487567115575075, acc: 1.0)
[2024-11-29 04:02:41,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:41,785][root][INFO] - Training Epoch: 8/10, step 495/574 completed (loss: 0.02927600033581257, acc: 1.0)
[2024-11-29 04:02:41,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:42,381][root][INFO] - Training Epoch: 8/10, step 496/574 completed (loss: 1.1120140552520752, acc: 0.7321428656578064)
[2024-11-29 04:02:42,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:42,977][root][INFO] - Training Epoch: 8/10, step 497/574 completed (loss: 0.7857552766799927, acc: 0.7977527976036072)
[2024-11-29 04:02:43,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:43,572][root][INFO] - Training Epoch: 8/10, step 498/574 completed (loss: 0.958800733089447, acc: 0.7078651785850525)
[2024-11-29 04:02:43,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:44,185][root][INFO] - Training Epoch: 8/10, step 499/574 completed (loss: 1.4443012475967407, acc: 0.5957446694374084)
[2024-11-29 04:02:44,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:44,781][root][INFO] - Training Epoch: 8/10, step 500/574 completed (loss: 1.0412145853042603, acc: 0.6847826242446899)
[2024-11-29 04:02:44,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:45,368][root][INFO] - Training Epoch: 8/10, step 501/574 completed (loss: 0.3253629207611084, acc: 0.9599999785423279)
[2024-11-29 04:02:45,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:45,954][root][INFO] - Training Epoch: 8/10, step 502/574 completed (loss: 0.011832361109554768, acc: 1.0)
[2024-11-29 04:02:46,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:46,541][root][INFO] - Training Epoch: 8/10, step 503/574 completed (loss: 0.08107947558164597, acc: 0.9629629850387573)
[2024-11-29 04:02:46,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:47,127][root][INFO] - Training Epoch: 8/10, step 504/574 completed (loss: 0.12867599725723267, acc: 0.9259259104728699)
[2024-11-29 04:02:47,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:47,717][root][INFO] - Training Epoch: 8/10, step 505/574 completed (loss: 0.24653851985931396, acc: 0.9245283007621765)
[2024-11-29 04:02:47,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:48,303][root][INFO] - Training Epoch: 8/10, step 506/574 completed (loss: 0.026239052414894104, acc: 1.0)
[2024-11-29 04:02:48,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:48,900][root][INFO] - Training Epoch: 8/10, step 507/574 completed (loss: 1.0681182146072388, acc: 0.6756756901741028)
[2024-11-29 04:02:48,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:49,493][root][INFO] - Training Epoch: 8/10, step 508/574 completed (loss: 0.6138625741004944, acc: 0.8309859037399292)
[2024-11-29 04:02:49,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:50,081][root][INFO] - Training Epoch: 8/10, step 509/574 completed (loss: 0.0024836354423314333, acc: 1.0)
[2024-11-29 04:02:50,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:50,668][root][INFO] - Training Epoch: 8/10, step 510/574 completed (loss: 0.005688743200153112, acc: 1.0)
[2024-11-29 04:02:50,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:51,258][root][INFO] - Training Epoch: 8/10, step 511/574 completed (loss: 0.23235303163528442, acc: 0.9615384340286255)
[2024-11-29 04:02:51,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:51,891][root][INFO] - Training Epoch: 8/10, step 512/574 completed (loss: 1.975062370300293, acc: 0.5285714268684387)
[2024-11-29 04:02:51,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:52,504][root][INFO] - Training Epoch: 8/10, step 513/574 completed (loss: 1.1349358558654785, acc: 0.6984127163887024)
[2024-11-29 04:02:52,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:53,091][root][INFO] - Training Epoch: 8/10, step 514/574 completed (loss: 0.2098572552204132, acc: 0.9285714030265808)
[2024-11-29 04:02:53,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:53,683][root][INFO] - Training Epoch: 8/10, step 515/574 completed (loss: 0.1836286336183548, acc: 0.949999988079071)
[2024-11-29 04:02:53,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:54,282][root][INFO] - Training Epoch: 8/10, step 516/574 completed (loss: 0.8427849411964417, acc: 0.7777777910232544)
[2024-11-29 04:02:54,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:54,870][root][INFO] - Training Epoch: 8/10, step 517/574 completed (loss: 0.007932569831609726, acc: 1.0)
[2024-11-29 04:02:54,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:55,458][root][INFO] - Training Epoch: 8/10, step 518/574 completed (loss: 0.1593754142522812, acc: 0.9677419066429138)
[2024-11-29 04:02:55,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:56,037][root][INFO] - Training Epoch: 8/10, step 519/574 completed (loss: 0.00703998189419508, acc: 1.0)
[2024-11-29 04:02:56,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:56,623][root][INFO] - Training Epoch: 8/10, step 520/574 completed (loss: 0.13678115606307983, acc: 0.9259259104728699)
[2024-11-29 04:02:56,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:57,379][root][INFO] - Training Epoch: 8/10, step 521/574 completed (loss: 2.031954050064087, acc: 0.43220338225364685)
[2024-11-29 04:02:57,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:58,001][root][INFO] - Training Epoch: 8/10, step 522/574 completed (loss: 0.9150956273078918, acc: 0.7388059496879578)
[2024-11-29 04:02:58,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:58,597][root][INFO] - Training Epoch: 8/10, step 523/574 completed (loss: 1.1008059978485107, acc: 0.6496350169181824)
[2024-11-29 04:02:58,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:59,217][root][INFO] - Training Epoch: 8/10, step 524/574 completed (loss: 1.400960087776184, acc: 0.5950000286102295)
[2024-11-29 04:02:59,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:02:59,809][root][INFO] - Training Epoch: 8/10, step 525/574 completed (loss: 0.11238298565149307, acc: 1.0)
[2024-11-29 04:02:59,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:00,400][root][INFO] - Training Epoch: 8/10, step 526/574 completed (loss: 0.3318806290626526, acc: 0.9230769276618958)
[2024-11-29 04:03:00,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:00,986][root][INFO] - Training Epoch: 8/10, step 527/574 completed (loss: 0.03940272331237793, acc: 1.0)
[2024-11-29 04:03:01,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:01,582][root][INFO] - Training Epoch: 8/10, step 528/574 completed (loss: 0.9356603622436523, acc: 0.7049180269241333)
[2024-11-29 04:03:01,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:02,174][root][INFO] - Training Epoch: 8/10, step 529/574 completed (loss: 0.42543530464172363, acc: 0.8644067645072937)
[2024-11-29 04:03:02,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:02,764][root][INFO] - Training Epoch: 8/10, step 530/574 completed (loss: 0.23235756158828735, acc: 0.9767441749572754)
[2024-11-29 04:03:02,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:03,353][root][INFO] - Training Epoch: 8/10, step 531/574 completed (loss: 0.3136862516403198, acc: 0.9090909361839294)
[2024-11-29 04:03:03,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:03,943][root][INFO] - Training Epoch: 8/10, step 532/574 completed (loss: 0.5645537972450256, acc: 0.849056601524353)
[2024-11-29 04:03:04,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:04,532][root][INFO] - Training Epoch: 8/10, step 533/574 completed (loss: 0.27604082226753235, acc: 0.9090909361839294)
[2024-11-29 04:03:04,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:05,118][root][INFO] - Training Epoch: 8/10, step 534/574 completed (loss: 0.047436732798814774, acc: 0.9599999785423279)
[2024-11-29 04:03:05,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:05,705][root][INFO] - Training Epoch: 8/10, step 535/574 completed (loss: 0.214211106300354, acc: 0.949999988079071)
[2024-11-29 04:03:05,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:06,291][root][INFO] - Training Epoch: 8/10, step 536/574 completed (loss: 0.02241537719964981, acc: 1.0)
[2024-11-29 04:03:06,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:06,884][root][INFO] - Training Epoch: 8/10, step 537/574 completed (loss: 0.27831438183784485, acc: 0.9538461565971375)
[2024-11-29 04:03:06,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:07,477][root][INFO] - Training Epoch: 8/10, step 538/574 completed (loss: 0.3878316283226013, acc: 0.875)
[2024-11-29 04:03:07,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:08,065][root][INFO] - Training Epoch: 8/10, step 539/574 completed (loss: 0.17221227288246155, acc: 0.96875)
[2024-11-29 04:03:08,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:08,653][root][INFO] - Training Epoch: 8/10, step 540/574 completed (loss: 0.08297495543956757, acc: 1.0)
[2024-11-29 04:03:08,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:09,239][root][INFO] - Training Epoch: 8/10, step 541/574 completed (loss: 0.07238230109214783, acc: 1.0)
[2024-11-29 04:03:09,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:09,825][root][INFO] - Training Epoch: 8/10, step 542/574 completed (loss: 0.03179646655917168, acc: 0.9677419066429138)
[2024-11-29 04:03:09,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:10,412][root][INFO] - Training Epoch: 8/10, step 543/574 completed (loss: 0.004424125887453556, acc: 1.0)
[2024-11-29 04:03:10,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:10,999][root][INFO] - Training Epoch: 8/10, step 544/574 completed (loss: 0.19080787897109985, acc: 0.8999999761581421)
[2024-11-29 04:03:11,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:11,588][root][INFO] - Training Epoch: 8/10, step 545/574 completed (loss: 0.16794425249099731, acc: 0.9024389982223511)
[2024-11-29 04:03:11,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:12,177][root][INFO] - Training Epoch: 8/10, step 546/574 completed (loss: 0.377091646194458, acc: 0.9142857193946838)
[2024-11-29 04:03:12,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:12,769][root][INFO] - Training Epoch: 8/10, step 547/574 completed (loss: 0.056031759828329086, acc: 0.9736841917037964)
[2024-11-29 04:03:12,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:13,355][root][INFO] - Training Epoch: 8/10, step 548/574 completed (loss: 0.0349566750228405, acc: 1.0)
[2024-11-29 04:03:13,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:13,942][root][INFO] - Training Epoch: 8/10, step 549/574 completed (loss: 0.005432761739939451, acc: 1.0)
[2024-11-29 04:03:14,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:14,531][root][INFO] - Training Epoch: 8/10, step 550/574 completed (loss: 0.2513752281665802, acc: 0.939393937587738)
[2024-11-29 04:03:14,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:15,120][root][INFO] - Training Epoch: 8/10, step 551/574 completed (loss: 0.10750673711299896, acc: 1.0)
[2024-11-29 04:03:15,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:15,711][root][INFO] - Training Epoch: 8/10, step 552/574 completed (loss: 0.40420567989349365, acc: 0.8999999761581421)
[2024-11-29 04:03:15,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:16,323][root][INFO] - Training Epoch: 8/10, step 553/574 completed (loss: 1.2740113735198975, acc: 0.6642335653305054)
[2024-11-29 04:03:16,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:16,930][root][INFO] - Training Epoch: 8/10, step 554/574 completed (loss: 0.9006409645080566, acc: 0.7724137902259827)
[2024-11-29 04:03:17,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:17,527][root][INFO] - Training Epoch: 8/10, step 555/574 completed (loss: 1.2716070413589478, acc: 0.6785714030265808)
[2024-11-29 04:03:17,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:18,121][root][INFO] - Training Epoch: 8/10, step 556/574 completed (loss: 0.9104427099227905, acc: 0.7615894079208374)
[2024-11-29 04:03:18,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:18,716][root][INFO] - Training Epoch: 8/10, step 557/574 completed (loss: 0.6759737730026245, acc: 0.8290598392486572)
[2024-11-29 04:03:19,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:19,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:20,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:20,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:21,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:22,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:22,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:23,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:23,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:24,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:24,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:25,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:25,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:26,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:26,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:27,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:27,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:28,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:28,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:29,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:30,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:30,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:31,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:31,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:32,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:32,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:33,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:33,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:34,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:34,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:35,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:35,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:36,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:36,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:37,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:38,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:38,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:39,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:39,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:40,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:40,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:41,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:41,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:42,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:42,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:43,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:43,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:44,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:44,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:45,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:45,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:46,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:46,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:47,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:48,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:48,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:49,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:49,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:50,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:50,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:51,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:51,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:52,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:52,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:53,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:53,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:54,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:54,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:55,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:55,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:56,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:56,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:57,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:58,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:58,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:59,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:03:59,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:00,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:00,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:01,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:01,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:02,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:02,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:03,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:03,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:04,671][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.5180, device='cuda:0') eval_epoch_loss=tensor(1.2579, device='cuda:0') eval_epoch_acc=tensor(0.7100, device='cuda:0')
[2024-11-29 04:04:04,673][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 04:04:04,673][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 04:04:04,896][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_8_step_558_loss_1.2578812837600708/model.pt
[2024-11-29 04:04:04,899][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 8 is 1.2578812837600708
[2024-11-29 04:04:04,899][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 8 is 0.7099992036819458
[2024-11-29 04:04:04,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:05,506][root][INFO] - Training Epoch: 8/10, step 558/574 completed (loss: 0.02766869217157364, acc: 1.0)
[2024-11-29 04:04:05,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:06,094][root][INFO] - Training Epoch: 8/10, step 559/574 completed (loss: 0.06628952920436859, acc: 0.9615384340286255)
[2024-11-29 04:04:06,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:06,681][root][INFO] - Training Epoch: 8/10, step 560/574 completed (loss: 0.0077825067564845085, acc: 1.0)
[2024-11-29 04:04:06,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:07,273][root][INFO] - Training Epoch: 8/10, step 561/574 completed (loss: 0.28943029046058655, acc: 0.9230769276618958)
[2024-11-29 04:04:07,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:07,882][root][INFO] - Training Epoch: 8/10, step 562/574 completed (loss: 0.7677947282791138, acc: 0.7555555701255798)
[2024-11-29 04:04:07,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:08,475][root][INFO] - Training Epoch: 8/10, step 563/574 completed (loss: 0.432513952255249, acc: 0.8831169009208679)
[2024-11-29 04:04:08,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:09,064][root][INFO] - Training Epoch: 8/10, step 564/574 completed (loss: 0.2222708910703659, acc: 0.9583333134651184)
[2024-11-29 04:04:09,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:09,656][root][INFO] - Training Epoch: 8/10, step 565/574 completed (loss: 0.09484826028347015, acc: 0.982758641242981)
[2024-11-29 04:04:09,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:10,251][root][INFO] - Training Epoch: 8/10, step 566/574 completed (loss: 0.5444353818893433, acc: 0.8809523582458496)
[2024-11-29 04:04:10,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:10,838][root][INFO] - Training Epoch: 8/10, step 567/574 completed (loss: 0.08796006441116333, acc: 0.9736841917037964)
[2024-11-29 04:04:10,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:11,424][root][INFO] - Training Epoch: 8/10, step 568/574 completed (loss: 0.13496172428131104, acc: 0.9259259104728699)
[2024-11-29 04:04:11,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:12,048][root][INFO] - Training Epoch: 8/10, step 569/574 completed (loss: 1.3115260601043701, acc: 0.6524063944816589)
[2024-11-29 04:04:12,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:12,637][root][INFO] - Training Epoch: 8/10, step 570/574 completed (loss: 0.17394715547561646, acc: 0.9677419066429138)
[2024-11-29 04:04:12,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:13,233][root][INFO] - Training Epoch: 8/10, step 571/574 completed (loss: 0.9234835505485535, acc: 0.7179487347602844)
[2024-11-29 04:04:13,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:13,844][root][INFO] - Training Epoch: 8/10, step 572/574 completed (loss: 1.6197617053985596, acc: 0.5663265585899353)
[2024-11-29 04:04:13,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:14,456][root][INFO] - Training Epoch: 8/10, step 573/574 completed (loss: 1.3434996604919434, acc: 0.5911949872970581)
[2024-11-29 04:04:14,775][slam_llm.utils.train_utils][INFO] - Epoch 8: train_perplexity=1.8057, train_epoch_loss=0.5909, epoch time 526.3174266312271s
[2024-11-29 04:04:14,775][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 15 GB
[2024-11-29 04:04:14,775][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-29 04:04:14,776][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 15 GB
[2024-11-29 04:04:14,776][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 7
[2024-11-29 04:04:14,776][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-29 04:04:15,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:15,822][root][INFO] - Training Epoch: 9/10, step 0/574 completed (loss: 0.07949468493461609, acc: 1.0)
[2024-11-29 04:04:15,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:16,409][root][INFO] - Training Epoch: 9/10, step 1/574 completed (loss: 0.07917016744613647, acc: 1.0)
[2024-11-29 04:04:16,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:16,999][root][INFO] - Training Epoch: 9/10, step 2/574 completed (loss: 0.48876139521598816, acc: 0.8648648858070374)
[2024-11-29 04:04:17,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:17,588][root][INFO] - Training Epoch: 9/10, step 3/574 completed (loss: 0.29213622212409973, acc: 0.9210526347160339)
[2024-11-29 04:04:17,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:18,176][root][INFO] - Training Epoch: 9/10, step 4/574 completed (loss: 0.41319510340690613, acc: 0.8648648858070374)
[2024-11-29 04:04:18,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:18,764][root][INFO] - Training Epoch: 9/10, step 5/574 completed (loss: 0.32768353819847107, acc: 0.9285714030265808)
[2024-11-29 04:04:18,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:19,355][root][INFO] - Training Epoch: 9/10, step 6/574 completed (loss: 0.3456510007381439, acc: 0.8979591727256775)
[2024-11-29 04:04:19,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:19,943][root][INFO] - Training Epoch: 9/10, step 7/574 completed (loss: 0.09542036056518555, acc: 0.9666666388511658)
[2024-11-29 04:04:20,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:20,530][root][INFO] - Training Epoch: 9/10, step 8/574 completed (loss: 0.008676212280988693, acc: 1.0)
[2024-11-29 04:04:20,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:21,117][root][INFO] - Training Epoch: 9/10, step 9/574 completed (loss: 0.0027861506678164005, acc: 1.0)
[2024-11-29 04:04:21,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:21,705][root][INFO] - Training Epoch: 9/10, step 10/574 completed (loss: 0.010218514129519463, acc: 1.0)
[2024-11-29 04:04:21,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:22,293][root][INFO] - Training Epoch: 9/10, step 11/574 completed (loss: 0.34285879135131836, acc: 0.8974359035491943)
[2024-11-29 04:04:22,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:22,880][root][INFO] - Training Epoch: 9/10, step 12/574 completed (loss: 0.2253091037273407, acc: 0.9090909361839294)
[2024-11-29 04:04:22,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:23,468][root][INFO] - Training Epoch: 9/10, step 13/574 completed (loss: 0.46473249793052673, acc: 0.8913043737411499)
[2024-11-29 04:04:23,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:24,055][root][INFO] - Training Epoch: 9/10, step 14/574 completed (loss: 0.1427886039018631, acc: 0.9607843160629272)
[2024-11-29 04:04:24,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:24,646][root][INFO] - Training Epoch: 9/10, step 15/574 completed (loss: 0.6361521482467651, acc: 0.7551020383834839)
[2024-11-29 04:04:24,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:25,232][root][INFO] - Training Epoch: 9/10, step 16/574 completed (loss: 0.050841499119997025, acc: 0.9473684430122375)
[2024-11-29 04:04:25,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:25,821][root][INFO] - Training Epoch: 9/10, step 17/574 completed (loss: 0.05491143837571144, acc: 1.0)
[2024-11-29 04:04:25,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:26,412][root][INFO] - Training Epoch: 9/10, step 18/574 completed (loss: 0.29827478528022766, acc: 0.9166666865348816)
[2024-11-29 04:04:26,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:26,997][root][INFO] - Training Epoch: 9/10, step 19/574 completed (loss: 0.019901517778635025, acc: 1.0)
[2024-11-29 04:04:27,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:27,584][root][INFO] - Training Epoch: 9/10, step 20/574 completed (loss: 0.06004144996404648, acc: 1.0)
[2024-11-29 04:04:27,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:28,172][root][INFO] - Training Epoch: 9/10, step 21/574 completed (loss: 0.3156236708164215, acc: 0.8620689511299133)
[2024-11-29 04:04:28,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:28,761][root][INFO] - Training Epoch: 9/10, step 22/574 completed (loss: 0.16711601614952087, acc: 0.9200000166893005)
[2024-11-29 04:04:28,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:29,347][root][INFO] - Training Epoch: 9/10, step 23/574 completed (loss: 0.012563716620206833, acc: 1.0)
[2024-11-29 04:04:29,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:29,934][root][INFO] - Training Epoch: 9/10, step 24/574 completed (loss: 0.004769452847540379, acc: 1.0)
[2024-11-29 04:04:30,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:30,527][root][INFO] - Training Epoch: 9/10, step 25/574 completed (loss: 0.5251922011375427, acc: 0.8113207817077637)
[2024-11-29 04:04:30,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:31,120][root][INFO] - Training Epoch: 9/10, step 26/574 completed (loss: 0.59002286195755, acc: 0.8630136847496033)
[2024-11-29 04:04:31,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:31,795][root][INFO] - Training Epoch: 9/10, step 27/574 completed (loss: 2.3414087295532227, acc: 0.3913043439388275)
[2024-11-29 04:04:31,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:32,384][root][INFO] - Training Epoch: 9/10, step 28/574 completed (loss: 0.19215793907642365, acc: 0.9069767594337463)
[2024-11-29 04:04:32,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:32,976][root][INFO] - Training Epoch: 9/10, step 29/574 completed (loss: 0.6388797163963318, acc: 0.8674699068069458)
[2024-11-29 04:04:33,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:33,573][root][INFO] - Training Epoch: 9/10, step 30/574 completed (loss: 1.0285636186599731, acc: 0.6790123581886292)
[2024-11-29 04:04:33,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:34,160][root][INFO] - Training Epoch: 9/10, step 31/574 completed (loss: 0.2572902739048004, acc: 0.9285714030265808)
[2024-11-29 04:04:34,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:34,745][root][INFO] - Training Epoch: 9/10, step 32/574 completed (loss: 0.08338389545679092, acc: 1.0)
[2024-11-29 04:04:34,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:35,332][root][INFO] - Training Epoch: 9/10, step 33/574 completed (loss: 0.014748037792742252, acc: 1.0)
[2024-11-29 04:04:35,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:35,929][root][INFO] - Training Epoch: 9/10, step 34/574 completed (loss: 0.9795295000076294, acc: 0.7899159789085388)
[2024-11-29 04:04:36,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:36,519][root][INFO] - Training Epoch: 9/10, step 35/574 completed (loss: 0.5739420056343079, acc: 0.8524590134620667)
[2024-11-29 04:04:36,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:37,114][root][INFO] - Training Epoch: 9/10, step 36/574 completed (loss: 0.7420744895935059, acc: 0.8253968358039856)
[2024-11-29 04:04:37,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:37,705][root][INFO] - Training Epoch: 9/10, step 37/574 completed (loss: 0.8883193731307983, acc: 0.7966101765632629)
[2024-11-29 04:04:37,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:38,300][root][INFO] - Training Epoch: 9/10, step 38/574 completed (loss: 0.6327028870582581, acc: 0.8735632300376892)
[2024-11-29 04:04:38,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:38,890][root][INFO] - Training Epoch: 9/10, step 39/574 completed (loss: 0.014161795377731323, acc: 1.0)
[2024-11-29 04:04:38,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:39,480][root][INFO] - Training Epoch: 9/10, step 40/574 completed (loss: 0.43465641140937805, acc: 0.9230769276618958)
[2024-11-29 04:04:39,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:40,076][root][INFO] - Training Epoch: 9/10, step 41/574 completed (loss: 1.0089820623397827, acc: 0.6891891956329346)
[2024-11-29 04:04:40,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:40,667][root][INFO] - Training Epoch: 9/10, step 42/574 completed (loss: 0.44073617458343506, acc: 0.8461538553237915)
[2024-11-29 04:04:40,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:41,260][root][INFO] - Training Epoch: 9/10, step 43/574 completed (loss: 0.8541151285171509, acc: 0.7272727489471436)
[2024-11-29 04:04:41,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:41,855][root][INFO] - Training Epoch: 9/10, step 44/574 completed (loss: 0.7310245037078857, acc: 0.7938144207000732)
[2024-11-29 04:04:41,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:42,453][root][INFO] - Training Epoch: 9/10, step 45/574 completed (loss: 1.257685661315918, acc: 0.6691176295280457)
[2024-11-29 04:04:42,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:43,038][root][INFO] - Training Epoch: 9/10, step 46/574 completed (loss: 0.008640492334961891, acc: 1.0)
[2024-11-29 04:04:43,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:43,625][root][INFO] - Training Epoch: 9/10, step 47/574 completed (loss: 0.02564701996743679, acc: 1.0)
[2024-11-29 04:04:43,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:44,211][root][INFO] - Training Epoch: 9/10, step 48/574 completed (loss: 0.05319969728589058, acc: 1.0)
[2024-11-29 04:04:44,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:44,800][root][INFO] - Training Epoch: 9/10, step 49/574 completed (loss: 0.14840693771839142, acc: 0.9722222089767456)
[2024-11-29 04:04:44,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:45,393][root][INFO] - Training Epoch: 9/10, step 50/574 completed (loss: 0.33870363235473633, acc: 0.8947368264198303)
[2024-11-29 04:04:45,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:45,989][root][INFO] - Training Epoch: 9/10, step 51/574 completed (loss: 0.663922905921936, acc: 0.8095238208770752)
[2024-11-29 04:04:46,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:46,584][root][INFO] - Training Epoch: 9/10, step 52/574 completed (loss: 1.0155631303787231, acc: 0.6760563254356384)
[2024-11-29 04:04:46,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:47,197][root][INFO] - Training Epoch: 9/10, step 53/574 completed (loss: 1.8421639204025269, acc: 0.5333333611488342)
[2024-11-29 04:04:47,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:47,783][root][INFO] - Training Epoch: 9/10, step 54/574 completed (loss: 0.16307245194911957, acc: 0.9729729890823364)
[2024-11-29 04:04:47,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:48,369][root][INFO] - Training Epoch: 9/10, step 55/574 completed (loss: 0.1706302911043167, acc: 0.9230769276618958)
[2024-11-29 04:04:48,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:49,071][root][INFO] - Training Epoch: 9/10, step 56/574 completed (loss: 2.0300064086914062, acc: 0.4778156876564026)
[2024-11-29 04:04:49,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:49,724][root][INFO] - Training Epoch: 9/10, step 57/574 completed (loss: 2.3964521884918213, acc: 0.4248366057872772)
[2024-11-29 04:04:49,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:50,345][root][INFO] - Training Epoch: 9/10, step 58/574 completed (loss: 1.484887719154358, acc: 0.6306818127632141)
[2024-11-29 04:04:50,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:50,943][root][INFO] - Training Epoch: 9/10, step 59/574 completed (loss: 1.4297629594802856, acc: 0.625)
[2024-11-29 04:04:51,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:51,556][root][INFO] - Training Epoch: 9/10, step 60/574 completed (loss: 1.4675039052963257, acc: 0.5652173757553101)
[2024-11-29 04:04:51,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:52,165][root][INFO] - Training Epoch: 9/10, step 61/574 completed (loss: 1.0647045373916626, acc: 0.7250000238418579)
[2024-11-29 04:04:52,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:52,751][root][INFO] - Training Epoch: 9/10, step 62/574 completed (loss: 0.20171065628528595, acc: 0.9117646813392639)
[2024-11-29 04:04:52,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:53,341][root][INFO] - Training Epoch: 9/10, step 63/574 completed (loss: 0.6329620480537415, acc: 0.8611111044883728)
[2024-11-29 04:04:53,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:53,936][root][INFO] - Training Epoch: 9/10, step 64/574 completed (loss: 0.3042801022529602, acc: 0.953125)
[2024-11-29 04:04:54,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:54,525][root][INFO] - Training Epoch: 9/10, step 65/574 completed (loss: 0.11565321683883667, acc: 0.9655172228813171)
[2024-11-29 04:04:54,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:55,117][root][INFO] - Training Epoch: 9/10, step 66/574 completed (loss: 0.4255896210670471, acc: 0.875)
[2024-11-29 04:04:55,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:55,708][root][INFO] - Training Epoch: 9/10, step 67/574 completed (loss: 0.4067968726158142, acc: 0.8666666746139526)
[2024-11-29 04:04:55,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:56,296][root][INFO] - Training Epoch: 9/10, step 68/574 completed (loss: 0.019956156611442566, acc: 1.0)
[2024-11-29 04:04:56,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:56,884][root][INFO] - Training Epoch: 9/10, step 69/574 completed (loss: 0.2916988432407379, acc: 0.9166666865348816)
[2024-11-29 04:04:56,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:57,473][root][INFO] - Training Epoch: 9/10, step 70/574 completed (loss: 0.06260670721530914, acc: 0.9696969985961914)
[2024-11-29 04:04:57,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:58,085][root][INFO] - Training Epoch: 9/10, step 71/574 completed (loss: 1.396895408630371, acc: 0.6617646813392639)
[2024-11-29 04:04:58,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:58,681][root][INFO] - Training Epoch: 9/10, step 72/574 completed (loss: 0.9561063647270203, acc: 0.7142857313156128)
[2024-11-29 04:04:58,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:59,295][root][INFO] - Training Epoch: 9/10, step 73/574 completed (loss: 1.814156413078308, acc: 0.5333333611488342)
[2024-11-29 04:04:59,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:04:59,888][root][INFO] - Training Epoch: 9/10, step 74/574 completed (loss: 0.8396508097648621, acc: 0.7755101919174194)
[2024-11-29 04:04:59,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:00,486][root][INFO] - Training Epoch: 9/10, step 75/574 completed (loss: 1.3500192165374756, acc: 0.611940324306488)
[2024-11-29 04:05:00,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:01,110][root][INFO] - Training Epoch: 9/10, step 76/574 completed (loss: 2.0982298851013184, acc: 0.45255473256111145)
[2024-11-29 04:05:01,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:01,695][root][INFO] - Training Epoch: 9/10, step 77/574 completed (loss: 0.05649356544017792, acc: 1.0)
[2024-11-29 04:05:01,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:02,283][root][INFO] - Training Epoch: 9/10, step 78/574 completed (loss: 0.019121291115880013, acc: 1.0)
[2024-11-29 04:05:02,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:02,870][root][INFO] - Training Epoch: 9/10, step 79/574 completed (loss: 0.0691400095820427, acc: 0.9696969985961914)
[2024-11-29 04:05:02,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:03,457][root][INFO] - Training Epoch: 9/10, step 80/574 completed (loss: 0.006337364669889212, acc: 1.0)
[2024-11-29 04:05:03,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:04,050][root][INFO] - Training Epoch: 9/10, step 81/574 completed (loss: 0.40448588132858276, acc: 0.8653846383094788)
[2024-11-29 04:05:04,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:04,641][root][INFO] - Training Epoch: 9/10, step 82/574 completed (loss: 0.30488210916519165, acc: 0.9230769276618958)
[2024-11-29 04:05:04,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:05,228][root][INFO] - Training Epoch: 9/10, step 83/574 completed (loss: 0.14056265354156494, acc: 0.96875)
[2024-11-29 04:05:05,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:05,823][root][INFO] - Training Epoch: 9/10, step 84/574 completed (loss: 0.4508548974990845, acc: 0.8695651888847351)
[2024-11-29 04:05:05,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:06,415][root][INFO] - Training Epoch: 9/10, step 85/574 completed (loss: 0.3984023332595825, acc: 0.8600000143051147)
[2024-11-29 04:05:06,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:07,003][root][INFO] - Training Epoch: 9/10, step 86/574 completed (loss: 0.01756364293396473, acc: 1.0)
[2024-11-29 04:05:07,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:07,601][root][INFO] - Training Epoch: 9/10, step 87/574 completed (loss: 0.6806997060775757, acc: 0.699999988079071)
[2024-11-29 04:05:07,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:08,199][root][INFO] - Training Epoch: 9/10, step 88/574 completed (loss: 0.8218371868133545, acc: 0.7961165308952332)
[2024-11-29 04:05:08,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:08,812][root][INFO] - Training Epoch: 9/10, step 89/574 completed (loss: 1.2437084913253784, acc: 0.6650485396385193)
[2024-11-29 04:05:08,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:09,425][root][INFO] - Training Epoch: 9/10, step 90/574 completed (loss: 1.488803505897522, acc: 0.6129032373428345)
[2024-11-29 04:05:09,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:10,048][root][INFO] - Training Epoch: 9/10, step 91/574 completed (loss: 1.5029665231704712, acc: 0.6293103694915771)
[2024-11-29 04:05:10,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:10,644][root][INFO] - Training Epoch: 9/10, step 92/574 completed (loss: 0.8908506035804749, acc: 0.7473683953285217)
[2024-11-29 04:05:10,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:11,259][root][INFO] - Training Epoch: 9/10, step 93/574 completed (loss: 1.5520535707473755, acc: 0.5346534848213196)
[2024-11-29 04:05:11,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:11,852][root][INFO] - Training Epoch: 9/10, step 94/574 completed (loss: 0.586485743522644, acc: 0.8225806355476379)
[2024-11-29 04:05:11,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:12,444][root][INFO] - Training Epoch: 9/10, step 95/574 completed (loss: 0.4467265009880066, acc: 0.8550724387168884)
[2024-11-29 04:05:12,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:13,041][root][INFO] - Training Epoch: 9/10, step 96/574 completed (loss: 1.168514370918274, acc: 0.6134454011917114)
[2024-11-29 04:05:13,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:13,638][root][INFO] - Training Epoch: 9/10, step 97/574 completed (loss: 1.1388479471206665, acc: 0.625)
[2024-11-29 04:05:13,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:14,238][root][INFO] - Training Epoch: 9/10, step 98/574 completed (loss: 1.364058494567871, acc: 0.5912408828735352)
[2024-11-29 04:05:14,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:14,830][root][INFO] - Training Epoch: 9/10, step 99/574 completed (loss: 0.5955803990364075, acc: 0.8208954930305481)
[2024-11-29 04:05:14,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:15,419][root][INFO] - Training Epoch: 9/10, step 100/574 completed (loss: 0.32301655411720276, acc: 0.949999988079071)
[2024-11-29 04:05:15,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:16,005][root][INFO] - Training Epoch: 9/10, step 101/574 completed (loss: 0.003994431812316179, acc: 1.0)
[2024-11-29 04:05:16,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:16,592][root][INFO] - Training Epoch: 9/10, step 102/574 completed (loss: 0.015444980934262276, acc: 1.0)
[2024-11-29 04:05:16,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:17,182][root][INFO] - Training Epoch: 9/10, step 103/574 completed (loss: 0.1093115508556366, acc: 0.9772727489471436)
[2024-11-29 04:05:17,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:17,773][root][INFO] - Training Epoch: 9/10, step 104/574 completed (loss: 0.4024263024330139, acc: 0.9137930870056152)
[2024-11-29 04:05:17,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:18,360][root][INFO] - Training Epoch: 9/10, step 105/574 completed (loss: 0.09635072201490402, acc: 0.9767441749572754)
[2024-11-29 04:05:18,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:18,945][root][INFO] - Training Epoch: 9/10, step 106/574 completed (loss: 0.021533412858843803, acc: 1.0)
[2024-11-29 04:05:19,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:19,530][root][INFO] - Training Epoch: 9/10, step 107/574 completed (loss: 0.006525574717670679, acc: 1.0)
[2024-11-29 04:05:19,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:20,118][root][INFO] - Training Epoch: 9/10, step 108/574 completed (loss: 0.009252308867871761, acc: 1.0)
[2024-11-29 04:05:20,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:20,710][root][INFO] - Training Epoch: 9/10, step 109/574 completed (loss: 0.4334827661514282, acc: 0.9047619104385376)
[2024-11-29 04:05:20,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:21,301][root][INFO] - Training Epoch: 9/10, step 110/574 completed (loss: 0.4629136323928833, acc: 0.892307698726654)
[2024-11-29 04:05:21,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:21,894][root][INFO] - Training Epoch: 9/10, step 111/574 completed (loss: 0.554439127445221, acc: 0.859649121761322)
[2024-11-29 04:05:21,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:22,485][root][INFO] - Training Epoch: 9/10, step 112/574 completed (loss: 0.443606436252594, acc: 0.8947368264198303)
[2024-11-29 04:05:22,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:23,073][root][INFO] - Training Epoch: 9/10, step 113/574 completed (loss: 0.14109084010124207, acc: 0.9743589758872986)
[2024-11-29 04:05:23,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:23,665][root][INFO] - Training Epoch: 9/10, step 114/574 completed (loss: 0.23399390280246735, acc: 0.9591836929321289)
[2024-11-29 04:05:23,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:24,252][root][INFO] - Training Epoch: 9/10, step 115/574 completed (loss: 0.0018783796112984419, acc: 1.0)
[2024-11-29 04:05:24,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:24,849][root][INFO] - Training Epoch: 9/10, step 116/574 completed (loss: 1.0083606243133545, acc: 0.7460317611694336)
[2024-11-29 04:05:24,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:25,442][root][INFO] - Training Epoch: 9/10, step 117/574 completed (loss: 0.7118333578109741, acc: 0.8130081295967102)
[2024-11-29 04:05:25,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:26,035][root][INFO] - Training Epoch: 9/10, step 118/574 completed (loss: 0.5256334543228149, acc: 0.8225806355476379)
[2024-11-29 04:05:26,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:26,675][root][INFO] - Training Epoch: 9/10, step 119/574 completed (loss: 1.8030403852462769, acc: 0.5817490220069885)
[2024-11-29 04:05:26,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:27,271][root][INFO] - Training Epoch: 9/10, step 120/574 completed (loss: 0.4605611562728882, acc: 0.9066666960716248)
[2024-11-29 04:05:27,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:27,864][root][INFO] - Training Epoch: 9/10, step 121/574 completed (loss: 0.685204267501831, acc: 0.8269230723381042)
[2024-11-29 04:05:27,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:28,450][root][INFO] - Training Epoch: 9/10, step 122/574 completed (loss: 0.016660666093230247, acc: 1.0)
[2024-11-29 04:05:28,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:29,036][root][INFO] - Training Epoch: 9/10, step 123/574 completed (loss: 0.02160893939435482, acc: 1.0)
[2024-11-29 04:05:29,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:29,634][root][INFO] - Training Epoch: 9/10, step 124/574 completed (loss: 1.4804351329803467, acc: 0.5398772954940796)
[2024-11-29 04:05:29,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:30,248][root][INFO] - Training Epoch: 9/10, step 125/574 completed (loss: 1.2716491222381592, acc: 0.6875)
[2024-11-29 04:05:30,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:30,843][root][INFO] - Training Epoch: 9/10, step 126/574 completed (loss: 1.1388161182403564, acc: 0.6583333611488342)
[2024-11-29 04:05:31,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:32,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:32,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:33,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:33,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:34,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:34,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:35,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:35,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:36,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:36,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:37,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:37,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:38,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:39,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:39,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:40,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:40,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:41,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:41,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:42,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:42,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:43,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:43,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:44,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:44,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:45,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:45,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:46,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:46,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:47,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:47,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:48,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:49,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:49,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:50,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:50,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:51,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:51,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:52,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:52,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:53,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:53,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:54,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:54,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:55,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:55,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:56,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:56,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:57,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:57,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:58,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:59,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:05:59,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:00,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:00,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:01,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:01,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:02,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:02,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:03,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:03,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:04,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:04,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:05,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:05,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:06,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:06,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:07,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:07,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:08,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:09,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:09,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:10,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:10,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:11,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:11,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:12,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:12,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:13,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:13,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:14,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:14,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:15,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:15,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:16,743][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.3273, device='cuda:0') eval_epoch_loss=tensor(1.2022, device='cuda:0') eval_epoch_acc=tensor(0.7095, device='cuda:0')
[2024-11-29 04:06:16,744][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 04:06:16,745][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 04:06:16,975][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_9_step_127_loss_1.202162265777588/model.pt
[2024-11-29 04:06:16,978][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 9 is 1.202162265777588
[2024-11-29 04:06:17,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:17,616][root][INFO] - Training Epoch: 9/10, step 127/574 completed (loss: 1.6738252639770508, acc: 0.5059523582458496)
[2024-11-29 04:06:17,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:18,227][root][INFO] - Training Epoch: 9/10, step 128/574 completed (loss: 1.3199143409729004, acc: 0.6051282286643982)
[2024-11-29 04:06:18,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:18,850][root][INFO] - Training Epoch: 9/10, step 129/574 completed (loss: 1.2945677042007446, acc: 0.6323529481887817)
[2024-11-29 04:06:18,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:19,435][root][INFO] - Training Epoch: 9/10, step 130/574 completed (loss: 0.11480850726366043, acc: 0.9615384340286255)
[2024-11-29 04:06:19,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:20,022][root][INFO] - Training Epoch: 9/10, step 131/574 completed (loss: 0.01221374236047268, acc: 1.0)
[2024-11-29 04:06:20,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:20,608][root][INFO] - Training Epoch: 9/10, step 132/574 completed (loss: 0.18948505818843842, acc: 0.96875)
[2024-11-29 04:06:20,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:21,194][root][INFO] - Training Epoch: 9/10, step 133/574 completed (loss: 0.4480089247226715, acc: 0.95652174949646)
[2024-11-29 04:06:21,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:21,780][root][INFO] - Training Epoch: 9/10, step 134/574 completed (loss: 0.11176581680774689, acc: 1.0)
[2024-11-29 04:06:21,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:22,367][root][INFO] - Training Epoch: 9/10, step 135/574 completed (loss: 0.0805342048406601, acc: 0.9615384340286255)
[2024-11-29 04:06:22,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:22,955][root][INFO] - Training Epoch: 9/10, step 136/574 completed (loss: 0.2184680551290512, acc: 0.9523809552192688)
[2024-11-29 04:06:23,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:23,543][root][INFO] - Training Epoch: 9/10, step 137/574 completed (loss: 0.39145299792289734, acc: 0.8999999761581421)
[2024-11-29 04:06:23,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:24,129][root][INFO] - Training Epoch: 9/10, step 138/574 completed (loss: 0.34814316034317017, acc: 0.95652174949646)
[2024-11-29 04:06:24,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:24,719][root][INFO] - Training Epoch: 9/10, step 139/574 completed (loss: 0.02980504184961319, acc: 1.0)
[2024-11-29 04:06:24,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:25,307][root][INFO] - Training Epoch: 9/10, step 140/574 completed (loss: 0.4281838834285736, acc: 0.9230769276618958)
[2024-11-29 04:06:25,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:25,896][root][INFO] - Training Epoch: 9/10, step 141/574 completed (loss: 0.3956368863582611, acc: 0.8387096524238586)
[2024-11-29 04:06:25,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:26,483][root][INFO] - Training Epoch: 9/10, step 142/574 completed (loss: 0.42591530084609985, acc: 0.8648648858070374)
[2024-11-29 04:06:26,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:27,095][root][INFO] - Training Epoch: 9/10, step 143/574 completed (loss: 1.0037786960601807, acc: 0.6754385828971863)
[2024-11-29 04:06:27,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:27,691][root][INFO] - Training Epoch: 9/10, step 144/574 completed (loss: 0.9219905138015747, acc: 0.6791045069694519)
[2024-11-29 04:06:27,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:28,291][root][INFO] - Training Epoch: 9/10, step 145/574 completed (loss: 1.1677000522613525, acc: 0.704081654548645)
[2024-11-29 04:06:28,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:28,901][root][INFO] - Training Epoch: 9/10, step 146/574 completed (loss: 1.2174670696258545, acc: 0.6808510422706604)
[2024-11-29 04:06:28,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:29,493][root][INFO] - Training Epoch: 9/10, step 147/574 completed (loss: 0.4957764148712158, acc: 0.8571428656578064)
[2024-11-29 04:06:29,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:30,079][root][INFO] - Training Epoch: 9/10, step 148/574 completed (loss: 0.12242869287729263, acc: 1.0)
[2024-11-29 04:06:30,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:30,666][root][INFO] - Training Epoch: 9/10, step 149/574 completed (loss: 0.15494346618652344, acc: 0.95652174949646)
[2024-11-29 04:06:30,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:31,255][root][INFO] - Training Epoch: 9/10, step 150/574 completed (loss: 0.09973085671663284, acc: 0.9655172228813171)
[2024-11-29 04:06:31,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:31,844][root][INFO] - Training Epoch: 9/10, step 151/574 completed (loss: 0.3962734043598175, acc: 0.804347813129425)
[2024-11-29 04:06:31,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:32,440][root][INFO] - Training Epoch: 9/10, step 152/574 completed (loss: 0.8119710087776184, acc: 0.7457627058029175)
[2024-11-29 04:06:32,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:33,030][root][INFO] - Training Epoch: 9/10, step 153/574 completed (loss: 0.3744545876979828, acc: 0.9298245906829834)
[2024-11-29 04:06:33,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:33,622][root][INFO] - Training Epoch: 9/10, step 154/574 completed (loss: 0.6238434910774231, acc: 0.8243243098258972)
[2024-11-29 04:06:33,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:34,208][root][INFO] - Training Epoch: 9/10, step 155/574 completed (loss: 0.15910586714744568, acc: 0.9285714030265808)
[2024-11-29 04:06:34,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:34,793][root][INFO] - Training Epoch: 9/10, step 156/574 completed (loss: 0.014122214168310165, acc: 1.0)
[2024-11-29 04:06:34,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:35,379][root][INFO] - Training Epoch: 9/10, step 157/574 completed (loss: 0.1242804154753685, acc: 1.0)
[2024-11-29 04:06:35,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:35,969][root][INFO] - Training Epoch: 9/10, step 158/574 completed (loss: 0.7762743830680847, acc: 0.8108108043670654)
[2024-11-29 04:06:36,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:36,558][root][INFO] - Training Epoch: 9/10, step 159/574 completed (loss: 0.5269067287445068, acc: 0.8518518805503845)
[2024-11-29 04:06:36,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:37,148][root][INFO] - Training Epoch: 9/10, step 160/574 completed (loss: 0.4857481122016907, acc: 0.8488371968269348)
[2024-11-29 04:06:37,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:37,739][root][INFO] - Training Epoch: 9/10, step 161/574 completed (loss: 0.3895840346813202, acc: 0.8705882430076599)
[2024-11-29 04:06:37,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:38,333][root][INFO] - Training Epoch: 9/10, step 162/574 completed (loss: 0.9530154466629028, acc: 0.7528089880943298)
[2024-11-29 04:06:38,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:38,922][root][INFO] - Training Epoch: 9/10, step 163/574 completed (loss: 0.6218750476837158, acc: 0.8863636255264282)
[2024-11-29 04:06:39,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:39,506][root][INFO] - Training Epoch: 9/10, step 164/574 completed (loss: 0.02657776139676571, acc: 1.0)
[2024-11-29 04:06:39,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:40,095][root][INFO] - Training Epoch: 9/10, step 165/574 completed (loss: 0.2865256667137146, acc: 0.931034505367279)
[2024-11-29 04:06:40,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:40,684][root][INFO] - Training Epoch: 9/10, step 166/574 completed (loss: 0.1523037999868393, acc: 0.9795918464660645)
[2024-11-29 04:06:40,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:41,271][root][INFO] - Training Epoch: 9/10, step 167/574 completed (loss: 0.36127912998199463, acc: 0.9599999785423279)
[2024-11-29 04:06:41,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:41,863][root][INFO] - Training Epoch: 9/10, step 168/574 completed (loss: 0.8533955216407776, acc: 0.6944444179534912)
[2024-11-29 04:06:41,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:42,458][root][INFO] - Training Epoch: 9/10, step 169/574 completed (loss: 1.1576511859893799, acc: 0.6666666865348816)
[2024-11-29 04:06:42,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:43,077][root][INFO] - Training Epoch: 9/10, step 170/574 completed (loss: 2.150621175765991, acc: 0.4383561611175537)
[2024-11-29 04:06:43,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:43,664][root][INFO] - Training Epoch: 9/10, step 171/574 completed (loss: 0.2820882797241211, acc: 0.9583333134651184)
[2024-11-29 04:06:43,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:44,251][root][INFO] - Training Epoch: 9/10, step 172/574 completed (loss: 0.023864934220910072, acc: 1.0)
[2024-11-29 04:06:44,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:44,837][root][INFO] - Training Epoch: 9/10, step 173/574 completed (loss: 0.2370341569185257, acc: 0.9642857313156128)
[2024-11-29 04:06:44,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:45,451][root][INFO] - Training Epoch: 9/10, step 174/574 completed (loss: 1.1119455099105835, acc: 0.7079645991325378)
[2024-11-29 04:06:45,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:46,044][root][INFO] - Training Epoch: 9/10, step 175/574 completed (loss: 0.47463005781173706, acc: 0.8840579986572266)
[2024-11-29 04:06:46,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:46,638][root][INFO] - Training Epoch: 9/10, step 176/574 completed (loss: 0.670380175113678, acc: 0.7954545617103577)
[2024-11-29 04:06:46,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:47,250][root][INFO] - Training Epoch: 9/10, step 177/574 completed (loss: 1.685191035270691, acc: 0.5496183037757874)
[2024-11-29 04:06:47,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:47,862][root][INFO] - Training Epoch: 9/10, step 178/574 completed (loss: 1.6546705961227417, acc: 0.5629629492759705)
[2024-11-29 04:06:47,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:48,453][root][INFO] - Training Epoch: 9/10, step 179/574 completed (loss: 0.6107985973358154, acc: 0.8360655903816223)
[2024-11-29 04:06:48,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:49,039][root][INFO] - Training Epoch: 9/10, step 180/574 completed (loss: 0.005041601601988077, acc: 1.0)
[2024-11-29 04:06:49,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:49,626][root][INFO] - Training Epoch: 9/10, step 181/574 completed (loss: 0.017436880618333817, acc: 1.0)
[2024-11-29 04:06:49,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:50,211][root][INFO] - Training Epoch: 9/10, step 182/574 completed (loss: 0.13837216794490814, acc: 0.9285714030265808)
[2024-11-29 04:06:50,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:50,807][root][INFO] - Training Epoch: 9/10, step 183/574 completed (loss: 0.8657659292221069, acc: 0.7317073345184326)
[2024-11-29 04:06:50,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:51,431][root][INFO] - Training Epoch: 9/10, step 184/574 completed (loss: 1.8271663188934326, acc: 0.5166162848472595)
[2024-11-29 04:06:51,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:52,055][root][INFO] - Training Epoch: 9/10, step 185/574 completed (loss: 2.009277820587158, acc: 0.4438040256500244)
[2024-11-29 04:06:52,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:52,675][root][INFO] - Training Epoch: 9/10, step 186/574 completed (loss: 2.0320894718170166, acc: 0.4625000059604645)
[2024-11-29 04:06:52,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:53,331][root][INFO] - Training Epoch: 9/10, step 187/574 completed (loss: 2.2920589447021484, acc: 0.39774858951568604)
[2024-11-29 04:06:53,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:53,965][root][INFO] - Training Epoch: 9/10, step 188/574 completed (loss: 1.835752010345459, acc: 0.5053380727767944)
[2024-11-29 04:06:54,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:54,553][root][INFO] - Training Epoch: 9/10, step 189/574 completed (loss: 0.26399993896484375, acc: 0.9200000166893005)
[2024-11-29 04:06:54,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:55,150][root][INFO] - Training Epoch: 9/10, step 190/574 completed (loss: 1.2481719255447388, acc: 0.5930232405662537)
[2024-11-29 04:06:55,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:55,744][root][INFO] - Training Epoch: 9/10, step 191/574 completed (loss: 1.5389970541000366, acc: 0.5396825671195984)
[2024-11-29 04:06:55,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:56,342][root][INFO] - Training Epoch: 9/10, step 192/574 completed (loss: 1.9203112125396729, acc: 0.43939393758773804)
[2024-11-29 04:06:56,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:56,935][root][INFO] - Training Epoch: 9/10, step 193/574 completed (loss: 1.0201261043548584, acc: 0.6823529601097107)
[2024-11-29 04:06:57,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:57,547][root][INFO] - Training Epoch: 9/10, step 194/574 completed (loss: 1.408385157585144, acc: 0.6296296119689941)
[2024-11-29 04:06:57,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:58,150][root][INFO] - Training Epoch: 9/10, step 195/574 completed (loss: 0.9363469481468201, acc: 0.6774193644523621)
[2024-11-29 04:06:58,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:58,738][root][INFO] - Training Epoch: 9/10, step 196/574 completed (loss: 0.02697138674557209, acc: 1.0)
[2024-11-29 04:06:58,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:59,326][root][INFO] - Training Epoch: 9/10, step 197/574 completed (loss: 0.21437504887580872, acc: 0.925000011920929)
[2024-11-29 04:06:59,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:06:59,918][root][INFO] - Training Epoch: 9/10, step 198/574 completed (loss: 0.4723195433616638, acc: 0.8676470518112183)
[2024-11-29 04:06:59,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:00,513][root][INFO] - Training Epoch: 9/10, step 199/574 completed (loss: 1.1609541177749634, acc: 0.75)
[2024-11-29 04:07:00,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:01,114][root][INFO] - Training Epoch: 9/10, step 200/574 completed (loss: 1.0201033353805542, acc: 0.694915235042572)
[2024-11-29 04:07:01,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:01,711][root][INFO] - Training Epoch: 9/10, step 201/574 completed (loss: 1.1225776672363281, acc: 0.6567164063453674)
[2024-11-29 04:07:01,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:02,306][root][INFO] - Training Epoch: 9/10, step 202/574 completed (loss: 0.9403971433639526, acc: 0.7281553149223328)
[2024-11-29 04:07:02,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:02,904][root][INFO] - Training Epoch: 9/10, step 203/574 completed (loss: 0.747624397277832, acc: 0.841269850730896)
[2024-11-29 04:07:02,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:03,502][root][INFO] - Training Epoch: 9/10, step 204/574 completed (loss: 0.5508142709732056, acc: 0.8461538553237915)
[2024-11-29 04:07:03,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:04,122][root][INFO] - Training Epoch: 9/10, step 205/574 completed (loss: 1.562424898147583, acc: 0.573991060256958)
[2024-11-29 04:07:04,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:04,747][root][INFO] - Training Epoch: 9/10, step 206/574 completed (loss: 1.580557942390442, acc: 0.586614191532135)
[2024-11-29 04:07:04,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:05,361][root][INFO] - Training Epoch: 9/10, step 207/574 completed (loss: 1.1008696556091309, acc: 0.7068965435028076)
[2024-11-29 04:07:05,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:05,978][root][INFO] - Training Epoch: 9/10, step 208/574 completed (loss: 1.5015813112258911, acc: 0.6268116235733032)
[2024-11-29 04:07:06,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:06,601][root][INFO] - Training Epoch: 9/10, step 209/574 completed (loss: 1.5171972513198853, acc: 0.5642023086547852)
[2024-11-29 04:07:06,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:07,215][root][INFO] - Training Epoch: 9/10, step 210/574 completed (loss: 1.3768073320388794, acc: 0.5978260636329651)
[2024-11-29 04:07:07,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:07,803][root][INFO] - Training Epoch: 9/10, step 211/574 completed (loss: 0.0073624057695269585, acc: 1.0)
[2024-11-29 04:07:07,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:08,391][root][INFO] - Training Epoch: 9/10, step 212/574 completed (loss: 0.01613568142056465, acc: 1.0)
[2024-11-29 04:07:08,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:08,982][root][INFO] - Training Epoch: 9/10, step 213/574 completed (loss: 0.2156354784965515, acc: 0.936170220375061)
[2024-11-29 04:07:09,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:09,591][root][INFO] - Training Epoch: 9/10, step 214/574 completed (loss: 1.1315902471542358, acc: 0.692307710647583)
[2024-11-29 04:07:09,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:10,183][root][INFO] - Training Epoch: 9/10, step 215/574 completed (loss: 0.6294577121734619, acc: 0.7837837934494019)
[2024-11-29 04:07:10,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:10,776][root][INFO] - Training Epoch: 9/10, step 216/574 completed (loss: 0.354082852602005, acc: 0.9186046719551086)
[2024-11-29 04:07:10,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:11,372][root][INFO] - Training Epoch: 9/10, step 217/574 completed (loss: 0.5924313068389893, acc: 0.8468468189239502)
[2024-11-29 04:07:11,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:11,965][root][INFO] - Training Epoch: 9/10, step 218/574 completed (loss: 0.4733544588088989, acc: 0.8888888955116272)
[2024-11-29 04:07:12,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:12,554][root][INFO] - Training Epoch: 9/10, step 219/574 completed (loss: 0.06891489773988724, acc: 1.0)
[2024-11-29 04:07:12,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:13,140][root][INFO] - Training Epoch: 9/10, step 220/574 completed (loss: 0.011023353785276413, acc: 1.0)
[2024-11-29 04:07:13,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:13,726][root][INFO] - Training Epoch: 9/10, step 221/574 completed (loss: 0.021500002592802048, acc: 1.0)
[2024-11-29 04:07:13,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:14,319][root][INFO] - Training Epoch: 9/10, step 222/574 completed (loss: 0.6136120557785034, acc: 0.807692289352417)
[2024-11-29 04:07:14,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:14,933][root][INFO] - Training Epoch: 9/10, step 223/574 completed (loss: 1.5364547967910767, acc: 0.6304348111152649)
[2024-11-29 04:07:15,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:15,545][root][INFO] - Training Epoch: 9/10, step 224/574 completed (loss: 1.494254231452942, acc: 0.5909090638160706)
[2024-11-29 04:07:15,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:16,157][root][INFO] - Training Epoch: 9/10, step 225/574 completed (loss: 1.4660662412643433, acc: 0.585106372833252)
[2024-11-29 04:07:16,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:16,749][root][INFO] - Training Epoch: 9/10, step 226/574 completed (loss: 0.515087902545929, acc: 0.8301886916160583)
[2024-11-29 04:07:16,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:17,343][root][INFO] - Training Epoch: 9/10, step 227/574 completed (loss: 0.3292809724807739, acc: 0.9166666865348816)
[2024-11-29 04:07:17,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:17,936][root][INFO] - Training Epoch: 9/10, step 228/574 completed (loss: 0.1358630508184433, acc: 0.9767441749572754)
[2024-11-29 04:07:18,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:18,523][root][INFO] - Training Epoch: 9/10, step 229/574 completed (loss: 0.10258469730615616, acc: 0.9666666388511658)
[2024-11-29 04:07:18,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:19,120][root][INFO] - Training Epoch: 9/10, step 230/574 completed (loss: 1.3077572584152222, acc: 0.6631578803062439)
[2024-11-29 04:07:19,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:19,712][root][INFO] - Training Epoch: 9/10, step 231/574 completed (loss: 0.7999088764190674, acc: 0.800000011920929)
[2024-11-29 04:07:19,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:20,323][root][INFO] - Training Epoch: 9/10, step 232/574 completed (loss: 1.3173506259918213, acc: 0.6166666746139526)
[2024-11-29 04:07:20,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:20,936][root][INFO] - Training Epoch: 9/10, step 233/574 completed (loss: 1.8012349605560303, acc: 0.5091742873191833)
[2024-11-29 04:07:21,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:21,551][root][INFO] - Training Epoch: 9/10, step 234/574 completed (loss: 1.2115296125411987, acc: 0.6615384817123413)
[2024-11-29 04:07:21,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:22,136][root][INFO] - Training Epoch: 9/10, step 235/574 completed (loss: 0.5476316809654236, acc: 0.8947368264198303)
[2024-11-29 04:07:22,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:22,722][root][INFO] - Training Epoch: 9/10, step 236/574 completed (loss: 0.058428794145584106, acc: 1.0)
[2024-11-29 04:07:22,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:23,309][root][INFO] - Training Epoch: 9/10, step 237/574 completed (loss: 0.17174455523490906, acc: 0.9545454382896423)
[2024-11-29 04:07:23,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:23,894][root][INFO] - Training Epoch: 9/10, step 238/574 completed (loss: 0.06564462929964066, acc: 1.0)
[2024-11-29 04:07:23,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:24,483][root][INFO] - Training Epoch: 9/10, step 239/574 completed (loss: 0.33521541953086853, acc: 0.8571428656578064)
[2024-11-29 04:07:24,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:25,073][root][INFO] - Training Epoch: 9/10, step 240/574 completed (loss: 0.18553031980991364, acc: 0.9318181872367859)
[2024-11-29 04:07:25,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:25,660][root][INFO] - Training Epoch: 9/10, step 241/574 completed (loss: 0.25666344165802, acc: 0.9090909361839294)
[2024-11-29 04:07:25,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:26,251][root][INFO] - Training Epoch: 9/10, step 242/574 completed (loss: 1.011242389678955, acc: 0.6290322542190552)
[2024-11-29 04:07:26,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:26,842][root][INFO] - Training Epoch: 9/10, step 243/574 completed (loss: 0.367125004529953, acc: 0.9318181872367859)
[2024-11-29 04:07:26,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:27,427][root][INFO] - Training Epoch: 9/10, step 244/574 completed (loss: 0.004037940409034491, acc: 1.0)
[2024-11-29 04:07:27,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:28,014][root][INFO] - Training Epoch: 9/10, step 245/574 completed (loss: 0.01309024915099144, acc: 1.0)
[2024-11-29 04:07:28,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:28,600][root][INFO] - Training Epoch: 9/10, step 246/574 completed (loss: 0.06276022642850876, acc: 1.0)
[2024-11-29 04:07:28,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:29,189][root][INFO] - Training Epoch: 9/10, step 247/574 completed (loss: 0.033585768193006516, acc: 1.0)
[2024-11-29 04:07:29,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:29,781][root][INFO] - Training Epoch: 9/10, step 248/574 completed (loss: 0.30617883801460266, acc: 0.8648648858070374)
[2024-11-29 04:07:29,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:30,367][root][INFO] - Training Epoch: 9/10, step 249/574 completed (loss: 0.07637327164411545, acc: 1.0)
[2024-11-29 04:07:30,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:30,956][root][INFO] - Training Epoch: 9/10, step 250/574 completed (loss: 0.19095619022846222, acc: 0.9459459185600281)
[2024-11-29 04:07:31,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:31,552][root][INFO] - Training Epoch: 9/10, step 251/574 completed (loss: 0.6432348489761353, acc: 0.7647058963775635)
[2024-11-29 04:07:31,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:32,146][root][INFO] - Training Epoch: 9/10, step 252/574 completed (loss: 0.06558992713689804, acc: 0.9756097793579102)
[2024-11-29 04:07:32,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:32,732][root][INFO] - Training Epoch: 9/10, step 253/574 completed (loss: 0.061736974865198135, acc: 1.0)
[2024-11-29 04:07:32,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:33,317][root][INFO] - Training Epoch: 9/10, step 254/574 completed (loss: 0.007996995002031326, acc: 1.0)
[2024-11-29 04:07:33,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:33,906][root][INFO] - Training Epoch: 9/10, step 255/574 completed (loss: 0.01747041940689087, acc: 1.0)
[2024-11-29 04:07:33,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:34,498][root][INFO] - Training Epoch: 9/10, step 256/574 completed (loss: 0.20944595336914062, acc: 0.9122806787490845)
[2024-11-29 04:07:34,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:35,086][root][INFO] - Training Epoch: 9/10, step 257/574 completed (loss: 0.39908063411712646, acc: 0.8999999761581421)
[2024-11-29 04:07:35,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:35,676][root][INFO] - Training Epoch: 9/10, step 258/574 completed (loss: 0.28106576204299927, acc: 0.9078947305679321)
[2024-11-29 04:07:35,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:36,283][root][INFO] - Training Epoch: 9/10, step 259/574 completed (loss: 0.5901902914047241, acc: 0.8301886916160583)
[2024-11-29 04:07:36,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:36,896][root][INFO] - Training Epoch: 9/10, step 260/574 completed (loss: 1.2396496534347534, acc: 0.7333333492279053)
[2024-11-29 04:07:36,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:37,486][root][INFO] - Training Epoch: 9/10, step 261/574 completed (loss: 0.07825730741024017, acc: 0.9722222089767456)
[2024-11-29 04:07:37,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:38,074][root][INFO] - Training Epoch: 9/10, step 262/574 completed (loss: 0.07531379908323288, acc: 1.0)
[2024-11-29 04:07:38,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:38,668][root][INFO] - Training Epoch: 9/10, step 263/574 completed (loss: 0.9710768461227417, acc: 0.746666669845581)
[2024-11-29 04:07:38,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:39,257][root][INFO] - Training Epoch: 9/10, step 264/574 completed (loss: 0.6713629364967346, acc: 0.7916666865348816)
[2024-11-29 04:07:39,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:39,874][root][INFO] - Training Epoch: 9/10, step 265/574 completed (loss: 1.6034414768218994, acc: 0.5519999861717224)
[2024-11-29 04:07:39,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:40,469][root][INFO] - Training Epoch: 9/10, step 266/574 completed (loss: 0.9652391076087952, acc: 0.7191011309623718)
[2024-11-29 04:07:40,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:41,062][root][INFO] - Training Epoch: 9/10, step 267/574 completed (loss: 0.8540114164352417, acc: 0.7162162065505981)
[2024-11-29 04:07:41,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:41,655][root][INFO] - Training Epoch: 9/10, step 268/574 completed (loss: 0.6883981227874756, acc: 0.7758620977401733)
[2024-11-29 04:07:41,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:42,241][root][INFO] - Training Epoch: 9/10, step 269/574 completed (loss: 0.012786215171217918, acc: 1.0)
[2024-11-29 04:07:42,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:43,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:43,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:44,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:45,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:45,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:46,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:46,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:47,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:47,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:48,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:48,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:49,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:49,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:50,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:50,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:51,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:51,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:52,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:52,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:53,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:53,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:54,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:55,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:55,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:56,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:56,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:57,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:57,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:58,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:58,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:59,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:07:59,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:00,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:00,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:01,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:01,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:02,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:02,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:03,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:04,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:04,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:05,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:05,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:06,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:06,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:07,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:07,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:08,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:08,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:09,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:09,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:10,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:10,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:11,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:12,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:12,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:13,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:13,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:14,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:14,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:15,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:15,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:16,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:16,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:17,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:17,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:18,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:19,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:19,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:20,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:20,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:21,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:21,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:22,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:22,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:23,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:23,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:24,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:24,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:25,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:25,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:26,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:26,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:27,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:28,263][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.5066, device='cuda:0') eval_epoch_loss=tensor(1.2546, device='cuda:0') eval_epoch_acc=tensor(0.7265, device='cuda:0')
[2024-11-29 04:08:28,265][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 04:08:28,265][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 04:08:28,492][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_9_step_270_loss_1.254645824432373/model.pt
[2024-11-29 04:08:28,496][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 9 is 0.7265159487724304
[2024-11-29 04:08:28,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:29,100][root][INFO] - Training Epoch: 9/10, step 270/574 completed (loss: 0.01879858784377575, acc: 1.0)
[2024-11-29 04:08:29,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:29,687][root][INFO] - Training Epoch: 9/10, step 271/574 completed (loss: 0.04518454521894455, acc: 1.0)
[2024-11-29 04:08:29,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:30,274][root][INFO] - Training Epoch: 9/10, step 272/574 completed (loss: 0.025657180696725845, acc: 1.0)
[2024-11-29 04:08:30,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:30,866][root][INFO] - Training Epoch: 9/10, step 273/574 completed (loss: 0.6345548033714294, acc: 0.8500000238418579)
[2024-11-29 04:08:30,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:31,454][root][INFO] - Training Epoch: 9/10, step 274/574 completed (loss: 0.12766027450561523, acc: 0.96875)
[2024-11-29 04:08:31,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:32,042][root][INFO] - Training Epoch: 9/10, step 275/574 completed (loss: 0.08547916263341904, acc: 0.9666666388511658)
[2024-11-29 04:08:32,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:32,631][root][INFO] - Training Epoch: 9/10, step 276/574 completed (loss: 0.28316521644592285, acc: 0.931034505367279)
[2024-11-29 04:08:32,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:33,217][root][INFO] - Training Epoch: 9/10, step 277/574 completed (loss: 0.011706351302564144, acc: 1.0)
[2024-11-29 04:08:33,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:33,806][root][INFO] - Training Epoch: 9/10, step 278/574 completed (loss: 0.29925623536109924, acc: 0.8936170339584351)
[2024-11-29 04:08:33,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:34,394][root][INFO] - Training Epoch: 9/10, step 279/574 completed (loss: 0.4139539301395416, acc: 0.8541666865348816)
[2024-11-29 04:08:34,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:34,981][root][INFO] - Training Epoch: 9/10, step 280/574 completed (loss: 0.11053615063428879, acc: 0.9772727489471436)
[2024-11-29 04:08:35,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:35,575][root][INFO] - Training Epoch: 9/10, step 281/574 completed (loss: 0.886711835861206, acc: 0.7349397540092468)
[2024-11-29 04:08:35,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:36,168][root][INFO] - Training Epoch: 9/10, step 282/574 completed (loss: 0.8632323741912842, acc: 0.7685185074806213)
[2024-11-29 04:08:36,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:36,754][root][INFO] - Training Epoch: 9/10, step 283/574 completed (loss: 0.3985343277454376, acc: 0.8421052694320679)
[2024-11-29 04:08:36,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:37,340][root][INFO] - Training Epoch: 9/10, step 284/574 completed (loss: 0.3820374011993408, acc: 0.9117646813392639)
[2024-11-29 04:08:37,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:37,929][root][INFO] - Training Epoch: 9/10, step 285/574 completed (loss: 0.17063632607460022, acc: 0.9750000238418579)
[2024-11-29 04:08:38,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:38,523][root][INFO] - Training Epoch: 9/10, step 286/574 completed (loss: 0.9612267017364502, acc: 0.734375)
[2024-11-29 04:08:38,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:39,130][root][INFO] - Training Epoch: 9/10, step 287/574 completed (loss: 1.0106441974639893, acc: 0.7440000176429749)
[2024-11-29 04:08:39,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:39,725][root][INFO] - Training Epoch: 9/10, step 288/574 completed (loss: 0.5763493776321411, acc: 0.8241758346557617)
[2024-11-29 04:08:39,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:40,321][root][INFO] - Training Epoch: 9/10, step 289/574 completed (loss: 1.207254409790039, acc: 0.7080745100975037)
[2024-11-29 04:08:40,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:40,933][root][INFO] - Training Epoch: 9/10, step 290/574 completed (loss: 1.4680726528167725, acc: 0.6082473993301392)
[2024-11-29 04:08:41,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:41,519][root][INFO] - Training Epoch: 9/10, step 291/574 completed (loss: 0.01235736533999443, acc: 1.0)
[2024-11-29 04:08:41,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:42,107][root][INFO] - Training Epoch: 9/10, step 292/574 completed (loss: 0.8267489075660706, acc: 0.7857142686843872)
[2024-11-29 04:08:42,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:42,699][root][INFO] - Training Epoch: 9/10, step 293/574 completed (loss: 0.3595113158226013, acc: 0.8965517282485962)
[2024-11-29 04:08:42,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:43,291][root][INFO] - Training Epoch: 9/10, step 294/574 completed (loss: 0.4705532193183899, acc: 0.8727272748947144)
[2024-11-29 04:08:43,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:43,913][root][INFO] - Training Epoch: 9/10, step 295/574 completed (loss: 1.293728232383728, acc: 0.6288659572601318)
[2024-11-29 04:08:43,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:44,508][root][INFO] - Training Epoch: 9/10, step 296/574 completed (loss: 0.47077617049217224, acc: 0.8275862336158752)
[2024-11-29 04:08:44,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:45,094][root][INFO] - Training Epoch: 9/10, step 297/574 completed (loss: 0.042144183069467545, acc: 1.0)
[2024-11-29 04:08:45,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:45,685][root][INFO] - Training Epoch: 9/10, step 298/574 completed (loss: 0.4356577396392822, acc: 0.8421052694320679)
[2024-11-29 04:08:45,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:46,275][root][INFO] - Training Epoch: 9/10, step 299/574 completed (loss: 0.39300987124443054, acc: 0.9285714030265808)
[2024-11-29 04:08:46,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:46,863][root][INFO] - Training Epoch: 9/10, step 300/574 completed (loss: 0.5960545539855957, acc: 0.84375)
[2024-11-29 04:08:46,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:47,454][root][INFO] - Training Epoch: 9/10, step 301/574 completed (loss: 0.46244847774505615, acc: 0.849056601524353)
[2024-11-29 04:08:47,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:48,044][root][INFO] - Training Epoch: 9/10, step 302/574 completed (loss: 0.06807352602481842, acc: 1.0)
[2024-11-29 04:08:48,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:48,632][root][INFO] - Training Epoch: 9/10, step 303/574 completed (loss: 0.026156965643167496, acc: 1.0)
[2024-11-29 04:08:48,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:49,219][root][INFO] - Training Epoch: 9/10, step 304/574 completed (loss: 0.15036773681640625, acc: 0.96875)
[2024-11-29 04:08:49,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:49,811][root][INFO] - Training Epoch: 9/10, step 305/574 completed (loss: 0.4200046956539154, acc: 0.868852436542511)
[2024-11-29 04:08:49,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:50,397][root][INFO] - Training Epoch: 9/10, step 306/574 completed (loss: 0.11862765997648239, acc: 0.9666666388511658)
[2024-11-29 04:08:50,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:50,982][root][INFO] - Training Epoch: 9/10, step 307/574 completed (loss: 0.017987605184316635, acc: 1.0)
[2024-11-29 04:08:51,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:51,574][root][INFO] - Training Epoch: 9/10, step 308/574 completed (loss: 1.0467780828475952, acc: 0.7101449370384216)
[2024-11-29 04:08:51,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:52,171][root][INFO] - Training Epoch: 9/10, step 309/574 completed (loss: 0.8976132869720459, acc: 0.7916666865348816)
[2024-11-29 04:08:52,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:52,764][root][INFO] - Training Epoch: 9/10, step 310/574 completed (loss: 0.5588006377220154, acc: 0.7951807379722595)
[2024-11-29 04:08:52,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:53,357][root][INFO] - Training Epoch: 9/10, step 311/574 completed (loss: 0.6624972224235535, acc: 0.8589743375778198)
[2024-11-29 04:08:53,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:53,966][root][INFO] - Training Epoch: 9/10, step 312/574 completed (loss: 1.044752597808838, acc: 0.6632652878761292)
[2024-11-29 04:08:54,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:54,554][root][INFO] - Training Epoch: 9/10, step 313/574 completed (loss: 0.0031281921546906233, acc: 1.0)
[2024-11-29 04:08:54,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:55,139][root][INFO] - Training Epoch: 9/10, step 314/574 completed (loss: 0.03027651272714138, acc: 1.0)
[2024-11-29 04:08:55,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:55,726][root][INFO] - Training Epoch: 9/10, step 315/574 completed (loss: 0.025409793481230736, acc: 1.0)
[2024-11-29 04:08:55,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:56,313][root][INFO] - Training Epoch: 9/10, step 316/574 completed (loss: 0.05581508204340935, acc: 0.9677419066429138)
[2024-11-29 04:08:56,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:56,907][root][INFO] - Training Epoch: 9/10, step 317/574 completed (loss: 0.670609176158905, acc: 0.7910447716712952)
[2024-11-29 04:08:56,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:57,504][root][INFO] - Training Epoch: 9/10, step 318/574 completed (loss: 0.7923184037208557, acc: 0.7211538553237915)
[2024-11-29 04:08:57,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:58,092][root][INFO] - Training Epoch: 9/10, step 319/574 completed (loss: 0.33263713121414185, acc: 0.8222222328186035)
[2024-11-29 04:08:58,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:58,683][root][INFO] - Training Epoch: 9/10, step 320/574 completed (loss: 0.22984157502651215, acc: 0.9354838728904724)
[2024-11-29 04:08:58,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:59,272][root][INFO] - Training Epoch: 9/10, step 321/574 completed (loss: 0.25654053688049316, acc: 0.9200000166893005)
[2024-11-29 04:08:59,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:08:59,858][root][INFO] - Training Epoch: 9/10, step 322/574 completed (loss: 0.5202001333236694, acc: 0.8518518805503845)
[2024-11-29 04:08:59,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:00,446][root][INFO] - Training Epoch: 9/10, step 323/574 completed (loss: 0.6610971093177795, acc: 0.8285714387893677)
[2024-11-29 04:09:00,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:01,033][root][INFO] - Training Epoch: 9/10, step 324/574 completed (loss: 0.5989556908607483, acc: 0.7692307829856873)
[2024-11-29 04:09:01,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:01,626][root][INFO] - Training Epoch: 9/10, step 325/574 completed (loss: 0.49090972542762756, acc: 0.9024389982223511)
[2024-11-29 04:09:01,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:02,216][root][INFO] - Training Epoch: 9/10, step 326/574 completed (loss: 0.5295668840408325, acc: 0.8157894611358643)
[2024-11-29 04:09:02,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:02,803][root][INFO] - Training Epoch: 9/10, step 327/574 completed (loss: 0.056078288704156876, acc: 1.0)
[2024-11-29 04:09:02,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:03,390][root][INFO] - Training Epoch: 9/10, step 328/574 completed (loss: 0.019986437633633614, acc: 1.0)
[2024-11-29 04:09:03,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:03,977][root][INFO] - Training Epoch: 9/10, step 329/574 completed (loss: 0.10574230551719666, acc: 1.0)
[2024-11-29 04:09:04,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:04,563][root][INFO] - Training Epoch: 9/10, step 330/574 completed (loss: 0.08139954507350922, acc: 0.96875)
[2024-11-29 04:09:04,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:05,154][root][INFO] - Training Epoch: 9/10, step 331/574 completed (loss: 0.4855811893939972, acc: 0.8387096524238586)
[2024-11-29 04:09:05,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:05,747][root][INFO] - Training Epoch: 9/10, step 332/574 completed (loss: 0.4197610020637512, acc: 0.8070175647735596)
[2024-11-29 04:09:05,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:06,336][root][INFO] - Training Epoch: 9/10, step 333/574 completed (loss: 0.05456910654902458, acc: 1.0)
[2024-11-29 04:09:06,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:06,925][root][INFO] - Training Epoch: 9/10, step 334/574 completed (loss: 0.3535257577896118, acc: 0.9666666388511658)
[2024-11-29 04:09:07,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:07,511][root][INFO] - Training Epoch: 9/10, step 335/574 completed (loss: 0.025525100529193878, acc: 1.0)
[2024-11-29 04:09:07,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:08,103][root][INFO] - Training Epoch: 9/10, step 336/574 completed (loss: 0.3926868140697479, acc: 0.8799999952316284)
[2024-11-29 04:09:08,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:08,701][root][INFO] - Training Epoch: 9/10, step 337/574 completed (loss: 1.0357345342636108, acc: 0.7241379022598267)
[2024-11-29 04:09:08,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:09,298][root][INFO] - Training Epoch: 9/10, step 338/574 completed (loss: 1.116607666015625, acc: 0.6595744490623474)
[2024-11-29 04:09:09,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:09,894][root][INFO] - Training Epoch: 9/10, step 339/574 completed (loss: 1.2053868770599365, acc: 0.6265060305595398)
[2024-11-29 04:09:09,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:10,481][root][INFO] - Training Epoch: 9/10, step 340/574 completed (loss: 0.1396513134241104, acc: 0.95652174949646)
[2024-11-29 04:09:10,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:11,069][root][INFO] - Training Epoch: 9/10, step 341/574 completed (loss: 0.46863844990730286, acc: 0.8717948794364929)
[2024-11-29 04:09:11,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:11,661][root][INFO] - Training Epoch: 9/10, step 342/574 completed (loss: 0.9898983836174011, acc: 0.7469879388809204)
[2024-11-29 04:09:11,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:12,253][root][INFO] - Training Epoch: 9/10, step 343/574 completed (loss: 0.38572385907173157, acc: 0.8867924809455872)
[2024-11-29 04:09:12,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:12,846][root][INFO] - Training Epoch: 9/10, step 344/574 completed (loss: 0.495191365480423, acc: 0.8860759735107422)
[2024-11-29 04:09:12,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:13,435][root][INFO] - Training Epoch: 9/10, step 345/574 completed (loss: 0.29817095398902893, acc: 0.9215686321258545)
[2024-11-29 04:09:13,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:14,031][root][INFO] - Training Epoch: 9/10, step 346/574 completed (loss: 0.6099681854248047, acc: 0.8208954930305481)
[2024-11-29 04:09:14,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:14,616][root][INFO] - Training Epoch: 9/10, step 347/574 completed (loss: 0.21408602595329285, acc: 0.949999988079071)
[2024-11-29 04:09:14,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:15,203][root][INFO] - Training Epoch: 9/10, step 348/574 completed (loss: 0.30862957239151, acc: 0.9200000166893005)
[2024-11-29 04:09:15,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:15,791][root][INFO] - Training Epoch: 9/10, step 349/574 completed (loss: 0.6240371465682983, acc: 0.8055555820465088)
[2024-11-29 04:09:15,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:16,380][root][INFO] - Training Epoch: 9/10, step 350/574 completed (loss: 0.21498408913612366, acc: 0.930232584476471)
[2024-11-29 04:09:16,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:16,968][root][INFO] - Training Epoch: 9/10, step 351/574 completed (loss: 0.30597013235092163, acc: 0.8717948794364929)
[2024-11-29 04:09:17,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:17,566][root][INFO] - Training Epoch: 9/10, step 352/574 completed (loss: 0.6032711267471313, acc: 0.8444444537162781)
[2024-11-29 04:09:17,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:18,154][root][INFO] - Training Epoch: 9/10, step 353/574 completed (loss: 0.062129512429237366, acc: 0.95652174949646)
[2024-11-29 04:09:18,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:18,741][root][INFO] - Training Epoch: 9/10, step 354/574 completed (loss: 0.22409620881080627, acc: 0.9230769276618958)
[2024-11-29 04:09:18,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:19,334][root][INFO] - Training Epoch: 9/10, step 355/574 completed (loss: 1.16451096534729, acc: 0.6483516693115234)
[2024-11-29 04:09:19,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:19,943][root][INFO] - Training Epoch: 9/10, step 356/574 completed (loss: 0.9837633371353149, acc: 0.686956524848938)
[2024-11-29 04:09:20,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:20,538][root][INFO] - Training Epoch: 9/10, step 357/574 completed (loss: 0.753609299659729, acc: 0.804347813129425)
[2024-11-29 04:09:20,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:21,127][root][INFO] - Training Epoch: 9/10, step 358/574 completed (loss: 0.560681164264679, acc: 0.8163265585899353)
[2024-11-29 04:09:21,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:21,713][root][INFO] - Training Epoch: 9/10, step 359/574 completed (loss: 0.07965194433927536, acc: 0.9583333134651184)
[2024-11-29 04:09:21,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:22,299][root][INFO] - Training Epoch: 9/10, step 360/574 completed (loss: 0.05666453391313553, acc: 1.0)
[2024-11-29 04:09:22,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:22,887][root][INFO] - Training Epoch: 9/10, step 361/574 completed (loss: 0.2963859736919403, acc: 0.9512194991111755)
[2024-11-29 04:09:22,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:23,476][root][INFO] - Training Epoch: 9/10, step 362/574 completed (loss: 0.28502121567726135, acc: 0.8666666746139526)
[2024-11-29 04:09:23,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:24,069][root][INFO] - Training Epoch: 9/10, step 363/574 completed (loss: 0.5771884918212891, acc: 0.8289473652839661)
[2024-11-29 04:09:24,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:24,660][root][INFO] - Training Epoch: 9/10, step 364/574 completed (loss: 0.5848994255065918, acc: 0.8292682766914368)
[2024-11-29 04:09:24,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:25,248][root][INFO] - Training Epoch: 9/10, step 365/574 completed (loss: 0.10945793241262436, acc: 1.0)
[2024-11-29 04:09:25,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:25,834][root][INFO] - Training Epoch: 9/10, step 366/574 completed (loss: 0.007366242352873087, acc: 1.0)
[2024-11-29 04:09:25,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:26,419][root][INFO] - Training Epoch: 9/10, step 367/574 completed (loss: 0.007095310837030411, acc: 1.0)
[2024-11-29 04:09:26,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:27,004][root][INFO] - Training Epoch: 9/10, step 368/574 completed (loss: 0.05935494229197502, acc: 1.0)
[2024-11-29 04:09:27,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:27,592][root][INFO] - Training Epoch: 9/10, step 369/574 completed (loss: 0.16772480309009552, acc: 0.96875)
[2024-11-29 04:09:27,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:28,204][root][INFO] - Training Epoch: 9/10, step 370/574 completed (loss: 1.8243732452392578, acc: 0.5454545617103577)
[2024-11-29 04:09:28,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:28,816][root][INFO] - Training Epoch: 9/10, step 371/574 completed (loss: 1.041723370552063, acc: 0.7358490824699402)
[2024-11-29 04:09:28,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:29,415][root][INFO] - Training Epoch: 9/10, step 372/574 completed (loss: 0.6480149626731873, acc: 0.8111110925674438)
[2024-11-29 04:09:29,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:30,006][root][INFO] - Training Epoch: 9/10, step 373/574 completed (loss: 0.5819220542907715, acc: 0.8928571343421936)
[2024-11-29 04:09:30,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:30,598][root][INFO] - Training Epoch: 9/10, step 374/574 completed (loss: 0.3454328179359436, acc: 0.8857142925262451)
[2024-11-29 04:09:30,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:31,186][root][INFO] - Training Epoch: 9/10, step 375/574 completed (loss: 0.006801477167755365, acc: 1.0)
[2024-11-29 04:09:31,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:31,772][root][INFO] - Training Epoch: 9/10, step 376/574 completed (loss: 0.010045749135315418, acc: 1.0)
[2024-11-29 04:09:31,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:32,363][root][INFO] - Training Epoch: 9/10, step 377/574 completed (loss: 0.24259920418262482, acc: 0.9166666865348816)
[2024-11-29 04:09:32,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:32,957][root][INFO] - Training Epoch: 9/10, step 378/574 completed (loss: 0.29182881116867065, acc: 0.9473684430122375)
[2024-11-29 04:09:33,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:33,568][root][INFO] - Training Epoch: 9/10, step 379/574 completed (loss: 1.0919549465179443, acc: 0.7065868377685547)
[2024-11-29 04:09:33,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:34,166][root][INFO] - Training Epoch: 9/10, step 380/574 completed (loss: 0.686405599117279, acc: 0.7969924807548523)
[2024-11-29 04:09:34,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:34,785][root][INFO] - Training Epoch: 9/10, step 381/574 completed (loss: 1.2217036485671997, acc: 0.6684492230415344)
[2024-11-29 04:09:34,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:35,394][root][INFO] - Training Epoch: 9/10, step 382/574 completed (loss: 0.6645461320877075, acc: 0.8198198080062866)
[2024-11-29 04:09:35,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:35,982][root][INFO] - Training Epoch: 9/10, step 383/574 completed (loss: 0.10574883967638016, acc: 0.9642857313156128)
[2024-11-29 04:09:36,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:36,567][root][INFO] - Training Epoch: 9/10, step 384/574 completed (loss: 0.008763276040554047, acc: 1.0)
[2024-11-29 04:09:36,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:37,154][root][INFO] - Training Epoch: 9/10, step 385/574 completed (loss: 0.029935965314507484, acc: 1.0)
[2024-11-29 04:09:37,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:37,740][root][INFO] - Training Epoch: 9/10, step 386/574 completed (loss: 0.06684844940900803, acc: 0.9722222089767456)
[2024-11-29 04:09:37,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:38,326][root][INFO] - Training Epoch: 9/10, step 387/574 completed (loss: 0.022681718692183495, acc: 1.0)
[2024-11-29 04:09:38,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:38,911][root][INFO] - Training Epoch: 9/10, step 388/574 completed (loss: 0.0067772818729281425, acc: 1.0)
[2024-11-29 04:09:38,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:39,496][root][INFO] - Training Epoch: 9/10, step 389/574 completed (loss: 0.00407013576477766, acc: 1.0)
[2024-11-29 04:09:39,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:40,082][root][INFO] - Training Epoch: 9/10, step 390/574 completed (loss: 0.134743332862854, acc: 0.9523809552192688)
[2024-11-29 04:09:40,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:40,670][root][INFO] - Training Epoch: 9/10, step 391/574 completed (loss: 0.42174607515335083, acc: 0.8703703880310059)
[2024-11-29 04:09:40,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:41,263][root][INFO] - Training Epoch: 9/10, step 392/574 completed (loss: 1.0451631546020508, acc: 0.6699029207229614)
[2024-11-29 04:09:41,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:41,877][root][INFO] - Training Epoch: 9/10, step 393/574 completed (loss: 1.2676507234573364, acc: 0.654411792755127)
[2024-11-29 04:09:41,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:42,475][root][INFO] - Training Epoch: 9/10, step 394/574 completed (loss: 1.2990074157714844, acc: 0.6600000262260437)
[2024-11-29 04:09:42,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:43,072][root][INFO] - Training Epoch: 9/10, step 395/574 completed (loss: 1.107872486114502, acc: 0.7083333134651184)
[2024-11-29 04:09:43,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:43,660][root][INFO] - Training Epoch: 9/10, step 396/574 completed (loss: 0.16717472672462463, acc: 0.9534883499145508)
[2024-11-29 04:09:43,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:44,247][root][INFO] - Training Epoch: 9/10, step 397/574 completed (loss: 0.0252611692994833, acc: 1.0)
[2024-11-29 04:09:44,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:44,836][root][INFO] - Training Epoch: 9/10, step 398/574 completed (loss: 0.34324830770492554, acc: 0.8604651093482971)
[2024-11-29 04:09:44,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:45,422][root][INFO] - Training Epoch: 9/10, step 399/574 completed (loss: 0.03111039102077484, acc: 1.0)
[2024-11-29 04:09:45,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:46,018][root][INFO] - Training Epoch: 9/10, step 400/574 completed (loss: 0.680968165397644, acc: 0.7941176295280457)
[2024-11-29 04:09:46,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:46,611][root][INFO] - Training Epoch: 9/10, step 401/574 completed (loss: 0.3994417190551758, acc: 0.8933333158493042)
[2024-11-29 04:09:46,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:47,200][root][INFO] - Training Epoch: 9/10, step 402/574 completed (loss: 0.06142335385084152, acc: 1.0)
[2024-11-29 04:09:47,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:47,787][root][INFO] - Training Epoch: 9/10, step 403/574 completed (loss: 0.30083391070365906, acc: 0.939393937587738)
[2024-11-29 04:09:47,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:48,374][root][INFO] - Training Epoch: 9/10, step 404/574 completed (loss: 0.003986862953752279, acc: 1.0)
[2024-11-29 04:09:48,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:48,961][root][INFO] - Training Epoch: 9/10, step 405/574 completed (loss: 0.0429118312895298, acc: 0.9629629850387573)
[2024-11-29 04:09:49,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:49,545][root][INFO] - Training Epoch: 9/10, step 406/574 completed (loss: 0.005873677786439657, acc: 1.0)
[2024-11-29 04:09:49,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:50,132][root][INFO] - Training Epoch: 9/10, step 407/574 completed (loss: 0.041672755032777786, acc: 0.9722222089767456)
[2024-11-29 04:09:50,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:50,717][root][INFO] - Training Epoch: 9/10, step 408/574 completed (loss: 0.015162263996899128, acc: 1.0)
[2024-11-29 04:09:50,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:51,303][root][INFO] - Training Epoch: 9/10, step 409/574 completed (loss: 0.04080462455749512, acc: 1.0)
[2024-11-29 04:09:51,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:51,894][root][INFO] - Training Epoch: 9/10, step 410/574 completed (loss: 0.22679173946380615, acc: 0.9482758641242981)
[2024-11-29 04:09:51,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:52,481][root][INFO] - Training Epoch: 9/10, step 411/574 completed (loss: 0.04267182573676109, acc: 1.0)
[2024-11-29 04:09:52,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:53,069][root][INFO] - Training Epoch: 9/10, step 412/574 completed (loss: 0.48306864500045776, acc: 0.9333333373069763)
[2024-11-29 04:09:53,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:54,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:54,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:55,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:55,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:56,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:56,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:57,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:57,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:58,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:59,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:09:59,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:00,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:00,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:01,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:01,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:02,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:02,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:03,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:03,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:04,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:04,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:05,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:05,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:06,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:06,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:07,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:08,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:08,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:09,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:09,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:10,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:10,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:11,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:11,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:12,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:12,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:13,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:13,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:14,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:14,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:15,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:15,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:16,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:17,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:17,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:18,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:18,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:19,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:19,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:20,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:20,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:21,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:21,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:22,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:22,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:23,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:23,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:24,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:25,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:25,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:26,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:26,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:27,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:27,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:28,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:28,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:29,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:29,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:30,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:30,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:31,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:31,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:32,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:33,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:33,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:34,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:34,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:35,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:35,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:36,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:36,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:37,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:37,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:38,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:39,174][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.5199, device='cuda:0') eval_epoch_loss=tensor(1.2584, device='cuda:0') eval_epoch_acc=tensor(0.7058, device='cuda:0')
[2024-11-29 04:10:39,175][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 04:10:39,176][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 04:10:39,376][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_9_step_413_loss_1.2584363222122192/model.pt
[2024-11-29 04:10:39,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:39,987][root][INFO] - Training Epoch: 9/10, step 413/574 completed (loss: 0.12611733376979828, acc: 0.939393937587738)
[2024-11-29 04:10:40,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:40,573][root][INFO] - Training Epoch: 9/10, step 414/574 completed (loss: 0.12036464363336563, acc: 0.9090909361839294)
[2024-11-29 04:10:40,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:41,163][root][INFO] - Training Epoch: 9/10, step 415/574 completed (loss: 0.613513171672821, acc: 0.8235294222831726)
[2024-11-29 04:10:41,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:41,752][root][INFO] - Training Epoch: 9/10, step 416/574 completed (loss: 0.04932127147912979, acc: 1.0)
[2024-11-29 04:10:41,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:42,337][root][INFO] - Training Epoch: 9/10, step 417/574 completed (loss: 0.18292024731636047, acc: 0.9444444179534912)
[2024-11-29 04:10:42,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:42,931][root][INFO] - Training Epoch: 9/10, step 418/574 completed (loss: 0.16363392770290375, acc: 0.949999988079071)
[2024-11-29 04:10:43,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:43,517][root][INFO] - Training Epoch: 9/10, step 419/574 completed (loss: 0.5255602598190308, acc: 0.8500000238418579)
[2024-11-29 04:10:43,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:44,103][root][INFO] - Training Epoch: 9/10, step 420/574 completed (loss: 0.0076102083548903465, acc: 1.0)
[2024-11-29 04:10:44,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:44,688][root][INFO] - Training Epoch: 9/10, step 421/574 completed (loss: 0.047272320836782455, acc: 1.0)
[2024-11-29 04:10:44,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:45,276][root][INFO] - Training Epoch: 9/10, step 422/574 completed (loss: 0.24212540686130524, acc: 0.90625)
[2024-11-29 04:10:45,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:45,863][root][INFO] - Training Epoch: 9/10, step 423/574 completed (loss: 0.3629986047744751, acc: 0.9444444179534912)
[2024-11-29 04:10:45,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:46,449][root][INFO] - Training Epoch: 9/10, step 424/574 completed (loss: 0.024271832779049873, acc: 1.0)
[2024-11-29 04:10:46,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:47,035][root][INFO] - Training Epoch: 9/10, step 425/574 completed (loss: 0.24738049507141113, acc: 0.939393937587738)
[2024-11-29 04:10:47,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:47,622][root][INFO] - Training Epoch: 9/10, step 426/574 completed (loss: 0.11823622137308121, acc: 0.95652174949646)
[2024-11-29 04:10:47,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:48,208][root][INFO] - Training Epoch: 9/10, step 427/574 completed (loss: 0.07665588706731796, acc: 0.9729729890823364)
[2024-11-29 04:10:48,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:48,796][root][INFO] - Training Epoch: 9/10, step 428/574 completed (loss: 0.010000870563089848, acc: 1.0)
[2024-11-29 04:10:48,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:49,380][root][INFO] - Training Epoch: 9/10, step 429/574 completed (loss: 0.3168102502822876, acc: 0.8695651888847351)
[2024-11-29 04:10:49,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:49,966][root][INFO] - Training Epoch: 9/10, step 430/574 completed (loss: 0.006783630698919296, acc: 1.0)
[2024-11-29 04:10:50,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:50,552][root][INFO] - Training Epoch: 9/10, step 431/574 completed (loss: 0.004979969933629036, acc: 1.0)
[2024-11-29 04:10:50,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:51,139][root][INFO] - Training Epoch: 9/10, step 432/574 completed (loss: 0.003765888512134552, acc: 1.0)
[2024-11-29 04:10:51,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:51,726][root][INFO] - Training Epoch: 9/10, step 433/574 completed (loss: 0.3702433109283447, acc: 0.8888888955116272)
[2024-11-29 04:10:51,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:52,313][root][INFO] - Training Epoch: 9/10, step 434/574 completed (loss: 0.28219878673553467, acc: 0.9599999785423279)
[2024-11-29 04:10:52,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:52,899][root][INFO] - Training Epoch: 9/10, step 435/574 completed (loss: 0.17597776651382446, acc: 0.939393937587738)
[2024-11-29 04:10:52,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:53,488][root][INFO] - Training Epoch: 9/10, step 436/574 completed (loss: 0.3484836518764496, acc: 0.8888888955116272)
[2024-11-29 04:10:53,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:54,078][root][INFO] - Training Epoch: 9/10, step 437/574 completed (loss: 0.20338867604732513, acc: 0.9545454382896423)
[2024-11-29 04:10:54,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:54,666][root][INFO] - Training Epoch: 9/10, step 438/574 completed (loss: 0.015774482861161232, acc: 1.0)
[2024-11-29 04:10:54,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:55,254][root][INFO] - Training Epoch: 9/10, step 439/574 completed (loss: 0.5654897093772888, acc: 0.8717948794364929)
[2024-11-29 04:10:55,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:55,852][root][INFO] - Training Epoch: 9/10, step 440/574 completed (loss: 0.7530452013015747, acc: 0.8333333134651184)
[2024-11-29 04:10:55,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:56,463][root][INFO] - Training Epoch: 9/10, step 441/574 completed (loss: 1.8605319261550903, acc: 0.5120000243186951)
[2024-11-29 04:10:56,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:57,059][root][INFO] - Training Epoch: 9/10, step 442/574 completed (loss: 1.2260719537734985, acc: 0.6612903475761414)
[2024-11-29 04:10:57,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:57,672][root][INFO] - Training Epoch: 9/10, step 443/574 completed (loss: 1.5448271036148071, acc: 0.5771144032478333)
[2024-11-29 04:10:57,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:58,267][root][INFO] - Training Epoch: 9/10, step 444/574 completed (loss: 0.38911670446395874, acc: 0.9056603908538818)
[2024-11-29 04:10:58,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:58,859][root][INFO] - Training Epoch: 9/10, step 445/574 completed (loss: 0.2934657037258148, acc: 0.9545454382896423)
[2024-11-29 04:10:58,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:10:59,447][root][INFO] - Training Epoch: 9/10, step 446/574 completed (loss: 0.010641241446137428, acc: 1.0)
[2024-11-29 04:10:59,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:00,032][root][INFO] - Training Epoch: 9/10, step 447/574 completed (loss: 0.19768844544887543, acc: 0.9615384340286255)
[2024-11-29 04:11:00,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:00,618][root][INFO] - Training Epoch: 9/10, step 448/574 completed (loss: 0.023787641897797585, acc: 1.0)
[2024-11-29 04:11:00,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:01,205][root][INFO] - Training Epoch: 9/10, step 449/574 completed (loss: 0.35645797848701477, acc: 0.8805969953536987)
[2024-11-29 04:11:01,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:01,798][root][INFO] - Training Epoch: 9/10, step 450/574 completed (loss: 0.2974070608615875, acc: 0.9444444179534912)
[2024-11-29 04:11:01,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:02,390][root][INFO] - Training Epoch: 9/10, step 451/574 completed (loss: 0.39926886558532715, acc: 0.9130434989929199)
[2024-11-29 04:11:02,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:02,983][root][INFO] - Training Epoch: 9/10, step 452/574 completed (loss: 0.39765864610671997, acc: 0.9102563858032227)
[2024-11-29 04:11:03,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:03,576][root][INFO] - Training Epoch: 9/10, step 453/574 completed (loss: 0.468967080116272, acc: 0.8421052694320679)
[2024-11-29 04:11:03,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:04,166][root][INFO] - Training Epoch: 9/10, step 454/574 completed (loss: 0.1481713205575943, acc: 0.9591836929321289)
[2024-11-29 04:11:04,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:04,753][root][INFO] - Training Epoch: 9/10, step 455/574 completed (loss: 0.2137298732995987, acc: 0.9090909361839294)
[2024-11-29 04:11:04,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:05,349][root][INFO] - Training Epoch: 9/10, step 456/574 completed (loss: 0.797656238079071, acc: 0.8247422575950623)
[2024-11-29 04:11:05,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:05,940][root][INFO] - Training Epoch: 9/10, step 457/574 completed (loss: 0.17160582542419434, acc: 0.9714285731315613)
[2024-11-29 04:11:06,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:06,561][root][INFO] - Training Epoch: 9/10, step 458/574 completed (loss: 1.2592226266860962, acc: 0.604651153087616)
[2024-11-29 04:11:06,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:07,152][root][INFO] - Training Epoch: 9/10, step 459/574 completed (loss: 0.25451305508613586, acc: 0.9464285969734192)
[2024-11-29 04:11:07,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:07,751][root][INFO] - Training Epoch: 9/10, step 460/574 completed (loss: 0.5391469597816467, acc: 0.8271604776382446)
[2024-11-29 04:11:07,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:08,340][root][INFO] - Training Epoch: 9/10, step 461/574 completed (loss: 0.28327780961990356, acc: 0.8888888955116272)
[2024-11-29 04:11:08,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:08,930][root][INFO] - Training Epoch: 9/10, step 462/574 completed (loss: 0.3496004045009613, acc: 0.96875)
[2024-11-29 04:11:09,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:09,515][root][INFO] - Training Epoch: 9/10, step 463/574 completed (loss: 0.09726132452487946, acc: 1.0)
[2024-11-29 04:11:09,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:10,105][root][INFO] - Training Epoch: 9/10, step 464/574 completed (loss: 0.20909398794174194, acc: 0.9130434989929199)
[2024-11-29 04:11:10,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:10,699][root][INFO] - Training Epoch: 9/10, step 465/574 completed (loss: 0.4090180993080139, acc: 0.8452380895614624)
[2024-11-29 04:11:10,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:11,293][root][INFO] - Training Epoch: 9/10, step 466/574 completed (loss: 0.45493561029434204, acc: 0.8433734774589539)
[2024-11-29 04:11:11,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:11,904][root][INFO] - Training Epoch: 9/10, step 467/574 completed (loss: 0.7647144198417664, acc: 0.7657657861709595)
[2024-11-29 04:11:11,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:12,498][root][INFO] - Training Epoch: 9/10, step 468/574 completed (loss: 0.8267963528633118, acc: 0.7864077687263489)
[2024-11-29 04:11:12,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:13,110][root][INFO] - Training Epoch: 9/10, step 469/574 completed (loss: 0.8855080604553223, acc: 0.7479674816131592)
[2024-11-29 04:11:13,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:13,698][root][INFO] - Training Epoch: 9/10, step 470/574 completed (loss: 0.03604114055633545, acc: 1.0)
[2024-11-29 04:11:13,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:14,283][root][INFO] - Training Epoch: 9/10, step 471/574 completed (loss: 0.04315223917365074, acc: 1.0)
[2024-11-29 04:11:14,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:14,898][root][INFO] - Training Epoch: 9/10, step 472/574 completed (loss: 1.4313961267471313, acc: 0.6176470518112183)
[2024-11-29 04:11:14,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:15,510][root][INFO] - Training Epoch: 9/10, step 473/574 completed (loss: 1.755086898803711, acc: 0.5502183437347412)
[2024-11-29 04:11:15,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:16,104][root][INFO] - Training Epoch: 9/10, step 474/574 completed (loss: 0.5913631319999695, acc: 0.8020833134651184)
[2024-11-29 04:11:16,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:16,703][root][INFO] - Training Epoch: 9/10, step 475/574 completed (loss: 1.0113345384597778, acc: 0.7055214643478394)
[2024-11-29 04:11:16,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:17,303][root][INFO] - Training Epoch: 9/10, step 476/574 completed (loss: 0.8156490921974182, acc: 0.7410072088241577)
[2024-11-29 04:11:17,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:17,915][root][INFO] - Training Epoch: 9/10, step 477/574 completed (loss: 1.5550687313079834, acc: 0.5678392052650452)
[2024-11-29 04:11:17,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:18,504][root][INFO] - Training Epoch: 9/10, step 478/574 completed (loss: 0.16551260650157928, acc: 0.9722222089767456)
[2024-11-29 04:11:18,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:19,090][root][INFO] - Training Epoch: 9/10, step 479/574 completed (loss: 0.195338636636734, acc: 0.9090909361839294)
[2024-11-29 04:11:19,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:19,678][root][INFO] - Training Epoch: 9/10, step 480/574 completed (loss: 0.01033763401210308, acc: 1.0)
[2024-11-29 04:11:19,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:20,263][root][INFO] - Training Epoch: 9/10, step 481/574 completed (loss: 0.01655084826052189, acc: 1.0)
[2024-11-29 04:11:20,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:20,849][root][INFO] - Training Epoch: 9/10, step 482/574 completed (loss: 0.037934307008981705, acc: 1.0)
[2024-11-29 04:11:20,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:21,445][root][INFO] - Training Epoch: 9/10, step 483/574 completed (loss: 0.5567887425422668, acc: 0.8793103694915771)
[2024-11-29 04:11:21,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:22,032][root][INFO] - Training Epoch: 9/10, step 484/574 completed (loss: 0.04693261906504631, acc: 1.0)
[2024-11-29 04:11:22,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:22,618][root][INFO] - Training Epoch: 9/10, step 485/574 completed (loss: 0.14928558468818665, acc: 0.9473684430122375)
[2024-11-29 04:11:22,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:23,205][root][INFO] - Training Epoch: 9/10, step 486/574 completed (loss: 0.1616107076406479, acc: 0.9259259104728699)
[2024-11-29 04:11:23,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:23,791][root][INFO] - Training Epoch: 9/10, step 487/574 completed (loss: 0.052634097635746, acc: 1.0)
[2024-11-29 04:11:23,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:24,377][root][INFO] - Training Epoch: 9/10, step 488/574 completed (loss: 0.039044711738824844, acc: 1.0)
[2024-11-29 04:11:24,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:24,969][root][INFO] - Training Epoch: 9/10, step 489/574 completed (loss: 0.5981495380401611, acc: 0.8153846263885498)
[2024-11-29 04:11:25,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:25,559][root][INFO] - Training Epoch: 9/10, step 490/574 completed (loss: 0.08488541096448898, acc: 0.9666666388511658)
[2024-11-29 04:11:25,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:26,145][root][INFO] - Training Epoch: 9/10, step 491/574 completed (loss: 0.24590080976486206, acc: 0.9655172228813171)
[2024-11-29 04:11:26,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:26,736][root][INFO] - Training Epoch: 9/10, step 492/574 completed (loss: 0.19661632180213928, acc: 0.9607843160629272)
[2024-11-29 04:11:26,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:27,322][root][INFO] - Training Epoch: 9/10, step 493/574 completed (loss: 0.11964379996061325, acc: 0.9655172228813171)
[2024-11-29 04:11:27,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:27,909][root][INFO] - Training Epoch: 9/10, step 494/574 completed (loss: 0.00922638364136219, acc: 1.0)
[2024-11-29 04:11:27,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:28,496][root][INFO] - Training Epoch: 9/10, step 495/574 completed (loss: 0.02358550764620304, acc: 1.0)
[2024-11-29 04:11:28,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:29,092][root][INFO] - Training Epoch: 9/10, step 496/574 completed (loss: 1.1418163776397705, acc: 0.7053571343421936)
[2024-11-29 04:11:29,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:29,686][root][INFO] - Training Epoch: 9/10, step 497/574 completed (loss: 0.7247783541679382, acc: 0.8089887499809265)
[2024-11-29 04:11:29,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:30,284][root][INFO] - Training Epoch: 9/10, step 498/574 completed (loss: 1.010970115661621, acc: 0.7415730357170105)
[2024-11-29 04:11:30,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:30,892][root][INFO] - Training Epoch: 9/10, step 499/574 completed (loss: 1.2508996725082397, acc: 0.6241135001182556)
[2024-11-29 04:11:30,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:31,494][root][INFO] - Training Epoch: 9/10, step 500/574 completed (loss: 0.9988909959793091, acc: 0.6521739363670349)
[2024-11-29 04:11:31,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:32,081][root][INFO] - Training Epoch: 9/10, step 501/574 completed (loss: 0.06892076134681702, acc: 0.9599999785423279)
[2024-11-29 04:11:32,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:32,669][root][INFO] - Training Epoch: 9/10, step 502/574 completed (loss: 0.01824108324944973, acc: 1.0)
[2024-11-29 04:11:32,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:33,254][root][INFO] - Training Epoch: 9/10, step 503/574 completed (loss: 0.011685491539537907, acc: 1.0)
[2024-11-29 04:11:33,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:33,842][root][INFO] - Training Epoch: 9/10, step 504/574 completed (loss: 0.11361955851316452, acc: 0.9259259104728699)
[2024-11-29 04:11:33,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:34,431][root][INFO] - Training Epoch: 9/10, step 505/574 completed (loss: 0.25674688816070557, acc: 0.9245283007621765)
[2024-11-29 04:11:34,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:35,018][root][INFO] - Training Epoch: 9/10, step 506/574 completed (loss: 0.08624286204576492, acc: 0.9655172228813171)
[2024-11-29 04:11:35,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:35,614][root][INFO] - Training Epoch: 9/10, step 507/574 completed (loss: 1.044872760772705, acc: 0.7207207083702087)
[2024-11-29 04:11:35,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:36,210][root][INFO] - Training Epoch: 9/10, step 508/574 completed (loss: 0.41383910179138184, acc: 0.8732394576072693)
[2024-11-29 04:11:36,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:36,795][root][INFO] - Training Epoch: 9/10, step 509/574 completed (loss: 0.003244660794734955, acc: 1.0)
[2024-11-29 04:11:36,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:37,381][root][INFO] - Training Epoch: 9/10, step 510/574 completed (loss: 0.08753745257854462, acc: 0.9666666388511658)
[2024-11-29 04:11:37,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:37,967][root][INFO] - Training Epoch: 9/10, step 511/574 completed (loss: 0.042659662663936615, acc: 1.0)
[2024-11-29 04:11:38,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:38,600][root][INFO] - Training Epoch: 9/10, step 512/574 completed (loss: 1.9605621099472046, acc: 0.4714285731315613)
[2024-11-29 04:11:38,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:39,211][root][INFO] - Training Epoch: 9/10, step 513/574 completed (loss: 1.1175063848495483, acc: 0.7222222089767456)
[2024-11-29 04:11:39,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:39,799][root][INFO] - Training Epoch: 9/10, step 514/574 completed (loss: 0.18977241218090057, acc: 0.9642857313156128)
[2024-11-29 04:11:39,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:40,393][root][INFO] - Training Epoch: 9/10, step 515/574 completed (loss: 0.12432748824357986, acc: 0.949999988079071)
[2024-11-29 04:11:40,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:40,991][root][INFO] - Training Epoch: 9/10, step 516/574 completed (loss: 0.7898557782173157, acc: 0.7777777910232544)
[2024-11-29 04:11:41,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:41,577][root][INFO] - Training Epoch: 9/10, step 517/574 completed (loss: 0.0026496523059904575, acc: 1.0)
[2024-11-29 04:11:41,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:42,164][root][INFO] - Training Epoch: 9/10, step 518/574 completed (loss: 0.033507756888866425, acc: 1.0)
[2024-11-29 04:11:42,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:42,744][root][INFO] - Training Epoch: 9/10, step 519/574 completed (loss: 0.009415077045559883, acc: 1.0)
[2024-11-29 04:11:42,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:43,330][root][INFO] - Training Epoch: 9/10, step 520/574 completed (loss: 0.08373972773551941, acc: 1.0)
[2024-11-29 04:11:43,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:44,129][root][INFO] - Training Epoch: 9/10, step 521/574 completed (loss: 1.9103726148605347, acc: 0.5254237055778503)
[2024-11-29 04:11:44,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:44,748][root][INFO] - Training Epoch: 9/10, step 522/574 completed (loss: 0.8375493288040161, acc: 0.753731369972229)
[2024-11-29 04:11:44,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:45,345][root][INFO] - Training Epoch: 9/10, step 523/574 completed (loss: 0.8957045078277588, acc: 0.7445255517959595)
[2024-11-29 04:11:45,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:45,964][root][INFO] - Training Epoch: 9/10, step 524/574 completed (loss: 1.3092869520187378, acc: 0.6650000214576721)
[2024-11-29 04:11:46,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:46,558][root][INFO] - Training Epoch: 9/10, step 525/574 completed (loss: 0.09769197553396225, acc: 0.9814814925193787)
[2024-11-29 04:11:46,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:47,151][root][INFO] - Training Epoch: 9/10, step 526/574 completed (loss: 0.19349494576454163, acc: 0.942307710647583)
[2024-11-29 04:11:47,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:47,737][root][INFO] - Training Epoch: 9/10, step 527/574 completed (loss: 0.010231800377368927, acc: 1.0)
[2024-11-29 04:11:47,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:48,332][root][INFO] - Training Epoch: 9/10, step 528/574 completed (loss: 0.8483572006225586, acc: 0.7868852615356445)
[2024-11-29 04:11:48,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:48,922][root][INFO] - Training Epoch: 9/10, step 529/574 completed (loss: 0.38817426562309265, acc: 0.8813559412956238)
[2024-11-29 04:11:49,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:49,514][root][INFO] - Training Epoch: 9/10, step 530/574 completed (loss: 0.2718006372451782, acc: 0.8837209343910217)
[2024-11-29 04:11:49,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:50,102][root][INFO] - Training Epoch: 9/10, step 531/574 completed (loss: 0.553709089756012, acc: 0.8863636255264282)
[2024-11-29 04:11:50,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:50,695][root][INFO] - Training Epoch: 9/10, step 532/574 completed (loss: 0.43946346640586853, acc: 0.8867924809455872)
[2024-11-29 04:11:50,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:51,282][root][INFO] - Training Epoch: 9/10, step 533/574 completed (loss: 0.30811402201652527, acc: 0.8636363744735718)
[2024-11-29 04:11:51,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:51,871][root][INFO] - Training Epoch: 9/10, step 534/574 completed (loss: 0.1651562750339508, acc: 0.9200000166893005)
[2024-11-29 04:11:51,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:52,457][root][INFO] - Training Epoch: 9/10, step 535/574 completed (loss: 0.08213479816913605, acc: 0.949999988079071)
[2024-11-29 04:11:52,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:53,043][root][INFO] - Training Epoch: 9/10, step 536/574 completed (loss: 0.024057531729340553, acc: 1.0)
[2024-11-29 04:11:53,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:53,634][root][INFO] - Training Epoch: 9/10, step 537/574 completed (loss: 0.304429829120636, acc: 0.892307698726654)
[2024-11-29 04:11:53,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:54,231][root][INFO] - Training Epoch: 9/10, step 538/574 completed (loss: 0.42473292350769043, acc: 0.875)
[2024-11-29 04:11:54,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:54,818][root][INFO] - Training Epoch: 9/10, step 539/574 completed (loss: 0.08901874721050262, acc: 0.96875)
[2024-11-29 04:11:54,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:55,407][root][INFO] - Training Epoch: 9/10, step 540/574 completed (loss: 0.263460636138916, acc: 0.9696969985961914)
[2024-11-29 04:11:55,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:55,991][root][INFO] - Training Epoch: 9/10, step 541/574 completed (loss: 0.03547205775976181, acc: 1.0)
[2024-11-29 04:11:56,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:56,579][root][INFO] - Training Epoch: 9/10, step 542/574 completed (loss: 0.020520731806755066, acc: 1.0)
[2024-11-29 04:11:56,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:57,163][root][INFO] - Training Epoch: 9/10, step 543/574 completed (loss: 0.0021049671340733767, acc: 1.0)
[2024-11-29 04:11:57,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:57,748][root][INFO] - Training Epoch: 9/10, step 544/574 completed (loss: 0.05295252427458763, acc: 1.0)
[2024-11-29 04:11:57,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:58,336][root][INFO] - Training Epoch: 9/10, step 545/574 completed (loss: 0.08767050504684448, acc: 0.9512194991111755)
[2024-11-29 04:11:58,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:58,927][root][INFO] - Training Epoch: 9/10, step 546/574 completed (loss: 0.12105399370193481, acc: 0.9714285731315613)
[2024-11-29 04:11:59,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:11:59,516][root][INFO] - Training Epoch: 9/10, step 547/574 completed (loss: 0.1050424873828888, acc: 0.9473684430122375)
[2024-11-29 04:11:59,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:00,106][root][INFO] - Training Epoch: 9/10, step 548/574 completed (loss: 0.10176931321620941, acc: 0.9677419066429138)
[2024-11-29 04:12:00,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:00,692][root][INFO] - Training Epoch: 9/10, step 549/574 completed (loss: 0.02450660429894924, acc: 1.0)
[2024-11-29 04:12:00,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:01,282][root][INFO] - Training Epoch: 9/10, step 550/574 completed (loss: 0.18379490077495575, acc: 0.9696969985961914)
[2024-11-29 04:12:01,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:01,870][root][INFO] - Training Epoch: 9/10, step 551/574 completed (loss: 0.10363759100437164, acc: 0.949999988079071)
[2024-11-29 04:12:01,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:02,470][root][INFO] - Training Epoch: 9/10, step 552/574 completed (loss: 0.2258613109588623, acc: 0.9285714030265808)
[2024-11-29 04:12:02,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:03,078][root][INFO] - Training Epoch: 9/10, step 553/574 completed (loss: 0.9909608960151672, acc: 0.7299270033836365)
[2024-11-29 04:12:03,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:03,687][root][INFO] - Training Epoch: 9/10, step 554/574 completed (loss: 0.7590065002441406, acc: 0.800000011920929)
[2024-11-29 04:12:03,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:04,286][root][INFO] - Training Epoch: 9/10, step 555/574 completed (loss: 0.9397774934768677, acc: 0.7571428418159485)
[2024-11-29 04:12:04,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:05,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:05,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:06,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:07,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:07,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:08,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:08,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:09,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:09,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:10,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:10,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:11,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:11,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:12,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:12,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:13,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:13,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:14,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:14,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:15,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:15,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:16,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:17,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:17,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:17,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:18,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:19,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:19,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:20,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:20,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:21,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:21,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:22,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:22,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:23,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:23,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:24,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:24,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:25,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:25,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:26,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:26,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:27,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:28,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:28,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:29,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:29,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:30,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:30,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:31,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:31,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:32,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:32,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:33,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:33,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:34,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:34,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:35,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:35,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:36,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:37,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:37,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:38,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:38,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:39,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:39,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:40,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:40,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:41,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:41,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:42,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:42,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:43,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:43,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:44,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:45,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:45,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:46,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:46,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:47,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:47,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:48,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:48,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:49,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:50,074][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.6031, device='cuda:0') eval_epoch_loss=tensor(1.2818, device='cuda:0') eval_epoch_acc=tensor(0.7121, device='cuda:0')
[2024-11-29 04:12:50,075][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 04:12:50,076][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 04:12:50,325][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_9_step_556_loss_1.2818018198013306/model.pt
[2024-11-29 04:12:50,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:50,966][root][INFO] - Training Epoch: 9/10, step 556/574 completed (loss: 0.7986253499984741, acc: 0.7549669146537781)
[2024-11-29 04:12:51,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:51,564][root][INFO] - Training Epoch: 9/10, step 557/574 completed (loss: 0.5596669316291809, acc: 0.8461538553237915)
[2024-11-29 04:12:51,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:52,151][root][INFO] - Training Epoch: 9/10, step 558/574 completed (loss: 0.010045696049928665, acc: 1.0)
[2024-11-29 04:12:52,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:52,737][root][INFO] - Training Epoch: 9/10, step 559/574 completed (loss: 0.0622931532561779, acc: 1.0)
[2024-11-29 04:12:52,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:53,324][root][INFO] - Training Epoch: 9/10, step 560/574 completed (loss: 0.019430488348007202, acc: 1.0)
[2024-11-29 04:12:53,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:53,915][root][INFO] - Training Epoch: 9/10, step 561/574 completed (loss: 0.4366571009159088, acc: 0.8974359035491943)
[2024-11-29 04:12:53,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:54,524][root][INFO] - Training Epoch: 9/10, step 562/574 completed (loss: 0.5622425079345703, acc: 0.8666666746139526)
[2024-11-29 04:12:54,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:55,117][root][INFO] - Training Epoch: 9/10, step 563/574 completed (loss: 0.36683544516563416, acc: 0.8961039185523987)
[2024-11-29 04:12:55,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:55,705][root][INFO] - Training Epoch: 9/10, step 564/574 completed (loss: 0.19611330330371857, acc: 0.9583333134651184)
[2024-11-29 04:12:55,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:56,296][root][INFO] - Training Epoch: 9/10, step 565/574 completed (loss: 0.14750537276268005, acc: 0.9655172228813171)
[2024-11-29 04:12:56,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:56,891][root][INFO] - Training Epoch: 9/10, step 566/574 completed (loss: 0.4217437207698822, acc: 0.8928571343421936)
[2024-11-29 04:12:56,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:57,478][root][INFO] - Training Epoch: 9/10, step 567/574 completed (loss: 0.042675960808992386, acc: 1.0)
[2024-11-29 04:12:57,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:58,066][root][INFO] - Training Epoch: 9/10, step 568/574 completed (loss: 0.03215251863002777, acc: 1.0)
[2024-11-29 04:12:58,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:58,692][root][INFO] - Training Epoch: 9/10, step 569/574 completed (loss: 1.227610468864441, acc: 0.6363636255264282)
[2024-11-29 04:12:58,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:59,282][root][INFO] - Training Epoch: 9/10, step 570/574 completed (loss: 0.08972958475351334, acc: 1.0)
[2024-11-29 04:12:59,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:12:59,878][root][INFO] - Training Epoch: 9/10, step 571/574 completed (loss: 0.738676905632019, acc: 0.7777777910232544)
[2024-11-29 04:12:59,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:00,489][root][INFO] - Training Epoch: 9/10, step 572/574 completed (loss: 1.483447790145874, acc: 0.581632673740387)
[2024-11-29 04:13:00,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:01,100][root][INFO] - Training Epoch: 9/10, step 573/574 completed (loss: 1.2006582021713257, acc: 0.6415094137191772)
[2024-11-29 04:13:01,481][slam_llm.utils.train_utils][INFO] - Epoch 9: train_perplexity=1.6578, train_epoch_loss=0.5055, epoch time 526.7045639585704s
[2024-11-29 04:13:01,481][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 15 GB
[2024-11-29 04:13:01,482][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-29 04:13:01,482][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 15 GB
[2024-11-29 04:13:01,482][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 8
[2024-11-29 04:13:01,482][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-29 04:13:01,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:02,501][root][INFO] - Training Epoch: 10/10, step 0/574 completed (loss: 0.15008743107318878, acc: 0.9629629850387573)
[2024-11-29 04:13:02,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:03,092][root][INFO] - Training Epoch: 10/10, step 1/574 completed (loss: 0.06371191889047623, acc: 1.0)
[2024-11-29 04:13:03,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:03,680][root][INFO] - Training Epoch: 10/10, step 2/574 completed (loss: 0.34209731221199036, acc: 0.9189189076423645)
[2024-11-29 04:13:03,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:04,270][root][INFO] - Training Epoch: 10/10, step 3/574 completed (loss: 0.19805294275283813, acc: 0.9736841917037964)
[2024-11-29 04:13:04,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:04,859][root][INFO] - Training Epoch: 10/10, step 4/574 completed (loss: 0.11979272216558456, acc: 0.9729729890823364)
[2024-11-29 04:13:04,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:05,446][root][INFO] - Training Epoch: 10/10, step 5/574 completed (loss: 0.15780644118785858, acc: 0.9642857313156128)
[2024-11-29 04:13:05,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:06,036][root][INFO] - Training Epoch: 10/10, step 6/574 completed (loss: 0.22523722052574158, acc: 0.9591836929321289)
[2024-11-29 04:13:06,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:06,624][root][INFO] - Training Epoch: 10/10, step 7/574 completed (loss: 0.062179870903491974, acc: 1.0)
[2024-11-29 04:13:06,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:07,216][root][INFO] - Training Epoch: 10/10, step 8/574 completed (loss: 0.003011326538398862, acc: 1.0)
[2024-11-29 04:13:07,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:07,808][root][INFO] - Training Epoch: 10/10, step 9/574 completed (loss: 0.005295209586620331, acc: 1.0)
[2024-11-29 04:13:07,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:08,397][root][INFO] - Training Epoch: 10/10, step 10/574 completed (loss: 0.004648301284760237, acc: 1.0)
[2024-11-29 04:13:08,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:08,990][root][INFO] - Training Epoch: 10/10, step 11/574 completed (loss: 0.1393602192401886, acc: 0.9487179517745972)
[2024-11-29 04:13:09,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:09,579][root][INFO] - Training Epoch: 10/10, step 12/574 completed (loss: 0.17926636338233948, acc: 0.9696969985961914)
[2024-11-29 04:13:09,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:10,168][root][INFO] - Training Epoch: 10/10, step 13/574 completed (loss: 0.1226414367556572, acc: 0.97826087474823)
[2024-11-29 04:13:10,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:10,755][root][INFO] - Training Epoch: 10/10, step 14/574 completed (loss: 0.12267401814460754, acc: 0.9607843160629272)
[2024-11-29 04:13:10,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:11,347][root][INFO] - Training Epoch: 10/10, step 15/574 completed (loss: 0.368908166885376, acc: 0.918367326259613)
[2024-11-29 04:13:11,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:11,933][root][INFO] - Training Epoch: 10/10, step 16/574 completed (loss: 0.0018531219102442265, acc: 1.0)
[2024-11-29 04:13:12,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:12,520][root][INFO] - Training Epoch: 10/10, step 17/574 completed (loss: 0.03173915669322014, acc: 1.0)
[2024-11-29 04:13:12,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:13,108][root][INFO] - Training Epoch: 10/10, step 18/574 completed (loss: 0.05478409677743912, acc: 1.0)
[2024-11-29 04:13:13,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:13,696][root][INFO] - Training Epoch: 10/10, step 19/574 completed (loss: 0.011496292427182198, acc: 1.0)
[2024-11-29 04:13:13,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:14,285][root][INFO] - Training Epoch: 10/10, step 20/574 completed (loss: 0.11299843341112137, acc: 0.9230769276618958)
[2024-11-29 04:13:14,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:14,874][root][INFO] - Training Epoch: 10/10, step 21/574 completed (loss: 0.034127768129110336, acc: 1.0)
[2024-11-29 04:13:14,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:15,462][root][INFO] - Training Epoch: 10/10, step 22/574 completed (loss: 0.13062481582164764, acc: 0.9599999785423279)
[2024-11-29 04:13:15,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:16,053][root][INFO] - Training Epoch: 10/10, step 23/574 completed (loss: 0.32741865515708923, acc: 0.9523809552192688)
[2024-11-29 04:13:16,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:16,640][root][INFO] - Training Epoch: 10/10, step 24/574 completed (loss: 0.01883155107498169, acc: 1.0)
[2024-11-29 04:13:16,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:17,234][root][INFO] - Training Epoch: 10/10, step 25/574 completed (loss: 0.48697057366371155, acc: 0.849056601524353)
[2024-11-29 04:13:17,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:17,824][root][INFO] - Training Epoch: 10/10, step 26/574 completed (loss: 0.41017964482307434, acc: 0.8904109597206116)
[2024-11-29 04:13:17,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:18,499][root][INFO] - Training Epoch: 10/10, step 27/574 completed (loss: 2.283919334411621, acc: 0.4268774688243866)
[2024-11-29 04:13:18,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:19,088][root][INFO] - Training Epoch: 10/10, step 28/574 completed (loss: 0.2462843805551529, acc: 0.9069767594337463)
[2024-11-29 04:13:19,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:19,683][root][INFO] - Training Epoch: 10/10, step 29/574 completed (loss: 0.4435621500015259, acc: 0.8433734774589539)
[2024-11-29 04:13:19,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:20,281][root][INFO] - Training Epoch: 10/10, step 30/574 completed (loss: 0.6231469511985779, acc: 0.8271604776382446)
[2024-11-29 04:13:20,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:20,869][root][INFO] - Training Epoch: 10/10, step 31/574 completed (loss: 0.042853452265262604, acc: 1.0)
[2024-11-29 04:13:20,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:21,454][root][INFO] - Training Epoch: 10/10, step 32/574 completed (loss: 0.03016902133822441, acc: 1.0)
[2024-11-29 04:13:21,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:22,045][root][INFO] - Training Epoch: 10/10, step 33/574 completed (loss: 0.007645133417099714, acc: 1.0)
[2024-11-29 04:13:22,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:22,642][root][INFO] - Training Epoch: 10/10, step 34/574 completed (loss: 0.6517996191978455, acc: 0.831932783126831)
[2024-11-29 04:13:22,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:23,233][root][INFO] - Training Epoch: 10/10, step 35/574 completed (loss: 0.3083737790584564, acc: 0.9344262480735779)
[2024-11-29 04:13:23,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:23,829][root][INFO] - Training Epoch: 10/10, step 36/574 completed (loss: 0.5197175145149231, acc: 0.841269850730896)
[2024-11-29 04:13:23,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:24,420][root][INFO] - Training Epoch: 10/10, step 37/574 completed (loss: 0.28841307759284973, acc: 0.9152542352676392)
[2024-11-29 04:13:24,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:25,015][root][INFO] - Training Epoch: 10/10, step 38/574 completed (loss: 0.45075827836990356, acc: 0.8390804529190063)
[2024-11-29 04:13:25,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:25,603][root][INFO] - Training Epoch: 10/10, step 39/574 completed (loss: 0.008308906108140945, acc: 1.0)
[2024-11-29 04:13:25,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:26,193][root][INFO] - Training Epoch: 10/10, step 40/574 completed (loss: 0.21985413134098053, acc: 0.9230769276618958)
[2024-11-29 04:13:26,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:26,790][root][INFO] - Training Epoch: 10/10, step 41/574 completed (loss: 0.7629401683807373, acc: 0.7702702879905701)
[2024-11-29 04:13:26,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:27,383][root][INFO] - Training Epoch: 10/10, step 42/574 completed (loss: 0.30888357758522034, acc: 0.9230769276618958)
[2024-11-29 04:13:27,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:27,977][root][INFO] - Training Epoch: 10/10, step 43/574 completed (loss: 0.728338897228241, acc: 0.808080792427063)
[2024-11-29 04:13:28,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:28,573][root][INFO] - Training Epoch: 10/10, step 44/574 completed (loss: 0.4945629835128784, acc: 0.8144329786300659)
[2024-11-29 04:13:28,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:29,172][root][INFO] - Training Epoch: 10/10, step 45/574 completed (loss: 1.0069938898086548, acc: 0.7426470518112183)
[2024-11-29 04:13:29,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:29,757][root][INFO] - Training Epoch: 10/10, step 46/574 completed (loss: 0.016471900045871735, acc: 1.0)
[2024-11-29 04:13:29,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:30,344][root][INFO] - Training Epoch: 10/10, step 47/574 completed (loss: 0.023282110691070557, acc: 1.0)
[2024-11-29 04:13:30,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:30,932][root][INFO] - Training Epoch: 10/10, step 48/574 completed (loss: 0.07315166294574738, acc: 0.9642857313156128)
[2024-11-29 04:13:31,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:31,521][root][INFO] - Training Epoch: 10/10, step 49/574 completed (loss: 0.2909602224826813, acc: 0.9444444179534912)
[2024-11-29 04:13:31,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:32,112][root][INFO] - Training Epoch: 10/10, step 50/574 completed (loss: 0.11045656353235245, acc: 0.9824561476707458)
[2024-11-29 04:13:32,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:32,707][root][INFO] - Training Epoch: 10/10, step 51/574 completed (loss: 0.4243001341819763, acc: 0.8888888955116272)
[2024-11-29 04:13:32,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:33,301][root][INFO] - Training Epoch: 10/10, step 52/574 completed (loss: 0.5554746985435486, acc: 0.8591549396514893)
[2024-11-29 04:13:33,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:33,916][root][INFO] - Training Epoch: 10/10, step 53/574 completed (loss: 1.7585673332214355, acc: 0.5533333420753479)
[2024-11-29 04:13:33,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:34,503][root][INFO] - Training Epoch: 10/10, step 54/574 completed (loss: 0.3499526083469391, acc: 0.9189189076423645)
[2024-11-29 04:13:34,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:35,089][root][INFO] - Training Epoch: 10/10, step 55/574 completed (loss: 0.08262460678815842, acc: 0.9615384340286255)
[2024-11-29 04:13:35,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:35,790][root][INFO] - Training Epoch: 10/10, step 56/574 completed (loss: 1.9716005325317383, acc: 0.49829351902008057)
[2024-11-29 04:13:35,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:36,442][root][INFO] - Training Epoch: 10/10, step 57/574 completed (loss: 2.5338919162750244, acc: 0.40305009484291077)
[2024-11-29 04:13:36,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:37,058][root][INFO] - Training Epoch: 10/10, step 58/574 completed (loss: 1.34224534034729, acc: 0.6306818127632141)
[2024-11-29 04:13:37,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:37,656][root][INFO] - Training Epoch: 10/10, step 59/574 completed (loss: 1.2139085531234741, acc: 0.6691176295280457)
[2024-11-29 04:13:37,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:38,271][root][INFO] - Training Epoch: 10/10, step 60/574 completed (loss: 1.27620530128479, acc: 0.6304348111152649)
[2024-11-29 04:13:38,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:38,881][root][INFO] - Training Epoch: 10/10, step 61/574 completed (loss: 0.7675968408584595, acc: 0.7749999761581421)
[2024-11-29 04:13:38,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:39,468][root][INFO] - Training Epoch: 10/10, step 62/574 completed (loss: 0.23670345544815063, acc: 0.8823529481887817)
[2024-11-29 04:13:39,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:40,059][root][INFO] - Training Epoch: 10/10, step 63/574 completed (loss: 0.10994075238704681, acc: 0.9722222089767456)
[2024-11-29 04:13:40,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:40,655][root][INFO] - Training Epoch: 10/10, step 64/574 completed (loss: 0.29632195830345154, acc: 0.9375)
[2024-11-29 04:13:40,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:41,242][root][INFO] - Training Epoch: 10/10, step 65/574 completed (loss: 0.00745164230465889, acc: 1.0)
[2024-11-29 04:13:41,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:41,834][root][INFO] - Training Epoch: 10/10, step 66/574 completed (loss: 0.31066861748695374, acc: 0.9464285969734192)
[2024-11-29 04:13:41,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:42,425][root][INFO] - Training Epoch: 10/10, step 67/574 completed (loss: 0.36340001225471497, acc: 0.8999999761581421)
[2024-11-29 04:13:42,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:43,012][root][INFO] - Training Epoch: 10/10, step 68/574 completed (loss: 0.060901422053575516, acc: 0.9599999785423279)
[2024-11-29 04:13:43,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:43,605][root][INFO] - Training Epoch: 10/10, step 69/574 completed (loss: 0.21086081862449646, acc: 0.9166666865348816)
[2024-11-29 04:13:43,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:44,193][root][INFO] - Training Epoch: 10/10, step 70/574 completed (loss: 0.039015669375658035, acc: 1.0)
[2024-11-29 04:13:44,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:44,805][root][INFO] - Training Epoch: 10/10, step 71/574 completed (loss: 1.3720779418945312, acc: 0.654411792755127)
[2024-11-29 04:13:44,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:45,401][root][INFO] - Training Epoch: 10/10, step 72/574 completed (loss: 0.7463221549987793, acc: 0.817460298538208)
[2024-11-29 04:13:45,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:46,015][root][INFO] - Training Epoch: 10/10, step 73/574 completed (loss: 1.7688875198364258, acc: 0.5538461804389954)
[2024-11-29 04:13:46,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:46,608][root][INFO] - Training Epoch: 10/10, step 74/574 completed (loss: 0.7445050477981567, acc: 0.8061224222183228)
[2024-11-29 04:13:46,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:47,205][root][INFO] - Training Epoch: 10/10, step 75/574 completed (loss: 1.1374270915985107, acc: 0.6716417670249939)
[2024-11-29 04:13:47,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:47,831][root][INFO] - Training Epoch: 10/10, step 76/574 completed (loss: 2.029632806777954, acc: 0.4635036587715149)
[2024-11-29 04:13:47,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:48,417][root][INFO] - Training Epoch: 10/10, step 77/574 completed (loss: 0.008090101182460785, acc: 1.0)
[2024-11-29 04:13:48,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:49,004][root][INFO] - Training Epoch: 10/10, step 78/574 completed (loss: 0.021724216639995575, acc: 1.0)
[2024-11-29 04:13:49,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:49,593][root][INFO] - Training Epoch: 10/10, step 79/574 completed (loss: 0.08481109142303467, acc: 0.9696969985961914)
[2024-11-29 04:13:49,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:50,180][root][INFO] - Training Epoch: 10/10, step 80/574 completed (loss: 0.009295424446463585, acc: 1.0)
[2024-11-29 04:13:50,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:50,771][root][INFO] - Training Epoch: 10/10, step 81/574 completed (loss: 0.4596278965473175, acc: 0.8846153616905212)
[2024-11-29 04:13:50,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:51,364][root][INFO] - Training Epoch: 10/10, step 82/574 completed (loss: 0.25607243180274963, acc: 0.9230769276618958)
[2024-11-29 04:13:51,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:51,951][root][INFO] - Training Epoch: 10/10, step 83/574 completed (loss: 0.13808442652225494, acc: 0.96875)
[2024-11-29 04:13:52,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:52,543][root][INFO] - Training Epoch: 10/10, step 84/574 completed (loss: 0.28665676712989807, acc: 0.8985507488250732)
[2024-11-29 04:13:52,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:53,135][root][INFO] - Training Epoch: 10/10, step 85/574 completed (loss: 0.4232299327850342, acc: 0.8399999737739563)
[2024-11-29 04:13:53,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:53,724][root][INFO] - Training Epoch: 10/10, step 86/574 completed (loss: 0.18739596009254456, acc: 0.95652174949646)
[2024-11-29 04:13:53,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:54,318][root][INFO] - Training Epoch: 10/10, step 87/574 completed (loss: 0.49840882420539856, acc: 0.800000011920929)
[2024-11-29 04:13:54,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:54,915][root][INFO] - Training Epoch: 10/10, step 88/574 completed (loss: 0.5412054061889648, acc: 0.8252426981925964)
[2024-11-29 04:13:54,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:55,527][root][INFO] - Training Epoch: 10/10, step 89/574 completed (loss: 1.1164891719818115, acc: 0.6796116232872009)
[2024-11-29 04:13:55,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:56,142][root][INFO] - Training Epoch: 10/10, step 90/574 completed (loss: 1.3111789226531982, acc: 0.6612903475761414)
[2024-11-29 04:13:56,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:56,767][root][INFO] - Training Epoch: 10/10, step 91/574 completed (loss: 1.3880689144134521, acc: 0.642241358757019)
[2024-11-29 04:13:56,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:57,362][root][INFO] - Training Epoch: 10/10, step 92/574 completed (loss: 0.8934947848320007, acc: 0.7473683953285217)
[2024-11-29 04:13:57,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:57,975][root][INFO] - Training Epoch: 10/10, step 93/574 completed (loss: 1.3495876789093018, acc: 0.6138613820075989)
[2024-11-29 04:13:58,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:58,568][root][INFO] - Training Epoch: 10/10, step 94/574 completed (loss: 0.4799928665161133, acc: 0.9032257795333862)
[2024-11-29 04:13:58,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:59,160][root][INFO] - Training Epoch: 10/10, step 95/574 completed (loss: 0.4584372341632843, acc: 0.8260869383811951)
[2024-11-29 04:13:59,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:13:59,761][root][INFO] - Training Epoch: 10/10, step 96/574 completed (loss: 0.9316593408584595, acc: 0.6638655662536621)
[2024-11-29 04:13:59,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:00,358][root][INFO] - Training Epoch: 10/10, step 97/574 completed (loss: 0.8434863686561584, acc: 0.7596153616905212)
[2024-11-29 04:14:00,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:00,957][root][INFO] - Training Epoch: 10/10, step 98/574 completed (loss: 1.2311487197875977, acc: 0.6642335653305054)
[2024-11-29 04:14:01,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:01,547][root][INFO] - Training Epoch: 10/10, step 99/574 completed (loss: 0.5101853609085083, acc: 0.8358209133148193)
[2024-11-29 04:14:01,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:02,136][root][INFO] - Training Epoch: 10/10, step 100/574 completed (loss: 0.3777008652687073, acc: 0.8999999761581421)
[2024-11-29 04:14:02,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:02,723][root][INFO] - Training Epoch: 10/10, step 101/574 completed (loss: 0.01120672281831503, acc: 1.0)
[2024-11-29 04:14:02,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:03,310][root][INFO] - Training Epoch: 10/10, step 102/574 completed (loss: 0.00869953166693449, acc: 1.0)
[2024-11-29 04:14:03,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:03,901][root][INFO] - Training Epoch: 10/10, step 103/574 completed (loss: 0.08729258179664612, acc: 0.9772727489471436)
[2024-11-29 04:14:03,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:04,492][root][INFO] - Training Epoch: 10/10, step 104/574 completed (loss: 0.25482580065727234, acc: 0.8965517282485962)
[2024-11-29 04:14:04,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:05,084][root][INFO] - Training Epoch: 10/10, step 105/574 completed (loss: 0.09465767443180084, acc: 0.9767441749572754)
[2024-11-29 04:14:05,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:05,673][root][INFO] - Training Epoch: 10/10, step 106/574 completed (loss: 0.10072220116853714, acc: 0.9599999785423279)
[2024-11-29 04:14:05,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:06,260][root][INFO] - Training Epoch: 10/10, step 107/574 completed (loss: 0.0036397904623299837, acc: 1.0)
[2024-11-29 04:14:06,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:06,848][root][INFO] - Training Epoch: 10/10, step 108/574 completed (loss: 0.0017821926157921553, acc: 1.0)
[2024-11-29 04:14:06,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:07,437][root][INFO] - Training Epoch: 10/10, step 109/574 completed (loss: 0.295542448759079, acc: 0.8809523582458496)
[2024-11-29 04:14:07,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:08,031][root][INFO] - Training Epoch: 10/10, step 110/574 completed (loss: 0.3505708575248718, acc: 0.8769230842590332)
[2024-11-29 04:14:08,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:08,622][root][INFO] - Training Epoch: 10/10, step 111/574 completed (loss: 0.4529299736022949, acc: 0.8421052694320679)
[2024-11-29 04:14:08,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:09,213][root][INFO] - Training Epoch: 10/10, step 112/574 completed (loss: 0.46431833505630493, acc: 0.8421052694320679)
[2024-11-29 04:14:09,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:09,803][root][INFO] - Training Epoch: 10/10, step 113/574 completed (loss: 0.20090708136558533, acc: 0.9230769276618958)
[2024-11-29 04:14:09,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:10,397][root][INFO] - Training Epoch: 10/10, step 114/574 completed (loss: 0.2384708821773529, acc: 0.918367326259613)
[2024-11-29 04:14:10,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:10,985][root][INFO] - Training Epoch: 10/10, step 115/574 completed (loss: 0.019232308492064476, acc: 1.0)
[2024-11-29 04:14:11,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:11,583][root][INFO] - Training Epoch: 10/10, step 116/574 completed (loss: 0.7449507713317871, acc: 0.7936508059501648)
[2024-11-29 04:14:11,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:12,176][root][INFO] - Training Epoch: 10/10, step 117/574 completed (loss: 0.7290022969245911, acc: 0.8130081295967102)
[2024-11-29 04:14:12,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:12,770][root][INFO] - Training Epoch: 10/10, step 118/574 completed (loss: 0.36986297369003296, acc: 0.8870967626571655)
[2024-11-29 04:14:12,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:13,413][root][INFO] - Training Epoch: 10/10, step 119/574 completed (loss: 1.634060263633728, acc: 0.5817490220069885)
[2024-11-29 04:14:13,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:14,010][root][INFO] - Training Epoch: 10/10, step 120/574 completed (loss: 0.15193058550357819, acc: 0.9866666793823242)
[2024-11-29 04:14:14,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:14,604][root][INFO] - Training Epoch: 10/10, step 121/574 completed (loss: 0.28910306096076965, acc: 0.9230769276618958)
[2024-11-29 04:14:14,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:15,192][root][INFO] - Training Epoch: 10/10, step 122/574 completed (loss: 0.020453602075576782, acc: 1.0)
[2024-11-29 04:14:15,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:15,780][root][INFO] - Training Epoch: 10/10, step 123/574 completed (loss: 0.2456621378660202, acc: 0.8421052694320679)
[2024-11-29 04:14:15,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:16,380][root][INFO] - Training Epoch: 10/10, step 124/574 completed (loss: 1.2880338430404663, acc: 0.6380367875099182)
[2024-11-29 04:14:17,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:17,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:18,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:18,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:19,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:19,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:20,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:20,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:21,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:21,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:22,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:22,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:23,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:23,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:24,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:24,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:25,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:25,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:26,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:27,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:27,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:28,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:28,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:29,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:29,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:30,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:30,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:31,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:31,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:32,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:32,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:33,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:33,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:34,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:34,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:35,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:35,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:36,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:37,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:37,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:38,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:38,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:39,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:39,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:40,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:40,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:41,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:41,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:42,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:42,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:43,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:43,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:44,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:44,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:45,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:45,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:46,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:46,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:47,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:47,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:48,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:49,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:49,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:50,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:50,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:51,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:51,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:52,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:52,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:53,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:53,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:54,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:54,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:55,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:55,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:56,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:56,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:57,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:57,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:58,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:59,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:14:59,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:00,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:00,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:01,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:01,854][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.3889, device='cuda:0') eval_epoch_loss=tensor(1.2205, device='cuda:0') eval_epoch_acc=tensor(0.7228, device='cuda:0')
[2024-11-29 04:15:01,856][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 04:15:01,856][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 04:15:02,119][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_10_step_125_loss_1.220504641532898/model.pt
[2024-11-29 04:15:02,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:02,751][root][INFO] - Training Epoch: 10/10, step 125/574 completed (loss: 1.2116761207580566, acc: 0.625)
[2024-11-29 04:15:02,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:03,346][root][INFO] - Training Epoch: 10/10, step 126/574 completed (loss: 0.9115684032440186, acc: 0.75)
[2024-11-29 04:15:03,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:03,967][root][INFO] - Training Epoch: 10/10, step 127/574 completed (loss: 1.5009244680404663, acc: 0.5595238208770752)
[2024-11-29 04:15:04,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:04,577][root][INFO] - Training Epoch: 10/10, step 128/574 completed (loss: 1.2399115562438965, acc: 0.6512820720672607)
[2024-11-29 04:15:04,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:05,201][root][INFO] - Training Epoch: 10/10, step 129/574 completed (loss: 1.267683982849121, acc: 0.6397058963775635)
[2024-11-29 04:15:05,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:05,788][root][INFO] - Training Epoch: 10/10, step 130/574 completed (loss: 0.03486712649464607, acc: 1.0)
[2024-11-29 04:15:05,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:06,374][root][INFO] - Training Epoch: 10/10, step 131/574 completed (loss: 0.010160677134990692, acc: 1.0)
[2024-11-29 04:15:06,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:06,961][root][INFO] - Training Epoch: 10/10, step 132/574 completed (loss: 0.19383534789085388, acc: 0.90625)
[2024-11-29 04:15:07,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:07,548][root][INFO] - Training Epoch: 10/10, step 133/574 completed (loss: 0.16390253603458405, acc: 0.9130434989929199)
[2024-11-29 04:15:07,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:08,135][root][INFO] - Training Epoch: 10/10, step 134/574 completed (loss: 0.020134299993515015, acc: 1.0)
[2024-11-29 04:15:08,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:08,723][root][INFO] - Training Epoch: 10/10, step 135/574 completed (loss: 0.03894056752324104, acc: 1.0)
[2024-11-29 04:15:08,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:09,312][root][INFO] - Training Epoch: 10/10, step 136/574 completed (loss: 0.1389188915491104, acc: 0.976190447807312)
[2024-11-29 04:15:09,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:09,898][root][INFO] - Training Epoch: 10/10, step 137/574 completed (loss: 0.10922665894031525, acc: 0.9666666388511658)
[2024-11-29 04:15:09,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:10,484][root][INFO] - Training Epoch: 10/10, step 138/574 completed (loss: 0.2295341044664383, acc: 0.95652174949646)
[2024-11-29 04:15:10,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:11,073][root][INFO] - Training Epoch: 10/10, step 139/574 completed (loss: 0.13780681788921356, acc: 0.9523809552192688)
[2024-11-29 04:15:11,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:11,660][root][INFO] - Training Epoch: 10/10, step 140/574 completed (loss: 0.16419266164302826, acc: 0.9615384340286255)
[2024-11-29 04:15:11,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:12,249][root][INFO] - Training Epoch: 10/10, step 141/574 completed (loss: 0.43941619992256165, acc: 0.8387096524238586)
[2024-11-29 04:15:12,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:12,837][root][INFO] - Training Epoch: 10/10, step 142/574 completed (loss: 0.5322468280792236, acc: 0.8648648858070374)
[2024-11-29 04:15:12,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:13,450][root][INFO] - Training Epoch: 10/10, step 143/574 completed (loss: 0.8391145467758179, acc: 0.7631579041481018)
[2024-11-29 04:15:13,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:14,049][root][INFO] - Training Epoch: 10/10, step 144/574 completed (loss: 0.8104891180992126, acc: 0.7388059496879578)
[2024-11-29 04:15:14,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:14,647][root][INFO] - Training Epoch: 10/10, step 145/574 completed (loss: 0.9567471742630005, acc: 0.704081654548645)
[2024-11-29 04:15:14,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:15,256][root][INFO] - Training Epoch: 10/10, step 146/574 completed (loss: 1.0405718088150024, acc: 0.6595744490623474)
[2024-11-29 04:15:15,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:15,850][root][INFO] - Training Epoch: 10/10, step 147/574 completed (loss: 0.5927666425704956, acc: 0.8142856955528259)
[2024-11-29 04:15:15,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:16,437][root][INFO] - Training Epoch: 10/10, step 148/574 completed (loss: 0.22864851355552673, acc: 0.8928571343421936)
[2024-11-29 04:15:16,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:17,022][root][INFO] - Training Epoch: 10/10, step 149/574 completed (loss: 0.04841143637895584, acc: 1.0)
[2024-11-29 04:15:17,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:17,610][root][INFO] - Training Epoch: 10/10, step 150/574 completed (loss: 0.26254042983055115, acc: 0.931034505367279)
[2024-11-29 04:15:17,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:18,197][root][INFO] - Training Epoch: 10/10, step 151/574 completed (loss: 0.30190199613571167, acc: 0.9130434989929199)
[2024-11-29 04:15:18,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:18,791][root][INFO] - Training Epoch: 10/10, step 152/574 completed (loss: 0.5409373044967651, acc: 0.7966101765632629)
[2024-11-29 04:15:18,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:19,383][root][INFO] - Training Epoch: 10/10, step 153/574 completed (loss: 0.44592493772506714, acc: 0.8947368264198303)
[2024-11-29 04:15:19,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:19,978][root][INFO] - Training Epoch: 10/10, step 154/574 completed (loss: 0.7354124188423157, acc: 0.8108108043670654)
[2024-11-29 04:15:20,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:20,566][root][INFO] - Training Epoch: 10/10, step 155/574 completed (loss: 0.02238485775887966, acc: 1.0)
[2024-11-29 04:15:20,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:21,153][root][INFO] - Training Epoch: 10/10, step 156/574 completed (loss: 0.02102375403046608, acc: 1.0)
[2024-11-29 04:15:21,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:21,740][root][INFO] - Training Epoch: 10/10, step 157/574 completed (loss: 0.06375501304864883, acc: 1.0)
[2024-11-29 04:15:21,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:22,333][root][INFO] - Training Epoch: 10/10, step 158/574 completed (loss: 0.8641723394393921, acc: 0.7972972989082336)
[2024-11-29 04:15:22,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:22,925][root][INFO] - Training Epoch: 10/10, step 159/574 completed (loss: 0.5628623962402344, acc: 0.7962962985038757)
[2024-11-29 04:15:23,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:23,520][root][INFO] - Training Epoch: 10/10, step 160/574 completed (loss: 0.39799946546554565, acc: 0.895348846912384)
[2024-11-29 04:15:23,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:24,113][root][INFO] - Training Epoch: 10/10, step 161/574 completed (loss: 0.254143625497818, acc: 0.929411768913269)
[2024-11-29 04:15:24,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:24,711][root][INFO] - Training Epoch: 10/10, step 162/574 completed (loss: 0.7482585310935974, acc: 0.8202247023582458)
[2024-11-29 04:15:24,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:25,303][root][INFO] - Training Epoch: 10/10, step 163/574 completed (loss: 0.3656318485736847, acc: 0.8863636255264282)
[2024-11-29 04:15:25,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:25,891][root][INFO] - Training Epoch: 10/10, step 164/574 completed (loss: 0.02216515876352787, acc: 1.0)
[2024-11-29 04:15:25,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:26,477][root][INFO] - Training Epoch: 10/10, step 165/574 completed (loss: 0.03916997089982033, acc: 1.0)
[2024-11-29 04:15:26,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:27,070][root][INFO] - Training Epoch: 10/10, step 166/574 completed (loss: 0.14001792669296265, acc: 0.9795918464660645)
[2024-11-29 04:15:27,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:27,658][root][INFO] - Training Epoch: 10/10, step 167/574 completed (loss: 0.141356959939003, acc: 0.9399999976158142)
[2024-11-29 04:15:27,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:28,253][root][INFO] - Training Epoch: 10/10, step 168/574 completed (loss: 0.6358423233032227, acc: 0.8194444179534912)
[2024-11-29 04:15:28,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:28,849][root][INFO] - Training Epoch: 10/10, step 169/574 completed (loss: 0.917369544506073, acc: 0.7156862616539001)
[2024-11-29 04:15:28,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:29,471][root][INFO] - Training Epoch: 10/10, step 170/574 completed (loss: 1.9351093769073486, acc: 0.5)
[2024-11-29 04:15:29,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:30,058][root][INFO] - Training Epoch: 10/10, step 171/574 completed (loss: 0.026035228744149208, acc: 1.0)
[2024-11-29 04:15:30,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:30,645][root][INFO] - Training Epoch: 10/10, step 172/574 completed (loss: 0.010017182677984238, acc: 1.0)
[2024-11-29 04:15:30,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:31,230][root][INFO] - Training Epoch: 10/10, step 173/574 completed (loss: 0.1371016949415207, acc: 0.9642857313156128)
[2024-11-29 04:15:31,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:31,845][root][INFO] - Training Epoch: 10/10, step 174/574 completed (loss: 1.1543866395950317, acc: 0.6902654767036438)
[2024-11-29 04:15:31,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:32,438][root][INFO] - Training Epoch: 10/10, step 175/574 completed (loss: 0.34478384256362915, acc: 0.8985507488250732)
[2024-11-29 04:15:32,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:33,033][root][INFO] - Training Epoch: 10/10, step 176/574 completed (loss: 0.6014299392700195, acc: 0.7954545617103577)
[2024-11-29 04:15:33,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:33,646][root][INFO] - Training Epoch: 10/10, step 177/574 completed (loss: 1.5233068466186523, acc: 0.5419847369194031)
[2024-11-29 04:15:33,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:34,258][root][INFO] - Training Epoch: 10/10, step 178/574 completed (loss: 1.438610315322876, acc: 0.5407407283782959)
[2024-11-29 04:15:34,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:34,850][root][INFO] - Training Epoch: 10/10, step 179/574 completed (loss: 0.2451595962047577, acc: 0.9344262480735779)
[2024-11-29 04:15:34,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:35,438][root][INFO] - Training Epoch: 10/10, step 180/574 completed (loss: 0.00568753108382225, acc: 1.0)
[2024-11-29 04:15:35,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:36,024][root][INFO] - Training Epoch: 10/10, step 181/574 completed (loss: 0.05907300487160683, acc: 1.0)
[2024-11-29 04:15:36,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:36,612][root][INFO] - Training Epoch: 10/10, step 182/574 completed (loss: 0.022848764434456825, acc: 1.0)
[2024-11-29 04:15:36,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:37,206][root][INFO] - Training Epoch: 10/10, step 183/574 completed (loss: 0.7112873196601868, acc: 0.8170731663703918)
[2024-11-29 04:15:37,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:37,833][root][INFO] - Training Epoch: 10/10, step 184/574 completed (loss: 1.7562555074691772, acc: 0.5256797671318054)
[2024-11-29 04:15:37,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:38,459][root][INFO] - Training Epoch: 10/10, step 185/574 completed (loss: 1.8980976343154907, acc: 0.49567723274230957)
[2024-11-29 04:15:38,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:39,081][root][INFO] - Training Epoch: 10/10, step 186/574 completed (loss: 1.8907073736190796, acc: 0.518750011920929)
[2024-11-29 04:15:39,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:39,738][root][INFO] - Training Epoch: 10/10, step 187/574 completed (loss: 2.1320583820343018, acc: 0.42213883996009827)
[2024-11-29 04:15:39,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:40,371][root][INFO] - Training Epoch: 10/10, step 188/574 completed (loss: 1.6759850978851318, acc: 0.5693950057029724)
[2024-11-29 04:15:40,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:40,957][root][INFO] - Training Epoch: 10/10, step 189/574 completed (loss: 0.1132260113954544, acc: 0.9599999785423279)
[2024-11-29 04:15:41,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:41,551][root][INFO] - Training Epoch: 10/10, step 190/574 completed (loss: 0.9148263335227966, acc: 0.7209302186965942)
[2024-11-29 04:15:41,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:42,147][root][INFO] - Training Epoch: 10/10, step 191/574 completed (loss: 1.2155303955078125, acc: 0.658730149269104)
[2024-11-29 04:15:42,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:42,745][root][INFO] - Training Epoch: 10/10, step 192/574 completed (loss: 1.5628890991210938, acc: 0.5378788113594055)
[2024-11-29 04:15:42,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:43,339][root][INFO] - Training Epoch: 10/10, step 193/574 completed (loss: 0.8195011019706726, acc: 0.7764706015586853)
[2024-11-29 04:15:43,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:43,952][root][INFO] - Training Epoch: 10/10, step 194/574 completed (loss: 1.207910418510437, acc: 0.6728395223617554)
[2024-11-29 04:15:44,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:44,550][root][INFO] - Training Epoch: 10/10, step 195/574 completed (loss: 0.7721562385559082, acc: 0.774193525314331)
[2024-11-29 04:15:44,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:45,135][root][INFO] - Training Epoch: 10/10, step 196/574 completed (loss: 0.012251784093677998, acc: 1.0)
[2024-11-29 04:15:45,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:45,725][root][INFO] - Training Epoch: 10/10, step 197/574 completed (loss: 0.19540773332118988, acc: 0.949999988079071)
[2024-11-29 04:15:45,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:46,316][root][INFO] - Training Epoch: 10/10, step 198/574 completed (loss: 0.7114109992980957, acc: 0.7647058963775635)
[2024-11-29 04:15:46,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:46,911][root][INFO] - Training Epoch: 10/10, step 199/574 completed (loss: 1.1546472311019897, acc: 0.7132353186607361)
[2024-11-29 04:15:46,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:47,510][root][INFO] - Training Epoch: 10/10, step 200/574 completed (loss: 0.856365978717804, acc: 0.7457627058029175)
[2024-11-29 04:15:47,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:48,107][root][INFO] - Training Epoch: 10/10, step 201/574 completed (loss: 0.7118191123008728, acc: 0.8134328126907349)
[2024-11-29 04:15:48,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:48,703][root][INFO] - Training Epoch: 10/10, step 202/574 completed (loss: 0.8246468901634216, acc: 0.737864077091217)
[2024-11-29 04:15:48,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:49,300][root][INFO] - Training Epoch: 10/10, step 203/574 completed (loss: 0.46666714549064636, acc: 0.9365079402923584)
[2024-11-29 04:15:49,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:49,895][root][INFO] - Training Epoch: 10/10, step 204/574 completed (loss: 0.3780364990234375, acc: 0.8901098966598511)
[2024-11-29 04:15:49,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:50,516][root][INFO] - Training Epoch: 10/10, step 205/574 completed (loss: 1.3828538656234741, acc: 0.6143497824668884)
[2024-11-29 04:15:50,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:51,143][root][INFO] - Training Epoch: 10/10, step 206/574 completed (loss: 1.5618938207626343, acc: 0.5787401795387268)
[2024-11-29 04:15:51,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:51,757][root][INFO] - Training Epoch: 10/10, step 207/574 completed (loss: 1.132423758506775, acc: 0.7025862336158752)
[2024-11-29 04:15:51,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:52,375][root][INFO] - Training Epoch: 10/10, step 208/574 completed (loss: 1.5748451948165894, acc: 0.5869565010070801)
[2024-11-29 04:15:52,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:52,996][root][INFO] - Training Epoch: 10/10, step 209/574 completed (loss: 1.3323838710784912, acc: 0.6459143757820129)
[2024-11-29 04:15:53,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:53,609][root][INFO] - Training Epoch: 10/10, step 210/574 completed (loss: 1.3160150051116943, acc: 0.6086956262588501)
[2024-11-29 04:15:53,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:54,196][root][INFO] - Training Epoch: 10/10, step 211/574 completed (loss: 0.008210712112486362, acc: 1.0)
[2024-11-29 04:15:54,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:54,783][root][INFO] - Training Epoch: 10/10, step 212/574 completed (loss: 0.01614215224981308, acc: 1.0)
[2024-11-29 04:15:54,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:55,374][root][INFO] - Training Epoch: 10/10, step 213/574 completed (loss: 0.06697769463062286, acc: 1.0)
[2024-11-29 04:15:55,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:55,983][root][INFO] - Training Epoch: 10/10, step 214/574 completed (loss: 0.8257122039794922, acc: 0.7461538314819336)
[2024-11-29 04:15:56,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:56,574][root][INFO] - Training Epoch: 10/10, step 215/574 completed (loss: 0.15828697383403778, acc: 0.9324324131011963)
[2024-11-29 04:15:56,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:57,169][root][INFO] - Training Epoch: 10/10, step 216/574 completed (loss: 0.31103241443634033, acc: 0.895348846912384)
[2024-11-29 04:15:57,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:57,772][root][INFO] - Training Epoch: 10/10, step 217/574 completed (loss: 0.6226093769073486, acc: 0.837837815284729)
[2024-11-29 04:15:57,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:58,367][root][INFO] - Training Epoch: 10/10, step 218/574 completed (loss: 0.6281670331954956, acc: 0.8888888955116272)
[2024-11-29 04:15:58,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:58,956][root][INFO] - Training Epoch: 10/10, step 219/574 completed (loss: 0.08059962838888168, acc: 0.939393937587738)
[2024-11-29 04:15:59,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:15:59,543][root][INFO] - Training Epoch: 10/10, step 220/574 completed (loss: 0.0036627177614718676, acc: 1.0)
[2024-11-29 04:15:59,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:00,129][root][INFO] - Training Epoch: 10/10, step 221/574 completed (loss: 0.009818249382078648, acc: 1.0)
[2024-11-29 04:16:00,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:00,723][root][INFO] - Training Epoch: 10/10, step 222/574 completed (loss: 0.7273471355438232, acc: 0.7307692170143127)
[2024-11-29 04:16:00,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:01,339][root][INFO] - Training Epoch: 10/10, step 223/574 completed (loss: 1.0254062414169312, acc: 0.7119565010070801)
[2024-11-29 04:16:01,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:01,953][root][INFO] - Training Epoch: 10/10, step 224/574 completed (loss: 1.1439344882965088, acc: 0.6761363744735718)
[2024-11-29 04:16:02,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:02,566][root][INFO] - Training Epoch: 10/10, step 225/574 completed (loss: 1.3226228952407837, acc: 0.6595744490623474)
[2024-11-29 04:16:02,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:03,159][root][INFO] - Training Epoch: 10/10, step 226/574 completed (loss: 0.30397847294807434, acc: 0.9245283007621765)
[2024-11-29 04:16:03,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:03,750][root][INFO] - Training Epoch: 10/10, step 227/574 completed (loss: 0.22013719379901886, acc: 0.9666666388511658)
[2024-11-29 04:16:03,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:04,345][root][INFO] - Training Epoch: 10/10, step 228/574 completed (loss: 0.46385326981544495, acc: 0.8837209343910217)
[2024-11-29 04:16:04,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:04,932][root][INFO] - Training Epoch: 10/10, step 229/574 completed (loss: 0.23900571465492249, acc: 0.8666666746139526)
[2024-11-29 04:16:05,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:05,528][root][INFO] - Training Epoch: 10/10, step 230/574 completed (loss: 1.2549397945404053, acc: 0.6526315808296204)
[2024-11-29 04:16:05,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:06,119][root][INFO] - Training Epoch: 10/10, step 231/574 completed (loss: 0.7164589762687683, acc: 0.7333333492279053)
[2024-11-29 04:16:06,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:06,730][root][INFO] - Training Epoch: 10/10, step 232/574 completed (loss: 1.123387098312378, acc: 0.6611111164093018)
[2024-11-29 04:16:06,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:07,345][root][INFO] - Training Epoch: 10/10, step 233/574 completed (loss: 1.6385968923568726, acc: 0.5458715558052063)
[2024-11-29 04:16:07,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:07,959][root][INFO] - Training Epoch: 10/10, step 234/574 completed (loss: 0.9995627999305725, acc: 0.7230769395828247)
[2024-11-29 04:16:08,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:08,547][root][INFO] - Training Epoch: 10/10, step 235/574 completed (loss: 0.06587392091751099, acc: 1.0)
[2024-11-29 04:16:08,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:09,134][root][INFO] - Training Epoch: 10/10, step 236/574 completed (loss: 0.014303521253168583, acc: 1.0)
[2024-11-29 04:16:09,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:09,718][root][INFO] - Training Epoch: 10/10, step 237/574 completed (loss: 0.5763867497444153, acc: 0.9545454382896423)
[2024-11-29 04:16:09,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:10,307][root][INFO] - Training Epoch: 10/10, step 238/574 completed (loss: 0.09459059685468674, acc: 0.9629629850387573)
[2024-11-29 04:16:10,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:10,895][root][INFO] - Training Epoch: 10/10, step 239/574 completed (loss: 0.5661050081253052, acc: 0.7714285850524902)
[2024-11-29 04:16:10,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:11,486][root][INFO] - Training Epoch: 10/10, step 240/574 completed (loss: 0.1488906741142273, acc: 0.9772727489471436)
[2024-11-29 04:16:11,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:12,074][root][INFO] - Training Epoch: 10/10, step 241/574 completed (loss: 0.15907907485961914, acc: 0.9090909361839294)
[2024-11-29 04:16:12,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:12,664][root][INFO] - Training Epoch: 10/10, step 242/574 completed (loss: 0.8535670638084412, acc: 0.7419354915618896)
[2024-11-29 04:16:12,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:13,255][root][INFO] - Training Epoch: 10/10, step 243/574 completed (loss: 0.37398311495780945, acc: 0.9318181872367859)
[2024-11-29 04:16:13,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:13,843][root][INFO] - Training Epoch: 10/10, step 244/574 completed (loss: 0.003775360994040966, acc: 1.0)
[2024-11-29 04:16:13,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:14,434][root][INFO] - Training Epoch: 10/10, step 245/574 completed (loss: 0.014394811354577541, acc: 1.0)
[2024-11-29 04:16:14,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:15,023][root][INFO] - Training Epoch: 10/10, step 246/574 completed (loss: 0.02868594229221344, acc: 1.0)
[2024-11-29 04:16:15,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:15,607][root][INFO] - Training Epoch: 10/10, step 247/574 completed (loss: 0.006975078489631414, acc: 1.0)
[2024-11-29 04:16:15,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:16,199][root][INFO] - Training Epoch: 10/10, step 248/574 completed (loss: 0.2604970335960388, acc: 0.9459459185600281)
[2024-11-29 04:16:16,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:16,786][root][INFO] - Training Epoch: 10/10, step 249/574 completed (loss: 0.11393304914236069, acc: 0.9729729890823364)
[2024-11-29 04:16:16,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:17,374][root][INFO] - Training Epoch: 10/10, step 250/574 completed (loss: 0.0626055896282196, acc: 0.9729729890823364)
[2024-11-29 04:16:17,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:17,970][root][INFO] - Training Epoch: 10/10, step 251/574 completed (loss: 0.6675747036933899, acc: 0.779411792755127)
[2024-11-29 04:16:18,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:18,560][root][INFO] - Training Epoch: 10/10, step 252/574 completed (loss: 0.10552603006362915, acc: 0.9756097793579102)
[2024-11-29 04:16:18,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:19,149][root][INFO] - Training Epoch: 10/10, step 253/574 completed (loss: 0.03850903734564781, acc: 1.0)
[2024-11-29 04:16:19,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:19,734][root][INFO] - Training Epoch: 10/10, step 254/574 completed (loss: 0.137565478682518, acc: 0.9599999785423279)
[2024-11-29 04:16:19,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:20,322][root][INFO] - Training Epoch: 10/10, step 255/574 completed (loss: 0.14786478877067566, acc: 0.9354838728904724)
[2024-11-29 04:16:20,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:20,913][root][INFO] - Training Epoch: 10/10, step 256/574 completed (loss: 0.26638224720954895, acc: 0.9122806787490845)
[2024-11-29 04:16:20,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:21,501][root][INFO] - Training Epoch: 10/10, step 257/574 completed (loss: 0.3797081708908081, acc: 0.9428571462631226)
[2024-11-29 04:16:21,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:22,094][root][INFO] - Training Epoch: 10/10, step 258/574 completed (loss: 0.23476924002170563, acc: 0.9342105388641357)
[2024-11-29 04:16:22,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:22,707][root][INFO] - Training Epoch: 10/10, step 259/574 completed (loss: 0.7284708619117737, acc: 0.7830188870429993)
[2024-11-29 04:16:22,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:23,321][root][INFO] - Training Epoch: 10/10, step 260/574 completed (loss: 1.120719313621521, acc: 0.7250000238418579)
[2024-11-29 04:16:23,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:23,912][root][INFO] - Training Epoch: 10/10, step 261/574 completed (loss: 0.34130871295928955, acc: 0.9722222089767456)
[2024-11-29 04:16:23,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:24,500][root][INFO] - Training Epoch: 10/10, step 262/574 completed (loss: 0.2891271710395813, acc: 0.8709677457809448)
[2024-11-29 04:16:24,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:25,093][root][INFO] - Training Epoch: 10/10, step 263/574 completed (loss: 0.9640324115753174, acc: 0.7066666483879089)
[2024-11-29 04:16:25,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:25,682][root][INFO] - Training Epoch: 10/10, step 264/574 completed (loss: 0.6294588446617126, acc: 0.8125)
[2024-11-29 04:16:25,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:26,296][root][INFO] - Training Epoch: 10/10, step 265/574 completed (loss: 1.663415551185608, acc: 0.5680000185966492)
[2024-11-29 04:16:26,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:26,890][root][INFO] - Training Epoch: 10/10, step 266/574 completed (loss: 0.8560774922370911, acc: 0.7415730357170105)
[2024-11-29 04:16:26,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:27,482][root][INFO] - Training Epoch: 10/10, step 267/574 completed (loss: 0.6228065490722656, acc: 0.7702702879905701)
[2024-11-29 04:16:28,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:28,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:29,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:29,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:30,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:30,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:31,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:31,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:32,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:32,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:33,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:33,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:34,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:35,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:35,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:36,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:36,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:37,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:37,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:38,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:38,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:39,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:39,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:40,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:40,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:41,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:41,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:42,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:43,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:43,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:44,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:44,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:45,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:45,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:46,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:46,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:47,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:47,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:48,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:48,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:49,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:49,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:50,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:50,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:51,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:52,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:52,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:53,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:53,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:54,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:54,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:55,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:55,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:56,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:56,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:57,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:57,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:58,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:58,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:16:59,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:00,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:00,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:01,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:01,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:02,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:02,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:03,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:03,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:04,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:04,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:05,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:05,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:06,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:06,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:07,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:08,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:08,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:09,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:09,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:10,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:10,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:11,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:11,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:12,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:12,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:13,540][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.2785, device='cuda:0') eval_epoch_loss=tensor(1.1874, device='cuda:0') eval_epoch_acc=tensor(0.7233, device='cuda:0')
[2024-11-29 04:17:13,542][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 04:17:13,542][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 04:17:13,743][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_10_step_268_loss_1.1873897314071655/model.pt
[2024-11-29 04:17:13,745][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 10 is 1.1873897314071655
[2024-11-29 04:17:13,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:14,359][root][INFO] - Training Epoch: 10/10, step 268/574 completed (loss: 0.5997154116630554, acc: 0.7758620977401733)
[2024-11-29 04:17:14,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:14,946][root][INFO] - Training Epoch: 10/10, step 269/574 completed (loss: 0.020234091207385063, acc: 1.0)
[2024-11-29 04:17:15,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:15,531][root][INFO] - Training Epoch: 10/10, step 270/574 completed (loss: 0.13064326345920563, acc: 0.9090909361839294)
[2024-11-29 04:17:15,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:16,118][root][INFO] - Training Epoch: 10/10, step 271/574 completed (loss: 0.3272980749607086, acc: 0.875)
[2024-11-29 04:17:16,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:16,707][root][INFO] - Training Epoch: 10/10, step 272/574 completed (loss: 0.03809792548418045, acc: 1.0)
[2024-11-29 04:17:16,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:17,299][root][INFO] - Training Epoch: 10/10, step 273/574 completed (loss: 0.5869181752204895, acc: 0.800000011920929)
[2024-11-29 04:17:17,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:17,885][root][INFO] - Training Epoch: 10/10, step 274/574 completed (loss: 0.05685349926352501, acc: 0.96875)
[2024-11-29 04:17:17,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:18,473][root][INFO] - Training Epoch: 10/10, step 275/574 completed (loss: 0.023348456248641014, acc: 1.0)
[2024-11-29 04:17:18,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:19,061][root][INFO] - Training Epoch: 10/10, step 276/574 completed (loss: 0.3795243501663208, acc: 0.9655172228813171)
[2024-11-29 04:17:19,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:19,646][root][INFO] - Training Epoch: 10/10, step 277/574 completed (loss: 0.0068161035887897015, acc: 1.0)
[2024-11-29 04:17:19,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:20,240][root][INFO] - Training Epoch: 10/10, step 278/574 completed (loss: 0.43763262033462524, acc: 0.914893627166748)
[2024-11-29 04:17:20,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:20,830][root][INFO] - Training Epoch: 10/10, step 279/574 completed (loss: 0.16511687636375427, acc: 0.9791666865348816)
[2024-11-29 04:17:20,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:21,420][root][INFO] - Training Epoch: 10/10, step 280/574 completed (loss: 0.11597532778978348, acc: 0.9545454382896423)
[2024-11-29 04:17:21,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:22,014][root][INFO] - Training Epoch: 10/10, step 281/574 completed (loss: 0.6686744689941406, acc: 0.7951807379722595)
[2024-11-29 04:17:22,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:22,611][root][INFO] - Training Epoch: 10/10, step 282/574 completed (loss: 0.8050200343132019, acc: 0.75)
[2024-11-29 04:17:22,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:23,197][root][INFO] - Training Epoch: 10/10, step 283/574 completed (loss: 0.22709284722805023, acc: 0.9210526347160339)
[2024-11-29 04:17:23,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:23,786][root][INFO] - Training Epoch: 10/10, step 284/574 completed (loss: 0.3234100341796875, acc: 0.9117646813392639)
[2024-11-29 04:17:23,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:24,374][root][INFO] - Training Epoch: 10/10, step 285/574 completed (loss: 0.28689929842948914, acc: 0.925000011920929)
[2024-11-29 04:17:24,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:24,971][root][INFO] - Training Epoch: 10/10, step 286/574 completed (loss: 0.7976518869400024, acc: 0.78125)
[2024-11-29 04:17:25,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:25,578][root][INFO] - Training Epoch: 10/10, step 287/574 completed (loss: 0.8992771506309509, acc: 0.7360000014305115)
[2024-11-29 04:17:25,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:26,171][root][INFO] - Training Epoch: 10/10, step 288/574 completed (loss: 0.5947558283805847, acc: 0.8131868243217468)
[2024-11-29 04:17:26,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:26,768][root][INFO] - Training Epoch: 10/10, step 289/574 completed (loss: 0.8922898173332214, acc: 0.7577639818191528)
[2024-11-29 04:17:26,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:27,380][root][INFO] - Training Epoch: 10/10, step 290/574 completed (loss: 1.3388677835464478, acc: 0.6649484634399414)
[2024-11-29 04:17:27,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:27,970][root][INFO] - Training Epoch: 10/10, step 291/574 completed (loss: 0.00867206696420908, acc: 1.0)
[2024-11-29 04:17:28,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:28,561][root][INFO] - Training Epoch: 10/10, step 292/574 completed (loss: 0.4168717861175537, acc: 0.9047619104385376)
[2024-11-29 04:17:28,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:29,153][root][INFO] - Training Epoch: 10/10, step 293/574 completed (loss: 0.44598662853240967, acc: 0.8965517282485962)
[2024-11-29 04:17:29,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:29,748][root][INFO] - Training Epoch: 10/10, step 294/574 completed (loss: 0.30107229948043823, acc: 0.9090909361839294)
[2024-11-29 04:17:29,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:30,371][root][INFO] - Training Epoch: 10/10, step 295/574 completed (loss: 1.1467175483703613, acc: 0.6701030731201172)
[2024-11-29 04:17:30,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:30,964][root][INFO] - Training Epoch: 10/10, step 296/574 completed (loss: 0.5392107963562012, acc: 0.8620689511299133)
[2024-11-29 04:17:31,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:31,550][root][INFO] - Training Epoch: 10/10, step 297/574 completed (loss: 0.08071352541446686, acc: 0.9629629850387573)
[2024-11-29 04:17:31,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:32,143][root][INFO] - Training Epoch: 10/10, step 298/574 completed (loss: 0.4360637664794922, acc: 0.8421052694320679)
[2024-11-29 04:17:32,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:32,734][root][INFO] - Training Epoch: 10/10, step 299/574 completed (loss: 0.14241310954093933, acc: 0.9642857313156128)
[2024-11-29 04:17:32,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:33,323][root][INFO] - Training Epoch: 10/10, step 300/574 completed (loss: 0.016154156997799873, acc: 1.0)
[2024-11-29 04:17:33,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:33,915][root][INFO] - Training Epoch: 10/10, step 301/574 completed (loss: 0.48384979367256165, acc: 0.9056603908538818)
[2024-11-29 04:17:33,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:34,505][root][INFO] - Training Epoch: 10/10, step 302/574 completed (loss: 0.04669953137636185, acc: 1.0)
[2024-11-29 04:17:34,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:35,092][root][INFO] - Training Epoch: 10/10, step 303/574 completed (loss: 0.042866650968790054, acc: 0.970588207244873)
[2024-11-29 04:17:35,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:35,682][root][INFO] - Training Epoch: 10/10, step 304/574 completed (loss: 0.04825599491596222, acc: 1.0)
[2024-11-29 04:17:35,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:36,276][root][INFO] - Training Epoch: 10/10, step 305/574 completed (loss: 0.1801217943429947, acc: 0.9672130942344666)
[2024-11-29 04:17:36,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:36,863][root][INFO] - Training Epoch: 10/10, step 306/574 completed (loss: 0.04864082857966423, acc: 1.0)
[2024-11-29 04:17:36,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:37,448][root][INFO] - Training Epoch: 10/10, step 307/574 completed (loss: 0.0028868657536804676, acc: 1.0)
[2024-11-29 04:17:37,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:38,041][root][INFO] - Training Epoch: 10/10, step 308/574 completed (loss: 0.4997531473636627, acc: 0.8550724387168884)
[2024-11-29 04:17:38,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:38,637][root][INFO] - Training Epoch: 10/10, step 309/574 completed (loss: 0.7157046794891357, acc: 0.7916666865348816)
[2024-11-29 04:17:38,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:39,231][root][INFO] - Training Epoch: 10/10, step 310/574 completed (loss: 0.3875539004802704, acc: 0.891566276550293)
[2024-11-29 04:17:39,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:39,825][root][INFO] - Training Epoch: 10/10, step 311/574 completed (loss: 0.5142365097999573, acc: 0.8461538553237915)
[2024-11-29 04:17:39,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:40,434][root][INFO] - Training Epoch: 10/10, step 312/574 completed (loss: 0.8607589602470398, acc: 0.7551020383834839)
[2024-11-29 04:17:40,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:41,020][root][INFO] - Training Epoch: 10/10, step 313/574 completed (loss: 0.040561970323324203, acc: 0.9583333134651184)
[2024-11-29 04:17:41,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:41,607][root][INFO] - Training Epoch: 10/10, step 314/574 completed (loss: 0.010958019644021988, acc: 1.0)
[2024-11-29 04:17:41,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:42,196][root][INFO] - Training Epoch: 10/10, step 315/574 completed (loss: 0.013561439700424671, acc: 1.0)
[2024-11-29 04:17:42,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:42,783][root][INFO] - Training Epoch: 10/10, step 316/574 completed (loss: 0.05701058357954025, acc: 0.9677419066429138)
[2024-11-29 04:17:42,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:43,376][root][INFO] - Training Epoch: 10/10, step 317/574 completed (loss: 0.31381532549858093, acc: 0.9253731369972229)
[2024-11-29 04:17:43,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:43,972][root][INFO] - Training Epoch: 10/10, step 318/574 completed (loss: 0.3821100890636444, acc: 0.875)
[2024-11-29 04:17:44,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:44,560][root][INFO] - Training Epoch: 10/10, step 319/574 completed (loss: 0.02810588851571083, acc: 1.0)
[2024-11-29 04:17:44,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:45,152][root][INFO] - Training Epoch: 10/10, step 320/574 completed (loss: 0.12287116795778275, acc: 0.9677419066429138)
[2024-11-29 04:17:45,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:45,740][root][INFO] - Training Epoch: 10/10, step 321/574 completed (loss: 0.19862598180770874, acc: 0.8999999761581421)
[2024-11-29 04:17:45,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:46,327][root][INFO] - Training Epoch: 10/10, step 322/574 completed (loss: 0.2609308958053589, acc: 0.8888888955116272)
[2024-11-29 04:17:46,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:46,917][root][INFO] - Training Epoch: 10/10, step 323/574 completed (loss: 0.5981600880622864, acc: 0.800000011920929)
[2024-11-29 04:17:46,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:47,504][root][INFO] - Training Epoch: 10/10, step 324/574 completed (loss: 0.34385019540786743, acc: 0.8461538553237915)
[2024-11-29 04:17:47,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:48,097][root][INFO] - Training Epoch: 10/10, step 325/574 completed (loss: 0.3433399796485901, acc: 0.8536585569381714)
[2024-11-29 04:17:48,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:48,687][root][INFO] - Training Epoch: 10/10, step 326/574 completed (loss: 0.34353747963905334, acc: 0.8947368264198303)
[2024-11-29 04:17:48,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:49,273][root][INFO] - Training Epoch: 10/10, step 327/574 completed (loss: 0.011759993620216846, acc: 1.0)
[2024-11-29 04:17:49,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:49,860][root][INFO] - Training Epoch: 10/10, step 328/574 completed (loss: 0.04632953926920891, acc: 0.9642857313156128)
[2024-11-29 04:17:49,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:50,446][root][INFO] - Training Epoch: 10/10, step 329/574 completed (loss: 0.111112579703331, acc: 0.9629629850387573)
[2024-11-29 04:17:50,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:51,032][root][INFO] - Training Epoch: 10/10, step 330/574 completed (loss: 0.0512368381023407, acc: 0.96875)
[2024-11-29 04:17:51,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:51,626][root][INFO] - Training Epoch: 10/10, step 331/574 completed (loss: 0.2267204225063324, acc: 0.9516128897666931)
[2024-11-29 04:17:51,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:52,218][root][INFO] - Training Epoch: 10/10, step 332/574 completed (loss: 0.23277932405471802, acc: 0.9473684430122375)
[2024-11-29 04:17:52,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:52,803][root][INFO] - Training Epoch: 10/10, step 333/574 completed (loss: 0.06426723301410675, acc: 0.96875)
[2024-11-29 04:17:52,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:53,390][root][INFO] - Training Epoch: 10/10, step 334/574 completed (loss: 0.2771182060241699, acc: 0.9333333373069763)
[2024-11-29 04:17:53,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:53,979][root][INFO] - Training Epoch: 10/10, step 335/574 completed (loss: 0.2503339946269989, acc: 0.8947368264198303)
[2024-11-29 04:17:54,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:54,571][root][INFO] - Training Epoch: 10/10, step 336/574 completed (loss: 0.500715970993042, acc: 0.800000011920929)
[2024-11-29 04:17:54,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:55,166][root][INFO] - Training Epoch: 10/10, step 337/574 completed (loss: 1.059588074684143, acc: 0.7011494040489197)
[2024-11-29 04:17:55,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:55,761][root][INFO] - Training Epoch: 10/10, step 338/574 completed (loss: 0.9311528205871582, acc: 0.7446808218955994)
[2024-11-29 04:17:55,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:56,354][root][INFO] - Training Epoch: 10/10, step 339/574 completed (loss: 1.123426079750061, acc: 0.6746987700462341)
[2024-11-29 04:17:56,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:56,941][root][INFO] - Training Epoch: 10/10, step 340/574 completed (loss: 0.015849005430936813, acc: 1.0)
[2024-11-29 04:17:57,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:57,528][root][INFO] - Training Epoch: 10/10, step 341/574 completed (loss: 0.3671242594718933, acc: 0.8461538553237915)
[2024-11-29 04:17:57,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:58,121][root][INFO] - Training Epoch: 10/10, step 342/574 completed (loss: 0.8723771572113037, acc: 0.7831325531005859)
[2024-11-29 04:17:58,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:58,714][root][INFO] - Training Epoch: 10/10, step 343/574 completed (loss: 0.3340407609939575, acc: 0.9245283007621765)
[2024-11-29 04:17:58,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:59,306][root][INFO] - Training Epoch: 10/10, step 344/574 completed (loss: 0.31297194957733154, acc: 0.9240506291389465)
[2024-11-29 04:17:59,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:17:59,894][root][INFO] - Training Epoch: 10/10, step 345/574 completed (loss: 0.21250781416893005, acc: 0.9215686321258545)
[2024-11-29 04:17:59,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:00,488][root][INFO] - Training Epoch: 10/10, step 346/574 completed (loss: 0.6330033540725708, acc: 0.8059701323509216)
[2024-11-29 04:18:00,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:01,073][root][INFO] - Training Epoch: 10/10, step 347/574 completed (loss: 0.045992083847522736, acc: 0.949999988079071)
[2024-11-29 04:18:01,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:01,661][root][INFO] - Training Epoch: 10/10, step 348/574 completed (loss: 0.15268009901046753, acc: 0.9200000166893005)
[2024-11-29 04:18:01,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:02,251][root][INFO] - Training Epoch: 10/10, step 349/574 completed (loss: 0.2215775102376938, acc: 0.9166666865348816)
[2024-11-29 04:18:02,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:02,839][root][INFO] - Training Epoch: 10/10, step 350/574 completed (loss: 0.26681795716285706, acc: 0.9069767594337463)
[2024-11-29 04:18:02,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:03,429][root][INFO] - Training Epoch: 10/10, step 351/574 completed (loss: 0.28877100348472595, acc: 0.8974359035491943)
[2024-11-29 04:18:03,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:04,019][root][INFO] - Training Epoch: 10/10, step 352/574 completed (loss: 0.4589119851589203, acc: 0.8666666746139526)
[2024-11-29 04:18:04,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:04,606][root][INFO] - Training Epoch: 10/10, step 353/574 completed (loss: 0.008761584758758545, acc: 1.0)
[2024-11-29 04:18:04,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:05,193][root][INFO] - Training Epoch: 10/10, step 354/574 completed (loss: 0.3253048360347748, acc: 0.9230769276618958)
[2024-11-29 04:18:05,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:05,786][root][INFO] - Training Epoch: 10/10, step 355/574 completed (loss: 0.9541481137275696, acc: 0.6813187003135681)
[2024-11-29 04:18:05,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:06,397][root][INFO] - Training Epoch: 10/10, step 356/574 completed (loss: 1.0252140760421753, acc: 0.7217391133308411)
[2024-11-29 04:18:06,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:06,988][root][INFO] - Training Epoch: 10/10, step 357/574 completed (loss: 0.48987963795661926, acc: 0.8586956262588501)
[2024-11-29 04:18:07,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:07,579][root][INFO] - Training Epoch: 10/10, step 358/574 completed (loss: 0.26582789421081543, acc: 0.8979591727256775)
[2024-11-29 04:18:07,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:08,165][root][INFO] - Training Epoch: 10/10, step 359/574 completed (loss: 0.00771711952984333, acc: 1.0)
[2024-11-29 04:18:08,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:08,752][root][INFO] - Training Epoch: 10/10, step 360/574 completed (loss: 0.022582339122891426, acc: 1.0)
[2024-11-29 04:18:08,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:09,340][root][INFO] - Training Epoch: 10/10, step 361/574 completed (loss: 0.07890946418046951, acc: 0.9756097793579102)
[2024-11-29 04:18:09,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:09,928][root][INFO] - Training Epoch: 10/10, step 362/574 completed (loss: 0.24659782648086548, acc: 0.9111111164093018)
[2024-11-29 04:18:10,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:10,523][root][INFO] - Training Epoch: 10/10, step 363/574 completed (loss: 0.4398437738418579, acc: 0.8421052694320679)
[2024-11-29 04:18:10,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:11,113][root][INFO] - Training Epoch: 10/10, step 364/574 completed (loss: 0.5179666876792908, acc: 0.8536585569381714)
[2024-11-29 04:18:11,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:11,702][root][INFO] - Training Epoch: 10/10, step 365/574 completed (loss: 0.17669177055358887, acc: 0.939393937587738)
[2024-11-29 04:18:11,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:12,290][root][INFO] - Training Epoch: 10/10, step 366/574 completed (loss: 0.0047388458624482155, acc: 1.0)
[2024-11-29 04:18:12,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:12,876][root][INFO] - Training Epoch: 10/10, step 367/574 completed (loss: 0.004890804179012775, acc: 1.0)
[2024-11-29 04:18:12,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:13,462][root][INFO] - Training Epoch: 10/10, step 368/574 completed (loss: 0.011423380114138126, acc: 1.0)
[2024-11-29 04:18:13,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:14,050][root][INFO] - Training Epoch: 10/10, step 369/574 completed (loss: 0.14659151434898376, acc: 0.90625)
[2024-11-29 04:18:14,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:14,669][root][INFO] - Training Epoch: 10/10, step 370/574 completed (loss: 1.4286521673202515, acc: 0.6424242258071899)
[2024-11-29 04:18:14,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:15,282][root][INFO] - Training Epoch: 10/10, step 371/574 completed (loss: 0.6927239894866943, acc: 0.8113207817077637)
[2024-11-29 04:18:15,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:15,876][root][INFO] - Training Epoch: 10/10, step 372/574 completed (loss: 0.20076777040958405, acc: 0.9444444179534912)
[2024-11-29 04:18:15,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:16,466][root][INFO] - Training Epoch: 10/10, step 373/574 completed (loss: 0.21558181941509247, acc: 0.9642857313156128)
[2024-11-29 04:18:16,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:17,058][root][INFO] - Training Epoch: 10/10, step 374/574 completed (loss: 0.18393048644065857, acc: 0.9714285731315613)
[2024-11-29 04:18:17,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:17,646][root][INFO] - Training Epoch: 10/10, step 375/574 completed (loss: 0.10497390478849411, acc: 0.9599999785423279)
[2024-11-29 04:18:17,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:18,231][root][INFO] - Training Epoch: 10/10, step 376/574 completed (loss: 0.004368443042039871, acc: 1.0)
[2024-11-29 04:18:18,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:18,822][root][INFO] - Training Epoch: 10/10, step 377/574 completed (loss: 0.3251175582408905, acc: 0.9166666865348816)
[2024-11-29 04:18:18,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:19,416][root][INFO] - Training Epoch: 10/10, step 378/574 completed (loss: 0.26398199796676636, acc: 0.9368420839309692)
[2024-11-29 04:18:19,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:20,026][root][INFO] - Training Epoch: 10/10, step 379/574 completed (loss: 0.9938192963600159, acc: 0.71257483959198)
[2024-11-29 04:18:20,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:20,622][root][INFO] - Training Epoch: 10/10, step 380/574 completed (loss: 0.6723456978797913, acc: 0.8270676732063293)
[2024-11-29 04:18:20,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:21,242][root][INFO] - Training Epoch: 10/10, step 381/574 completed (loss: 1.0512140989303589, acc: 0.7433155179023743)
[2024-11-29 04:18:21,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:21,853][root][INFO] - Training Epoch: 10/10, step 382/574 completed (loss: 0.4161736071109772, acc: 0.8918918967247009)
[2024-11-29 04:18:21,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:22,440][root][INFO] - Training Epoch: 10/10, step 383/574 completed (loss: 0.10839606821537018, acc: 0.9285714030265808)
[2024-11-29 04:18:22,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:23,029][root][INFO] - Training Epoch: 10/10, step 384/574 completed (loss: 0.007510925643146038, acc: 1.0)
[2024-11-29 04:18:23,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:23,617][root][INFO] - Training Epoch: 10/10, step 385/574 completed (loss: 0.03192196786403656, acc: 1.0)
[2024-11-29 04:18:23,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:24,203][root][INFO] - Training Epoch: 10/10, step 386/574 completed (loss: 0.03466903045773506, acc: 1.0)
[2024-11-29 04:18:24,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:24,790][root][INFO] - Training Epoch: 10/10, step 387/574 completed (loss: 0.022652601823210716, acc: 1.0)
[2024-11-29 04:18:24,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:25,377][root][INFO] - Training Epoch: 10/10, step 388/574 completed (loss: 0.03853946551680565, acc: 1.0)
[2024-11-29 04:18:25,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:25,962][root][INFO] - Training Epoch: 10/10, step 389/574 completed (loss: 0.006563498172909021, acc: 1.0)
[2024-11-29 04:18:26,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:26,548][root][INFO] - Training Epoch: 10/10, step 390/574 completed (loss: 0.04010095074772835, acc: 1.0)
[2024-11-29 04:18:26,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:27,138][root][INFO] - Training Epoch: 10/10, step 391/574 completed (loss: 0.5373072028160095, acc: 0.8148148059844971)
[2024-11-29 04:18:27,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:27,731][root][INFO] - Training Epoch: 10/10, step 392/574 completed (loss: 0.8743261098861694, acc: 0.6990291476249695)
[2024-11-29 04:18:27,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:28,345][root][INFO] - Training Epoch: 10/10, step 393/574 completed (loss: 1.0996800661087036, acc: 0.6617646813392639)
[2024-11-29 04:18:28,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:28,944][root][INFO] - Training Epoch: 10/10, step 394/574 completed (loss: 1.1806336641311646, acc: 0.6800000071525574)
[2024-11-29 04:18:29,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:29,540][root][INFO] - Training Epoch: 10/10, step 395/574 completed (loss: 1.0597652196884155, acc: 0.7013888955116272)
[2024-11-29 04:18:29,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:30,129][root][INFO] - Training Epoch: 10/10, step 396/574 completed (loss: 0.16448025405406952, acc: 0.9534883499145508)
[2024-11-29 04:18:30,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:30,716][root][INFO] - Training Epoch: 10/10, step 397/574 completed (loss: 0.011570057831704617, acc: 1.0)
[2024-11-29 04:18:30,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:31,305][root][INFO] - Training Epoch: 10/10, step 398/574 completed (loss: 0.13786135613918304, acc: 0.9767441749572754)
[2024-11-29 04:18:31,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:31,891][root][INFO] - Training Epoch: 10/10, step 399/574 completed (loss: 0.015696071088314056, acc: 1.0)
[2024-11-29 04:18:31,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:32,486][root][INFO] - Training Epoch: 10/10, step 400/574 completed (loss: 0.5078110694885254, acc: 0.8676470518112183)
[2024-11-29 04:18:32,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:33,080][root][INFO] - Training Epoch: 10/10, step 401/574 completed (loss: 0.35947826504707336, acc: 0.8799999952316284)
[2024-11-29 04:18:33,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:33,668][root][INFO] - Training Epoch: 10/10, step 402/574 completed (loss: 0.024630732834339142, acc: 1.0)
[2024-11-29 04:18:33,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:34,255][root][INFO] - Training Epoch: 10/10, step 403/574 completed (loss: 0.18172229826450348, acc: 0.9696969985961914)
[2024-11-29 04:18:34,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:34,842][root][INFO] - Training Epoch: 10/10, step 404/574 completed (loss: 0.004270831122994423, acc: 1.0)
[2024-11-29 04:18:34,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:35,429][root][INFO] - Training Epoch: 10/10, step 405/574 completed (loss: 0.05254421383142471, acc: 1.0)
[2024-11-29 04:18:35,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:36,014][root][INFO] - Training Epoch: 10/10, step 406/574 completed (loss: 0.010662699118256569, acc: 1.0)
[2024-11-29 04:18:36,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:36,601][root][INFO] - Training Epoch: 10/10, step 407/574 completed (loss: 0.02891935221850872, acc: 1.0)
[2024-11-29 04:18:36,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:37,188][root][INFO] - Training Epoch: 10/10, step 408/574 completed (loss: 0.015830643475055695, acc: 1.0)
[2024-11-29 04:18:37,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:37,774][root][INFO] - Training Epoch: 10/10, step 409/574 completed (loss: 0.015455036424100399, acc: 1.0)
[2024-11-29 04:18:37,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:38,365][root][INFO] - Training Epoch: 10/10, step 410/574 completed (loss: 0.14499443769454956, acc: 0.9482758641242981)
[2024-11-29 04:18:39,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:39,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:40,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:40,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:41,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:41,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:42,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:42,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:43,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:43,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:44,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:44,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:45,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:45,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:46,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:46,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:47,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:47,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:48,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:48,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:49,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:50,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:50,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:51,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:51,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:52,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:52,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:53,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:53,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:54,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:54,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:55,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:55,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:56,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:56,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:57,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:57,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:58,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:58,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:18:59,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:00,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:00,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:01,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:01,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:02,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:02,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:03,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:03,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:04,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:04,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:05,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:05,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:06,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:06,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:07,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:07,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:08,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:08,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:09,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:10,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:10,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:11,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:11,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:12,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:12,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:13,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:13,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:14,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:14,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:15,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:15,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:16,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:16,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:17,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:17,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:18,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:18,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:19,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:20,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:20,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:21,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:21,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:22,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:22,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:23,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:24,042][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.6175, device='cuda:0') eval_epoch_loss=tensor(1.2858, device='cuda:0') eval_epoch_acc=tensor(0.7200, device='cuda:0')
[2024-11-29 04:19:24,046][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 04:19:24,047][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 04:19:24,323][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_10_step_411_loss_1.2857953310012817/model.pt
[2024-11-29 04:19:24,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:24,929][root][INFO] - Training Epoch: 10/10, step 411/574 completed (loss: 0.017748849466443062, acc: 1.0)
[2024-11-29 04:19:25,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:25,518][root][INFO] - Training Epoch: 10/10, step 412/574 completed (loss: 0.2640005350112915, acc: 0.9333333373069763)
[2024-11-29 04:19:25,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:26,106][root][INFO] - Training Epoch: 10/10, step 413/574 completed (loss: 0.35038089752197266, acc: 0.939393937587738)
[2024-11-29 04:19:26,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:26,693][root][INFO] - Training Epoch: 10/10, step 414/574 completed (loss: 0.026568787172436714, acc: 1.0)
[2024-11-29 04:19:26,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:27,289][root][INFO] - Training Epoch: 10/10, step 415/574 completed (loss: 0.46678709983825684, acc: 0.8823529481887817)
[2024-11-29 04:19:27,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:27,879][root][INFO] - Training Epoch: 10/10, step 416/574 completed (loss: 0.016173237934708595, acc: 1.0)
[2024-11-29 04:19:27,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:28,465][root][INFO] - Training Epoch: 10/10, step 417/574 completed (loss: 0.013634930364787579, acc: 1.0)
[2024-11-29 04:19:28,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:29,060][root][INFO] - Training Epoch: 10/10, step 418/574 completed (loss: 0.24204547703266144, acc: 0.8999999761581421)
[2024-11-29 04:19:29,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:29,646][root][INFO] - Training Epoch: 10/10, step 419/574 completed (loss: 0.22210092842578888, acc: 0.8999999761581421)
[2024-11-29 04:19:29,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:30,232][root][INFO] - Training Epoch: 10/10, step 420/574 completed (loss: 0.005797788500785828, acc: 1.0)
[2024-11-29 04:19:30,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:30,821][root][INFO] - Training Epoch: 10/10, step 421/574 completed (loss: 0.037123892456293106, acc: 1.0)
[2024-11-29 04:19:30,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:31,409][root][INFO] - Training Epoch: 10/10, step 422/574 completed (loss: 0.047278787940740585, acc: 1.0)
[2024-11-29 04:19:31,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:32,000][root][INFO] - Training Epoch: 10/10, step 423/574 completed (loss: 0.312695175409317, acc: 0.8888888955116272)
[2024-11-29 04:19:32,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:32,590][root][INFO] - Training Epoch: 10/10, step 424/574 completed (loss: 0.007975487969815731, acc: 1.0)
[2024-11-29 04:19:32,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:33,179][root][INFO] - Training Epoch: 10/10, step 425/574 completed (loss: 0.3534698188304901, acc: 0.9090909361839294)
[2024-11-29 04:19:33,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:33,765][root][INFO] - Training Epoch: 10/10, step 426/574 completed (loss: 0.022075964137911797, acc: 1.0)
[2024-11-29 04:19:33,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:34,356][root][INFO] - Training Epoch: 10/10, step 427/574 completed (loss: 0.06910265237092972, acc: 0.9729729890823364)
[2024-11-29 04:19:34,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:34,944][root][INFO] - Training Epoch: 10/10, step 428/574 completed (loss: 0.1808687001466751, acc: 0.9629629850387573)
[2024-11-29 04:19:35,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:35,530][root][INFO] - Training Epoch: 10/10, step 429/574 completed (loss: 0.12574808299541473, acc: 0.95652174949646)
[2024-11-29 04:19:35,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:36,116][root][INFO] - Training Epoch: 10/10, step 430/574 completed (loss: 0.004668399691581726, acc: 1.0)
[2024-11-29 04:19:36,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:36,702][root][INFO] - Training Epoch: 10/10, step 431/574 completed (loss: 0.0034053358249366283, acc: 1.0)
[2024-11-29 04:19:36,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:37,287][root][INFO] - Training Epoch: 10/10, step 432/574 completed (loss: 0.005021608900278807, acc: 1.0)
[2024-11-29 04:19:37,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:37,876][root][INFO] - Training Epoch: 10/10, step 433/574 completed (loss: 0.08667802065610886, acc: 0.9722222089767456)
[2024-11-29 04:19:37,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:38,463][root][INFO] - Training Epoch: 10/10, step 434/574 completed (loss: 0.04971567168831825, acc: 0.9599999785423279)
[2024-11-29 04:19:38,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:39,051][root][INFO] - Training Epoch: 10/10, step 435/574 completed (loss: 0.25696709752082825, acc: 0.9696969985961914)
[2024-11-29 04:19:39,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:39,638][root][INFO] - Training Epoch: 10/10, step 436/574 completed (loss: 0.3482478857040405, acc: 0.8611111044883728)
[2024-11-29 04:19:39,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:40,231][root][INFO] - Training Epoch: 10/10, step 437/574 completed (loss: 0.293337881565094, acc: 0.8863636255264282)
[2024-11-29 04:19:40,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:40,819][root][INFO] - Training Epoch: 10/10, step 438/574 completed (loss: 0.044857174158096313, acc: 1.0)
[2024-11-29 04:19:40,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:41,410][root][INFO] - Training Epoch: 10/10, step 439/574 completed (loss: 0.2923685312271118, acc: 0.9487179517745972)
[2024-11-29 04:19:41,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:42,007][root][INFO] - Training Epoch: 10/10, step 440/574 completed (loss: 0.6412007808685303, acc: 0.8333333134651184)
[2024-11-29 04:19:42,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:42,618][root][INFO] - Training Epoch: 10/10, step 441/574 completed (loss: 1.5148775577545166, acc: 0.527999997138977)
[2024-11-29 04:19:42,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:43,214][root][INFO] - Training Epoch: 10/10, step 442/574 completed (loss: 1.1321346759796143, acc: 0.6612903475761414)
[2024-11-29 04:19:43,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:43,827][root][INFO] - Training Epoch: 10/10, step 443/574 completed (loss: 1.3410205841064453, acc: 0.6218905448913574)
[2024-11-29 04:19:43,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:44,417][root][INFO] - Training Epoch: 10/10, step 444/574 completed (loss: 0.3077682852745056, acc: 0.9056603908538818)
[2024-11-29 04:19:44,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:45,010][root][INFO] - Training Epoch: 10/10, step 445/574 completed (loss: 0.142698273062706, acc: 0.9772727489471436)
[2024-11-29 04:19:45,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:45,598][root][INFO] - Training Epoch: 10/10, step 446/574 completed (loss: 0.08940743654966354, acc: 0.95652174949646)
[2024-11-29 04:19:45,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:46,183][root][INFO] - Training Epoch: 10/10, step 447/574 completed (loss: 0.03570271283388138, acc: 1.0)
[2024-11-29 04:19:46,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:46,769][root][INFO] - Training Epoch: 10/10, step 448/574 completed (loss: 0.03428170084953308, acc: 1.0)
[2024-11-29 04:19:46,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:47,358][root][INFO] - Training Epoch: 10/10, step 449/574 completed (loss: 0.23396040499210358, acc: 0.9253731369972229)
[2024-11-29 04:19:47,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:47,949][root][INFO] - Training Epoch: 10/10, step 450/574 completed (loss: 0.27939459681510925, acc: 0.9166666865348816)
[2024-11-29 04:19:48,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:48,543][root][INFO] - Training Epoch: 10/10, step 451/574 completed (loss: 0.30549028515815735, acc: 0.9239130616188049)
[2024-11-29 04:19:48,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:49,138][root][INFO] - Training Epoch: 10/10, step 452/574 completed (loss: 0.31698861718177795, acc: 0.9358974099159241)
[2024-11-29 04:19:49,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:49,732][root][INFO] - Training Epoch: 10/10, step 453/574 completed (loss: 0.5863173604011536, acc: 0.8421052694320679)
[2024-11-29 04:19:49,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:50,322][root][INFO] - Training Epoch: 10/10, step 454/574 completed (loss: 0.21418754756450653, acc: 0.9591836929321289)
[2024-11-29 04:19:50,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:50,910][root][INFO] - Training Epoch: 10/10, step 455/574 completed (loss: 0.04002482444047928, acc: 1.0)
[2024-11-29 04:19:50,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:51,508][root][INFO] - Training Epoch: 10/10, step 456/574 completed (loss: 0.6958615183830261, acc: 0.8247422575950623)
[2024-11-29 04:19:51,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:52,098][root][INFO] - Training Epoch: 10/10, step 457/574 completed (loss: 0.12000664323568344, acc: 0.9857142567634583)
[2024-11-29 04:19:52,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:52,720][root][INFO] - Training Epoch: 10/10, step 458/574 completed (loss: 1.0000340938568115, acc: 0.7267441749572754)
[2024-11-29 04:19:52,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:53,309][root][INFO] - Training Epoch: 10/10, step 459/574 completed (loss: 0.3751353621482849, acc: 0.9285714030265808)
[2024-11-29 04:19:53,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:53,906][root][INFO] - Training Epoch: 10/10, step 460/574 completed (loss: 0.3068276047706604, acc: 0.9012345671653748)
[2024-11-29 04:19:53,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:54,494][root][INFO] - Training Epoch: 10/10, step 461/574 completed (loss: 0.21634213626384735, acc: 0.9444444179534912)
[2024-11-29 04:19:54,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:55,086][root][INFO] - Training Epoch: 10/10, step 462/574 completed (loss: 0.06370532512664795, acc: 0.96875)
[2024-11-29 04:19:55,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:55,673][root][INFO] - Training Epoch: 10/10, step 463/574 completed (loss: 0.07928363233804703, acc: 0.9615384340286255)
[2024-11-29 04:19:55,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:56,264][root][INFO] - Training Epoch: 10/10, step 464/574 completed (loss: 0.22774940729141235, acc: 0.95652174949646)
[2024-11-29 04:19:56,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:56,856][root][INFO] - Training Epoch: 10/10, step 465/574 completed (loss: 0.2967333495616913, acc: 0.9047619104385376)
[2024-11-29 04:19:56,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:57,451][root][INFO] - Training Epoch: 10/10, step 466/574 completed (loss: 0.30340349674224854, acc: 0.9156626462936401)
[2024-11-29 04:19:57,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:58,062][root][INFO] - Training Epoch: 10/10, step 467/574 completed (loss: 0.6363162994384766, acc: 0.8018018007278442)
[2024-11-29 04:19:58,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:58,655][root][INFO] - Training Epoch: 10/10, step 468/574 completed (loss: 0.6107757091522217, acc: 0.8058252334594727)
[2024-11-29 04:19:58,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:59,268][root][INFO] - Training Epoch: 10/10, step 469/574 completed (loss: 0.7088145017623901, acc: 0.7886179089546204)
[2024-11-29 04:19:59,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:19:59,855][root][INFO] - Training Epoch: 10/10, step 470/574 completed (loss: 0.004661593120545149, acc: 1.0)
[2024-11-29 04:19:59,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:00,441][root][INFO] - Training Epoch: 10/10, step 471/574 completed (loss: 0.00767406914383173, acc: 1.0)
[2024-11-29 04:20:00,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:01,054][root][INFO] - Training Epoch: 10/10, step 472/574 completed (loss: 1.1112010478973389, acc: 0.6666666865348816)
[2024-11-29 04:20:01,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:01,668][root][INFO] - Training Epoch: 10/10, step 473/574 completed (loss: 1.482741117477417, acc: 0.5851528644561768)
[2024-11-29 04:20:01,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:02,261][root][INFO] - Training Epoch: 10/10, step 474/574 completed (loss: 0.640392005443573, acc: 0.8229166865348816)
[2024-11-29 04:20:02,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:02,861][root][INFO] - Training Epoch: 10/10, step 475/574 completed (loss: 0.6186582446098328, acc: 0.8159509301185608)
[2024-11-29 04:20:02,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:03,459][root][INFO] - Training Epoch: 10/10, step 476/574 completed (loss: 0.6680054664611816, acc: 0.8057553768157959)
[2024-11-29 04:20:03,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:04,073][root][INFO] - Training Epoch: 10/10, step 477/574 completed (loss: 1.2592681646347046, acc: 0.6281406879425049)
[2024-11-29 04:20:04,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:04,662][root][INFO] - Training Epoch: 10/10, step 478/574 completed (loss: 0.15133577585220337, acc: 0.9722222089767456)
[2024-11-29 04:20:04,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:05,250][root][INFO] - Training Epoch: 10/10, step 479/574 completed (loss: 0.5445374846458435, acc: 0.8787878751754761)
[2024-11-29 04:20:05,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:05,837][root][INFO] - Training Epoch: 10/10, step 480/574 completed (loss: 0.13128139078617096, acc: 0.9629629850387573)
[2024-11-29 04:20:05,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:06,422][root][INFO] - Training Epoch: 10/10, step 481/574 completed (loss: 0.04394269362092018, acc: 1.0)
[2024-11-29 04:20:06,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:07,008][root][INFO] - Training Epoch: 10/10, step 482/574 completed (loss: 0.014181678183376789, acc: 1.0)
[2024-11-29 04:20:07,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:07,604][root][INFO] - Training Epoch: 10/10, step 483/574 completed (loss: 0.441443532705307, acc: 0.8620689511299133)
[2024-11-29 04:20:07,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:08,193][root][INFO] - Training Epoch: 10/10, step 484/574 completed (loss: 0.06116665154695511, acc: 1.0)
[2024-11-29 04:20:08,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:08,779][root][INFO] - Training Epoch: 10/10, step 485/574 completed (loss: 0.0696696937084198, acc: 0.9473684430122375)
[2024-11-29 04:20:08,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:09,365][root][INFO] - Training Epoch: 10/10, step 486/574 completed (loss: 0.3104669451713562, acc: 0.8518518805503845)
[2024-11-29 04:20:09,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:09,952][root][INFO] - Training Epoch: 10/10, step 487/574 completed (loss: 0.020293891429901123, acc: 1.0)
[2024-11-29 04:20:10,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:10,538][root][INFO] - Training Epoch: 10/10, step 488/574 completed (loss: 0.17967355251312256, acc: 0.9545454382896423)
[2024-11-29 04:20:10,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:11,129][root][INFO] - Training Epoch: 10/10, step 489/574 completed (loss: 0.8272320628166199, acc: 0.800000011920929)
[2024-11-29 04:20:11,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:11,720][root][INFO] - Training Epoch: 10/10, step 490/574 completed (loss: 0.388116717338562, acc: 0.8999999761581421)
[2024-11-29 04:20:11,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:12,307][root][INFO] - Training Epoch: 10/10, step 491/574 completed (loss: 0.05268396437168121, acc: 1.0)
[2024-11-29 04:20:12,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:12,896][root][INFO] - Training Epoch: 10/10, step 492/574 completed (loss: 0.15884003043174744, acc: 0.9607843160629272)
[2024-11-29 04:20:12,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:13,483][root][INFO] - Training Epoch: 10/10, step 493/574 completed (loss: 0.16331851482391357, acc: 0.931034505367279)
[2024-11-29 04:20:13,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:14,068][root][INFO] - Training Epoch: 10/10, step 494/574 completed (loss: 0.24255624413490295, acc: 0.9473684430122375)
[2024-11-29 04:20:14,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:14,655][root][INFO] - Training Epoch: 10/10, step 495/574 completed (loss: 0.037968359887599945, acc: 1.0)
[2024-11-29 04:20:14,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:15,251][root][INFO] - Training Epoch: 10/10, step 496/574 completed (loss: 0.8743168115615845, acc: 0.7410714030265808)
[2024-11-29 04:20:15,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:15,845][root][INFO] - Training Epoch: 10/10, step 497/574 completed (loss: 0.6181857585906982, acc: 0.8089887499809265)
[2024-11-29 04:20:15,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:16,443][root][INFO] - Training Epoch: 10/10, step 498/574 completed (loss: 0.9387903809547424, acc: 0.6966292262077332)
[2024-11-29 04:20:16,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:17,052][root][INFO] - Training Epoch: 10/10, step 499/574 completed (loss: 1.1614874601364136, acc: 0.609929084777832)
[2024-11-29 04:20:17,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:17,651][root][INFO] - Training Epoch: 10/10, step 500/574 completed (loss: 0.8058522343635559, acc: 0.79347825050354)
[2024-11-29 04:20:17,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:18,237][root][INFO] - Training Epoch: 10/10, step 501/574 completed (loss: 0.03511326387524605, acc: 1.0)
[2024-11-29 04:20:18,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:18,823][root][INFO] - Training Epoch: 10/10, step 502/574 completed (loss: 0.04336892068386078, acc: 1.0)
[2024-11-29 04:20:18,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:19,409][root][INFO] - Training Epoch: 10/10, step 503/574 completed (loss: 0.020772267132997513, acc: 1.0)
[2024-11-29 04:20:19,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:19,995][root][INFO] - Training Epoch: 10/10, step 504/574 completed (loss: 0.025602268055081367, acc: 1.0)
[2024-11-29 04:20:20,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:20,585][root][INFO] - Training Epoch: 10/10, step 505/574 completed (loss: 0.1452942192554474, acc: 0.9622641801834106)
[2024-11-29 04:20:20,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:21,172][root][INFO] - Training Epoch: 10/10, step 506/574 completed (loss: 0.06265543401241302, acc: 1.0)
[2024-11-29 04:20:21,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:21,770][root][INFO] - Training Epoch: 10/10, step 507/574 completed (loss: 0.9679509997367859, acc: 0.7027027010917664)
[2024-11-29 04:20:21,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:22,366][root][INFO] - Training Epoch: 10/10, step 508/574 completed (loss: 0.34274712204933167, acc: 0.8873239159584045)
[2024-11-29 04:20:22,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:22,952][root][INFO] - Training Epoch: 10/10, step 509/574 completed (loss: 0.014520153403282166, acc: 1.0)
[2024-11-29 04:20:23,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:23,540][root][INFO] - Training Epoch: 10/10, step 510/574 completed (loss: 0.013013600371778011, acc: 1.0)
[2024-11-29 04:20:23,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:24,126][root][INFO] - Training Epoch: 10/10, step 511/574 completed (loss: 0.03819290176033974, acc: 1.0)
[2024-11-29 04:20:24,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:24,758][root][INFO] - Training Epoch: 10/10, step 512/574 completed (loss: 1.8426129817962646, acc: 0.5285714268684387)
[2024-11-29 04:20:24,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:25,377][root][INFO] - Training Epoch: 10/10, step 513/574 completed (loss: 0.9829461574554443, acc: 0.738095223903656)
[2024-11-29 04:20:25,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:25,964][root][INFO] - Training Epoch: 10/10, step 514/574 completed (loss: 0.08164142072200775, acc: 0.9642857313156128)
[2024-11-29 04:20:26,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:26,557][root][INFO] - Training Epoch: 10/10, step 515/574 completed (loss: 0.23595258593559265, acc: 0.9166666865348816)
[2024-11-29 04:20:26,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:27,158][root][INFO] - Training Epoch: 10/10, step 516/574 completed (loss: 0.6724379062652588, acc: 0.8194444179534912)
[2024-11-29 04:20:27,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:27,745][root][INFO] - Training Epoch: 10/10, step 517/574 completed (loss: 0.0026161319110542536, acc: 1.0)
[2024-11-29 04:20:27,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:28,331][root][INFO] - Training Epoch: 10/10, step 518/574 completed (loss: 0.022439515218138695, acc: 1.0)
[2024-11-29 04:20:28,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:28,910][root][INFO] - Training Epoch: 10/10, step 519/574 completed (loss: 0.01580999046564102, acc: 1.0)
[2024-11-29 04:20:28,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:29,496][root][INFO] - Training Epoch: 10/10, step 520/574 completed (loss: 0.0393095538020134, acc: 1.0)
[2024-11-29 04:20:29,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:30,291][root][INFO] - Training Epoch: 10/10, step 521/574 completed (loss: 1.8048349618911743, acc: 0.5593220591545105)
[2024-11-29 04:20:30,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:30,912][root][INFO] - Training Epoch: 10/10, step 522/574 completed (loss: 0.7325233221054077, acc: 0.7761194109916687)
[2024-11-29 04:20:30,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:31,507][root][INFO] - Training Epoch: 10/10, step 523/574 completed (loss: 0.6364412307739258, acc: 0.8102189898490906)
[2024-11-29 04:20:31,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:32,129][root][INFO] - Training Epoch: 10/10, step 524/574 completed (loss: 1.158178448677063, acc: 0.7049999833106995)
[2024-11-29 04:20:32,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:32,721][root][INFO] - Training Epoch: 10/10, step 525/574 completed (loss: 0.05387554317712784, acc: 0.9814814925193787)
[2024-11-29 04:20:32,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:33,314][root][INFO] - Training Epoch: 10/10, step 526/574 completed (loss: 0.38508427143096924, acc: 0.8653846383094788)
[2024-11-29 04:20:33,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:33,901][root][INFO] - Training Epoch: 10/10, step 527/574 completed (loss: 0.01674773171544075, acc: 1.0)
[2024-11-29 04:20:33,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:34,496][root][INFO] - Training Epoch: 10/10, step 528/574 completed (loss: 0.6293812394142151, acc: 0.8196721076965332)
[2024-11-29 04:20:34,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:35,087][root][INFO] - Training Epoch: 10/10, step 529/574 completed (loss: 0.3900444507598877, acc: 0.8474576473236084)
[2024-11-29 04:20:35,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:35,679][root][INFO] - Training Epoch: 10/10, step 530/574 completed (loss: 0.21650296449661255, acc: 0.930232584476471)
[2024-11-29 04:20:35,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:36,267][root][INFO] - Training Epoch: 10/10, step 531/574 completed (loss: 0.267110675573349, acc: 0.9090909361839294)
[2024-11-29 04:20:36,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:36,857][root][INFO] - Training Epoch: 10/10, step 532/574 completed (loss: 0.24006450176239014, acc: 0.9433962106704712)
[2024-11-29 04:20:36,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:37,446][root][INFO] - Training Epoch: 10/10, step 533/574 completed (loss: 0.2701311409473419, acc: 0.9318181872367859)
[2024-11-29 04:20:37,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:38,033][root][INFO] - Training Epoch: 10/10, step 534/574 completed (loss: 0.2764841318130493, acc: 0.9200000166893005)
[2024-11-29 04:20:38,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:38,620][root][INFO] - Training Epoch: 10/10, step 535/574 completed (loss: 0.10293161869049072, acc: 0.949999988079071)
[2024-11-29 04:20:38,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:39,204][root][INFO] - Training Epoch: 10/10, step 536/574 completed (loss: 0.03611890971660614, acc: 1.0)
[2024-11-29 04:20:39,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:39,798][root][INFO] - Training Epoch: 10/10, step 537/574 completed (loss: 0.14226089417934418, acc: 0.9692307710647583)
[2024-11-29 04:20:39,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:40,394][root][INFO] - Training Epoch: 10/10, step 538/574 completed (loss: 0.27856022119522095, acc: 0.90625)
[2024-11-29 04:20:40,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:40,983][root][INFO] - Training Epoch: 10/10, step 539/574 completed (loss: 0.15963594615459442, acc: 0.96875)
[2024-11-29 04:20:41,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:41,572][root][INFO] - Training Epoch: 10/10, step 540/574 completed (loss: 0.13568003475666046, acc: 0.9696969985961914)
[2024-11-29 04:20:41,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:42,157][root][INFO] - Training Epoch: 10/10, step 541/574 completed (loss: 0.006129169836640358, acc: 1.0)
[2024-11-29 04:20:42,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:42,744][root][INFO] - Training Epoch: 10/10, step 542/574 completed (loss: 0.027521317824721336, acc: 1.0)
[2024-11-29 04:20:42,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:43,329][root][INFO] - Training Epoch: 10/10, step 543/574 completed (loss: 0.04044386371970177, acc: 0.95652174949646)
[2024-11-29 04:20:43,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:43,914][root][INFO] - Training Epoch: 10/10, step 544/574 completed (loss: 0.0483902283012867, acc: 0.9666666388511658)
[2024-11-29 04:20:43,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:44,502][root][INFO] - Training Epoch: 10/10, step 545/574 completed (loss: 0.09289051592350006, acc: 0.9756097793579102)
[2024-11-29 04:20:44,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:45,091][root][INFO] - Training Epoch: 10/10, step 546/574 completed (loss: 0.1320028156042099, acc: 0.9142857193946838)
[2024-11-29 04:20:45,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:45,679][root][INFO] - Training Epoch: 10/10, step 547/574 completed (loss: 0.1594908982515335, acc: 0.9473684430122375)
[2024-11-29 04:20:45,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:46,266][root][INFO] - Training Epoch: 10/10, step 548/574 completed (loss: 0.2067970335483551, acc: 0.9354838728904724)
[2024-11-29 04:20:46,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:46,851][root][INFO] - Training Epoch: 10/10, step 549/574 completed (loss: 0.008806408382952213, acc: 1.0)
[2024-11-29 04:20:46,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:47,440][root][INFO] - Training Epoch: 10/10, step 550/574 completed (loss: 0.1433679312467575, acc: 0.9696969985961914)
[2024-11-29 04:20:47,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:48,026][root][INFO] - Training Epoch: 10/10, step 551/574 completed (loss: 0.3259403109550476, acc: 0.925000011920929)
[2024-11-29 04:20:48,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:48,618][root][INFO] - Training Epoch: 10/10, step 552/574 completed (loss: 0.16137439012527466, acc: 0.9285714030265808)
[2024-11-29 04:20:48,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:49,227][root][INFO] - Training Epoch: 10/10, step 553/574 completed (loss: 0.7782536149024963, acc: 0.7591241002082825)
[2024-11-29 04:20:49,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:50,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:51,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:51,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:52,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:52,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:53,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:53,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:54,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:54,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:55,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:55,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:56,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:56,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:57,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:57,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:58,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:58,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:20:59,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:00,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:00,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:01,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:01,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:02,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:02,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:03,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:03,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:04,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:04,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:05,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:05,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:06,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:06,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:07,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:08,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:08,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:09,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:09,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:10,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:10,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:11,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:11,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:12,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:12,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:13,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:13,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:14,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:14,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:15,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:15,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:16,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:17,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:17,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:18,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:18,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:19,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:19,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:20,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:20,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:21,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:21,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:22,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:22,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:23,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:23,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:24,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:24,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:25,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:25,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:26,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:27,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:27,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:28,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:28,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:29,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:29,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:30,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:30,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:31,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:31,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:32,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:32,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:33,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:33,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:34,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:35,152][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.4356, device='cuda:0') eval_epoch_loss=tensor(1.2342, device='cuda:0') eval_epoch_acc=tensor(0.7350, device='cuda:0')
[2024-11-29 04:21:35,153][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 04:21:35,153][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 04:21:35,386][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_freeze_llm/asr_epoch_10_step_554_loss_1.2341796159744263/model.pt
[2024-11-29 04:21:35,390][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 10 is 0.7350079417228699
[2024-11-29 04:21:35,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:36,015][root][INFO] - Training Epoch: 10/10, step 554/574 completed (loss: 0.6278178095817566, acc: 0.8413792848587036)
[2024-11-29 04:21:36,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:36,612][root][INFO] - Training Epoch: 10/10, step 555/574 completed (loss: 0.7303726673126221, acc: 0.8142856955528259)
[2024-11-29 04:21:36,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:37,208][root][INFO] - Training Epoch: 10/10, step 556/574 completed (loss: 0.8061044216156006, acc: 0.7947019934654236)
[2024-11-29 04:21:37,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:37,803][root][INFO] - Training Epoch: 10/10, step 557/574 completed (loss: 0.36503276228904724, acc: 0.8717948794364929)
[2024-11-29 04:21:37,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:38,392][root][INFO] - Training Epoch: 10/10, step 558/574 completed (loss: 0.011222299188375473, acc: 1.0)
[2024-11-29 04:21:38,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:38,979][root][INFO] - Training Epoch: 10/10, step 559/574 completed (loss: 0.061596229672431946, acc: 1.0)
[2024-11-29 04:21:39,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:39,564][root][INFO] - Training Epoch: 10/10, step 560/574 completed (loss: 0.004910169169306755, acc: 1.0)
[2024-11-29 04:21:39,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:40,154][root][INFO] - Training Epoch: 10/10, step 561/574 completed (loss: 0.2683456242084503, acc: 0.9230769276618958)
[2024-11-29 04:21:40,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:40,761][root][INFO] - Training Epoch: 10/10, step 562/574 completed (loss: 0.5569900274276733, acc: 0.8666666746139526)
[2024-11-29 04:21:40,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:41,352][root][INFO] - Training Epoch: 10/10, step 563/574 completed (loss: 0.21940310299396515, acc: 0.9350649118423462)
[2024-11-29 04:21:41,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:41,940][root][INFO] - Training Epoch: 10/10, step 564/574 completed (loss: 0.21990792453289032, acc: 0.8958333134651184)
[2024-11-29 04:21:42,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:42,530][root][INFO] - Training Epoch: 10/10, step 565/574 completed (loss: 0.10044129192829132, acc: 0.9655172228813171)
[2024-11-29 04:21:42,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:43,126][root][INFO] - Training Epoch: 10/10, step 566/574 completed (loss: 0.3937554657459259, acc: 0.8452380895614624)
[2024-11-29 04:21:43,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:43,713][root][INFO] - Training Epoch: 10/10, step 567/574 completed (loss: 0.04715973883867264, acc: 1.0)
[2024-11-29 04:21:43,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:44,299][root][INFO] - Training Epoch: 10/10, step 568/574 completed (loss: 0.33369582891464233, acc: 0.9259259104728699)
[2024-11-29 04:21:44,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:44,924][root][INFO] - Training Epoch: 10/10, step 569/574 completed (loss: 1.1368229389190674, acc: 0.6470588445663452)
[2024-11-29 04:21:45,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:45,516][root][INFO] - Training Epoch: 10/10, step 570/574 completed (loss: 0.1385979950428009, acc: 0.9677419066429138)
[2024-11-29 04:21:45,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:46,113][root][INFO] - Training Epoch: 10/10, step 571/574 completed (loss: 0.5793983936309814, acc: 0.8547008633613586)
[2024-11-29 04:21:46,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:46,724][root][INFO] - Training Epoch: 10/10, step 572/574 completed (loss: 1.1138889789581299, acc: 0.6632652878761292)
[2024-11-29 04:21:46,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 04:21:47,336][root][INFO] - Training Epoch: 10/10, step 573/574 completed (loss: 0.897018551826477, acc: 0.7798742055892944)
[2024-11-29 04:21:47,637][slam_llm.utils.train_utils][INFO] - Epoch 10: train_perplexity=1.5311, train_epoch_loss=0.4260, epoch time 526.1542299762368s
[2024-11-29 04:21:47,637][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 15 GB
[2024-11-29 04:21:47,637][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-29 04:21:47,637][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 15 GB
[2024-11-29 04:21:47,638][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 9
[2024-11-29 04:21:47,638][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-29 04:21:47,640][root][INFO] - Key: avg_train_prep, Value: 7.160559177398682
[2024-11-29 04:21:47,641][root][INFO] - Key: avg_train_loss, Value: 1.314282774925232
[2024-11-29 04:21:47,641][root][INFO] - Key: avg_train_acc, Value: 0.6730289459228516
[2024-11-29 04:21:47,641][root][INFO] - Key: avg_eval_prep, Value: 7.46144437789917
[2024-11-29 04:21:47,641][root][INFO] - Key: avg_eval_loss, Value: 1.7374696731567383
[2024-11-29 04:21:47,641][root][INFO] - Key: avg_eval_acc, Value: 0.5809099674224854
[2024-11-29 04:21:47,641][root][INFO] - Key: avg_epoch_time, Value: 527.2600188363343
[2024-11-29 04:21:47,641][root][INFO] - Key: avg_checkpoint_time, Value: 0.26173219494521616
